---
title: pytorch常用代码
data: 2019-7-25
categories: pytorch
---

```python
torch.randperm(n)  #返回[0,n-1]的数组
```

```python
torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)
# mode 表示当监控量不再下降时减小学习率
# factor 每次学习率减小的比率
# patience 容忍网络性能不提升的次数，高于此次数即减小学习率

#使用方法如下：
optimizer = torch.optim.SGD(model.parameters(), lr=0.01) 
scheduler = ReduceLROnPlateau(optimizer, 'min',factor=0.5, patience=4, verbose=True)
scheduler.step(val_loss)
```

