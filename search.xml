<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[EfficientNet (ICML, 2019)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-EfficientNet-ICML2019%2F</url>
    <content type="text"><![CDATA[论文: EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks作者: Mingxing Tan, Quoc V.Le机构: Google Brain 摘要卷积神经网络(ConvNets)通常是在固定的资源预算下开发的，如果有更多的资源可用，则会进行扩展以获得更高的精度。在本文中，我们系统地研究了模型缩放，并发现仔细平衡网络的深度、宽度和分辨率可以获得更好的性能。在此基础上，我们提出了一种新的 Scaling 方法，该方法使用一个简单而高效的复合系数来均匀地 scale 深度/宽度/分辨率的所有维度。我们证明了该方法在扩展mobilenet和ResNet方面的有效性。更进一步地，我们使用 神经结构搜索 设计了一个新的基线网络，并将其扩展，以获得一系列被称为efficient entnets的模型，这些模型比以前的ConvNets具有更好的准确性和效率。特别是，我们的 EfficientNet-B7 在 ImageNet 上实现了最先进的84.4%的top-1 / 97.1%的top-5精度，同时比现有最好的ConvNet小8.4倍，推理速度快6.1倍。在CIFAR-100(91.7%)、Flowers(98.8%)和其他3个传输学习数据集上，我们的高效网络传输效果也很好，并且达到了最先进的精度，参数少了一个数量级。 Introduction为了获得更好的精度，人们广泛使用了放大的ConvNets。例如，通过使用更多的层，可以将ResNet从ResNet-18扩展到ResNet-200;最近，GPipe将基准模型扩大了四倍，实现了84.3%的ImageNet top-1精度。然而，扩展ConvNets的过程从来没有被很好地理解过，目前有很多方法可以做到这一点。最常见的方法是加深网络的深度或者宽度。另一种不太常见但越来越流行的方法是通过图像分辨率放大模型。在以前的工作中，通常只缩放三个维度中的一个——深度、宽度和图像大小。虽然可以任意缩放两个或三个维度，但是任意缩放需要繁琐的手工调优，而且常常会产生次优的精度和效率。 在这篇论文中，我们想研究和重新思考扩大 ConvNets 的过程。我们研究的中心问题是: 有没有一种原则性的方法来扩大对流，从而达到更好的精度和效率? 我们的实证研究表明，平衡网络宽度/深度/分辨率的所有维度是至关重要的，令人惊讶的是，这种平衡可以通过简单地按比例缩放每个维度来实现。在此基础上观察,我们提出一个简单但有效的复合比例法。与传统的任意缩放这些因子的方法不同，我们的方法使用一组固定的缩放系数来均匀地缩放网络的宽度、深度和分辨率。例如,如果我们想使用 $2^N$ 倍的计算资源,然后我们可以简单地增加网络由 &amp;\alpha^N$ 深度,宽度变成 $\beta^N$, 图像大小变成 $\gamma^N$, $\alpha, \beta, \gamma$ 是常系数, 它们是由小网格搜索在原始小模型上搜索出来的结果。图2说明了我们的缩放方法和传统方法之间的区别。 直观地说，复合缩放方法是有意义的，因为如果输入图像更大，那么网络需要更多的层来增加感受野，需要更多的通道来捕捉更大图像上更细粒度的模式。事实上，之前的理论和实证结果都表明网络宽度和深度之间存在一定的关系，但据我们所知，我们是第一个对网络宽度、深度和分辨率三个维度之间的关系进行实证量化的人。 我们证明了我们的缩放方法在现有的 MobileNet 和 ResNet 上运行良好。值得注意的是，模型缩放的有效性在很大程度上取决于 Baseline Network;为了更进一步，我们使用神经架构搜索来开发一个新的基线网络，并将其扩展以获得一系列模型，称为 EfficientNets。图1总结了ImageNet的性能，其中我们的 EfficientNets 明显优于其他convnet。特别的是，我们的EfficientNet-B7超过了现有的最佳GPipe精度，但是使用的参数少了8.4倍，并且在推断时运行速度快了6.1倍。与广泛使用的ResNet-50相比，我们的 EfficientNet-B4 在类似 FLOPs 的情况下，将 top-1 的精度从 76.3% 提高到了 82.6%(+6.3%)。除了ImageNet, EfficientNets 还可以很好地迁移到 8 个广泛使用的数据集中的 5 个，并达到最先进的精度，同时比现有ConvNets减少了21倍的参数。 Related Work ConvNet Acc: GPipe(过大), 虽然这些模型主要是为ImageNet设计的，但最近的研究表明，更好的ImageNet模型在各种迁移学习数据集和其他计算机视觉任务(如目标检测)中也表现得更好 ConvNet Efficiency: 模型压缩, SqueezeNet, MobileNet, ShuffleNet. 在本文中，我们的目标是研究超大型超精确 ConvNets 的模型效率。为了实现这个目标，我们采用模型缩放。 Model Scaling: 络的深度和宽度对ConvNet的表达能力都很重要，如何有效地缩放ConvNet以获得更好的效率和准确性仍然是一个有待解决的问题。我们的工作系统地和经验地研究了网络宽度、深度和分辨率三个维度的 ConvNet 缩放。 Compound Model Scaling(复合模型扩展)在本节中，我们将阐述缩放问题，研究不同的方法，并提出我们新的缩放方法。 Problem Formulation… Scaling Dimensions问题2的主要难点是最优的d、w、r相互依赖，且在不同的资源约束条件下值会发生变化。由于这一困难，传统的方法大多在这些三维中的某一维进行卷积网络的缩放. Depth(d)扩展网络深度是许多ConvNets最常用的方法。直观的感觉是，更深层次的ConvNet可以捕获更丰富、更复杂的特性，并很好地概括新的任务。然而，由于梯度消失问题，更深层次的网络也更加难以训练。虽然一些技术，如skip connections 和batch normalization 可以缓解训练问题，但是非常深的网络的精度增益会降低:例如，ResNet-1000的精度与ResNet-101相似，尽管它有更多的层。图3(中)显示了我们对不同深度系数d的基线模型进行缩放的实证研究，进一步表明深度卷积网的精度收益递减。 宽度(w)缩放网络宽度通常用于小尺寸模型。如前所述，更广泛的网络往往能够捕获更细粒度的特性，并且更易于培训。然而，非常宽而浅的网络往往很难捕捉到更高层次的特征。我们在图3(左)中得到的经验结果表明，当网络越宽，w越大时，准确率会迅速饱和。 分辨率(r)使用更高分辨率的输入图像，ConvNets可以捕获更细粒度的模式。从早期ConvNets的224x224开始，现代ConvNets倾向于使用299x299或331x331来获得更好的精度。最近，GPipe以480x480分辨率实现了最先进的ImageNet精度。更高的分辨率，如600x600，也广泛用于目标检测卷积。图3(右)显示了缩放网络分辨率的结果，确实更高的分辨率可以提高精度，但是对于非常高的分辨率，精度增益会减小(r = 1.0表示分辨率224x224, r = 2.5表示分辨率560x560)。 以上分析使我们得出第一个观察结果:Observation 1: 扩展网络宽度、深度或分辨率的任何维度都可以提高精度，但是对于较大的模型，精度增益会降低。 Compound Scaling我们从经验上观察到，对不同的维度进行放缩并不是独立的。直观地说，对于高分辨率的图像，我们应该增加网络深度，这样更大的感受野可以帮助捕获包含更大图像中更多像素的类似特性。相应地，我们也应该在分辨率较高的情况下增加网络宽度，以便在高分辨率图像中以更多的像素捕获更多的细粒度模式。这些直觉表明，我们需要协调和平衡不同的维度放缩比例，而不是传统的对单一维度进行放缩. 为了验证我们的直觉，我们比较了不同网络深度和分辨率下的宽度缩放，如图4所示。如果我们只缩放网络宽度w而不改变深度(d=1.0)和分辨率(r=1.0)，那么精度很快就会饱和。随着深度(d=2.0)和分辨率(r=2.0)的提高，宽度缩放在相同的 FLOPs 成本下实现了更高的精度。这些结果使我们得出第二个观察结果: Observation 2: 为了追求更高的精度和效率，在ConvNet缩放过程中平衡网络宽度、深度和分辨率的所有维度是至关重要的。 事实上，之前的一些工作已经尝试过任意平衡网络的宽度和深度，但是它们都需要繁琐的手工调优。 在本文中,我们提出一个新的复合缩放(Compound Scaling)方法,使用一个复合系数 $\phi$ 以一种 principled way 来调节网络宽度、深度和分辨率. d = \alpha^\phiw = \beta^\phir = \gamma^\phis.t. \alpha \cdot \beta^2 \cdot \gamma^2 \approx 2, \alpha \geq 1, \beta \geq 1, \gamma \geq 1上式中, balabala… EfficientNet Architecture由于模型缩放不更改 baseline network 中的网络层算子 $\hat F_i$, 因此有一个好的基线网络也很重要。我们将使用现有的ConvNets来评估我们的缩放方法，但是为了更好地证明我们的缩放方法的有效性，我们还开发了一个新的 mobile-size baseline, 称为 EfficientNet. 受(Tan et al.， 2019)的启发，我们开发了我们的基线网络，利用多目标神经结构搜索，优化 acc 和 FLOPs。具体来说,我们使用相同的搜索空间(Tan et al ., 2019),并使用 $ACC(m)×(FLOPs(m) / T)^w$ 作为优化目标, $ACC(m)$ 和 $FLOPs(m)$ 表示的准确性和模型的 FLOPs. $T$ 是 target FLOPs, w = -0.07, 这是一个 hyperparameter, 用于控制准确性和 FLOPs 之间的权衡。不像(Tan等，2019;Cai等人，2019)，这里我们优化了 FLOPs 而不是 latency(延时)，因为我们没有针对任何特定的硬件设备。我们的搜索产生了一个高效的网络，我们将其命名为 EfficientNet-B0。由于我们使用的搜索空间与(Tan et al.， 2019)相同，所以架构类似于 MnasNet，只是我们的 EfficientNet-B0 稍大一些，因为 FLOPs 目标更大(我们的FLOPS目标是400M)。Table 1给出了 EfficientBet-B0 的体系结构。其主要构建块是 Mobile Inverted Bottlenect MBConv (San- dler et al.,2018);此外，我们还添加了 Squeeze-and-Excitation(Hu et al., 2018)。 从基线 EffectiveNet-B0 开始，我们使用我们的复合缩放方法将其放大，分为两个步骤: 步骤1: 我们首先固定 $\phi = 1$,假设具有两倍多新资源可用, 首先做一个小网格搜索, 得到 $\alpha, \beta, \gamma$。特别的, 我们找到最佳值 EfficientNet-B0 的配置为: $\alpha = 1.2, \beta=1.1, \gamma = 1.15$, 该配置处于 $\alpha \cdot \beta^2 \cdot gamma^2 \approx 2$ 的条件下. 步骤2: 然后我们固定 $\alpha, \beta, \gamma$ 为常量, 同时利用 $\phi$ 来扩展 baseline network 这样就可以获得 EfficientNet-B1 to B7.(细节如表2所示)。 值得注意的是, 直接围绕一个大模型来搜索 $\alpha, \beta, phi$ 可以获得更好的性能, 但是搜索成本却贵得让人望而却步。因此我们的方法只在小型基线网络上搜索一次(步骤1)，然后对所有其他模型使用相同的比例系数(步骤2)，从而解决了这个问题。 Experiments在本节中，我们将首先评估我们对现有的 ConvNets 和新提出的 EfficientNet 的缩放方法。 Scaling Up MobileNets and ResNets作为简单的理论证明，我们首先将我们的缩放方法应用于广泛使用的 MobileNet 和 ResNet。表3显示了以不同方式缩放它们的ImageNet结果。与其他单维尺度法相比，本文提出的复合缩放法提高了所有模型的精度，表明本文提出的缩放法对一般已有的卷积神经网络是有效的。 ImageNet Results for EfficientNet我们在ImageNet上使用类似的设置(Tan等，2019)来训练我们的有效网络模型: RMSProp optimizer, 0.9 decay, 0.9 momentum batch norm momentum 0.99 weight decay 1e-5 initial lr 0.256, decays 0.97 every 2.4 epochs (这个超参调的也太细了吧…) swish activation fixed AutoAugment policy stochastic depth with drop connect ratio 0.2 As commonly known that bigger models need more regularization, we linearly increase dropout (Srivastava et al., 2014) ratio from 0.2 for EfficientNet-B0 to 0.5 for EfficientNet-B7 表2显示了从相同基线 Effecentnet-B0 扩展而来的所有 EffecentNet 模型的性能。我们的 EfficientNet 模型通常参数数量和 FLOPs 更少, 但是却具有和其他 ConvNets 相当的精度。其中，我们的 EffectiveNet-B7 以 66M 参数和 37B FLOPs 实现了 84.4% 的 top1 和 97.1% 的 top5 精度，比之前的最佳的 GPipe精度高, 但是比它小了8.4倍(Huang et al.， 2018)。 图1和图5展示了典型的 ConvNets 的参数量-精确度和FLOPS-精确度曲线，其中我们的 scaled EfficientNet 模型在参数和FLOPS都比其他ConvNets少得多的情况下获得了更好的精确度。值得注意的是，我们的有效网络模型不仅体积小，而且计算成本更低。例如，我们的 EfficientNet-B3 比 ResNeXt-101 (Xie et al.， 2017)使用少于18x的 FLOPs, 但是却获得了更高的精度。 为了验证计算成本，我们还测量了真实CPU上几个典型covnet的推断延迟，如表4所示，我们统计了超过20次运行的平均延迟。我们的EfficientNet-B1运行速度比广泛使用的ResNet-152快5.7倍(He et al.， 2016)，而EfficientNet-B7运行速度大约比GPipe快6.1倍(Huang et al.， 2018)，这表明我们的efficient net在实际硬件上确实是很快的。 Transfer Learning Results for EfficientNet我们还在一系列常用的迁移学习数据集列表上评估了我们的 EfficientNet，如表6所示。我们借鉴了(Kornblith et al.， 2019)和(Huang et al.， 2018)相同的训练设置，在新数据集上使用ImageNet预训练模型并在新的数据集上进行 finetuning. 表5显示了转移学习的性能:(1)与NASNet-A (Zoph et al.， 2018)和 Inception-v4 (Szegedy et al.， 2017)等公共可用模型相比，我们的 EffectiveNet模型的精度更高，平均参数降低4.7倍(高达21倍)。(2)与动态综合训练数据的DAT (Ngiam et al.， 2018)和使用专用管道并行性训练的GPipe (Huang et al.， 2018)等最先进的模型相比，我们的效率网模型在8个数据集中有5个数据集的精度超过了它们，但是使用的参数少了9.6倍 图6比较了各种模型的精度-参数曲线。总的来说，我们的效率网在参数比现有模型少一个数量级的情况下，始终能够达到更好的精度，包括ResNet (He et al.， 2016)、DenseNet (Huang et al.， 2017)、Inception (Szegedy et al.， 2017)和NASNet (Zoph et al.， 2018)。 Discussion为了将我们提出的缩放方法从 EffecentNet 体系结构中分离出来，图8比较了相同 EffecentNet-B0 baseline networks 中不同缩放方法的ImageNet性能。总的来说，所有的缩放方法都可以提高精度，但代价是更多的 FLOPs，但我们的复合缩放方法可以进一步提高精度，比其他一维缩放方法多提高2.5%的精度，这表明我们提出的复合缩放的重要性。 为了进一步理解为什么我们的复合缩放方法比其他方法更好，图7比较了几种具有代表性的模型的 class activation map(Zhou et al.， 2016)。所有这些模型都是从相同的基线进行缩放的，它们的统计数据如表7所示。从ImageNet验证集中随机抽取图像。如图所示，compound scaling 模型更倾向于关注具有更多对象细节的相关区域，而其他模型要么缺乏对象细节，要么无法捕获图像中的所有对象。 Conclusion在本文中，我们系统地研究了ConvNet缩放，并发现仔细平衡网络的宽度、深度和分辨率是一个重要但缺少的部分，这阻碍了我们获得更好的精度和效率。为了解决这个问题，我们提出了一种简单高效的复合缩放方法，使我们能够更有原则地将基线卷积网络缩放到任何目标资源约束，同时保持模型的效率。通过这种复合缩放方法，我们证明了在ImageNet和五种常用的传输学习数据集上，一个移动尺寸的有效网络模型可以非常有效地缩放，以一个数量级更少的参数和更少的失败来超越最先进的精度。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CBAM (ECCV, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-CBAM-ECCV2018%2F</url>
    <content type="text"><![CDATA[CBAM: Convolutional Block Attention Module 摘要作者指出, 目前的大量工作, 在对 backbone 网络进行改进时, 大多会从三个方面进行改进: depth, width, and cardinality. 而作者从另外一个角度: attention 进行改进. 相比于之前的 SE-Block attention 工作, 作者不仅利用了特征图谱中通道之间的关系, 还利用了特征图谱上空间上的关系. 由此提出了 Channel attention module 和 Spatial attention module. 这两个 module 在实现方式上和 BAM 类似. 区别在于 CBAM 是以 Sequential 的形式使用在 basic block 上的, 而 BAM 是以 parallel 的形式使用在 bottleneck 上的. 作者通过使用证明, CBAM 可以使用在大多数的 backbone 网络上, 并且可以在极低的计算资源增加下增强 backbone 网络的能力. 方法CBAM 的整体结构图如下图 1 所示. 原始的 feature map 会首先经过一个 attention 模块, 然后得到的结果会再经过另一个 attention 模块. 最终会利用 element-wise multiplication 将 attention 模块添加到原始的 feature map 之上. CBAM 的 attention 机制由两部分组成. 它的主要机制可以用下面的公式 1 来概括: 两者机制的基本实现如下图 2 所示: 首先是 channel attention module, 该模块的思想和 SE-Block 类似, 都是强调 ‘what’ is meaningful given an input image. 利用了通道间的关系来使用 attention. 和 SE-Block 不同的是, 作者不仅使用了 Global Average Pooling, 同时还使用了 Global Max Pooling. channel attention module 的实现和作用机制可以用下面的公式 2 来概括: 接下来是 Spatial attention module, 和 channel attention module 不同的是, Spatial attention module 是在 channel 维度上进行 pooling 的, 这样, 最终生成的特征图谱的深度就会变成 1. 从直观感受上我们可以看出, Different from the channel attention, the spatial attention focuses on ‘where’ is an informative part. 这一 attention 模块的实现和作用机制可以用下面的公式 3 来概括: 作者建议 CBAM 插入到 backbone 网络的 basic block 部分, 如下图 3 所示. 实验部分实验结果如下所示, 可以看出 CBAM 还有有效果的, 只是作者没有进行 BAM 和 CBAM 的对比实验. 个人觉得, CBAM 和 BAM 的 attention 思想是相同的, 只不过是在具体实现时的作用位置和作用顺序有所区别而已. 可以尝试自己做下实验来看看这两种 attention 方法的优劣.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[BAM (Arxiv, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-BAM-Arxiv2018%2F</url>
    <content type="text"><![CDATA[BAM: Bottleneck Attention Module 摘要在这项工作中，我们把重心放在了Attention对于一般深度神经网络的影响上，我们提出了一个简单但是有效的Attention 模型—BAM，它可以结合到任何前向传播卷积神经网络中，我们的模型通过两个分离的路径 channel和spatial, 得到一个Attention Map，实验验证了我们算法的有效性。 整体的结构图如图1所示 具体细节对于原始的特征图谱, 通过两个不同分支应用 attention 机制. 具体的实现如下图2所示. BAM 的使用方法是: 对于给定的 feature map $F\in R^{C\timesH\timesW}$, BAM可以得到一个 3D 的 Attention map $M(F)\in R^{C\times H\timesW}$, 那么, 增强后的新的特征图谱就可以通过下面的式子计算得到: F' = F + F\otimes M(F)上式中, $\otimes$ 可以是 element-wise summation, element-wise multiply 等, 根据实验结果显示, element-wise summation 效果最好. 为了得到一个有效且强大的 $M(F)$ Attention map 生成模块, 本文从 channel 和 spatial 两个分支分别使用 attention 机制, 然后利用下面的公式计算 $M(F)$: M(F) = \sigma (M_c (F) + M_s (F))上式中, $\sigma$ 代表 Sigmoid 函数. channel attention branch 和 spatial attention branch 的模块结构如下面的公式3和公式4所示, 具体的符号含义可以查阅论文或代码: 在从两个注意力分支中获取通道注意力 $M_c (F)$ 和空间注意力 $M_S (F)$ 后，我们将它们组合起来，生成最终的3D attention map $M(F)$. 由于这两个 attention map 的 shape 不同，我们还需要将 attention map 扩展到 $R^{C\times H\times W}$, 然后将它们合并. 在逐项求和、乘法、max运算等多种组合方法中, 针对梯度流的特点, 我们选择逐项求和. 我们通过实证验证了基于元素的求和在三种选择中效果最好. 求和后, 我们取一个sigmoid函数，得到0到1范围内的三维 attention map $M(F)$. 将该三维注意图与输入特征图F巧妙相乘，然后将其添加到原始输入特征图上，得到细化后的特征图 F' = F + F\otimes M(F)实验部分实验结果如下图所示]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FoveaBox (CVPR, 2019)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FoveaBox-CVPR2019%2F</url>
    <content type="text"><![CDATA[论文: FoveaBox: Beyond Anchor-based Object Detector作者: Tao Kong1 Fuchun Sun1 Huaping Liu1 Yuning Jiang2 Jianbo Shi3机构: 1Department of Computer Science and Technology, Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist) 2ByteDance AI Lab 3University of Pennsylvania 摘要我们提出了一个精确、灵活和 completely anchor-free 的目标检测框架 FoveaBox。虽然几乎所有 sota 对象检测器都使用预定义的 anchor 来枚举可能的位置、尺寸和纵横比来搜索对象，但是它们的性能和泛化能力也受到 anchor 自身设计的限制。相反，FoveaBox 直接学习目标存在的可能性和无需借鉴 anchor 的边界框坐标。这是通过两点来实现的: 预测物体存在可能性的基于类别的语义映射(predicting category-sensitive semantic maps for the object existing possibility) 为每个可能包含对象的位置生成类别无关的边界框(producing category-agnostic bounding box for each position that potentially contains an object)目标 box 的尺度与每个输入图像的特征金字塔表征相关联。Without bells and whistles，FoveaBox在标准的COCO检测基准上实现了 SOTA 的 One-stage 性能42.1 AP。特别是对于任意宽高比的目标，与基于锚点的探测器相比，FoveaBox带来了显著的改进。 更令人惊讶的是，当它受到拉伸过的测试图像的挑战时，FoveaBox对 bounding box 形状变化的分布具有很强的鲁棒性和泛化能力。 Introduction目标检测需要解决两个主要任务:识别和定位。给定任意图像，目标检测系统需要确定是否存在来自预定义类别的语义对象实例，如果存在，则返回空间位置和范围。为了将定位功能添加到通用对象检测系统中，滑动窗口方法多年来一直是[25][7]的首选方法。RCNN, FPN, 略… 但是，使用 anchor 或(候选框)有一些缺点: 首先， anchor 引入了设计选择的 额外超参数。在设计 anchor 时，最重要的因素之一是 anchor 能够覆盖目标位置空间的密集程度。为了获得良好的召回率，anchor 是根据训练/验证集计算的统计数据精心设计的。 其次，基于特定数据集的一种设计选择并不总是适用于其他应用，这损害了通用性。 例如，anchor 是方形的用于人脸检测。而行人检测则需要更多的高桩形式的 anchor。 第三，由于在图像中有大量的候选对象位置定期采样，密集的对象检测器通常依赖有效的技术来处理面临的前-后台类不平衡挑战。 MetaAnchorGuided-Anchoring FoveaBox is motivated from the fovea of human eyes: the center of the vision field (object) is with the highest visual acuity. FoveaBox联合预测对象的中心区域可能存在的位置以及每个有效位置的边界框。多亏了特征金字塔表示，不同尺度的物体可以自然的从多个层次的特征中检测出来. Related WorkClassic Object Detectors: DPM, HOG, SIFT Modern Object Detectors: RCNN, RPN, SSD, YOLO FoveaBoxFoveaBox 是一个单一的、统一的网络，由一个主干网络和两个负责特定任务的子网络组成。backbone 负责计算整个输入图像上的卷积特征图，是一个现成的卷积网络。第一个 subnet 会对 backbone 的输出逐像素进行分类;第二个 subnet 在相应的位置上执行 bounding box prediction。虽然这些组件的细节有许多可能的选择，但为了简单和公平的比较，我们采用了RetinaNet的设计[28]。 Feature Pyramid Network Backbone我们采用特征金字塔网络(FPN)[27]作为后续检测的 backbone network。一般来说，FPN使用自顶向下的体系结构和横向连接，从单尺度的输入图像中构建网络内的特征金字塔。金字塔的每一层都可以用来探测不同尺度的物体。我们构造一个金字塔，其 level 为 ${P_l}, l = 3,4,···,7, 其中 $l$ 表示金字塔级别。$P_l$ 的分辨率是输入图像的 $1/2^l$。所有金字塔级别都有 $C = 256$ 通道。 Scale Assignment虽然我们的目标是预测目标物体的边界，但由于物体的大规模形状变化，直接预测这些数字并不稳定。 相反，我们 根据特征金字塔等级的数量将对象的比例划分到若干个 bins 中去。 每个金字塔的金字塔等级 $P_3$ 到 $P_7$ 的基本面积分别为 $32^2$ 到 $512^2$。 因此，对于级别 $P_l$，基本面积 $S_l$ 由下面的公式计算得到: S_l = 4^l \cdot S_0 \tag 1类似于使用 $C4$ 作为单尺度特征图的基于ResNet的 Faster R-CNN系统，我们将 $S_0$ 设置为 16 (也就是 $4^2$). 在FoveaBox中，每个特征金字塔会学习响应特定尺度的对象。 金字塔等级 $l$ 的目标框的有效比例范围计算为 [S_l / \eta^2, S_l \cdot \eta^2] \tag 2其中 $\eta$ 是根据经验设置的，以控制每个金字塔的比例范围。在训练过程中忽略不在相应尺度范围内的目标对象。注意，一个对象可能被网络的多个金字塔检测到，这与以前只将对象映射到一个特征金字塔的做法不同(FPN, MaskRCNN). Object Fovea金字塔形 heatmap 的每组输出都有 $K$ 个通道，其中 $K$ 是类别数，尺寸为 $H×W$ (图4)。 每个通道都是一个二进制掩码，表示类的可能性。 给出一个 gt box，表示为$(x1,y1,x2,y2)$。我们首先将该框映射到步幅为 $2^l$ 的目标特征金字塔 $P_l$ 上: \begin{cases} x_1' = \frac{x_1}{2^l}, y_1' = \frac{y_1}{2^l} , \\ x_2' = \frac{x_2}{2^l}, y_2' = \frac{y_2}{2^l}, \\ c_x' = x_1' + 0.5(x_2' - x_1'), \\ c_y' = y_1' + 0.5(y_2' - y_1').\end{cases} \tag 3score map 上四边形的 positive area(fovea) 定义为原始四边形的缩小版(见图3)。$R^{pos} = (x_1’’, y_1’’, x_2’’, y_2’’)$ \begin{cases}x_1'' = c_x' - 0.5(x_2'-x_1')\sigma_1, \\ y_1'' = c_y' - 0.5(y_2' - y_1')\sigma_1, \\ x_2'' = c_x' + 0.5(x_2' - x_1')\sigma_1, \\ y_2'' = c_y' + 0.5(y_2' - y_1')\sigma_1, \end{cases} \tag 4 其中 $\sigma_1$ 是收缩因子。 在训练的时候, positive area 内的每个 cell 都用相应的目标类标签进行标注以进行训练。 对于负样本的定义，我们引入另一个缩小因子 $\sigma_2$ 并使用等式(4)生成 $R^{neg}$。negative area 是整个 feature map 中不包括 $R^{neg}$ 的区域(注意, 这里没有写错, 通常 $R^{neg}$ 会比 $R^{pos}$ 大一圈, 而除了这两处之外的其他地方, 皆认为是 background, 即负样本)。 如果单元格未分配，则在训练期间将忽略该单元格。 positive area 通常占整个特征图的一小部分，因此我们使用Focal Loss [28]来训练该分支的 target $L{cls}$。 Box Predictionobject fovea 只编码目标物体存在的可能性。要确定位置，模型必须预测每个潜在实例的边界框。每个 ground-truth 边界框都以 $G = (x1, y1, x2, y2)$ 的方式指定。我们的 目标是学习一个 transformation， 它可以将 feature maps 中在 cell $(x, y)$ 处的网络 localization outputs $(t_{x1}, t_{y1}, t_{x2}, t_{y2})$ 映射到 ground-truth box $G$: \begin{cases}t_{x1} = \log \frac{2^l(x+0.5) - x_1}{z}, \\ t_{y1} = \log \frac{2^l(y+0.5) - y_1}{z}, \\ t_{x2} = \log\frac{x_2 - 2^l(x+0.5)}{z}, \\ t_{y2} = \log\frac{y_2 - 2^l(y+0.5)}{z} \end{cases} \tag 5上式中 $z = \sqrt{S_l}$ 是将输出空间投影到以1为中心的空间的归一化因子，使得目标的学习更加敏捷和稳定. 该函数首先将坐标(x, y)映射到输入图像，然后计算投影坐标与 $G$ 之间的归一化偏移量。最后利用对数空间函数对目标进行正则化。 为简便起见，我们采用广泛使用的 Smooth L1损失[40]训练 box prediction $L_{box}$。优化目标后，我们可以在输出特征图上为每个 positive cell $(x, y)$ 生成 bounding box。我们注意到，在现代深度学习框架中，通过 element-wise layer 可以很容易地实现 Eq.(5)和 inverse transformation。 Optimizationsynchronized SGDlearning rate: 0.005, 180k, 240k, 缩小10倍Weight decay: 0.0001momentum: 0.9standard horizontal image flipping, random aspect ratio jittering.$\sigma_1 = 0.3$, $\sigma_2 = 0.4$ Inference在推理过程中，我们首先使用0.05的置信阈值来过滤掉低置信值的预测。然后，我们从每个预测层中选择前1000个 scoring box。然后，对 每个类 分别应用阈值为0.5的非最大抑制(non-maximum suppression, NMS)。最后，为每个图像选择前100个 scoring predictions。这个推理设置与Detectron基线[13]完全相同。尽管有更智能的方法来执行后处理，如bbox voting[10]、Soft-NMS[2]或 test-time image augmentations，为了保持简单性并与基线模型进行公平比较，我们这里不使用这些技巧。 ExperimentsAblation StudyVarious anchor densities and FoveaBox基于 anchor 的检测系统中最重要的设计因素之一是它如何密集地覆盖可能的图像框的空间。 由于基于 anchor 的探测器使用固定的采样网格，在这些方法中实现高覆盖率的主要方法是在每个空间位置使用多个 anchor 来覆盖各种尺度和纵横比的框。可以预期，当在每个位置上附加更密集的 anchor 时，我们总能获得更好的性能。为了验证这一假设，我们枚举了 RetinaNet 中每个空间位置和每个金字塔等级使用的比例和纵横比 anchor 的数量，包括每个位置的单个方形 anchor 到每个位置 12个 anchor, 如表 1(a) 所示。 当增加超过 6~9 个 anchor 后模型并没有显示出进一步的收益。 性能或者说密集程度的饱和意味着手工制作的、密度过大的 anchor 没有优势。 过于密集的 anchor 不仅会增加 前景-背景 的优化难度，而且还可能导致模糊位置定义问题。 对于每个输出空间的 location 来说，其 anchors 的标签根据与 GT 的 IoU 值定义。 其中，有一些 anchor 被定义为 positive samples，而另一些则被定义为 negative samples。 但是，它们共享这相同的 feature maps。因此分类器不仅需要区分不同位置的样本，还需要在同一位置区分不同的 anchor。 相比之下，FoveaBox 会明确预测每个位置的一个目标，并且其性能不比最好的 anchor-based 模型差。 target 的标签由它是否在物体的边界框内定义。 与 anchor-based 的方案相比，FoveaBox 具有几个优点: 由于我们在每个位置只会预测一个目标，因此输出空间已减少到 anchor based 方法的 $1/A$，其中A是每个位置的 anchor 数量。由于 前景-背景 的分类难度已经减轻，因此更容易优化模型。 没有位置定义模棱两可的问题，优化的目标更为直接 FoveaBox 在使用上更灵活，因为我们不需要认为设计 anchor 来获得相对更好的结果 Analysis of Scale Assignment在公式(2)中, $\eta$ 控制了每一个金字塔层级的尺度匹配范围. 当 $\eta=\sqrt 2$ 时，物体的尺度会被划分为 非重叠 的区间，每个区间由相应的特征金字塔进行预测。 随着 $\eta$ 的增加，每个金字塔都会响应更多的物体尺度, 这就使得同一个尺度可能会被不同的金字塔层级进行检测。 表2显示了 $\eta$ 最终检测性能的影响。(在本文的实验中, 我们使用 $\eta = 2$) FoveaBox is more robust to box distributions与传统的预定义 anchor 策略不同，FoveaBox 的主要优点之一是对边界框预测的鲁棒性。 为了验证这一点，我们进行了两个实验来比较不同方法的定位性能。 在第一个实验中，我们根据 GT 的宽高比将验证集中的 boxes 划分成三组, GT 宽高比为 $U={u_i= \min(\frac{h_i}{w_i},\frac{w_i}{h_i})}, i = 1,···,N$, 其中 $N$ 是数据集中的实例数量。我们在不同的长宽比阈值下比较 FoveaBox 和 RetinaNet, 如表 1(b) 所示。 这里*表示训练模型的时候会使用 aspect ratio jittering。我们看到，当 $u$ 很低时，两种方法都能获得最佳性能。 虽然 FoveaBox 在 $u$ 增加时也会降低性能，但它比 anchor free 的 RetinaNet 要好得多。 为了进一步验证不同方法的边界框的鲁棒性，我们手动拉伸图像以及验证集中的标注，并查看不同检测器的行为。 图5显示了在不同 $h/w$ 拉伸阈值下的 localization 性能。在 $h/w=1$ 的评估标准下，两个检测器之间的性能差距相对较小。 随着我们增加拉伸阈值，差距开始增大。 具体来说，当将 $h/w$ 拉伸3倍时，FoveaBox获得21.3的AP，比对应的 RetinaNet* 高3.7分。 anchor based 方法依赖于具有 anchor reference 的 box regression 来生成最终边界框。 在实践中，回归器是针对 positive anchor 进行训练的，这将在预测更多任意形状的目标时损害其泛化性。 在FoveaBox中，每个预测位置与特定参考形状无关，它会直接预测目标的 GT Box。 由于FoveaBox允许生成任意宽高比的 box，因此它能够更好地捕获那些极高或极宽的物体。 具体可参见图6中的一些示例。 Per-class difference图2显示了 FoveaBox 和 RetinaNet 每一类的 AP 差异。 它们都具有 ResNet-50-FPN BackBone 和 800 的输入尺寸。 纵轴代表 $AP_{FoveaBox} - AP_{RetinaNet}$ 的值。 FoveaBox 对于大多数类都能获得一定改进，特别是对于边界框更随意的类, 例如对于类牙刷，叉子，运动球，滑雪板，领带和火车等，AP的改进都大于 5 个点。 Generating high-quality region proposals将 classification target 更改为与 class-agnostic head 是非常直截的，并且可以生成 region proposals。 我们将 proposal performance 与 RPN[40]进行比较，并使用在 COCO minival 上生成不同数量的 proposals 集合来评估平均召回率（AR），如表1（c）所示。 令人惊讶的是，我们的方法在所有标准中都大大优于RPN baseline。 具体来说，在前100个 region proposals 中，FoveaBox获得53.0 AR，高出RPN 8.5分。 这证实了我们的模型在生成高质量 region proposals 方面的能力。 Across model depth and scale表3显示了FoveaBox利用不同的 backbone 和 input resolutions 的 AP 性能。Inference settings 与RetinaNet完全相同，速度也与相应的 baseline 相同。 如表3所示，FoveaBox 对 RetinaNet baseline 始终提高提升 1~2分。 并且这种提升来自与所有尺度(S, M, L)的物体。 Main Results我们将FoveaBox与表4中目标检测 SOTA 的方法进行了比较。我们模型的所有实例都优于以前的模型的 baseline variants。 表4中的第一组 detectors 是 two-stage detectors，第二组是 one-stage detectors，最后一组是 FoveaBox detector。 在所有评估指标下，FoveaBox 优于 ResNet-101 backbone 下的所有 one-stage detector。 这包括最近的 CornerNet。 FoveaBox 也优于大多数 two-stage detector，包括 FPN 和 Mask R-CNN 。 two-stage detector 依赖于 region-wise sub-networks 来进一步对 sparse region proposals 进行分类。 Cascade R-CNN 将 two-stage 方案扩展到多个 stage 以进一步 refine region。 由于 FoveaBox 还可以通过将模型 head 改为 class agnostic scheme（表1（c））来生成 region proposals，我们相信它可以进一步提高 two-stage detector 的性能，不过这超出了本文的重点, 故暂时不做讨论. More Discussions to Prior WorksScore Mask for Text Detection: score mask 技术已经广泛应用于文本检测领域。 这些工作通常利用完全卷积网络[32]来预测目标场景文本和四边形形状的 existence。 与场景文本检测相比，通用对象检测更具挑战性，因为它面临更多的遮挡，多类别分类和规模问题。简单地将文本检测方法应用于通用对象检测通常会得到较差的性能。 Guided-Anchoring: 它共同预测了可能存在感兴趣目标中心的位置以及以相应位置为中心的尺度和宽高比。 如果 $(x,y)$ 不在目标中心，则检测到的框不是最佳框。 Guided-Anchoring 依靠中心点来提供最佳预测。 相比之下，FoveaBox 预测每个前景位置的对象（左，上，右，下）边界，这更加健壮。 FSAF: 这是与 FoveaBox 同时期的工作。 它还尝试直接预测目标对象的边界框。 FoveaBox和FSAF之间的区别是: FSAF依靠在线特征选择模块为每个实例和锚点选择合适的特征。 在FoveaBox中，特定尺度的实例同时由相邻的金字塔进行优化, 具体层级有方程(2)确定，这更加简单和稳健。 为了优化 box boundary，FSAF 利用 IoU-Loss [47]来最大化 predicted box 和 GT 之间的 IoU。在 FoveaBox中，我们使用 Smooth L1 损失直接预测四个边界，这更简单直接。 与 FSAF 相比，FoveaBox显示出更好的性能，如表5所示. CornerNet: CornerNet 通过左上角和右下角的关键点对来检测对象。 CornerNet 的关键步骤是 识别哪些关键点属于同一个实例并正确分组。 相反，在 FoveaBox 中, 实例的类和边界框关联在一起。 我们直接预测框和类，不需要任何分组方案来分隔不同的实例。 Conclusionanchor 的数量并不是越多越好, 虽然直观上来说, anchor 越多时, 可以覆盖越好的 gt box, 但是, 当 anchor 的数量过多时, 一方面由于每一个点上产生的 anchor 实际上共享了一块相似的特征, 但是这些 anchor 有一部分作为正样本, 而另一部分作为负样本, 因此, 对于神经网络来说, 他要通过不断学习来区分这些样本, 不仅如此, 他还要将这些样本与其他点产生的 anchor 区分开, 虽然 anchor 数量的增多, 学习的难度也就慢慢增多, 最终甚至会出现掉点的现象, 个人任务不会掉的特别多, 因为毕竟更多的 anchor 可以覆盖更多的局部最优解. 但是 anchor 会导致计算量的上升, 因此不建议设置过多 anchor. FoveaBox 的优势(就 anchor 来说): (1) 神经网络的输出维度大大降低(1/A), 学习起来相对简单直接; (2) 不会出现 anchor 之间互相矛盾的现象 (3) 没有了 anchor 后, 检测网络变的更加简单直接, 扩展性更好]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[牛客2018年校招真题]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-%E7%89%9B%E5%AE%A22018%E5%B9%B4%E6%A0%A1%E6%8B%9B%E7%9C%9F%E9%A2%98%2F</url>
    <content type="text"><![CDATA[拼多多-最大乘积题目描述给定一个无序数组，包含正数、负数和0，要求从中找出3个数的乘积，使得乘积最大，要求时间复杂度：O(n)，空间复杂度：O(1)输入描述:无序整数数组A[n]输出描述:满足条件的最大乘积 示例1输入3 4 1 2输出24 解法一: 记录三个最大值, 两个最小值最终的结果只可能是三个最大值的乘积, 或者是两个最小值(负负得正)和一个最最大值的乘积 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;climits&gt;int main() &#123; int n; std::cin &gt;&gt; n; std::vector&lt;long long&gt; vec(n); for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; vec[i]; &#125; if (vec.size() &lt; 3) return 0; std::priority_queue&lt;long long, std::vector&lt;long long&gt;, std::greater&lt;long long&gt;&gt; min_heap; std::priority_queue&lt;long long&gt; max_heap; for (auto v : vec) &#123; if (min_heap.size() &lt; 3 or v &gt; min_heap.top()) &#123; if (min_heap.size() == 3) min_heap.pop(); min_heap.push(v); &#125; if (max_heap.size() &lt; 2 or v &lt; max_heap.top()) &#123; if (max_heap.size() == 2) max_heap.pop(); max_heap.push(v); &#125; &#125; long long max_digits[3]; for(int i = 0; i &lt; 3; i++) &#123; max_digits[i] = min_heap.top(); min_heap.pop(); &#125; long long res1 = max_digits[0] * max_digits[1] * max_digits[2]; long long min_digits[2]; for(int i = 0; i &lt; 2; i++) &#123; min_digits[i] = max_heap.top(); max_heap.pop(); &#125; long long res2 = min_digits[0] * min_digits[1] * max_digits[2]; std::cout &lt;&lt; std::max(res1, res2) &lt;&lt; std::endl; return 0;&#125; 拼多多-大整数相乘题目描述大数乘法, 给定任意位数的两个大数, 写出计算结果(以字符串形式). 常用的解法有三种: 模拟计算的普通大数乘法, 分治算法, FFT算法 普通大数乘法: 空间复杂度低, 时间复杂度为 $O(nm)$分治算法: 时间复杂度为 $O(N^{log_2 3}) = O(N^{1.58})$FFT算法(快速傅里叶变换): 较复杂, 一般不会作为考察点 解法一: 模拟乘法时间复杂度: $O(mn)$, $m, n$ 分别为两个大整数的长度 先实现大整数乘以单个数的乘法, 再实现两个大整数的加法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import sysstr_num1, str_num2 = sys.stdin.readline().split()len1 = len(str_num1)len2 = len(str_num2)def multiply(str_num1, c): str_num1 = list(str_num1) len1 = len(str_num1) carry = 0 res = 0 for i, n in enumerate(str_num1[::-1]): i = len1 - 1 - i tmp = int(n) * int(c) + carry carry = tmp // 10 str_num1[i] = str(tmp % 10) return ''.join(str_num1) if carry == 0 else str(carry) + ''.join(str_num1)def big_add(str1, str2): if (len(str1) &lt; len(str2)): str1, str2 = str2, str1 len1 = len(str1) len2 = len(str2) str1 = list(str1) carry = 0 for i, c in enumerate(str1[::-1]): j = len2 - 1 - i i = len1 - 1 - i if (j &gt;= 0): tmp = int(str1[i]) + int(str2[j]) + carry str1[i] = str(tmp % 10) carry = tmp // 10 elif carry != 0: tmp = int(str1[i]) + carry str1[i] = str(tmp % 10) carry = tmp // 10 else: break; return ''.join(str1) if carry == 0 else str(carry) + ''.join(str1)res = '0'suffix = ''for i, n in enumerate(str_num2[::-1]): tmp = multiply(str_num1, n) tmp += suffix suffix += '0' res = big_add(res, tmp)print(res) 解法二: 模拟乘法时间复杂度与解法一相同, 只不过这里是直接先申请了一定长度的结果列表res, 然后根据乘法的规则从后往前填写每一位的值, 注意进位的存储和使用. 1234567891011121314import sysstr_num1, str_num2 = sys.stdin.readline().split()len1 = len(str_num1)len2 = len(str_num2)res = ['0'] * (len1 + len2)for i, n1 in enumerate(str_num1[::-1]): for j, n2 in enumerate(str_num2[::-1]): index = (len1 + len2) - 1 - j - i tmp = int(n1) * int(n2) + int(res[index]) res[index] = str(tmp % 10) res[index-1] = str(int(res[index-1]) + tmp // 10) #这里注意之前不能直接等于, 因为上一次得到的进位还没有加到结果中print(''.join(res)) if res[0] != '0' else print(''.join(res[1:])) 分治法https://blog.csdn.net/jeffleo/article/details/53446095 对于任意位数的两个数相乘 $a \times b$, 可以写成 ($n_1, n_2$ 分别为两个乘数的位数): a = a_1 \times 10^{(\frac{n_1}{2})} + a_0b = b_1 \times 10^{(\frac{n_2}{2})} + b_0于是就有: a \times b = a_1\times b_1\times 10^{(\frac{n_1 + n_2}{2})} + a_1\times b_0 \times 10^{(n_1 / 2)} + a_0 \times b_1 \times 10^{(\frac{n_2}{2})} + a_0 \times b_0通过 递归 的方法不断分解上面的乘法, 最终可以不断降低问题的规模, 时间复杂度可以降为 $O(N^{log_2 3}) = O(N^{1.58})$ 通常, 我们选择两个数中有一个数的位数为 1 时结束递归, 代码实现如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import sysstr_num1, str_num2 = sys.stdin.readline().split()# 自己实现的普通加法def str_add(str_num1, str_num2): len1 = len(str_num1) len2 = len(str_num2) res = ['0'] * max(len1 + 1, len2 + 1) for i in range(len(res)): i1 = len1 - 1 - i i2 = len2 - 1 - i i = len(res) - 1 - i num1 = 0 if i1 &lt; 0 else int(str_num1[i1]) num2 = 0 if i2 &lt; 0 else int(str_num2[i2]) tmp = int(res[i]) + num1 + num2 res[i] = str(tmp % 10) if i &gt; 0: res[i-1] = str(tmp // 10) return ''.join(res) if res[0] != '0' else ''.join(res[1:])# 分治def dc_multiply(str_num1, str_num2, str_zero): # dc: divide and conquer len1 = len(str_num1) len2 = len(str_num2) if (len1 == 1 or len2 == 1): # 当某个为1时, 直接乘法, 实际上也可以定为当某个数位数为8时就执行 val = int(str_num1) * int(str_num2) return str(val) + str_zero str_num1_front = str_num1[ : len1//2] str_num1_back = str_num1[len1//2 : ] str_num2_front = str_num2[ : len2//2] str_num2_back = str_num2[len2//2 : ] # 分别计算四个分段的乘法, 注意不要忘了记录各个位数的 0 的个数 tmp1 = dc_multiply(str_num1_front, str_num2_front, '0' * (len(str_zero) + len1 - len1//2 + len2 - len2//2)) tmp2 = dc_multiply(str_num1_front, str_num2_back, '0' * (len(str_zero) + len1 - len1//2)) tmp3 = dc_multiply(str_num1_back, str_num2_front, '0' * (len(str_zero) + len2 - len2//2)) tmp4 = dc_multiply(str_num1_back, str_num2_back, '0' * len(str_zero)) # 将四个加起来 res = str_add(tmp1, str_add(tmp2, str_add(tmp3, tmp4))) return resprint(dc_multiply(str_num1, str_num2, '')) 上面的写法是当某个数的位数为 1 时, 使用内置乘法进行计算, 但是实际上, 会存在一个数的位数为 1, 另一个数为大整数的情况, 此时, 就必须使用自实现的大整数乘法来计算, 如下所示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import sysstr_num1, str_num2 = sys.stdin.readline().split()# 自己实现的普通乘法def str_multiply(str_num1, str_num2, str_zero): len1 = len(str_num1) len2 = len(str_num2) res = ['0'] * (len1 + len2) for i, n1 in enumerate(str_num1[::-1]): for j, n2 in enumerate(str_num2[::-1]): index = (len1 + len2) - 1 - j - i tmp = int(n1) * int(n2) + int(res[index]) res[index] = str(tmp % 10) if index &gt; 0: res[index-1] = str(int(res[index-1]) + tmp // 10) #这里注意之前不能直接等于, 因为上一次得到的进位还没有加到结果中 res.append(str_zero) return ''.join(res) if res[0] != '0' else ''.join(res[1:])# 自己实现的普通加法def str_add(str_num1, str_num2): len1 = len(str_num1) len2 = len(str_num2) res = ['0'] * max(len1 + 1, len2 + 1) for i in range(len(res)): i1 = len1 - 1 - i i2 = len2 - 1 - i i = len(res) - 1 - i num1 = 0 if i1 &lt; 0 else int(str_num1[i1]) num2 = 0 if i2 &lt; 0 else int(str_num2[i2]) tmp = int(res[i]) + num1 + num2 res[i] = str(tmp % 10) if i &gt; 0: res[i-1] = str(tmp // 10) return ''.join(res) if res[0] != '0' else ''.join(res[1:])# 分治def dc_multiply(str_num1, str_num2, str_zero): # dc: divide and conquer len1 = len(str_num1) len2 = len(str_num2) if (len1 == 1 or len2 == 1): # 当某个为1时, 直接乘法, 实际上也可以定为当某个数位数为8时就执行 return str_multiply(str_num1, str_num2, str_zero) str_num1_front = str_num1[ : len1//2] str_num1_back = str_num1[len1//2 : ] str_num2_front = str_num2[ : len2//2] str_num2_back = str_num2[len2//2 : ] # 分别计算四个分段的乘法, 注意不要忘了记录各个位数的 0 的个数 tmp1 = dc_multiply(str_num1_front, str_num2_front, '0' * (len(str_zero) + len1 - len1//2 + len2 - len2//2)) tmp2 = dc_multiply(str_num1_front, str_num2_back, '0' * (len(str_zero) + len1 - len1//2)) tmp3 = dc_multiply(str_num1_back, str_num2_front, '0' * (len(str_zero) + len2 - len2//2)) tmp4 = dc_multiply(str_num1_back, str_num2_back, '0' * len(str_zero)) # 将四个加起来 res = str_add(tmp1, str_add(tmp2, str_add(tmp3, tmp4))) return resprint(dc_multiply(str_num1, str_num2, '')) 拼多多-六一儿童节题目描述六一儿童节，老师带了很多好吃的巧克力到幼儿园。每块巧克力j的重量为w[j]，对于每个小朋友i，当他分到的巧克力大小达到h[i] (即w[j]&gt;=h[i])，他才会上去表演节目。老师的目标是将巧克力分发给孩子们，使得最多的小孩上台表演。可以保证每个w[i]&gt; 0且不能将多块巧克力分给一个孩子或将一块分给多个孩子。输入描述:第一行：n，表示h数组元素个数 第二行：n个h数组元素 第三行：m，表示w数组元素个数 第四行：m个w数组元素输出描述:上台表演学生人数 解法一: 排序时间复杂度: $O(mn)$空间复杂度:$$ $O(1)$ 先将两个数组排序, 然后对于每块巧克力, 找到恰好能满足的小孩, count+1, 并将该小孩清除出队列 12345678910111213141516171819import sysn = sys.stdin.readline().split()h = [int(x) for x in sys.stdin.readline().split()]m = sys.stdin.readline().split()w = [int(x) for x in sys.stdin.readline().split()]h.sort()w.sort()count = 0for i, wi in enumerate(w): for j, hj in enumerate(h): if wi &gt;= hj: h.pop(j) count += 1 breakprint(count) 拼多多-迷宫寻路题目描述题目链接 题目描述假设一个探险家被困在了地底的迷宫之中，要从当前位置开始找到一条通往迷宫出口的路径。迷宫可以用一个二维矩阵组成，有的部分是墙，有的部分是路。迷宫之中有的路上还有门，每扇门都在迷宫的某个地方有与之匹配的钥匙，只有先拿到钥匙才能打开门。请设计一个算法，帮助探险家找到脱困的最短路径。如前所述，迷宫是通过一个二维矩阵表示的，每个元素的值的含义如下 0-墙，1-路，2-探险家的起始位置，3-迷宫的出口，大写字母-门，小写字母-对应大写字母所代表的门的钥匙输入描述:迷宫的地图，用二维矩阵表示。第一行是表示矩阵的行数和列数M和N后面的M行是矩阵的数据，每一行对应与矩阵的一行（中间没有空格）。M和N都不超过100, 门不超过10扇。输出描述:路径的长度，是一个整数 解法]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FSAF (CVPR, 2019)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FSAF-CVPR2019%2F</url>
    <content type="text"><![CDATA[论文: Feature Selective Anchor-Free Module for Single-Shot Object Detection作者: Chenchen Zhu Yihui He Marios Savvides 摘要本文提出了一种简单有效的针对 single-shot detector 的 Feature Selective Anchor Free(FSAF) 模块。它可以嵌入到具有特征金字塔结构的任何 single-shot detector 中。FSAF模块解决了传统 anchor-based 检测方法存在的 两个局限性: 1)启发式引导的特征选择; 2)overlap-based anchor sampling。 FSAF模块的基本概念是将 在线特征选择 应用于多级 anchor free 分支的训练。具体来说，一个 anchor free 分支会被附加到特征金字塔的每一层，允许在任意一层以 anchor free 的方式进行 box 的编码和解码。在训练过程中，我们动态地将每个实例分配到最合适的金字塔特征级别。在 inference 阶段，FSAF 模块可以通过并行输出 predictions 来与 anchor-based 分支协同工作。我们用 anchor free 的简单实现和在线特征选择策略实现了这个想法。在COCO检测任务上的实验结果表明，我们的 FSAF 模块性能优于 anchor-based 的同类模块，同时速度更快。当与 anchor-based 的分支协同工作时，FSAF 模块在各种条件下都显著提高了 baseline RetinaNet 的性能，同时引入了几乎 free 的 inference cost。本文所得到的最佳模型可以获得 SOTA 的44.6%的mAP，性能优于COCO上现有的所有 single-shot detector 。 Introduction目标检测是计算机视觉领域的一项重要任务。它是各种下游视觉应用的先决条件，如实例分割[12]、人脸分析[1,39]、自动驾驶汽车[6,20]和视频分析[25,33]。由于深度卷积神经网络[16,29,13,34]和注释良好的数据集[7,23]的发展，对象检测器的性能得到了显著提高。 Anchor box… 然而，这种设计(anchor box)有两个局限性:1)启发式引导的特征选择;2)基于覆盖锚取样。在训练过程中，每个实例总是根据IoU重叠匹配到最近的锚盒(es)。而锚框则通过 人类定义 的规则(如框的大小)与特定级别的功能映射相关联。因此，为每个实例选择的特性级别完全基于自组织启发式。例如,一个50×50像素大小的汽车实例和另一个类似的 60x60 大小的汽车实例可能分配到两个不同的 feature levels, 而另一个 40×40 的汽车实例可能被分配到和 50×50 实例相同的 feature levels,如图2所示。换句话说，anchor 匹配机制本质上是启发式引导的。这将导致一个主要缺陷，即用于训练每个实例的所选特征级别可能不是最优的。(与认为定义的 anchor 参数有关) 为了同时解决这两个缺点，我们提出了一种简单有效的方法 - Feature Selective Anchor Free(FSAF)模块。我们的动机是 让每个实例自由地选择最佳级别的金字塔特征来优化网络，因此在我们的模块中不应该有 anchor box 来约束特征的选择。相反，我们以 anchor free 的方式对实例进行编码，以学习用于分类和回归的参数。图3给出了概念示意图。每个层次的特征金字塔都会构建一个 anchor free 分支，该分支独立于 anchor based 分支。与 anchor based 分支类似，它由 classification subnet 和 regression subnet 组成(如图所示)。可以将实例分配到 anchor free 分支的任意级别。在训练过程中，我们 根据实例内容动态地为每个实例选择最合适的金字塔特征级别，而不是仅仅根据实例框的大小。然后，所选的特征级别将检测所分配到的对应实例。在 inference 时，FSAF 模块可以独立运行，也可以与 anchor-based 的分支联合运行。我们的 FSAF 模块与 backbone 无关，因此可以应用到任何具有特征金字塔结构的 single-shot 检测器中。此外，anchor free 分支的具体实例化和 online feature selection 可以是多种多样的。在这项工作中，我们保持我们的 FSAF 模块的实现简单，使其计算成本和整个网络相比只增加一点. 我们在COCO[23]目标检测的 benchmark 上的大量实验验证了该方法的有效性。FSAF模块本身性能优于 anchor based 的对应模块，运行速度也更快。在与 anchor-based 分支协同工作时，FSAF模块可以在不同主干网之间持续大幅度地改进 strong baselines，同时引入最小的计算成本。特别的，我们使用 ResNeXt-101[34]提高了将 RetinaNet 的分数提高了 1.8%，并且仅增加了6ms的推断延迟。此外，我们最终的 detector 在使用 multi-scale testing 时实现了 SOTA 的44.6%的 mAP，超过了所有现有的 single-shot detector. Related WorkSSD, FPN, DSSD, RetinaNet, DetNetDenseBox, UnitBox, CornerNet Feature Selective Anchor-Free Module在本节中，我们实例化了 Feature Selective Anchor Free(FSAF)模块，展示了如何将它应用于具有特征金字塔的 single-shot detector，如SSD[24]、DSSD[8]和RetinaNet[22]。在不失一般性的前提下，我们将FSAF模块应用到目前最先进的RetinaNet[22]中，并从以下几个方面展示了我们的设计: 如何在网络中创建 anchor-free 分支(3.1) 如何为 anchor free 支路生成 supervision signals(监控信号)(3.2); 如何为每个实例动态选择 feature level (3.3); 如何联合训练和测试 anchor free 分支和 anchor based 的分支(3.4)。 Network Architecture从网络模型的角度来看，我们的FSAF模块非常简单。图4说明了带有FSAF模块的RetinaNet[22]的体系结构。简而言之，RetinaNet由一个主干网络和两个用于特定任务的子网组成。特征金字塔 backbone 网络的P3到P7构成，其中 $l$ 为金字塔级，$P_l$ 的分辨率为输入图像的 $1/2^l$。为了简单起见，只显示了三个级别。金字塔的每一层都用于探测不同尺度(scale)的物体。为此，每一层的 $P_l$ 都附加了一个分类子网和一个回归子网，它们都是小的全卷积网络。分类子网为 A 个 anchor 中每个 anchor 和K个对象类预测对象在每个空间位置的概率。如果存在，回归子网预测每个 anchor 到附近实例的4维类无关偏移量。 在RetinaNet的顶部，我们的FSAF模块仅为每个金字塔层引入两个额外的conv层，如图4中虚线 feature maps 所示。这两个网络层分别负责 anchor free 分支的分类和回归预测。更具体地说，我们会在分类子网中最后的 feature map 上附加了一个带有 $K$ 个 filter 的 3×3 conv 层，后面是 sigmoid 函数, 用于二分类，该网络层与 anchor based 分支的网络层并行。它为K个对象类预测对象会出现在每个空间位置的概率。同样的，回归子网中的 feature map 上也附加了一个 3×3 conv 层，带有 4 个filter，然后是ReLU[26]函数。它负责预测以 anchor free 方式编码的 bbox 偏移量。 因此，anchor free 和 anchor based 分支可以以多任务的方式联合工作，共享每个金字塔级别的特性。 Ground-truth and Loss给定一个对象实例，我们已知它的类标签 $k$ 和边界框坐标 $b = [x, y, w,h]$，其中 $(x, y)$ 是框的中心，$w,h$ 分别是框的宽度和高度。在训练过程中，实例可以被分配到任意的 feature level $P_l$。我们将投影框 $b^l_p = [x_p^l, y_p^l, w_p^l, h_p^l]$ 定义为 $b$ 在特征金字塔 $P_l$ 上的投影，即 $b^l_p = b/2^l$。我们还定义了 $b_p^l$ 的部分区域分别为 effective box $b_e^l = [x_e^l, y_e^l, w_e^l, h_e^l]$ 和 ignoring box $b_i^l = [x_i^l, y_i^l, w_i^l, h_i^l]$, 它们分别受到缩放因子 $\epsilon_e$ 和 $\epsilon_i$ 的控制, $x^l_e = x^l_p, y_e^l= y_p^l, w_e^l = \epsilon_e w_p^l, h_e^l = \epsilon_e h_e^l, x_i^l = x_p^l, y_i^l = y_p^l, w_i^l = \epsilon_i w_p^l, h_i^l = \epsilon_i h_p^l$, 在本文中, 我们设置 $\epsilon_e = 0.2, \epsilon_i = 0.5$. 图5显示了一个为car实例生成ground-truth的示例。 Classification Output: 针对分类输出的 gt 是 $K$ 个 maps，每个 map 对应一个类。每个实例以三种方式影响第 $k$ 个 gt map。首先，effective box $b^l_e$ 区域是由 “car” class map 中的白色方框所填充的 positive region，表示该实例的存在性。其次，不包括 effective box 的 ignoring box $(b^l_i−b^l_e)$ 是显示为灰色区域的 ignoring region，这意味着该区域的梯度不会传播回网络。第三，相邻特征层 $(b^{l-1}_i, b^{l+1}_i)$ 中的忽略框如果存在，也将忽略该区域。注意，如果两个实例的 effective box 在一个特征级别上重叠，则较小的实例具有更高的优先级。gt map 的其余区域是由零填充的 negative region(黑色)，表示没有对象。我们使用 Focal Loss 作为损失函数进行监督, 超参数 $\alpha = 0.25$, $\gamma = 2.0$。图像 anchor free 分支的分类总损失是所有非忽略区域上的 Focal Loss 之和，由所有 effective box 区域内的像素总数归一化 Box Regression Output: 回归输出的 gt 是 4 个与类别无关的 offset maps。实例只影响 offset maps 上的 $b^l_e$ 区域。对于 $b^l_e$ 中的每一个像素 location $(i, j)$, 我们将 projected box 表示为一个四维矢量 $d^l_{i,j} = [d^l_t_{i,j}, d^l_l{i,j}, d^l_b{i,j}, d^l_r_{i,j}]$, 其中, $d^l_t, d^l_l, d^l_b,d^l_r$ 是当前像素位置 $(i, j)$ 分别和 $b^l_p$ 顶部,左部,底部,右部边界之间的距离。然后将4个 offset maps 上(i, j)处的四维向量设置为 $d^l_{i,j}/S$，每个 map 对应一个维度。$S$ 是一个归一化常量，我们根据经验选择 $S = 4.0$。effective box 外的位置是忽略梯度的灰色区域。我们采用IoU损失[36]进行优化。图像 anchor free 分支的总回归损失是所有有效盒区域IoU损失的平均值. 在 Inference 过程中，很容易从分类和回归输出中解码 predicted boxes。在每个像素位置 $(i, j)$,假设 predicted offsets 为$[\hat o_t_{i,j}, \hat o_l_{i,j}, \hat o_b_{i,j}, \hat o_r_{i,j}]$。然后 predicted distances 为 $[S\hat o_t_{i,j}, S\hat o_l_{i,j}, S\hat o_b_{i,j}, S\hat o_r_{i,j}]$。predicted projected box 左上角和右下角分别为 $i-S\hat o_t_{i,j}, j-S\hat_l_{i,j}$ 和 $i+S\hat b_{i,j}, j+S\hat o_r_{i,j}$。我们进一步将投影框放大 $2^l$，得到图像平面中的最终框。框的置信度和类别由分类输出图上位置 $(i, j)$ 处的 $k$ 维向量的最大得分和对应的类决定。 Online Feature Selectionanchor free 分支的设计允许我们使用任意金字塔级 $P_l$ 的特征来学习每个实例。为了找到最优的特征级别，我们的FSAF模块根据实例内容(instance content)选择最佳 $P_l$，而不是像anchor-based的方法中那样选择实例框的大小。 以实例 $I$ 为例，将其在 $P_l$ 上的分类损失和box回归损失分别定义为 $L^I_{FL}(l)$ 和 $L^I_{IoU}(l)$。它们的是通过平均有效盒区 $b^l_e$ 上的 Focal Loss 和 IoU loss 得到的，即: L^I_{FL}(l) = \frac{1}{N(b^l_e)}\sum_{i,j \in b^l_e} FL(l, i, j)L^I_{IoU}(l) = \frac{1}{N(b^l_e)}\sum_{i,j \in b^l_e} IoU(l, i, j)其中 $N(b^l_e)$ 为 $b^l_e$ 区域内的像素个数，$FL(l,i,j)$、$IoU(l,i,j)$ 分别为 $P_l$ 在 location $(i,j)$ 处的 Focal Loss[22]和IoU Loss[36]。 图6显示了 FASF 过程。首先，实例 $I$ 通过特征金字塔所有层级的 forward 计算。在此基础上，对所有 anchor free 支路进行计算 $L^I_{FL}(l)$ 和 $L^I_{IoU}(l)$ 的求和。最后，我们选择产生最小损失和的金字塔级 $P_l$ 作为学习实例的最佳目标层级，即 l^* = \arg \min_l L^I_{FL}(l) + F^I_{IoU}(l)对于一个 training batch，将为其相应分配的实例更新特性。直观的感觉是，所选的特性目前是对实例建模的最佳特性。它的损失在特征空间中形成一个下界。通过训练，我们进一步拉下这个下界。在 Inference 时，我们不需要选择特征，因为最合适的特征金字塔水平自然会输出较高的置信度得分。 为了验证我们的在线特征选择的重要性，我们还在消融研究中进行了启发式特征选择过程的比较(4.1)。启发式特征选择完全依赖于框的大小。根据框的大小决定实例应该分配给哪一个特征金字塔层级进行处理. Joint Inference and Training当插入到RetinaNet[22]时，我们的FSAF模块与 anchor-based 的分支协同工作，如图4所示。我们保持了原始的 anchor-based 的分支，在训练和推理过程中，所有超参数都保持不变。 Inference: FSAF模块只是在全卷积的 RetinaNet 上增加了几个卷积层，所以 Inference 过程仍然像之前一样简单。对于 anchor free 的分支，我们只解码每个金字塔级别中得分最高的 1k 个 locations 的 box predictions，将置信值阈值设为0.05。这些来自各个级别的 top predictions 会与 anchor-based 的分支的box predictions 合并，然后利用阈值为0.5的非最大抑制，得到最终的检测结果。 Initialization: 略… Optimization: 略… ExperimentsAblation StudiesAnchor-free branches are necessary: 事实证明，anchor free 分支只能取得不错的效果, 它需要结合 anchor-based 分支才能显示出较好的检测效果. 为了找出FSAF模块能够检测到的对象类型，我们在图7中展示了与我们的RetinaNet进行面对面比较的一些定性结果。显然，我们的FSAF模块更擅长于寻找具有挑战性的实例，例如锚盒不能很好地覆盖的微小和非常薄的对象 Online feature selection is essential: 表1第4和第5项进一步证实，我们的在线特性选择对于 anchor free 和 anchor based 的分支机构很好地协同工作是必不可少的。 How is optimal feature selected? 为了理解为实例选择的最优金字塔级别，我们可视化了图8中仅来自 anchor-free 分支的一些定性检测结果。类名前的数字表示检测对象的特性级别。事实证明，在线特性选择实际上遵循这样的规则:上层选择较大的实例，而低层负责较小的实例，这与anchor-based的分支中的原则相同。然而，也有相当多的例外，即在线特征选择选择金字塔级别不同于anchor-based的分支的选择。我们将这些异常标记为图8中的红色框。绿框表示FSAF模块和anchor-based的分支之间的协议。通过捕获这些异常，我们的FSAF模块可以使用更好的特性来检测具有挑战性的对象。 FSAF module is robust and efficient: 我们也评估了主干网对我们的FSAF模块在精度和速度方面的影响。三个主干网络包括ResNet-50、ResNet-101[13]和ResNeXt-101[34]。探测器运行在一个单一的泰坦X GPU与CUDA 9和CUDNN 7使用批量大小为1。结果见表2。我们发现我们的FSAF模块对各种主干网都是鲁棒的。FSAF模块本身已经比anchor-based的RetinaNet更好更快。在ResNeXt-101上，FSAF模块的性能比anchor-based的模块高出1.2%，同时速度快68毫秒。当与anchor-based的分支联合应用时，我们的FSAF模块始终能够提供相当大的改进。这也表明anchor-based的分支没有充分利用主干网络的能力。同时，我们的FSAF模块在整个网络中引入了边际计算成本，推理速度损失可以忽略不计。特别地，我们在ResNeXt-101的基础上提高了1.8% AP，仅增加了6ms的推断延迟。 Comparison to State of the Art我们评估了COCO test-dev分割上的最终检测器，并与最新的最先进的方法进行了比较。我们最后的模型是带有FSAF模块的RetinaNet，即anchor-based的分支加上FSAF模块。该模型使用比标度{640,672,704,736,768,800}更大的尺度抖动进行训练，比第4.1节中的模型长1.5倍。评估包括单尺度和多尺度版本，其中单尺度测试使用800像素的图像尺度，多尺度测试使用测试时间增量。在检测器[10]之后，测试时间的增加是在超过400、500、600、700、900、1000、1100、1200}的刻度上进行测试，并在每个刻度上进行水平翻转。我们所有的结果都来自于没有集成的单个模型。表3给出了比较。通过ResNet-101，我们的检测器能够在单尺度和多尺度场景中实现竞争性能。插入ResNeXt-101-64x4d后，AP进一步提高到44.6%，大大超过了以前最先进的single-shot detector。 Conclusion该工作确定启发式特征选择作为anchor-based点的单镜头特征金字塔检测器的主要限制。为了解决这一问题，我们提出了FSAF模块，该模块应用在线特征选择来训练特征金字塔中的 anchor-free 分支。它显著提高了强大的基线与微小的推理开销，并优于目前最先进的single-shot detector。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FCOS]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FCOS-CVPR2019%2F</url>
    <content type="text"><![CDATA[论文: FCOS: Fully Convolutional One-Stage Object Detection作者: Zhi Tian Chunhua Shen Hao Chen Tong He机构: The University of Adelaide, Australia 论文亮点TL;DR本文提出了一种新的基于全卷积的 anchor free 目标检测方法, 抛弃了传统的 anchor 设定, 以每个像素点距离四个边框的距离作为回归目标, 通过多级特征和center-ness的加持, 取得了超过anhor-based方法的性能表现 Algorithm首先, 作者重新定义了 bounding box 的回归方式, 以此抛弃 anchor box 的设定, 新的回归方式如下图, 对于每一个像素点, 其回归目标是该点到四个边界的距离, 当一个像素点落在 gt 物体内部时, 认为他是正样本, 反之, 认为是负样本 由于同一个像素点可能会属于多个不同的物体, 因此, 为了解决这个问题, 作者提出用特征金字塔的不同层来控制不同物体的预测, 由于交并比高的物体, 往往具有不同的尺寸, 因此, 将它们分别放在不同的特征图谱上去预测, 可以有效的解决这个模糊样本带来的问题. 由于每个像素点都可以参与预测, 这样就会造成很多低质量预测结果的产生, 对于一个物体来说, 远离物体中心点的的像素点, 往往更容易生成低质量的框, 因此, 作者提出对于靠近中心的像素点, 我们赋予它更大的权重, 远离的则赋予更小的权重, 这样, 在后续的nms过程中, 就可以消除大部分的低质量框 anchor box 固然可以帮助神经网络更好的预测物体框, 但是 anchor box 会带来大量的超参数和计算量, 因此, 这种 anchor free 的想法非常值得尝试, 有望在以后取代 anchor based 的目标检测方法. 摘要IntroductionRelated WorkOur Approach]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ExtremeNet (CVPR, 2019)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-ExtremeNet-CVPR2019%2F</url>
    <content type="text"><![CDATA[论文: Bottom-up Object Detection by Grouping Extreme and Center Points作者: Xingyi Zhou… 摘要随着深度学习的出现，目标检测从一个自下而上的问题逐渐发展为一个自上而下的识别问题。最先进的算法列举了一个几乎详尽的 object locations 列表，并将每个位置分类为: 对象或非对象。在本文中，我们证明了 自底向上方法仍然具有竞争力。我们使用一个标准的关键点估计(keypoint estimation)网络检测对象的四个极值点(最上、最左、最下、最右)和一个中心点。如果五个关键点是呈现几何对齐的，我们就将它们分组到一个 bounding box 中。目标检测是一个纯基于外观的关键点估计问题，没有区域分类和隐式特征学习。该方法与现有的基于区域的检测方法性能相当，在COCO test-dev上的边界框AP为43.7%。此外，我们估计的极值点直接跨越一个粗糙的八角形掩模，COCO掩模AP为18.9%，比vanilla包围盒的掩模AP好得多。极值点引导分割进一步提高到34.6%的掩模AP。 Introduction自顶向下方法多年来一直主导着目标检测。流行的检测器通过显式裁剪区域[12]或区域特征(两阶段目标检测)，或者隐式地为区域代理设置固定大小的锚点(一步目标检测)，将目标检测转换为矩形区域分类。然而，自顶向下检测并不是没有限制的。矩形边框不是自然对象表示。大多数对象的形状不是矩形框，将它们放入矩形框中包含许多分散注意力的背景像素(图1)。此外，自顶向下的目标检测器枚举了大量可能的框位置，而没有真正理解对象本身的 compositional visual grammars[9,13]。这在计算上很昂贵。最后，框本身不是一个好的描述物体的方式。它们能够传达的对象信息很少，比如无法传达对象的形状和姿态。 在本文中，我们提出了一种自底向上的目标检测框架ExtremeNet，它可以检测一个对象的四个极值点(最上、最左、最下、最右)。我们使用最先进的关键点估计框架[3,5,30,31,49]，通过预测每个对象类别的四个 multi-peak heatmaps 来找到极端点。此外，我们使用每个类别的热图预测对象中心，作为x和y维度上两个边界框边缘的平均值。我们用纯粹基于几何的方法将极值点分组到对象中。每个极值点来自于一个 heat map，当且仅当它们的几何中心在中心热图中以高于预定义阈值的值进行预测时, 我们才将这四个极值点分为一组。我们列举了极端点预测的所有 $O(n^4)$ 组合，并选择了有效的组合。对于 COCO 来说 n≤40，因此极值点预测n的个数通常比较小，在 GPU 上实现的暴力算法就足够了。图2显示了本文方法的概述。 我们并不是第一个使用 deep keypoint prediction 来检测对象的。CornerNet[22]预测一个边界框的两个对角。它们使用 associative embedding feature 将角点分组到 bounding box 中。我们的方法在 两个关键方面有之所不同: 关键点定义和分组策略。角点是边界框的另一种形式，它受到自顶向下检测的许多问题的困扰。一个角落往往位于物体的外面，没有很强的外观特征。然而，极值点位于物体上，视觉上可区分，具有一致的局部外观特征。例如，人类最顶端的点通常是头部，而汽车或飞机的底部点将是轮子。这使得极端点检测更容易。与CornerNet的第二个不同点是几何分组(geometric grouping)。我们的检测框架完全基于外观(即图片特征)，没有任何隐含的特征学习。在我们的实验中，基于外观的分组效果明显更好。 我们的想法是受到Papadopoulos等人的启发[33]提出的，他们提出通过单击四个极端点来为边界框添加 annotations。这个 annotations 的收集速度大约是包围框的四倍，并且提供了比包围框更丰富的信息。极值点也与对象掩码有密切的联系。与边界框相比，直接连接膨胀的端点提供了更细粒度的对象掩码。在我们的实验中，我们证明了将一个简单的八边形拟合到极值点上可以得到一个很好的目标掩模估计。我们的方法可以进一步与深度极值切割(DEXTR)[29]相结合，将极值点 annotations 转化为指定对象的分割掩码。直接将我们的极值点预测作为指导提供给DEXTR[29]，可以得到接近最先进的实例分割结果。我们提出的方法在COCO test-dev上实现了43.7%的 bbox AP，性能优于所有已知的单级对象检测器[22、25、40、52]，与成熟的两级检测器相当。一个在 Pascal VOC[8,14] 上预训练的DEXTR[29]模型结合本文的方法可以产生34.6%的 Mask AP，并且不使用任何 COCO mask annotations. Related WorkTwo-stage object detectors: R-CNN, SPP, Fast R-CNN, Faster R-CNNOne-stage object detectors: SSD, YOLO, RetinaNet, RefineDet 我们的方法属于一级探测器的范畴。但是，我们不是在 $O(h^2w^2)$ 空间中设置 anchor (这个空间指的是对于每一个 location, 其可能的 anchor 情况总共有 wh 种, 虽然我们只会选择其中的 k 种作物 RoI)，而是在 $O(hw)$ 空间中检测一个边界框的五个单独部分(四个端点和一个中心)。我们没有在每个像素位置设置默认的比例或方面比作为锚点，而是只预测该位置成为关键点的概率。我们的中心图也可以看作是一个不受比例和长宽比影响的区域建议网络，没有边界盒回归。 DPMGrouping in bottom-up human pose estimationImplicit keypoint detection PreliminariesExtreme and center points: 设 $(x^{(tl)}， y^{(tl)}， x^(br)， y^(br))$ 表示一个边界框的四条边。要给一个边界框添加 annotations，用户通常单击左上角 $(x^{(tl)}、y^{(tl)})$ 和右下角 $(x^{(br)}、y^{(br))}$。由于这两个点通常都位于对象之外，所以这些单击常常是不准确的，需要调整几次。整个过程平均耗时34.5秒。Papadopoulos等人的[33]建议通过单击框的四个端点 $(x^{(t)},y^{(t)})、(x^{(l)},y^{(l)})、(x^{(b)},y^{(b)})、(x^{(r)},y^{(r)})$ 来标注边界框，其中 box 表示为: $(x^{(l)},y^{(t)}、x^{(r)}、y^{(b)})$。一个点 $(x^{(a)},y^{(a)})$ 是极值点的条件是使得物体上没有其他点 $(x, y)$ 在四个基本方向之一(不是所有)上超过该点(顶部，底部，左侧，右侧)。极值单击的标注时间平均为7.2秒。生成的标注与更耗时的框标注相同。在这里，我们直接使用极值单击标注, 从而绕过边界框。同时我们还定义每个对象的中心点为 $(\frac{x^{(l)}+x^{(r)}}{2}， \frac{y^{(t)}+y^{(b)}}{2})$ Keypoint detection: 关键点估计，如人体关节估计[3,5,15,30,49]或椅角点估计[36,53]，通常使用全卷积编解码器网络来预测每种关键点的多通道热图(例如，一个头部热图，另一个手腕热图)。该网络以完全监督的方式训练，要么L2损失到呈现的高斯图[3,5,30,49]，要么每像素逻辑回归损失[22,34,35]。最先进的关键点估计网络，如104层的沙漏网[22,31]，是以完全卷积的方式训练的。他们回归的热图Yˆ∈(0,1)H×W(为每一个输出通道宽度W和高度H。训练由多峰高斯热图Y∈(0,1)H×W引导，其中每个关键点定义高斯核的均值。标准偏差要么是固定的，要么与对象大小[22]成比例。在L2损失情况下，高斯热图作为回归目标;在logistic回归情况[22]中，高斯热图作为权值图，在正位置附近减少惩罚。 CornerNet Deep Extreme Cut (DEXTR) ExtremeNet for Object detectionExtremeNet使用 HourGlass 网[31]来检测每个类的五个关键点(四个极值点和一个中心)。我们使用了 CornerNet [22]的训练设置、 loss 和 offset predictions。offset predictions 与类别无关，但与 extreme point 有关。中心映射没有 offset predictions。因此，我们的网络输出为 $5×C$ 的 heatmap和 $4×2$ 的偏移图，其中 $C$ 为类别数(COCO 中 $C = 80$)。Figure 3 shows an overview. 一旦提取出极值点，我们就把它们分组成纯几何形式的检测形式。 Center Grouping极值点位于物体的不同侧面。这使得分组变得复杂。例如， Associative Embedding[30]可能没有足够的全局视图来对这些关键点进行分组。在这里，我们采用了一种不同的方法来利用极值点的分布特性。 我们的分组算法的输入是每类五个热图：一个中心热图 $\hat Y^(c) \in (0,1)^{H×W}$ 和四个 Extreme 热图 $Y^{(t)},Y^{(l)},Y^{(b)},Y^{(r)} \in (0,1)^{H×W}$ 分别为顶部，左侧，底部，右侧的。给定一个热图，我们通过检测所有峰值来提取相应的关键点。峰值是值大于 $\tau p$ 的任何像素位置，并且其在周围像素的 $3×3$ 窗口中是局部最大的。 我们将此过程命名为 ExtrectPeak. 给定从热图 $\hat Y^{(t)}, \hat Y^{(1)}, \hat Y^{(b)}, \hat Y^{(r)}$ 中提取的四个极值点 $t,b,r,l$ 我们计算它们的几何中心 $c =\frac{(l_x + r_x)}{2}, \frac{(t_y + b_y)}{2}$。 如果在预测的 center heatmap $\hat Y^{(c)}$ 中该中心具有较高响应，则我们就将这些极值点作为一个有效检测: $\hat Y^{(c)}_{cx,cy} \geq \tau c$。 然后，我们以暴力搜索的方式对所有关键点 $t，b，r，l$ 的进行四元组的枚举。我们独立地提取每个类别的检测。算法1总结了这个过程。 我们在所有实验中设定 $\tau p= 0.1$ 和 $\tau c = 0.1$。 这种暴力分组算法具有 $O(n^4)$ 的运行时间，其中 $n$ 是每个基本方向的提取极值点的数量。 补充材料提出了一种在纸上更快的 $O^(n2)$ 算法。 然而，对于 MS COCO 数据集而言，很难在GPU上加速并且在实践中更慢，其中 $n\leq 40$。 Ghost box suppression中心分组会对 相同大小的三个等间距共线 物体给出高置信度假阳性检测(仔细想一想就能知道, 如果三个相同大小的物体共线, 那么左右两边的物体的左右极值点很有可能会被分组到中间物体上, 这是非常错误的!)。 中心物体在这里有两个选择，一是提交正确的小方框，而是预测一个包含其邻居极值点的更大的方框(FP)。 我们将这些 FP 检测称为 Ghost box。 正如我们将在实验中展示的那样，这些鬼盒很少见，但仍然是 a consistent error mode of our grouping. 我们提供了一个简单的后处理步骤来删除 ghost box。根据定义， ghost box 会包含许多其他较小的检测框。为了阻止 ghost box ，我们使用了一种 soft-nms 的变种, 即如果某一个大边界框中包含的所有框的得分之和超过其自身得分的3倍，则将这个大边界框(可能是 ghost box)得分除以2。这种非极大值抑制类似于标准的基于重叠的非极大值抑制，但是会惩罚潜在的 ghost box，而不是多个重叠的 box。 Edge aggregation极值点并不总是唯一定义的。 如果物体的垂直或水平边缘形成极值点（例如，汽车的顶部），沿着该边缘的任何点都可以被认为是极值点。 因此，我们的网络会沿对象的任意对齐边缘产生多处弱响应，而不是单个强峰响应。 这种弱响应存在两个问题：第一，较弱的响应可能低于我们的峰值选择阈值 $\tau p$，我们将完全错过极值点。 其次，即使我们检测到关键点，其得分也会低于具有强烈峰值响应的轻微旋转对象。 我们使用 边缘聚合 来解决这个问题。对于提取为局部最大值的每个极值点，我们在垂直方向(对于左和右极值点)或水平方向(对于顶部和底部关键字点)汇总其得分。我们对所有 单调递减 的分数进行聚合，并在聚合方向上以 局部最小值 停止聚合。具体地说, 我们令 $m$ 是一个 extreme point, $N_i^{(m)} = \hat Y_{m_x+i, m_y}$ 该点的垂直线段或水平线段. 令 $i_0 &lt; 0$ 和 $0 &lt; i_1$ 为两个最近的局部最小点, 于是我们更新 extreme point 的值为 $\tilde Y_m = \hat Y_m + \lambda_{aggr} sum^{i_1}_{i=i_0} N^{(m)}_i$, 其中, $\lambda_{aggr}$ 是 aggregation weight, 在我们的实验中, 取其值为 $0.1$. 效果如图 4 所示. Extreme Instance Segmentation与简单的边界框相比，极值点携带有关对象的更多信息，其标注值至少为两倍（8比4）。 我们提出了一种简单的方法，通过创建一个边缘以极值点为中心的八边形来使用极值点逼近 object mask。 具体而言，对于极端点，我们将其在相应边缘上的两个方向上延伸到整个边缘长度的1/4的区段。 该段在遇到角落时会被截断。 然后，我们连接四个段的端点以形成八边形。 有关示例，请参见图1。 为了进一步细化边界框分割，我们使用了 Deep Extreme Cut (DEXTR)[29]，这是一个训练有素的深度网络，可以将手动提供的极值点转换为实例分割掩码。在这项工作中，我们只是用我们的极值点预测替换了手工输入的DEXTR[29]，来执行一个两阶段的实例分割。具体来说，对于每个预测的边界框，我们裁剪边界框区域，用预测的极值点呈现高斯映射，然后将连接的图像提供给预训练的DEXTR模型。DEXTR[29]与类无关，因此我们直接使用极值集的检测类和分数。没有使用进一步的后处理。 ExperimentsExtreme point annotations在COCO[26]中没有直接的极值点注释。不过，对象分割掩码有完整的注释。因此，我们在多边形掩模注释中找到了极值点作为极值。如果一条边平行于一条轴，或者在边缘中心的极值点3以内。虽然我们的训练数据来自于更昂贵的分割注释，但是极值点数据本身收集起来比标准的边界框[33]便宜4倍。 Training details略… Testing details为了保持枚举效率，ExtrectPeak中最多提取了40个top point。 略… Ablation studiesCenter Grouping vs. Associative Embedding: 有表 1 看出, 当使用 CornerNet 中的 Associative Embedding 时, AP 下降了 2.1%. 虽然 Associative Embedding在人体姿态估计和 CornerNet中工作得很好，但我们的极值点位于物体的一侧。从整个物体的极值点的优势点来学习它的身份和外观可能是太困难了。虽然它可能适用于小对象，在小对象中，整个对象很容易适合于关键点的有效接受域，但是对于中、大对象就不适用了，如表1所示。此外，极值点往往位于重叠对象之间的交点，这进一步混淆了身份特征。我们的几何分组方法很好地处理了这些问题，因为它只需要对外观进行推理。 Edge aggregation: Edge aggregation (第4.3节)使AP有了0.7%的改进。它对于较大的物体更有效, 因为这些物体往往具有更长的边缘, 使得 extreme point 不够明显. 去除边缘聚合将解码时间提高到76ms，整体速度提高到4.1 FPS。 Ghost box suppression: 0.3% AP improvement. 这说明 Ghost Box 并不是一种广泛存在的情况. Error Analysis 为了更好地理解错误从何而来，以及我们的每个组件训练得有多好，我们提供了错误分析，将每个输出组件替换为其基本事实。表1显示了结果。地面真相中心的热图本身并没有增加多少AP。这说明我们的中心热图训练得很好，说明隐式对象中心是可学习的。用地面真实值替换极端点热图可以提高16.3%的AP。同时对极值点热图和中心热图进行了替换，得到了79.8%的结果，远远高于对其中一个极值点热图和中心热图的替换。这是由于我们的中心分组在关键点位置非常严格，高性能要求提高极端点热图和中心热图。添加地面真相偏移量将进一步增加AP到86.0%。其余错误来自ghost框(第4.2节)。 State-of-the-art comparisons表2将ExtremeNet与COCO test-dev上的其他最先进方法进行了比较。我们的多尺度测试模型的AP达到了43.7，超过了所有的 one-stage 目标探测器，与流行的 two-stage 探测器相当。值得注意的是，与 CornerNet相比，它的性能提高了1.6%，这表明了检测端点和中心点比检测具有关联特征的角的优势。在单标度设置下，我们的性能比 CornerNet[22]低0.3%。然而，我们的方法对于小的和中值对象的AP比 CornerNet更高，小目标检测众所周知的更具挑战性。对于较大的对象，我们的中心响应图可能不够精确，无法很好地执行，因为几个像素的偏移可能会造成检测和假阴性之间的差异。 此外，请注意，我们使用了一半的gpu来训练我们的模型。 Instance Segmentation最后，我们将使用/不使用DEXTR[29]的实例分割结果与表3中的其他基线进行比较。作为一个虚拟基线，我们直接将矩形边框内的所有像素指定为分割掩码。我们的最佳模型(43.3%的边界框AP)的结果是12.1%的掩模AP。基于我们预测的极值点的简单八边形掩模(第4.4节)得到18.9%的掩模AP，比边界框基线好得多。这说明这个简单的八角形掩模可以在不增加成本的情况下，给出一个相对合理的对象掩模。注意，直接使用四个极值点的四边形会产生一个过小的掩码，其IoU较低。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉-GIoU-CVPR2019]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-GIoU-CVPR2019%2F</url>
    <content type="text"><![CDATA[Paper Reading Note URL: https://arxiv.org/abs/1902.09630 TL;DR本文从 IOU 的角度出发, 提出了可以避免不相交bbox的反向传播问题的 GIoU, 同时将 GIoU 作为新的损失函数和评价标准进行 bbox 的回归训练, 实验表明, GIoU 对常用的目标检测算法都具有相当的提升作用. Algorithm目前常用的目标检测算法在进行 bbox 的回归时, 通常会采用 smooth l1 loss 或者 mse 来计算损失, 但是这种损失的计算方式并不能体现出 bbox 的准确程度, 举例来说, 对于具有相同 loss 的不同组合, 有可能具有不同的 IoU , 如图1 所示, 这说明, 当我们对 smooth l1 loss 或者 mse 进行优化时, 实际上并不能完全对 IoU 进行优化. 但是, 当使用标准的 IoU 计算损失时, 如果两个 bbox 不相交, 那么, 他们的 IoU 就会变成 0, 但是, bbox 之间距离的不同, 应该具有不同程度的损失, 因此, 如果之间使用 IoU 作为 loss 进行优化的话, 当 bbox 之间不相交, 就无法准备描述出 bbox 的不匹配程度. 因此, 文本提出了一个通用的 IoU, 称为 GIoU, GIoU 的计算方法如算法1所示. 用 GIoU 做 loss 时, 不仅保持了 IoU 的优良性质, 同时还可以解决 bbox 不相交的问题, 将 IoU 作为 loss 的具体实施方法如下所示 Experiment Detail作者利用 YOLOv3, FasterRCNN 等经典模型在 COCO, VOC 的数据集上进行了实验, 实验结果显示, 不论是 IoU 还是 GIoU, 都可以获得相应的提升, 同时 GIoU 可以获得更大的提升, 实验结果如下所示.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++-编译和链接]]></title>
    <url>%2Fz_post%2FCpp-%E7%BC%96%E8%AF%91%E5%92%8C%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[C++ 生成可执行文件大致需要经过以下几个过程:源程序 -&gt; 预处理 -&gt; 编译和优化 -&gt; 生成目标文件(.obj) -&gt; 链接 -&gt; 可执行文件 1. 预处理C++ 的预处理是指在 C++ 程序源代码被编译之前, 由预编译器对 C++ 程序源代码进行的处理, 这个过程并不对程序的源代码进行解析, 主要是完成以下几项任务: 宏的替换 删除注释 处理预处理指令, 如#include, #ifdef等等 2. 编译和优化 词法分析 语法分析 语义分析 代码优化 代码生成 内联函数的替换就发生在这一阶段 3. 生成目标文件将汇编语言代码翻译成目标机器指令 4. 链接]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bag of Freebies (Arxiv, 2019)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-BagofFreebies-Arxiv2019%2F</url>
    <content type="text"><![CDATA[文章: Bag of Freebies for Training Object Detection Neural Networks作者: Zhi Zhang, Tong He, Hang Zhang, Zhongyuan Zhang, Junyuan Xie, Mu Li机构: Amazon Web Services 摘要与针对更好的图像分类模型的大量研究成果相比, 应用于目标检测器训练的研究在普及度和广泛性上相对较差. 由于越来越复杂的网络结构和优化目标, 各种训练策略和流程(pipeline)都是针对特定的检测算法而设计的. 在本文中, 我们将会探索通用的调整方法, 来帮助提高现有目标检测模型的性能, 并且确保不降低 inference 速度. 我们的实验表明, 本文提出的这些方法可以使得现有模型的绝对精度提高5%, 因此, 我们建议大家在一定程度上将其应用于目标检测训练当中. Introduction目标检测无疑是计算机视觉领域的前沿应用之一, 受到了各个领域研究者的关注. 最新的检测模型都是基于分类的 backbone 网络(VGG, ResNet, Inception, MobileNet)建立的.但是, 由于模型容量和训练复杂度相对较高, 目标检测任务从最近的 training tweaks 的研究中获益较少. 更糟糕的是, 不同的检测网络在没有进行显式初始化, 数据预处理和优化分析的情况下, 只使用自己的训练步骤, 这使得在采用最新技术来提高图像分类能力时造成了巨大的混乱.在本文中, 我们的重点是探索有效的方法, 使得可以在提高主流目标检测网络性能的同时, 维持原有的计算成本. 我们首先探讨了将混合技术(mixup: Beyond empirical risk minimization)应用在目标检测上. 和 mixup 原文不同的是, 我们注意到多目标检测任务倾向于保持空间变换(favors spatial preserving transforms)的特殊性质, 因此提出了一种 用于多目标检测任务的视觉相干图像混合方法(visually coherent image mixup methods for object detection tasks). 然后, 我们讨论了训练过程的许多细节问题, 包括学习率调度(learning rate scheduling), 权重衰减(weight decay)和同步 BatchNorm (synchronized BatchNorm)等. 最后, 我们讨论了本文提出的训练策略优化(training tweaks)的有效性, 并通过增量叠加这些优化来训练 one-stage 和 multiple-stage 的目标检测网络. 我们的主要贡献可以总结如下: 我们首次系统的评估了各种应用于不同目标检测流程的启发式训练规则, 为未来的研究提供了有价值的实践指导. 我们提出了一种用于训练目标检测网络的视觉相干图像混合方法, 并证明了该方法在提高模型泛化能力方法的有效性. 我们在不改变现有模型网络结构和损失函数的情况下, 实现了 5% ~ 30% 的绝对精度提高. 我们所做的一切都没有增加额外的推理成本. 我们扩展了目标检测中数据增广领域的研究深度, 显著的增强了模型的泛化能力, 并有减少了过拟合问题. 实验还展示了一些很好的技术, 可以在不同的网络结构中 一致的 提高目标检测结果. Related WorkScattering tricks from Image ClassificationLearning rate warm up: 用于克服超大的 mini-batch size 带来的负面影响(Accurate, large minibatch sgd: training imagenet in 1 hour, FAIR 铁三角). 有趣的是, 尽管在典型的目标检测训练中使用的 mini-batch size 和图像分类中的规模(10k, 30k)相差甚远, 大量的 anchor (30k) 有会隐式的增加 mini-batch 的大小. 在我们的实验中, 我们发现热身机制(gradual warmup heuristic)对于 YOLOv3 来说是直观重要的. 有一系列的方法试图解决深层神经网络的脆弱性. Inceptionv3 介绍了标签平滑性(Label smoothing), 对交叉熵损失中的难真实标签(hard ground truth labeling)进行的改进. Zhang 等人 提出了 mixup 方法来缓解对抗性扰动. 针对传统的步长策略, Sgdr 提出了学习率衰减的 余弦退火策略. He Tao等人通过探索大量 tricks, 在训练精度上取得了显著的提高(Bag of tricks for image classification). 在本文中, 我们将会深入研究这些由分类任务引入的启发式技术在目标检测任务中的应用. Deep Object Detection PipelinesSSD, YOLO, Faster R-CNN 等 由于 one-stage 缺少空间上的多样性, 因此, 对于 one-stage 模型来说, 空间数据增广对于性能的提升非常重要. Technique DetailsVisually Coherent Image Mixup for Object Detection由 Zhang Hongyi 等人引入的 mix-up 被证明在减轻分类网络中的对抗性扰动方面是成功的. 原文中的 mix-up 算法的混合比例(blending ratio)是通过 beta 分布得到的($a = 0.2, b = 0.2$). 大部分的混合结构几乎都是 beta 分布的噪声. 受到 Rosenfeld 等人启发式实验(The elephant in the room)的影响, 我们更关注那些在目标检测任务中起重要作用的自然共现目标的特征表示. 半对抗性的目标移植方法并不是传统的攻击方式. 通过应用更复杂的空间变换, 我们引入了在自然图像表示中常见的遮挡, 空间信号扰动.在我们的经验实验中, 当我们持续增加 mixup 中的混合比(blending ratio)时, 得到的图像帧中的目标物体变的更加具有活力和连贯的自然表现, 就像是在低 FPS 电影中的过渡帧一样. 图2和图3分别展示了图像分类和这种高混合比例融合的视觉对比. 特别的, 我们使用几何保留对其(geometry preserved alignment)的图像融合, 以避免在最初中步骤中扭曲图像. 我们同时还选择了一个更具视觉一致性的 beta 分布($a\geq 1, b\geq 1$), 而不是采用和图像分类中同样的融合方法, 如图4所示. 我们还在 Pascal VOC 数据集上用 YOLOv3 对经验混合比的分布进行了实验测试. 表1显示了使用 detection mixup 后实际的提升情况. 可以看出, 使用 $\alpha = 1.5, \beta = 1.5$ 的 beta 分布稍微比使用 1.0 的 beta 分布(相当于是均匀分布, uniform distribution)好一点, 同时也比一半一半的混合方法好. 为了验证视觉相干混合(visually coherent mixup)的有效性, 我们进行了和 “The elephant in the room” 论文中相同的实验, 我们将大象的图片在一张室内的图片上滑动通过. 我们在 COCO 2017 数据集上训练了两个 YOLOv3 模型, 除了模型 mix 使用了我们的 mixup 方法以外, 其他的设置都是相同的. 我们在图5中给出了一些令人惊讶的发现. 如图5所示, 原始模型(vanilla model)没有采用我们的 mix 方法, 它在面对 “房间里的大象” 时往往很难正确检测, 这是由于当缺乏足够的上下文时, 原始的模型不足以检测到我们希望的目标, 实际上, 当我们检查了常用的数据集以后, 也没有发现有这样的训练图像. 相比之下, 使用 mix 方法的模型在训练后会变得更加健壮, 这多亏了随机生成的具有视觉欺骗性的训练图像. 除此以外, 我们还注意到使用了 mix 方法训练后的模型会变得更加 “不自信”, 它在给目标物体进行置信度打分的时候, 往往会给出较低的分数. 但是, 这种行为并不影响我们将在实验部分中展示的评估结果. Classification Head Label Smoothing对于每一个物体, 检测网络经常会在所有类别上使用 softmax 函数来计算概率分布: p_i = \frac{e^{z_i}}{\sum_j e^{z_j}} \tag 1上式中, $z_i$ 是直接从最后一个用于分类预测的线性层中获得的非归一化对数. 对于训练阶段中的目标检测任务来说, 我们只通过比较输出分布 $p$ 和真实分布 $q$ 的交叉熵来修正分类损失: L = \sum_i q_i log p_i \tag 2$q$ 通常是 one-hot 编码, 正确类别位置为1, 其他位0. 但是, 对于 softmax 函数来说, 只有当 $z_i &gt;&gt; z_j, \forall j \neq i$ 时才能逼近公式(2)分布, 但是永远不会完全等于它. 这使得模型对自己的预测过于自信, 容易过度拟合(因为模型会趋势预测结果想着 $z_i &gt;&gt; z_j, \forall j \neq i$ 的方向更新).标签平滑化(Label smoothing) 是由 Szegedy (Inception v3)等人提出的一种正则化形式(regularization). 我们用下面的公式来对真实分布进行平滑化处理: q^{'}_i = (1 - \epsilon) q_i + \frac{\epsilon}{K} \tag 3上式中, $K$ 代表类别的数量, $\epsilon$ 是一个很小的常数. 这个技巧可以降低模型的自信度, 由最大对数和最小对数之间的差值来衡量.在 YOLOv3 中, 当 sigmoid 的输出为 0 到 1 时, 通过修正目标范围的上下限可以让 label smoothing 过程变的更加简单. Data Pre-processing和图像分类领域中网络对几何变换具有极强的容忍度不同. 实际上, 我们鼓励这样做来提高模型的泛化精度. 但是, 对于目标检测任务的图像预处理来说, 由于检测网络对于这种转换更加敏感, 因此我们需要格外的谨慎. 我们通过实验回顾了以下数据增强的方法: 随机几何变换(Random geometry transformation). 包括随机剪裁(random cropping with constraints), 随机扩展(random expansion), 随机水平翻转(random horizontal flip), 随机缩放(random resize with random interpolation) 随机颜色抖动(Random color jittering). 包括亮度(brightness), 色调(hue), 饱和度(saturation), 和对比度(contrast).就检测网络的类型而言, 有两种类型. 第一种是 one-stage 检测网络, 其最后的输出结果是从特征图谱上的每一个像素点生成的. 如 SSD 和 YOLO. 第二种是 multi-stage 检测网络, 如 Fast-RCNN 等, 它的检测结果是通过在特征图谱上进行滑动窗口式的遍历生成的 proposals 进行回归和分类得到的由于基于 proposals 的方法会产生大量的候选框, 因此它在一定程度上梯段了随机检测输入图像的操作, 所以这些网络在训练阶段不需要大量的几何增强. Training Scheduler Revamping(改进)在训练过程中, 学习率往往从一个相对较大的数字开始, 然后在整个训练过程中逐渐变小. 例如, step schedule 是使用最广泛的学习率调整策略. 在 step schedule 中, 在达到预定义的时间点或者迭代次数之后, 学习率会乘以一个小于 1 的常数. 例如 Faster R-CNN 和 YOLO 都采用的这种学习率调整策略. Step schedule 方法的学习速率转换机制过于突然, 这可能导致优化器在接下来的几个迭代中重新稳定学习势头(learning momentum). 相比之下, Loshchilov 提出了一种更平滑的余弦学习率调整策略(cosine learning rate adjustment). cosine schedule 根据 cosine 函数在 0 到 $\pi$ 上的值来调整学习率. 它从缓慢的降低大的学习率开始, 然后在中途快速降低学习速度, 最后以微小的斜率降低小的学习率直至达到0.Warm up learning rate 是另一种常见的策略, 它可以在初始训练迭代过程中发生梯度爆炸. Warm-up learning rate 策略对于一些目标检测模型来说至关重要, 例如 YOLOv3, which has a dominant gradient from negative examples in the very beginning iterations where sigmoid classification score is initialized around 0.5 and biased towards 0 for the majority predictions.训练时使用 cosine schedule 和适当的 warmup 可以得到更好的验证集检测结果, 如图6所示. 在训练过程中, 使用 cosine schedule 的验证集 mAP 始终优于 step schedule. 优于学习率的调整频率较高, 也较少出现 step schedule 的 plateau 现象(由于当前学习率下的训练以及近乎收敛, 所以验证集性能会在学习率降低前卡住(stuck)一段时间). Synchronized Batch Normalization近来来, 大量的计算需求迫使训练环境必须装备多个设备(GPUs)来加速训练. 尽管在训练过程中需要处理不同的超参数来应对更大的 mini batch 大小, BN 仍然由于其实现细节而引起了多设备用户的注意. 尽管在多设备上工作的 Batch Norm 的典型实现非常快(没有通信开销), 但它不可避免的会减少 mini batch 的大小, 并在计算期间导致统计数据略有不同, 这可能会降低性能. 在一些标准的视觉任务中, 例如 ImageNet 分类, 这不是一个重要的问题(因为每个设备的 mini batch 大小通常足够大, 可以获得良好的统计数据). 但是, 在某些任务中, mini batch 的设置通常会非常小, 这可能会影响性能. 最近, Peng 等人通过 Megdet(A large mini-batch object detector) 分析证明了同步(synchronized) Batch Norm 在目标检测中的重要性. 在本文中, 我们重新审视了 YOLOv3 中 Synchronized Batch Normalization 的重要性, 以评估相对较小的 batch-size 对每个 GPU 的影响. 因为目标检测任务中的图片大小远远大于分类任务中的图片, 因此, 无法使用较大的 mini-batch. Random shapes training for single-stage object detection networks自然训练图像具有多种性状. 为了使用内存限制和使用更简单的 batching, 许多 one-stage 目标检测网络采用固定的形状进行训练. 为了降低过拟合的风险, 同时提高模型预测结果的泛化性, 我们采用随机尺度训练的方法(正如 YOLOv3 中一样). 更具体的说, 我们将一个 mini-batch 中的 $N$ 张训练图片 resized 到 $N\times 3\times H\times W$ 的大小, 这里的 $H$ 和 $W$ 通过乘以一定的系数 $D = randint(1, k)$ 来获得. 例如, 在 YOLOv3 的训练中, $H = W \in \{320, 352, 384, 416, 480, 512, 544, 576, 608\}$ Experiments 为了比较所有的 tweaks 对目标检测结果的增量改进, 我们使用了 YOLOv3 和 Faster R-CNN 分别作为 one-stage 和 two-stage 的代表模型. 为了适应大规模的训练任务, 我们使用 VOC 进行精细级的技巧评估(trick evaluation), 使用 COCO 数据集进行整体性能增兴和泛化能力的验证. Pascal VOC. 按照 Fast-RCNN 和 SSD 中常用的设置, 我们使用 Pascal VOC 2007 trainval 和 Pascal VOC 2012 进行训练, 并使用 2007 test 进行验证. 最终的结果根据 VOC 中定义的 mAP(mean average precision) 进行评估. 对于 YOLOv3 模型, 我们始终在 $416\times 416$ 的分辨率下测量评价精度(mAP). 如果使用随机尺度训练, YOLOv3 模型的随机分辨率将从 320 增加到 608, 增量大小为 32, 否则将固定在 416 尺寸进行训练. Faster R-CNN 模型采用任意的输入分辨率. 为了约束训练时的内存消耗, 输入图片的较短边会被 resized 到 600, 同时要确保较长边不超过 1000 pixels. Faster R-CNN 的训练和验证过程遵循相同的预处理步骤, 只不过训练图像将有 0.5 的概率进行水平翻转来进行数据增广. YOLOv3 和 Faster-RCNN 的实验细节如表2和表3所示. 实验结果表明, 通过叠加这些技巧, YOLOv3 模型可以获得高达3.5%的性能增益, 而 Faster-RCNN 模型的技巧增益效果较差, 但获得了类型的性能提升. 从实验结果我们还发现, 数据增广对于 two-stage 的 Faster R-CNN 模型的增益效果一般, 但是对于 YOLOv3 模型来说却构成了非常重要的影响, 其原因是由于 YOLOv3 模型缺乏空间突变操作(spatial mutational operations) MS COCO. COCO 2017 比 VOC 数据集大 10 倍, 同时包含了更多的小物体. 我们使用 MS COCO 来验证本文中 ticks 的泛化性. 我们使用了和 VOC 数据集上差不多的训练和验证设置, 只不过 Faster R-CNN 使用了 $800 \times 1300$ 的大小来适应更小的目标物. 最终的结果如表4所示. 总的来说, 我们的 ticks 可以令 ResNet50 和 ResNet101 的 Faster-RCNN 模型的 mAP 分别提升 1.1% 和 1.7%. 同时可以将 YOLOv3 模型的 mAP 提升 4.0%. 注意, 所有这些结果都是通过在完全兼容的 inference model 中生成更好的权重得到的, 所以这些提升可以完美的应用在 inference 中. Impact of mixup on different phases of training detection networkMixup 可以在目标检测模型中的两个阶段中使用: (1) 在预训练的 backbone 网络中使用 mixup; (2) 利用提出的针对目标检测任务的视觉相干混合(visually coherent image mixup)来训练目标检测网络. 我们比较了使用 Darknet-53 的 YOLOv3 和 ResNet101 的 Faster R-CNN 来进行比较, 结果如表5和表6所示. 结果表明, 不论在那个阶段使用 mixup 都可以取得一致的性能提升. 同样值得注意的是, 在这两个阶段都使用 mixup 可以产生更加显著的增益, 即 $1+1 &gt; 2$.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rethinking ImageNet Pre-training]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-RethinkingImageNetPre-training%2F</url>
    <content type="text"><![CDATA[文章: Rethinking ImageNet Pre-training作者: Kaiming He Ross Girshick Piotr Dollar备注: Facebook AI Research (FAIR) ImageNet 的作用: 加速收敛 当数据集较小时, 使用 ImageNet 可以获得更高的表现]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】通用深度学习推理框架-EasyInfer]]></title>
    <url>%2Fz_post%2F%E9%A1%B9%E7%9B%AE-EasyInfer%2F</url>
    <content type="text"><![CDATA[一. 项目简介在实际生产环境下, 当我们的深度学习模型训练完成后, 我们通常需要将预测模型部署到嵌入式平台上才能正式产生效益, 但是在模型部署过程中, 脱离了训练环境, 就会产生各种依赖问题, 使得部署过程十分麻烦, 另外, 一般的用户对现在流行的神经网络前向计算框架如 TensorRT, NCNN, OpenVINO 等加速引擎的诸多细节都无法清楚理解, 尤其是对于专注于算法提升的算法人员来说, 更是无暇顾及. 因此, 我们开发了一个通用的神经网络前向计算框架: EasyInfer, 之所以说它通用, 是因为它的底层支持调用 NCNN, TensorRT 和 OpenVINO 三种不同的引擎, 同时, 可以支持多种模型格式的输入, 包括 MXNet, Caffe, Onnx 等, 未来还计划支持 PyTorch 和 TensorFlow. 同时还提供了 C, C++ 和 Python 三套接口, 并且可以支持 Linux, Windows 以及 OSX 系统, 未来计划支持 Android 和 IOS 系统.当用户需要快速验证模型在部署环境下的性能或效率时, 只需要掌握 EasyInfer 提供的自定义引擎开发接口和自定义模型开发接口, 就可以根据自己的需求快速的完成模型的部署, 同时还能灵活的选择和切换底层的推理引擎, 大大地节省了算法和部署人员的时间成本. 源码架构EasyInfer 的整体代码架构如下图所示, 首先 EasyInfer 本身并不是一个独立的前向计算引擎, 它实际上可以看做是众多主流加速引擎的一个代理, 用户通过调用 EasyInfer 统一的 API 接口, 可以自由灵活的切换底层使用的加速引擎, 如图中所示, 我们目前提供了三种加速引擎的支持, 分别是 NCNN, TensorRT 以及 OpenVINO. 其中, NCNN 加速引擎已经作为一个子模块被内置到 EasyInfer 源码中, 用户无需单独编译和安装 NCNN 就可以直接使用 EasyInfer 进行模型部署(默认调用 NCNN 引擎). 对于其他的加速引擎, 用户只需要安装官网的安装教程完成引擎安装, 就可以在代码中改变需要调用的引擎. 而对于一些特殊的网络层, 有些推理引擎可能没有提供相应的接口. 例如 Slice 层, 在 TensorRT 中就没有对应的层与之匹配, 对于这种情况, 我们也提供了相应的插件可以让用户使用, 目的就是为了让用户更加方便无痛地完成模型的转换和部署(如图中的 TRTPlugin Factory 所示). 模型转换在 EasyInfer 的工作流程中, 很重要的第一步工作就是将用户提供的模型文件转换成底层引擎使用的模型文件格式, 如下图所示, 目前我们已经支持将 Caffe, Onnx, 和 MXNet 模型全自动的转换到不同的底层引擎模型格式. 其中, 对于 MXNet 模型文件, 起初由于我们是开发了一个将 MXNet 模型文件转换成 Caffe 模型文件的工具, 但是后来我们发现, 有些 MXNet 网络的参数在 Caffe 中不支持, 并且 Caffe 目前已经处于停止维护的状态, 因此, 我们决定重新编写将 MXNet 网络模型直接转换成底层引擎模型格式的代码, 但是对于 TensorRT 来说, 由于它没有提供现成可用的 MXNet 解析类, 因此, 我们必须手动实现对 MXNet 模型文件的解析, 然后将解析后的结果存入 TensorRT 模型中. 这一部分的任务也是我的任务之一, 关于这一部分的细节会在后文介绍. 模型运行在完成模型转换后(我们会将模型统一转换成指定的格式, 这里我们用 EasyModel 指代这些转换后的模型). 我们就可以根据我们的模型和需要来编写相应的代码完成模型部署工作. 这里我们为用户提供了极简的引擎开发接口和模型开发接口: ModelBase. ModelBase 在整个模型执行流程中扮演了一个非常重要的角色, 它会接受来自用户提供的转换后的模型文件, 同时会调用底层的 EasyEngine 引擎代理, 然后根据用户提供的不同输入, 做出相应的预测结果, 如下图所示. 上图中的 ModelBase 是所有模型组件的基类, 是模型到引擎的桥梁, 也是整个 EasyInfer 的核心, 它面向算法研发人员封装了引擎操作的细节, 仅暴露极简的接口实现图像数据的输入和输出. 其主要接口(并非所有接口, 这里只介绍最主要的一些接口)有: LoadModelFromFile: 面向最终用户, 加载 EasyModel 文件, 并提供加密接口(模型文件是由用户提供的, 因为本项目的最终计划是要进行商业部署, 因此, 用户提供的模型必须是经过加密的) _UploadImage: 加载输入图像 _UploadData: 加载自定义格式数据 _Calculate: 执行运行 _GetOutput: 获取输出 当我们想要利用上述接口编写一个 Model 类时, 我们需要做以下六件事: 准备模型文件, 编写模型文件的配置文件(.json); 利用提供的工具计算模型的摘要信息(MD5); 从 ModelBase 继承一个子类, 填入模型的名称和摘要信息; 设计用户接口函数, 提供用户输入; 设定图像各通道的 mean 和 var; 移植前处理和后处理代码. ModelBase 实例下面我们会根据上一小节 Model 类的编写流程完成一个简单的示例, 以更好的说明如何使用 EasyInfer 来加速模型部署. 我们以人脸角度模型为例: C++ 接口用法1234567891011121314151617181920212223242526272829303132333435363738class EXPORT Angle : public ModelBase &#123;public: Angle(); cv::Point3f EstimateAngles(cv::Mat img, const cv::Rect &amp;faceBox);protected: float _Result2Angle(const float* pBuf) const;&#125;;Angle::Angle() : ModelBase("angle", "266e697c57339b515bb0b24cac167eb5") &#123; _SetGammaBeta(0, 1.f / 57.63f, -103.53f / 57.63f); _SetGammaBeta(1, 1.f / 57.63f, -116.28f / 57.63f); _SetGammaBeta(2, 1.f / 57.63f, -123.675f / 57.63f);&#125;float Angle::_Result2Angle(const float* pBuf) const &#123; float fSum = 0; for(int i = 0; i &lt; CLASS_NUM; ++i) &#123; fSum += pBuf[i] * i; &#125; return fSum * 3 - 99;&#125;cv::Point3f Angle::EstimateAngles(cv::Mat img, const cv::Rect &amp;_box) &#123; const cv::Scalar fillColor = cv::Scalar(0, 0, 0); const float fExpandScale = 1.8f; cv::Rect faceBox = BoundingSquare(_box); faceBox = ScaleRect2f(faceBox, fExpandScale); _CalculateSingleImage("data", CropRect(img, faceBox, fillColor), true); auto &amp;outYaw = _GetOutput(OUTNAME_YAW); auto &amp;outPitch = _GetOutput(OUTNAME_PITCH); auto &amp;outRoll = _GetOutput(OUTNAME_ROLL); CHECK_EQ(outYaw.shape[0], CLASS_NUM); CHECK_EQ(outPitch.shape[0], CLASS_NUM); CHECK_EQ(outRoll.shape[0], CLASS_NUM); return &#123;_Result2Angle(outYaw.data.data()), _Result2Angle(outPitch.data.data()), _Result2Angle(outRoll.data.data())&#125;;&#125; Python 接口用法123456789101112131415161718192021222324252627282930313233343536373839import cv2import numpy as npimport sys sys.path.append('../build/python') import eibaseimport eifaceclass Angle: modelObj = None angleNum = 66 def __init__(self, modelFile): self.modelObj = eibase.EasyModel("angle", "266e697c57339b515bb0b24cac167eb5") self.modelObj.SetGammaBeta(0, 1. / 57.63, -103.53 / 57.63); self.modelObj.SetGammaBeta(1, 1. / 57.63, -116.28 / 57.63); self.modelObj.SetGammaBeta(2, 1. / 57.63, -123.675 / 57.63); self.modelObj.LoadModelFromFile(modelFile); def Result2Angle(self, data): data = data.flatten() sum = 0. for i in range(0, self.angleNum): sum += data[i] * i return sum * 3 - 99 def EstimateAngles(self, img, rect): expandScale = 1.8 fillColor = (0, 0, 0) faceBox = eiface.BoundingSquare(rect[0], rect[1]) faceBox = eiface.ScaleRect2f(faceBox[0], faceBox[1], expandScale) img = eiface.CropRect(img, faceBox[0], faceBox[1], fillColor) self.modelObj.UploadImage("data", img, True) self.modelObj.Calculate() outYaw = self.modelObj.GetOutput("yaw"); outPitch = self.modelObj.GetOutput("pitch"); outRoll = self.modelObj.GetOutput("roll"); return (self.Result2Angle(outYaw), self.Result2Angle(outPitch), self.Result2Angle(outRoll)) 请注意:用 Python 实现的模型算法组件，EasyInfer 无法保证其跨平台兼容性和多语言支持。 因为Python解释器不是到处都有，版本也不统一, 因此, 目前 Python 接口的兼容性仍处于开发和完善当中. 二. 负责任务在 EasyInfer 项目中, 我主要承担了三部分任务, 分别为: 将 MXNet 模型转换成 TensorRT 模型, 为 EasyInfer 的底层引擎添加 MXNet 模型文件支持. 为 EasyInfer 提供封装完善的 C 接口 添加 OPENVINO 推理引擎底层支持 下面, 我将会详细介绍这三部分任务在 EasyInfer 项目中的功能和细节. 1. MXNet 模型到 TensorRT 模型的转换在上一节中模型转换的示意图中, 我们可以看到, EasyInfer 最初在接受 MXNet 文件时的处理办法是, 是首先利用一个 mxnet2caffe 模型转换工具将 MXNet 模型文件转换成对应的 Caffe 模型文件, 然后再对 Caffe 模作为输入送入到 EngineConvert 模块中去, 最终生成相应的 EasyModel 模型文件(引擎相关的单一文件). 如下图所示. 但是在后来的开发中我们发现, 有些 MXNet 网络层的参数在 Caffe 中不支持, 并且 Caffe 目前已经处于停止维护的状态, 因此, 我们决定重新实现模型转换部分的相关代码, 使得可以将 MXNet 的模型文件直接作为输入传给 EngineConvert 模块, 然后生成相应底层引擎的单一模型文件. 这部分的功能主要由我来负责, 我采取的实现思路如下所示: 设计能够封装 MXNet 模型文件信息的数据结构. 解析 MXNet 模型文件(.json 和 .params), 并将解析出来的信息存储到设计好的数据结构中. 根据节点的输入输出关系, 对网络层节点进行排序, 将各个网络层串接起来, 以确保每个网络层所处的位置正确. 设计 Mxnet 模型对应的 proto 数据结构, 完成对 MxnetNode 和 MxnetParams 的封装 根据封装好的 protobuf 数据, 填充 TensorRT 的 INetworkDefinition 实例对象 将填充好的 INetworkDefinition 返回, 完成引擎模型的转换工作. 下面, 我将会对每一个步骤的设计和实现进行介绍: (1). 设计能够封装 MXNet 模型文件信息的数据结构.对于 MXNet 模型文件来说, 它的网络结构描述放置在 .json 结尾的配置文件中, 其神经网络的每一个网络层在 .json 中都是以一个节点来表示的, 节点与节点之间的连接关系也是通过自身的 inputs 属性决定的, 为此, 首先设计出用于表示模型网络结构的数据结构, 将其命名为 MXNet, 其实现形式如下所示12345678using MxnetInput = std::pair&lt;size_t, size_t&gt;;struct MxnetNode &#123; std::string strName; std::string strOp; std::vector&lt;MxnetInput&gt; inputs; Attributes attrs;&#125;; 上面的定义中, strName代表了节点的名字, strOp代表了节点的操作类型(卷积, 池化等), inputs是一个pair类型的数据结构, 它记录了当前节点的输入层的编号, 最后是代表节点其他属性的一个封装类的实例对象, 该属性类的定义如下所示:12345678910111213using StringPair = std::pair&lt;std::string, std::string&gt;;class Attributes : public std::vector&lt;StringPair&gt; &#123;public: Attributes() = default; Attributes(const std::vector&lt;StringPair&gt; &amp;baseObj); std::string GetValue(const std::string &amp;strKey, bool bRequired) const; bool HasValue(const std::string &amp;strKey) const; boolRemoveValue(const std::string &amp;strKey);private: std::vector&lt;StringPair&gt;::iterator _Find(const std::string &amp;strKey); std::vector&lt;StringPair&gt;::const_iterator_Find(const std::string &amp;strKey) const;&#125;; (2). 解析 MXNet 模型文件(.json 和 .params)解析 MXNet 的.json文件时, 需要借助一个.json解析类, 该类会将.json文件中的信息按照字段的类别进行存储, 拿到这些信息后, 将相应字段的内容填充到MxnetNode数据结构中即可.而对于 MXNet 的.params参数文件, 可以根据.json文件中提供的信息获取到参数的个数, 然后根据参数的数据类型和占用的字节总数, 通过fread()函数完成参数数值的获取, 之后将其存储到MxnetParams数据结构中即可. 由于解析模型部分的代码较多, 因此这里只给出一些重要函数的声明和调用关系, 更细节的部分不再贴出, 具体代码如下所示:12345678#include "json_helper.hpp" // 定义了json的辅助解析工具MxnetNode ParseMxnetNode(Json::iterator jNode);std::vector&lt;MxnetNode&gt; ParseMxnetJson(const std::string &amp;strFile, std::vector&lt;size_t&gt; &amp;headIndices); // 内部会调用 ParseMxnetNode 函数std::vector&lt;MxnetParam&gt; LoadMxnetParam(std::string strModelFn); // strModelFN 为 .params 文件的路径 (3). 根据节点的输入输出关系, 对网络层节点进行排序我们知道, MXNet 的.json文件中, 节点是以编号的形式来记录的, 因此, 将节点的信息存储了以后, 为了后续流程能够更加方便的进行, 还需要按照节点的inputs属性对网络中的节点进行排序, 由于网络中节点的输入来源可能不止一个, 因此, 这里的排序使用了深度优先的遍历算法, 具体的代码实现如下所示: 123456789101112131415161718192021222324252627std::vector&lt;size_t&gt; GetSortedIndicesByDependencies( const std::vector&lt;MxnetNode&gt; &amp;nodeAry, const std::vector&lt;size_t&gt; &amp;headIndices) &#123; std::map&lt;size_t, size_t&gt; nodesLevel; for (size_t i = 0; i &lt; nodeAry.size(); ++i) &#123; nodesLevel[i] = 0; &#125; std::function&lt;void(size_t, size_t)&gt; VisitTree; VisitTree = [&amp;](size_t iNode, size_t nLevel) &#123; CHECK_LT(iNode, nodesLevel.size()); nodesLevel[iNode] = std::max(nodesLevel[iNode], nLevel); for (auto iInput : nodeAry[iNode].inputs) &#123; VisitTree(iInput.first, nLevel + 1); &#125; &#125;; for (auto iHead : headIndices) &#123; VisitTree(iHead, 0); &#125; std::vector&lt;size_t&gt; results(nodeAry.size()); std::iota(results.begin(), results.end(), 0); std::stable_sort(results.begin(), results.end(), [&amp;](size_t i1, size_t i2)&#123; return nodesLevel[i1] &gt; nodesLevel[i2]; &#125; ); return std::move(results);&#125; (4). 设计 Mxnet 模型对应的 proto 数据结构, 完成对 MxnetNode 和 MxnetParams 的封装为了使得代码在设计层面上的抽象程度更高, 这里需要将 mxnet 的网络结构和参数信息都封装在 protobuf 结构中, 这样做的好处是可以统一模型转换的中间数据结构, 同时也为以后进行其他类型模型转换时提供了代码复用的可能. 同样, 由于这部分的代码也比较多, 因此, 这里只给出少部分代表性的 proto 数据设计, 具体代码如下所示:12345678910111213141516171819202122232425message LayerParameter &#123; required string name = 1; // the layer name optional string type = 2; // the layer type repeated LayerInput inputs = 3; // the name of each bottom blob // The train / test phase for computation. optional Phase phase = 6; optional ConcatParameter concat_param = 104; optional ConvolutionParameter convolution_param = 106; optional DropoutParameter dropout_param = 108; optional InnerProductParameter inner_product_param = 117; optional ReLUParameter relu_param = 123; optional PoolingParameter pooling_param = 121; optional SoftmaxParameter softmax_param = 125; optional SliceParameter slice_param = 126; optional FlattenParameter flatten_param = 135; optional BatchNormParameter batch_norm_param = 139; optional EltwiseParameter eltwise_param = 110; // continue...&#125;message NetParameter &#123; optional string name = 1; repeated LayerParameter layer = 100;&#125; 在定义了相应的 proto 数据结构后, 下面是对应的 Mxnet 到 protoNet 的转换代码(同理, 由于篇幅问题, 只能给出函数声明和调用关系): 123456789101112131415161718192021222324252627282930313233343536373839void MxnetNode2ProtoLayer(MxnetNode mxnetNode, const std::vector&lt;MxnetParam&gt; &amp;mxnetParams, mxproto::LayerParameter &amp;mxLayer, int id) &#123; //... too long to show&#125;mxproto::NetParameter MxnetNodes2ProtoNet( const std::vector&lt;MxnetNode&gt; &amp;mxnetNodes, const std::vector&lt;MxnetParam&gt; &amp;mxnetParams, const std::vector&lt;size_t&gt; &amp;sortedIndices, const std::vector&lt;InputInfo&gt; &amp;inputInfos)&#123; std::vector&lt;mxproto::LayerParameter&gt; TRTLayers; std::map&lt;std::string, size_t&gt; typeCnt; // for unamed layers for (size_t i = 0; i &lt; sortedIndices.size(); ++i) &#123; auto &amp;mxnetNode = mxnetNodes[sortedIndices[i]]; mxproto::LayerParameter TRTLayer; MxnetNode2ProtoLayer(mxnetNode, mxnetParams, TRTLayer, sortedIndices[i]); // Put this layer to vector TRTLayers.emplace_back(std::move(TRTLayer)); &#125; mxproto::NetParameter net; for (auto &amp;layer : TRTLayers) &#123; net.add_layer()-&gt;CopyFrom(layer); &#125; return net;&#125;mxproto::NetParameter ParseMxnetModel(std::string strSymbolFn, std::string strParamsFn, const std::vector&lt;InputInfo&gt; &amp;inputInfos) &#123; std::vector&lt;size_t&gt; headIndices; auto mxnetNodes = ParseMxnetJson(strSymbolFn, headIndices); auto mxnetParams = LoadMxnetParam(strParamsFn); auto sortedIndices = GetSortedIndicesByDependencies(mxnetNodes, headIndices); mxproto::NetParameter protoNet = MxnetNodes2ProtoNet(mxnetNodes, mxnetParams, sortedIndices, inputInfos); //... too long to show&#125; (5). 根据封装好的 protobuf 数据, 填充 TensorRT 的 INetworkDefinition 实例对象在得到封装好的 protobuf 数据以后, 就可以根据 protobuf 数据中的属性来填充 TensorRT 模型, 填充方法是首先定义一个空的 nvinfer1::INetworkDefinition 对象, 然后根据 protobuf 中的网络层类型调用不同的成员函数, 如: addConvolution, addActivation 等等, 另外还需要根据之前排好序的节点编号将各个网络层的输入输出串接起来, 使得输入数据可以正确的在网络中执行前向计算, 最终还要特别标记输出层的数据, 以便得到最终的预测结果. 同样, 关于这里的代码实现也非常长, 因此只给出关键的类定义和函数声明和它们的调用关系, 具体代码如下所示:1234567891011121314151617181920212223242526272829303132class TRTNetworkPtr : public INetDefPtr &#123;public: enum class POOLING_ROUNDMODE&#123; UNDEF = 0, FULL = 1, VALID = 2&#125;; TRTNetworkPtr(INetDef *pNetwork) : INetDefPtr(pNetwork, std::bind( &amp;TRTNetworkPtr::NetDefDeleter, this, ph::_1)) &#123; &#125; float* GetWeight(std::string strName, size_t nSize) &#123; std::vector&lt;float&gt; &amp;buf = m_WeightMap[strName]; buf.resize(nSize); return buf.data(); &#125; void NetDefDeleter(INetDef *pNetDef) &#123; pNetDef-&gt;destroy(); &#125;; void SetPoolRoundMode(POOLING_ROUNDMODE roundMode);private: std::unique_ptr&lt;nvi::IOutputDimensionsFormula&gt; m_pPoolRoundFormula; std::map&lt;std::string, std::vector&lt;float&gt;&gt; m_WeightMap;&#125;;void ProtoNet2TRTNet(const mxproto::NetParameter &amp;protoNet, const std::vector&lt;InputInfo&gt; &amp;inputInfos, const std::vector&lt;std::string&gt; &amp;outputNames, TRTNetworkPtr &amp;pNetwork) &#123; //... too long to show&#125; (6). 将填充好的 INetworkDefinition 返回, 完成引擎模型的转换工作.当获取到正确填充后的 nvinfer1::INetworkDefinition 对象实例后, 需要将其转换成项目接受的引擎模型格式, 同样由于篇幅问题, 这里只给出最关键的核心函数的代码实现, 如下所示:12345678910111213141516171819202122232425262728293031323334void MxnetToTRTModel(std::string strSymbolFn, std::string strParamsFn, const ei::ModelInfo &amp;modelConfig, unsigned int maxBatchSize, MODE mode, nvcaffeparser1::IPluginFactory *pPluginFactory, nvi::IHostMemory** trtModelStream) &#123; // Preparing for pNetwork (nvinfer1::INetworkDefinition*) auto pLog = &amp;gLogger; CHECK_NOTNULL(pLog); auto pBuilder = nvi::createInferBuilder(*pLog); CHECK_NOTNULL(pBuilder); trt::TRTNetworkPtr pNetwork(pBuilder-&gt;createNetwork()); CHECK_NOTNULL(pNetwork); // Parse mxnet model to MxnetProto auto protoNet = mxparser::ParseMxnetModel(strSymbolFn, strParamsFn, modelConfig.inputInfos); // Convert MxnetProto to trtNet trt::ProtoNet2TRTNet(protoNet, modelConfig.inputInfos, modelConfig.outputNames, pNetwork); // Create TensorRT engine pBuilder-&gt;setMaxBatchSize(1); pBuilder-&gt;setMaxWorkspaceSize(36 &lt;&lt; 20); pBuilder-&gt;setFp16Mode(false); auto pEngine = pBuilder-&gt;buildCudaEngine(*pNetwork); CHECK_NOTNULL(pEngine); // Serialize trtNet to memory (*trtModelStream) = pEngine-&gt;serialize(); pEngine-&gt;destroy(); pBuilder-&gt;destroy();&#125; 2. EasyInfer 的 C 接口封装由于实际项目需求, 我们需要提供 EasyInfer 的纯 C 语言接口, 该任务的完成思路主要是将现有的 C++ 接口进行封装, 并对外提供统一完善的 API C 接口, 下面是较为主要的一些数据结构和函数的声明.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/*** Copyright (C) DeepGlint, Inc - All Rights Reserved* Unauthorized copying of this file, via any medium is strictly prohibited* Proprietary and confidential** C API Header** Written by Zhao Zheng &lt;zhengzhao@deepglint.com&gt;, Jan. 2019*/#include "easyinfer/common.hpp"//extern "C" &#123;typedef unsigned char UInt8;typedef struct &#123; int x; int y;&#125; POINT, *PPOINT;// ... too long to showtypedef struct &#123; float first; float second;&#125; LIVESCORE, *PLIVESCORE;#define LMK_PTS 72typedef struct &#123; POINT2F v[LMK_PTS];&#125; LMKS, *PLMKS;typedef struct MAT MAT;typedef MAT* PMAT;EXPORT void CreateMatFromImage(const char *imgPath, PMAT *ppMat);EXPORT void CreateMat(int rows, int cols, int channels, MAT **ppMat);EXPORT void DestroyMat(PMAT pMat);EXPORT void SetImgData(PMAT pMat, UInt8 *pImgData);EXPORT void GetRows(PMAT pMat, int *rows);EXPORT void GetCols(PMAT pMat, int *cols);EXPORT void GetChannels(PMAT pMat, int *channels);typedef struct CONFBOXES CONFBOXES;typedef CONFBOXES* PCONFBOXES;EXPORT void CreateConfBoxes(CONFBOXES **ppConfBoxes); //Invisible to userEXPORT void DestroyConfBoxes(PCONFBOXES pConfBoxes);EXPORT void GetConfBoxesSize(PCONFBOXES pConfBoxes, int *size);EXPORT void GetConf(PCONFBOXES pConfBoxes, int i, float *conf);EXPORT void GetBox(PCONFBOXES pConfBoxes, int i, PRECT2F pRect2f);EXPORT void GetConfBox(PCONFBOXES pConfBoxes, int i, float *conf, PRECT2F pRect2f);EXPORT void AddConfBox(PCONFBOXES pConfBoxes, float conf, RECT2F rect2f);typedef struct FLOATS FLOATS, *PFLOATS;EXPORT void CreateFloats(PFLOATS *ppFloats);EXPORT void DestroyFloats(PFLOATS pFloats);EXPORT void GetFloatsSize(PFLOATS pFloats, float *size);EXPORT void GetFloatVal(PFLOATS pFloats, int i, float *res);// ... continue 3. 添加 OPENVINO 推理引擎底层支持OpenVINO 是英特尔推出的一个视觉推理和神经网络优化的工具包, 可以让开发人员在主流深度学习框架上(TensorFlow, MXNet, Caffe 等)构建和训练人工智能模型, 并将其部署到各种产品中. EasyInfer 对于该引擎也提供了支持, 主要分以下四步完成: 模型转换 初始化 执行计算 获取输出结果 (1). 模型转换OpenVINO 官方提供了相应的模型转换工具: mo.py, 因此, 我们通过在 C++ 代码中执行该脚本, 来将用户的模型文件转换成 OpenVINO 所支持的文件格式:.xml和.bin. 然后, 我们将这些生成的文件中的数据写入到 Buffer 中, 最终将其以一个.VINOEngine结尾的文件进行存储, 这也是 EasyInfer 所接受的文件格式之一. 12345void _ConvertModel2Mem(ei::ModelInfo &amp;modelInfo, const std::string &amp;strModelType, const std::vector&lt;std::string&gt; &amp;modelFiles, std::string &amp;strModelBuf, std::string strWorkPath) const override; (2). 初始化完成模型文件的转换后, 根据相应的信息进行一些初始化工作, 其中包括基本类的初始化, 数据参数的数据化, 底层引擎的注册等 12void _Initialize(const ModelInfo &amp;modelInfo, const std::string &amp;strEngineData) override; (3). 执行计算在得到了网络模型的结构和参数信息, 就可以根据用户的输入来执行推理计算, 代码实现如下所示. 1void _CalculateInputs(std::vector&lt;Blob&gt; &amp;blobs) override; (4). 获取输出结果最终, 将计算的结果存储到 Buffer 中传送给用户, 由用户自行决定如何使用这些结果. 1void _DownloadOutputs(std::vector&lt;Blob&gt; &amp;outputBlobs) override; 三. 遇到的问题/usr/local/libopencv, cmake, ncnn, tensorRT python 的封装是用 Boost 中的组件完成的. experimental/filesystemgcc 4.8 缺少 stdc++fsgcc 版本需指定到5.0以上https://blog.csdn.net/PCaiyue/article/details/82117895 CMAKE 相关APPEND 指令要求cmake必须在3.5以上 undefined reference to: 说明没有找到相关的库, 有可能是链接错了, 或者路径找错了, 例如include的是opencv4.0, 使用的确实opencv3.4的库 cpp 链接or编译错误 调试方法: 学会使用 demangle, ld, ldd, lddtree 等等 cppg++ -std=c++11 -I/train/results/tensorRT/TensorRT-5.0.2.6/include -L/train/results/tensorRT/TensorRT-5.0.2.6/lib -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib64/stubs main.cpp -lnvinfer_static -lcuda -lcublas -lcudart -lcudnn -lcurand -lnvparsers_static -lprotobuf -o main 符号表.a: 相当于是一部分, 只要连进来就不会再出去, 会把库中的所有内容都加进来, 链接的时候直接添加.a的文件路径, 无需任何前缀.so: 链接的时候会先链进来到符号表中, 然后根据函数或者变量的使用情况进行剪枝, 如果发现没有使用任何内容, 那么就不会吧.so库中的内容加起来, 链接的时候需要时候 -l 前缀 TensorRT 没有BN的API利用两个 Scale 实现 TensorRT 的池化层不支持更改 ceil(valid) 和 floor(full) 模式利用setPoolingOutputDimensionsFormula接口进行全局设置, 如果中途被更改, 则应向用户报错. protobuf 内置问题需要将封装protobuf到easyinfer中, 但是ncnn本身也要使用protobuf, 因此要先对protobuf进行编译 直接问题: easyinfer定制版要做到无任何外部依赖, 但是内部继承的ncnn使用了protobuf, 而ei自身也使用了protobuf, 我们在编译自身项目的时候, 会正确的编译子模块的protobuf, 但是在编译子模块ncnn的时候, 他使用的是系统的protobuf, 如果系统没有装protobuf, 那么就会报错. (ncnn作为子模块, 无需任何改动, 可以与官方同步更新, protobuf因为删减了很多东西, 需要重新编写CMakeList, 因此不能同步更新, 事实上,我们也不需要更新protubf, 足够 ncnn 和 easyinfer 的使用需求), 解决上面的问题的方法之一就是在 CMakeLists.txt 中调用FindNCNN.cmake的时候, 显示的指定其 Module_PATH, 使它指向工程项目的cmake文件夹, 从而可以找到FindNCNN.cmake文件.但是这个问题虽然可以这样解决, 但是又会带来下面的新问题. 问题1: 主项目的CMakeLists.txt和NCNN中的tools里面的caffe, tf, onnx里面都有自身的CMakeList.txt, 他们都有find_package(protobuf)调用语句. 这个时候就会重复执行 protobuf 的 cmake 文件, 从而产生错误, 解决方法是在FindProtobuf.cmake里面设置一个变量, 然后检查是否之前已经执行过FindProtobuf.cmake, 如果执行过, 就不再执行, 这里需要注意的是, 不同的CMakeLists文件调用.cmake文件时, 变量不会共享值. 因此, 我们必须在FindNCNN.cmake文件里面, 用-D选项将该值传递. 因为主项目的CMakeList.txt里面会find_package(ncnn), 所以利用-D选项将主项目里面的值传递过来, 这样, 在NCNN里面tools的三个CMakeList文件都能够获取该值.最新更新: IF(NOT EXISTS ${PROTOBUF_PROTOC_EXECUTABLE}), 用该语句可以更加合理的控制只进行一次make, 并且不会受到大CMakeLists中FindPackage语句的顺序影响. 问题2: PROTOBUF_BUILD_DIR会根据CMAKE_BINARY_PATH的值来设置生成的protoc执行文件的位置, 但是CMAKE_BINARY_PATH 会随着context的不同改变自身的值, 在主项目中的CMakeList.txt中调用FindProtobuf.cmake的时候, protoc的路径是正确的,即easyinfer/build/protobuf/protoc. 但是子项目NCNN的CMakeLists也会执行一次Find_package(protobuf), 而此时CMAKE_BINARY_PATH的值就变成了easyinfer/3rdparty/ncnn/protobuf/protoc了, 但是我们生成的protoc是在build里面的, 所以此时就会报错找不到protoc. 解决方法是加一个变量, 强行把路径指到主项目的路径下. 这样, 最后make的时候路径才回正确(在make的时候才会令ncnn调用FindProtobuf.cmake)SET(PROTO_BINARY_DIR “${CMAKE_BINARY_DIR}/protobuf”) 问题3: 当所有路径的库依赖设置正确以后, 又有一个问题, 就是在第一遍make的时候, ncnn还是提示找不到protoc, 这个时候你直接在打一遍 make 就可以正常通过, 就是说这个时候确实已经生成了protoc, 也确实设置了正确的路径和选项, 但是不知道什么原因, ncnn看不到这个已经生成的protoc. 这个问题虽然看起来不太难解决, 但是也不太好处理, 因为我们的项目很大, 使用多线程make, 整个make大概需要5min的时候, 如果单线程make的话, 就会很慢很慢. 但是多线程失败后, 再单线程make的话, 就可以直接通过, 而不会报错, 所以不太好直接看到出问题的地方. 出现这个错误的原因是因为, 在多线程编译时有可能会先编译ncnn, 再编译protobuf, 但是ncnn需要protoc程序来生成src/engine/proto/文件夹下的.pb.cc和.pb.h文件, 如果此时没有编译好protoc, 那么就会报错. 但问题是ncnn应该是依赖于protobuf的, 为什么会先编译ncnn呢. 后来发现其实ncnn内部并没有添加强依赖, 而第二次编译通过的原因可能就是此时把 protoc 又给正确生成了. 所以第二遍可以过去, 这里面有一个随机性, 因此这个能编译过去也是一种侥幸, 如果改变文件中一些语句的位置, 使得对随机种子添加一些扰动, 那么就有可能又编不过去了. 出现这个错误的主要原因是NCNN中并没有对protobuf加ADD_DEPENDENCISE(ncnn, protobuf)依赖, 我们之前以为NCNN肯定对protobuf加了依赖. 因为它的官方就说了必须要装protobuf才可以, 后来才发现, 官网想表达的意思是你在装ncnn之前, protobuf的protoc可执行程序就必须已经存在于系统中, 它是默认你存在的, 如果不存在就会告诉你未找到, 后来我们在NCNN中tools/caffe的CMakeLists里面找, 还真的没找到加依赖的语句, 因此, 我们就在FindNCNN.camke文件里面, 添加了FindPackage(Protobuf REQUIRED) 和 ADD_DEPENDENCIES(ncnn, protobuf)两句话, 然后就确保了在编译安装ncnn之前, 一定会先把protoc给安装好, 这样就不会错误提示未找到protoc了. ncnn 要用protoc生成caffe/tf/onnx下的.cc和.h文件, 然后ncnn会使用这些文件 这中间还有很多依赖库的设置问题(libprotobuf.a), 各种编译选项的设置问题(-lpthread), 等等等等 回看的话感觉好像不是那么难, 但是当时调试的时候并不知道问题具体出错在哪了, 因为明明正确生成了protoc, 但是ncnn却显示找不到, 而且当时对cmake和make的流程也不是特别熟悉, 所以这个bug调了很久(一整天, 印象很深刻) 定制版 easyinfer 的命名空间问题由于定制版的 easyinfer 不使用任何依赖, 也就是说我们需要将 protobuf 和 opencv 全部内置到 easyinfer 中(内部需求), 这个时候, 命名空间就会出现问题, 以 opencv 举例来说, 当 easyinfer 底层使用类似于cv::imread()这样的语句时, 如果此时用户的系统中已经安装了其他版本的 opencv, 那么在编译连接的时候, 就有可能会链接到用户自己安装的opencv库中, 而在程序其他地方有可能会使用内置的opencv库, 又或者是版本之间的兼容性等等问题, 往往就会报类似 undefined reference 的错误. 对于 protobuf 来说也是同理, 对于 google:: 来说, 也会报出相应的错误.解决上面问题的方案是(不是最好的方案, 但是是目前正在使用的方案): 修改自定义 opencv 和 protobuf 的命名空间, 将cv::修改成CV::, google::修改成Google::. 实际上, 在opencv内部也使用了自己封装的protobuf, 它采取了和我们类似的解决方案, 也就是将protobuf的命名空间改成了google_private::. 其他pkg-config 查询opencv 文件是根据 opencv.pc 里面的文本输出的 -L 指定路径 -l 会在 L 指定的路径想进行搜索, 链接对应的文件 ImportError: cannot import name main when running pip —version command in windows7 32 bit https://stackoverflow.com/questions/28210269/importerror-cannot-import-name-main-when-running-pip-version-command-in-windo报错Traceback (most recent call last): File “/usr/bin/pip3”, line 9, in from pip import mainImportError: cannot import name ‘main’]]></content>
      <categories>
        <category>项目</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[M2Det (AAAI, 2019)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-M2Det-AAAI2019%2F</url>
    <content type="text"><![CDATA[文章: M2Det: A Single-Shot Object Detector based on Multi-Level Feature PyramidNetwork作者: Qijie Zhao, Tao Sheng, Yongtao Wang机构: 北京大学, 阿里达摩院 摘要Feature pyramids 在现阶段 SOTA 的 one-stage (DSSD, RetinaNet, RefineDet) 和 two-stage (Mask R-CNN, DetNet) 中都被用来解决目标实例的尺度变化问题. 尽管这些模型取得了令人鼓舞的结果. 但是他们都具有一些限制: 因为他们的特征金字塔都是简单的根据 backbone 固有的多尺度的金字塔结构建立起来的, 但是这些 backbone 实际上是针对物体分类任务而设计的. 在本文中, 我们提出了 Multi-Level Feature Pyramid Network (MLFPN) 来构建更加有效的, 针对不同尺度下的目标检测问题的特征金字塔结构. 首先, 我们融合了从 backbone 中提取的 multi-level 的特征(即 multi-layers)作为 base feature. 然后, 将 base feature 送入一组交替连接的 Thinned U-shape Modules(简化U型模块) 和 Feature Fusion Modules(特征融合模块), 利用每个 U shape 模块的 decode layers 的输出作为特征用来检测物体. 最后, 将 decode layers 具有相同尺寸的特征组合起来, 构建用于目标检测的特征金字塔, 这个特征金字塔中的每一个 feature map 都包含不同 levels 当中的特征(layers). 为了评价 MLFPN 的有效性, 我们设计并训练了一个强有力的端到端的 one-stage 模型, 命名为 M2Det (将 MLFPN 应用到 SSD 上面), 并且取到了更好的检测性能. 具体来说, 在 MS-COCO 上取得了 41.0 mAP, 11.8 FPS 的成绩, 使用的是 sing-scale inference strategy. 如果使用 multi-scale inference strategy 的话, 可以达到 44.2 的 mAP. 介绍物体实例之间的尺度变化是目标检测任务中主要挑战之一, 并且通常有两种策略来解决该问题. 其一是在 image pyramid (一系列输入图片的不同尺度的副本)上检测物体, 该方法仅仅可以在 testing 阶段使用. 很明显, 该方法会大大增加计算的复杂度和内存的消耗, 因此检测器的效率会大大降低. 第二种方法是在从输入图片中提取的 feature pyramid 上检测物体, 该方法可以同时在 training 和 testing 阶段使用. 相对于使用 image pyramid, 第二种方法使用更少的内存和算力. 更重要的是, feature pyramid 的结构可以很容易的添加到 sota 的模型当中, 并且可以进行端到端的训练. 尽管目标检测的 feature pyramids 取得了很大令人鼓舞的结果, 但是它依然有一些缺点(limitations), 因为这些特征金字塔的构建都是简单的从 backbone 固有的多尺度的, 金字塔式的结构中得到的, 而这些 backbone 主要是为目标分类任务设计的. 例如, 如图1所示, SSD 直接使用 backbone(VGG16) 的最后两个卷积段的卷积层和 4 个额外的步长为 2 的卷积层来构建特征金字塔. FPN 通过融合深层和浅层的特征图谱来构建特征金字塔. STDN 仅仅使用 DenseNet 的最后一个 dense block 通过 pooling 和 scale-transfer 操作来构建特征金字塔. 一般来说, 上面提到的方法都具有两点 limitations: 第一, 金字塔中的特征图谱不足以表示针对目标检测任务的特征, 因为它们仅仅是从针对分类任务的 backbone 的特征层中构建的. 第二, 金字塔中的每一层特征图谱大多都被用来检测对应尺度的物体, 即主要或者仅仅是从 backbone 中一个单一的 level 层中构建的. 一般情况下, 深层网络中的高级特征对分类子任务的区分能力更强, 而层次较浅的低级特征有助于物体的 location regression 子任务. 此外, 低级特征更适合描述具有简单外观的物体, 而高级特征适用于具有复杂外观的物体. 例如, 一个交通灯和一个处于远处的人也许会具有相当的大小, 但是很明显人具有更加复杂的特征. 因此, 金字塔中的每一个特征图谱(用于检测固定范围大小)主要或者仅仅包含了单一 level 的特征, 这样就有可能无法生成最优的检测结果.本文的目标是构建一个更加有效的 feature pyramid 来检测不同尺寸的物体, 同时可以避免现有方法存在的那些 limitations. 如图 2 所示, 为了达到该目标, 我们首先融合了从 backbone 中提取的 multi-level 的特征(即, multi layers), 然后将其送入到一个由 TUM 和 FFM 交替连接的组件中, 来提取 表征能力更强, 的 multi-level multil-scale 的特征. 值得注意的是, 在每一个 U-shape 模块中的 decoder layers 都共享中相似的 depth. 最后, 我们将具有相同尺寸的特征图谱聚集起来, 从而构建最终的用于目标检测的特征金字塔. 很明显, 组成特征金字塔的最后一层的 decoder layers 具有比 backbone 中的网络层更深的层次, 也就是说, 它们的表征能力更强. 不仅如此, 最终的特征金字塔的每一层特征图谱的 decoder layers 都是从不同的层级中获得, 也就是说, 它们的表征能力更强. 不仅如此, 最终的特征金字塔的每一层特征图谱的 decoder layers 都是从不同的层级中获得的. 因此, 我们称本文的 feature pyramid block 为 Multi-Level Feature Pyramid Network(MLFPN). 为了验证 MLFPN 的有效性, 我们设计并训练了一个强有力的端到端的 one-stage 目标检测器, 命名为 M2Det (M2 的意思是 multi-level multi-scale features). 该模型在 MS-COCO 上取得了 41.0 mAP, 11.8 FPS 的成绩, 使用的是 sing-scale inference strategy. 如果使用 multi-scale inference strategy 的话, 可以达到 44.2 的 mAP. 相关工作featurizing image pyramid: 由于对内存和算力的消耗, 该策略在 real-time 任务中几乎不可用. feature pyramid: MS-CNN, SSD, DSSD, FPN, YOLOv3, RetinaNet, RefineDet Proposed MethodM2Det 的整体结构如图2所示. M2Det 使用 backbone 和 Multi-Level Feature Pyramid Network(MLFPN) 从输入图片中提取特征, 然后类似于 SSD, 基于学习到的特征生成密集的 bounding boxes 和 category scores, 最终再使用 NMS 算法生成最终的结果. MLFPN 包含三个模块: 特征融合模块(Feature Fusion Module, FFM), 简化的 U-shape 模块(Thinned U-shape Module, TUM), 以及尺度特征聚合模块(Scale-wise Feature Aggregation Module, SFAM). FFMv1 通过融合 backbone 的特征图谱来丰富 base features 中的语义信息. 每一个 TUM 都会生成一组多尺度的特征(a group of multi-shape features), 然后会交替的连接 TUMs 和 FFMv2s 模块来提取 multi-level multi-scale features. 除此以外, SFAM 会收集这些特征, 并通过尺度特征连接操作和自适应的注意力机制(scale-wise feature concatenation operation and an adaptive attention mechanism)将它们送到不同层次的特征金字塔中. 下面我们将详细介绍这三个模块. Multi-level Features Pyramid Network.如图2所示, MLFPN 包含三部分, 首先, FFMv1 融合了浅层和深层的特征来生成 base feature, 具体来说就是 VGGNet 的 conv4_3 和 conv5_3. 这为 MLFPN 提供了多层级(multi-level)语义信息. 其次, 若干个 TUMs 和 FFMv2 交替连接. 具体的说, 每一个 TUM 都会生成多个不同尺度的 feature maps. FFMv2 融合了 base feature 和前一个 TUM 输出个最大的 feature map. 融合后的 feature maps 会被送到下一个 TUM 中. 注意到第一个 TUM 没有其他 TUMs 的先验知识, 因此它仅仅是从 base feature 中进行学习. 输出的 multi-level multi-scale features 的计算方式如下: [x_1^l, x_2^l, ..., x_i^l] = \begin{cases} T_l(X_{base}), && l = 1 \\ T_l(F(X_{base}, x_i^l-1)), && l = 2, ..., L \end{cases} \tag 1上式中, $X_{base}$ 表示 base feature, $x_i^l$ 表示第 $l$ 个 TUM 中的 第 $i$ 个尺寸(scale)的 feature, $L$ 代表 TUMs 的数量, $T_l$ 代表第 $l$ 个 TUM 的处理过程, $F$ 代表 FFMv1 的处理过程. 最终, SFAM 会通过按照尺度的特征连接操作(scale-wise feature concatenation operation)和按照深度的注意力机制(channel-wise attention mechanism)来聚集 multi-level multi-scale features. FFMs: FFMs 会从 M2Det 网络中的不同层级(different levels)融合特征, 这一点对于构建最终的 multi-level feature pyramid 来说至关重要. FFMs 使用 $1\times 1$ 的卷积层来压缩 input features 的 channels, 同时使用连接操作(concatenation operation) 来聚集这些特征图谱. 特别的, 由于 FFMv1 接受 backbone 中两个不同尺寸(scales)的 feature map 作为输入, 所以它将会采用上采样操作(upsample operation)来将深层次的 feature map 放大到和浅层 map 相同到尺寸, 然后才进行 concatenation 操作. 同时, FFMv2 接受 base feature 和前一个 TUM 输出的最大 feature map 作为输入, 这两个 feature map 本身就具有相同的尺寸(scale), 并且会生成融合后的特征, 用作下一个 TUM 的输入. FFMv1 和 FFMv2 的结构细节分别如图4(a)和(b)所示. TUMs: 如图4(c)所示, 和 FPN 以及 RetinaNet 不同, TUM 采用一个 “更薄” 的 U-shape 结构. encoder 是一系列 stride 为 2 的 $3 \times 3$ 的卷积层组成, decoder 将这些卷积层的输出作为其特征映射的参考集, 而 FPN 的做法是将 ResNet backbone 中每一个卷积段(stage)的最后一层的输出作为参考集. 除此以外, 我们在 decoder 的 upsample 和 element-wise sum operation 之后添加了 $1\times 1$ 的卷积层来增加学习能力, 同时保持特征的平滑度(smoothness). 每一个 TUM 的 decoder 的所有输出构成了当前 level 和 multi-scale features. 最终, 堆叠的 TUMs 的输出构成了 multi-level multi-scale features, 中间的 TUM 提供中间层级特征(medium-level features), 后面的 TUM 提供深层次的特征(deep-level features). SFAM: SFAM 的目的是聚集 TUMs 产生的 multi-level multi-scale features 到图3所示的 multi-level feature pyramid. SFAM 的第一阶段是沿着 channel dimension 将具有相同尺寸(scale) 的特征图片连接(concatenate)起来. 聚集后的特征金字塔可以表示成: $X = [X_1, X_2, …, X_i]$, 这里 $X_i = Concat(x_i^1, x_i^2, …, x_i^L) \in R^{W_i \times H_i \times C}$, 代表第 $i$ 大(scale)的特征. 因此, 在聚集后的特征金字塔中的每一个 scale 都包含 multi-level depths 的特征. 然而, 简单的连接操作(concatenation) 并没有足够的适应能力(not adaptive enough). 在第二阶段, 我们引入了 channel-wise attention module 来丰富特征, 以便它能关注那些有益的 channels. Following SE block, 我们在 squeeze step 使用 global average pooling 来生成 channel-wise statistics $z\in R^C$. 同时为了完全捕获 channel-wise dependencies, 在之后的 excitation step 通过两个全连接层来学习注意力机制: s = F_{ex}(z, W) = \sigma(W_2 \delta (W_1 z)), \tag 2上式中 $\sigma$ 代表 ReLU, $\delta$ 代表 sigmoid, $W_1 \in R^{\frac{C}{r}\times C}$, $W_2 \in R^{ C\times \frac{C}{r}}$, $r$ 是 reduction ratio(在本文的实验中 $r=16$). 最终的输出是通过 reweighting the input X with activation s 得到的: \tilde X_i^c = F_{scale}(X_i^c, s_c) = s_c \dot X_i^C, \tag 3上式中, $\tilde X_i = [\tilde X_i^1, \tilde X_i^2, …, \tilde X_i^C]$, 每一个特征都被 rescaling operation 增加或减弱(enhanced or weakened). 二阶段的自适应调整过程实际上是先用 avg 得到 channel 上的统计数据, 然后用两个全连接层来学习 channel 之间的依赖, 最后根据此依赖对输入的 multi-level feature map 的权重进行 reweighting Network Configurations我们使用了两种类型的 backbones. 在训练整个网络之前, 先将 backbone 在 Image 2012 上进行预训练. MLFPN 的默认配置包含有 8 个 TUMs, 每一个 TUM 具有 5 个卷积层和 5 个上采样操作, 因此每个 TUM 将会输出 6 种 scales 的 feature maps. 为了降低参数的数量, 对于 TUM 的每种尺度的特征, 我们仅仅申请 256 维的通道, 因此网络可以容易的在 GPUs 上进行训练. 对于输入的尺寸大小, 我们采用和 SSD, RefineDet, 以及 RetinaNet 一样的设置, 即 320, 512, 和 800.在检测阶段, 我们为 6 个金字塔特征都添加了两个卷积层, 分别用来获取位置回归和物体分类的预测结果. 检测使用的 default boxes 的尺度范围和 SSD 的规则相同. 并且当输入尺寸为 $800\times 800$ 的时候, 除了保持最大特征图的最小尺寸外, scale ranges 将会按比例增加. 在 特征金字塔的 每一个像素点 上, 我们设置了 6 个 anchors(具有3中宽高比). 然后, 我们利用 0.05 的阈值来过滤那些 socres 很低的 anchors (难负样例挖掘). 接着使用了 soft-NMS with linear kernel 来进行后处理. ExperimentsImplementation detailsstart training with warm-up strategy for 5 epochs.initialize lr: $2\times 10^{-3}$, decrease it to $2\times 10^{-4}$ and $2\times 10{-5}$ at 90 epochs and 120 epochs, and stop at 150 epochs.developed with PyTorch v0.4.0input size: 320, 512GPU: 4 NVIDIA Titan X GPUsbatch size: 32 (16 each for 2 Gpus, or 8 each for 4 GPUs)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DCN v2 (Arxiv, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DCNv2-Arxiv2018%2F</url>
    <content type="text"><![CDATA[文章: Deformable ConvNets v2: More Deformable, Better Results作者: Xizhou Zhu, Han Hu, Stephen Lin, Jifeng Dai机构: 中科大, Microsoft Research Asia 摘要可变形卷积网络的优越性能源于其对目标几何变化的适应能力。通过对其自适应行为的考察，我们发现，虽然其自然特征的空间支持比规则的ConvNets更接近于对象结构，但这种支持可能 远远超出了感兴趣的区域，导致特征受到不相关图像内容的影响。为了解决这个问题，我们提出了一种新的可变形卷积神经网络，通过增加建模能力和更强的训练，提高了它对相关图像区域的 聚焦能力。通过在网络内部对可变形卷积进行更全面的集成，引入一种可以扩展变形建模范围的 modulation mechanism，增强了建模能力。为了有效利用这种丰富的建模能力，我们提出了一种 feature mimicking scheme 来指导网络训练，帮助网络学习反映R-CNN特征的对象焦点和分类能力的特征。在本文的贡献下，这个可变形ConvNets的新版本在原始模型的基础上获得了显著的性能提升，并在用于对象检测和实例分割的COCO基准上产生了领先的结果。 由于尺度、姿态、视点和零件变形等因素引起的几何变化是物体识别和检测的主要挑战。目前解决这一问题的最先进的方法是可变形卷积网络(DCNv1)[8]，它引入了两个模块来帮助CNNs对这种变化进行建模。其中一个模块是可变形卷积(deformable convolution)，其中标准卷积的网格采样位置都是通过相对于前面的特征图所学习到的位移来偏移的。另一个是可变形的RoIpooling，在这里可以学习RoIpooling[16]中bin位置的偏移量。将这些模块合并到一个神经网络中，使其能够适应对象的配置，特别是通过变形其采样和池化模式来适应对象的结构。利用该方法，可以大大提高目标检测的精度。 在本文中，我们提出了一种新的变形卷积算法，称为Deformable ConvNets v2 (DCNv2)，它增强了学习可变形卷积的建模能力。这种建模能力的增加来自于两种互补的形式。首先是网络中可变形卷积层的扩展使用。使用偏移学习能力装备更多的卷积层允许DCNv2在更大范围的特征级别上控制采样。第二种是可变形卷积模块中的 modulation mechanism，其中每个样本不仅要经过学习偏移量，而且还要经过学习到的特征幅值的 modulated(调制)。因此，网络模块能够改变空间分布及其样本的相对影响。(The network module is thus given the ability to vary both the spatial distribution and the relative influence of its samples.) 为了充分利用DCNv2不断增长的建模能力，需要进行有效的 training。受神经网络中知识蒸馏工作的启发[2,22]，我们利用 teacher network 来实现这一目的，teacher 会在 training 过程中提供指导。我们特别使用 R-CNN[17] 作为 teacher。由于R-CNN是一个训练有素的对裁剪后的图像内容进行分类的网络，它可以学习不受感兴趣区域之外无关信息影响的特征。为了模拟这个特性，DCNv2在其训练中加入了一个模拟损失的特性，这有助于学习与R-CNN一致的特性。这样，DCNv2的增强变形采样得到了较强的训练信号。 通过以上提议的更改，可变形模块仍然是轻量级的，并且可以轻松地集成到现有的网络体系结构中。具体来说，我们将DCNv2合并到 Faster R-CNN[33]和 Mask R-CNN[20]系统中，使用多种骨干网络。在 COCO benchmark 上的大量实验表明，在对象检测和实例分割方面，DCNv2比DCNv1有显著的改进。DCNv2的代码将会发布。 Analysis of Deformable ConvNet BehaviorSpatial Support Visualization为了更好地理解可变形卷积网络的行为，我们通过网络节点的有效感受野(Effective receptive fileds)[31]、有效采样位置(Effective sampling/bin locations)和误差有界显著性区域(Error-bounded saliency regions)来形象化网络节点的空间支持。这三种模式提供了不同的和互补的观点，可以帮助理解图像区域对于神经网络节点的响应。 Effective receptive fields: 并不是网络节点感受野内的所有像素都对其响应做出相同的贡献。这些贡献的差异由一个有效的感受野表示，其值计算为节点响应相对于每个图像像素[31]的强度扰动的梯度。我们利用有效感受野来检验单个像素对网络节点的相对影响，但注意，该方法不能反映完整图像区域的结构化影响。 Effective sampling/bin locations: 在[8]中，为了理解可变形卷积网络的行为，可视化了(堆叠)卷积层的采样位置和RoIpooling层中的 sampling bins。但是，这些采样位置对网络节点的相对贡献没有被揭示。相反，我们将包含此信息的有效抽样位置可视化，计算为网络节点相对于 sampling / bin locations的梯度，以便了解它们的贡献强度。 Error-bounded saliency regions: 最近关于图像显著性的研究[41,44,13,7]表明，去除不影响网络节点的图像区域，网络节点的响应不会发生变化。基于此属性，我们可以在一个小的误差范围内，将节点的支持区域确定为与完整图像响应相同的最小图像区域。我们将此称为错误有界显著性区域(Error-bounded saliency regions)，它可以通过逐步屏蔽图像的部分并计算得到的节点响应来找到，详见附录。误差有界显著性区域便于比较不同网络的支持区域。 Spatial Support of Deformable ConvNets本文分析了可变形卷积网络在目标检测中的视觉支持区域。我们使用常规的 ConvNet 作为 baseline，包括一个 Faster R-CNN + ResNet-50[21]对象检测器与 Aligned RoIpooling1[20]。ResNet-50中的所有卷积层都应用于整个输入图像。conv5阶段的有效步长由32个像素降低到16个像素，提高了 feature map 的分辨率。RPN[33]头是在ResNet-101的 conv4 特征的基础上添加的。在 conv5 特征的基础上，我们添加了 Faster R-CNN 头部[16]，它由 Aligned RoIpooling和两个完全连接(fc)层组成，然后是分类和 bbox 回归分支。我们按照[8]中的步骤将目标检测器转换为 Deformable 的对应网络。将conv5阶段的3×3卷积层替换为可变形卷积层。此外，将 Aligned RoIpooling 替换为 Deformable RoIpooling。这两个网络都是在COCO基准上训练和可视化的。值得一提的是，当 offset 的学习率设置为零时，Deformable Faster R-CNN检测器会退化为规则的 Faster R-CNN with aligned RoIpooling. 使用这三种可视化模式，我们检查了conv5阶段的最后一层节点的空间支持, 如图 1 (a)~(b) 所示。并给出了在[8]中分析的采样位置。通过这些可视化，我们得出以下观察结果: 规则的ConvNets可以在一定程度上对几何变化进行建模，这可以从图像内容在空间支持方面的变化得到证明。由于深卷积的强大表示能力，网络权值能够适应一定程度的几何变换。 通过引入可变形卷积，网络对几何变换建模的能力大大增强，即使在具有挑战性的COCO基准上也是如此。空间支持更适合于图像内容，前景的节点拥有覆盖整个对象的支持，而后景的节点则扩展了包含更大上下文的支持。然而，空间支持的范围可能是不精确的，包括与检测无关的背景区域在内的前景节点的有效感受野和误差有界显著性区域。 这三种类型的空间支持可视化比[8]中使用的采样位置提供更多的信息。这一点可以在规则的ConvNets中看到，规则ConvNets在网格中具有固定的采样位置，但实际上通过网络权重调整其有效的空间支持。可变形卷积网络也是如此，它的预测受到学习偏移量和网络权重的共同影响。就像在[8]中所做的那样，单独检查采样位置可能会导致关于可变形卷积网络的错误结论。图2 (a)∼(b)显示了每个roi检测头中2fc节点的空间支持，紧接着是分类和边界框回归分支。有效bin位置的可视化表明，目标前景上的bin通常会从分类分支获得较大的梯度，从而对预测产生较大的影响。这种观察适用于 Aligned RoIpooling和 Deformable RoIpooling。在 Deformable RoIpooling中，由于引入了可学习的bin偏移量，与 Aligned RoIpooling相比，覆盖对象前景的bin比例要大得多。因此，下游 Faster R-CNN head可以获得更多相关 bins 的信息。同时，Aligned RoIpooling和 Deformable RoIpooling中误差有界的显著性区域都没有完全聚焦于对象前景，这 说明RoI外的图像内容影响预测结果。根据最近的一项研究[6]，这种特征干扰可能对检测有害。 虽然与常规卷积网相比，可变形卷积网对几何变化的适应能力明显提高，但也可以看出，它们的空间支持可以扩展到感兴趣的区域之外。因此，我们寻求升级可变形卷积网络，使其能够更好地聚焦于相关的图像内容，并提供更高的检测精度。(这是 DCN v2 的核心优化点) More Deformable ConvNets为了提高网络适应几何变化的能力，我们提出了一些变化来增强其建模能力，并帮助它利用这种增强后的能力。 Stacking More Deformable Conv Layers在可变形卷积网络能够有效地对具有挑战性的基准进行几何变换建模这一观察结果的鼓舞下，我们大胆地用可变形卷积层替换更多的常规卷积层。我们希望通过叠加更多的可变形conv层，进一步增强整个网络的几何变换建模能力。 本文将 ResNet-50 的 conv3、conv4、conv5 阶段中的所有 3×3 卷积层都替换成了可变形卷积。因此，网络中有12层可变形卷积。相比之下，[8]中只使用了三层可变形卷积，全部处于conv5阶段。在[8]中可以观察到，在相对简单和小规模的PASCAL VOC基准测试中，当叠加超过三层时，性能达到饱和。此外，对COCO的误导偏移可视化可能阻碍了对更具挑战性的基准的进一步探索。 在实验中，我们观察到将可变形层应用到 conv3-conv5 阶段可以达到对COCO目标检测的精度和效率之间的 best tradeoff。详见5.2节。 Modulated Deformable Modules为了进一步增强可变形卷积神经网络对空间支持区域的控制能力，提出了一种调制机制(Modulation Mechanism)。使用该机制, 可变形 ConvNets 模块不仅可以在感知输入特征时调整偏移量，还可以从不同的 spatial locations/bins 中调节输入的特征幅值(feature amplitude)。在极端情况下，模块可以通过将特征振幅设置为零来决定不接收来自特定 location / bin 的信号。因此，来自相应空间位置的图像内容会大大减少或不影响模块输出。也可以说，调制机制为网络模块提供了另一个自由度来调整其空间支持区域。 给定 $K$ 个采样点的卷积核，令 $w_k$ 和 $p_k$ 分别表示第 $K$ 个采样点的权值和预先指定的偏移量。例如，$K = 9, pk∈{(- 1，- 1)，(- 1,0)，…，(1,1)}$ 定义了一个膨胀为 1 的 $3×3$ 卷积核。设 $x(p)$ 和 $y(p)$ 分别表示输入特征图 $x$ 和输出特征图 $y$ 中位置 $p$ 处的特征。那么调制(modulated)后的可变形卷积可表示为: y(p) = \sum^K_{k=1} w_k \cdot x(p + p_k + \Delta p_k) \cdot \Delta m_k上式中 $\Delta p_k$ 和 $\Delta m_k$ 分别为第 $k$ 个位置的学习参数偏移量和调制标量。调制标量 $\Delta m_k$ 位于 $[0,1]$ 范围内，$\Delta p_k$ 为实数，取值范围无约束。由于 $p + p_k +\Delta p_k$ 为分数形式，因此在计算 $x(p + p_k +\Delta p_k)$ 时采用了双线性插值，和[8]相同。 $\Delta p_k$ 和 $\Delta m_k$ 都是通过在相同的输入 feature map $x$ 上应用一个单独的卷积层得到的，这个卷积层与当前卷积层具有相同的空间分辨率和膨胀。输出为 $3K$ 通道，其中第一个 $2K$ 通道对应于学习到的偏移量 $\{\Delta p_k\}^K_{k=1}$，其余 $K$ 通道进一步送入 sigmoid层，得到调制标量 $\{\Delta m_k\}^K_{k=1}$。在这个单独的卷积层中，内核权值初始化为零。因此，$\Delta p_k$ 和 $\Delta m_k$ 的初始值分别为 0 和 0.5。新添加的用于偏移和调制学习的conv层的学习率设置为现有层的0.1倍。 Modulated Deformable RoIpooling 的设计与此类似。给定一个 RoI 输入, RoIpooling 将其划分为 K 个 spatial bins(如7×7)，在每个 bin 中应用空间间隔相等的采样网格(如2×2)，取网格上采样值的平均值，计算bin输出。设 $\Delta p_k$ 和 $\Delta m_k$ 为第 k 个 bin 的可学习偏移量和调制量。output binning feature y(k) 计算如下: y(k) = \sum^{n_k}{j=1} x(p_{kj} + \Delta p_k) \cdot m_k / n_k其中 $p_{kj}$ 为第 $k$ 个 $bin$ 中第 $j$ 个网格单元的采样位置，$n_k$ 为采样网格单元的个数。采用双线性插值获取特征 $x(p_{kj} +\Delta p_k)$。$\Delta p_k$ 和 $\Delta m_k$ 的值由输入的 feature map 上的同级分支产生。在这个分支中，RoIpooling在RoI上生成特征，然后是 1024 维的两个fc层(初始化的值为标准差为0.01的高斯分布)。在此之上，新添加一个额外 fc 层生成 $3K$ 通道的输出(初始化的值为零)。其中第一个 $2K$ 通道是归一化的可学习偏移量(normalized learnable offsets)，其中会会根据 RoI 的宽和高使用 element-wise multiplications，以此获得 $\{\Delta p_k\}^K_{k=1}$。其余的 $K$ 个通道用一个 sigmoid 层进行归一化，以此生成 $\{\Delta m_k\}^K_{k=1}$。新添加的fc层用于学习 offset 的学习率与现有层相同。 R-CNN Feature Mimicking如图2所示，对于常规的卷积网和可变形卷积网，每个RoI分类节点的误差有界显著性区域都可以超出RoI。RoI外的图像内容可能会影响提取的特征，从而降低目标检测的最终结果。 在[6]中，作者发现冗余上下文可能是 Faster R-CNN 检测错误的来源。结合其他动机(如分类和边界盒回归分支之间共享较少的特征)，作者提出将 Faster R-CNN 和 R-CNN 的分类得分结合起来，得到最终的检测得分。由于 R-CNN 分类得分主要集中在从输入RoI中裁剪的图像内容上，将其合并将有助于缓解冗余上下文问题，提高检测精度。然而，由于 Faster R-CNN 和 R-CNN 分支都需要同时应用于训练和推理，因此组合后的系统速度较慢。 同时，可变形卷积网络在调节空间支持区域方面具有强大的功能。对于 DCNv2 来说，Modulated Deformable RoIpooling 模块可以通过简单地设置 bin 的调制量(Modulated Scalars)，来排除冗余上下文。然而，我们在第5.3节的实验表明，即使使用 Modulated Deformable 模块，也不能通过标准的 Faster R-CNN 训练程序很好地学习这种表征。 我们怀疑这是因为传统的 Faster R-CNN 的训练损失不能有效地驱动这种表征的学习。因此需要额外的 guidance 来指导 training。 受最近关于特征模仿的研究[2,22,28]的启发，我们在 Deformable Faster R-CNN 的每个 RoI 特征上加入了一个特征模拟损失(feature mimic loss)，以迫使它们类似于从裁剪图像中提取的 R-CNN 特征。这个辅助训练目标的目的是驱动 Deformable Faster R-CNN 学习更多的“聚焦”特征表示(“focused” feature representations)，就像 R-CNN 一样。我们注意到，基于图2中可视化的空间支持区域，对于图像背景上的 negative RoIs，聚焦特征表示很可能不是最优的。因为对于背景区域，可能需要考虑更多的上下文信息，以免产生假阳性检测。因此，特征模拟损失只在和那些与 ground-truth objects 有足够重叠的 positive RoIs 上强制执行。 训练 Deformable Faster R-CNN 的网络结构如图3所示。除了 Faster R-CNN 网络之外，还增加了一个R-CNN分支，用于模拟特征。给定一个用于特征模仿的 RoI $b$，裁剪相应的图像块并将其大小调整到224×224像素。在R-CNN分支中，主干网对 resized image patch 进行操作，生成14×14空间分辨率的feature map。在特征图的顶部应用 (Modulated) Deformable RoIpooling 层，其中 input RoI 覆盖整个 resized image patch(左上角为(0,0)，高度和宽度为224像素)。然后，应用两个 1024 维的 fc 层，对输 input image patch 生成 R-CNN 特征表示，用 $f_{RCNN}(b)$ 表示。在 fc 层之后, 一个 $(C+1)$ 维的 Softmax 分类器紧跟其后, $C$ 代表类别数, 加一代表背景. 特征模拟损失是在 R-CNN 特征表示 $f_{RCNN}(b)$ 和 Faster R-CNN 对应的 $f_{FRCNN}(b)$ 之间进行的，后者也是1024维，由 Fast R-CNN 头部的2个fc层产生。特征模仿损失(feature mimic loss)由 $f_{RCNN}(b)$ 与 $f_{FRCNN}(b)$ 的余弦相似度定义，计算如下: L_{mimic} = \sum_{b\in \Omega} [1 - \cos(f_{RCNN}(b), f_{FRCNN}(b))]上式中 $\Omega$ 表示用于 feature mimic training的 RoIs 采样集合. 。在 SGD 训练中, 给定一个输入图像, RPN 会产生 32 个 positive region proposals 采样样本添加到 $\Omega$ 当中。在 R-CNN 的 classification head 上, 我们使用了交叉熵损失, 同时也会计算 $\Omega$ 中的 RoIs。网络训练是由特征模拟损失和 R-CNN 分类损失以及 Faster R-CNN 的原始损失项驱动的。两个新引入的损失项的权重是原来 Faster R-CNN 损失项的0.1倍。R-CNN中对应模块与 Faster R-CNN 分支之间的网络参数是共享的，包括主干网络、(Modulated) Deformable RoIpooling 和2个fc头(两个分支中的分类头是不共享的)。在推理过程中，对测试图像只使用 Faster R-CNN网络，不使用辅助的R-CNN分支。因此，R-CNN feature mimicking 在 inference 中没有引入额外的计算。 Related WorkDeformation Modeling: SIFT, ORB, DPM, STN(Spatial translation-invariant)Relation Networks and Attention ModulesSpatial Support ManipulationEffective Receptive Field and Salient RegionNetwork Mimicking and Distillation ExperimentsEnriched Deformation Modeling从表1所示的消融实验中检验了 enriched deformable 模型的效果。 表2给出了输入图像分辨率为800像素时的结果，该结果遵循 Detectron 代码库中的默认设置。同样的结论也成立。 R-CNN Feature Mimicking表3显示了 R-CNN feature mimicking 不同设计选择的消融实验 Application on Stronger Backbones将ResNet-50替换为ResNet-101和ResNext-101[39]，得到的结果如表4所示。 Conclusion尽管可变形卷积网络在几何变化建模方面具有优越的性能，但其空间支持远远超出了感兴趣的区域，导致特征受到无关图像内容的影响。在本文中，我们提出了一种新的可变形的卷积神经网络，通过增强建模能力和更强的训练策略，提高了它对相关图像区域的聚焦能力。在用于对象检测和实例分割的COCO基准上获得了显著的性能提升。 A1. Error-bounded Image SaliencyA2. DCNv2 with Various Image Resolution图4为常规的 ConvNets 和 DCNv2 在不同分辨率图像上的应用结果。 如图5所示，常规ConvNets的空间支持只能覆盖如此高分辨率大对象的一小部分，精度受到影响。同时，DCNv2的空间支持可以有效地适应不同分辨率的物体。 表5给出了使用ResNet-101进行多尺度测试的结果。 A3. ImageNet Pre-Trained DCNv2表6给出了验证集的前1和前5个分类精度。DCNv2比常规基线和DCNv1基线都有明显的改进，只需要少量额外的计算开销。DCNv2丰富的变形建模能力，有利于ImageNet分类任务本身。 表7比较了使用不同预训练模型的DCNv2在不同任务上的性能。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSD 源码实现 (PyTorch)]]></title>
    <url>%2Fz_post%2FPyTorch-SSD%2F</url>
    <content type="text"><![CDATA[概览SSD 和 YOLO 都是非常主流的 one-stage 目标检测模型, 并且相对于 two-stage 的 RCNN 系列来说, SSD 的实现更加的简明易懂, 接下来我将从以下几个方面展开对 SSD 模型的源码实现讲解: 模型结构定义 DefaultBox 生成候选框 解析预测结果 MultiBox 损失函数 Augmentations Trick 模型训练 模型预测 模型验证 其他辅助代码 可以看出, 虽然 SSD 模型本身并不复杂, 但是也正是由于 one-stage 模型较简单的原因, 其检测的准确率相对于 two-stage 模型较低, 因此, 通常需要借助许多训练和检测时的 Tricks 来提升模型的精确度, 这些代码我们会放在第三部分讲解. 下面, 我们按照顺序首先对 SSD 模型结构定义的源码进行解析.(项目地址: https://github.com/amdegroot/ssd.pytorch) 模型结构定义本部分代码主要位于 ssd.py 文件里面, 在本文件中, 定义了SSD的模型结构. 主要包含以下类和函数, 整体概览如下:1234567891011121314151617181920# ssd.pyclass SSD(nn.Module): # 自定义SSD网络 def __init__(self, phase, size, base, extras, head, num_classes): # ... SSD 模型初始化 def forward(self, x): # ... 定义forward函数, 将设计好的layers和ops应用到输入图片 x 上 def load_weights(self, base_file): # ... 加载参数权重值def vgg(cfg, i, batch_norm=False): # ... 搭建vgg网络def add_extras(cfg, i, batch_norm=False): # ... 向VGG网络中添加额外的层用于feature scalingdef multibox(vgg, extra_layers, cfg, num_classes): # ... 构建multibox结构base = &#123;...&#125; # vgg 网络结构参数extras = &#123;...&#125; # extras 层参数mbox = &#123;...&#125; # multibox 相关参数def build_ssd(phase, size=300, num_classes=21): # ... 构建模型函数, 调用上面的函数进行构建 为了方便理解, 我们不按照文件中的定义顺序解析, 而是根据文件中函数的调用关系来从外而内, 从上而下的进行解析, 解析顺序如下: build_ssd(…) 函数 vgg(…) 函数 add_extras(…) 函数 multibox(…) 函数 SSD(nn.Module) 类 build_ssd(…) 函数在其他文件通常利用build_ssd(phase, size=300, num_classes=21)函数来创建模型, 下面先看看该函数的具体实现: 123456789101112131415161718192021222324252627282930313233343536373839# ssd.pyclass SSD(nn.Module): # 自定义SSD网络 def __init__(self, phase, size, base, extras, head, num_classes): # ... def forward(self, x): # ... def load_weights(self, base_file): # ...def vgg(cfg, i, batch_norm=False): # ... 搭建vgg网络def add_extras(cfg, i, batch_norm=False): # ... 向VGG网络中添加额外的层用于feature scalingdef multibox(vgg, extra_layers, cfg, num_classes): # ... 构建multibox结构base = &#123; # vgg 网络结构参数 '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M', 512, 512, 512], '500': []&#125;extras = &#123; # extras 层参数 '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256], '500': []&#125;mbox = &#123; # multibox 相关参数 '300': [4, 6, 6, 6, 4, 4], '500': []&#125;def build_ssd(phase, size=300, num_classes=21): # 构建模型函数, 调用上面的函数进行构建 if phase != "test" and phase != "train": # 只能是训练或者预测阶段 print("ERROR: Phase: " + phase + " not recognized") return if size != 300: print("ERROR: You specified size " + repr(size) + ". However, "+ "currently only SSD300 is supported!") # 仅仅支持300size的SSD return base_, extras_, head_ = multibox(vgg(base[str(size)], 3), add_extras(extras[str(size), 1024), mbox[str(size)], num_classes ) return SSD(phase, size, base_, extras_, head_, num_classes) 可以看到, build_ssd(...)函数主要使用了multibox(...)函数来获取base_, extras_, head_, 在调用multibox(...)函数的同时, 还分别调用了vgg(...)函数, add_extras(...)函数, 并将其返回值作为参数. 之后, 利用这些信息初始化了SSD网络. 那么下面, 我们就先查看一下这些函数定义和作用 vgg(…) 函数我们以调用顺序为依据, 先对multibox(...)函数的内部实现进行解析, 但是在查看multibox(...)函数之前, 我们首先需要看看其参数的由来, 首先是vgg(...)函数, 因为 SSD 是以 VGG 网络作为 backbone 的, 因此该函数主要定义了 VGG 网络的结果, 根据调用语句vgg(base[str(size)], 3)可以看出, 调用vgg时向其传入了两个参数, 分别为base[str(size)] 和3, 对应的就是base[&#39;300&#39;]和3. 123456789101112131415161718192021222324# ssd.pydef vgg(cfg, i, batch_norm = False): # cfg = base['300'] = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M', 512, 512, 512], # i = 3 layers = [] in_channels = i for v in cfg: if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)] if v == 'C': layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)] else: conv2d = nn.Conv2d(in_channels=in_channels, out_channels=v, kernel_size=3, padding=1) if batch_norm: layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)] else: layers += [conv2d, nn.ReLU(inplace=True)] in_channels = v pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6) conv7 = nn.Con2d(1024, 1024, kernel_size=1) layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)] return layers 上面的写法是 ssd.pytorch 代码中的原始写法, 代码风格体现了 PyTorch 灵活的编程特性, 但是这种写法不是那么直观, 需要很详细的解读才能看出来这个网络的整个结构是什么样的. 建议大家结合 VGG 网络的整个结构来解读这部分代码, 核心思想就是通过预定义的 cfg=base={...} 里面的参数来设置 vgg 网络卷积层和池化层的参数设置, 由于 vgg 网络的模型结构很经典, 有很多文章都写的很详细, 这里就不再啰嗦了, 我们主要来看一下 SSD 网络中比较重要的点, 也就是下面的 extras_layers. add_extras(…) 函数想必了解 SSD 模型的朋友都知道, SSD 模型中是利用多个不同层级上的 feature map 来进行同时进行边框回归和物体分类任务的, 除了使用 vgg 最深层的卷积层以外, SSD 还添加了几个卷积层, 专门用于执行回归和分类任务(如文章开头图2所示), 因此, 我们在定义完 VGG 网络以后, 需要额外定义这些新添加的卷积层. 接下来, 我们根据论文中的参数设置, 来看一下 add_extras(...) 的内部实现, 根据调用语句add_extras(extras[str(size)], 1024) 可知, 该函数中参数cfg = extras[&#39;300&#39;], i=1024.123456789101112131415161718# ssd.pydef add_extras(cfg, i, batch_norm=False): # cfg = [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256] # i = 1024 layers = [] in_channels = i flag = False for k, v in enumerate(cfg): if in_channels != 'S': if v == 'S': # (1,3)[True] = 3, (1,3)[False] = 1 layers += [nn.Conv2d(in_channels=in_channels, out_channels=cfg[k+1], kernel_size=(1, 3)[flag], stride=2, padding=1)] else: layers += [nn.Conv2d(in_channels=in_channels, out_channels=v, kernel_size=(1, 3)[flag])] flag = not flag in_channels = v return layers 注意, 在extras中, 卷积层之间并没有使用 BatchNorm 和 ReLU, 实际上, ReLU 的使用放在了forward函数中 同样的问题, 上面的定义不是很直观, 因此我将上面的代码用 PyTorch 重写了, 重写后的代码更容易看出网络的结构信息, 同时可读性也较强, 代码如下所示(与上面的代码完全等价): 1234567891011def add_extras(): exts1_1 = nn.Conv2d(in_channels=1024, out_channels=256, kernel_size=1) exts1_2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1) exts2_1 = nn.Conv2d(512, 128, 1, 1, 0) exts2_2 = nn.Conv2d(128, 256, 3, 2, 1) exts3_1 = nn.Conv2d(256, 128, 1, 1, 0) exts3_2 = nn.Conv2d(128, 256, 3, 1, 0) exts4_1 = nn.Conv2d(256, 128, 1, 1, 0) exts4_2 = nn.Conv2d(128, 256, 3, 1, 0) return [exts1_1, exts1_2, exts2_1, exts2_2, exts3_1, exts3_2, exts4_1, exts4_2] 在定义完整个的网络结构以后, 我们就需要定义最后的 head 层, 也就是特定的任务层, 因为 SSD 是 one-stage 模型, 因此它是同时在特征图谱上产生预测边框和预测分类的, 我们根据类别的数量来设置相应的网络预测层参数, 注意需要用到多个特征图谱, 也就是说要有多个预测层(原文中用了6个卷积特征图谱, 其中2个来自于 vgg 网络, 4个来自于 extras 层), 代码实现如下: multibox(…) 函数multibox(...) 总共有4个参数, 现在我们已经得到了两个参数, 分别是vgg(...)函数返回的layers, 以及add_extras(...)函数返回的layers, 后面两个参数根据调用语句可知分别为mbox[str(size)](mbox[&#39;300&#39;])和num_classes(默认为21). 下面, 看一下multibox(...)函数的具体内部实现: 12345678910111213141516# ssd.pydef multibox(vgg, extra_layers, cfg, num_classes): # cfg = [4, 6, 6, 6, 4, 4] # num_classes = 21 # ssd总共会选择6个卷积特征图谱进行预测, 分别为, vggnet的conv4_3, 以及extras_layers的5段卷积的输出(每段由两个卷积层组成, 具体可看extras_layers的实现). # 也就是说, loc_layers 和 conf_layers 分别具有6个预测层. loc_layers = [] conf_layers = [] vgg_source = [21, -2] for k, v in enumerate(vgg_source): loc_layers += [nn.Conv2d(vgg[v].out_channels, cfg[k]*4, kernel_size=3, padding=1] conf_layers += [nn.Conv2d(vgg[v].out_channels, cfg[k]*num_classes, kernel_size=3, padding=1)] for k, v in enumerate(extra_layers[1::2], 2): loc_layers += [nn.Conv2d(v.out_channels, cfg[k]*4, kernel_size=3, padding=1)] conf_layers += [nn.Conv2d(v.out_channels, cfg[k]*num_classes, kernel_size=3, padding=1)] return vgg, extra_layers, (loc_layers, conf_layers) 同样, 我们可以将上面的代码写成可读性更强的形式:1234567891011121314151617181920212223242526272829# ssd.pydef multibox(vgg, extras, num_classes): loc_layers = [] conf_layers = [] #vgg_source=[21, -2] # 21 denote conv4_3, -2 denote conv7 # 定义6个坐标预测层, 输出的通道数就是每个像素点上会产生的 default box 的数量 loc1 = nn.Conv2d(vgg[21].out_channels, 4*4, 3, 1, 1) # 利用conv4_3的特征图谱, 也就是 vgg 网络 List 中的第 21 个元素的输出(注意不是第21层, 因为这中间还包含了不带参数的池化层). loc2 = nn.Conv2d(vgg[-2].out_channels, 6*4, 3, 1, 1) # Conv7 loc3 = nn.Conv2d(vgg[1].out_channels, 6*4, 3, 1, 1) # exts1_2 loc4 = nn.Conv2d(extras[3].out_channels, 6*4, 3, 1, 1) # exts2_2 loc5 = nn.Conv2d(extras[5].out_channels, 4*4, 3, 1, 1) # exts3_2 loc6 = nn.Conv2d(extras[7].out_channels, 4*4, 3, 1, 1) # exts4_2 loc_layers = [loc1, loc2, loc3, loc4, loc5, loc6] # 定义分类层, 和定位层差不多, 只不过输出的通道数不一样, 因为对于每一个像素点上的每一个default box, # 都需要预测出属于任意一个类的概率, 因此通道数为 default box 的数量乘以类别数. conf1 = nn.Conv2d(vgg[21].out_channels, 4*num_classes, 3, 1, 1) conf2 = nn.Conv2d(vgg[-2].out_channels, 6*num_classes, 3, 1, 1) conf3 = nn.Conv2d(extras[1].out_channels, 6*num_classes, 3, 1, 1) conf4 = nn.Conv2d(extras[3].out_channels, 6*num_classes, 3, 1, 1) conf5 = nn.Conv2d(extras[5].out_channels, 4*num_classes, 3, 1, 1) conf6 = nn.Conv2d(extras[7].out_channels, 4*num_classes, 3, 1, 1) conf_layers = [conf1, conf2, conf3, conf4, conf5, conf6] # loc_layers: [b×w1×h1×4*4, b×w2×h2×6*4, b×w3×h3×6*4, b×w4×h4×6*4, b×w5×h5×4*4, b×w6×h6×4*4] # conf_layers: [b×w1×h1×4*C, b×w2×h2×6*C, b×w3×h3×6*C, b×w4×h4×6*C, b×w5×h5×4*C, b×w6×h6×4*C] C为num_classes # 注意pytorch中卷积层的输入输出维度是:[N×C×H×W], 上面的顺序有点错误, 不过改起来太麻烦 return loc_layers, conf_layers 定义完网络中所有层的关键结构以后, 我们就可以利用这些结构来定义 SSD 网络了, 下面就介绍一下 SSD 类的实现. SSD(nn.Module) 类在 build_ssd(...) 函数的最后, 利用语句return SSD(phase, size, base_, extras_, head_, num_classes)调用的返回了一个SSD类的对象, 下面, 我们就来看一下看类的内部细节(这也是SSD模型的主要框架实现) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# ssd.pyclass SSD(nn.Module): # SSD网络是由 VGG 网络后街 multibox 卷积层 组成的, 每一个 multibox 层会有如下分支: # - 用于class conf scores的卷积层 # - 用于localization predictions的卷积层 # - 与priorbox layer相关联, 产生默认的bounding box # 参数: # phase: test/train # size: 输入图片的尺寸 # base: VGG16的层 # extras: 将输出结果送到multibox loc和conf layers的额外的层 # head: "multibox head", 包含一系列的loc和conf卷积层. def __init__(self, phase, size, base, extras, head, num_classes): # super(SSD, self) 首先找到 SSD 的父类, 然后把类SSD的对象转换为父类的对象 super(SSD, self).__init__() self.phase = phase self.num_classes = num_classes self.cfg = (coco, voc)[num_classes == 21] self.priorbox = PriorBox(self.cfg) # layers/functions/prior_box.py class PriorBox(object) self.priors = Variable(self.priorbox.forward(), volatile=True) # from torch.autograd import Variable self.size = size self.vgg = nn.ModuleList(base) self.L2Norm = L2Norm(512,20) # layers/modules/l2norm.py class L2Norm(nn.Module) self.extras = nn.ModuleList(extras) self.loc = nn.ModuleList(head[0]) # head = (loc_layers, conf_layers) self.conf = nn.ModuleList(head[1]) if phase = "test": self.softmax = nn.Softmax(dim=-1) # 用于囧穿概率 self.detect = Detect(num_classes, 0, 200, 0.01, 0.45) # layers/functions/detection.py class Detect # 用于将预测结果转换成对应的坐标和类别编号形式, 方便可视化. def forward(self, x): # 定义forward函数, 将设计好的layers和ops应用到输入图片 x 上 # 参数: x, 输入的batch 图片, Shape: [batch, 3, 300, 300] # 返回值: 取决于不同阶段 # test: 预测的类别标签, confidence score, 以及相关的location. # Shape: [batch, topk, 7] # train: 关于以下输出的元素组成的列表 # 1: confidence layers, Shape: [batch*num_priors, num_classes] # 2: localization layers, Shape: [batch, num_priors*4] # 3: priorbox layers, Shape: [2, num_priors*4] sources = list() # 这个列表存储的是参与预测的卷积层的输出, 也就是原文中那6个指定的卷积层 loc = list() # 用于存储预测的边框信息 conf = list() # 用于存储预测的类别信息 # 计算vgg直到conv4_3的relu for k in range(23): x = self.vgg[k](x) s = self.L2Norm(x) sources.append(s) # 将 conv4_3 的特征层输出添加到 sources 中, 后面会根据 sources 中的元素进行预测 # 将vgg应用到fc7 for k in range(23, len(self.vgg)): x = self.vgg[k](x) sources.append(x) # 同理, 添加到 sources 列表中 # 计算extras layers, 并且将结果存储到sources列表中 for k, v in enumerate(self.extras): x = F.relu(v(x), inplace=True) # import torch.nn.functional as F if k % 2 = 1: # 在extras_layers中, 第1,3,5,7,9(从第0开始)的卷积层的输出会用于预测box位置和类别, 因此, 将其添加到 sources列表中 sources.append(x) # 应用multibox到source layers上, source layers中的元素均为各个用于预测的特征图谱 # apply multibox to source layers # 注意pytorch中卷积层的输入输出维度是:[N×C×H×W] for (x, l, c) in zip(sources, self.loc, self.conf): # permute重新排列维度顺序, PyTorch维度的默认排列顺序为 (N, C, H, W), # 因此, 这里的排列是将其改为 $(N, H, W, C)$. # contiguous返回内存连续的tensor, 由于在执行permute或者transpose等操作之后, tensor的内存地址可能不是连续的, # 然后 view 操作是基于连续地址的, 因此, 需要调用contiguous语句. loc.append(l(x).permute(0,2,3,1).contiguous()) conf.append(c(x).permute(0,2,3,1).contiguous()) # loc: [b×w1×h1×4*4, b×w2×h2×6*4, b×w3×h3×6*4, b×w4×h4×6*4, b×w5×h5×4*4, b×w6×h6×4*4] # conf: [b×w1×h1×4*C, b×w2×h2×6*C, b×w3×h3×6*C, b×w4×h4×6*C, b×w5×h5×4*C, b×w6×h6×4*C] C为num_classes # cat 是 concatenate 的缩写, view返回一个新的tensor, 具有相同的数据但是不同的size, 类似于numpy的reshape # 在调用view之前, 需要先调用contiguous loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1) # 将除batch以外的其他维度合并, 因此, 对于边框坐标来说, 最终的shape为(两维):[batch, num_boxes*4] conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1) # 同理, 最终的shape为(两维):[batch, num_boxes*num_classes] if self.phase == "test": # 这里用到了 detect 对象, 该对象主要由于接预测出来的结果进行解析, 以获得方便可视化的边框坐标和类别编号, 具体实现会在后文讨论. output = self.detect( loc.view(loc.size(0), -1, 4), # 又将shape转换成: [batch, num_boxes, 4], 即[1, 8732, 4] self.softmax(conf.view(conf.size(0), -1, self.num_classes)), # 同理, shape 为[batch, num_boxes, num_classes], 即 [1, 8732, 21] self.priors.type(type(x.data)) # 利用 PriorBox对象获取特征图谱上的 default box, 该参数的shape为: [8732,4]. 关于生成 default box 的方法实际上很简单, 类似于 anchor box, 详细的代码实现会在后文解析. # 这里的 self.priors.type(type(x.data)) 与 self.priors 就结果而言完全等价(自己试验过了), 但是为什么? ) if self.phase == "train": # 如果是训练阶段, 则无需解析预测结果, 直接返回然后求损失. output = ( loc.view(loc.size(0), -1, 4), conf.view(conf.size(0), -1, self.num_classes), self.priors ) return output def load_weights(self, base_file): # 加载权重文件 other, ext = os.path.splitext(base_file) if ext == ".pkl" or ".pth": print("Loading weights into state dict...") self.load_state_dict(torch.load(base_file, map_location=lambda storage, loc: storage)) print("Finished!") else: print("Sorry only .pth and .pkl files supported") 在上面的模型定义中, 我们可以看到使用其他几个类, 分别是 layers/functions/prior_box.py class 的 PriorBox(object), layers/modules/l2norm.py 的 class L2Norm(nn.Module) layers/functions/detection.py 的 class Detect 基本上从他们的名字就可以看出他们的用途, 其中, 最简单的是 l2norm 类, 该类实际上就是实现了 L2归一化(也可以利用 PyTorch API 提供的归一化接口实现). 这一块没什么好讨论的, 朋友们可以自己去源码去查看实现方法, 基本看一遍就能明白了.下面我们着重看一下用于生成 Default box(也可以看成是 anchor box) 的 PriorBox 类, 以及用于解析预测结果, 并将其转换成边框坐标和类别编号的 Detect类. 首先来看如何利用卷积图谱来生成 default box. DefaultBox 生成候选框根据 SSD 的原理, 需要在选定的特征图谱上输出 Default Box, 然后根据这些 Default Box 进行边框回归任务. 首先梳理一下生成 Default Box 的思路. 假如feature maps数量为 $m$, 那么每一个feature map中的default box的尺寸大小计算如下: s_k = s_{min} + \frac{s_{max} - s_{min}}{m-1}(k-1), k\in [1,m]上式中, $s_{min} = 0.2 , s_{max} = 0.9$. 对于原文中的设置 $m=6 (4, 6, 6, 6, 4, 4)$, 因此就有 $s = \{0.2, 0.34, 0.48, 0.62, 0.76, 0.9\}$然后, 几个不同的aspect ratio, 用 $a_r$ 表示: $a_r = {1,2,3,1/2,1/3}$, 则每一个default boxes 的width 和height就可以得到( $w_k^a h_k^a=a_r$ ): w_k^a = s_k \sqrt{a_r}h_k^a = \frac{s_k}{\sqrt {a_r}}对于宽高比为1的 default box, 我们额外添加了一个 scale 为 $s_k’ = \sqrt{s_k s_{k+1}}$ 的 box, 因此 feature map 上的每一个像素点都对应着6个 default boxes (per feature map localtion).每一个default box的中心, 设置为: $(\frac{i+0.5}{|f_k|}, \frac{j+0.5}{f_k})$, 其中, $|f_k|$ 是第 $k$ 个feature map的大小 $i,j$ 对应了 feature map 上所有可能的像素点.在实际使用中, 可以自己根据数据集的特点来安排不同的 default boxes 参数组合 了解原理以后, 就来看一下怎么实现, 输出 Default Box 的代码定义在 layers/functions/prior_box.py 文件中. 代码如下所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# `layers/functions/prior_box.py`class PriorBox(object): # 所谓priorbox实际上就是网格中每一个cell推荐的box def __init__(self, cfg): # 在SSD的init中, cfg=(coco, voc)[num_classes=21] # coco, voc的相关配置都来自于data/cfg.py 文件 super(PriorBox, self).__init__() self.image_size = cfg["min_dim"] self.num_priors = len(cfg["aspect_ratios"]) self.variance = cfg["variance"] or [0.1] self.min_sizes = cfg["min_sizes"] self.max_sizes = cfg["max_sizes"] self.steps = cfg["steps"] self.aspect_ratios = cfg["aspect_ratios"] self.clip = cfg["clip"] self.version = cfg["name"] for v in self.variance: if v &lt;= 0: raise ValueError("Variances must be greater than 0") def forward(self): mean = [] for k, f in enumerate(self.feature_maps): # 存放的是feature map的尺寸:38,19,10,5,3,1 # from itertools import product as product for i, j in product(range(f), repeat=2): # 这里实际上可以用最普通的for循环嵌套来代替, 主要目的是产生anchor的坐标(i,j) f_k = self.image_size / self.steps[k] # steps=[8,16,32,64,100,300]. f_k大约为feature map的尺寸 # 求得center的坐标, 浮点类型. 实际上, 这里也可以直接使用整数类型的 `f`, 计算上没太大差别 cx = (j + 0.5) / f_k cy = (i + 0.5) / f_k # 这里一定要特别注意 i,j 和cx, cy的对应关系, 因为cy对应的是行, 所以应该零cy与i对应. # aspect_ratios 为1时对应的box s_k = self.min_sizes[k]/self.image_size mean += [cx, cy, s_k, s_k] # 根据原文, 当 aspect_ratios 为1时, 会有一个额外的 box, 如下: # rel size: sqrt(s_k * s_(k+1)) s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size)) mean += [cx, cy, s_k_prime, s_k_prime] # 其余(2, 或 2,3)的宽高比(aspect ratio) for ar in self.aspect_ratios[k]: mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)] mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)] # 综上, 每个卷积特征图谱上每个像素点最终产生的 box 数量要么为4, 要么为6, 根据不同情况可自行修改. output = torch.Tensor(mean).view(-1,4) if self.clip: output.clamp_(max=1, min=0) # clamp_ 是clamp的原地执行版本 return output # 输出default box坐标(可以理解为anchor box) 最终, 输出的ouput就是一张图片中所有的default box的坐标, 对于论文中的默认设置来说产生的box数量为: 38^2 \times 4+19^2 \times 6+ 10^2 \times 6+5^2 \times 6+3^2 \times 4+1^2 \times 4 = 8732 解析预测结果在模型中, 我们为了加快训练速度, 促使模型收敛, 因此会将相应的 box 的坐标转换成与图片size成比例的小数形式, 因此, 无法直接将模型产生的预测结果可视化. 下面, 我们首先会通过接受 Detect 类来说明如何解析预测结果, 同时, 还会根据源码中提过的 demo 文件来接受如何将对应的结果可视化出来, 首先, 来看一下 Detect 类的定义和实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445# ./layers/class Detect(Function): # 测试阶段的最后一层, 负责解码预测结果, 应用nms选出合适的框和对应类别的置信度. def __init__(self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh): self.num_classes = num_classes self.background_label = bkg_label self.top_k = top_k self.conf_thresh = conf_thresh self.nms_thresh = nms_thresh self.variance = voc_config["variance"] def forward(self, loc_data, conf_data, prior_data): # loc_data: [batch, num_priors, 4], [batch, 8732, 4] # conf_data: [batch, num_priors, 21], [batch, 8732, 21] # prior_data: [num_priors, 4], [8732, 4] num = loc_data.size(0) # batch_size num_priors = prior_data.size(0) output = torch.zeros(num, self.num_classes, self.top_k, 5) # output:[b, 21, k, 5] conf_preds = conf_data.view(num, num_priors, self.num_classes).transpose(2,1) # 维度调换 # 将预测结果解码 for i in range(num): # 对每一个image进行解码 decoded_boxes = decode(loc_data[i], prior_data, self.variance)#获取第i个图片的box坐标 conf_scores = conf_preds[i].clone() # 复制第i个image置信度预测结果 for cl in range(1, self.num_classes): # num_classes=21, 所以 cl 的值为 1~20 c_mask = conf_scores[cl].gt(self.conf_thresh) # 返回由0,1组成的数组, 0代表小于thresh, 1代表大于thresh scores = conf_scores[cl][c_mask] # 返回值为1的对应下标的元素值(即返回conf_scores中大于thresh的元素集合) if scores.size(0) == 0: continue # 没有置信度, 说明没有框 l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes) # 获取对应box的二值矩阵 boxes = decoded_boxes[l_mask].view(-1,4) # 获取置信度大于thresh的box的左上角和右下角坐标 # 返回每个类别的最高的score 的下标, 并且除去那些与该box有较大交并比的box ids, count = nms(boxes, scores, self.nms_thresh, self.top_k) # 从这些box里面选出top_k个, count&lt;=top_k # count&lt;=top_k output[i, cl, :count] = torch.cat((scores[ids[:count]].unsqueeze(1), boxes[:count]), 1) flt = output.contiguous().view(num,-1,5) _, idx = flt[:, :, 0].sort(1, descending=True) _, rank = idx.sort(1) flt[(rank &lt; self.top_k).unsqueeze(-1).expand_as(flt)].fill_(0) # 注意, view共享tensor, 因此, 对flt的修改也会反应到output上面 return output 在这里, 用到了两个关键的函数 decode() 和 nms(), 这两个函数定义在./layers/box_utils.py文件中, 代码如下所示:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384def decode(loc, priors, variances): """Decode locations from predictions using priors to undo the encoding we did for offset regression at train time. Args: loc (tensor): location predictions for loc layers, Shape: [num_priors,4] priors (tensor): Prior boxes in center-offset form. Shape: [num_priors,4]. variances: (list[float]) Variances of priorboxes Return: decoded bounding box predictions """ boxes = torch.cat(( priors[:, :2] + loc[:, :2] * variances[0] * priors[:, 2:], priors[:, 2:] * torch.exp(loc[:, 2:] * variances[1])), 1) boxes[:, :2] -= boxes[:, 2:] / 2 boxes[:, 2:] += boxes[:, :2] return boxesdef nms(boxes, scores, overlap=0.5, top_k=200): """Apply non-maximum suppression at test time to avoid detecting too many overlapping bounding boxes for a given object. Args: boxes: (tensor) The location preds for the img, Shape: [num_priors,4]. scores: (tensor) The class predscores for the img, Shape:[num_priors]. overlap: (float) The overlap thresh for suppressing unnecessary boxes. top_k: (int) The Maximum number of box preds to consider. Return: The indices of the kept boxes with respect to num_priors. """ keep = scores.new(scores.size(0)).zero_().long() if boxes.numel() == 0: return keep x1 = boxes[:, 0] y1 = boxes[:, 1] x2 = boxes[:, 2] y2 = boxes[:, 3] area = torch.mul(x2 - x1, y2 - y1) v, idx = scores.sort(0) # sort in ascending order # I = I[v &gt;= 0.01] idx = idx[-top_k:] # indices of the top-k largest vals xx1 = boxes.new() yy1 = boxes.new() xx2 = boxes.new() yy2 = boxes.new() w = boxes.new() h = boxes.new() # keep = torch.Tensor() count = 0 while idx.numel() &gt; 0: i = idx[-1] # index of current largest val # keep.append(i) keep[count] = i count += 1 if idx.size(0) == 1: break idx = idx[:-1] # remove kept element from view # load bboxes of next highest vals torch.index_select(x1, 0, idx, out=xx1) torch.index_select(y1, 0, idx, out=yy1) torch.index_select(x2, 0, idx, out=xx2) torch.index_select(y2, 0, idx, out=yy2) # store element-wise max with next highest score xx1 = torch.clamp(xx1, min=x1[i]) yy1 = torch.clamp(yy1, min=y1[i]) xx2 = torch.clamp(xx2, max=x2[i]) yy2 = torch.clamp(yy2, max=y2[i]) w.resize_as_(xx2) h.resize_as_(yy2) w = xx2 - xx1 h = yy2 - yy1 # check sizes of xx1 and xx2.. after each iteration w = torch.clamp(w, min=0.0) h = torch.clamp(h, min=0.0) inter = w*h # IoU = i / (area(a) + area(b) - i) rem_areas = torch.index_select(area, 0, idx) # load remaining areas) union = (rem_areas - inter) + area[i] IoU = inter/union # store result in iou # keep only elements with an IoU &lt;= overlap idx = idx[IoU.le(overlap)] return keep, count MultiBox 损失函数在layers/modules/multibox_loss.py 中定义了SSD模型的损失函数, 在SSD论文中, 损失函数具体定义如下: L_{loc}(x,l,g) = \sum_{i\in Pos}^N \sum_{m\in\{cx,cy,w,h\}} x_{ij}^k smooth_{L_1}(l_i^m - \hat g_j^m)L_{conf}(x,c) = -\sum_{i\in Pos}^N x_{ij}^p log(\hat c_i^p) - \sum_{i\in Neg} log(\hat c_i^0), 其中, \hat c_i^p = \frac{exp(c_i^p)}{\sum_p exp(c_i^p)}损失函数定义根据上面的公式, 我们可以定义下面的损失函数类, 该类继承了 nn.Module, 因此可以当做是一个 Module 用在训练函数中.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112# layers/modules/multibox_loss.pyclass MultiBoxLoss(nn.Module): # 计算目标: # 输出那些与真实框的iou大于一定阈值的框的下标. # 根据与真实框的偏移量输出localization目标 # 用难样例挖掘算法去除大量负样本(默认正负样本比例为1:3) # 目标损失: # L(x,c,l,g) = (Lconf(x,c) + αLloc(x,l,g)) / N # 参数: # c: 类别置信度(class confidences) # l: 预测的框(predicted boxes) # g: 真实框(ground truth boxes) # N: 匹配到的框的数量(number of matched default boxes) def __init__(self, num_classes, overlap_thresh, prior_for_matching, bkg_label, neg_mining, neg_pos, neg_overlap, encode_target, use_gpu=True): super(MultiBoxLoss, self).__init__() self.use_gpu = use_gpu self.num_classes= num_classes # 列表数 self.threshold = overlap_thresh # 交并比阈值, 0.5 self.background_label = bkg_label # 背景标签, 0 self.use_prior_for_matching = prior_for_matching # True 没卵用 self.do_neg_mining = neg_mining # True, 没卵用 self.negpos_ratio = neg_pos # 负样本和正样本的比例, 3:1 self.neg_overlap = neg_overlap # 0.5 判定负样本的阈值. self.encode_target = encode_target # False 没卵用 self.variance = cfg["variance"] def forward(self, predictions, targets): loc_data, conf_data, priors = predictions # loc_data: [batch_size, 8732, 4] # conf_data: [batch_size, 8732, 21] # priors: [8732, 4] default box 对于任意的图片, 都是相同的, 因此无需带有 batch 维度 num = loc_data.size(0) # num = batch_size priors = priors[:loc_data.size(1), :] # loc_data.size(1) = 8732, 因此 priors 维持不变 num_priors = (priors.size(0)) # num_priors = 8732 num_classes = self.num_classes # num_classes = 21 (默认为voc数据集) # 将priors(default boxes)和ground truth boxes匹配 loc_t = torch.Tensor(num, num_priors, 4) # shape:[batch_size, 8732, 4] conf_t = torch.LongTensor(num, num_priors) # shape:[batch_size, 8732] for idx in range(num): # targets是列表, 列表的长度为batch_size, 列表中每个元素为一个 tensor, # 其 shape 为 [num_objs, 5], 其中 num_objs 为当前图片中物体的数量, 第二维前4个元素为边框坐标, 最后一个元素为类别编号(1~20) truths = targets[idx][:, :-1].data # [num_objs, 4] labels = targets[idx][:, -1].data # [num_objs] 使用的是 -1, 而不是 -1:, 因此, 返回的维度变少了 defaults = priors.data # [8732, 4] # from ..box_utils import match # 关键函数, 实现候选框与真实框之间的匹配, 注意是候选框而不是预测结果框! 这个函数实现较为复杂, 会在后面着重讲解 match(self.threshold, truths, defaults, self.variance, labels, loc_t, conf_t, idx) # 注意! 要清楚 Python 中的参数传递机制, 此处在函数内部会改变 loc_t, conf_t 的值, 关于 match 的详细讲解可以看后面的代码解析 if self.use_gpu: loc_t = loc_t.cuda() conf_t = conf_t.cuda() # 用Variable封装loc_t, 新版本的 PyTorch 无需这么做, 只需要将 requires_grad 属性设置为 True 就行了 loc_t = Variable(loc_t, requires_grad=False) conf_t = Variable(conf_t, requires_grad=False) pos = conf_t &gt; 0 # 筛选出 &gt;0 的box下标(大部分都是=0的) num_pos = pos.sum(dim=1, keepdim=True) # 求和, 取得满足条件的box的数量, [batch_size, num_gt_threshold] # 位置(localization)损失函数, 使用 Smooth L1 函数求损失 # loc_data:[batch, num_priors, 4] # pos: [batch, num_priors] # pos_idx: [batch, num_priors, 4], 复制下标成坐标格式, 以便获取坐标值 pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data) loc_p = loc_data[pos_idx].view(-1, 4)# 获取预测结果值 loc_t = loc_t[pos_idx].view(-1, 4) # 获取gt值 loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False) # 计算损失 # 计算最大的置信度, 以进行难负样本挖掘 # conf_data: [batch, num_priors, num_classes] # batch_conf: [batch, num_priors, num_classes] batch_conf = conf_data.view(-1, self.num_classes) # reshape # conf_t: [batch, num_priors] # loss_c: [batch*num_priors, 1], 计算每个priorbox预测后的损失 loss_c = log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1,1)) # 难负样本挖掘, 按照loss进行排序, 取loss最大的负样本参与更新 loss_c[pos.view(-1, 1)] = 0 # 将所有的pos下标的box的loss置为0(pos指示的是正样本的下标) # 将 loss_c 的shape 从 [batch*num_priors, 1] 转换成 [batch, num_priors] loss_c = loss_c.view(num, -1) # reshape # 进行降序排序, 并获取到排序的下标 _, loss_idx = loss_c.sort(1, descending=True) # 将下标进行升序排序, 并获取到下标的下标 _, idx_rank = loss_idx.sort(1) # num_pos: [batch, 1], 统计每个样本中的obj个数 num_pos = pos.long().sum(1, keepdim=True) # 根据obj的个数, 确定负样本的个数(正样本的3倍) num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1) # 获取到负样本的下标 neg = idx_rank &lt; num_neg.expand_as(idx_rank) # 计算包括正样本和负样本的置信度损失 # pos: [batch, num_priors] # pos_idx: [batch, num_priors, num_classes] pos_idx = pos.unsqueeze(2).expand_as(conf_data) # neg: [batch, num_priors] # neg_idx: [batch, num_priors, num_classes] neg_idx = neg.unsqueeze(2).expand_as(conf_data) # 按照pos_idx和neg_idx指示的下标筛选参与计算损失的预测数据 conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes) # 按照pos_idx和neg_idx筛选目标数据 targets_weighted = conf_t[(pos+neg).gt(0)] # 计算二者的交叉熵 loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False) # 将损失函数归一化后返回 N = num_pos.data.sum() loss_l = loss_l / N loss_c = loss_c / N return loss_l, loss_c GT box 与default box 的匹配在上面的代码中, 有一个很重要的函数, 即 match() 函数, 因为我们知道, 当根据特征图谱求出这些 prior box(default box, 8732个)以后, 我们仅仅知道这些 box 的 scale 和 aspect_ratios 信息, 但是如果要计算损失函数, 我们就必须知道与每个 prior box 相对应的 ground truth box 是哪一个, 因此, 我们需要根据交并比来求得这些 box 之间的匹配关系. 匹配算法的核心思想如下: 首先将找到与每个 gtbox 交并比最高的 defaultbox, 记录其下标 然后找到与每个 defaultbox 交并比最高的 gtbox. 注意, 这两步不是一个相互的过程, 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有的priorbox都与G匹配. 为了防止上面的情况, 我们将那些对于gtbox来说, 交并比最高的priorbox, 强制进行互相匹配, 即令 best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环. 根据下标获取每个priorbox对应的gtbox的坐标, 然后对坐标进行相应编码, 并存储起来, 同时将gt类别也存储起来, 到此, 匹配完成. 根据上面的求解思想, 我们可以实现相应的匹配代码, 主要用到了以下几个函数: point_form(boxes): 将 boxes 的坐标信息转换成左上角和右下角的形式 intersect(box_a, box_b): 返回 box_a 与 box_b 集合中元素的交集 jaccard(box_a, box_b): 返回 box_a 与 box_b 集合中元素的交并比 encode(matched, priors, variances): 将 box 信息编码成小数形式, 方便网络训练 match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx): 匹配算法, 通过调用上述函数实现匹配功能 完整代码及解析如下所示(位于 ./layers/box_utils.py 文件中):123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103# ./layers/box_utils.pydef point_form(boxes): # 将(cx, cy, w, h) 形式的box坐标转换成 (xmin, ymin, xmax, ymax) 形式 return torch.cat( (boxes[:2] - boxes[2:]/2), # xmin, ymin (boxes[:2] + boxes[2:]/2), 1) # xmax, ymaxdef intersect(box_a, box_b): # box_a: (truths), (tensor:[num_obj, 4]) # box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4]) # return: (tensor:[num_obj, num_priors]) box_a 与 box_b 两个集合中任意两个 box 的交集, 其中res[i][j]代表box_a中第i个box与box_b中第j个box的交集.(非对称矩阵) # 思路: 先将两个box的维度扩展至相同维度: [num_obj, num_priors, 4], 然后计算面积的交集 # 两个box的交集可以看成是一个新的box, 该box的左上角坐标是box_a和box_b左上角坐标的较大值, 右下角坐标是box_a和box_b的右下角坐标的较小值 A = box_a.size(0) B = box_b.size(0) # box_a 左上角/右下角坐标 expand以后, 维度会变成(A,B,2), 其中, 具体可看 expand 的相关原理. box_b也是同理, 这样做是为了得到a中某个box与b中某个box的左上角(min_xy)的较大者(max) # unsqueeze 为增加维度的数量, expand 为扩展维度的大小 min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A,B,2), box_b[:, :2].unsqueeze(0).expand(A,B,2)) # 在box_a的 A 和 2 之间增加一个维度, 并将维度扩展到 B. box_b 同理 # 求右下角(max_xy)的较小者(min) max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A,B,2), box_b[:, 2:].unsqueeze(0).expand(A,B,2)) inter = torch.clamp((max_xy, min_xy), min=0) # 右下角减去左上角, 如果为负值, 说明没有交集, 置为0 return inter[:, :, 0] * inter[:, :, 0] # 高×宽, 返回交集的面积, shape 刚好为 [A, B]def jaccard(box_a, box_b): # A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B) # box_a: (truths), (tensor:[num_obj, 4]) # box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4]) # return: (tensor:[num_obj, num_priors]), 代表了 box_a 和 box_b 两个集合中任意两个 box之间的交并比 inter = intersect(box_a, box_b) # 求任意两个box的交集面积, shape为[A, B], 即[num_obj, num_priors] area_a = ((box_a[:,2]-box_a[:,0]) * (box_a[:,3]-box_a[:,1])).unsqueeze(1).expand_as(inter) # [A,B] area_b = ((box_b[:,2]-box_b[:,0]) * (box_b[:,3]-box_b[:,1])).unsqueeze(0).expand_as(inter) # [A,B], 这里会将A中的元素复制B次 union = area_a + area_b - inter return inter / union # [A, B], 返回任意两个box之间的交并比, res[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.def encode(matched, priors, variances): # 对边框坐标进行编码, 需要宽度方差和高度方差两个参数, 具体公式可以参见原文公式(2) # matched: [num_priors,4] 存储的是与priorbox匹配的gtbox的坐标. 形式为(xmin, ymin, xmax, ymax) # priors: [num_priors, 4] 存储的是priorbox的坐标. 形式为(cx, cy, w, h) # return : encoded boxes: [num_priors, 4] g_cxy = (matched[:, :2] + matched[:, 2:])/2 - priors[:, :2] # 用互相匹配的gtbox的中心坐标减去priorbox的中心坐标, 获得中心坐标的偏移量 g_cxy /= (variances[0]*priors[:, 2:]) # 令中心坐标分别除以 d_i^w 和 d_i^h, 正如原文公式所示 #variances[0]为0.1, 令其分别乘以w和h, 得到d_i^w 和 d_i^h g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:] # 令互相匹配的gtbox的宽高除以priorbox的宽高. g_wh = torch.log(g_wh) / variances[1] # 这里这个variances[1]=0.2 不太懂是为什么. return torch.cat([g_cxy, g_wh], 1) # 将编码后的中心坐标和宽高``连接起来, 返回 [num_priors, 4]def match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx): # threshold: (float) 确定是否匹配的交并比阈值 # truths: (tensor: [num_obj, 4]) 存储真实 box 的边框坐标 # priors: (tensor: [num_priors, 4], 即[8732, 4]), 存储推荐框的坐标, 注意, 此时的框是 default box, 而不是 SSD 网络预测出来的框的坐标, 预测的结果存储在 loc_data中, 其 shape 为[num_obj, 8732, 4]. # variances: cfg['variance'], [0.1, 0.2], 用于将坐标转换成方便训练的形式(参考RCNN系列对边框坐标的处理) # labels: (tensor: [num_obj]), 代表了每个真实 box 对应的类别的编号 # loc_t: (tensor: [batches, 8732, 4]), # conf_t: (tensor: [batches, 8732]), # idx: batches 中图片的序号, 标识当前正在处理的 image 在 batches 中的序号 overlaps = jaccard(truths, point_form(priors)) # [A, B], 返回任意两个box之间的交并比, overlaps[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比. # 二部图匹配(Bipartite Matching) # [num_objs,1], 得到对于每个 gt box 来说的匹配度最高的 prior box, 前者存储交并比, 后者存储prior box在num_priors中的位置 best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True) # keepdim=True, 因此shape为[num_objs,1] # [1, num_priors], 即[1,8732], 同理, 得到对于每个 prior box 来说的匹配度最高的 gt box best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True) best_prior_idx.squeeze_(1) # 上面特意保留了维度(keepdim=True), 这里又都把维度 squeeze/reduce 了, 实际上只需用默认的 keepdim=False 就可以自动 squeeze/reduce 维度. best_prior_overlap.squeeze_(1) best_truth_idx.squeeze_(0) best_truth_overlap.squeeze_(0) best_truth_overlap.index_fill_(0, best_prior_idx, 2) # 维度压缩后变为[num_priors], best_prior_idx 维度为[num_objs], # 该语句会将与gt box匹配度最好的prior box 的交并比置为 2, 确保其最大, 以免防止某些 gtbox 没有匹配的 priorbox. # 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比 # 最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有 # 的priorbox都与G匹配, 为了防止这种情况, 我们将那些对gtbox来说, 具有最高交并比的priorbox, # 强制进行互相匹配, 即令best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环 # 注意!!: 因为 gt box 的数量要远远少于 prior box 的数量, 因此, 同一个 gt box 会与多个 prior box 匹配. for j in range(best_prior_idx.size(0)): # range:0~num_obj-1 best_truth_idx[best_prior_idx[j]] = j # best_prior_idx[j] 代表与box_a的第j个box交并比最高的 prior box 的下标, 将与该 gtbox # 匹配度最好的 prior box 的下标改为j, 由此,完成了该 gtbox 与第j个 prior box 的匹配. # 这里的循环只会进行num_obj次, 剩余的匹配为 best_truth_idx 中原本的值. # 这里处理的情况是, priorbox中第i个box与gtbox中第k个box的交并比最高, # 即 best_truth_idx[i]= k # 但是对于best_prior_idx[k]来说, 它却与priorbox的第l个box有着最高的交并比, # 即best_prior_idx[k]=l # 而对于gtbox的另一个边框gtbox[j]来说, 它与priorbox[i]的交并比最大, # 即但是对于best_prior_idx[j] = i. # 那么, 此时, 我们就应该将best_truth_idx[i]= k 修改成 best_truth_idx[i]= j. # 即令 priorbox[i] 与 gtbox[j]对应. # 这样做的原因: 防止某个gtbox没有匹配的 prior box. mathes = truths[best_truth_idx] # truths 的shape 为[num_objs, 4], 而best_truth_idx是一个指示下标的列表, 列表长度为 8732, # 列表中的下标范围为0~num_objs-1, 代表的是与每个priorbox匹配的gtbox的下标 # 上面的表达式会返回一个shape为 [num_priors, 4], 即 [8732, 4] 的tensor, 代表的就是与每个priorbox匹配的gtbox的坐标值. conf = labels[best_truth_idx]+1 # 与上面的语句道理差不多, 这里得到的是每个prior box匹配的类别编号, shape 为[8732] conf[best_truth_overlap &lt; threshold] = 0 # 将与gtbox的交并比小于阈值的置为0 , 即认为是非物体框 loc = encode(matches, priors, variances) # 返回编码后的中心坐标和宽高. loc_t[idx] = loc # 设置第idx张图片的gt编码坐标信息 conf_t[idx] = conf # 设置第idx张图片的编号信息.(大于0即为物体编号, 认为有物体, 小于0认为是背景) 模型训练在定义了模型结构和相应的随时函数以后, 接下来就是训练阶段, 训练代码位于train.py文件中, 下面对该文件代码进行解读: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131# train.pydef str2bool(v): return v.lower() in ("yes", "true", "t", 1)import argparseparser = argparse.ArgumentParser(description="Single Shot MultiBox Detection")#...parser.add_argument("--cuda", default=True, type=str2bool, help="Use CUDA to train model")#...args = parser.parse_args()if torch.cuda.is_available(): if args.cuda: torch.set_default_tensor_type("torch.cuda.FloatTensor") else: torch.set_default_tensor_type("torch.FloatTensor")else: torch.set_default_tensor_type("torch.FloatTensor")def train():# 该文件中中主要的函数, 在main()中, 仅调用了该函数 if args.dataset == "COCO": if args.dataset_root == VOC_ROOT: # ... cfg = coco # coco位于config.py文件中 # COCODetection类 位于coco.py文件中 # SSDAugmentation类 位于utils/augmentations.py文件中 dataset = COCODetection(root=args.dataset_root, transform=SSDAugmentation(cfg["min_dim"], MEANS)) elif args.dataset == "VOC": if args.dataset_root == COCO_ROOT: #... cfg = voc dataset = VOCDetection(root=args.dataset_root, transform=SSDAugmentation(cfg["min_dim"], MEANS)) if args.visdom: import visdom viz = visdom.Visdom() # from ssd import build_ssd ssd_net = build_ssd("train", cfg["min_dim"], cfg["num_classes"]) net = ssd_net if args.cuda: net = torch.nn.DataParallel(ssd_net) # import torch.backends.cudnn as cudnn cudnn.benchmark = True # 大部分情况下, 这个flag可以让内置的cuDNN的auto-tuner自动寻找最适合当前配置的算法. if args.resume: # resume 类型为 str, 值为checkpoint state_dict file ssd_net.load_weights(args.resume) else: vgg_weights = torch.load(args.save_folder + args.basenet) ssd_net.load_state_dict(vgg_weights) if args.cuda: net = net.cuda() # 将所有的参数都移送到GPU内存中 if not args.resume: ssd_net.extras.apply(weights_init) # 本文件的函数: def weights_init(), 对网络参数执行Xavier初始化. ssd_net.loc.apply(weights_init) ssd_net.conf.apply(weights_init) # import torch.optim as optim optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay) # MultiBoxLoss类 位于layers/modules/multibox_loss.py文件中 criterion = MultiBoxLoss(cfg["num_classes"], 0.5, True, 0, True, 3, 0.5, False, args.cuda) net.train() # loss计数器 loc_loss = 0 conf_loss = 0 epoch = 0 epoch_size = len(dataset) // args.batch_size step_index = 0 if args.visdom: #... # import torch.utils.data as data data_loader = data.DataLoader(dataset, args.batch_size, num_workers=args.num_workers, shuffle=True, collate_fn=detection_collate, pin_memory=True) # 创建batch迭代器 batch_iterator = iter(data_loader) for iteration in range(args.start_iter, cfg["max_iter"]): if args.visdom and iteration != 0 and (iteration % epoch_size==0): update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None, "append", epoch_size) loc_loss = 0 conf_loss = 0 epoch += 1 if iteration in cfg["lr_steps"]: step_index += 1 # 每经过固定迭代次数, 就将lr衰减1/10 adjust_learning_rate(optimizer, args.gamma, step_index) # load train data images, targets = next(batch_iterator) if args.cuda: images = Variable(images.cuda()) targets = [Variable(ann.cuda(), volatile=True) for ann in targets] else: images = Variable(images) targets = [Variable(ann, valotile=True) for ann in targets] # forward t0 = time.time() out = net(images) # backprop optimizer.zero_grad() loss_l, loss_c = criterion(out, targets) # criterion = MultiBoxLoss(...) loss = loss_l + loss_c loss.backward() optimizer.step() t1 = time.time() loc_loss += loss_l.data[0] conf_loss += loss_c.data[0] if iteratioin % 10 == 0: # print(...) 每隔10次迭代就输出一次训练状态信息 if args.visdom: # update_vis_plot(...) if iteration != 0 and iteration % 5000 ==0: # save model 模型验证下面是模型验证的相关代码, 存在于./test.py文件中, 代码没有太多特殊的处理, 和./train.py文件略有相似. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def test_net(save_folder, net, cuda, testset, transform, thresh): filename = save_folder+"test1.txt" num_images = len(testset) for i in range(num_images): print("Testing image &#123;:d&#125;/&#123;:d&#125;...".format(i+1, num_images)) img = testset.pull_image(i) img_id, annotation = testset.pull_anno(i) x = torch.from_numpy(transform(img)[0]).permute(2,0,1) x = Variable(x.unsqueeze(0)) with open(filename, mode='a') as f: f.write('\n GROUND TRUTH FOR: ' + img_id + '\n') for box in annotation: f.write("label"+" || ".join(str(b) for b in box) + "\n") if cuda: x = x.cuda() y = net(x) detections = y.data # 将检测结果返回到图片上 scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]]) pred_num = 0 for i in range(detections.size(1)): j = 0 while detections[0, i, j, 0] &gt;= 0.6: if pred_num == 0: with open(filename, mode='a') as f: f.write('PREDICTIONS' + '\n') score = detections[0, i, j, 0] label_name = labelmap[i-1] pt = (detections[0, i, j, 1:]*scale).cpu().numpy() coords = (pt[0], pt[1], pt[2], pt[3]) pred_num += 1 with open(filename, mode='a') as f: f.write(str(pred_num)+' label:' + label_name + ' score' + str(socre) + ' '+ ' || '.join(str(c) for c in coords) + '\n') j += 1def test_voc(): # 加载网络 num_classes = len(VOC_CLASSES) + 1 # 1 为背景 net = build_ssd("test", 300, num_classes) net.load_state_dict(torch.load(args.trained_model)) net.eval() # 将网络只与eval状态, 主要会影响 dropout 和 BN 等网络层 print("Finished loading model!") # 加载数据 testset = VOCDetection(args.voc_root, [("2007", "test")], None, VOCAnnotationTransform()) if args.cuda: net = net.cuda() cudnn.benchmark = True # evaluation test_net(args.save_folder, net, args.cuda, testset, BaseTransform(net.size, (104, 117, 123)), thresh=args.visual_threshold)if __name__ == '__main__': test_voc() 其他辅助代码学习率衰减12345def adjust_learning_rate(optimizer, gamma, step): lr = args.lr * (gamma ** (step)) ## **为幂乘 for param_group in optimizer.param_groups: param_group["lr"] = lr Xavier 初始化123456789# tran.pydef xavier(param): init.xavier_uniform(param) # import torch.nn.init as initdef weights_init(m): if isinstance(m, nn.Conv2d): # 只对卷积层初始化 xavier(m.weight.data) m.bias.data.zero_()]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>源码实现</tag>
        <tag>SSD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Image Augmentation]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DataAugmentation%2F</url>
    <content type="text"><![CDATA[项目地址: https://github.com/aleju/imgaug 安装及卸载先安装相关依赖1pip install six numpy scipy Pillow matplotlib scikit-image opencv-python imageio Shapely 安装 imgaug1pip install imgaug 卸载1pip uninstall imgaug 使用方法]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSD 源码实现 (PyTorch)-数据处理]]></title>
    <url>%2Fz_post%2FPyTorch-SSD-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[源码文件 ./data/: coco.py, ./utils/: augmentations.py augmentations.py 文件概览众多周知, SSD 模型虽然比较简单, 但是也因此在精度上不够优秀, 故而需要借助较多的 Augmentation Trick 来提升模型的 mAP, 这部分代码位于 utils/augmentations.py 文件中, 由于这部分代码比较琐碎, 并且与 SSD 网络的关系并不大, 所以这里我们只给出一个整体概览, 不做过多注释, 有兴趣的朋友可以自己查看源码. 代码文件内容概览如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# ./utils/augmentations.pydef intersect(box_a, box_b): # ...def jaccard_numpy(box_a, box_b): # ...class Compose(object): # ...class Lambda(object): # ...class ConvertFromInts(object): # ...class SubtractMeans(object): # ...class ToAbsoluteCoords(object): # ...class ToPercentCoords(object): # ...class Resize(object): # ...class RandomSaturation(object): # ...class RandomHue(object): # ...class RandomLightingNoise(object): def __init__(self): # ... def __call__(self, image, boxes=None, labels=None): # ...class ConvertColor(object): def __init__(self, current="BGR", transform="HSV"): # ... def __call__(self, image, boxes=None, labels=None): # ...class RandomContrast(object): def __init__(self, lower=0.5, upper=1.5): # ... def __call__(self, image, boxes=None, labels=None): # ...class RandomBrightness(object): def __init__(self, delta=32): # ... def __call__(self, image, boxes=None, labels=None): # ...class ToCV2Image(object): # ...class ToTensor(object): # ...class RandomSampleCrop(object): def __init__(self): # ... def __call__(self, image, boxes=None, labels=None): # ...class Expand(object): def __init__(self, mean): # ... def __call__(self, image, boxes, labels): # ...class RandomMirror(object): def __call__(self, image, boxes, classes): # ...class SwapChannels(object): # ...class PhotometricDistort(object): # ...class SSDAugmentation(object): # ... class SSDAugmentation(object) 类上面文件中的函数之间的具有明确的调用关系和顺序, 因此我们将根据这些函数之间的逻辑关系来对该文件进行解析. 由于在模型训练创建数据集时, 调用了 class SSDAugmentation(object) 类, 因此, 我们首先对该类进行解析, 该类的定义如下: 1234567891011121314151617181920# ./utils/augmentation.pyclass SSDAugmentation(object): def __init__(self, size=300, mean=(104, 117, 123)): self.mean = mean self.size = size self.augment = Compose([ ConvertFromInts(), ToAbsoluteCoords(), PhotometricDistort(), Expand(self.mean), RandomSampleCrop(), RandomMirror(), ToPercentCoords(), Resize(self.size), SubtractMeans() ]) def __call__(self, img, boxes, labels): return self.augment(img, boxes, labels) class Compose(object) 类可以看到, 上面的类中主要包含三个成员, 一个是图片 BGR 的平均值 mean, 一个是图片的尺寸大小, 还有一个使用了本文件中的 class Compose(object), 并想该类传递了一个列表参数, 列表内的元素类型实现了 __call__ 方法的类, 也就是可以直接当做函数进行调用, 下面我们先来看一下 class Compose(object) 类的实现: 1234567891011121314# ./utils/augmentation.pyclass Compose(object): # 该类用于将多个 transformations 函数组合起来 def __init__(self, transforms): # transforms (list): 列表元素为各种 transformations self.transforms = transforms def __call__(self, img, boxes=None, labels=None): # 按照列表中顺序依次执行各种 transformations, 最终返回三个对象 for t in self.transforms: img, boxes, labels = t(img, boxes, labels) return img, boxes, labels 可以看到, Compose 的作用实际上就是按照顺序不断调用列表内的类函数来对数据进行 transformations, 下面我们就根据默认调用的函数顺序对文件中的其他类进行解析. class ConvertFromInts(object) 类该类将 image 数据中的像素类型从整形变成浮点型. 12345# ./utils/augmentation.pyclass ConvertFromInts(object): def __call__(self, image, boxes=None, labels=None): return image.astype(np.float32), boxes, labels class ToAbsoluteCoords(object) 类我们知道, 在进行目标检测时, 默认的生成的 boxes 的坐标值是按照图片的长宽比例来存储的, 这里为了方便我们后续的 transformations 的执行, 因此, 我们需要暂时将 boxes 的坐标切换成绝对值坐标. (事后会切换回来) 1234567891011# ./utils/augmentation.pyclass ToAbsoluteCoords(object): def __call__(self, image, boxes, labels): width, height, channels = image.shape boxes[:, 0] *= width boxes[:, 2] *= width boxes[:, 1] *= height boxes[:, 3] *= height return image, boxes, labels class PhotometricDistort(object) 类该类会随机选择一些图片执行扭曲操作(distort), 可以看做是一种数据增广技术, 代码如下: 12345678910111213141516171819202122232425262728# ./utils/augmentation.pyclass PhotometricDistort(object): def __init__(self): # pd 是一个列表, 其中存放的多个 transformations 类. # pd 将会作为 Compose 的参数使用 self.pd = [ RandomContrast(), ConvertColor(transform='HSV'), RandomSaturation(), RandomHue(), ConvertColor(current='HSV', transform='BGR'), # opencv RandomContrast() ] # 随机调节亮度 self.rand_brightness = RandomBrightness() # 随机增加噪声 self.rand_light_noise = RandomLightingNoise() def __call__(self, image, boxes, labels): im = image.copy() im, boxes, labels = self.rand_brightness(im, boxes, labels) if random.randint(2): # 随机执行下面两者操作之一 distort = Compose(self.pd[:-1]) else: distort = Compose(self.pd[1:]) im, boxes, labels = distort(im, boxes, labels) return self.rand_light_noise(im, boxes, labels) 上面的类中包含了许多数据增广的方法, 下面我们会逐个进行介绍. class RandomContrast(object) 类令图片中所有像素的值都乘以一个介于 [lower, upper] 之间的随机系数. 该操作会随机执行. 12345678910111213141516# ./utils/augmentation.pyclass RandomContrast(object): def __init__(self, lower=0.5, upper=1.5): self.lower = lower self.upper = upper assert self.upper &gt;= self.upper assert self.lower &gt;= 0 def __call__(self, image, boxes=None, labels=None): # 随机执行 if random.randint(2): alpha = random.uniform(self.lower, self.upper) image *= alpha return image, boxes, labels class ConvertColor(object) 类123456789101112131415# ./utils/augmentation.pyclass ConvertColor(object): def __init__(self, current='BGR', transform='HSV'): self.current = current self.transform = transform def __call__(self, image, boxes=None, labels=None): if self.current == 'BGR' and self.transforms == 'HSV': image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) elif self.current == 'HSV' and self.transforms == 'BGR': image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR) else: raise NotImplementError return image, boxes, labels class RandomSaturation(object) 类随机的改变图片的饱和度, 会给图片中的绿色通道的值乘以一个 [lower, upper] 之间的随机值 12345678910111213# ./utils/augmentation.pyclass RandomSaturation(object): def __init__(self, lower=0.5, upper=1.5): self.lower = lower self.upper = upper assert self.upper &gt;= self.lower assert self.lower &gt;=0 def __call__(self, image, boxes=None, labels=None): if random.randint(2): image[:, :, 1] *= random.uniform(self.lower, self.upper) return image, boxes, labels class RandomHue(object) 类随机改变图片的色调, 对蓝色通道值进行修改. 12345678910111213# ./utils/augmentation.pyclass RandomHue(object): def __init__(self, delta=18.0): assert delta &gt;= 0.0 and delta &lt;= 360.0 self.delta = delta def __call__(self, image, boxes=None, labels=None): if random.randint(2): image[:, :, 0] += random.uniform(-self.delta, self.delta) image[:, :, 0][image[:, :, 0] &gt; 360.0] -= 360.0 image[:, :, 0][image[:, :, 0] &lt; 0.0] += 360.0 return image, boxes, labels class RandomBrightness(object) 类随机调节图片的亮度, 给 BGR 三通道随机加上或减去一个值. 12345678910111213# ./utils/augmentation.pyclass RandomBrightness(object): def __init__(self, delta=32): assert delta &gt;= 0.0 assert delta &lt;= 255.0 self.delta = delta def __call__(self, image, boxes=None, labels=None): if random.randint(2): delta = random.uniform(-self.delta, self.delta) image += delta return image, boxes, labels class RandomLightingNoise(object) 类该类会随机给图片增加噪声, 随机调换 BGR 三通道的顺序. 在该类的使用了 class SwapChannels(object) 类来辅助完成目的功能, 代码会在下面一并给出: 1234567891011121314151617181920212223# ./utils/augmentation.pyclass RandomLightingNoise(object): def __init__(self): self.perms = ( (0,1,2), (0,2,1), (1,0,2), (1,2,0), (2,0,1), (2,1,0) ) def __call__(self, image, boxes=None, labels=None): if random.randint(2): swap = random.randint(len(self.perms)) shuffle = SwapChannels(swap) image = shuffle(image) return image, boxes, labelsclass SwapChannels(object): def __init__(self, swaps): self.swaps = swaps def __call__(self, image): image = image[:, :, self.swaps] return image, boxes, labels class Expand(object)该操作将创建一个数倍于原图的画板, 将图片随机放置在画板中的某部分, 其他部分的像素值权值填充成参数 mean 的值. 1# ./utils/augmentation.py class RandomSampleCrop(object)对图片进行随机裁剪 1# ./utils/augmentation.py class RandomMirror(object)将图片横向反转(就向镜子的功能一样) 1# ./utils/augmentation.py class ToPercentCoords(object)将当前 numpy 数组内的图片的真实坐标转换成百分比坐标(相对于图片的尺寸而言) 1# ./utils/augmentation.py class Resize(object)调用 cv2.resize() 函数将图片的大小进行缩放 1# ./utils/augmentation.py class SubtractMeans(object)将图片中的像素值减去给定的平均值参数 meand 1# ./utils/augmentation.py]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>源码实现</tag>
        <tag>SSD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法经典题型整理]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-%E7%AE%97%E6%B3%95%E7%BB%8F%E5%85%B8%E9%A2%98%E5%9E%8B%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[LeetCode 算法题(Easy)LeetCode 算法题(Medium)LeetCode 算法题(Hard)剑指 offer 背包问题01 背包完全背包多重背包最长公共子串题目地址 题目描述对于两个字符串, 请设计一个时间复杂度为 $O(mn)$ 的算法(这里的 $m$ 和 $n$ 为两串的长度), 求出两串的最长公共子串的长度。这里的最长公共子串的定义为两个序列 U1,U2,..Un 和 V1,V2,...Vn, 其中 Ui + 1 == Ui+1 , Vi + 1 == Vi+1, 同时 Ui == Vi. 给定两个字符串 A 和 B, 同时给定两串的长度 $n$ 和 $m$. 解法一: 暴力时间复杂度: $O(mnl)$, $l$ 为公共子串的长度空间复杂度: $O(1)$ 以一个字符串中的每一个字符作为公共子串的起始字符, 在另一个字符串中查找以该字符为起始的公共子串, 每一个字符的查找复杂度为 $O(nl)$, 共有 $m$ 个字符, 因此总的时间复杂度为 $O(mnl)$ 123456789101112131415161718192021class LongestSubstring &#123;public: int findLongest(string A, int n, string B, int m) &#123; int longest = 0; for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; int ii = i; int jj = j; int len = 0; while(ii&lt;n &amp;&amp; jj&lt;m &amp;&amp; A[ii] == B[jj])&#123; len++; ii++; jj++; &#125; longest = max(longest, len); &#125; &#125; return longest; &#125;&#125;; 解法二: 动态规划时间复杂度: $O(mn)$, 两个 for 循环, 内部复杂度为 $O(1)$.空间复杂度: $O(mn)$, 需要额外申请 $O(mn)$ 大小的矩阵空间 我们申请一个 dp 矩阵, dp[i][j] 代表以 A[i] 和 B[j] 字符为结尾的公共子串的长度, 那么, 就可以分为如下几种情况: s[i]!=s[j]: 将 dp[i][j] 置为 0 s[i]=s[j]: 令 dp[i][j] = dp[i-1][j-1]+1, 要注意越界保护, 即如果 i=0, 或者j=0, 我们就直接令 dp[i][j]=1 在进行上面判断的同时, 每更新一次 dp[i][j], 就更新 longest 的值. 12345678910111213141516171819class LongestSubstring &#123;public: int findLongest(string A, int n, string B, int m) &#123; int longest = 0; vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(m, 0)); for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; if(A[i] == B[j])&#123; if(i&gt;0 &amp;&amp; j&gt;0) dp[i][j] = dp[i-1][j-1]+1; else dp[i][j] = 1; longest = max(longest, dp[i][j]); &#125;// dp 数组默认元素为0, 因此不用显式在 else 中赋值0 &#125; &#125; return longest; &#125;&#125;; 解法三: 优化的动态规划时间复杂度: $O(mn)$, 两个 for 循环, 内部复杂度为 $O(1)$.空间复杂度: $O(2m)$ 或者 $O(2n)$, 选择短的申请 dp 数组. 在解法二的 dp 数组更新公式中, 我们发现, dp[i][j] 只与它左上角的元素 dp[i-1][j-1] 有关, 因此, 我们可以只申请大小为 $2\times m$ 的动态数组即可, 只需每次将上一个数组的值更新为当前数组值, 而当前的数组可以作为未使用的数组来更新公共子串长度. 123456789101112131415161718192021class LongestSubstring &#123;public: int findLongest(string A, int n, string B, int m) &#123; int longest = 0; vector&lt;vector&lt;int&gt;&gt; dp(2, vector&lt;int&gt;(m, 0)); for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; if(A[i] == B[j])&#123; if(j&gt;0) dp[1][j] = dp[0][j-1]+1; else dp[1][j] = 1; longest = max(longest, dp[1][j]); &#125;else dp[1][j]=0;// 此时需要显式在 else 中赋值0, 确保不相等时长度为0 &#125; dp[0] = dp[1]; // 更新上一个数组的值为当前数组值 &#125; return longest; &#125;&#125;; 解法四: 再优化的动态规划时间复杂度: $O(mn)$, 填充 “dp数组”, 复杂度不变空间复杂度: $O(1)$, 利用一个变量就可以维护我们的 “dp数组” 从解法三中我们已经知道, dp[i][j] 的值只与 dp[i-1][j-1] 的值有关, 在解法二中, 我们是从左到右, 左上到下的维护 “dp数组”, 因此最少需要两行数据空间才能够维护, 如下图所示: 但是实际上, 我们 仅仅只需要当前元素的左上角元素就够了, 也就是说, 如果我们沿着对角线的顺序来填充 “dp数组”, 那么我们 只需要一个变量 就可以完成对整个数组的填充, 如下图所示: 1234567891011121314151617181920212223242526272829303132class LongestSubstring &#123;public: int findLongest(string A, int n, string B, int m) &#123; int longest = 0; int dp = 0; int i=0, j=0; while(true)&#123; int ii, jj; if(i&lt;n)&#123; //先计算以第一列的开头 ii=i++; jj=0; &#125;else&#123; // 再计算第一行的 ii=0; jj=++j; &#125; if(jj==m) break; // 当jj=m时, 说明已经遍历完, 程序终止 dp = 0; while(ii&lt;n &amp;&amp; jj&lt;m)&#123; // 沿着对角线填充"dp数组" if(A[ii] == B[jj])&#123; dp = dp+1; &#125;else dp = 0; longest = max(longest, dp); ii++; jj++; &#125; &#125; return longest; &#125;&#125;; 1234567891011121314151617181920212223242526272829303132# python 实现# -*- coding:utf-8 -*-class LongestSubstring: def findLongest(self, A, n, B, m): # write code here i = 0 j = 0 res = 0 while (i &lt; n or j &lt; m): dp = 0 if i &lt; n: ii = i jj = 0 i += 1 elif j &lt; m: ii = 0 jj = j j += 1 else: break while(ii &lt; n and jj &lt; m): if (A[ii] == B[jj]): dp = dp + 1 ii += 1 jj += 1 else: dp = 0 ii += 1 jj += 1 res = max(res, dp) return res 解法五: 后缀自动机利用后缀自动机可以实现 $O(n)$ 的空间和时间复杂度, 但是考虑到时间成本问题, 并没有对该解法进行详细解析.因为要彻底搞懂后缀自动机, 不仅仅要会解最长公共子串, 还应该熟悉其他的字符串题型如: 最小循环串. 最长公共子序列最长公共子串与最长公共子序列的区别: 前者要求字符连续, 后者字符只需保持相对位置一致即可. 题目链接 解法一: 动态规划时间复杂度: $O(mn)$空间复杂度: $O(mn)$ 我们令 dp[i][j] 代表字符串中 i 和 j 之前的最长公共子序列的长度(不包含 A[i] 和 B[j]), 则最终的结果会存在与 dp[n][m] 中. 1234567891011121314151617class LCS &#123;public: int findLCS(string A, int n, string B, int m) &#123; // write code here vector&lt;vector&lt;int&gt;&gt; dp(n+1, vector&lt;int&gt;(m+1, 0)); // dp[i][j] 代表的是i,j之前(不包括ij)的字符的最长公共子序列的长度 for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; if(A[i] == B[j]) dp[i+1][j+1] = dp[i][j]+1; else// 如果不相等, 则dp[i+1][j+1]的值取上边和左边的较大者 dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j]); &#125; &#125; return dp[n][m]; &#125;&#125;; 解法二: 优化的动态规划时间复杂度: $O(mn)$空间复杂度: $O(2m)$, 或$O(2n)$, 与最长公共子串思路一致 该解法与最长公共子串解法三思路一致, 代码如下: 12345678910111213141516class LCS &#123;public: int findLCS(string A, int n, string B, int m) &#123; vector&lt;vector&lt;int&gt;&gt; dp(2, vector&lt;int&gt;(m+1, 0)); for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; if(A[i] == B[j]) dp[1][j+1] = dp[0][j]+1; else// 如果不相等, 则dp[i+1][j+1]的值取上边和左边的较大者 dp[1][j+1] = max(dp[0][j+1], dp[1][j]); &#125; dp[0] = dp[1]; //将前一行数组的值更新为当前数组的值 &#125; return dp[1][m]; &#125;&#125;; 1234567891011121314151617181920# python 实现# -*- coding:utf-8 -*-class LCS: def findLCS(self, A, n, B, m): if m &gt; n: # 令申请的空间大小为 n, m 中的较小者 A, B = B, A n, m = m, n dp = [[0] * (m+1), [0] * (m+1)] res = 0 for i in range(n): for j in range(m): tmp_len = max([dp[0][j-1], dp[1][j-1], dp[0][j]]) if A[i] == B[j]: dp[1][j] = dp[0][j-1] + 1 else:# 取左方和上方的较大者 dp[1][j] = max(dp[1][j-1], dp[0][j]) res = max(res, dp[1][j]) dp[0] = dp[1][:] return res 由于最长子序列需要同时用到左上角, 左边, 上边三个元素的值, 因此无法用常数变量来维护, 最少需要两行元素才能维护, 故无法做到常数空间复杂度 字符串匹配算法题目链接找到子串在字符串中出现的位置 算法 预处理时间 匹配时间 暴力匹配法(朴素字符串匹配) 无预处理过程 $O((n-m+1)m)$ Rabin-Karp $O(m)$ $O((n-m+1)m$ Finite automaton(优先自动机) $O(mk)$ $O(n)$ Knuth-Morris-Pratt(KMP) $O(m)$ $O(n)$ 上表中, $n$ 是原始串(文本)的长度, $m$ 是子串的长度, $k$ 是字符集的大小. 暴力匹配法(朴素字符串匹配)时间复杂度: $O((n-m+1)\times m)$空间复杂度: $O(1)$ 子串在原始串中的可能起始位置为: 0, 1, 2, …, n-m, 因此共有 $n-m+1$ 种可能性, 我们对每种可能性都进行遍历判断是否为子串, 每次遍历的复杂度为子串的长度 $m$, 因此, 最终的时间复杂度为: $O((n-m+1)\times m$. 该解法没有使用额外的空间. 下图是朴素字符串匹配的下标改变过程: 12345678910111213141516class Solution &#123;public: int strStr(string str, string substr) &#123; if(str.empty() &amp;&amp; substr.empty()) return 0; int n = str.size(); int m = substr.size(); for(int i=0; i&lt;n-m+1; i++)&#123; // 起始位置为 0, 1, ..., n-m 供 n-m+1 种可能性 int p=i, q=0; while(str[p] == substr[q])&#123; // 对于每种可能性都一一判断 p++; q++; &#125; if(q==m) return i; &#125; return -1; &#125;&#125;; Rabin-KarpFinite automaton(优先自动机)Knuth-Morris-Pratt(KMP)时间复杂度: $O(m+n)$, $m$ 为求 next 数组的复杂度, $n$ 为遍历原始串的复杂度空间复杂度: $O(m)$, next 数组所占空间为子串的长度. 若只想看代码实现, 可以直接跳转到代码部分 在解法一当中, 每次失配时, 我们都是改变原始串(T)的下标 i, 这样复杂度肯定是最高的, 在 KMP 算法中, 我们通过改变子串(P)的下标 j 来降低复杂度, 首先来看两组 KMP 算法的下标 j 的跳跃示意图: 第一组: 第二组: 根据上面的示意图, 我们可以大致体会出 KMP 算法的思想所在, 具体来说就是, 当 T[i] 与 P[j] 失配时, 我们不改变 i 的指向, 而是令 j 指向之前的某一个位置 k, 继续判断 T[i] 与 P[k] 的值, 而这个位置 k, 必须满足性质: 字符串 P 中前面的 k 个字符(0~k-1)和后面的 k 个字符(j-k~j-1)必须相等, 也就是要满足下面的公式: P[0\sim k-1] == P[j-k\sim j-1]图片表示如下: 为什么可以直接移动到 k 位置而不需要检查 0~k-1 处的字符? 证明如下: 当 T[i]!=P[j] 时, 一定有 T[0~i-1]=P[0~j-1]又因为 P[0~k-1]=P[j-k~j-1], 故而一定有 P[0~k-1]=P[j-k~j-1]=T[j-k~j-1]. 下面, 我们就需要求得这些 k 的值, 并将其存储在 next 数组中, next 数组和长度和 P 相同, 并且其中的值只有 P 有关, 与 T 无关. 当我们求得 next 数组的值以后, 一旦 T[i] 与 P[j] 发生失配, 我们只需要令 j 跳到 k 处即可, 也就是 j=next[j]. 求取 next 数组的代码如下所示: 123456789101112131415class Solution &#123;private: void getNext(vector&lt;int&gt; &amp;next, string P)&#123; next[0] = -1; int k = -1; int j=0; while(j&lt;next.size()-1)&#123; if(k==-1 || P[j]==P[k])&#123; k++; j++; next[j] = k; // next[j+1] = next[j]+1 = k+1; //以上可省略成一句: next[++j]=++k; &#125;else k = next[k]; &#125; &#125; 我们来仔细分析一下改代码的含义, 首先, 当 j=0 时发生失配, 由于 j 之前再没有可使用的字符的, 因此我们令 next[j]=-1, 此时, 我们不应该挪动 j, 而是应该将 i 指向下一个字符.其次, 对于 j=1 时的情况, 我们只能将 j 跳到子串的最开始字符处, 因此, 当 j=1 时, 我们令 next[j]=0, 在代码中, 我们使用 k=-1 来代表 j=1 的, 这里 k 的值代表 next[j] 的值.首先, 假设我们已经得到了 next[0~j] 的值, 我们该如何求 next[j+1] 呢? 有下面两个情况:情况一: P[k]=P[j], 注意, 这里的 k=next[j], 因此就有 P[0~k-1] = P[j-k~j-1], 又因为 P[k]=P[j], 所以可以得到: P[0~k]=P[0~j], 所以我们可以得到 next[j+1] = k + 1, 在代码中, 我们令 k++; j++, 目的是为了满足 k=next[j]. 图示过程如下所示: 情况二: P[k]!=P[j] 此时我们无法得到 P[0~k]=P[0~j], 因此, 我们必须寻找 更短的 符合条件的 k 值, 因此, 我们令 k=next[k], 注意, 由于 k=next[j], 因此, 这里的赋值语句相当于 k=next[next[j]], 也就是说, 这里相当于是一个自我匹配的过程(令前缀和后缀匹配), 我们用已得到的 next 数组的部分值, 来得到最短的符合条件的 k 值. 如下图所示: 当得到 next 数组后, 我们就可以很容易的实现 KMP 的完整算法了, 注意这里有一个很容易错的点, .size 是无符号整数, 直接与负值比较或者会产生溢出(但如果参与计算后, 则会自动转换成整形, 因为常数默认是整形), 系统会判断-1比无符号的整数大!! 因此, 我们最好利用 int 型变量来持有其 size, 当需要动态的 size 时, 最好根据需要将其转换成 int 类型. 代码如下所示.1234567891011121314151617181920212223242526272829303132class Solution &#123;private: void getNext(vector&lt;int&gt; &amp;next, string &amp;substr)&#123; int m = substr.size(); next[0] = -1; int k = -1; int j=0; while(j&lt;m-1)&#123; if(k==-1 || substr[k]==substr[j]) next[++j]=++k;// 相当于: j++; k++; next[j] = k; else k = next[k]; &#125; &#125;public: int strStr(string str, string substr) &#123; int n=str.size(), m=substr.size(); if(m==0) return 0; if(n==0) return -1;//当 m!=0, 而 n=0时, 应该返回-1 vector&lt;int&gt; next(substr.size()); getNext(next, substr); int i=0, j=0; while(i&lt;n &amp;&amp; j&lt;m)&#123; if(j==-1 || str[i]==substr[j])&#123; i++; j++; &#125;else j = next[j]; &#125; if(j==m) return i-j; return -1; &#125;&#125;; 下面是 KMP 算法的 python 1234567891011121314151617181920212223242526# python 实现class Solution: def strStr(self, prostr: str, substr: str) -&gt; int: def get_next(substr): next_arr = [-1] * len(substr) k = -1 j = 0 while j &lt; len(substr) - 1: if k == -1 or substr[j] == substr[k]: j += 1 k += 1 next_arr[j] = k else: k = next_arr[k] return next_arr next_arr = get_next(substr) i = 0 j = 0 while(i &lt; len(prostr) and j &lt; len(substr)): if (j == -1 or prostr[i] == substr[j]): i += 1 j += 1 else: j = next_arr[j] return -1 if j &lt; len(substr) else i - j 排列算法题目连接: next_permutation, prev_permutation next_permutationpermutations: 不含有重复元素permutations II: 含有重复元素, 用 next_permutation 可以直接解决permutations sequence 快速找到第 $k$ 个排列 python 的排列函数:12import itertoolsreturn list(itertools.permutations(nums)) # itertools 返回的是迭代对象, 因此需要将其转换成list 问题给定一个排列 P, 求出其后(前)一个排列 P+1(P-1), 关于次知识点的算法题可见Permutations next_permutation首先要知道, 这里的 “上一个” 和 “下一个” 是按照字典序的定义进行排序的, 因此对于 “123” 或者 “abc” 这样的字符串, 正序排列就被认为是 最小的或者最前面的 的排列(如 “123”), 而逆序排列被认为 最大的或者最后面的 的排列. 从字典序的角度出发, 当用排列 P 求下一个排列 P+1 时, 我们需要找到 刚好比当前排列大一位 的下一个排列.因为我们已经知道逆序是最大的排列, 因此, 为了找到比当前排列刚好大一点的排列, 我们首先需要找到一个使排列为 非逆序 的元素, 因此, 我们从后往前找, 找到首个构成非逆序排列的元素, 即要满足 nums[i] &lt; nums[i+1] 的元素 nums[i].找到该元素后, 为了让新的排列只比当前排列大一位, 我们要将 i 之后的元素中大于 nums[i] 的所有元素中 最小的 那一个, 假设为 nums[j], 令 nums[j]与 nums[i] 位置互换, 注意, 如果不是最小的, 那么互换后一定会变得过大, 因为还存在介于二者之间的排列.当 nums[j] 与 nums[i] 位置互换后, 由于在 i 之后, j 之前(注意此时已经互换), 仍然 可能 存在比 nums[j] (因为互换了, 所以此时的 nums[j] 是较小的那个元素) 大的其他元素, 因此, 说明在新排列和旧排列之间还存在有其他的排列. 为了使新排列只比旧排列大一位, 我们需要将 [i+1, end] 之内的元素逆置, 逆置后排列刚好比当前的排列大一位. 因为 j 之后的元素都是比原来的 nums[j] 和 nums[i] 小的, j 之前的元素都不小于原来的 nums[j], 并且大于原来的 nums[i], 因此, 逆置后的排列一定是最小的那一种, 故而可以组成只比当前排列大一位的下一个排列, 代码实现可能的版本如下( “321” 的下一个排列是 “123”, 但是会返回 false): 123456789101112131415class Solution &#123;public: bool nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; // 当 i&gt;= 0 时, 说明可以找到组成非逆序的元素, 所以返回 ture, 当&lt;0时, 说明当前排列已经是逆序, 即最后的排列, 故返回 false &#125;&#125;; 注意: next_permutation() 函数接受的是迭代器参数, 所以上面的实现只是一种参考, 并非是 STL 源码实现 123456789101112131415# python 实现class Solution: def nextPermutation(self, nums: List[int]) -&gt; None: """ Do not return anything, modify nums in-place instead. """ n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &gt;= nums[i+1]): i -= 1 # 找到i if (i &gt;= 0): while (j &gt; i and nums[i] &gt;= nums[j]): j -= 1 # 找到 j nums[i], nums[j] = nums[j], nums[i] # 交换 nums[i+1:] = nums[i+1:][::-1] # 将 i 之后元素的进行逆置 return prev_permutation对于 prev_permutation() 函数的原理原始差不多的, 只不过我们需要找到的是 只比当前排列小一位的前一个排列, 代码示例如下: 1234567891011bool prevPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&lt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&lt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false;&#125; 123456789101112131415# python 实现class Solution: def prevPermutation(self, nums: List[int]) -&gt; None: """ Do not return anything, modify nums in-place instead. """ n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &lt;= nums[i+1]): i -= 1 # 找到i if (i &gt;= 0): while (j &gt; i and nums[i] &lt;= nums[j]): j -= 1 # 找到 j nums[i], nums[j] = nums[j], nums[i] # 交换 nums[i+1:] = nums[i+1:][::-1] # 将 i 之后元素的进行逆置 return permutation sequence给定 $n$, 则 [1, 2, ..., n] 可能的排列有 $n!$ 种, 要求你快速找到第 $k$ 个排列. 该题目用 next_permutatioin 或者 prev_permutation 求解时会严重超时. 下面给出正确思路 对于 [1,2,3,4]来说, 所有的排列可以分为下面 4 种情况: 1 + [2,3,4] 2 + [1,3,4] 3 + [1,2,4] 4 + [1,2,3] 因为, 我们可以利用 $k / (n-1)!$, 确定第一个数字的取值, 然后对于剩下的数字, 迭代的使用该方法确定, 知道确定了所有的 $n$ 个数字为止, 代码实现如下所示: 1234567891011121314import mathclass Solution: def getPermutation(self, n: int, k: int) -&gt; str: nums = list(range(1, n+1)) res = '' k = k - 1 while n &gt; 0: f = math.factorial(n - 1) index = k // f res += str(nums[index]) nums.pop(index) k = k - index * f n -= 1 return res 组合算法题目链接:Combinations: 给定 $n$ 和 $k$, 返回所有可能的 $k$ 元组Combinations Sum I:返回和为 target 的组合, 数列中的元素可以使用无限次Combinations Sum II: 返回和为 target 的组合, 数列中的元素可以只可以使用一次Combinations Sum III: 返回和为 target 的 k 元组, 只可以使用 1~9 的数字Combinations Sum IV: 返回和为 target 的所有可能情况的个数, 数列中的元素可以使用无限次 12import itertoolsitertools.combinations(nums, 2) # 从中选2个进行组合 CombinationsCombinations: 给定 $n$ 和 $k$, 返回所有可能的 $k$ 元组 解法一: 递归对于给定的 $n$ 和 $k$, 我们可以先确定一个数字, 该数字一定处于当前数列中的第 $k$ 个到最后一个中, 然后, 对于剩下的 $k-1$ 个数字, 我们可以在选定的数字前面的数列中进行选取, 此时就形成了一个新的给定 $i-1$, $k-1$ 的组合问题. 12345class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: if k == 0: return [[]] return [pre+[i] for i in range(k, n+1) for pre in self.combine(i-1, k-1)] 解法二: 迭代迭代的核心思想就是要控制 i 的范围, 使其刚好处在可以与现有 res 中元素形成组合, 有两种不同的实现角度(思路一致, 只不过一个是从前往后组合, 一个是从后往前组合) 12345678# 从前往后组合class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: res = [[]] for _ in range(k): res = [c + [i] for c in res for i in range(c[-1]+1 if c else 1, n+1)] return res# [[1,2],[1,3],[1,4],[2,3],[2,4],[3,4]] 1234567# 从后往前组合class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: res = [[]] for _ in range(k): res = [[i] +c for c in res for i in range(1, c[0] if c else n+1)] return res 解法三: 回溯12345678910111213class Solution: def combine(self, n: int, k: int) -&gt; List[List[int]]: def backtrack(nums, index, path, res, k): if len(path) == k: res.append(path) return for i in range(index, len(nums)): backtrack(nums, i+1, path+[nums[i]], res, k) nums = range(1, n+1) res = [] backtrack(nums, 0, [], res, k) return res Combinations Sum ICombinations Sum I:返回和为 target 的组合, 数列中的元素可以使用无限次, 数列中的数 全部是正数 如果有负数存在, 会有什么问题? 答: 会出现无限长的解, 例如: [-1, 1, -1, 1, …] 1234567Input: candidates = [2,3,5], target = 8,A solution set is:[ [2,2,2,2], [2,3,3], [3,5]] 解法一: 回溯下面使用了 sort() 进行排序 123456789101112131415class Solution: def combinationSum(self, candidates: List[int], target: int) -&gt; List[List[int]]: def backtrack(nums, target, index, path, res): if (target == 0): res.append(path) return for i in range(index, len(nums)): if (nums[i] &gt; target): break # 在这里就break的好处是后面的for循环可以不用再执行, 起到剪枝的效果 backtrack(nums, target - nums[i], i, path+[nums[i]], res) res = [] candidates.sort() backtrack(candidates, target, 0, [], res) return res 实际上可以不使用 sort, 此时注意当nums[i] &gt; target时, 我们不能直接break, 因为后面还存在其他可能的解, 因此, 需要用continue1234567891011121314class Solution: def combinationSum(self, candidates: List[int], target: int) -&gt; List[List[int]]: def backtrack(nums, target, index, path, res): if (target == 0): res.append(path) return for i in range(index, len(nums)): if (nums[i] &gt; target): continue backtrack(nums, target - nums[i], i, path+[nums[i]], res) res = [] backtrack(candidates, target, 0, [], res) return res Combination Sum IICombinations Sum II: 返回和为 target 的组合, 数列中的元素可以只可以使用一次 12345678Input: candidates = [10,1,2,7,6,1,5], target = 8,A solution set is:[ [1, 7], [1, 2, 5], [2, 6], [1, 1, 6]] 解法一: 回溯12345678910111213141516class Solution: def combinationSum2(self, candidates: List[int], target: int) -&gt; List[List[int]]: def back_track(nums, res, index, path, target): if (target == 0): #if len(res) == 0 or path not in res: res.append(path) return for i in range(index, len(nums)): if i != index and nums[i-1] == nums[i]: continue if nums[i] &gt; target: break back_track(nums, res, i+1, path+[nums[i]], target-nums[i]) res = [] back_track(sorted(candidates), res, 0, [], target) # 注意, 为了方便我们判断重复, 这里需要用排序的序列 return res Combination Sum IIICombinations Sum III: 返回和为 target 的 k 元组, 只可以使用 1~9 的数字 解法一: 回溯123456789101112131415class Solution: def combinationSum3(self, k: int, n: int) -&gt; List[List[int]]: def back_track(nums, res, index, path, k, target): if (k == 0): if (target == 0): res.append(path) return for i in range(index, len(nums)): back_track(nums, res, i+1, path+[nums[i]], k-1, target-nums[i]) nums = range(1, 10) res = [] back_track(nums, res, 0, [], k, n) return res Combinations Sum IVCombinations Sum IV: 返回和为 target 的所有可能情况的个数(需要用到排列, 该题认为 [1, 1, 2] 和 [2, 1, 1] 是不同的情况), 数列中的元素可以使用无限次 解法一: 回溯由于该题将 [1, 1, 2] 和 [2, 1, 1] 看做是不同的情况, 因此, 在组合之后, 还要对每种组合进行排列, 但是这样的复杂度非常高, 例如 [1,1,1,1,1,1,1,1,1,,1,1…, 5], 所以该方法会超时 解法二: 动态规划当我们求取某个值的可能组合数时, 我们可以利用前面已经求得的情况来简化. 如下所示 12345678910class Solution: def combinationSum4(self, nums: List[int], target: int) -&gt; int: # dp[i] 代表, target 为 i 的组合数目 nums, dp = sorted(nums), [0] + [0] * target for i in range(1, target+1): for num in nums: if num &gt; i: break if num == i: dp[i] += 1 if num &lt; i : dp[i] += dp[i - num] return dp[target] 回溯用回溯解决一系列问题: https://leetcode.com/problems/combination-sum/discuss/16502/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partitioning) 卡塔兰数定义卡特兰数又称卡塔兰数, 英文名Catalan number, 是组合数学中一个常出现在各种计数问题中出现的数列。以比利时的数学家欧仁·查理·卡塔兰 (1814–1894)的名字来命名, 其前几项为（从第零项开始） : 1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, 16796, 58786, 208012, 742900, 2674440, 9694845, 35357670, 129644790, 477638700, 1767263190, 6564120420, 24466267020, 91482563640, 343059613650, 1289904147324, 4861946401452, … 卡特兰数 $Cn$ 满足以下递推关系: $C_{n+1} = C_0 C_n + C_1 C_{n-1} + … + C_n C_0$ $(n-1)C_n = \frac{n}{2} (C_3C_{n-1} + C_4 C_{n-2} + C_5 C_{n-3} + … + C_{n-2}C_4 + C_{n-1} C_3)$ 其他符合卡特兰数的特征: 令 $h(0)=1, h(1)=1$, 卡特兰树满足递推式: $h(n)=h(0)\times h(n-1) + h(1)\times h(n-2) + … + h(n-1) \times h(0)$ 卡特兰数满足递推式: $h(n) = \frac{4n-2}{n+1} h(n-1)$, 写代码时多用: $h(n+1) = \frac{4n+2}{n+2} h(n)$ 卡特兰数的解为: $h(n) = \frac{1}{n+1} C_{2n}^{n}$ 卡特兰数的解为: $h(n) = C_{2n}^{n} - C_{2n}^{n-1}$ 常见题型0-1 类n 个 0 与 n 个 1 随机组合, 要求从左到右数时, 确保每一个数之前 0 的个数不少于 1 个个数. 实际题型举例: 括号化问题。一个合法的表达式由()包围, ()可以嵌套和连接, 如(())()也是合法 表达式；现在有 n 对(), 它们可以组成的合法表达式的个数为 矩阵连乘： P=a1×a2×a3×……×an, 依据乘法结合律, 不改变其顺序, 只用括号表示成对的乘积, 试问有几种括号化的方案 出栈次序问题. 一个栈(无穷大)的进栈序列为1,2,3,..n,有多少个不同的出栈序列 在图书馆一共 2n 个人在排队, n 个还《面试宝典》一书, n 个在借《面试宝典》一书, 图书馆此时没有了面试宝典了, 确保所有人都能借到书, 求他们排队的总数 2n 个人排队买票, 其中 n 个人持 50 元, n 个人持 100 元。每张票 50 元, 且一人只买一张票。初始时售票处没有零钱找零。请问这 2n 个人一共有多少种排队顺序, 不至于使售票处找不开钱 $n\times n$ 的方格地图中, 从一个角到另外一个角, 不跨越对角线的路径数 多边形类将多边行划分为三角形问题。将一个凸N+2多边形区域分成三角形区域的方法数?类似：一位大城市的律师在她住所以北n个街区和以东n个街区处工作。每天她走2n个街区去上班。如果她从不穿越（但可以碰到）从家到办公室的对角线, 那么有多少条可能的道路？类似：在圆上选择2n个点,将这些点成对连接起来使得所得到的n条线段不相交的方法数 二叉树类给顶节点组成二叉树的问题。给定N个节点, 能构成多少种不同的二叉树 不同的二叉搜索树: https://leetcode-cn.com/problems/unique-binary-search-trees/]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[洗牌的正确姿势-Knuth shuffle算法]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-KnuthShuffle%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[注: 在 LeetCode 上, 将该解法称为 Fisher-Yates 算法. 怎样用计算机模拟出 足够随机 的洗牌结果, 看似很简单, 但其实它比给一副乱糟糟的牌排好序可能还更难一些. 洗牌问题的描述很简单:即如何通过打乱顺序, 让一副扑克牌变成随机的排列, 而且每一种可能的排列有相同机会出现. 关键点在于 “相同机会” , 即各种随机排列是等可能的. 下面先简单介绍一个常见的错误做法, 然后看看如何改进变成Knuth 洗牌算法. 先看看一个很直接的做法(一副牌在这里用一个数组表示):对数组从头到尾扫描一遍, 扫描过程中, 每次都从整个数组随机选一个元素, 跟当前扫描到的元素交换位置. 也就是, 先拿起第一张牌, 把它跟从整副牌里随机挑出的另一张牌(把它叫做随机牌)交换位置(随机牌也可能是第一张牌自己, 这个时候就相当于不交换位置); 接着拿起第二张牌, 也把它跟随机选出的另一张牌交换位置; 一直重复直到把最后一张牌跟随机牌交换位置. 代码实现如下:12345vector&lt;int&gt; sv(v); // v 为给定的待打乱的数组for(int i=0; i&lt;sv.size(); i++)&#123; int j = rand() % sv.size(); //这里生成的 j 位于 0 ~ size()-1 之间 swap(sv[i], sv[j]);&#125; 这样随机交换之后, 每种排列出现的可能性会是等概率的吗? 假设我们的数组元素有三个: {A, B, C}, 那么最终的所有的可能排列方式就有六种, 按照要求, 这六种排列方式的出现概率应该是 相等的. 但是, 如果按照上面的方法, 最终的可能分支数为: $3\times 3 \times 3 = 27$ 种, 无法整除 6, 所以各个排列的出现概率 绝对不可能是等概率的. 分支情况如下图所示: 可以看到, 最后产生的27个结果里面, {A, B, C}, {C, A, B}, {C, B, A}都出现了4次, 而{A, C, B}, {B, A, C}, {B, C, A}都出现了5次. 也就是说有些排序出现的可能性是4/27, 有些却是5/27. 而且, 随着牌数目的增加, 这个概率的不均衡会更加严重. 从上面的分析可以看出, 要让结果够公平, 一个必要条件就是产生的分支是6的整数倍, 也就是 $N!$ 的整数倍, 为此, 我们就来介绍 Knuth Shuffle 算法. 在上述方法的基础上, 做一处修改, 就能剪去一些分支, 让分支数是N!的整数倍. 这就是Knuth洗牌算法. 代码实现如下:12345vector&lt;int&gt; sv(v); // v 为给定的待打乱的数组for(int i=0; i&lt;sv.size(); i++)&#123; int j = i + rand() % (sv.size()-i); //这里生成的 j 只可能在 i 之后 swap(sv[i], sv[j]);&#125; 此时的分支情况如下所示: 最终得到的结果只有6个, 正好是三张牌的所有6种排列结果, 每种出现一次. 所以, Knuth洗牌算法是公平的. (对于更多的情况, 也是公平的, 证明起来比较麻烦, 这里就不放严谨的证明过程了) 做个实验验证一下, 把牌数增加到5张{A,B,C,D,E},分别用以上两种洗牌算法做50w次使用, 看5张牌的所有120种排列出现的次数是否足够接近. 第一种算法的洗牌结果中, 各种排序出现次数在2500~7500之间有很大波动, 如下所示: 而在Knuth洗牌算法的结果中, 每种排序出现的次数都在4000左右, 符合计算结果(50w/120=4166.7): 参考资料:https://yjk94.wordpress.com/2017/03/17/%E6%B4%97%E7%89%8C%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF-knuth-shuffle%E7%AE%97%E6%B3%95/]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-模型定义(modeling)之辅助文件解析]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-modeling-other%2F</url>
    <content type="text"><![CDATA[balanced_positive_negative_sampler.py在 rpn/loss.py 文件中的 class RPNLossComputation(object) 类使用了 class BalancedPositiveNegativeSampler(object) 类的实例对象作为函数参数, 下面我们就来看看该类的具体实现: 123456789101112131415161718192021222324252627# ../maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.pyclass BalancedPositiveNegativeSampler(object): # 该类用于生成采样 batch, 使得 batch 中的正负样本比例维持一个固定的数 def __init__(self, batch_size_per_image, positive_fraction): # batch_size_per_image(int): 每张图谱包含的样本个数 # positive_fraction: 每个 batch 中包含的正样本个数 self.batch_size_per_image = batch_size_per_image self.positive_fraction = positive_fraction def __call__(self, matched_idxs): # matched idxs: 一个元素类型为 tensor 的列表, # tensor 包含值 -1, 0, 1. 每个 tensor 都对应这一个具体的图片 # -1 代表忽略图片中的该样本, 0 代表该样本为负, 1 代表该样本为正 # 返回值: # pos_idx (list[tensor]) # neg_idx (list[tensor]) # 每张图片都返回两个二值掩膜列表, 其中一个指示了哪些正样本被采样, 另一个指示了负样本 pos_idx = [] neg_idx = [] for matched_idxs_per_image in matched_idxs: box_coder.py在 ./maskrcnn_benchmark/modeling/rpn/rpn.py 文件中, 使用了下面的语句创建 class BoxCoder(object) 实例:1rpn_box_coder = BoxCoder(weights=(1.0, 1.0, 1.0, 1.0)) 这个类位于 ./maskrcnn_benchmark/modeling/box_coder.py 文件中, 在对这个类的定义展开详细解析前, 我们首先对 R-CNN 中 bounding box 的回归任务的坐标编码方式进行介绍. 假设我们具有一个候选区域框, 用 $P=(P_x, P_y, P_w, P_h)$ 表示, 它对应的真实框用 $G=(G_x, G_y, G_w, G_h)$ 表示, 那么, 我们的目标是希望回归器能够学习到一个从 $P$ 到 $G$ 的转化(transformation), 假设此时模型从 $P$ 中预测得到的框为 $\hat G = (\hat G_x, \hat G_y, \hat G_h, \hat G_w)$, 那么我们可以定义出如下的从 $P$ 到 $\hat G$ 的转化: \hat G_x = P_w d_x(P) + P_x\hat G_y = P_h d_y(P) + P_y\hat G_w = P_w exp(d_w(P))\hat G_h = P_h exp(d_h(P))上式中的 $d_x(P), d_y(P), d_w(P), d_h(P)$ 就是我们要学习的参数, 那么我们的学习目标就是使得这些参数可以满足 $\hat G = G$, 也就是说, 我们的学习目标就是令参数 $d_x(P), d_y(P), d_w(P), d_h(P)$ 无限近似于下面的 $(t_x, t_y, t_w, t_h)$: t_x = (G_x - P_x) / P_wt_y = (G_y - P_y) / P_ht_w = log(G_w / P_w)t_h = log(G_h / P_h)BoxCoder 类的代码解析如下所示:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# ./maskrcnn_benchmark/modeling/box_coder.pyclass BoxCoder(object): # 这个类负责将一系列的 bounding boxes 编码, 使之可以被用于训练对应的回归器 def __init__(self, weights, bbox_xform_clip=math.log(1000. / 16)): # weights (4-element tuple) # bbox_xform_clip (float): 用于对 dw 和 dh 剪枝 # 将参数置为成员变量 self.weights = weights self.bbox_xform_clip = bbox_xform_clip def encode(self, reference_boxes, proposals): # 根据给定的 reference_boxes 对一系列的 proposals 进行编码 # reference_boxes(Tensor) # proposals(Tensor): 待编码的 boxes TO_REMOVE = 1 # 获取宽度(x2-x1) ex_widths = proposals[:, 2] - proposals[:, 0] + TO_REMOVE # 获取高度(y2-y1) ex_heights = proposals[:, 3] - proposals[:, 1] + TO_REMOVE # 获取中心点坐标 ex_ctr_x = proposals[:, 0] + 0.5 * ex_widths ex_ctr_y = proposals[:, 1] + 0.5 * ex_heights # 同样的计算逻辑, 获取真实框的宽高和重心坐标 gt_widths = reference_boxes[:, 2] - reference_boxes[:, 0] + TO_REMOVE gt_heights = reference_boxes[:, 3] - reference_boxes[:, 1] + TO_REMOVE gt_ctr_x = reference_boxes[:, 0] + 0.5 * gt_widths gt_ctr_y = reference_boxes[:, 1] + 0.5 * gt_heights # 计算当前 proposals box 的训练目标, 注意, 不同的 proposals 具有不同的训练目标 # 最终返回的 tensor 的 shape 为 [n, 4], n 为 proposals 的大小. wx, wy, ww, wh = self.weights targets_dx = wx * (gt_ctr_x - ex_ctr_x) / ex_widths targets_dy = wy * (gt_ctr_y - ex_ctr_y) / ex_heights targets_dw = ww * torch.log(gt_widths / ex_widths) targets_dh = wh * torch.log(gt_heights / ex_heights) # 将中心坐标和宽高的学习目标结合起来 targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh), dim=1) return targets def decode(self, rel_codes, boxes): # 将编码后的 transformation 形式的 box 转化成 (x1, y1, x2, y2) 形式 # rel_codes (Tensor): encoded boxes # boxes (Tensor): reference boxes boxes = boxes.to(rel_codes.dtype) TO_REMOVE = 1 # 获取真实 box 的宽高和中心坐标 widths = boxes[:, 2] - boxes[:, 0] + TO_REMOVE heights = boxes[:, 3] - boxes[:, 1] + TO_REMOVE ctr_x = boxes[:, 0] + 0.5 * widths ctr_y = boxes[:, 1] + 0.5 * heights # 先对权重解码 wx, wy, ww, wh = self.weights dx = rel_codes[:, 0::4] / wx # 步长为4 dy = rel_codes[:, 1::4] / wy dw = rel_codes[:, 2::4] / ww dh = rel_codes[:, 3::4] / wh # 对 dw, 和 dh 剪枝, 防止向 troch.exp() 传送过大的值 dw = torch.clamp(dw, max=self.bbox_xform_clip) dh = torch.clamp(dh, max=self.bbox_xform_clip) # 计算预测的 box 的中心坐标和宽高, 公式说明参见前面的原理讲解 pred_ctr_x = dx * widths[:, None] + ctr_x[:, None] pred_ctr_y = dy * heights[:, None] + ctr_y[:, None] pred_w = torch.exp(dw) * widths[:, None] pred_h = torch.exp(dh) * heights[:, None] # 将中心坐标和宽高转化成 (x1, y1, x2, y2) 的表示形式, 然后将其返回 pred_boxes = torch.zeros_like(rel_codes) # x1 pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w # y1 pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h # x2 pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1 # y2 pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1 return pred_boxes matcher.py在 rpn/loss.py 文件中的 make_rpn_loss_evaluator() 函数中利用如下语句创建了一个 class Matcher(object) 实例:1234567# ./maskrcnn_benchmark/modeling/rpn/loss.pymatcher = Matcher( cfg.MODEL.RPN.FG_IOU_THRESHOLD, cfg.MODEL.RPN.BG_IOU_THRESHOLD, allow_low_quality_matches=True,) 下面我们就来看看该类的具体实现: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# ./maskrcnn_benchmark/modeling/matcher.pyimport torchclass Matcher(object): # 这个类会给每一个预测 "元素" (如box) 赋值一个 gt "元素". # 每一个预测结果最多匹配一个真实框, 每一个真实框可以有多个匹配的预测框. # 匹配过程是基于一个 M×N 的匹配矩阵进行的, 矩阵的值代表了行列元素匹配的程度.(如IoU) # matcher 对象会返回一个 N 长度的 tensor, N 代表了预测结果的长度, # tensor 中的值是一个 0~m-1 的值, 指向了匹配的真实框的下标, 如果没有匹配, 则为负值. BELOW_LOW_THRESHOLD = -1 BETWEEN_THRESHOLDS = -2 def __init__(self, high_threshold, low_threshold, allow_low_quality_matches=False): # high_threshold: 置信度大于等于该阈值的 box 被选为候选框. 如 0.7 # low_threshold: 置信度小于high阈值但是大于等于low阈值的置为 BETWEEN_THRESHOLD, # 置信度小于low阈值的置为 BELOW_LOW_THRESHOLD # allow_low_quality_matches: 若为真, 则会产生额外一些只有低匹配度的候选框 ## high 阈值必须大于等于 low 阈值 assert low_threshold &lt;= high_threshold # 设成员变量 self.high_threshold = high_threshold self.low_threshold = low_threshold self.allow_low_quality_matches = allow_low_quality_matches def __call__(self, match_quality_matrix): # match_quality_matrix (Tensor[float]): 一个 M×N 的 tensor # 包含着 M 个 gt box 和 predicted box 之间的匹配程度 # 返回值 matches(Tensor[int64]): 一个长度为 N 的 tensor, 其中的元素 N[i] # 代表了与第 i 个 predict box 匹配的 gt box 的下标 if match_quality_matrix.numel() == 0: # 在训练过程中, 匹配矩阵中的元素个数不能为 0, 否则, 输出如下错误 if match_quality_matrix.shape[0] == 0: raise ValueError( "No ground-truth boxes available for one of the images" "during training" ) else: raise ValueError( "No proposal boxes available for one of the images" "during training" ) # match_quality_matrix 的 shape 为 M(gt) × N(predicted) # 为每个 prediction 找到匹配度最高的 gt candidate matched_vals, matches = match_quality_matrix.max(dim=0) # 不在乎每个匹配度的实际大小, 保留所有的 prediction 的匹配值 if self.allow_low_quality_matches: all_matches = matches.clone() # 将那些具有低匹配度的值赋值成负数 below_low_threshold = matched_vals &lt; self.low_threshold between_thresholds = (matched_vals &lt; self.low_threshold) &amp; (matched_vals &lt; self.high_threshold) # 将 matches 中符合相应条件的值置为对应的值 matches[below_low_threshold] = Matcher.BELOW_LOW_THRESHOLD matches[between_thresholds] = Matcher.BETWEEN_THRESHOLD # 如果选项为 True, 则调用类的 set_low_quality_matches_ 函数 if self.allow_low_quality_matches: self.set_low_quality_matches_(matches, all_matches, match_quality_matrix) return matches def set_low_quality_matches_(self, matches, all_matches, match_quality_matrix): # 为 predictions 添加仅具有低匹配度的额外的 matches # 具体来说, 就是给每一个 gt 找到一个具有最大交并比的 prediction 集合. # 对于集合中的每一个 prediction, 如果它还没有与其他 gt 匹配, # 则把它匹配到具有最高匹配值的 gt 上. # 对于每一个 gt, 找到匹配度最高的 prediction highest_quality_foreach_gt, _ = match_quality_matrix.max(dim=1) # 找到非零匹配度的下标: (z×2), z 为非零元素的个数. gt_pred_pairs_of_highest_quality = torch.nonzero( match_quality_matrix == highest_quality_foreach_gt[:, None] ) pred_inds_to_update = gt_pred_pairs_of_highest_quality[:, 1] matches[pred_inds_to_update] = all_matches[pred_inds_to_update] poolers.py registry.py utils.py]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 标准模板库STL完整笔记]]></title>
    <url>%2Fz_post%2FCpp-STL%2F</url>
    <content type="text"><![CDATA[顺序式容器vector, list, deque 容器 说明 底层实现 vector 数组 list 双向链表 deque 中央控制器和多个缓冲区 顺序式容器中元素的位置是按照插入顺序排列的, 也就是容器自身没有排序功能, 顺序式容器都至少具有以下成员函数:123456789101112begin()end()rbegin()rend()front()back()erase()clear()push_back()pop_back()insert() // vector 和 deque 的 insert 复杂度较高 vector连续存储结果, 每个元素在内存上是连续的, 支持 高效的随机访问和尾端插入/删除操作, 但其他位置的插入/删除操作效率低下, 可以看做是一个数组, 但是与数组的区别为: 内存空间的扩展. vector 支持动态大小的数据存储, 而数组则必须指定大小, 但需要扩展空间时, 需要手动实现. vector的内存分配原理及实现:在STL内部实现时, 首先分配一个较大的内存空间预备存储, 即capacity()函数返回的大小, 当超过此分配的空间时, 会再重新分配一块更大的内存空间(VS6.0是两倍, VS2005是1.5倍). 通常默认的内存分配能完成大部分情况下的存储操作. 扩展空间的步骤: 配置一块新空间 将就元素一一移动到新地址中 把原来的空间释放掉 vector的数据安排以及操作方式, 与数组模板Array十分相似, 两者唯一的差别在于空间利用的灵活性, Array的空间扩展需要手动实现 头文件:1#include &lt;vector&gt; 声明及初始化:12345678vector&lt;int&gt; vec; // 声明一个空的vectorvector&lt;int&gt; vec(5);vector&lt;int&gt; vec(10, 1); // 大小为10, 初始值为1vector&lt;int&gt; vec(oldVec);vector&lt;int&gt; vec(oldVec.begin(), dolVec.begin()+3);int arr[5] = &#123;1, 2, 3, 4, 5&#125;;vector&lt;int&gt; vec(arr, arr+5); // 用数组初始化vecvector&lt;int&gt; vec(&amp;arr[0], &amp;arr[5]); // 用数组初始化vec, 注意这里是超尾, 与end相对应 注意: push_back和emplace_back并不等价, 例如, 如果 vector 中存储的是一个 pair 类型的数据, 那么在添加新元素时, 存在以下区别:12345std::vector&lt;std::pair&lt;int, int&gt;&gt; vec;vec.push_back(std::make_pair(1, 2)); // 合法vec.push_back(&#123;1, 2&#125;); // 合法vec.emplace_back(std::make_pair(1, 2)); // 合法vec.emplace_back(&#123;1, 2&#125;); // 不合法!!!! vector 的内存分配机制是怎样的?vector 是一个动态数组, 里面由一个指针值指向一片连续的内存空间, 当空间不够装下数据时, 就会自动申请一片更大的空间, 然后把原有数据拷贝过去, 接着释放原来的那片空间. 不同的编译器实现的扩容方式不一样, 有的是 1.5 倍, 有的是 2 倍(GCC). 初始时刻的capacity为 0. list非连续存储结构, 具有双向链表结构, 每个元素维护一对前向和后向指针, 因此支持前向/后向遍历. 支持高效的随机插入/删除操作, 但是随机访问效率低下, 且由于需要额外维护指针, 开销也比较大. 每一个节点都包括一个信息块info, 一个前驱指针Pre, 一个后驱指针Post. 优点: 不使用连续内存完成插入和删除操作, 使得能够在常数时间内插入新元素 在内部方便的进行插入和删除操作 可以在两端 push, pop 缺点: 不能进行随机访问, 即不支持[]操作符和.at()访问函数 相对于 vector 占用内存多 list与vector的区别 vector 为存储的对象分配一块连续的地址空间, 随机访问效率很高. 但是插入和删除需要移动大量的数据, 效率较低. 尤其当vector内部元素较复杂, 需要调用复制构造函数时, 效率更低. list 中的对象是离散的, 随机访问需要遍历整个链表, 访问效率比 vector 低, 但是在 list 中插入元素, 尤其在首尾插入时, 效率很高. vector 是 单向的 的, 而 list 是双向的 (vector为什么单向???) vector 中的 iterator 在使用后就释放了, 但是 list 不同, 它的迭代器在使用后还可以继续使用, 是链表所特有的. 头文件:1#include &lt;list&gt; 声明和初始化:12345678list&lt;int&gt; l;list&lt;int&gt; l(5); // 含有5个元素的list, 初始值为0list&lt;int&gt; l(10, 1); // 含有10个元素的list, 初始值为1list&lt;int&gt; l(oldL); // 复制构造list&lt;int&gt; l(oldL.begin(), oldL.end());int arr[5] = &#123;1, 2, 3, 4, 5&#125;;list&lt;int&gt; l(arr, arr+5); // 用数组初始化listlist&lt;int&gt; l(&amp;arr[1], &amp;arr[5]); // 用数组初始化list 常用函数:12345678910list.merge() // 合并两个listlist.remove()list.remove_if() // 按指定条件删除元素list.reverse() // 逆置list元素list.sort() // 排序list.unique() // 删除重复元素list.splice() // 从另一个 list 中移动元素push_front() // vector 没有该函数pop_front() // vector 没有该函数 deque双端队列: double-end queue连续存储元素, 即每个元素在内存上是连续的, 类似于vector, 不同之处在于, deque提供了两级数组结构, 第一级完全类似于vector, 代表实际容器, 另一级维护容器的首位地址, 这样, deque除了具有vector的所有功能之外, 还支持高效的首/尾端的插入/删除操作. 连续内存的容器有个明显的缺点, 就是在插入新元素或删除老元素时, 有时需要进行移动, 代价很大, 而 deque 实际上是分配到不同的内存块, 通过链表把内存块连载一起, 再进行连续存放, 是 list 与 vector 的折衷. 优点: 随机访问方便, 支持[]操作符和.at()访问函数, 常数时间, 次于 vector, 因为有可能存在尾部的内存位置在头部之前的场景. 可在两端进行push, pop操作, 效率都较高. 缺点:占用内存多 头文件1#include &lt;deque&gt; 常用函数:1234push_back()pop_back()push_front() // vector 没有该函数pop_front() // vector 没有该函数 关联式容器map, unordered_map, multimap, unordered_multimapset, unordered_set, multiset, unordered_multiset 容器 说明 底层实现 操作复杂度 map 键值对的映射, 有序, 元素不可重复 红黑树 $O(logn)$ unordered_map 键值对的映射, 无序, 元素不可重复 哈希表 $O(1)$ multimap 键值对的映射, 有序, 元素可重复 红黑树 $O(logn)$ unordered_multimap 键值对的映射, 无序, 元素可重复 哈希表 $O(1)$ set 关键字集合, 有序, 元素不可重复 红黑树 $O(logn)$ unordered_set 关键字集合, 无序, 元素不可重复 哈希表 $O(1)$ multiset 关键字集合, 有序, 元素可重复 红黑树 $O(logn)$ unordered_multiset 关键字集合, 无序, 元素可重复 哈希表 $O(1)$ map简介 map 提供键值对的映射关系, 相当于 字典, 其中, 每个关键字只能出现一次, map 底层采用红黑树实现, 会按照给定的排序规则进行排序, 在 map 上进行的搜索, 插入和移除等操作都具有 对数复杂度. 头文件1#include &lt;map&gt; 常用操作(以下操作复杂度均为对数复杂度)1234567891011121314// 数据插入, 复杂度为 lognmap.insert(&#123;key, value&#125;);map[key] = value;// 移除, 复杂度为 lognmap.erase(key)// 搜索, 复杂度为 lognmap.find()map[key]map.count() // 返回匹配特定键的元素数量, 对数复杂度map.contains()map.equal_range()map.lower_bound()map.upper_bound() unordered_map简介 map 提供键值对的映射关系, 相当于 字典, 其中, 每个关键字只能出现一次, unordered_map 底层采用哈希表实现, 容器中的元素是无序的, 在容器上进行的搜索, 插入和移除等操作都拥有平均常数时间复杂度. 头文件1#include &lt;unordered_map&gt; 常用操作(以下操作复杂度平均情况下均为常数)1234567891011121314151617// 数据插入unordered_map[key] = value;// 移除unordered_map.erase(key)// 搜索unordered_map.find()unordered_map[key]unordered_map.count() // 返回匹配特定键的元素数量unordered_map.contains()unordered_map.equal_range() // 复杂度平均情况下与带有关键字的元素数呈线性// 桶接口bucket_count() // 返回桶数max_bucket_count() // 返回桶的最大数量bucket_size() // 返回在特定的桶中的元素数量bucket() // 返回带有特定键的桶 键的类型 默认情况下, unordered_map 只支持将基本类型作为 key, 如下面的代码是不合法的:1unordered_map&lt;pair&lt;int, int&gt;, int&gt; hash; 而map可以使用pair类型作为key. 关于 hash_map C++中的hash_map是标准模板库(STL)的一部分, 但是它不是标准库(Standard Library)的一部分. 有很多编译器(GNU, VS)的实现都提供了这个数据结构.C++11标准库引入了unordered_map, 其功能和hash_map相同. 与map的区别在STL中, map对应的数据结构是红黑树, 红黑树是一种近似于平衡的二叉查找树, 里面的数据是有序的, 在红黑树上做查找的时间为 $O(lonN)$. 而unordered_map对应哈希表, 哈希表的特点就是查找效率高, 时间复杂度基本为 $O(1)$, 而额外空间复杂度较高. multimap简介 multimap 提供键值对的映射关系, 相当于 字典, 其中, 每个关键字可以出现多次, multimap 底层采用红黑树实现, 会按照给定的排序规则进行排序, 拥有等价关键字的键值对的顺序就是插入时的顺序, 且不会发生更改. 在 multimap 上进行的搜索, 插入和移除等操作都具有 对数复杂度. 头文件1#include &lt;map&gt; 常用操作(以下操作复杂度均为对数复杂度)12345678910111213// 数据插入, 复杂度为 lognmultimap.insert(&#123;key, value&#125;);// 移除, 复杂度为 lognmultimap.erase(key)// 搜索, 复杂度为 lognmultimap.find() // 寻找指定关键字对应的元素, 如果容器中存在多个满足条件的元素, 则可能会返回任意一者multimap[key] // 不支持!!multimap.count() // 返回匹配特定键的元素数量, 对数复杂度multimap.contains()multimap.equal_range()multimap.lower_bound() // 有序 map 所独有的multimap.upper_bound() 注意, multimap 不支持使用 [] 和 at() 对来访问关键字对应的 value, find() 查找到的元素迭代器可能是满足条件的任意一个元素 unordered_multimap简介 map 提供键值对的映射关系, 相当于 字典, 其中, 每个关键字可以出现多次, unordered_multimap 底层采用哈希表实现, 容器中的元素是 无序 的, 在容器上进行的搜索, 插入和移除等操作都拥有平均常数时间复杂度. 头文件1#include &lt;unordered_multimap&gt; 常用操作(以下操作复杂度平均情况下均为常数)12345678910111213141516// 数据插入unordered_multimap.insert() // 不支持 [] 或者 at 访问// 移除unordered_multimap.erase(key)// 搜索unordered_multimap.find()unordered_multimap.count() // 返回匹配特定键的元素数量unordered_multimap.contains()unordered_multimap.equal_range() // 复杂度平均情况下与带有关键字的元素数呈线性// 桶接口bucket_count() // 返回桶数max_bucket_count() // 返回桶的最大数量bucket_size() // 返回在特定的桶中的元素数量bucket() // 返回带有特定键的桶 注意, unordered_multimap 不支持使用 [] 和 at() 对来访问关键字对应的 value, find() 查找到的元素迭代器可能是满足条件的任意一个元素 set简介set 是一个关键字集合, 其中的关键字 不可重复, 其底层采用红黑树实现, 因此集合中的元素是 有序 的, 在 set 容器上进行的搜索, 插入和移除等操作都是 对数复杂度 的. 特有操作123lower_bound() // 返回指向首个不小于给定键的元素的迭代器upper_bound() // 返回指向首个大于给定键的元素的迭代器erase_if() unordered_set简介 set 是一个关键字集合, 其中的关键字 不可重复, 其底层采用哈希表实现, 因此集合中的元素是 无序 的, 在 unordered_set 容器上进行的搜索, 插入和移除等操作都是 常数复杂度 的. 基本用法12345678910111213unordered_set&lt;string&gt; stringSet;stringSet.insert("code");stringSet.insert("fast");string key1 = "fast";stringSet.find(key1); // return iter, 指向 faststring key2 = "slow"stringSet.find(key2); // return stringSet.end()vector&lt;int&gt; nums &#123;1,2,3,4,5,6,7,8,9&#125;;unordered_set&lt;int&gt; sets(nums.begin(), nums.end())int key;sets.count(key); // 返回拥有关键key的元素个数, 即只会返回1或0. multiset简介 multiset 是一个关键字集合, 其中的关键字 可以重复, 其底层采用红黑树实现, 因此集合中的元素是 有序 的, 在 multiset 容器上进行的搜索, 插入和移除等操作都是 对数复杂度 的. 注意, 迭代器不能进行算数运算, 即不能 multiset.end() - multiset.begin(). 如果要计算两个迭代器之间的元素数目, 应该用 std::distance(multiset.begin(), multiset.end()), 同时, 要注意, 第一个元素必须小于第二个元素, 在vector中, 可以返回负值距离, 但是在multiset中, 不会返回负值距离, 程序会一直循环直到溢出. unordered_multiset简介set 是一个关键字集合, 其中的关键字 可以重复, 其底层采用哈希表实现, 因此集合中的元素是 无序 的, 在 unordered_set 容器上进行的搜索, 插入和移除等操作都是 常数复杂度 的. 容器适配器stackqueuepriority_queue堆中元素相同时, 先来的会先输出 大顶堆默认比较函数为less, 对应为大顶堆1priority_queue&lt;int&gt; q; 小顶堆使用比较函数greater, 对应为小顶堆 123456priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q;// pair 自身重载的比较运算符, 默认按字典序比较pair中的值// 首先比较 first 的大小, 当 first 大小相同时, 比较 second 的大小priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt; &gt; min_heap; 自定义类型和排序方法优先出列时会对 !cmp 判定, 所以如果希望小的在前(小顶堆), 那么就应该返回 元素1 &gt; 元素2. 注意, 不能在排序方法中写 &lt;=, 或者 &gt;= 等包含 = 的情况. 123456789101112131415161718192021222324252627282930313233343536#include &lt;vector&gt;#include &lt;string&gt;#include &lt;queue&gt;#include &lt;iostream&gt;int main() &#123; // 仿函数自定义比较 struct cmp &#123; bool operator()(const std::pair&lt;int, std::string&gt; &amp;p1, const std::pair&lt;int, std::string&gt; &amp;p2) &#123; return p1.first &gt; p2.first; &#125; &#125;; std::priority_queue&lt; std::pair&lt;int, std::string&gt;, std::vector&lt;std::pair&lt;int, std::string&gt;&gt;, cmp &gt; min_heap_fun; min_heap_fun.push(&#123;1, "abc"&#125;); min_heap_fun.push(&#123;2, "def"&#125;); std::cout &lt;&lt; min_heap_fun.top().second &lt;&lt; std::endl; // lambda 自定义比较 auto lamCmp = [](const std::pair&lt;int, std::string&gt; &amp;p1, const std::pair&lt;int, std::string&gt; &amp;p2) &#123; return p1.first &gt; p2.first; &#125;; std::priority_queue&lt; std::pair&lt;int, std::string&gt;, std::vector&lt;std::pair&lt;int, std::string&gt;&gt;, decltype(lamCmp) &gt; min_heap_lam(lamCmp); min_heap_lam.push(&#123;1, "abc"&#125;); min_heap_lam.push(&#123;2, "def"&#125;); std::cout &lt;&lt; min_heap_lam.top().second &lt;&lt; std::endl; return 0; &#125; 123456struct cmp&#123; bool operator()(ListNode * node1, ListNode * node2)&#123; return node1-&gt;val &gt; node2-&gt;val; &#125;&#125;;priority_queue&lt;ListNode *, vector&lt;ListNode *&gt;, cmp&gt; min_heap; 算法【链接】C++STL一般总结http://www.cnblogs.com/biyeymyhjob/archive/2012/07/22/2603525.html sort()注意, sort 传入的比较函数和 priority_queue 的比较类是不同的, 前者传入的是 Compare 类型的对象(实际上是传入了二元函数, 这里的函数对象重载了()运算符), 后者传入的是 Compare 类型. 也因此, 二者在使用 lambda 表达式上也存在区别. 12 partial_sort()nth_element()nth_element算法将重新排列区间[first, last)的序列元素, 算法执行完毕后, 会使得 第 $k$ 个位置的元素在最终的算法执行完毕后, 和整个区间完全排序后该位置的元素相同. 这个新的nth元素之前的所有元素均 &lt;= (&gt;=) nth元素之后的所有元素.但是该算法并不保证位于第 $k$ 个元素两边区间的元素有序. 该算法和 partial_sort 算法之间一个很大的区别在于: nth_element对于除第 $k$ 位置的元素之外的区间元素的顺序不做保证, 而partial_sort排序后会使得前 $m$ 个数的子区间是有序的. 正因为如此, 在需要无序的前 top_k 个值时, nth_element 相对于 partial_sort 要更快.(只需要找第 $k$ 个值, 其前面的元素即为 top_k, 时间复杂度为 $O(n)$). 假如有序列1int v[10]=&#123;41,67,34,0,69,24,78,58,62,64&#125;; 我们用nth_element求第5小的元素, 则可以执行1std::nth_element(v, v+4, v+10); 若使用的是模板vector, 则可执行:12vector &lt;int&gt; v = &#123;41,67,34,0,69,24,78,58,62,64&#125;;std::nth_element(v.begin(), v.begin()+4, v.end()); 算法执行完毕后, 第5小的元素便是v[4] = 58. 并且, 所有比58小的元素都在v[4]的左边, 大于等于58的都在v[4]的右边.(v[4]在相同元素中排在最前面) nth_element默认时按照从小到大排序, 如果希望找到第 $k$ 大的元素, 则应该传入相应的仿函数:1std::nth_element(v.begin(), v.begin()+4, v.end(), std::greater&lt;int&gt;()); nth_element的算法原理: 基于 Partition 从给定的区间[first, last)中使用三点取值法获取一个枢纽值(三点中值)pivot. 将小于pivot的元素调整至左边区间, 将大于等于pivot的元素调整至右边区间 判断nth的位置是处在左边的区间还是右边的区间, 然后对nth所在的区间重复进行上述操作, 直到该区间的元素数小于等于3. 经过上面的操作, 此时的区间元素数小于等于3, 对该区间进行一次全排列, 以固定nth所处位置的元素. 复杂度分析:基于 Partition , 查找第 $k$ 大/小的元素, 其复杂度为 $O(n)$. 因为当我们找到第一个 Partition 的结果pivot时, 只有三种可能: pivot的位置就是nth, 则程序结束, 可返回结果 pivot的位置在nth的右边, 则说明nth在pivot的左边, 因此需要在左边的范围内继续调用 Partition pivot的位置在nth的左边, 则说明nth在pivot的右边, 因此需要在右边的范围内继续调用 Partition 可以看出, 基于 Partition 的查找第 $k$ 大/小元素的算法, 与快排的一个明显区别就是: 每一次 Partition 之后, nth_element 算法只需要再对两边中的其中一边调用 Partition 即可, 而快排则需要同时对两边都调用 Partition.鉴于 Partition 的复杂度为 $O(n)$, 则快排因为要进行 $logn$ 次 Partition, 所以快排的时间复杂度就是 $nlogn$.($T(n) = 2\times T(n/2) + O(n)$)而 nth_element 的时间复杂度为 $T(n) = T(n/2) + O(n) = O(n) + O(n/2) + O(n/4) + …$, 也就是 $O(n)$. 源码剖析: binary_search()upper_bound()lower_bound()next_permutation()prev_permutation()is_permutation()find()标准库中各个容器的数据结构是什么?vector 的容量增长机制是怎样的? 内存分配机制是怎样的?为什么vector::push_back()的复杂度是分摊之后的 $O(1)$?设计一道可以使用low_bound/upper_bound轻松解决的算法题对于一个已排序的数组, 统计指定元素的个数 实现一下set_intersection()/set_union()/merge()迭代器在什么情况下会失效?标准库的线程安全性list 的insert()/erase()与 vector 相比哪个快?对于百万量级以上的数据, list 的插入和删除比 vector 快很多. 但是对于容器大小为十万量级的数据, 从前端一次删除所有元素, vector 需要 3 s 左右, 而 list 需要 8s, list 更慢. 这篇博客对比了在list、vector、deque上进行不同操作的效率差别。C++ benchmark作者在文章最后给出了源码：articles/bench.cpp at master · wichtounet/articles · GitHub 这一篇更是颠覆我的三观（待会儿做个测试）http://blog.davidecoppola.com/2014/05/20/cpp-benchmarks-vector-vs-list-vs-deque/C++之父动情地抓着记者的手，说：I hate linked list。. C++ STL containers: what’s the difference between deque and list?]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-模型定义(modeling)之RPN网络]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-modeling-rpn%2F</url>
    <content type="text"><![CDATA[源码文件在 Faster R-CNN 中, 首次提出了 RPN 网络, 该网络用于生成目标检测任务所需要候选区域框, 在 MaskrcnnBenchmark 中, 关于 RPN 网络的定义位于 ./maskrcnn_benchmark/modeling/rpn/ 文件夹中, 该文件夹包含以下四个文件: rpn.py anchor_generator.py inference.py loss.py 在 class GeneralizedRCNN(nn.Module) 类中, 会通过 self.rpn = build_rpn(cfg) 函数来创建 RPN 网络, 该函数位于 ./maskrcnn_benchmark/modeling/rpn/rpn.py 文件中, 下面我们就先来看看该文件的内部实现. rpn.py 区域候选框网络在 rpn.py 文件中的最后, 定义了 build_fpn() 函数, 如下所示: 12def build_fpn(cfg): return RPNModule(cfg) 可以看出, 构建 RPN 网络的核心定义在 class RPNModule 中, 该类的定义如下所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127# ./maskrcnn_benchmark/modeling/rpn/rpn.pyimport torchimport torch.nn.functional as Ffrom torch import nnfrom maskrcnn_benchmark.modeling import registryfrom maskrcnn_benchmark.modeling.box_coder import BoxCoderfrom .loss import make_rpn_loss_evaluatorfrom .anchor_generator import make_anchor_generatorfrom .inference import make_rpn_postprocessor@registry.RPN_HEADS.register("SingleConvHead")class RPNHead(nn.Module): # 利用分类层和回归层添加一个简单的 RPN heads # ...class RPNModule(torch.nn.Module): # 用于 RPN 计算的 Module. # 从 backbone 中获取特征图谱用于计算 def __init__(self, cfg):# super(RPNModule, self).__init__() self.cfg = cfg.clone() # from .anchor_generator import make_anchor_generator # 根据配置文件的信息输出对应的 anchor, 详细的实现逻辑需要查看 anchor_generator.py文件 anchor_generator = make_anchor_generator(cfg) # cfg.MODEL.BACKBONE.OUT_CHANNELS = 256 (默认为256*4), 即stage2的输出通道数 in_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS # 创建 rpn heads, 具体的代码解析请看 class RPNHead # cfg.MODEL.RPN.RPN_HEAD = "SingleConvRPNHead" rpn_head = registry.RPN_HEADS[cfg.MODEL.RPN.RPN_HEAD] # num_anchors_per_location() 是 AnchorGenerator 的成员函数, 具体解析请看后文 head = rpn_head( cfg, in_channels, anchor_generator.num_anchors_per_location()[0] ) # from maskrcnn_benchmark.modeling.box_coder import BoxCoder # class BoxCoder(object) 类定义在 ./maskrcnn_benchmark/modeling/box_coder.py 文件中 # 其主要功能是将 bounding boxes 的表示形式编码成易于训练的形式(详细信息可查看R-CNN原文) rpn_box_coder = BoxCoder(weights=(1.0, 1.0, 1.0, 1.0)) # from .inference import make_rpn_postprocessor # 根据配置信息对候选框进行后处理, 选取合适的框用于训练 box_selector_train = make_rpn_postprocessor(cfg, rpn_box_coder, is_train=Fasle) # 选取合适的框用于测试 box_selector_test = make_rpn_postprocessor(cfg, rpn_box_coder, is_train=False) # 利用得到的box获取损失函数 loss_evaluator = make_rpn_loss_evaluator(cfg, rpn_box_coder) # 设置相应的成员 self.anchor_generator = anchor_generator self.head = head self.box_selector_train = box_selector_train self.box_selector_test = box_selector_test self.loss_evaluator = loss_evaluator # 定义前向传播过程 def forward(self, images, features, targets=None): # images (ImageList): # features (list[Tensor]): # targets (list[BoxList]): # 返回值: # boxes (list[BoxList]): # losses (dict[Tensor]): # 利用给定的特征图谱计算相应的 rpn 结果 objectness, rpn_box_regression = self.head(features) # 在图片上生成 anchors anchors = self.anchor_generator(images, features) # 当处在训练状态时, 调用 _foward_train(), 当处在推演状态时, 调用 _forward_test() if self.training: return self._forward_train(anchors, objectness, rpn_box_regression, targets) else: self._forward_test(anchors, objectness, rpn_box_regression) # 训练状态时的前向传播函数 def _forward_train(self, anchors, objectness, rpn_box_regression, targets): if self.cfg.MODEL.RPN_ONLY: # 当处在 rpn-only 的训练模式时, 网络的 loss 仅仅与rpn的 objectness 和 # rpn_box_regression values 有关, 因此无需将 anchors 转化成 boxes boxes = anchors else: # 对于 end-to-end 模型来说, anchors 必须被转化成 boxes, # 然后采样到目标检测网络的 batch 中用于训练, 注意此时不更新网络参数 with torch.no_grad(): boxes = self.box_selector_train( anchors, objectness, rpn_box_regression, targets ) # 获取损失函数的结果 loss_objectness, loss_rpn_box_reg = self.loss_evaluator( anchors, objectness, rpn_box_regression, targets ) # 创建一个loss字典 losses = &#123; "loss_objectness": loss_objectness, "loss_rpn_box_reg": loss_rpn_box_reg, &#125; return boxes, losses # 测试状态时的前向传播函数 def _forward_test(self, anchors, objectness, rpn_box_regression): # 将 anchors 转化成对应的 boxes boxes = self.box_selector_test(anchors, objectness, rpn_box_regression) if self.cfg.MODEL.RPN_ONLY: # 对于 end-to-end 模型来说, RPN proposals 仅仅只是网络的一个中间状态, # 我们无需将它们以降序顺序存储, 直接返回 FPN 结果即可 # 但是对于 RPN-only 模式下, RPN 的输出就是最终结果, 我们需要以置信度从高 # 到低的顺序保存结果并返回. inds = [ box.get_field("objectness").sort(descending=True)[1] for box in boxes ] boxes = [box[ind] for box, ind in zip(boxes, inds)] return boxes, &#123;&#125; 在 class RPNModule 中, 使用了 class RPNHead 作为其头部, 下面我们就来看一下该类的定义及实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# ../maskrcnn_benchmark/modeling/rpn/rpn.py@registry.RPN_HEADS.register("SingleConvRPNHead")class RPNHead(nn.Module): # 添加 classification 和 regression heads def __init__(self, cfg, in_channels, num_anchors): # cfg: 配置信息 # in_channels (int): 输入特征的通道数 # num_anchors (int): 需要预测的 anchors 的数量 super(RPNHead, self).__init__() # 维持通道数不变 self.conv = nn.Conv2d( in_channels, in_channels, kernel_size=3, stride=1, padding=1 ) # objectness 预测层, 输出的 channels 数为 anchors 的数量.(每一点对应 k 个 anchors) self.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1) # 预测 box 回归的网络层 self.bbox_pred = nn.Conv2d( in_channels, num_anchors * 4, kernel_size=1, stride=1 ) # 对定义的网络层参数进行初始化 for l in [self.conv, self.cls_logits, self.bbox_pred]: torch.nn.init.normal_(l.weight, std=0.01) torch.nn.init.constant_(l.bias, 0) # 定义 rpn head 的前向传播过程 def forward(self, x): logits = [] bbox_reg = [] for feature in x: # 先执行卷积+激活 t = F.relu(self.conv(feature)) # 根据卷积+激活后的结果预测objectness logits.append(self.cls_logits(t)) # 根据卷积+激活后的结果预测 bbox bbox_reg.append(self.bbox_pred(t)) return logits, bbox_reg 在定义 RPNModule 时, 分别使用了 make_anchor_generator(), make_rpn_postprocessor() 和 make_rpn_loss_evaluator() 函数来构建模型的 anchor_generator, box_selector 以及 loss_evaluator, 这三个函数分别定义在其他的三个文件中, 下面我们就根据函数的调用顺序, 对这几个文件展开解析. anchor_generator.py 生成 anchors首先是 make_anchor_generator() 函数, 该函数定义在 rpn/ 文件夹下的 anchor_generator.py 文件中, 由于该文件内容较多, 因此, 我们先看一下文件的整体概览, 了解一下文件中都包含了哪些类和函数. 文件概览1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# ./maskrcnn_benchmark/modeling/rpn/anchor_generator.py# 包的导入from maskrcnn_benchmark.structures.bounding_box import BoxList# ...class BufferList(nn.Module): # 和 nn.ParameterList 差不多, 但是是针对 buffers 的 def __init__(self, buffers=None): # 初始化函数 # ... def extend(self, buffers): # buffer 扩展 # ... def __len__(self): # 获取 buffer 长度 return len(self._buffers) def __iter__(self): # buffer 迭代器 return iter(self._buffers.values())class AnchorGenerator(nn.Module): # 对于给定的一系列 image sizes 和 feature maps, 计算对应的 anchors def __init__(...): # 初始化函数 # ... def num_anchors_per_location(self): # 获取每个位置的 anchors 数量 return [len(cell_anchors) for cell_anchors in self.cell_anchors] def grid_anchors(self, grid_sizes): # 获取 anchors # ... def add_visibility_to(self, boxlist): # ??? # ... def forward(self, image_list, feature_maps): # 定义前向传播过程 # ...def make_anchor_generator(config): # 根据配置信息创建 AnchorGenerator 对象实例 # ...def generator_anchors(...): # 根据给定的 stride, sizes, aspect_ratio 等参数返回一个 anchor box 组成的矩阵 # ...def _generate_anchors(base_size, scales, aspect_ratios): # 返回 anchor windows ?? # ...def _whctrs(anchor): # 返回某个 anchor 的宽高以及中心坐标 # ...def _mkanchors(ws, hs, x_ctr, y_ctr): # 给定关于一系列 centers 的宽和高, 返回对应的 anchors # ... make_anchor_generator() 函数由于外部文件往往通过 make_anchor_generator(config) 函数来获取对应的 anchors, 因此, 我们就从这个函数入手解析, 代码如下所示: 1234567891011121314151617181920212223242526272829303132def make_anchor_generator(config): # 定义了 RPN 网络的默认的 anchor 的面积大小 # 默认值为: (32, 64, 128, 256, 512) anchor_sizes = config.MODEL.RPN.ANCHOR_SIZES # 定义了 RPN 网络 anchor 的高宽比 # 默认值为: (0.5, 1.0, 2.0) aspect_ratios = config.MODEL.RPN.ASPECT_RATIOS # 定义了 RPN 网络中 feature map 采用的 stride, # 对于 FPN 来说, strides 的值应该与 scales 的值匹配 # 默认值为: (16,) anchor_stride = config.MODEL.RPN.ANCHOR_STRIDE # 移除那些超过图片 STRADDLE_THRESH 个像素大小的 anchors, 起到剪枝作用 # 默认值为 0, 如果想要关闭剪枝功能, 则将该值置为 -1 或者一个很大的数, 如 100000 straddle_thresh = config.MODEL.RPN.STRADDLE_THRESH if config.MODEL.RPN.USE_FPN: # 当使用 fpn 时, 要确保rpn与fpn的相关参数匹配 assert len(anchor_stride) == len( anchor_sizes ), "FPN should have len(ANCHOR_STRIDE) == len(ANCHOR_SIZES)" else: assert len(anchor_stride) == 1, "Non-FPN should have a single ANCHOR_STRIDE" # 当获取到相关的参数以后, 创建一个 AnchorGenerator 实例并将其返回 anchor_generator = AnchorGenerator( anchor_sizes, aspect_ratios, anchor_stride, straddle_thresh ) return anchor_generator AnchorGenerator 类根据上面的函数我们知道, make_anchor_generator(config) 函数会根据对应的配置文件创建一个 AnchorGenerator 的实例, 因此, 我们下面就对 class AnchorGenerator(nn.Module) 类进行解析, 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# ./maskrcnn_benchmark/modeling/rpn/anchor_generator.pyclass AnchorGenerator(nn.Module): # 对于给定的 image sizes 和 feature maps, 计算对应的 anchors def __init__( self, sizes=(128, 256, 512), aspect_ratios=(0.5, 1.0, 2.0) anchor_strides=(8, 16, 32), straddle_thresh=0, ): super(AnchorGenerator, self).__init__() if len(anchor_strides) == 1: # 如果 anchor_strides 的长度为1, 说明没有 fpn 部分, 则直接调用相关函数 anchor_stride = anchor_strides[0] # 此处调用了本文件的 generate_anchors 函数, 详解见后文 cell_anchors = [ generate_anchors(anchor_stride, sizes, aspect_ratios).float() ] else: if len(anchor_strides) != len(sizes): raise RuntimeError("FPN should have #anchor_strides == #sizes") # 调用 generate_anchors 函数 cell_anchors = [ generate_anchors(anchor_stride, (size,), aspect_ratios).float() for anchor_stride, size in zip(anchor_strides, sizes) ] # 将 strides, cell_anchors, straddle_thresh 作为 AnchorGenerator 的成员 self.strides = anchor_strides self.cell_anchors = BufferList(cell_anchors) # 使用了 BufferList 类 self.straddle_thresh = straddle_thresh # 返回每一个 location 上对应的 anchors 的数量 def num_anchors_per_location(self): return [len(cell_anchors) for cell_anchors in self.cell_anchors] # 用于生成所有特征图谱的 anchors, 会被 forward 函数调用. def grid_anchors(self, grid_sizes): # 创建一个空的 anchors 列表 anchors = [] # 针对各种组合 for size, stride, base_anchors in zip( grid_sizes, self.strides, self.cell_anchors ): # 获取 grid 的尺寸和 base_anchors 的 device grid_height, grid_width = size device = base_anchors.device # 按照步长获取偏移量 shifts_x = torch.arange( 0, grid_width * stride, step=stride, dtype=torch.float32, device=device ) # 获取 y 的偏移量 shifts_y = torch.arange( 0, grid_height * stride, step=stride, dtype=torch.float32, device=device ) # 创建关于 shifts_y, shifts_x 的 meshgrid shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x) # 将二者展开成一维 shift_x = shift_x.reshape(-1) shift_y = shift_y.reshape(-1) shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1) anchors.append( (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4) ) return anchors def add_visibility_to(self, boxlist): ## TODO... 解析 def forward(self, image_list, feature_maps): # TODO... 解析 根据参数生成 anchors在 class AnchorGenerator 中, 利用了 generate_anchors() 函数来生成对应的 anchors, 该函数是生成 anchors 的入口函数, 在生成 anchors 时, 需要进行一些计算和转换, 其大致流程和对应的实现函数如下所示 获取生成 anchors 必要的参数, 包括: stride, sizes, 和 aspect_ratios, 其中, stride 代表特征图谱上的 anchors 的基础尺寸, sizes 代表 anchor 对应在原始图片中的大小(以像素为单位), 因此, 我们容易知道 anchor 在特征图谱上的放缩比例为 sizes/stride, aspect_ratios 代表 anchors 的高宽比, 于是, 最终返回的 anchors 的数量就是 sizes (在特征图谱上固定 base_window 的尺寸, 根据比例的不同来对应不同大小的物体)的数量和 aspect_ratios 数量的乘积; 在获取特征图谱上对应的 base_size(stride)后, 我们将其表示成 [x1, y1, x2, y2](坐标是相对于 anchor 的中心而言的) 的 box 形式. 例如对于 stride=4 的情况, 我们将其表示成 [0, 0, 3, 3], 此部分的实现位于 _generate_anchors(...) 函数中 然后根据 aspect_ratios 的值来获取不同的 anchor boxes 的尺寸, 例如, 对于 stride=4 的 base_anchor 来说, 如果参数 aspect_ratios 为 [0.5, 1.0, 2.0], 那么它就应该返回面积不变, 但是高宽比分别为 [0.5, 1.0, 2.0] 的三个 box 的坐标, 也就是应该返回下面的 box 数组(注意到这里 box 的比例实际上是 [5/2, 1, 2/5], 并不是绝对符合 aspect_ratios, 这是因为像素点只能为整数, 后面还能对这些坐标取整). 这部分的实现位于 _ratio_enum() 函数中; 123[[-1. 0.5 4. 2.5] [ 0. 0. 3. 3. ] [ 0.5 -1. 2.5 4. ]] 在获取到不同比例的特征图谱上的 box 坐标以后, 我们就该利用 scales = sizes/stride 来将这些 box 坐标映射到原始图像中, 也就是按照对应的比例将这些 box 放大, 对于我们刚刚举的例子 scales = 32/4 = 8 来说, 最终的 box 的坐标如下所示. 这部分的代码实现位于 _scale_num() 函数中. 123[[-22., -10., 25., 13.], [-14., -14., 17., 17.], [-10., -22., 13., 25.]] 代码解析如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ./maskrcnn_benchmark/modeling/rpn/anchor_generator.pydef generate_anchors( stride=16, sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.5, 1, 2)): # 该函数会生成一个 anchor boxes 列表, 列表中的元素为以 (x1, x2, y1, y2) 形式表示的 box # 这些 box 的坐标是相对于 anchor 的中心而言的, 其大小为 sizes 数组中元素的平方 # 这里的默认参数对应的是使用 resnet-C4 作为 backbone 的 faster_rcnn 模型 # 如果使用了 FPN, 则不同的 size 会对应到不同的特征图谱上, 下面我们利用 FPN 的参数来讲解代码 # fpn 第一阶段参数值为:(注意sizes必须写成元组或列表的形成) # stride=4, sizes=(32,), aspect_ratios=(0.5, 1, 2) return _generate_anchors( # 调用 _generate_anchors() 函数 stride, # stride=4 np.array(sizes, dtype=np.float) / stride, # sizes / stride = 32 / 4 = 8 np.array(aspect_ratios, dtype=np.float), # [0.5, 1, 2] )def _generate_anchors(base_size, scales, aspect_ratios): # 根据调用语句知, 参数值分别为: 4, 8, [0.5, 1, 2] # 首先得到 anchor 的 base box 坐标(相对于 anchor 中心而言), [0, 0, 3, 3] anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1 # 根据 base_box 和给定的高宽比, 得到拥有不同高宽比的 anchors, # 此处是使 anchor 的比例转化成 [0.5, 1, 2], 对应的 box 为: #[[-1. 0.5 4. 2.5] # [ 0. 0. 3. 3. ] # [ 0.5 -1. 2.5 4. ]] # 注意到这里的 box 的比例实际为 [5/2, 1, 2/5], 具体原理可查看 _ratio_enum() 函数解析 anchors = _ratio_enum(anchor, aspect_ratios) # 得到不同高宽比的 anchors 以后, 按照给定的比例(scales)将其缩放到原始图像中, # 此处 scales 的值只有一个, 即为 8, 因此, 将上面的 boxes 放大 8 倍(指的是宽高各放大 8 倍, 故总面积会放大64倍), 得到新的 boxes 坐标如下: #[[-22., -10., 25., 13.], # [-14., -14., 17., 17.], # [-10., -22., 13., 25.]] # 这里的 vstack 用于将 3 个 1×4 的数组合并成一个 3×4 的数组, 如上所示. # anchors[i, :] 代表的是一个 box 的坐标, 如: [-1. 0.5 4. 2.5] anchors = np.vstack( [_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])] ) # 将numpy数组转换成tensors, 然后返回, anchor的 shape 为: (n, 4), 其中 n 为 anchors 的数量 return torch.from_numpy(anchors) 在上面的函数上, 分别使用了 _ratio_enum() 和 _scale_enum() 函数来实现高宽比和放缩比的组合, 下面, 我们就先对这两个函数进行解析: 1234567891011121314151617181920212223242526./maskrcnn_benchmark/modeling/rpn/anchor_generator.pydef _ratio_enum(anchor, ratios): # 该函数按照给定的 ratios 将 base anchor 转化成具有不同高宽比的多个 anchor boxes, 假设: # anchor: [0. 0. 3. 3.] # ratios: [0.5, 1.0, 2.0] # 获取 anchor 的宽, 高, 以及中心点的坐标 w, h, x_ctr, y_ctr = _whctrs(anchor) # 获取 anchor 的面积 size = w * h # 根据高宽比获取 size_ratios 变量, 后续会用该变量对 box 的高宽比进行转化 size_ratios = size / ratios # ws = sqrt(size) / sqrt(ratios) # hs = sqrt(size) * sqrt(ratios) # 高宽比 = hs/ws = sqrt(ratios) * sqrt(ratios) = ratios # round 代表四舍五入 ws = np.round(np.sqrt(size_ratios)) hs = np.round(ws * ratios) # 根据新的 w 和 h, 生成新的 box 坐标(x1, x2, y1, y2) 并将其返回 anchors = _mkanchors(ws, hs, x_ctr, y_ctr) return anchors 接下来看看对放缩比进行遍历的函数 _scale_enum() 的代码实现12345678910111213def _scale_enum(anchor, scales): # anchor: [-1. 0.5 4. 2.5] (举例) # scales: 8 # 获取 anchor 的宽, 高, 以及中心坐标 w, h, x_ctr, y_ctr = _whctrs(anchor) # 将宽和高各放大8倍 ws = w * scales hs = h * scales # 根据新的宽, 高, 中心坐标, 将 anchor 转化成 (x1, x2, y1, y2) 的形式 return anchors 在 _ratio_enum() 和 _scale_enum() 函数中, 都使用了 _whctrs() 和 _mkanchors 函数, 前者可以根据 box 的坐标信息得到 box 的宽高以及中心点坐标, 后者则是根据宽高以及中心点坐标得到 box 的 (x1, y1, x2, y2) 形式, 这两个函数的代码解析如下所示:12345678910111213141516171819202122232425262728./maskrcnn_benchmark/modeling/rpn/anchor_generator.pydef _whctrs(anchor): # 根据左上角和右下角坐标返回该 box 的宽高以及中心点坐标 w = anchor[2] - anchor[0] + 1 h = anchor[3] - anchor[1] + 1 x_ctr = anchor[0] + 0.5 * (w - 1) y_ctr = anchor[1] + 0.5 * (h - 1) return w, h, x_ctr, y_ctrdef _mkanchors(ws, hs, x_ctr, y_ctr): # 将给定的宽, 高以及中心点坐标转化成 (x1, y1, x2, y2) 的坐标形式 # 这里新增加了一个维度, 以便可以是有 hstack 将结果叠加. ws = ws[:, np.newaxis] hs = hs[:, np.newaxis] # 将结果组合起来并返回 anchors = np.hstack( ( x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1), x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1), ) ) return anchors 经过以上步骤, 最终的 anchors 会被作为初始化参数来实例化一个 class BufferList(nn.Module) 对象, 这一部分的详细解析可以翻到上面的关于 class AnchorGenerator(nn.Module) 的解析. inference.py 文件解析在 class RPNModule(torch.nn.Module) 中, 使用了下面的语句来分别创建训练时和测试时的 box selector:1234rpn_box_coder = BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))box_selector_train = make_rpn_postprocessor(cfg, rpn_box_coder, is_train=True)box_selector_test = make_rpn_postprocessor(cfg, rpn_box_coder, is_train=False) 以 box_selector_train 为例, 该方法用于在 end-to-end 的模型中, 返回训练用的 boxes, 调用形式如下:123boxes = self.box_selector_train( anchors, objectness, rpn_box_regression, targets) 由于 make_rpn_postprocessor() 函数位于 inference.py 文件中, 因此, 我们将在这一小节对该文件进行解析.(关于 BoxCoder 的解析请看模型定义-其他辅助文件解析) inference.py 文件概览./maskrcnn_benchmark/modeling/rpn/inference.py 文件概览如下: 1234567891011121314151617181920212223242526# ./maskrcnn_benchmark/modeling/rpn/inference.py# 导入各种包及函数from maskrcnn_benchmark.modeling.box_coder import BoxCoderclass RPNPostProcessor(torch.nn.Module): # 在将 proposals 喂到网络的 heads 之前, 先对 RPN 输出的 boxes 执行后处理 def __init__(...): # 初始化函数 # ... def add_gt_proposals(self, proposals, targets): # ... def forward_for_single_feature_map(self, anchors, objectness, box_regression): # ... def forward(self, anchors, objectness, box_regression, targets=None): # ... def select_over_all_levels(self, boxlists): # ...def make_rpn_postprocessor(config, rpn_box_coder, is_train): # ... make_rpn_postprocessor() 入口函数在 rpn.py 中使用了 make_rpn_postprocessor() 函数来创建 class RPNPostProcessor(nn.Module) 实例, 该函数的第二个参数是一个 class BoxCoder(object) 的实例, 关于该类的解析请看模型定义-其他辅助文件解析).make_rpn_postprocessor() 函数解析如下: 12345678910111213141516171819202122232425262728293031323334353637383940# ./maskrcnn_benchmark/modeling/rpn/rpn.pydef make_rpn_postprocessor(config, rpn_box_coder, is_train): # rpn_box_coder: BoxCoder 实例 # eg: 2000 fpn_post_nms_top_n = config.MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN if not is_train: # eg: 1000 fpn_post_nms_top_n = config.MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN # eg: 2000 pre_nms_top_n = config.MODEL.RPN.PRE_NMS_TOP_N_TRAIN # eg: 2000 post_nms_top_n = config.MODEL.RPN.POST_NMS_TOP_N_TRAIN if not is_train: # eg: 1000 pre_nms_top_n = config.MODEL.RPN.PRE_NMS_TOP_N_TEST # eg: 1000 post_nms_top_n = config.MODEL.RPN.POST_NMS_TOP_N_TEST # eg: 0.7 nms_thresh = config.MODEL.RPN.NMS_THRESH # eg: 0 min_size = config.MODEL.RPN.MIN_SIZE # 根据配置参数创建一个 RPNPostProcessor 实例 box_selector = RPNPostProcessor( pre_nms_top_n=pre_nms_top_n, post_nms_top_n=post_nms_top_n, nms_thresh=nms_thresh, min_size=min_size, box_coder=rpn_box_coder, fpn_post_nms_top_n=fpn_post_nms_top_n, ) return box_selector 可以看到, 上面函数的主要功能就是根据配置文件的信息创建一个 RPNPostProcessor 的实例对象, 下面我们来看看这个类的定义. RPNPostProcessor 类RPNPostProcessor 类中的 proposals 使用了 BoxList 数据结构, 关于该结构的定义可以看BoxList结构解析. 另外, 还使用了三个函数: cat_boxlist(), boxlist_nms(), 以及 remove_small_boxes(), 关于它们的详细解析请看BoxList Ops 解析 RPNPostProcessor 类的代码解析如下: 初始化函数123456789101112131415161718192021222324252627282930313233343536# ./maskrcnn_benchmark/modeling/rpn/inference.pyclass RPNPostProcessor(torch.nn.Module): # 该类主要完成对 RPN boxes 的后处理功能(在将 boxes 送到 heads 之前执行) def __init__( self, pre_nms_top_n, post_nms_top_n, nms_thresh, min_size, box_coder=None, fpn_post_nms_top_n=None, ): # pre_nms_top_n (int) # post_nms_top_n (int) # nms_thresh (float) # min_size (int) # box_coder (BoxCoder) # fpn_post_nms_top_n (int) super(RPNPostProcessor, self).__init__() # 将传送进来的参数都变成成员变量 self.pre_nms_top_n = pre_nms_top_n self.post_nms_top_n = post_nms_top_n self.nms_thresh = nms_thresh self.min_size = min_size # 创建一个 BoxCoder 实例 if box_coder is None: box_coder = BoxCoder(weights=(1.0, 1.0, 1.0, 1.0)) self.box_coder = box_coder if fpn_post_nms_top_n is None: fpn_post_nms_top_n = post_nms_top_n self.fpn_post_nms_top_n = fpn_post_nms_top_n 添加真实候选框函数1234567891011121314151617181920212223242526272829# ./maskrcnn_benchmark/modeling/rpn/inference.pyclass RPNPostProcessor(torch.nn.Module): def __init__(...): # ... def add_gt_proposals(self, proposals, targets): # 将真实的边框标签 targets 添加到当前的 BoxList 列表数据中. # proposals: list[BoxList] # proposals: list[BoxList] # 获取当前正在操作的设备 device = proposals[0].bbox.device # 调用 BoxList 的 copy_with_fields 方法进行深度复制, gt_boxes 是一个列表 # 其元素的类型是 BoxList gt_boxes = [target.copy_with_fields([]) for target in targets] # 添加一个字典键, "objectness", 值为当前 BoxList 元素中的 box 的数量长度的一维 tensor for gt_box in gt_boxes: gt_box.add_field("objectness", torch.ones(len(gt_box), device=device)) # from maskrcnn_benchmark.structures.boxlist_ops import cat_boxlist # 调用 boxlist_ops.py 中的 cat_boxlist 函数将 proposal 和 gt_box 合并成一个 BoxList proposals = [ cat_boxlist((proposal, gt_box)) for proposal, gt_box zip(proposals, gt_boxes) ] return proposals 在单一的特征图谱上执行前向传播123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# ./maskrcnn_benchmark/modeling/rpn/inference.pyclass RPNPostProcessor(torch.nn.Module): def __init__(...): # ... def add_gt_proposals(...): # ... def forward_for_single_feature_map(self, anchors, objectness, box_regression): # anchors: list[BoxList] # objectness: tensor of size N, A, H, W, A 代表每个像素点 anchors 的数量 # N 代表 batchsize, H, W 代表特征图谱的高和宽 # box_regression: tensor of size N, A * 4, H, W # 获取当前的设备 device = objectness.device # 获取 objectness 的 shape N, A, H, W = objectness.shape # 将格式转换成和 anchors 相同的格式, 先改变维度的排列, 然后改变 shape 的形式 objectness = objectness.permute(0, 2, 3, 1).reshape(N, -1) # shape: (N, H*W*A) # sigmoid 归一化 objectness = objectness.sigmoid() # 相似的操作, 应用在 box_regression 上 box_regression = box_regression.view(N, -1, 4, H, W).permute(0, 3, 4, 1, 2) box_regression = box_regression.reshape(N, -1, 4) # 计算 anchors 的总数量 num_anchors = A * H * W # 确保 pre_nms_top_n 不会超过 anchors 的总数量, 以免产生错误 pre_nms_top_n = min(self.pre_nms_top_n, num_anchors) # 调用 PyTorch 的 topk 函数, 该函数返回两个列表, 一个是 topk 的值, 一个是对应下标 objectness, topk_idx = objectness.topk(pre_nms_top_n, dim=1, sorted=True) # 创建 batch 的下标, shape 为 N×1, 按顺序递增, 如:[[0],[1],...,[N-1]] batch_idx = torch.arange(N, device=device)[:, None] # 获取所有 batch 的 top_k box box_regression = box_regression[batch_idx, topk_idx] # 获取所有 anchor 的尺寸 image_shapes = [box.size for box in anchors] # 获取所有 box, 将 anchors 连接成一个列表 concat_anchors = torch.cat([a.bbox for a in anchors], dim=0) # 重新按照 batch 划分, 同时获取每个 batch 的 topk concat_anchors = concat_anchors.reshape(N, -1, 4)[batch_idx, topk_idx] # 将最终的结果解码成方便表示的形式(原本为方便训练的形式) proposals = self.box_coder.decode( box_regression.view(-1,4), concat_anchors.view(-1,4) ) proposals = proposals.view(N, -1, 4) result = [] # 组建结果并返回 for proposal, score, im_shape in zip(proposals, objectness, image_shapes): # 根据当前的结果创建一个 BoxList 实例 boxlist = BoxList(proposal, im_shape, mode="xyxy") # 添加 score boxlist.add_field("objectness", score) # 防止 box 超出 image 的边界 boxlist = boxlist.clip_to_image(remove_empty=False) # 移除过小的 box boxlist = remove_small_boxes(boxlist, self.min_size) # 在当前的 box 上执行 nms 算法 boxlist = boxlist_nms( boxlist, self.nms_thresh, max_proposals=self.post_nms_top_n, score_field="objectness", ) result.append(boxlist) return result 前向传播函数1234567891011121314151617181920212223242526272829303132333435363738394041424344# ./maskrcnn_benchmark/modeling/rpn/inference.pyclass RPNPostProcessor(torch.nn.Module): def __ init__(...): # ... def add_gt_proposals(...): # ... def forward_for_single_feature_map(...): # ... def forward(self, anchors, objectness, box_regression, targets=None): # anchors: list[list[BoxList]] # objectness: list[tensor] # box_regression: list[tensor] # 返回值: # boxlists (list[BoxList]): 经过 box decoding 和 NMS 操作的处理后的 anchors, # 创建一个空的 box 列表 sampled_boxes = [] num_levels = len(objectness) anchors = list(zip(*anchors)) # 调用类的 forward_for_single_feature_map() 成员函数 for a, o, b in zip(anchors, objectness, box_regression): sampled_boxes.append(self.forward_for_single_feature_map(a, o, b)) boxlists = list(zip(*sampled_boxes)) # 调用 boxlist_ops.py 文件中的 cat_boxlist函数 boxlists = [cat_boxlist(boxliist) for boxlist in boxlists] if num_levels &gt; 1: # 调用类的 select_over_all_levels 成员函数 boxlists = self.select_over_all_levels(boxlists) # 添加 gt bboxes 到 proposals 当中去 if self.training and targets is not None: # 调用类的 add_gt_proposals 成员函数 boxlists = self.add_gt_proposals(boxlists, targets) return boxlists 在所有层次上进行选择1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# ./maskrcnn_benchmark/modeling/rpn/inference.pyclass RPNPostProcessor(torch.nn.Module): def __init__(...): # ... def add_gt_proposals(...): # ... def forward_for_single_feature_map(...): # ... def forward(...): # ... def select_over_all_level(self, boxlists): # 在训练阶段和测试阶段的行为不同, 在训练阶段, post_nms_top_n 是在所有的 proposals 上进行的, # 而在测试阶段, 是在每一个图片上的 proposals 上进行的 num_images = len(boxlists) if self.training: # 连接 "objectness" objectness = torch.cat( [boxlist.get_field("objectness") for boxlist in boxlists], dim=0 ) # 获取box的数量 box_sizes = [len(boxlist) for boxlist in boxlists] # 防止 post_nms_top_n 超过 anchors 总数, 产生错误 post_nms_top_n = min(self.fpn_post_nms_top_n, len(objectness)) # 获取 topk 的下标 _, inds_sorted = torch.topk(objectness, post_nms_top_n, dim=0, sorted=True) inds_mask = torch.zeros_like(objectness, dtype=torch.uint8) inds_mask[inds_sorted] = 1 inds_mask = inds_mask.split(box_sizes) # 获取所有满足条件的box for i in range(num_images): boxlists[i] = boxlists[i][inds_mask[i]] else: for i in range(num_images): objectness = boxlists[i].get_field("objectness") post_nms_top_n = min(self.fpn_post_nms_top_n, len(objectness)) _, inds_sorted = torch.topk( objectness, post_nms_top_n, dim=0, sorted=True ) boxlists[i] = boxlists[i][inds_sorted] return boxlists loss.py在 rpn.py 中, 使用了下面的语句来创建损失函数评价器:12345# ./maskrcnn_benchmark/modeling/rpn/rpn.pyfrom .loss import make_rpn_loss_evaluatorloss_evaluator = make_rpn_loss_evaluator(cfg, rpn_box_coder) 可以看出, 该语句使用了 ./rpn/loss.py 文件中的 make_rpn_loss_evaluator() 函数来创建 RPN 网络的损失函数评价器, 下面我们就来看看该函数的代码实现是怎样的, 代码解析如下. 123456789101112131415161718192021222324# ./maskrcnn_benchmark/modeling/rpn/loss.pyfrom ..balanced_positive_negative_sampler import BalancedPositiveNegativeSamplerfrom maskrcnn_benchmark.modeling.matcher import Matcher# ...def make_rpn_loss_evaluator(cfg, box_coder): # 根据配置信息创建 Matcher 实例 matcher = Matcher( cfg.MODEL.RPN.FG_IOU_THRESHOLD, # 0.7 cfg.MODEL.RPN.BG_IOU_THRESHOLD, # 0.3 allow_low_quality_matches=True, ) # 根据配置信息创建一个 BalancedPositiveNegativeSampler 实例 fg_bg_sampler = BalancedPositiveNegativeSampler( cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE, cfg.MODEL.RPN.POSITIVE_FRACTION ) # 利用上面创建的实例对象进一步创建 RPNLossComputation 实例 loss_evaluator = RPNLossComputation(matcher, fg_bg_sampler, box_coder) 从上面的代码我们可以看出, 在 make_rpn_loss_evaluator() 函数中, 创建了 ./modeling/matcher.py 中的 Matcher 实例, 同时还创建了 ./modeling/balanced_positive_negative_sampler.py 文件中的 BalancedPositiveNegativeSampler, 最后, 利用这两个实例创建了本文件中定义的 RPNLossComputation 实例, 前两个类的解析我们已经介绍过, 下来, 我们就来详细介绍一下本文件的 RPNLossComputation 类的代码实现 1234567891011121314151617# ./maskrcnn_benchmark/modeling/loss.pyimport torchfrom torch.nn import functional as Ffrom ..balanced_positive_negative_sampler import BalancedPositiveNegativeSamplerfrom ..utils import catfrom maskrcnn_benchmark.layers import smooth_l1_lossfrom maskrcnn_benchmark.modeling.matcher import Matcherfrom maskrcnn_benchmark.structures.boxlist_ops import boxlist_ioufrom maskrcnn_benchmark.structures.boxlist_ops import cat_boxlistclass RPNLossComputation(object): # 该类用于计算 RPN 的损失函数结果 def __init__(self, proposal_matcher, fg_bg_sampler, box_coder):]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-模型定义(modeling)之骨架网络(backbone)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-modeling-backbone%2F</url>
    <content type="text"><![CDATA[源码文件不论是在训练脚本文件 train_net.py 还是在测试脚本文件 test_net.py 中, 都调用了 build_detection_model(cfg) 函数来创建模型, 该函数封装了模型定义的内部细节, 使得我们可以通过配置文件轻松的组合出不同类型的模型, 为了能够更好的了解模型的内部细节, 我们有必要知道这些模型是如何被定义, 又是如何组合到一起的, 为此我们需要对 MaskrcnnBenchmark 的 modeling 文件夹进行解析, 该文件夹的结构及文件关系如下所示(位于 ./maskrcnn_benchmark/modeling/ 文件夹下): backbone backbone.py fpn.py resnet.py detector detectors.py generalized_rcnn.py roi_heads box_head box_head.py inference.py loss.py roi_box_feature_extractors.py roi_box_predictors.py mask_head inference.py loss.py mask_head.py roi_mask_feature_extractors.py rpn anchor_generator.py inference.py loss.py rpn.py balanced_positive_negative_sampler.py box_coder.py matcher.py poolers.py registry.py utils.py 下面, 我们根据各个文件和函数之间的逻辑关系(而不是上面的文件顺序), 对 MaskrcnnBenchmark 的模型定义模块展开详细的解析和讨论. 想要透彻了解此部分的代码, 只需要按照本文的顺序仔细阅读即可. detector 模型定义入口第一部分是 detector 文件夹, 该文件夹中的两个文件定义了是整个 modeling 模块的入口. 文件解析如下 detectors.py 文件解析第一个文件 detectors.py 中的代码只有短短几行, 其主要功能就是根据给定的配置信息实例化一个 class GeneralizedRCNN 的对象, 代码如下所示: 12345678910111213# ./maskrcnn_benchmark/modeling/detector/detectors.pyfrom .generalized_rcnn import GeneralizedRCNN_DETECTION_META_ARCHITECTURES = &#123;"GeneralizedRCNN": GeneralizedRCNN&#125;# 该函数是创建模型的入口函数, 也是唯一的模型创建函数def build_detection_model(cfg): # 构建一个模型字典, 虽然只有一对键值, 但是可以方便后续的扩展 meta_arch = _DETECTION_META_ARCHITECTURES[cfg.MODEL.META_ARCHITECTURE] # 下面的语句等价于 # return GeneralizedRCNN(cfg) return meta_arch(cfg) 上面的代码利用配置信息 cfg 实例化了一个 class GeneralizedRCNN 类, 该类定义在 ./maskrcnn_benchmark/modeling/detector/generalized_rcnn.py 文件中, 关于该文件的解析请看下一节. generalized_rcnn.py 文件解析该文件定义了 MaskrcnnBenchmark 的 GeneralizedRCNN 类, 用于表示各种组合后的目标检测模型, 代码解析如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import torchfrom torch import nn# 该函数定义于 ./maskrcnn_benchmark/structures/image_list.py 文件中from maskrcnn_benchmark.structures.image_list import to_image_listfrom ..backbone import build_backbonefrom ..rpn.rpn import build_rpnfrom ..roi_heads.roi_heads import build_roi_heads# 定义类的具体实现class GeneralizedRCNN(nn.Module): # 该类是 MaskrcnnBenchmark 中所有模型的共同抽象, 目前支持 boxes 和 masks 两种形式的标签 # 该类主要包含以下三个部分: # - backbone # - rpn(option) # - heads: 利用前面网络输出的 features 和 proposals 来计算 detections / masks. def __init__(self, cfg): # 根据配置信息初始化模型 super(GeneralizedRCNN, self).__init__() # 根据配置信息创建 backbone 网络 self.backbone = build_backbone(cfg) # 根据配置信息创建 rpn 网络 self.rpn = build_rpn(cfg) # 根据配置信息创建 roi_heads self.roi_heads = build_roi_heads(cfg) def forward(self, images, targets=None): # 定义模型的前向传播过程 # images (list[Tensor] or ImageList) # targets (list[BoxList]) # 返回值: result (list[BoxList] or dict[Tensor]) # 在训练阶段, 返回字典类型的模型损失, 在测试阶段, 返回模型的预测结果. # 当 training 设置为 True 时, 必须提供 targets. if self.training and targets is None: raise ValueError("In training mode, targets should be passed") images = to_image_list(images) # 将图片的数据类型转换成 ImageList # 利用 backbone 网络获取图片的 features features = self.backbone(images.tensors) # 利用 rpn 网络获取 proposals 和相应的 loss proposals, proposal_losses = self.rpn(images, features, targets) if self.roi_heads: # 如何 roi_heads 不为 None 的话, 就计算其输出的结果 x, result, detector_losses = self.roi_heads(features, proposals, targets) else: # RPN-only models don't have roi_heads x = features result = proposals detector_losses = &#123;&#125; if self.training: # 在训练模式下, 输出损失值 losses = &#123;&#125; losses.update(detector_losses) losses.update(proposal_losses) return result # 如果不在训练模式下, 则输出模型的预测结果. 上面的代码中, to_image_list 函数位于 MaskrcnnBenchmark 的结构模块当中, 具体解析可以看structures. 另外, 可以看出, MaskrcnnBenchmark 模型的创建主要依赖于三个函数, 即 build_backbone(cfg), build_rpn(cfg), build_roi_heads(cfg). 下面, 我们就按照模型定义的顺序, 分别讲解这三个函数的内部实现 backbone 模型骨架定义modeling/ 文件夹下面的 backbone/ 文件夹定义了有关模型骨架的相关代码, 该文件夹中总共三个主要的文件, 分别为: backbone.py fpn.py resnet.py backbone.py 文件解析我们在定义骨架网络时使用到的 build_backbone(cfg) 函数, 正位于 ./maskrcnn_benchmark/modeling/backbone/backbone.py 文件中, 因此, 我们首先来看看该文件的内部实现. 1234567891011121314151617181920212223242526272829303132333435363738from collections import OrderedDict # 导入有序字典from torch import nn# 注册器, 用于管理 module 的注册, 使得可以像使用字典一样使用 modulefrom maskrcnn_benchmark.modeling import registryfrom . import fpn as fpn_module # 同文件夹下的文件, 会在后面讲解from . import resnet # 同文件夹下的文件, 会在后面讲解# 创建 resnet 骨架网络, 根据配置信息会被后面的 build_backbone() 函数调用@registry.BACKBONES.register("R-50-C4")def build_resnet_backbone(cfg): body = resnet.ResNet(cfg) # resnet.py 文件中的 class ResNet(cfg) model = nn.Sequential(OrderedDict([("body", body)])) # 利用 nn.Sequential 定义模型 return model# 创建 fpn 网络, 根据配置信息会被下面 build_backbone 函数调用@registry.BACKBONES.register("R-50-FPN")@registry.BACKBONES.register("R-101-FPN")def build_resnet_fpn_backbone(cfg): body = resnet.ResNet(cfg) # 先创建 resnet 网络 # 获取 fpn 所需的channels参数 in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS out_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS fpn = fpn_module.FPN( # 利用 fpn.py 文件夹的 class FPN 创建 fpn 网络 in_channels_list=[ in_channels_stage2, in_channels_stage2 * 2, in_channels_stage2 * 4, in_channels_stage2 * 8, ], out_channels=out_channels, top_blocks=fpn_module.LastLevelMaxPool(), ) model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)])) return model 上面两个函数分别定义了创建 ResNet 和 FPN 的代码逻辑, 下面我们就用这两个函数来进行模型创建, 代码解析如下: 123456def build_backbone(cfg): assert cfg.MODEL.BACKBONE.CONV_BODY in registry.BACKBONES, \ "cfg.MODEL.BACKBONE.CONV_BODY: &#123;&#125; are not registered in registry".format( cfg.MODEL.BACKBONE.CONV_BODY ) return registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg) resnet.py 网络主体(特征提取器)在上面一节中的 backbone.py 文件中的两个函数 build_resnet_backbone() 和 build_resnet_fpn_backbone() 都使用了 body = resnet.ResNet(cfg) 来创建网络的主体, 这部分的代码定义位于 ./maskrcnn_benchmark/modeling/backbone/resnet.py 文件中, 下面我们就该该文件进行解析, 由于该文件篇幅较多, 因此我们先来看一下文件的整体结构:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# ./maskrcnn_benchmark/modeling/backbone/resnet.py# 导入各种包及函数# ...from maskrcnn_benchmark.layers ipmort FrozenBatchNorm2d# ...# ResNet stage specificationStageSpec = #...# ResNetclass ResNet(nn.Module): def __init__(self, cfg): super(ResNet, self).__init__() # 初始化 # ... def _freeze_backbone(self, freeze_at): # 将指定的参数置为: requires_grad = False # ... def forward(self, x): # 定义 resnet 的前向传播过程 # ...# ResNetHeadclass ResNetHead(nn.Module): def __init__(...): # 初始化 # ... def foward(self, x): # 定义 ResNetHead 的前向传播过程 # ...def _make_stage(...): # 创建 ResNet 的 residual-block # ...class BottleneckWithFixedBatchNorm(nn.Module): # 使用固定的BN def __init__(...): # 初始化 # ... def forward(self, x): # 定义前向传播过程 # ...class StemWithFixedBatchNorm(nn.Module): def __init__(self, cfg): # 初始化 # ... def forward(self, x): # 定义前向传播过程 # ..._TRANSFORMATION_MODULES = Registry(&#123;..&#125;)_STEM_MODULES = Registry(&#123;..&#125;)_STAGE_SPECS = Registry(&#123;..&#125;) ResNet Stage Specification文件的开头定义了 ResNet 的不同 stage 下的 block 的定义, 使用了 namedtuple 数据结构(命名元组, 可以用名字访问元素)来实现, 如下所示: 12345678910111213141516171819202122232425262728293031323334StageSpec = namedtuple( "StageSpec", [ "index", # stage 的下标, 如 1, 2, ..., 5 "block_count", # stage 当中的 block 的数量 "return_features", # 布尔值, 若为 True, 则返回当前 stage 的最后一层的 feature map ],)# 标准 ResNet 模块# ResNet-50 full stages 的2~5阶段的卷积层数分别为:3,4,6,3ResNet50StagesTo5 = tuple( # 元组内部的元素类型为 StageSpec StageSpec(index=i, block_count=c, return_features=r) for (i, c, r) in ((1, 3, False), (2, 4, False), (3, 6, False), (4, 3, True)))# ResNet-50-C4, 只使用到第四阶段输出的特征图谱ResNet50StagesTo4 = tuple( StageSpec(index=i, block_count=c, return_features=r) for (i, c, r) in ((1, 3, False), (2, 4, False), (3, 6, True)))# ResNet-50-FPN full stages, 由于 FPN需要用到每一个阶段输出的特征图谱, 故 return_features 参数均为 TrueResNet50FPNStagesTo5 = tuple( StageSpec(index=i, block_count=c, return_features=r) for (i, c, r) in ((1, 3, True), (2, 4, True), (3, 6, True), (4, 3, True)))# ResNet-101-FPN full stages 的卷积层数分别为: 3, 4, 23, 3ResNet101FPNStagesTo5 = tuple( StageSpec(index=i, block_count=c, return_features=r) for (i, c, r) in ((1, 3, True), (2, 4, True), (3, 23, True), (4, 3, True))) ResNet 类为了使阅读代码时不被搞混, 我们首先将文件最后的注册的各个模块贴出来, 这些模块会通过配置文件中的字符串信息来决定调用哪一个类或者参数, 代码如下所示:123456789101112_TRANSFORMATION_MODULES = Registry(&#123; "BottleneckWithFixedBatchNorm": BottleneckWithFixedBatchNorm&#125;)_STEM_MODULES = Registry(&#123;"StemWithFixedBatchNorm": StemWithFixedBatchNorm&#125;)_STAGE_SPECS = Registry(&#123; "R-50-C4": ResNet50StagesTo4, "R-50-C5": ResNet50StagesTo5, "R-50-FPN": ResNet50FPNStagesTo5, "R-101-FPN": ResNet101FPNStagesTo5,&#125;) 当定义完各个 ResNet 模型的 stages 的卷积层数量后, 我们再来看一看 ResNet 类的实现, 代码解析如下所示: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117# ./maskrcnn_benchmark/modeling/backbone/resnet.pyclass ResNet(nn.Module): def __init__(self, cfg): super(ResNet, self).__init__() # 如果我们希望在 forward 函数中使用 cfg, 那么我们就应该创建一个副本以供其使用 # self.cfg = cfg.clone() # 将配置文件中的字符串转化成具体的实现, 下面三个分别使用了对应的注册模块, 定义在文件的最后 # 这里是 stem 的实现, 也就是 resnet 的第一阶段 conv1 # cfg.MODEL.RESNETS.STEM_FUNC = "StemWithFixedBatchNorm" stem_module = _STEM_MODULES[cfg.MODEL.RESNETS.STEM_FUNC] # resnet conv2_x~conv5_x 的实现 # eg: cfg.MODEL.CONV_BODY="R-50-FPN" stage_specs = _STAGE_SPECS[cfg.MODEL.CONV_BODY] # residual transformation function # cfg.MODEL.RESNETS.TRANS_FUNC="BottleneckWithFixedBatchNorm" transformation_module = _TRANSFORMATION_MODULES[cfg.MODEL.RESNETS.TRANS_FUNC] # 获取上面各个组成部分的实现以后, 就可以利用这些实现来构建模型了 # 构建 stem module(也就是 resnet 的stage1, 或者 conv1) self.stem = stem_module(cfg) # 获取相应的信息来构建 resnet 的其他 stages 的卷积层 # 当 num_groups=1 时为 ResNet, &gt;1 时 为 ResNeXt num_groups = cfg.MODEL.RESNETS.NUM_GROUPS # width_per_group = cfg.MODEL.RESNETS.WIDTH_PER_GROUP # in_channels 指的是向后面的第二阶段输入时特征图谱的通道数, # 也就是 stem 的输出通道数, 默认为 64 in_channels = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS # 第二阶段输入的特别图谱的通道数 stage2_bottleneck_channels = num_groups * width_per_group # 第二阶段的输出, resnet 系列标准模型可从 resnet 第二阶段的输出通道数判断后续的通道数 # 默认为256, 则后续分别为512, 1024, 2048, 若为64, 则后续分别为128, 256, 512 stage2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS # 创建一个空的 stages 列表和对应的特征图谱字典 self.stages = [] self.return_features = &#123;&#125; for stage_spec in stage_specs: # 关于 stage_specs 的定义可以看上一节 name = "layer" + str(stage_spec.index) # 计算每个stage的输出通道数, 每经过一个stage, 通道数都会加倍 stage2_relative_factor = 2 ** (stage_spec.index - 1) # 计算输入图谱的通道数 bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor # 计算输出图谱的通道数 out_channels = stage2_out_channels * stage2_relative_factor # 当获取到所有需要的参数以后, 调用本文件的 `_make_stage` 函数, # 该函数可以根据传入的参数创建对应 stage 的模块(注意是module而不是model) module = _make_stage( transformation_module, in_channels, # 输入的通道数 bottleneck_channels, # 压缩后的通道数 out_channels, # 输出的通道数 stage_spec.block_count, #当前stage的卷积层数量 num_groups, # ResNet时为1, ResNeXt时&gt;1 cfg.MODEL.RESNETS.STRIDE_IN_1X1, # 当处于 stage3~5时, 需要在开始的时候使用 stride=2 来downsize first_stride=int(stage_spec.index &gt; 1) + 1, ) # 下一个 stage 的输入通道数即为当前 stage 的输出通道数 in_channels = out_channels # 将当前stage模块添加到模型中 self.add_module(name, module) # 将stage的名称添加到列表中 self.stages.append(name) # 将stage的布尔值添加到字典中 self.return_features[name] = stage_spec.return_features # 根据配置文件的参数选择性的冻结某些层(requires_grad=False) self._freeze_backbone(cfg.MODEL.BACKBONE.FREEZE_CONV_BODY_AT) def _freeze_backbone(self, freeze_at): # 根据给定的参数冻结某些层的参数更新 for stage_index in range(freeze_at): if stage_index == 0: m = self.stem # resnet 的第一阶段, 即为 stem else: m = getattr(self, "layer" + str(stage_index)) # 将 m 中的所有参数置为不更新状态. for p in m.parameters(): p.requires_grad = False # 定义 ResNet 的前行传播过程 def forward(self, x): outputs = [] x = self.stem(x) # 先经过 stem(stage 1) # 再依次计算 stage2~5的结果 for stage_name in self.stages: x = getattr(self, stage_name)(x) if self.return_features[stage_name]: # 将stage2~5的所有计算结果(也就是特征图谱)以列表形式保存 outputs.append(x) # 将结果返回, outputs为列表形式, 元素为各个stage的特征图谱, 刚好作为 FPN 的输入 return outputs ResNetHead 类接下来, 我们来看看 ResNetHead 类的实现, 代码解析如下所示: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class ResNetHead(nn.Module): def __init__( self, block_module, stages, num_groups=1, width_per_group=64, stride_in_1x1=True, stride_init=None, res2_out_channels=256, ): super(ResNetHead, self).__init__() # 获取不同stage的通道数相对于stage2的倍数 stage2_relative_factor = 2 ** (stages[0].index - 1) # 获取压缩后的 stage2 的 channels stage2_bottleneck_channels = num_groups * width_per_group # 获取输出的 channels out_channels = res2_out_channels * stage2_relative_factor # 获取输入的 channels in_channels = out_channels // 2 # 获取压缩后的 channels bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor # 根据给定的名称获取相应 block_module # 目前 _TRANSFORMATION_MODULES 只包含 "BottleneckWithFixedBatchNorm" 这一个模块 block_module = _TRANSFORMATION_MODULES[block_module] # 创建一个空的 stages 列表 self.stages = [] # 初始化 stride stride = stride_init for stage in stages: name = "layer" + str(stage.index) if not stride: # 当处于 stage3~5时, 需要在开始的时候使用 stride=2 来downsize stride = int(stage.index &gt; 1) + 1 module = _make_stage( block_module, in_channels, bottleneck_channels, out_channels, stage.block_count, num_groups, stride_in_1x1, first_stride=stride, ) stride = None self.add_module(name, module) self.stages.append(name) # 定义前向传播过程 def forward(self, x): for stage in self.stages: x = getattr(self, stage)(x) return x make_stage在上面两个类中, 都使用了 _make_stage() 函数来创建对应的 stage, 下面, 我们就来看看该函数的具体实现, 代码解析如下所示: 123456789101112131415161718192021222324252627# ./maskrcnn_benchmark/modeling/backbone/resnet.pydef _make_stage( transformation_module, in_channels, bottleneck_channels, out_channels, block_count, num_groups, stride_in_1x1, first_stride,): blocks = [] stride = first_stride for _ in range(block_count): blocks.append( transformation_module( in_channels, bottleneck_channels, out_channels, num_groups, stride_in_1x1, stride, ) ) stride = 1 in_channels = out_channels StemWithFixedBatchNorm 类该类负责构建 ResNet 的 stem 模块, 也可以认为是 ResNet 的第一阶段(或者说是第零阶段), 在 ResNet 50 中, 该阶段主要包含一个 7×7 大小的卷积核, 在 MaskrcnnBenchmark 的实现中, 为了可以方便的复用实现各个 stage 的代码, 它将第二阶段最开始的 3×3 的 max pooling 层也放到了 stem 中的 forward 函数中实现(一般不带参数网络层的都放在 forward 中), 该类的实现代码解析如下: 123456789101112131415161718192021222324# ./maskrcnn_benchmark/modeling/backbone/resnet.pyclass StemWithFixedBatchNorm(nn.Module): def __init__(self, cfg): super(StemWithFixedBatchNorm, self).__init__() # resnet-50, out_channels=64 out_channels = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS # 输入的 channels 为 3, 输出为 64 self.conv1 = Conv2d( 3, out_channels, kernel_size=7, stride=2, padding=3, bias=False ) # 使用固定参数的 BN 层 self.bn1 = FrozenBatchNorm2d(out_channels) # 定义前向传播过程 def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = F.relu_(x) # 原地激活, 因为不含参数, 因此不放在模型定义中, 而放在 forward 中实现 x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1) return x 上面代码中的 Conv2d 是封装在 ./maskrcnn_benchmark/layers/misc.py 文件中的 class Conv2d(nn.Conv2d) 类, 它会根据 tensor 的 numel 参数决定其返回值, 当 x.numel()&gt;0 时, 与普通的 torch.nn.Conv2d() 函数没有区别. 另外还使用了 ./maskrcnn_benchmark/layers/batch_norm.py 文件中定义的 class FrozenBatchNorm2d(nn.Module) 类, 该类主要实现了 BN 层的功能, 只不过其中的参数都是固定的, 而非可更新的. BottleneckWithFixedBatchNorm 类创建完 stem(stage1) 以后, 接下来就是需要创建 resnet 的 stage2~5, 根据 resnet 的特点我们可以知道, resnet2~5 阶段的整体结构是非常相似的, 都是有最基础的 resnet bottleneck block 堆叠形成的, 不同 stage 的 bottleneck block 的数量不同, 对于 resnet50 来说, 每一个阶段的 bottleneck block 的数量分别为 3,4,6,3, 并且各个相邻 stage 之间的通道数都是两倍的关系, 所以可以很容易的从一个 stage 的通道数推知另一个 stage 的通道数, 关于 bottleneck block 的代码解析如下所示: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# ./maskrcnn_benchmark/modeling/backbone/resnet.pyclass BottleneckWithFixedBatchNorm(nn.Module): def __init__( self, in_channels, # bottleneck 的输入 channels bottleneck_channels, # bottleneck 压缩后的 channels out_channels, # 当前stage的输出channels num_groups=1, stride_in_1x1=True, stride=1, ): super(BottleneckWithFixedBatchNorm, self).__init__() # downsample: 当 bottleneck 的输入和输出的 channels 不相等时, 则需要采用一定的策略 # 在原文中, 有 A, B, C三种策略, 本文采用的是 B 策略(也是原文推荐的) # 即只有在输入输出通道数不相等时才使用 projection shortcuts, # 也就是利用参数矩阵映射使得输入输出的 channels 相等 self.downsample = None # 当输入输出通道数不同时, 额外添加一个 1×1 的卷积层使得输入通道数映射成输出通道数 if in_channels != out_channels: self.downsample = nn.Sequential( Conv2d( in_channels, out_channels, kernel_size=1, stride=stride, bias=False ), FrozenBatchNorm2d(out_channels), # 后街一个固定参数的 BN 层 ) # 在 resnet 原文中, 会在 conv3_1, conv4_1, conv5_1 处使用 stride=2 的卷积 # 而在 fb.torch.resnet 和 caffe2 的实现中, 是将之后的 3×3 的卷积层的 stride 置为2 # 下面中的 stride 虽然默认值为1, 但是在函数调用时, 如果stage为3~5, 则会显示置为2 stride_1x1, stride_3x3 = (stride, 1) if stride_in_1x1 else (1, stride) # 当获取到当前stage所需的参数后, 就创建相应的卷积层, 创建原则参见 resnet50 的定义 self.conv1 = Conv2d( in_channels, bottleneck_channels, kernel_size=1, stride=stride_1x1, bias=False, ) self.bn1 = FrozenBatchNorm2d(bottleneck_channels) # 后接一个固定参数的 BN 层 # 创建 bottleneck 的第二层卷积层 self.conv2 = Conv2d( bottleneck_channels, bottleneck_channels, kernel_size=3, stride=stride_3x3, padding=1, bias=False, groups=num_groups, ) self.bn2 = FrozenBatchNorm2d(bottleneck_channels) # 后接一个 BN 层 # 创建 bottleneck 的最后一个卷积层, padding默认为1 self.conv3 = Conv2d( bottleneck_channels, out_channels, kernel_size=1, bias=False ) self.bn3 = FrozenBatchNorm2d(out_channels) def forward(self, x): # 执行一次forward, 相当于执行一次 bottleneck, # 默认情况下, 具有三个卷积层, 一个恒等连接, 每个卷积层之后都带有 BN 和 relu 激活 # 注意, 最后一个激活函数要放在恒等连接之后 residual = x # 恒等连接, 直接令残差等于x即可 # conv1, bn1 out = self.conv1(x) out = self.bn1(out) out = F.relu_(out) # conv2, bn2 out = self.conv2(out) out = self.bn2(out) out = F.relu_(out) # conv3, bn3 out0 = self.conv3(out) # 这里的out0好像没必要带0? out = self.bn3(out0) if self.downsample is not None: # 如果输入输出的通道数不同, 则需要通过映射使之相同. residual = self.downsample(x) out += residual # H = F + x out = F.relu_(out) # 最后进行激活 return out # 返回带有残差项的卷积结果 fpn.py 特征金字塔网络对于 ResNet-50-C4 来说, 只需要上面的 ResNet 模型即可完成特征提取任务, 但是对于 ResNet-50-FPN 来说, 我们还需要实现 FPN 网络以获得更强的特征提取能力, 在 backbone.py 文件中的 build_resnet_fpn_backbone(cfg) 函数中, 就使用了 fpn = fpn_module.FPN(...) 来创建一个 FPN 类的实例对象, 并且利用 nn.Sequential() 将 ResNet 和 FPN 组合在一起形成一个模型, 并将其返回, 下面, 我们就来看看 FPN 网络的具体实现, 实例代码位于 ./maskrcnn_benchmark/modeling/backbone/fpn.py 文件中, 解析如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# ./maskrcnn_benchmark/modeling/backbone/fpn.pyimport torchimport torch.nn.functional as Ffrom torch import nnclass FPN(nn.Module): # 在一系列的 feature map (实际上就是stage2~5的最后一层输出)添加 FPN # 这些 feature maps 的 depth 假定是不断递增的, 并且 feature maps 必须是连续的(从stage角度) def __init__(self, in_channels_list, out_channels, top_blocks=None): # in_channels_list (list[int]): 指示了送入 fpn 的每个 feature map 的通道数 # out_channels (int): FPN表征的通道数, 所有的特征图谱最终都会转换成这个通道数大小 # top_blocks (nn.Module or None): 当提供了 top_blocks 时, 就会在 FPN 的最后 # 的输出上进行一个额外的 op, 然后 result 会扩展成 result list 返回 super(FPN, self).__init__() # 创建两个空列表 self.inner_blocks = [] self.layer_blocks = [] # 假设我们使用的是 ResNet-50-FPN 和配置, 则 in_channels_list 的值为: # [256, 512, 1024, 2048] for idx, in_channels in enumerate(in_channels_list, 1): # 下标从1开始 # 用下表起名: fpn_inner1, fpn_inner2, fpn_inner3, fpn_inner4 inner_block = "fpn_inner&#123;&#125;".format(idx) # fpn_layer1, fpn_layer2, fpn_layer3, fpn_layer4 layer_block = "fpn_layer&#123;&#125;".format(idx) # 创建 inner_block 模块, 这里 in_channels 为各个stage输出的通道数 # out_channels 为 256, 定义在用户配置文件中 # 这里的卷积核大小为1, 该卷积层主要作用为改变通道数到 out_channels(降维) inner_block_module = nn.Conv2d(in_channels, out_channels, 1) # 改变 channels 后, 在每一个 stage 的特征图谱上再进行 3×3 的卷积计算, 通道数不变 layer_block_module = nn.Conv2d(out_channels, out_channels, 3, 1, 1) for module in [inner_block_module, layer_block_module]: # Caffe2 的实现使用了 XavierFill, # 实际上相当于 PyTorch 中的 kaiming_uniform_ nn.init.kaiming_uniform_(module.weight, a=1) nn.init.constant_(module.bias, 0) # 在当前的特征图谱上添加 FPN self.add_module(inner_block, inner_block_module) #name, module self.add_module(layer_block, layer_block_module) # 将当前 stage 的 fpn 模块的名字添加到对应的列表当中 self.inner_blocks.append(inner_block) self.layer_blocks.append(layer_block) # 将top_blocks作为 FPN 类的成员变量 self.top_blocks = top_blocks def forward(self, x): # x (list[Tensor]): 每个 feature level 的 feature maps, # ResNet的计算结果正好满足 FPN 的输入要求, 也因此可以使用 nn.Sequential 将二者直接结合 # results (tuple[Tensor]): 经过FPN后的特征图谱组成的列表, 排列顺序是高分辨率的在前 # 先计算最后一层(分辨率最低)特征图谱的fpn结果. last_inner = getattr(self, self.inner_blocks[-1])(x[-1]) # 创建一个空的结果列表 results=[] # 将最后一层的计算结果添加到 results 中 results.append(getattr(self, self.layer_blocks[-1])(last_inner)) # [:-1] 获取了前三项, [::-1] 代表从头到尾切片, 步长为-1, 效果为列表逆置 # 举例来说, zip里的操作 self.inner_block[:-1][::-1] 的运行结果为 # [fpn_inner3, fpn_inner2, fpn_inner1], 相当于对列表进行了逆置 for feature, inner_block, layer_block in zip( x[:-1][::-1], self.inner_block[:-1][::-1], self.layer_blocks[:-1][::-1] ): # 根据给定的scale参数对特征图谱进行放大/缩小, 这里scale=2, 所以是放大 inner_top_down = F.interpolate(last_inner, scale_factor=2, mode="nearest") # 获取 inner_block 的计算结果 inner_lateral = getattr(self, inner_block)(feature) # 将二者叠加, 作为当前stage的输出 同时作为下一个stage的输入 last_inner = inner_lateral + inner_top_down # 将当前stage输出添加到结果列表中, 注意还要用 layer_block 执行卷积计算 # 同时为了使得分辨率最大的在前, 我们需要将结果插入到0位置 results.insert(0, getattr(self, layer_block)(last_inner)) # 如果 top_blocks 不为空, 则执行这些额外op if self.top_blocks is not None: last_results = self.top_blocks(results[-1]) results.extend(last_results) # 将新计算的结果追加到列表中 # 以元组(只读)形式返回 return tuple(results)# 最后一级的 max pool 层class LastLevelMaxPool(nn.Module): def forward(self, x): return [F.max_pool2d(x, 1, 2, 0)] roi_heads在detector/generalized_rcnn.py文件中, 模型定义如下所示:123456def __init__(self, cfg): super(GeneralizedRCNN, self).__init__() self.backbone = build_backbone(cfg) self.rpn = build_rpn(cfg, self.backbone.out_channels) self.roi_heads = build_roi_heads(cfg, self.backbone.out_channels) 所以, 当使用 backbone 和 rpn 构建后特征图谱的生成结构以后, 我们就需要在特征图谱上划分相应的 RoI, 该模块的定义入口就是roi_heads/roi_heads.py中build_roi_heads函数, 下面我们对该文件进行解析 roi_heads首先是入口函数build_roi_heads 1234567891011121314151617181920def build_roi_heads(cfg, in_channels): # individually create the heads, that will be combined together # afterwards roi_heads = [] if cfg.MODEL.RETINANET_ON: # RetinaNet 不需要 RoI return [] # 从概念上, 下面的 roi 可以同时开启, 互不影响, 但通常只会开启其中一个 if not cfg.MODEL.RPN_ONLY: # 使用 RPN roi_heads.append(("box", build_roi_box_head(cfg, in_channels))) if cfg.MODEL.MASK_ON: # 使用 Mask roi_heads.append(("mask", build_roi_mask_head(cfg, in_channels))) if cfg.MODEL.KEYPOINT_ON: # 使用 key point roi_heads.append(("keypoint", build_roi_keypoint_head(cfg, in_channels))) # combine individual heads in a single module if roi_heads: roi_heads = CombinedROIHeads(cfg, roi_heads) return roi_heads 上面在构建roi时, 根据种类的不同分别使用了build_roi_box_head, build_roi_mask_head, 以及build_roi_keypoint_head, 同时, 利用CombinedROIHeads将它们结合在一起, 前三个是函数, CombinedROIHeads是一个类. 下面我们逐个介绍 box_headbuild_roi_box_head() 该函数位于roi_heads/box_head/box_head.py文件中, 我们来看一下该函数的实现: 1234567def build_roi_box_head(cfg, in_channels): """ Constructs a new box head. By default, uses ROIBoxHead, but if it turns out not to be enough, just register a new class and make it a parameter in the config """ return ROIBoxHead(cfg, in_channels) 该函数返回了ROIBoxHead的实例, 该类同样定义在roi_heads/box_head/box_head.py文件中, 实现如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class ROIBoxHead(torch.nn.Module): """ Generic Box Head class. """ def __init__(self, cfg, in_channels): super(ROIBoxHead, self).__init__() self.feature_extractor = make_roi_box_feature_extractor(cfg, in_channels) # roi_box_feature_extractors.py 文件中的函数 self.predictor = make_roi_box_predictor( # roi_box_predictors.py 文件中的函数 cfg, self.feature_extractor.out_channels) self.post_processor = make_roi_box_post_processor(cfg) # inference.py 文件中函数 self.loss_evaluator = make_roi_box_loss_evaluator(cfg) # loss.py 文件中函数 def forward(self, features, proposals, targets=None): """ Arguments: features (list[Tensor]): feature-maps from possibly several levels proposals (list[BoxList]): proposal boxes targets (list[BoxList], optional): the ground-truth targets. Returns: x (Tensor): the result of the feature extractor proposals (list[BoxList]): during training, the subsampled proposals are returned. During testing, the predicted boxlists are returned losses (dict[Tensor]): During training, returns the losses for the head. During testing, returns an empty dict. """ if self.training: # Faster R-CNN subsamples during training the proposals with a fixed # positive / negative ratio with torch.no_grad(): proposals = self.loss_evaluator.subsample(proposals, targets) # extract features that will be fed to the final classifier. The # feature_extractor generally corresponds to the pooler + heads x = self.feature_extractor(features, proposals) # final classifier that converts the features into predictions class_logits, box_regression = self.predictor(x) if not self.training: result = self.post_processor((class_logits, box_regression), proposals) return x, result, &#123;&#125; loss_classifier, loss_box_reg = self.loss_evaluator( [class_logits], [box_regression] ) return ( x, proposals, dict(loss_classifier=loss_classifier, loss_box_reg=loss_box_reg), ) 可以看出, ROIBoxHead 主要由 4 个部分组成, 分别是:feature_extractor, predictor, post_processor, 以及loss_evaluator. 其中, feature_extractor主要是提取各个 RoI 的特征, predictor是对每个 RoI 进行预测, 得到class_logits和box_regression, 然后, 利用post_processor和loss_evaluator计算分类器和回归器的损失, 这四个部分的分别位于roi_heads/box_head/目录下的不同文件中, 下面我们一一对其进行分析. make_roi_box_feature_extractor该函数位于roi_heads/box_head/roi_box_feature_extractors.py文件中, 函数定义如下: 12345def make_roi_box_feature_extractor(cfg, in_channels): func = registry.ROI_BOX_FEATURE_EXTRACTORS[ cfg.MODEL.ROI_BOX_HEAD.FEATURE_EXTRACTOR ] return func(cfg, in_channels) 上面的代码表示, 该函数会根据用户配置文件中指定的cfg.MODEL.ROI_BOX_HEAD.FEATURE_EXTRACTOR来调用不同的函数, 对应了不同的 RoIHEAD, roi_box_feature_extractors.py文件中定义了三种不同的 ROI_BOX_HEAD.FEATURE_EXTRACTOR, 分别如下所示: ResNet50Conv5ROIFeatureExtractor12345678910111213141516171819202122232425262728293031323334@registry.ROI_BOX_FEATURE_EXTRACTORS.register("ResNet50Conv5ROIFeatureExtractor")class ResNet50Conv5ROIFeatureExtractor(nn.Module): def __init__(self, config, in_channels): super(ResNet50Conv5ROIFeatureExtractor, self).__init__() resolution = config.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION scales = config.MODEL.ROI_BOX_HEAD.POOLER_SCALES sampling_ratio = config.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO pooler = Pooler( # 位于 modeling/pooler.py 文件中 output_size=(resolution, resolution), scales=scales, sampling_ratio=sampling_ratio, ) stage = resnet.StageSpec(index=4, block_count=3, return_features=False) head = resnet.ResNetHead( block_module=config.MODEL.RESNETS.TRANS_FUNC, stages=(stage,), num_groups=config.MODEL.RESNETS.NUM_GROUPS, width_per_group=config.MODEL.RESNETS.WIDTH_PER_GROUP, stride_in_1x1=config.MODEL.RESNETS.STRIDE_IN_1X1, stride_init=None, res2_out_channels=config.MODEL.RESNETS.RES2_OUT_CHANNELS, dilation=config.MODEL.RESNETS.RES5_DILATION ) self.pooler = pooler self.head = head self.out_channels = head.out_channels def forward(self, x, proposals): x = self.pooler(x, proposals) x = self.head(x) return x FPN2MLPFeatureExtractor123456789101112131415161718192021222324252627282930313233@registry.ROI_BOX_FEATURE_EXTRACTORS.register("FPN2MLPFeatureExtractor")class FPN2MLPFeatureExtractor(nn.Module): """ Heads for FPN for classification """ def __init__(self, cfg, in_channels): super(FPN2MLPFeatureExtractor, self).__init__() resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION scales = cfg.MODEL.ROI_BOX_HEAD.POOLER_SCALES sampling_ratio = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO pooler = Pooler( output_size=(resolution, resolution), scales=scales, sampling_ratio=sampling_ratio, ) input_size = in_channels * resolution ** 2 representation_size = cfg.MODEL.ROI_BOX_HEAD.MLP_HEAD_DIM use_gn = cfg.MODEL.ROI_BOX_HEAD.USE_GN self.pooler = pooler self.fc6 = make_fc(input_size, representation_size, use_gn) self.fc7 = make_fc(representation_size, representation_size, use_gn) self.out_channels = representation_size def forward(self, x, proposals): x = self.pooler(x, proposals) x = x.view(x.size(0), -1) x = F.relu(self.fc6(x)) x = F.relu(self.fc7(x)) return x FPNXconv1fcFeatureExtractor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@registry.ROI_BOX_FEATURE_EXTRACTORS.register("FPNXconv1fcFeatureExtractor")class FPNXconv1fcFeatureExtractor(nn.Module): """ Heads for FPN for classification """ def __init__(self, cfg, in_channels): super(FPNXconv1fcFeatureExtractor, self).__init__() resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION scales = cfg.MODEL.ROI_BOX_HEAD.POOLER_SCALES sampling_ratio = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO pooler = Pooler( output_size=(resolution, resolution), scales=scales, sampling_ratio=sampling_ratio, ) self.pooler = pooler use_gn = cfg.MODEL.ROI_BOX_HEAD.USE_GN conv_head_dim = cfg.MODEL.ROI_BOX_HEAD.CONV_HEAD_DIM num_stacked_convs = cfg.MODEL.ROI_BOX_HEAD.NUM_STACKED_CONVS dilation = cfg.MODEL.ROI_BOX_HEAD.DILATION xconvs = [] for ix in range(num_stacked_convs): xconvs.append( nn.Conv2d( in_channels, conv_head_dim, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False if use_gn else True ) ) in_channels = conv_head_dim if use_gn: xconvs.append(group_norm(in_channels)) xconvs.append(nn.ReLU(inplace=True)) self.add_module("xconvs", nn.Sequential(*xconvs)) for modules in [self.xconvs,]: for l in modules.modules(): if isinstance(l, nn.Conv2d): torch.nn.init.normal_(l.weight, std=0.01) if not use_gn: torch.nn.init.constant_(l.bias, 0) input_size = conv_head_dim * resolution ** 2 representation_size = cfg.MODEL.ROI_BOX_HEAD.MLP_HEAD_DIM self.fc6 = make_fc(input_size, representation_size, use_gn=False) self.out_channels = representation_size def forward(self, x, proposals): x = self.pooler(x, proposals) x = self.xconvs(x) x = x.view(x.size(0), -1) x = F.relu(self.fc6(x)) return x mask_head接下来是build_roi_mask_head函数, 该函数位于roi_heads/mask_head/mask_head.py文件中, 定义如下: 12def build_roi_mask_head(cfg, in_channels): return ROIMaskHead(cfg, in_channels) ROIMaskHead 定义如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344class ROIMaskHead(torch.nn.Module): def __init__(self, cfg, in_channels): super(ROIMaskHead, self).__init__() self.cfg = cfg.clone() self.feature_extractor = make_roi_mask_feature_extractor(cfg, in_channels) self.predictor = make_roi_mask_predictor( cfg, self.feature_extractor.out_channels) self.post_processor = make_roi_mask_post_processor(cfg) self.loss_evaluator = make_roi_mask_loss_evaluator(cfg) def forward(self, features, proposals, targets=None): """ Arguments: features (list[Tensor]): feature-maps from possibly several levels proposals (list[BoxList]): proposal boxes targets (list[BoxList], optional): the ground-truth targets. Returns: x (Tensor): the result of the feature extractor proposals (list[BoxList]): during training, the original proposals are returned. During testing, the predicted boxlists are returned with the `mask` field set losses (dict[Tensor]): During training, returns the losses for the head. During testing, returns an empty dict. """ if self.training: # during training, only focus on positive boxes all_proposals = proposals proposals, positive_inds = keep_only_positive_boxes(proposals) if self.training and self.cfg.MODEL.ROI_MASK_HEAD.SHARE_BOX_FEATURE_EXTRACTOR: x = features x = x[torch.cat(positive_inds, dim=0)] else: x = self.feature_extractor(features, proposals) mask_logits = self.predictor(x) if not self.training: result = self.post_processor(mask_logits, proposals) return x, result, &#123;&#125; loss_mask = self.loss_evaluator(proposals, mask_logits, targets) return x, all_proposals, dict(loss_mask=loss_mask) 同样可以看到, ROIMaskHead 由四部分组成, 分别为feature_extractor, predictor, post_processor以及loss_evaluator, 他们分别定义在下面的四个文件当中, 具体细节可查看源代码. roi_mask_feature_extractors.py, roi_mask_predictors.py, inference.py, loss.py keypoint_head函数build_roi_keypoint_head定义在roi_heads/keypoint_head/keypoint_head.py, 具体如下所示: 1234567891011121314151617181920212223242526272829303132333435363738394041def build_roi_keypoint_head(cfg, in_channels): return ROIKeypointHead(cfg, in_channels)class ROIKeypointHead(torch.nn.Module): def __init__(self, cfg, in_channels): super(ROIKeypointHead, self).__init__() self.cfg = cfg.clone() self.feature_extractor = make_roi_keypoint_feature_extractor(cfg, in_channels) self.predictor = make_roi_keypoint_predictor( cfg, self.feature_extractor.out_channels) self.post_processor = make_roi_keypoint_post_processor(cfg) self.loss_evaluator = make_roi_keypoint_loss_evaluator(cfg) def forward(self, features, proposals, targets=None): """ Arguments: features (list[Tensor]): feature-maps from possibly several levels proposals (list[BoxList]): proposal boxes targets (list[BoxList], optional): the ground-truth targets. Returns: x (Tensor): the result of the feature extractor proposals (list[BoxList]): during training, the original proposals are returned. During testing, the predicted boxlists are returned with the `mask` field set losses (dict[Tensor]): During training, returns the losses for the head. During testing, returns an empty dict. """ if self.training: with torch.no_grad(): proposals = self.loss_evaluator.subsample(proposals, targets) x = self.feature_extractor(features, proposals) kp_logits = self.predictor(x) if not self.training: result = self.post_processor(kp_logits, proposals) return x, result, &#123;&#125; loss_kp = self.loss_evaluator(proposals, kp_logits) return x, proposals, dict(loss_kp=loss_kp)]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Faster-RCNN 源码实现 (PyTorch)]]></title>
    <url>%2Fz_post%2FPyTorch-FasterRCNN%2F</url>
    <content type="text"><![CDATA[我们知道, FasterRCNN 作为目标检测任务的一个标志性的检测模型, 在目标检测领域具有十分广泛的应用, 其模型原理主要包含以下几个重要的组成部分: BackBone: VGG, ResNet等 RoIPool: 感兴趣区域池化层 RPN: 候选框区域推荐网络, FasterRCNN最主要的贡献点 接下来, 我们就按照上面的模块划分, 介绍一下 FasterRCNN 的具体实现(源码地址: https://github.com/jwyang/faster-rcnn.pytorch). RPNRPN 网络是在 FasterRCNN 中提出来的, 也算是 FasterRCNN 的核心所在. rpn.py 文件:该文件定义了 RPN 的网络结构.由于 FasterRCNN 模型的突出贡献在于提出了 RPN 网络, 并且要实现 FasterRCNN 模型, 首先就需要实现 RPN 网络结构, 因此, 我们先来看一下如何利用 PyTorch 实现 RPN 的网络结构. init 函数123456789101112131415161718192021222324252627282930# ./lib/model/rpn/rpn.pyclass _RPN(nn.Module): def __init__(self, din): # 代表输入的特征图谱的深度, 如 512 super(_RPN, self).__init__() self.din = din # from model.utils.config import cfg self.anchor_scales = cfg.ANCHOR_SCALES self.anchor_ratios = cfg.ANCHOR_RATIOS self.feat_stride = cfg.FEAT_STRIDE[0] # 图片转化成特征图谱后缩小的尺寸倍数 # 定义 RPN 网络的卷积层 self.RPN_Conv = nn.Conv2d(self.din, 512, 3, 1, 1, bias=True) # kernel size为3, stride 和 padding 为1, 所以输出图谱的尺寸不变. # 定义前景和后景的分类层 self.nc_score_out = len(self.anchor_scales) * len(self.anchor_ratios) * 2 # 输出深度为 2(前/后景) * 9 (9个anchors) self.RPN_cls_score = nn.Conv2d(512, self.nc_score_out, 1, 1, 0) # 输出尺寸不变, 深度变为 2*9. 对应9个anchor box的前后景概率. # 定义anchor box的坐标偏移量预测层 self.nc_bbox_out = len(self.anchor_scales) * len(self.anchor_ratios) * 4 # 输出的深度(channels), 对应 9 个anchor boxes 的 4 个坐标 self.RPN_bbox_pred = nn.Con2d(512, self.nc_bbox_out, 1, 1, 0) # 定义 proposal 层, from .proposal_layer import _ProposalLayer self.RPN_proposal = _ProposalLayer(self.feat_stride, self.anchor_scales, self.anchor_ratios) # 定义 anchor 匹配层(将anchor于gt匹配), from .anchor_target_layer import _AnchorTargetLayer self.RPN_anchor_target = _AnchorTargetLayer(self.feat_stride, self.anchor_scales, self.anchor_ratios) self.rpn_loss_cls = 0 self.rpn_loss_box = 0 在 RPN 网络类的初始化函数中, 可以看出, 除了定义预测预测分类和box坐标的两个卷积层外, 最关键的两行代码分别来自于 _ProposalLayer 和 _AnchorTargetLayer 这两个类, 前者定义在proposal_layer.py文件中, 后者定义在anchor_target_layer.py文件中. 因此, 在继续分析 RPN 网络的其他函数之前, 我建议你先看看这两个类的内部实现(点击名字直接跳转). reshape 函数将指定 tensor 的维度改变.1234567891011# ./lib/model/rpn/rpn.py@staticmethoddef reshape(x, d): input_shape = x.size() x = x.view( input_shape[0], # batch 不变 int(d), int(float(input_shape[1]*input_shape[2]) / float(d)), input_shape[3] # ? ) return x forward 函数123456789101112131415161718192021222324252627282930313233343536# ./lib/model/rpn/rpn.pydef foward(self, base_feat, im_info, gt_boxes, num_boxes): batch_size = base_feat.size(0) # 首先得到经过RPN网络第一层卷积的特征图谱 rpn_conv1 = F.relu(self.RPN_Conv(base_feat), inplace = True) # 获得rpn分类score, 1×1的卷积网络 rpn_cls_score = self.RPN_cls_score(rpn_conv1) rpn_cls_score_reshape = self.reshape(rpn_cls_score, 2) # 将score按照前后景概率reshape rpn_cls_prob_reshape = F.softmax(rpn_cls_score_reshape, 1) # 利用softmax在第一个维度上, 也就是前后景概率的维度上, 将socre转换为概率 rpn_cls_prob = self.reshape(rpn_cls_prob_reshape, self.nc_score_out) # 转化成每一类的概率 # 获取到 anchor boxes 的 offsets rpn_bbox_pred = self.RPN_bbox_pred(rpn_conv1) # proposal layer 候选框提取层 cfg_key = "TRAIN" if self.training else "TEST" # 输入给 RPN_proposal 对应的 forward 函数的 input 是一个包含4个元素的元组 rois = self.RPN_proposal((rpn_cls_prob.data, rpn_bbox_pred.data, im_info, cfg_KEY)) self.rpn_loss_cls = 0 self.rpn_loss_box = 0 # 生成训练时产生的预测结果, 并且构造rpn损失 if self.training: assert gt_boxes is not None # 利用 RPN_anchor_target 得到rpn的计算结果 rpn_data = self.RPN_anchor_target((rpn_cls_score.data, gt_boxes, im_info, num_boxes)) # TODO loss的计算 # 计算分类 loss # 计算 bbox 回归 loss proposal_layer.py 文件该文件中定义了类 _ProposalLayer, 其功能主要是根据规则的 anchor box 生成对应的 proposal box init() 函数1234567891011121314# ./lib/model/rpn/proposal_layer.pyclass _ProposalLayer(nn.Module): """ 该类通过在一系列的标准box(anchor box)上应用 estimated bounding-box transformations 来输出目标检测的候选框 """ def __init__(self, feat_stride, scales, ratios): super(_ProposalLayer, self).__init__() self._feat_stride = feat_stride # 图谱缩小的倍数 # from .generate_anchors import generate_anchors self._anchors = torch.from_numpy(generate_anchors(scales=np.array(scales), ratios=np.array(ratios))).float() self._num_anchors = self._anchors.size(0) 在上面的初始化函数中, 我们可以看到, 调用了 generate_anchors (位于文件 generate_anchor.py中)函数来生成标准的box (anchor box). forward() 函数接下来, 我们具体看一下该类的 foraward() 函数的实现方法, 其实现过程体现了 RoI 的生成方式. 1234567891011121314151617181920# ./lib/model/rpn/proposal_layer.pydef foward(self, input): # 算法: # 对于每一个 location i 上的 (H,W) # 生成以cell i 为中心的 A 个 anchor boxes # 将所有预测的到 bbox deltas 应用到 A 个 anchors 上面 # 在图像上截取该 boxes # 移除掉那些宽度或高度不满足要求的 predicted boxes # 按照score从高到低对proposal排序 # 应用NMS筛选一定数量的proposals # 在NMS筛选出的proposals中选取N个 # 返回 top N proposals scores = input[0][:, self._num_anchors:, :, :] bbox_deltas = input[1] im_info = input[2] cfg_key = input[3] pre_nms_topN = cfg 其他函数12# ./lib/model/rpn/proposal_layer.pydef backward(self, ): 12# ./lib/model/rpn/proposal_layer.pydef reshape(self, bottom, top): 12# ./lib/model/rpn/proposal_layer.pydef _filter_boxes(): generate_anchors.py 文件该文件的功能主要用于生成规则的 anchor box.在 class _ProposalLayer 的初始化函数中, 我们可以看到, 调用了 generate_anchors() 函数来生成标准的box (anchor box), 该函数的具体实现如下: 1234567# ./lib/model/rpn/generate_anchors.pydef generate_anchors(base_size=16, ratios=[0.5, 1, 2], scales=2**np.arange(3, 6)): # ** 代表幂次, 所以 scales = [2^3, 2^4, 2^5] = [8,16,32] """base_anchor 的大小为 16×16的, 其坐标为(0,0,15,15)""" base_anchor = np.array([1, 1, base_size, base_size]) - 1 # base_anchor = array([ 0, 0, 15, 15]) # _ratio_enum 为本文件内定义的函数, 作用为相对于每一个anchor枚举所有可能ratios的anchor box.(注意, base_anchor的size只是作用一个过渡使用, 后面的语句会利用scales参数将其覆盖) ratio_anchors = _ratio_enum(base_anchor, ratios) # 在给定anchor下, 根据scale的值枚举所有可能的anchor box anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales) for i in range(ratio_anchors.shape[0])]) whctrs 函数1234567# ./lib/model/rpn/generate_anchors.pydef _whctrs(anchor): # 返回一个anchor的宽, 高, 以及中心点的(x,y)坐标值 w = anchor[2] - anchor[0] + 1 # eg:15-0+1 = 16 h = anchor[3] - anchor[1] + 1 # eg:15-0+1 = 16 x_ctr = anchor[0] + 0.5 * (w-1) # eg: 0+0.5*(16-1) = 7.5 y_ctr = anchor[1] + 0.5 * (h-1) # eg:0+0.5*(16-1) = 7.5 mkanchors 函数12345678910# ./lib/model/rpn/generate_anchors.pydef _mkanchors(ws, hs, x_ctr, y_ctr): # 给定一组围绕中心点(x_ctr, y_ctr) 的 widths(ws) 和 heights(hs) 序列, 输出对应的 anchors ws = ws[:, np.newaxis] hs = hs[:, np.newaxis] # anchors里面的坐标分别对应着左上角的坐标和右下角的坐标 anchors = np.hstack((x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1), x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1))) ratio_enum 函数相对于每一个anchor, 遍历其所有可能ratios对应的anchors123456789# ./lib/model/rpn/generate_anchors.pydef _ratio_enum(anchor, ratios): w, h, x_ctr, y_ctr = whctrs(anchor) # 返回一个anchor的宽, 高, 以及中心点的(x,y)坐标值 size = w * h size_ratios = size / ratios ws = np.round(np.sqrt(size_ratios)) hs = np.round(ws * ratios) anchors = _mkanchors(ws, hs, x_ctr, y_ctr) return anchors scale_enum() 函数12345678# ./lib/model/rpn/generate_anchors.pydef _scale_enum(anchor, scales): # 根据给定的anchor(box), 枚举其所有可能scales的anchors(boxes) w, h, x_ctr, y_ctr = _whctrs(anchor) ws = w * scales hs = h * scales anchors = _mkanchors(ws, hs, x_ctr, y_ctr) return anchors anchor_target_layer.py 文件该文件中定义了class _AnchorTargetLayer(nn.Module), 可以将 anchors 和 groun-truth 匹配起来, 然后生成相应的分类标签和bounding-box的回归targets. init() 函数12# ./lib/model/rpn/anchor_target_layer.py/class _AnchorTargetLayer():def __init__(self, feat_stride, scales, ratios): forward() 函数12# ./lib/model/rpn/anchor_target_layer.py/class _AnchorTargetLayer():def __init(self, feat_stride, scales, ratios): backward() 函数12# ./lib/model/rpn/anchor_target_layer.py/class _AnchorTargetLayer():def backward(): reshape() 函数12# ./lib/model/rpn/anchor_target_layer.py/class _AnchorTargetLayer():def reshape(): unmap() 函数12# ./lib/model/rpn/anchor_target_layer.py 不是类内部的函数def _unmap(): compute_targets_batch() 函数12# ./lib/model/rpn/anchor_target_layer.py 不是类内部的函数def _compute_targets_batch(): bbox_transform.py 文件bbox_transform() 函数bbox_transform_batch() 函数bbox_transform_inv() 函数BackBoneFasterRCNN 采用的 backbone 主要有两种, 一种是经典简单的 VGG16 网络, 一种是提取能力更强的 ResNet网络, 接下来我们对这两个网络的实现进行代码说明. VGG16首先, 我们可以利用 PyTorch 的 torchvision.models 来载入 VGG16 模型(当然也可以自己实现, 不过这不在本文的讨论范围内), 从卷积核的size等信息可以看出, 这已经是优化过的 vgg16 网络, 在网络层参数设置上和原始的 vgg16 有略微不同, 但大体上结构是相似的, 如下所示: 12import torchvisionvgg = models.vgg16() 可以看一下 vgg16 网络的内部结构(可以依照此结构来复现 vgg16 网络):1print(vgg) 输出如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace) (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace) (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=1000, bias=True) )) ResNetResNet 的结构稍微复杂一些. 这里就不再贴出了, 不过和 VGGNet 相同, 都是利用 torchvision.mdoels 模块来导入的. Faster RCNN 模型结构在了解了以上两种模型骨架之后, 我们首先创建 Faster RCNN 的整个结构(包含 RoIPool 和 RPN, 不过, 这里只是先用作占位, 具体实现在后面). 123456789101112131415class _fasterRCNN(nn.Module): # 以单下划线开头, 表明为内部函数 """faster RCNN""" def __init__(self, classes, class_agnostic): super(_FasterRCNN, self).__init__() self.classes = classes # self.n_classes = len(self.classes) # 类别个数 self.class_agnostic = class_agnostic # 标志是否是类别不可知的, 默认为False, 即类别是可知的 # loss self.RCNN_loss_cls = 0 # 分类损失 self.RCNN_loss_bbox = 0 # 边框回归损失 # 定义RPN网络 # from model.rpn.rpn import _RPN self.RCNN_rpn = _RPN(self.dout_base_model) self. RoI Pooling]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>源码实现</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-数据结构(structures)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-structures%2F</url>
    <content type="text"><![CDATA[源码文件在 ./maskrcnn_benchmark/structures/ 文件夹中, 定义了许多检测模式使用的数据结构, 如 BoxList, ImageList 等, 下面我们就将对这些数据结构以后适用于它们的操作进行讲解, 涉及到的源码文件如下所示: bounding_box.py boxlist_ops.py image_list.py segmentation_mask.py bounding_box.py 文件解析该文件的主要内容就是定义了 class BoxList(object) 类, 该类用于表示一系列的 bounding boxes. 这些 boxes 会以 N×4 大小的 Tensor 来表示. 为了唯一的确定 boxes 在图片中的准确位置, 该类还保存了图片的维度, 另外, 也可以添加额外的信息到特定的 bounding box 中, 如标签信息. 文件概览该文件篇幅较长, 文件概览如下所示: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): def __init__(self, bbox, image_size, mode="xyxy"): # 初始化函数 # ... def add_field(self, field, field_data): self.extra_fields[field] = field_data def get_field(self, field): return self.extra_fields[field] def fields(self): return list(self.extra_fields.keys()) def _copy_extra_fields(self, bbox): for k, v in bbox.extra_fields.items(): self.extra_fields[k] = v def convert(self, mode): # ... def _split_into_xyxy(self): # ... def resize(self, size, *args, **kwargs): # ... def transpose(self, method): # ... def crop(self, box): # ... def to(self, device): # ... def __getitem__(self, item): # ... def __len__(self): return self.bbox.shape[0] def clip_to_image(self, remove_empty=True): # ... def area(self): # ... def copy_with_fields(self, fields): # ... def __repr__(self): # ... class BoxList 解析下面我们对该类进行解析, 由于这个类的定义比较长, 且这个文件没有外部函数, 所有的函数都是类的成员函数, 因此, 我们将这个类拆分来讲解, 以方便我们查阅. 初始化函数1234567891011121314151617181920212223242526272829303132333435363738394041424344# ./maskrcnn_benchmark/structures/bounding_box.pyimport torch# 转换标志FLIP_LEFT_RIGHT = 0FLIP_TOP_BOTTOM = 1class BoxList(object): # 该类用于表示一系列的 bounding boxes. 这些 boxes 会以 N×4 大小的 Tensor 来表示. # 为了唯一的确定 boxes 在图片中的准确位置, 该类还保存了图片的维度, # 另外, 也可以添加额外的信息到特定的 bounding box 中, 如标签信息. def __init__(self, bbox, image_size, mode="xyxy"): # bbox (tensor): n×4, 代表n个box, 如: [[0,0,10,10],[0,0,5,5]] # image_size: (width, height) # 根据 bbox 的数据类型获取对应的 device device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device("cpu") # 将 bbox 转换成 tensor 类型 bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device) # bbox 的维度数量必须为2, 并且第二维必须为 4, 即 shape=(n, 4), 代表 n 个 box if bbox.ndimension() != 2: raise ValueError( "bbox should have 2 dimensions, got &#123;&#125;".format(bbox.ndimension()) ) if bbox.size(-1) !=4: raise ValueError( "last dimension of bbox should have a" "size of 4, got &#123;&#125;".format(bbox.size(-1)) ) # 只支持以下两种模式 if mode not in ("xyxy", "xywh"): raise ValueError("mode should be 'xyxy' or 'xywh'") # 为成员变量赋值 self.bbox = bbox self.size = image_size self.mode = mode self.extra_fields = &#123;&#125; # 以字典结构存储额外信息 extra_fields 操作函数12345678910111213141516171819202122232425# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... # 添加新的键值或覆盖旧的键值 def add_field(self, field, field_data): self.extra_fields[field] = field_data # 获取指定键对应的值 def get_field(self, field): return self.extra_fields[field] # 判断额外信息中是否存在该键 def has_field(self, field): return field in self.extra_fields # 以列表的形式返回所有的键的名称 def fields(self): return list(self.extra_fields.keys()) # 将另一个 BoxList 类型的额外信息(字典)复制到到的额外信息(extra_fields)中. def _copy_extra_fields(self, bbox): for k, v in bbox.extra_fields.items(): self.extra_fields[k] = v convert() 模式转换函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... # 将当前 bbox 的表示形式转换成参数指定的模式 def convert(self, mode): # 只支持以下两种模式 if mode not in ("xyxy", "xywh"): raise ValueError("mode should be 'xyxy' or 'xywh'") if mode == self.mode: return self # 调用成员函数, 将坐标表示转化成 (x1,y1,x2,y2) 的形式 xmin, ymin, xmax, ymax = self._split_into_xyxy() if mode == "xyxy": # 如果模式为 "xyxy", 则直接将 xmin, ymin, xmax, ymax 合并成 n×4 的 bbox bbox = torch.cat((xmin, ymin, xmax, ymax), dim=-1) # 这里创建了一个新的 BoxList 实例 bbox = BoxList(bbox, self.size, mode) else: # 否则的话, 就将 xmin, ymin, xmax, ymax 转化成 (x,y,w,h) 后再连接在一起 TO_REMOVE = 1 torch.cat((xmin, ymin, xmax - xmin + TO_REMOVE, ymax - ymin + TO_REMOVE), dim=-1) # 创建新的 BoxList 实例 bbox = BoxList(bbox, self.size, mode=mode) # 复制当前实例的 extra_fields 信息到这个新创建的实例当中, 并将这个新实例返回 bbox._copy_extra_fields(self) return bbox # 获取 bbox 的 (x1,y1,x2,y2)形式的坐标表示, .split 为 torch 内置函数, 用于将 tensor 分成多块 def _split_into_xyxy(self): if self.mode == "xyxy": # x, y 的 shape 为 n × 1, 代表着 n 个 box 的 x, y 坐标 xmin, ymin, xmax, ymax = self.split(1, dim=-1) return xmin, ymin, xmax, ymax elif self.mode == "xywh": TO_REMOVE = 1 # 4 个 tensor 的 shape 均为 n×1 xmin, ymin, w, h = self.bbox.split(1, dim=-1) return( xmin, ymin, xmin + (w - TO_REMOVE).clamp(min=0), ymin + (w - TO_REMOVE).clamp(min=0), ) else: raise RuntimeError("Should not be here") resize() 放缩函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... # 将所有的 boxes 按照给定的 size 和图片的尺寸进行放缩, 创建一个副本存储放缩后的 boxes 并返回 def resize(self, *args, **kwargs): # size: 指定放缩后的大小 (width, height) # 计算宽和高的放缩比例(new_size/old_size) ratios = tuple(float(s) / float(s_orig) for s, s_orig in zip(size, self.size)) # 宽高放缩比例相同 if ratios[0] == ratios[1]: ratio = ratios[0] # 令所有的 bbox 都乘以放缩比例, 不论 bbox 是以 xyxy 形式还是以 xywh 表示 # 乘以系数就可以正确的将 bbox 的坐标转化到放缩后图片的对应坐标 scaled_box = self.box * ratio bbox = BoxList(scaled_box, size, mode=self.mode) # 复制/转化其他信息 for k, v in self.extra_fields.items(): if not isinstance(v, torch.Tensor): v = v.resize(size, *args, **kwargs) bbox.add_field(k, v) return bbox # 宽高的放缩比例不同, 因此, 需要拆分后分别放缩然后在连接在一起 ratio_width, ratio_height = ratios # 获取 bbox 的左上角和右下角的坐标 xmin, ymin, xmax, ymax = self._split_into_xyxy() # 分别对宽 (xmax, xmin) 和高 (ymax, ymin) 进行放缩 scaled_xmin = xmin * ratio_width scaled_xmax = xmax * ratio_width scaled_ymin = ymin * ratio_height scaled_ymax = ymax * ratio_height # 将左上角和右下角坐标连接起来, 组合放缩后的 bbox 表示 scaled_box = torch.cat( (scaled_xmin, scaled_ymin, scaled_xmax, scaled_ymax), dim=-1 ) bbox = BoxList(scaled_box, size, mode="xyxy") # 复制或转化其他信息 for k, v in self.extra_fields.items(): if k not isinstance(v, torch.Tensor): v = v.resize(size, *args, **kwargs) bbox.add_field(k, v) # 将 bbox 转换成指定的模式(因为前面强制转换成 xyxy 模式了, 所这里要转回去) retrun bbox.convert(self.mode) transpose() 图片翻转或旋转1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def transpose(self, method): # 对 bbox 进行转换(翻转或者旋转90度) # methon (int) 此处只能为 0 或 1, 目前仅仅支持两个转换方法 # FLIP_LEFT_RIGHT = 0, FLIP_TOP_BOTTOM = 1 # :param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`, # :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`, # :py:attr:`PIL.Image.ROTATE_180`, :py:attr:`PIL.Image.ROTATE_270`, # :py:attr:`PIL.Image.TRANSPOSE` or :py:attr:`PIL.Image.TRANSVERSE`. # 目前仅仅支持 FLIP_LEFT_RIGHT 和 FLIP_TOP_BOTTOM 两种方式 if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM): raise NotImplementedError( "Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented" ) # 获取图片的宽和高 image_width, image_height = self.size # 获取左上角和右下角的坐标 xmin, ymin, xmax, ymax = self._split_into_xyxy() if method == FLIP_LEFT_RIGHT: # method=0 TO_REMOVE = 1 transposed_xmin = image_width - xmax - TO_REMOVE transposed_xmax = image_width - xmin - TO_REMOVE transposed_ymin = ymin transposed_ymax = ymax elif method == FLIP_TOP_BOTTOM: transposed_xmin = xmin transposed_xmax = xmax transposed_ymin = image_height - ymax transposed_ymax = image_height - ymin # 将转换后的坐标组合起来形成新的 boxes transposed_boxes = torch.cat( (transposed_xmin, transposed_ymin, transposed_xmax, transposed_ymax), dim=-1 ) # 根据转换后的 boxes 坐标创建一个新的 BoxList 实例, 同时将 extra_fields 信息复制 bbox = BoxList(transposed_boxes, self.size, mode="xyxy") for k, v in self.extra_fields.items(): if not isinstance(v, torch.Tensor): v = v.transpose(method) bbox.add_field(k, v) # 将 bbox 的 mode 转换后返回 return bbox.convert(self.mode) crop() 裁剪函数123456789101112131415161718192021222324252627282930# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def crop(self, box): # box 是一个4元组, 指定了希望剪裁的区域的左上角和右下角 # 获取当前所有 boxes 的最左, 最上, 最下, 最右的坐标 xmin, ymin, xmax, ymax = self._split_into_xyxy() # 获取欲剪裁的 box 的宽和高 w, h = box[2] - box[0], box[3] - box[1] # 根据 box 指定的区域, 对所有的 proposals boxes 进行剪裁 # 即改变其坐标的位置, 如果发现有超出规定尺寸的情况, 则将其截断 cropped_xmin = (xmin - box[0]).clamp(min=0, max=w) cropped_ymin = (ymin - box[1]).clamp(min=0, max=h) cropped_xmax = (xmax - box[0]).clamp(min=0, max=w) cropped_ymax = (ymax - box[1]).clamp(min=0, max=h) # 将新的剪裁后的 box 坐标连接起来创建一个新的 BoxList 实例 bbox = BoxList(cropped_box, (w, h), mode="xyxy") # 复制其他信息 for k, v in self.extra_fields.items(): if not isinstance(v, torch.Tensor): v = v.crop(box) bbox.add_field(k, v) # 将 bbox 的模式转换成传入时的模式 return bbox.convert(self.mode) to() 设备转移函数将 BoxList 实例转化到指定的设备上(创建新实例返回). 1234567891011121314# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def to(self, device): # device: "cuda:x" or "cpu" # 将当前的 bbox 移动到指定的 device 上, 并且重新创建一个新的 BoxList 实例 bbox = BoxList(self.bbox.to(device), self.size, self.mode) # 深度复制 for k, v in self.extra_fields.items(): if hasattr(v, "to"): v = v.to(device) bbox.add_field(k, v) return bbox clip_to_image()该函数将 bbox 的坐标限制在 image 的尺寸内, 以便可以将边框显示在 image uh. 12345678910111213141516171819202122# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def clip_to_image(self, remove_empty=True): TO_REMOVE = 1 self.bbox[:, 0].clamp_(min=0, max=self.size[0] - TO_REMOVE) self.bbox[:, 1].clamp_(min=0, max=self.size[1] - TO_REMOVE) self.bbox[:, 2].clamp_(min=0, max=self.size[0] - TO_REMOVE) self.bbox[:, 3].clamp_(min=0, max=self.size[1] - TO_REMOVE) if remove_empty: box = self.bbox # 该语句会返回一个 n×1 的列表, 对应着 n 个 box, 如果 box 的坐标满足 # 下面的语句条件, 则对应位为 1, 否则 为 0, keep = (box[:, 3] &gt; box[:, 1]) &amp; (box[:, 2] &gt; box[:, 0]) # 返回那些对应位为 1 的 box return self[keep] return self area() 获取区域面积函数123456789101112131415# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def area(self): box = self.bbox if self.mode = "xyxy": TO_REMOVE = 1 # 一个像素点的面积我们认为是 1, 而不是 0 area = (box[:, 2] - box[:, 0] + TO_REMOVE) * (box[:, 3] - box[:, 1] + TO_REMOVE) elif self.mode == "xywh": # 直接令 w * h area = box[:, 2] * box[:, 3] else: raise RuntimeError("Should not be here") copy_with_fields() 深度复制函数连带 BoxList 的 extra_fields 信息进行复制, 返回一个新的 BoxList 实例 123456789101112131415# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def copy_with_fields(self, fields): bbox = BoxList(self.bbox, self.size, self.mode) if not isinstance(fields, (list, tuple)): # 将 fields 包裹在列表里面, 注意 [fields] 和 list(fields) 的区别 fields = [fields] # 遍历 fields 中的所有元素, 并将其添加到当前的 BoxList 实例 bbox 中 for field in fields: bbox.add_field(field, self.get_field(field)) return bbox 其他函数getitem(), len(), repr() 1234567891011121314151617181920212223242526272829303132# ./maskrcnn_benchmark/structures/bounding_box.pyclass BoxList(object): #... def __getitem__(self, item): # item 必须是列表类型 # 假设 bbox 是一个 BoxList 实例, 那么我们可以利用下面语句得到该实例的子集 # sub_bbox = bbox[[0,3,4,8]] # one_bbox = bbox[[2]] # 创建新的子集实例 bbox = BoxList(self.bbox[item], self.size, self.mode) # 复制其他信息 for k, v in self.extra_fields.items(): bbox.add_field(k, v[item]) return bbox def __len__(self): # 获取当前 BoxList 中含有的 box 的数量 return self.bbox.shape[0] def __repr__(self): # 改变 print(BoxList_a) 的打印信息, 使之显示更多的有用信息, 示例如下: # BoxList(num_boxes=2, image_width=10, image_height=10, mode=xyxy) s = self.__class__.__name__ + "(" s += "num_boxes=&#123;&#125;, ".format(len(self)) s += "image_width=&#123;&#125;, ".format(self.size[0]) s += "image_height=&#123;&#125;, ".format(self.size[1]) s += "mode=&#123;&#125;)".format(self.mode) return s boxlist_ops.py该文件定义了一些与 BoxList 类型数据有关的操作, 根据函数的相互调用关系, 可以分为以下四个主要的函数: boxlist_nms(): remove_small_boxes(): boxlist_iou(): cat_boxlist(): 下面我们按照顺序对分别上面的函数进行解析 boxlist_nms() 函数该函数会对一个 BoxList 类型数据中的 box 执行非极大值抑制算法, 这些 box 的 socre 值可以通过 score_field 获取, 代码的核心逻辑实际上是调用了 ./maskrcnn_benchmark/layers/nms.py 文件中的 _box_nms() 函数, 关于该函数的详细解析可以看 nms 解析 12345678910111213141516171819202122232425# ./maskrcnn_benchmark/structures/boxlist_ops.pydef boxlist_nms(boxlist, nms_thresh, max_proposals=-1, score_field="score"): # boxlist (BoxList) # nms_thresh (float) # max_proposals (int): top-k # score_field (str): 键 if nms_thresh &lt;= 0: return boxlist mode = boxlist.mode # 缓存当前的模式 boxlist = boxlist.convert("xyxy") # 转换成指定模式 boxes = boxlist.bbox # 获取 n*4 的 bbox 列表 score = boxlist.get_field(score_field) # 获取对应的 socre 列表 # 调用 _box_nms 执行非极大值抑制抑制 keep = _box_nms(boxes, score, nms_thresh) if max_proposals &gt; 0: # 只保留 top-k keep = keep[: max_proposals] # keep为下标列表, 指示了需要保存哪些box, 这里已经重写了 __getitem__ 方法, 因此会根据下标返回 BoxList boxlist = boxlist[keep] return boxlist.convert[mode] remove_small_boxes() 函数该函数执行后, BoxList 中只会保留那些尺寸大于一定值的区域 box. 123456789101112131415# ./maskrcnn_benchmark/structures/boxlist_ops.pydef remove_small_boxes(boxlist, min_size): # boxlist (BoxList) # min_size (int) # 获取 xywh 形式的bbox列表 xywh_boxes = boxlist.convert("xywh").bbox # torch 的 unbind 函数, 用于 "移除" tensor 的维度, _, _, ws, hs = xywh_boxes.unbind(dim=1) keep = ( (ws &gt;= min_size) &amp; (hs &gt;= min_size) ).() boxlist_iou() 函数 cat_boxlist() 函数该函数会将一个组成元素为 BoxList 的列表合并成一个 BoxList 对象. 注意, 列表中的 BoxList 对象必须具有相同 image size. 1234567891011121314151617181920212223242526272829303132333435# ./maskrcnn_benchmark/structures/boxlist.pydef cat_boxlist(bboxes): # bboxes (list[BoxList]) # 确保类型为列表或元组, 且其中元素类型为 BoxList assert isinstance(bboxes, (list, tuple)) assert all(isinstance(bbox, BoxList) for bbox in bboxes) # 确保所有的 BoxList 的 size , mode, 以及 extra_fields 字典的 keys 是相同的 size = bboxes[0].size assert all(bbox.size == size for bbox in bboxes) mode = bboxes[0].mode assert all(bbox.mode == mode for bbox in bboxes) fields = set(bboxes[0].fields()) # 获取字典的所有 key 值 assert all(set(bbox.fields()) == fields for bbox in bboxes) # 调用本文件的 _cat() 方法, 将 bboxes 里面的 BoxList 数据连接成一个 BoxList, 具体解析看下方 cat_boxes = BoxList(_cat([bbox.bbox for bbox in boxes], dim=0), size, mode) # 将各个 BoxList 的 fields 补充上 for field in fields: data = _cat([bbox.get_field(field) for bbox in bboxes], dim=0) cat_boxes.add_field(field, data) return cat_boxesdef _cat(tensors, dim=0): # 调用 torch.cat 将数据连接 assert isinstance(tenosrs, (list, tuple)) if len(tensors) == 1: return tensors[0] return torch.cat(tensors, dim) image_list.py segmentation_mask.py]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-训练/推演核心代码(engine)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-engine%2F</url>
    <content type="text"><![CDATA[源码文件./maskrcnn_benchmark/engine/trainer.py./maskrcnn_benchmark/engine/inference.py 模型测试/推演时, 无需计算每个参数的梯度, 因此会大大减少 GPU 的显存占用空间 trainer.py 文件概览本文件中的代码是用来定义模型训练的步骤的, 当我们确定了模型, 数据集载入器, 优化器, 更新策略等相关组件以后, 就可以调用该文件中的函数来进行模型训练, 下面先简单看一下本文件的函数概览. 123456789101112# ./maskrcnn_benchmark/engine/trainer.py# 导入各种包及函数import torchdef reduce_loss_dict(loss_dict): # 计算 reduce 后的损失函数字典 # ...def do_train(...): # 模型训练核心代码 # ... trainer 导入各种包及函数下面是本文件导入的包及函数, 我们会对这些包进行简要的介绍, 并且会给出详细解析的博文链接. 12345678910111213# ./maskrcnn_benchmark/engine/trainer.py# 常规包import datetimeimport loggingimport timeimport torchimport torch.distributed as dist # 分布式相关from maskrcnn_benchmark.utils.comm import get_world_sizefrom maskrcnn_benchmark.utils.metric_logger import MetricLogger get_world_size: 该函数封装了 troch.distributed.get_world_size() 函数, 位于 ./maskrcnn_benchmark/utils/comm.py 文件中, 详细解析请看commMetricLogger: 该类中包含了同文件的 SmoothedValue 类作为其数据成员, SmoothedValue 类用于跟踪一系列的值, 同时还会提供访问这些值的滑动平均值或全局平均值, 而位于 MetricLogger 定义了将这些值打印到屏幕或保存到文件中的代码, 这两个类位于 ./maskrcnn_benchmark/utils.metric_logger 文件中, 详细解析请看metric_logger trainer.do_train() 模型训练核心函数我们按照函数的一般调用顺序, 首先来看看模型训练的核心逻辑代码的实现, 具体如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# ./maskrcnn_benchmark/engine/trainer.pydef do_train( model, # 从 build_detection_model 函数得到的模型对象 data_loader, # PyTorch 的 DataLoader 对象, 对应自己的数据集 optimizer, # torch.optim.sgd.SGD 对象 scheduler, # 学习率的更新策略, 封装在 solver/lr_scheduler.py 文件中 checkpointer, # DetectronCheckpointer, 用于自动转换 Caffe2 Detectron 的模型文件 device, # torch.device, 指定训练的设备 checkpoint_period, # 整形, 指定了模型的保存迭代间隔, 默认为 2500 arguments, # 额外的其他参数, 字典类型, 一般情况只有 arguments[iteratioin], 初值为0): # 记录日志信息 logger = logging.getLogger("maskrcnn_benchmark.trainer") logger.info("Start training") # 用于记录一些变量的滑动平均值和全局平均值 meters = MetricLogger(delimiter=" ") # delimiter为定界符, 这里用两个空格作为定界符 # 数据载入器重写了 len 函数, 使其返回载入器需要提供batch的次数, 即 cfg.SOLVER.MAX_ITER max_iter = len(data_loader) start_iter = arguments["iteration"] # 默认为0, 但是会根据载入的权重文件, 变成其他值. model.train() # 将 model 的模式置为 train, train() 函数的参数 mode 默认值为True. start_training_time = time.time() end = time.time() # 计时 # 遍历 data_loader, 第二个参数是设置序号的开始序号, # data_loader 的返回值为(images, targets, shape) for iteration, (images, targets, _) in enumerate(data_loader, start_iter): data_time = time.time() - end # 获取一个 batch 所需的时间 iteration = iteration + 1 arguments["iteration"] = iteration scheduler.step() # 更新一次学习率 images = images.to(device) # 把 images 移动到指定设备上 targets = [target.to(device) for target in targets] # 移动到指定设备上 loss_dict = model(images, targets) # 根据 images 和 targets 计算 loss losses = sum(loss for loss in loss_dict.values()) # 将各个loss合并 # 根据 GPUs 的数量对 loss 进行 reduce, 详细请看关于 reduce_loss_dict() 函数的解析 loss_dict_reduced = reduce_loss_dict(loss_dict) losses_reduced = sum(loss for loss in loss_dict_reduced.values) # 合并loss meters.update(loss=losses_reduced, **loss_dict_reduced) # 更新滑动平均值 optimizer.zero_grad() # 清除梯度缓存 losses.backward() # 计算梯度 optimizer.step() # 更新参数 batch_time = time.time()-end # 进行一次 batch 所需时间 end = time.time() meters.update(time=batch_time, data=data_time) # 根据时间的滑动平均值计算大约还剩多长时间结束训练 eta_seconds = meters.time.global_avg * (max_iter - iteration) eta_string = str(datetime.timedelta(seconds=int(eta_seconds))) # 每经过20次迭代, 输出一次训练状态 if iteration % 20 == 0 or iteration == max_iter: logger.info( meters.delimiter.join( [ "eta: &#123;eta&#125;", "iter: &#123;iter&#125;", "&#123;meters&#125;", "lr: &#123;lr:.6f&#125;", "max mem: &#123;memory:.0f&#125;", ] ).format( eta=eta_string, iter=iteration, meters=str(means), lr=optimizer.param_groups[0]["lr"], memory=torch.cuda.max_memory_allocated() / 1024.0 / 1024.0, ) ) # 每经过 checkpoint_period 次迭代后, 就将模型保存 if iteration % checkpoint_period == 0: checkpointer.save("model_&#123;:07d&#125;".format(iteration), **arguments) # 达到最大迭代次数后, 也进行保存 if iteration == max_iter: checkpointer.save("model_final", **arguments) # 输出总的训练耗时 total_training_time = time.time() - start_training_time total_time_str = str(datetime.timedelta(seconds=total_training_time)) logger.info( "Total training time: &#123;&#125; (&#123;:.4f&#125; s / it)".format( total_time_str, total_training_time / (max_iter) ) ) trainer.reduce_loss_dict() 计算 reduced_loss下面的代码会计算多 GPU 时的 reduce loss, 直接来看代码解析: 123456789101112131415161718192021222324252627# ../maskrcnn_benchmark/engine/trainer.pydef reduce_loss_dict(loss_dict): # 对loss进行reduce, 使其可以利用 rank 0进行处理 world_size = get_world_size() if world_size &lt; 2: # 单 GPU, 直接返回, 无需reduce return loss_dict with torch.no_grad(): # 不要计算任何参数的梯度 loss_names = [] all_losses = [] for k, v in loss_dict.items(): loss_names.append(k) # 获取键 all_losses.append(v) # 获取值 # 将列表中的 loss 连接起来组成一个一维的tensor, tensor的每个元素代表一个 loss. all_losses = torch.stack(all_losses, dim=0) # import torch.distributed as dist dist.reduce(all_losses, dst=0) if dist.get_rank() == 0: # only main process gets accumulated, so only divide by # world_size in this case call_losses /= world_size reduced_losses = &#123;k: v for k, v in zip(loss_nams, all_losses)&#125; return reduced_losses inference.py 文件概览该文件定义了模型推演时的代码逻辑, 在拥有预训练的模型文件时, 可以通过调用本文件的函数来进行模型测试或模型推演, 文件的函数概览如下所示: 1234567891011121314151617# ./maskrcnn_benchmark/engine/inference.py# 导入各种包及函数import torch# ...def compute_on_dataset(model, data_loader, device): # 计算结果 # ...def _accumulate_predictions_from_multiple_gpus(predictions_per_gpu): # 累积预测 # ...def inference(...): # 模型测试/推演核心代码 # ... inference 导入各种包及函数我们首先来看看该文件导入了哪些包及函数 12345678910111213141516# ./maskrcnn_benchmark/engine/inference.py# 导入常规包import datetimeimport loggingimport timeimportimport torchfrom tqdm import tqdm# 导入评价函数, 包含 coco_evaluation 和 voc_evaluationfrom maskrcnn_benchmark.data import datasetsfrom ..utils.comm import is_main_processfrom ..utils.comm import scatter_gatherfrom ..utils.comm import synchronize evaluate: 该函数封装了 coco_evaluation 和 voc_evaluation, 具体解析可以查看data.其余三个函数都来自 comm.py 文件, 详情着看 comm inference.inference() 模型测试/推演核心代码下面我们按照函数的调用顺序, 先来看看模型测试/推演的核心代码, 解析如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# ./maskrcnn_benchmark/engine/inference.pydef inference( model, # 从 build_detection_model 函数得到的模型对象 data_loader, # PyTorch 的 DataLoader 对象, 对应自定义的数据集 dataset_name, # str, 数据集的名字 iou_types=("bbox",), # iou的类型, 默认为 bbox box_only=False, # cfg.MODEL.RPN_ONLY="False" device="cuda", # cfg.MODEL.DEVICE="cuda" expected_results=(), # cfg.TEST.EXPECTED_RESULTS=[] expected_results_sigma_tol=4, # cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL=4 output_folder=None, # 自定义输出文件夹): # 获取设备 device = torch.device(divice) num_devices = ( torch.distributed.get_world_size() if torch.distributed.is_initialized else 1 ) # 日志信息 logger = logging.getLogger("maskrcnn_benchmark.inference") dataset = data_loader.dataset # 自定义的数据集类, 如 coco.COCODataset logger.info("Start evaluation on &#123;&#125; dataset(&#123;&#125; images).".format(dataset_name, len(dataset))) # 开始计时 start_time = time.time() # 调用本文件的函数, 获得预测结果, 关于该函数的解析可看后文 predictions = compute_on_dataset(model, data_loader, device) # 调用下面的语句, 使得等到所有的进程都结束以后再计算总耗时 synchronize() # 计算总耗时记入log total_time = time.time() - start_time total_time_str = str(datetime.timedelta(seconds=total_time)) logger.info( "Total inference time: &#123;&#125; (&#123;&#125; s / img per device, on &#123;&#125; devices)".format( total_time_str, total_time * num_devices / len(dataset), num_devices ) ) # 调用本文件的函数, 将所有GPU设备上的预测结果累加并返回 predictions = _accumulate_predictions_from_multiple_gpus(predictions) if output_folder: # 将结果保存 torch.save(predictions, os.path.join(output_folder, "predictions.pth")) extra_args = dict( box_only=box_only, iou_types=iou_types, expected_results=expected_results, expected_results_sigma_tol=expected_results_sigma_tol, ) # 调用评价函数, 返回预测结果的质量 return evaluate( dataset=dataset, predictions=predictions, output_folder=output_folder, **extra_args ) inference.compute_on_dataset() 计算结果在上面的函数中, 调用了 compute_on_dataset() 函数来获得预测结果, 该函数的主要逻辑就是利用训练好的模型来预测模型的输出, 然后再将放在字典里返回, 代码解析如下: 123456789101112131415161718# ./maskrcnn_benchmark/engine/inference.pydef compute_on_dataset(model, data_loader, device): model.eval() # 将模型状态置于eval, 主要影响 dropout, BN 等操作的行为 results_dict = &#123;&#125; cpu_device = torch.device("cpu") for i, batch in enumerate(tqdm(data_loader)): images, targets, image_ids = batch images = images.to(device) # 将图片移动至 gpu 上(默认device="cuda") with torch.no_grad(): # 使用model运算时, 不用计算梯度 output = model(images) output = [o.to(cpu_device) for o in output] # 将计算结果转移到cpu上 # 更新结果字典 results_dict.update( &#123;img_id: result for img_id, result in zip(image_ids, output)&#125; ) return results_dict inference._accumulate_predictions_from_multiple_gpus()由于 MaskrcnnBenchmark 默认是支持分布式的, 因此可以在多个 GPU 上计算结果, 但是最终需要把所有的结果都合并起来, 这正是 _accumulate_predictions_from_multiple_gpus() 的功能, 函数解析如下: 1234567891011121314151617181920212223# ./maskrcnn_benchmark/engine/inference.pydef _accumulate_predictions_from_multiple_gpus(predictions_per_gpu): # from ..utils.comm import scatter_gather all_predictions = scatter_gather(predictions_per_gpu) if not is_main_process(): return # merge the list of dicts predictions = &#123;&#125; for p in all_predictions: predictions.update(p) # convert a dict where the key is the index in a list image_ids = list(sorted(predictions.keys())) if len(image_ids) != image_ids[-1] + 1: logger = logging.getLogger("maskrcnn_benchmark.inference") logger.warning( "Number of images that were gathered from multiple processes is not " "a contiguous set. Some images might be missing from the evaluation" ) # convert to a list predictions = [predictions[i] for i in image_ids] return predictions]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-训练/推演工具脚本(tools)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-tools%2F</url>
    <content type="text"><![CDATA[源码文件 ./tools/train_net.py ./tools/test_net.py train_net.py 文件概览为了更好的解读 MaskrcnnBenchmark 的源代码, 我们首先来看看执行模型训练代码的脚本文件都使用了哪些类和函数, 该脚本可以训练 MaskrcnnBenchmark 中的所有模型, 因此, 我们可以从该文件出发, 顺藤摸瓜的探索, 以期最终能够对整个 MaskrcnnBenchmark 框架有一个全面系统的了解, 那么接下来就先来改一下该文件的大致结构, 如下所示: 12345678910111213141516# 导入各种包from maskrcnn_benchmark.config import cfg#...def train(cfg, local_rank, distributed): # ... 训练脚本核心代码def test(cfg, model, distributed): # ... 推演代码def main(): # ... 主函数, 会在内部调用上述函数if __name__ == "__main__": main() train_net 导入的各种包和函数首先来看看该文件导入了那些包和函数, 同时我们会针对性的简单介绍一下它们的主要作用和功能.123456789101112131415161718192021222324252627282930313233343536# ./tools/train_net.py# 下面的这个必须在导入所有包之前导入, 不能放到其他位置. TODO 原因from maskrcnn_benchmark.utils.env import setup_environment# 常规包import argparseimport osimport torchfrom maskrcnn_benchmark.config import cfg # 导入默认配置信息from maskrcnn_benchmark.data import make_data_loader # 数据集载入from maskrcnn_benchmark.solver import make_lr_scheduler # 学习率更新策略from maskrcnn_benchmark.solver import make_optimizer # 设置优化器, 封装了PyTorch的SGD类from maskrcnn_benchmark.engine.inference import inference # 推演代码from maskrcnn_benchmark.engine.trainer import do_train # 模型训练的核心逻辑. 会重点解析# 调用了 ./maskrcnn_benchmark/modeling/detector/ 中的 build_detection_model() 函数# 该函数和 Detectron 中的类似, 都是用来创建目标检测模型的, 这也是创建模型的入口函数, 十分重要from maskrcnn_benchmark.modeling.detector import build_detection_modelfrom maskrcnn_benchmark.checkpoint import DetectronCheckpointer# 封装了 PyTorch 的 torch.utils.collect_env.get_preety_env_info 函数, 同时附加了 PIL.__version__ 版本新from maskrcnn_benchmark.utils.collect_env import collect_env_info# 分布式训练相关设置, 由于我的gpu个数为1, 因此 get_rank() 会返回 0from maskrcnn_benchmark.utils.comm import synchronize, get_rankfrom maskrcnn_benchmark.utils.imports import import_file# 封装了 logging 模块, 用于向屏幕输出一些日志信息from maskrcnn_benchmark.utils.logger import set_up_logger# 封装了 os.mkdirs 函数, 当文件夹已存在时会自动略过, 不会提示错误from maskrcnn_benchmark.utils.miscellaneous import mkdir cfg: 详情可看MaskrcnnBenchmark 默认配置 make_data_loader: 详情可看数组载入 make_lr_scheduler: 详情可看优化器及学习率更新策略 make_optimizer: 详情可看优化器及学习率更新策略 inference: 该函数是执行模型推演逻辑的核心代码, 具体的解析请看inference do_train: 该函数是执行模型训练逻辑的核心代码, 具体的解析请看do_train build_detection_model: 详情可看模型创建 DetectronCheckpointer: 详情可看DetectronCheckpoint collect_env_info: 详情可看collect_env_info synchronize 和 get_rank: 详情可看comm import_file: 详情可看imports set_logger: 详情可看logger mkdir: 详情可看mkdir 相比于 Detectron 来说, MaskrcnnBenchmark 的默认配置文件显得相当 “清爽”, 定义的配置项也很精简, 下面就是 cfg 的部分配置清单, 输入 print(cfg) 即可看到全部配置项.12345678910111213141516171819202122DATALOADER: ASPECT_RATIO_GROUPING: True NUM_WORKERS: 4 SIZE_DIVISIBILITY: 0DATASETS: TEST: () TRAIN: ()INPUT: MAX_SIZE_TEST: 1333 MAX_SIZE_TRAIN: 1333 MIN_SIZE_TEST: 800 MIN_SIZE_TRAIN: 800 PIXEL_MEAN: [102.9801, 115.9465, 122.7717] PIXEL_STD: [1.0, 1.0, 1.0] TO_BGR255: TrueMODEL: BACKBONE: CONV_BODY: R-50-C4 FREEZE_CONV_BODY_AT: 2 OUT_CHANNELS: 1024 DEVICE: cuda# ... train_net.main() 主函数下面我们根据脚本的执行顺序, 先来看看主函数的代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# ./tools/train_net.pydef main(): parser = argparse.ArgumentParser(description="PyTorch Object Detection Training") parser.add_argument( # 这里虽然是 config-file, 但要用 args.config_file来访问, 不能用 args.config-file 访问. "--config-file", default="", metavar="FILE", help="path to config file", type=str, ) parser.add_argument("--local_rank", type=int, default=0) parser.add_argument( "--skip-test", dest="skip_test", help="Do not test the final model", action="store_true", ) parser.add_argument( "opts", help="Modify config options using the command-line", default=None, nargs=argparse.REMAINDER, # 这一行不能少 ) args = parser.parse_args() # 获取 gpu 的数量, 我电脑只有一个GPU, 故 num_gpus = 1 num_gpus = int(os.environ["WORLD_SIZE"]) if "WORLD_SIZE" in os.environ else 1 # 是否进行多GPU的分布式训练 args.distributed = num_gpus &gt; 1 # 设置分布式训练时的一些初始化信息 if args.distributed: torch.cuda.set_device(args.local_rank) torch.distributed.init_process_group( backend="nccl", init_method="env://" ) # 将 config_file 指定的配置项覆盖到默认配置项当中 cfg.merge_from_file(args.config_file) cfg.merge_from_list(args.opts) cfg.freeze() # 冻结所有的配置项, 防止修改 output_dir = cfg.OUTPUT_DIR if output_dir: # 这里封装了 os.mkdir, 使得当output_dir存在时, 会直接略过, 不会返回错误 mkdir(output_dir) # 下面的多行代码都是一些向屏幕上输出相关信息的日志代码 # 同时也会保存在 output_dir 文件夹下的 log.txt 文件内 # 输出的信息来源于自身系统以及配置文件中的信息 logger = setup_logger("maskrcnn_benchmark", output_dir, get_rank()) logger.info("Using &#123;&#125; GPUs".format(num_gpus)) logger.info(args) logger.info("Collecting env info (might take some time)") logger.info("\n" + collect_env_info()) logger.info("Loaded configuration file &#123;&#125;".format(args.config_file)) # 打开指定的配置文件, 并读取其中的相关信息, 将值存储在 config_str 中, 然后输出到屏幕上 with open(args.config_file, "r") as cf: config_str = "\n" + cf.read() logger.info(config_str) logger.info("Running with config:\n&#123;&#125;".format(cfg)) # 调用 train 函数, 该函数会执行模型训练的代码逻辑, 详解可看后文 model = train(cfg, args.local_rank, args.distributed) if not args.skip_test: # 同理, 该函数会执行模型推演的代码逻辑, 详情可看后文 test(cfg, model, args.distributed) train_net.train() 训练脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def train(cfg, local_rank, distributed): # 该语句调用了 ./maskrcnn_benchmark/modeling/detector/ 中的 build_detection_model() 函数 # 该函数和 Detectron 中的类似, 都是用来创建目标检测模型的, 这也是创建模型的入口函数, 十分重要 # 这里我们只需要知道该函数会根据我们的配置文件返回一个网络模型就可以了 model = build_detection_model(cfg) # 默认为 "cuda" device = torch.device(cfg.MODEL.DEVICE) model.to(device) # 将模型移到指定设备上 # 封装了 torch.optiom.SGD() 函数, 根据tensor的requires_grad属性构成需要更新的参数列表 optimizer = make_optimizer(cfg, model) # 根据配置信息设置 optimizer 的学习率更新策略 scheduler = make_lr_scheduler(cfg, optimizer) # 分布式训练情况下, 并行处理数据 if distributed: model = torch.nn.parallel.DistributedDataParallel( model, device_ids=[local_rank], output_device=local_rank, # this should be removed if we update BatchNorm stats broadcast_buffers=False, ) # 创建一个参数字典, 并将迭代次数置为0 arguments = &#123;&#125; arguments["iteration"] = 0 # 获取输出的文件夹路径, 默认为 '.', 这里建议将 cfg.OUTPUT_DIR 提前设置成自己的路径. output_dir = cfg.OUTPUT_DIR # 因为我只有一个gpu, 所以这里 save_to_disk=True save_to_disk = get_rank() == 0 # DetectronCheckpointer 对象, 后面会用在 do_train() 函数的参数 checkpointer = DetectronCheckpointer( cfg, model, optimizer, scheduler, output_dir, save_to_disk ) extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT) # 加载指定权重文件 arguments.update(extra_checkpoint_data) # 字典的update方法, 对字典的键值进行更新 # data_loader 的类型为列表, 内部元素类型为 torch.utils.data.DataLoader # 注意, 当is_train=True时, 要确保 cfg.DATASETS.TRAIN 的值为一个列表 # 并且必须指向一个或多个存在的anns文件, 默认情况下该值为空, 所以必须在配置文件中指定 data_loader = make_data_loader( cfg, is_train=True, is_distributed=distributed, start_iter=arguments["iteration"], ) checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD # 默认值为2500 do_train( model, data_loader, optimizer, scheduler, checkpointer, device, checkpoint_period, arguments, ) return model 在执行模型训练逻辑时, 该函数调用了 ./maskrcnn_benchmark/engine/trainer.py 文件中的 do_train()函数, 该函数是执行训练逻辑的核心代码, 具体的解析请看do_train 我们注意到, 在代码的第一句开头使用了 ./maskrcnn_benchmark/modeling/detector/ 文件夹下面的用来创建目标检测模型的函数, 这也是创建模型的入口函数, 十分重要. 关于该函数的详细解析可以查看讲解模型创建的博文, 这里只需要知道该函数会根据我们的配置文件返回一个模型就可以了, 如果想查看该模型的具体网络结构及其参数, 可以利用 print(model) 查看, 如下所示为当前当前配置信息下的部分结构信息:123456789101112131415161718192021GeneralizedRCNN( (backbone): Sequential( (body): ResNet( (stem): StemWithFixedBatchNorm( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): FrozenBatchNorm2d() ) (layer1): Sequential( (0): BottleneckWithFixedBatchNorm( (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): FrozenBatchNorm2d() ) (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): FrozenBatchNorm2d() (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): FrozenBatchNorm2d() (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): FrozenBatchNorm2d() )#... train_net.test() 推演脚本1234567891011121314151617181920212223242526272829303132def test(cfg, model, distributed): if distributed: model = model.module torch.cuda.empty_cache() # TODO check if it helps. releases unoccupied memory iou_types = ("bbox",) if cfg.MODEL.MASK_ON:# 如果mask为Ture, 则添加分割信息 iou_types = iou_types + ("segm",) output_folders = [None] * len(cfg.DATASETS.TEST) # 根据标签文件数确定输出文件夹数 dataset_names = cfg.DATASETS.TEST if cfg.OUTPUT_DIR: for idx, dataset_name in enumerate(dataset_names):# 遍历标签文件 output_folder = os.path.join(cfg.OUTPUT_DIR, "inference", dataset_name) mkdir(output_folder) # 创建输出文件夹 output_folders[idx] = output_folder # 将文件夹的路径名放入列表 # 根据配置文件信息创建数据集 data_loaders_val = make_data_loader(cfg, is_train=False, is_distributed=distributed) # 遍历每个标签文件, 执行 inference 过程. for output_folder, dataset_name, data_loader_val in zip(output_folders, dataset_names, data_loaders_val): inference( model, data_loader_val, dataset_name=dataset_name, iou_types=iou_types, box_only=cfg.MODEL.RPN_ONLY, device=cfg.MODEL.DEVICE, expected_results=cfg.TEST.EXPECTED_RESULTS, expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL, output_folder=output_folder, ) synchronize() # 多GPU推演时的同步函数 在执行模型的推演逻辑时, 该函数调用了 ./maskrcnn_benchmark/engine/inference.py 文件中的 inference()函数, 该函数是执行推演逻辑的核心代码, 具体的解析请看inference test_net.py 文件概览123456789101112# ./tools/test_net.py# 导入各种包及函数from maskrcnn_benchmark.config import cfg# ...# 主程序def main(): # ...if __name__ == "__main__": main() test_net 导入的各种包及函数我们首先看看该文件导入的包及函数 123456789101112131415161718192021222324252627# ./tools/test_net.pyfrom maskrcnn_benchmark.utils.env import setup_environment# 常规包import argparseimport osimport torchfrom maskrcnn_benchmark.config import cfg # 导入全局配置from maskrcnn_benchmark.data import make_data_loader # 数据载入器from maskrcnn_benchmark.engine.inference import inference # 模型推演函数from maskrcnn_benchmark.modeling.detector import build_detection_model # 创建模型from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointerfrom maskrcnn_benchmark.utils.collect_env import collect_env_infofrom maskrcnn_benchmark.utils.comm import synchronize, get_rankfrom maskrcnn_benchmark.utils.logger import setup_loggerfrom maskrcnn_benchmark.utils.miscellaneous import mkdir 可以看出, 在 ./tools/test_net.py 文件中导入的包和函数和 ./tools/train_net.py 差不多, 我们已经在之前简单介绍了这些包的功能和用途, 并给出了详细解析的链接, 这里我们就不再重复介绍, 有疑惑的可以翻到上面去看关于 train_net.py 导入的包及函数的解析. test_net.main() 主函数由于在进行模型推演时, 我们只需要准备好预训练文件, 数据集, 以及模型结构就可以完成整个推演过程, 因此在 test_net.py 脚本中只用了一个主函数来完成这些功能, 下面我们就来看看这个主函数的具体实现吧. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# ./tools/test_net.pydef main(): parser = argparse.ArgumentParser(description="PyTorch Object Detection Inference") # 权重文件路径 parser.add_argument( "--config-file", default="/private/home/fmassa/github/detectron.pytorch_v2/configs/e2e_faster_rcnn_R_50_C4_1x_caffe2.yaml", metavar="FILE", help="path to config file", ) # local_rank parser.add_argument("--local_rank", type=int, default=0) # 其他的配置选项 parser.add_argument( "opts", help="Modify config options using the command-line", default=None, nargs=argparse.REMAINDER, ) args = parser.parse_args() # 获取 gpu 数目 num_gpus = int(os.environ["WORLD_SIZE"]) if "WORLD_SIZE" in os.environ else 1 # 根据gpu数目设置distributed布尔变量 distributed = num_gpus &gt; 1 if distributed: torch.cuda.set_device(args.local_rank) torch.distributed.init_process_group( backend="nccl", init_method="env://" ) # 将指定的配置文件的设置覆盖到全局设置中 cfg.merge_from_file(args.config_file) cfg.merge_from_list(args.opts) cfg.freeze() # 冻结配置信息, 防止更改 save_dir = "" logger = setup_logger("maskrcnn_benchmark", save_dir, get_rank()) logger.info("Using &#123;&#125; GPUs".format(num_gpus)) logger.info(cfg) logger.info("Collecting env info (might take some time)") logger.info("\n" + collect_env_info()) # 根据配置信息创建模型 model = build_detection_model(cfg) # 将模型移动到指定设备上 model.to(cfg.MODEL.DEVICE) # 获取输出文件夹父路径 output_dir = cfg.OUTPUT_DIR # 加载权重 checkpointer = DetectronCheckpointer(cfg, model, save_dir=output_dir) _ = checkpointer.load(cfg.MODEL.WEIGHT) # 设置 iou 类型 iou_types = ("bbox",) if cfg.MODEL.MASK_ON: iou_types = iou_types + ("segm",) # 根据数据集的数量定义输出文件夹 output_folders = [None] * len(cfg.DATASETS.TEST) dataset_names = cfg.DATASETS.TEST # 创建输出文件夹 if cfg.OUTPUT_DIR: for idx, dataset_name in enumerate(dataset_names): output_folder = os.path.join(cfg.OUTPUT_DIR, "inference", dataset_name) mkdir(output_folder) output_folders[idx] = output_folder # 加载测试数据集 data_loaders_val = make_data_loader(cfg, is_train=False, is_distributed=distributed) # 对数据集中的数据按批次调用inference函数 for output_folder, dataset_name, data_loader_val in zip(output_folders, dataset_names, data_loaders_val): inference( model, data_loader_val, dataset_name=dataset_name, iou_types=iou_types, box_only=cfg.MODEL.RPN_ONLY, device=cfg.MODEL.DEVICE, expected_results=cfg.TEST.EXPECTED_RESULTS, expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL, output_folder=output_folder, ) synchronize()]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-乱七八糟]]></title>
    <url>%2Fz_post%2FPyTorch-MaskcnnBenchmark-%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F%2F</url>
    <content type="text"><![CDATA[command ‘gcc’ failed with exit status 1更换 gcc 版本.如果更换后, 会产生一大堆其他cpp文件错误, 则删除那些文件(我这里是在练习用的cpp文件夹下报错) https://github.com/facebookresearch/maskrcnn-benchmark/issues/25 command ‘:/usr/local/cuda/bin/nvcc’ failed with exit status 1https://github.com/facebookresearch/maskrcnn-benchmark/issues/132 12unable to execute &apos;:/usr/local/cuda/bin/nvcc&apos;: No such file or directoryerror: command &apos;:/usr/local/cuda/bin/nvcc&apos; failed with exit status 1 提示找不到 nvcc, 但是输入 nvcc --version, 却可以正常显示:1234nvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Sep__1_21:08:03_CDT_2017Cuda compilation tools, release 9.0, V9.0.176 仔细观察发现, 报错的路径里面多了一个冒号!!1unable to execute &apos;:/usr/local/cuda/bin/nvcc&apos;: No such file or directory 因此, 说明是环境变量的设置有问题, 将~/.zshrc(或者~/.bashrc)中进行如下修改123export CUDA_HOME=$CUDA_HOME:/usr/local/cuda# 将上面的语句修改成:export CUDA_HOME=/usr/local/cuda 然后, 刷新shell1exec $SHELL$ 接着, 删掉旧文件重新build12rm -rf buildpython setup.py build develop cocoModuleNotFoundError: No module named ‘pycocotools._ mask’有可能是换了虚拟环境导致访问不了 coco api, 也有可能是因为编译的时候没有成功, 或者没有安装 cython, 解决方案如下12345cd ~/githubgit clone https://github.com/cocodataset/cocoapi.gitcd cocoapi/PythonAPI# pip install cypthon 记住确保安装了 cypthonpython setup.py build_ext install 执行上面的步骤后依然报错, 仔细观察发现是指向了其他文件里的 _mask.py 文件, 这是由于我多次重复安装 coco api 导致的, 删除下面文件夹里面的 pycocotools 即可解决问题(最好再重新遍历一下) 1~/Works/PycharmProjects/tf_practice/models/research/pycocotools/mask.py in &lt;module&gt;() 数据载入报错12345678~/Works/maskrcnn-benchmark/maskrcnn_benchmark/data/build.py in build_dataset(dataset_list, transforms, dataset_catalog, is_train) 50 51 # for training, concatenate all datasets into a single one---&gt; 52 dataset = datasets[0] 53 if len(datasets) &gt; 1: 54 dataset = D.ConcatDataset(datasets)IndexError: list index out of range 一般是coco数据集放置位置不对, 或者没有找到 anns 标签文件等原因造成的错误. 重新设置软连接即可, 如果是在 jupyter notebook 中操作的, 注意还应该重启一下 kernel. 如果还不行, 则看看你是否缺少了相应的标签文件, MaskrcnnBenchmark 的默认标签文件为 Detectron 自定义的 coco_2014_minival 标签文件, 要确保你下载了该文件并把它放在了 datasets/coco/annotations/ 文件夹中, 下载地址为: https://github.com/facebookresearch/Detectron/blob/master/detectron/datasets/data/README.md. 另外还要确保参数 cfg.DATASETS.TRAIN 和 cfg.DATASETS.TEST 是有值的, 默认情况下只有后者不为空, 所以你需要自己给前者赋值]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
        <tag>源码实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-总览]]></title>
    <url>%2Fz_post%2FPyTorch-MaskcnnBenchmark%2F</url>
    <content type="text"><![CDATA[文件夹路径 文件 maskrcnn_benchmark/config/ maskrcnn_benchmark/csrc/ maskrcnn_benchmark/data/ maskrcnn_benchmark/engine/ maskrcnn_benchmark/layers/ maskrcnn_benchmark/modeling/ balanced_positive_negative_sampler.py, box_coder.py, matcher.py, poolers.py, registry.py, utils.py maskrcnn_benchmark/modeling/backbone/ backbone.py, fpn.py, resnet.py maskrcnn_benchmark/modeling/detector/ detectors.py, generalized_rcnn.py maskrcnn_benchmark/modeling/roi_heads/ maskrcnn_benchmark/modeling/roi_heads/box_head/ box_head.py, inference.py, loss.py, roi_box_feature_extractors.py, roi_box_predictors.py maskrcnn_benchmark/modeling/roi_heads/mask_head/ inference.py, loss.py, mask_head.py, roi_mask_feature_extractors.py maskrcnn_benchmark/modeling/rpn/ anchor_generator.py, inference.py, loss.py, rpn.py tests/ tools/]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-乱七八糟]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F%2F</url>
    <content type="text"><![CDATA[内存超限在 shell 中运行指令123456python tools/infer_simple.py \ --cfg configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml \ --output-dir ./demo/detectron-visualizations \ --image-ext jpg \ --wts https://s3-us-west-2.amazonaws.com/detectron/ImageNetPretrained/MSRA/R-50.pkl \ demo 报错:1RuntimeError: [enforce fail at context_gpu.cu:329] error == cudaSuccess. 2 vs 0. Error at: /home/zerozone/Works/Competition/DF/pytorch/caffe2/core/context_gpu.cu:329: out of memory 解决方案: https://github.com/facebookresearch/Detectron/issues/21 123456python2 tools/infer_simple.py \ --cfg configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_2x.yaml \ --output-dir /tmp/detectron-visualizations \ --image-ext jpg \ --wts https://s3-us-west-2.amazonaws.com/detectron/35857389/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_2x.yaml.01_37_22.KSeq0b5q/output/train/coco_2014_train%3Acoco_2014_valminusminival/generalized_rcnn/model_final.pkl \ demo 该指令运行模型所需显存大小不会超过 3GB 连接超时指令123456python2 tools/infer_simple.py \ --cfg configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_2x.yaml \ --output-dir /tmp/detectron-visualizations \ --image-ext jpg \ --wts https://s3-us-west-2.amazonaws.com/detectron/35857389/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_2x.yaml.01_37_22.KSeq0b5q/output/train/coco_2014_train%3Acoco_2014_valminusminival/generalized_rcnn/model_final.pkl \ demo 报错 1urllib.error.URLError: &lt;urlopen error [Errno 110] Connection timed out&gt; 说明无法通过 --wts 指令的 url 找到预下载的模型, 此时有可能你的模型没有下载成功, 可能已经下载成功, 但就是连不上, 对此, 可以在 Detectron 的 model zoo 里面找到对应的模型, 手动下载到本地, 然后更改 --wts 指令为本地路径, 如下所示.(如果你下载成功了, 但就是连接不上, 那么直接更改--wts参数即可).123456python tools/infer_simple.py \ --cfg configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_2x.yaml \ --output-dir ./demo/detectron-visualizations \ --image-ext jpg \ --wts ./detectron-download-cache/35857389/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_2x.yaml.01_37_22.KSeq0b5q/output/train/coco_2014_train%3Acoco_2014_valminusminival/generalized_rcnn/model_final.pkl \ demo 多gpu 非法内存multi-GPU training throw an illegal memory access 解决方案https://github.com/facebookresearch/Detectron/issues/32]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇异值分解(SVD)]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[奇异值分解(Singular Value Decomposition, SVD)是在机器学习领域广泛使用的算法, 本文是对SVD原理的一个梳理和总结, 并讨论在 PCA 降维算法中是如何运用 SVD 的. 1. 特征值分解(EVD)首先回顾下特征值和特征向量的定义如下: Ax = \lambda x其中, $A$ 是一个 $n\times n$ 的矩阵, $x$ 是一个 $n$ 维向量, $\lambda$ 是矩阵 $A$ 的一个特征值, 而 $x$ 是矩阵 $A$ 的特征值 $\lambda$ 所对应的特征向量. 方阵 $A_{n\times n}$ 可以做特征值分解的 充要条件 是其具有 $n$ 个线性无关的特征向量. 即 $A_{n\times n}$ 有 $n$ 个线性无关的特征向量时, $A_{n\times n}$ 才可以做特征值分解. 当我们求出了矩阵 $A$ 的 $n$ 个特征值 $\lambda_1 \leq \lambda_2 \leq … \leq \lambda_n$, 以及这 $n$ 个特征值所对应的特征向量 $w_1, w_2, …, w_n$, 我们就可以将矩阵 $A$ 分解成下面的形式: A = W \Sigma W^{-1}其中, $W$ 是这 $n$ 个特征向量组成的 $n\times n$ 维矩阵, 而 $\Sigma$ 为这 $n$ 个特征值为主对角线的 $n\times n$ 维矩阵. 一般我们都会把 $W$ 的这 $n$ 个特征向量标准化, 即满足 $| w_i|_2 = 1$, 或者 $w_i^T w_i = 1$, 此时 $W$ 的 $n$ 个特征向量为标准正交基, 满足 $W^T W = I$, 即 $W^T = W^{-1}$, 也就是说 $W$ 为正交阵. 这样我们的特征分解表达式可以进一步写成: A = W\Sigma W^T这里注意, 要进行特征分解, 矩阵 $A$ 必须是 方阵. 如果不是方阵, 即行和列不同时, 就需要使用奇异值分解(SVD). 2. SVD 的定义SVD 也是对矩阵进行分解, 但是和特征分解不同, SVD 并不要求分解的矩阵为方阵. 假设我们的矩阵 A 是一个 $m\times n$ 的矩阵, 那么我们定义矩阵 $A$ 的 SVD 为: A = U\Sigma V^T其中 $U$ 是一个 $m \times m$ 的矩阵, $\Sigma$ 是一个 $m\times n$ 的矩阵, 除了主对角线上的元素以外全为 0, 主对角线上的每个元素都称为奇异值, $V$ 是一个 $n \times n$ 的矩阵, $U$ 和 $V$ 都是正交矩阵, 既满足 $U^T U = I$, $V^T V = I$, 下图可以很形象的看出 SVD 的分解状态. 那么我们如何求出 SVD 分解后的 $U$, $\Sigma$, $V$ 这三个矩阵呢? 如果我们将 $A$ 的转置和 $A$ 做矩阵乘法, 那么就会得到一个 $n\times n$ 的方阵 $A^T A$, 由于 $A^T A$ 是方阵, 那么我们进而可以进行特征值分解(假设条件已经满足), 得到的特征值和特征向量如下式: (A^T A)v_i = \lambda_i v_i这样我们就可以得到矩阵 $A^T A$ 的 $n$ 个特征值和对应的 $n$ 个特征向量 $v_i$ 了. 然后将 $A^T A$ 的所有特征向量组织成一个 $n\times n$ 的矩阵 $V$, 该矩阵就是我们 SVD 公式里面的 $V$ 矩阵了, 一般我们将 $V$ 中的特征向量叫做 $A$ 的右奇异向量. 反过来, 如果我们将 $A$ 和 $A$ 的转置做矩阵乘法, 那么会得到一个 $m \times m$ 的方阵 $AA^T$, 同理, 我们可以对其进行特征分解, 得到的特征值和特征向量如下: (AA^T) u_i = \lambda_i u_i这样我们就得到了矩阵 $AA^T$ 的 $m$ 个特征值和对应的 $m$ 个特征向量 $u_i$. 同理, 我们将 $AA^T$ 的所有特征向量组织成一个 $m\times m$ 的矩阵 $U$, 该矩阵就是我们 SVD 公式里面的 $U$ 矩阵了. 一般我们将 $U$ 中的特征向量叫做 $A$ 的左奇异向量. 到现在为止, $U$ 和 $V$ 我们都求出来了, 现在就剩下奇异值矩阵 $\Sigma$ 没有求出了. 由于 $\Sigma$ 除了对角线上是奇异值, 其他位置都是0, 那么我们只需要求出每个奇异值 $\sigma$ 就可以了. 我们注意到: A = U\Sigma V^T \Longrightarrow AV = U\Sigma V^T V \Longrightarrow AV = U\Sigma \Sigma \Longrightarrow Av_i = \sigma_i u_i \Longrightarrow \sigma_i = Av_i / u_i根据上市我们就可以求出每个奇异值, 进而求出奇异值矩阵 $\Sigma$. 上面还有一个问题没有讲, 就是我们说 $A^T A$ 的特征向量组成的就是 SVD 的 V 矩阵, 而 $A A^T$ 的特征向量组成的矩阵 SVD 中的 $U$ 矩阵. 这有什么根据吗? 实际上, 证明如下(以 $V$ 为例): A = U \Sigma V^T \Longrightarrow A^T = V\Sigma U^T \Longrightarrow A^T A = V\Sigma U^T U\Sigma V^T = V\Sigma^2 V^T上面的证明过程使用了 $U^T U = I$, 和 $\Sigma^T = \Sigma$ 两个性质. 进一步还可以看出特征值矩阵等于奇异值矩阵的平方, 就是说特征值和奇异值满足以下关系: \sigma_i = \sqrt{\lambda_i}通过上式, 我们可以不用 $\sigma_i = \frac{Av_i}{u_i}$ 来计算奇异值, 也可以通过求出 $A^T A$ 的特征值取平方根来求奇异值. 3. SVD 计算举例 4. SVD 的一些性质对于奇异值, 它跟特征值分解中的特征值类似, 在奇异值矩阵中也是按照从大到小排列, 而且奇异值的下降速度很快, 在很多情况下, 前 10% 甚至 1% 的奇异值的和就站了全部奇异值之和的 99% 以上的比例. 也就是说, 我们可以用最大的 $k$ 个奇异值和对应的左右奇异值向量来近似描述矩阵, 即: A_{m\times n} = U_{m\times m} \Sigma_{m\times n} V^T_{n\times n} \approx U_{m\times k} \Sigma_{k\times k} V^T_{k\times n}其中, $k$ 要比 $\min(m, n)$ 小很多, 也就是一个大的矩阵 $A$ 可以用三个小的矩阵 $U_{m\times k} \Sigma_{k\times k} V^T_{k\times n}$ 来表示. 如下图所示, 矩阵 $A$ 只需要棕色部分的三个小矩阵就可以近似描述了.(在 Fast R-CNN 中对全连接层的矩阵使用了该方法降维). 由于这个重要的性质, SVD 可以很自然的用来进行 PCA 降维, 数据压缩和去噪. SVD 用于 PCA PCA 降维，需要找到样本协方差矩阵 $X^{T}X$ 的最大的 $d$ 个特征向量，然后用这最大的 $d$ 个特征向量张成的矩阵来做低维投影降维。可以看出，在这个过程中需要先求出协方差矩阵 $X^{T}X$ ，当样本数多样本特征数也多的时候，这个计算量是很大的。 注意到我们的SVD也可以得到协方差矩阵 $X^{T}X$ 最大的d个特征向量张成的矩阵，但是SVD有个好处，有一些SVD的实现算法可以不求先求出协方差矩阵 $X^{T}X$ ，也能求出我们的右奇异矩阵 $V$。也就是说，我们的PCA算法可以不用做特征分解，而是做 SVD 来完成。这个方法在样本量很大的时候很有效。实际上，scikit-learn 的 PCA 算法的背后真正的实现就是用的 SVD，而不是我们我们认为的暴力特征分解。 另一方面，注意到 PCA 仅仅使用了我们 SVD 的右奇异矩阵，没有使用左奇异矩阵，那么左奇异矩阵有什么用呢？ 假设我们的样本是 $m\times n$的矩阵 $X$，如果我们通过 SVD 找到了矩阵 $XX^{T}$ 最大的 $d$ 个特征向量张成的 $m\times d$ 维矩阵 $U$，则我们如果进行如下处理：可以得到一个 $d\times n$ 的矩阵 $X’$,这个矩阵和我们原来的 $m\times n$ 维样本矩阵 $X$ 相比，行数从 $m$ 减到了 $k$，可见对行数进行了压缩。左奇异矩阵可以用于行数的压缩。右奇异矩阵可以用于列数即特征维度的压缩，也就是我们的PCA降维。 6. SVD 小结SVD 作为一个很基本的算法, 在很多机器学习算法中都有它的身影, 特别是在现在的大数据时代, 由于 SVD 可以实现并行化, 因此更是大展身手. SVD 的 缺点 是分解出的矩阵解释性往往不强, 有点黑盒子的味道, 不过这不影响它的使用.]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pelee (NIPS, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-Pelee-NIPS2018%2F</url>
    <content type="text"><![CDATA[文章: Pelee: A Real-Time Object Detection System on Mobile Devices作者: Robert J. Wang, Xiang Li, Charles X. Ling备注: Department of Computer Science University of Western Ontario London, Ontario, Canada 核心亮点摘要近年来, 可在移动设备上运行的卷积神经网络的需求不断增长, 促进了相关高效模型的设计和研究. 目前已经有大量的研究成果发表, 如 MobileNet, ShuffleNet, 以及 MobileNetV2 等等. 但是, 所有的这些模型都严重依赖于深度可分离卷积(depthwise separable convolution), 但是这在大多数深度学习框架中都缺乏有效的实现. 在本文中, 我们提出了一个高效的结构, 命名为 PeleeNet, 它是通过 传统的卷积 构建的. 在 ImageNet ILSVRC 2012 数据集上, 本文提出的 PeleeNet 相对于 MobileNet 和 MobileNetV2 来说, 不仅具有更高的准确率, 同时还具有更快的速度(1.8倍). 同时, PeleeNet 的模型大小只有 MobileNet 的 66%. 我们还将 PeleeNet 和 SSD 方法结合起来, 提出了一个实时的目标检测系统, 并将其命名为 Pelee, 在 VOC2007 数据集上达到了 76.4% 的 mAP, 在 COCO 数据集上达到了 22.4 的 mAP, 在 iPone8 手机上达到了 23.6 FPS, 在 NVIDIA TX2 上达到了 125 FPS. 介绍越来越多的研究开始关注在限制内存和计算成本的条件下, 如何构建可以高效运行的神经网络模型. 目前已经有很多创新的模型被提出, 如 MobileNets, ShuffleNet, NASNet-A, MobileNetV2, 但是所有的这些模型都严重依赖于深度可分离卷积(depthwise separable convolution), 但是这种卷积缺乏有效的实现. 同时, 有一些研究会将高效的模型和快速的目标检测算法结合起来(Speed/Accuracy trade-offs). 因此, 本文主要的研究就是设计一个用于图片分类和目标检测任何的高效 CNN 模型, 主要的贡献点有以下几点: (1)PeleeNet:我们提出了 DenseNet 的一种变体, 并将其命名为 PeleeNet, 它主要是为了在移动设备上运行而设计的. PeleeNet 延续了 DenseNet 的 connectivity pattern 和 一些关键的设计原则. 同时, 它的有些设计也是为了解决有限的内存和算力问题而存在的. 实现表明, PeleeNet 在 ImageNet ILSVRC 2012 上的 top-1 准确率为 72.1% (比 MobileNet 高 1.6%). 同时需要注意, PeleeNet 的模型大小只有 MobileNet 的 66%. PeleeNet 主要有以下几点关键特征: Two-Way Dense Layer: 受到 GooLeNet 的启发, 我们使用了 2-way dense layer 来获取不同尺寸的感受野. 其中一路使用了 $3\times 3$ 大小的卷积核. 另一路使用了两个 $3\times 3$ 大小的卷积核来学习更大物体的视觉特征. 具体的结构如下图1所示. Stem Block: 受到 Inception-v4 和 DSOD 的启发, 我们在第一层 dense layer 之前设计了一个高效低成本(cost efficient)的 stem block. 该 stem block 的结构如图2所示. 它可以有效的提升特征表达能力, 同时不需要增减太大的计算成本, 要其他方法(增加第一个卷积层的通道数或者增加通道数的增长速度)要好. Dynamic Number of Channels in Bottleneck Layer: 另一个亮点是 bottleneck 层的通道数是根据输入形状变化的, 而不是原始 DenseNet 中固定的 4 倍增长速度. 在 DenseNet 中, 我们观察到, 对于前一个 dense layers, bottlenec 层通道的数量远远大于其输入通道的数量, 这意味着对于这些层, 瓶颈层增加了计算成本, 而不是降低了成本. 为了保持体系结构的一致性, 我们仍然将 bottlenect 层添加到所有的 dense layers 当中, 但是数量是根据输入数据的 shape 动态调整的, 以 确保通道的数量不超过输入通道的数量. 实验显示, 和原始的 DenseNet 结构相比, 这个方法可以节省 28.5% 的算力耗费, 但是只会轻微降低最终的结果. 如图3所示 Transition Layer without Compression: 我们的实验表明, DenseNet 提出的压缩因子(compression factor)对于特征表达有一定的负面影响. 我们在 transition layers 当中总是保持输出通道的数量和输入通道的数量相同. Composite Function: 为了提高实际速度, 我们使用传统的 “后激活(conv+bn+relu)” 作为我们的复合函数, 而不是 DenseNet 中使用的预激活(这样会降低准确率). 对于后激活方法来说, 所有的 BN 层都可以与卷积层合并, 从而大大加快了推理的速度. 为了弥补这种变化对精度的负面影响, 我们使用了一种浅而宽的网络结果. 在最后一个 dense block 之后, 我们还添加了一个 $1\times 1$ 的卷积层, 以获得更强的表达能力. (2). 我们优化了 SSD 的结构, 使其速度更快, 然后将它与我们的 PeleeNet 相结合.我们将结合后的模型称为 Pelee, 该模型达到了 76.4% mAP on VOC 2007, 22.4 mAP on COCO. 为了平衡速度和准确度而提出的改善措施主要如下: Feature Map Selection: 我们以一种不同于原始 SSD 的方式构建了目标检测网络, 并精心选择了一组 5 个尺度的特征图谱(19, 10, 5, 3, 1). 为了降低计算的复杂度, 我们没有使用 $38\times 38$ 大小的 feature map. Residual Prediction Block: 我们令特征沿着网络进行传递. 对于每个用于检测的特征图, 我们构建一个残差块, 具体的结构如图4所示. Small Convolutional Kernel for Prediction: 残差预测块使得我们可以应用 $1\times 1$ 的卷积核来预测类别得分和框的偏移量. 实验表明, 使用 $1\times 1$ 核的模型精度与使用 $3\times 3$ 核的模型精度基本相同. 然而, $1\times 1$ 核的计算成本减少了 21.5%. (3).我们在 NVIDIA TX2 嵌入式平台上和 iPhone8 上为不同的高效分类模型和不同的单阶段目标检测方法提供了一个 benchmark test. PeleeNetAn Efficient Feature Extraction Network Architecture我们提出的 PeleeNet 的架构如表1所示. 整个网络由一个 stem block 和四个阶段的特征提取器构成(four stages of feature extractor). 除了最后一个阶段外, 每个阶段的最后一层是步长为2的平均池化层. 四阶段(不算 stem)结构是大型模型设计中常用的结构形式. ShuffleNet 使用了一个三阶段的结构, 并在每个阶段的开始将 feature map 的大小缩小. 虽然这可以有效的降低计算成本, 但我们认为, 早期阶段的特征对于视觉任务非常重要, 过早的减小特征图的大小会损害表征能力. 因此, 我们仍然保持四阶段结构. 前两个阶段的层数会专门控制在一个可介绍的范围内. Ablation StudyDataset 自定义了 Stanford Dogs 数据集用来进行消融实验(从 ILSVRC 2012 数据集的子集中创建) 类别数: 120 训练集图片数: 150466 验证集图片数: 6000 Effects of Various Design Choices on the Performance: 我们构建了一个类似于 DenseNet 的网络, 并将其命名为 DenseNet-41, 作为我们的 baseline 模型. 该模型和原始的 DenseNet 模型有两点不同. 第一, 首层 conv layer 参数不同, 其通道数设定为 24 而不是 64, 核的大小从 $7\times 7$ 改变到 $3\times 3$. 第二点不同是, 调整了每个 dense block 中的层的数量以满足算力限制. 我们在这部分的模型都是有 batch size 为 256 的 PyTorch 进行 120 epochs 的训练. 我们遵循了 ResNet 的大多数训练设置和超参数. 表2显示了各种设计选择对性能的影响. 可以看到, 在综合了所有这些设计选择以后, Peleenet 的准确率达到了 79.25%, 比 DenseNet-41 的准确率高 4.23%. 并且计算成本更低. Results on ImageNet 2012Cosine Learning Rate Annealing ($t \leq 120$) 0.5 \times lr \times (cos(\pi \times t / 120) + 1) Speed on Real Devices 使用 FP16 而不是 FP32 是一个常用的在 inference 阶段的加速方法. 但是基于 depthwise separable convolution 的网络却很难从 TX2 的 half-precision(FP16)中获益, 如图5所示. PeleeA Real-Time Object Detection System Overview本小节介绍了我们的目标检测系统以及对 SSD 做出的一些优化. 我们的优化目的主要是在提升速度的同时还要保持一定的精确度. 除了我们上一节提到的特征提取网络以外, 我们还构建与原始 SSD 不同的目标检测网络, 并精心选择了一组 5 个尺度的特征图. 同时, 对于每一个用于检测的特征图谱, 我们在进行预测之前建立了一个残差块(如图4). 我们还使用小卷积核来预测对象类别和边界框位置, 以降低计算成本. 此外, 我们使用了非常不同的训练超参数. 尽管这些贡献单独看起来影响很小, 但是我们注意到最终的模型在 PASCAL VOC 2007 上达到了 70.9% 的 mAP, 在 MS COCO 上实现了 22.4 的 mAP. 在我们的模型中我们使用了 5 种尺寸的特征图谱: 19, 10, 5, 3, 1. 我们没有使用 38 大小的特征图谱是为了平衡速度与精度. 19 大小的特征图谱使用了两种尺寸的 default boxes, 其他 4 个特征图谱使用了一种尺寸的 default box. Speed/Accuracy Trade-offs 论文中在使用 SSD 与 MobileNet 结合时, 也没有使用 38 尺寸的特征图谱. 但是, 他们额外添加了一个 $2\times 2$ 的特征图谱来保留6个尺寸的特征图谱进行预测, 这与我们的解决方案不多. Results on VOC 2007我们的目标检测模型是基于 SSD 的源码实现的(Caffe). batch-size 为 32, 初始的 learning rate 为 0.005, 然后在 80k 和 100k 次迭代时降低 10 倍. 总的迭代数是 120K. Effects of Various Design Choices表7显示了不同设计选择对性能的影响. 我们可以看到残差预测模块可以有效的提升准确率. 有残差预测模块的模型比无残差预测模块的模型精度高 2.2%. 使用 $1\times 1$ 卷积核进行预测的模型和使用 $3\times 3$ 的模型的精度几乎相同. 但是 $1\times 1$ 的内核减少了 21.5% 的计算成本和 33.9% 的模型大小. Comparison with Other Frameworks表8显示了我们的模型与其他不同模型的对比 Results on COCO Speed on Real Devices]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-工具箱(utils)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-utils%2F</url>
    <content type="text"><![CDATA[c2_model_loading checkpoint collect_env comm env imports logger metric_logger miscellaneous model_serialization model_zoo registry]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RefineDet (CVPR, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-RefineDet-CVPR2018%2F</url>
    <content type="text"><![CDATA[文章: Single-Shot Refinement Neural Network for Object Detection作者: Shifeng Zhang, Longyin Wen, Xiao Bian, Zhen Lei, Stan Z.Li 论文亮点:结合了one-stage方法和two-stage方法各自的优势, 提出了一个基于single-shot的检测模型:模型主要包含两大模块, 分别是anchor精化模块和物体检测模块. 网络采用了类似FPN的思想, 通过 Transfer Connection Block 将特征图谱在两个模块之间传送, 不仅提升了的精度, 同时还在速度方面取得了与one-stage方案相媲美的表现 论文细节摘要本文提出了一个基于single-shot的检测模型, 称为RefineDet, 它在精度上高于现有的two-stage方法, 同时, 可以和one-stage方法的速度相媲美. RefineDet包含两个内部连接的模块(如图1): anchor精化模块(anchor refinement module): 过滤掉负样本的anchors, 以减少分类器的搜索空间; 对anchors的位置和size进行粗糙的调整, 以便为后续的回归网络提供更好的初始化状态. 物体检测模块(object detection module): 用refined anchors作为输入进行回归预测. 同时, 设计一个传送连接模块(transfer connection block), 将anchor refinement module里面的特征进行传送, 以此来预测框的位置, size 和 类别标签. 由于本文使用了多任务联合损失函数, 因此可以进行端到端的训练. 介绍在作者看来, 目前的two-stage方法(Faster RCNN, R-FCN, FPN), 相比于One-Stage方法来说具有三个优势: 具有启发式规则来处理正负样本不均衡问题 具有两个级联的物体边框回归阶段(边框更加精确) 提取了更加丰富的物体特征(anchor使得提取过程更精细) 为了结合One-Stage和Two-Stage方法的优势, 同时克服他们的缺点, 本文的RefineDet设计了两个内部连接的模块: anchor refinement module(ARM) 和 object detection module(ODM).(如图1所示) 网络结构网络结构的整体视图如图1所示, 和SSD类似, RefineDet会基于前向传播网络预测出固定数量的bounding box和对应的类别score. 本文的网络主要包含ARM和ODM两大部分. ARM: 对经典网络结构(VGG-16, ResNet-101)进行改造, 去掉分类层, 并加上一些附属结构ODM: ODM由TCBs (Transfer Connection Block)和预测层(3×3 卷积层)组成, 会输出物体的类别score和相对于refined anchor box的相对位置坐标. Transfer Connection Block: 用于链接ARM和ODM, 引入TCBs的目的主要是为了将ARM中不同层的特征转换成ODM接受的形式, 这样一来,ODM和ARM就可以共享特征向量. 值得注意的是, 在ARM中, 本文仅仅对于anchor相关的特征图谱使用TCBs. 其实很像FPN的想法, 但是与它又不太一样. TCBs的结构如图2所示 Two-Step Cascaded Regression: 当前的one-stage方法仅仅依赖于一次边框回归过程, 其主要是基于在不同尺度的特征图谱上来预测不同size的物体的位置, 因此预测的精度较低, 尤其是在面对小物体时. 因此, 本文的模型采用了Two-Step Cascaded Regression. 首先, 利用ARM来调节anchor的位置和大小, 以便为后续的ODM的回归预测提供更好的anchor初始状态. 具体来说, 我们会从特征图谱中的每一个cell上得到n个anchor boxes, 最开始的时候, 每一个anchor box的位置相对于它的cell来说都是固定的. 在每一个特征图谱的cell上面, 我们都会预测4个相对坐标(refined网格相对于origin网格的位移坐标). 因此, 我们可以在每一个cell上面, 产生n个refined anchors. 在获得了refined anchor boxes以后, 我们将它们传送到对应的ODM中去(不同的feature map对应不同的ODM) 来预测物体类别,边框位置和大小等信息. 互相关联的ARM和ODM具有相同的维度, 对于每一个anchor box, ODM都会生成 $c+4$ 个输出( $c$ 为物体类别数 ). 这个预测过程与SSD很相似, 但是与之不同的是本文使用了Refined anchor boxes, 从而可以获得更精确的结果. 注意: 这里 RefineDet 和 SSD 一样, 没有使用 RoI Pooling, 而是直接在 feature map 上中每个位置上, 都预定义了固定数量的 default boxes. SSD 与 RefineDet 的另一区别是: SSD 仅仅使用了 one-stage 的 default box 的预测方案, 而 RefineDet 对 anchor 的调整是 two-stage 的, ARM 会先进行 objectness 的二分类预测和回归, 然后 ODM 会在基于 refined anchor 进行 object class 的多分类预测和回归. Negative Anchor Filtering: 同以往检测模型一样, 本文不希望训练过多的(容易分类的)简单样本, 同时需要减轻样本不均衡问题, 因此, 本文设计了一个 negative anchor过滤机制. 具体来说, 就是在训练阶段, 对于一个refined anchor box, 如果它的负样本概率大于一个阈值(如0.99), 那么我们在训练 ODM 的时候就会忽略这个 refined anchor box, 具体代码实习时就是在匹配的时候, 将背景分类预测值大于 0.99 的直接置为 -1 即可. 这样一来, 网络只会训练 难负样本(refined hard negative anchor boxes) 以及 所有的 正样本(refined positive anchor boxes). 同样, 在预测阶段, 对于大于阈值的负样本, 也会对其放弃检测. 训练和预测(Training and Inference)Data Augmentatin: 采用了和SSD相同的数据增广方法 Backbone Network: 使用了 VGG-16 和 ResNet-101 作为骨架网络, 分别在两个网络后面多加了一些卷积层或者残差模块, 以提取更高level的特征. Anchors Design and Matching: 为了处理不同的物体尺度问题, 本文选择了4个特征层, stride size分别为8, 16, 32 和 64. Hard Negative Mining: 采用了和SSD类似的难样例挖掘算法. Loss Function: RefineDet 的损失函数包含两部分, 即ARM的损失和ODM的损失. 对于ARM损失来说, 我们给每个anchor赋予一个二值标签(是或不是物体), 同时会对 anchor 的 size 和 scale 进行回归来得到 refined anchor. 之后, 我们会将 refined anchors 送入 ODM 模块, 来更进一步的预测物体的类别和更加精确的物体的 locations 和 size. 从这个定义可以知道, RefineNet 的 loss 通常都要比 SSD 的 loss 更大, 因为它比 SSD 的 loss 多了一个二分类和边框回归的 loss 计算. 具体的损失函数如下: L(\{p_i\}, \{x_i\}, \{c_i\}, \{t_i\}) = \frac{1}{N_{ram}} (\sum_i L_b(p_i, [l_i^* \geq 1]) + \sum_i[l_i^* \geq 1] L_r(x_i, g_i^* ))+ \frac{1}{N_{odm}}(\sum_i L_m (c_i, l_i^* ) + \sum_i[l_i^* \geq 1] L_r (t_t, g_i^* ))上式中, $i$ 代表 mini-batch 中 anchor 的 index. $l_i^*$ 是第 $i$ 个 anchor 所对应的真实类别的标签, $g_i^*$ 是第 $i$ 个 anchor 所对应的真实边框的 location 和 size. $p_i$ 和 $x_i$ 是预测出来的第 $i$ 个 anchor 的二分类置信度和 refined anchor 的坐标. $c_i$ 和 $t_i$ 是 ODM 预测出的 object class 以及最终的 bbox 的坐标. $N_{arm}$ 和 $N_{odm}$ 分别是 ARM 和 ODM 中的 positive anchors 的数量. 二分类损失函数 $L_b$ 是二分类交叉熵损失, 多分类损失函数 $L_m$ 是 Softmax 多分类损失. $L_r$ 是 smooth L1 损失. $[]$ 为示性函数, 当框内表达式为真时, 输出 1, 否则输出 0. 当 $N_{arm}$ 或者 $N_{odm}$ 为 0 时, 则将对应损失置为0 . Optimization: “xvavier”初始化用于额外增加的层(两层, conv6_1, conv6_2). batch size 设为 32, fine-tuned 使用 SGD + 0.9 momentum + 0.0005 weight decay + 0.001 initial learning rate. Inference: 在测试阶段, ARM 首先过滤掉负样本置信度大于 $\theta$ (0.99) 的 anchors, 然后对于剩下的 anchors 进行 refine 操作. 之后, ODM 将这些 refined anchors 作为输入, 最终每张图片输出置信度 top 400 的边框, 然后使用 阈值为 0.45 的 NMS 算法去重, 最终将置信度 top 200 的边框作为最终的输出. RefineNet 使用了 two-stage 的边框回归过程, 为什么还说它是 one-stage 模型?其实我个人觉得现在目标检测的很多模型中, one-stage 和 two-stage 的界限在慢慢变得模糊, 这也是一个正常的趋势, 因为我们希望得到的模型是不仅精度高, 速度也要快. 在 RefineDet, 这种界限就更模糊了, 我个人觉得 RefienDet 本质上还是属于 one-stage 模型, 因为它在 forward 计算的时候, 整体的流程还是和 SSD 很类似的, 是一步到底的走下来的, 只不过多走了一部分 anchor refine 的步骤. 而不像 Faster R-CNN 和 FPN 那样, proposals 的生成和最终 bbox 的预测有很明显的分隔. 因此, 我们还是倾向于认为它是 one-stage 模型. ReferenceRefineDet(5)源码(1)CVPR2018: https://zhuanlan.zhihu.com/p/50917804RefineDet 论文解析: https://zhuanlan.zhihu.com/p/39184173尝试自己做一个refinedet的网络来训练数据: https://github.com/sfzhang15/RefineDet/issues/144CVPR2018目标检测（objectdetection）算法总览: http://bbs.cvmart.net/articles/139/cvpr2018-mu-biao-jian-ce-object-detection-suan-fa-zong-lan]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron源码解析-Fast R-CNN Heads]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-FastRCNN-Heads%2F</url>
    <content type="text"><![CDATA[源码文件./detectron/modeling/fast_rcnn_heads.py Fast R-CNN Heads本文件定义了 Fast R-CNN Heads 的结构, 即 backbone 网络之上的两个并列的预测层: 分类层和回归层. Fast R-CNN 的设计如下: 1234... -&gt; RoI ----\ /-&gt; box cls output -&gt; cls loss -&gt; RoIFeatureXform -&gt; box head... -&gt; Feature / \-&gt; box reg output -&gt; reg loss Map 首先, Fast R-CNN 会利用 RoI pooling 生成固定长度的 RoI 的特征表示, 然后利用此特征进行物体的类别预测和边框回归预测. fast_rcnn_heads.py 文件概览12345678910111213141516171819202122232425262728293031323334# ./detectron/modeling/fast_rcnn_head.py# ...from detectron.core.config import cfg# ...# ----------------------------------- ## Fast R-CNN outputs and losses# ----------------------------------- #def add_fast_rcnn_outputs(model, blob_in, dim): # 添加 RoI 分类器和 bounding box 回归器的输出 # ...def add_fast_rcnn_losses(model): # 添加损失函数 # ...# ----------------------------------- ## Box heads# ----------------------------------- #def add_roi_2mlp_head(model, blob_in, dim_in, spatial_scale): # 添加具有两层隐藏层的 ReLU MLP # ...def add_roi_Xconv1fc_head(model, blob_in, dim_in, spatial_scale): # 添加一层 X conv + 一层 fc 作为 head # ...def add_roi_Xconv1fc_gn_head(model, blob_in, dim_in, spatial_scale): # 添加一层 X conv + 一层 fc 作为 head, 同时使用 GN # ... 导入的包及函数老样子, 我们先看一下这个文件使用了哪些包和函数12345678910111213# ./detectron/modeling/fast_rcnn_heads.py# 常规包from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functioinfrom __future__ import unicode_literalsfrom detectron.core.config import cfgfrom detectron.utils.c2 import const_fillfrom detectron.utils.c2 import gauss_fillfrom detectron.utils.net import get_group_onimport detectron.utils.blob as blob_utils Fast R-CNN outputs and lossesadd_fast_rcnn_outputs()会在./detectron/modeling/model_builder.py中的_add_fast_rcnn_head()函数中调用, 如果此时模型处于训练状态, 还会同时调用add_fast_rcnn_losses()函数. 下面我们就先来看一下这两个函数的内部实现. 首先是add_fast_rcnn_outputs()函数. 1234567891011121314151617181920212223242526def add_fast_rcnn_outputs(model, blob_in, dim): # 依据 Fast R-CNN 的设计, 创建 box 分类层 model.FC( blob_in, 'cls_score', # blob_out, 以名称存在于 workspace 当中 dim, # dim_in model.num_classes, # dim_out weight_init=gauss_fill(0.01), # 该函数来自于 detectron.utils.c2 文件 bias_init=const_fill(0.0) ) if not model.train: # == test # 在推演的时候, 仅仅添加softmax # 在训练的时候, 需要将softmax和交叉熵结合 model.Softmax('cls_score', 'cls_prob', engine='CUDNN') # Box 回归层 num_bbox_reg_classes=( # 回归层的类别数, 当只要求分成前景和后景时, 为2, 当要求对分成对应类别时, 为 num_classes 2 if cfg.MODEL.CLS_AGNOSTIC_BBOX_REG else model.num_classes ) model.FC( blob_in, 'bbox_pred', dim, # dim_in num_bbox_reg_classes*4, # dim_out weight_init=gauss_fill(0.001), bias_init=const_fill(0.0) ) 可以看到, 上面的函数是根据 Fast R-CNN 中两个并列的预测层进行定义的, 这两个预测层分别为物体类别置信度的分类预测层, 以及物体边框坐标点的回归预测层, 其中回归预测层在 Fast R-CNN 中的类别默认值为2, 即类别不可知(class-agnostic), 只分前景和背景, 并且预测出前景框和背景框的坐标. 下面是 Fast R-CNN 的损失定义123456789101112131415161718def add_fast_rcnn_losses(model): # 添加 RoI 分类损失 cls_prob, loss_cls = model.net.SoftmaxWithLoss( ['cls_score', 'labels_int32'], ['cls_prob', 'loss_cls'], scale=model.GetLossScale() ) # 添加 bounding box 回归损失 loss_bbox = model.net.SmoothL1Loss( [ 'bbox_pred', 'bbox_targets', 'bbox_inside_weights', 'bbox_outside_weights' ], 'loss_bbox', scale=model.GetLossScale() ) # 求梯度 loss_gradients = blob_utils.get_loss_gradients(model, [loss_cls, loss_bbox])]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-检测模型辅助器(DetectionModelHelper)]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-DetectionModelHelper%2F</url>
    <content type="text"><![CDATA[DetectionModelHelper 类概览在./detectron/modeling/model_builder.py文件中的, Detectron 使用了 create() 函数来创建目标检测模型, 其中最主要的部分是使用了 detectron/modeling/detector.py文件中的 class DetectionModelHelper()类, 该类是 Detectron 所有类型模型的最基本结构, 下面, 我们就对该类进行解析. 首先, 还是老样子, 我们大致浏览一下这个文件中的类和函数, 以及各个函数的功能, 把握类的设计思路和整体结构. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# ./detectron/modeling/detector.py# 导入各种包及函数from detectron.core.config import cfg# ...# 该类继承了cnn.CNNModelHelper, 用于表示各种检测模型. 最新的 caffe2 建议用 ModelHelper + brew 来替换 CNNModelHelperclass DetectionModelHelper(cnn.CNNModelHelper): def __init__(self, **kwargs): # 初始化函数, 处理各种配置选项 # ... def TrainableParams(self, gpu_id=-1): # 获取所有可训练参数的 blob 名字 # .. def AffineChannel(self, blob_in, blob_out, dim, inplace=False): # 当 BN 不能使用时(minibatch size 太小), 用仿射变换来替代BN # ... def GenerateProposals(self, blobs_in, blobs_out, anchors, spatial_scale): # 用于生成 RPN 候选区域框的 Op # ... def GenerateProposalLabels(self, blobs_in): # 用于生成 RPN 候选区域标签的 Op. 该函数只会在 e2e Faster/Mask 训练时才会被调用 # ... def CollectAndDistributeFpnRpnProposals(self): # 将多个 FPN levels 产生的 RPN proposals 融合, 然后再将这些候选区域分配到其自身适应的 FPN levels # ... def DropoutIfTraining(self, blob_in, dropout_rate): # 添加 dropout def RoIFeatureTransform(self, blobs_in, blob_out, blob_rois='rois', method='RoIPoolF', resolution=7, spatial_scale=1. / 16., sampling_ratio=0): # 添加具体的 RoI pooling 方法. # ... def ConvShared(self, blob_in, blob_out, dim_in, dim_out, kernel, weight=None, bias=None, **kwargs): # 添加与另一个 conv op 共享权重的 conv op # ... def BilinearInterpolation(self, blob_in, blob_out, dim_in, dim_out, up_scale): # 双线性插值 # ... def ConvAffine( # args in the same order of Conv() self, blob_in, prefix, dim_in, dim_out, kernel, stride, pad, group=1, dilation=1, weight_init=None, bias_init=None, suffix='_bn', inplace=False ): # 在 AffineChannel Op 之后添加 Conv op # ... def ConvGN( # args in the same order of Conv() self, blob_in, prefix, dim_in, dim_out, kernel, stride, pad, group_gn, # gn 中 groups 的数量 group=1, dilation=1, weight_init=None, bias_init=None, suffix='_gn', no_conv_bias=1, ): # 在 GroupNorm op 之后添加 Conv op # ... def DisableCudnn(self): # ... def RestorePreviousUseCudnn(self): # ... def UpdateWorkspaceLr(self, cur_iter, new_lr): # 更新当前模型的学习率和workspace # ... def _SetNewLr(self, cur_lr, new_lr): # 更新模型和 workspace blobs # ... def _CorrectMomentum(self, correction): # MomentumSGDUpdate op 实现 # ... def GetLossScale(self): # 动态开支 loss 大小 # ... def AddLosses(self, losses): # ... def AddMetrics(self, metrics): # ...def _get_lr_change_ratio(cur_lr, new_lr): # ... 导入的包和函数该文件导入的包和函数, 及其它们的功能如下所示: 1234567891011121314151617181920212223242526# ./detectron/modeling/detector.py# 常规包from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionfrom __future__ import unicode_literalsimport numpy as npimport logging# caffe2 包from caffe2.python import cnn # cnn.CNNModelHelperfrom caffe2.python import corefrom caffe2.python import workspacefrom caffe2.python.modeling import initializersfrom caffe2.python.modeling.parameter_info import ParameterTags# detectron 包及函数from detectron.core.config import cfgfrom detectron.ops.collect_and_distribute_fpn_rpn_proposals \ import CollectAndDistributeFpnRpnProposalsOpfrom detectron.ops.generate_proposal_labels import GenerateProposalLabelsOpfrom detectron.ops.generate_proposals import GenerateProposalsOpimport detectron.roi_data.fast_rcnn as fast_rcnn_roi_dataimport detectron.utils.c2 as c2_utils 初始化函数123456789101112131415161718192021222324252627# detectron/modeling/detector.py# from caffe2.python import cnnclass DetectionModelHelper(cnn.CNNModelHelper):# 该类是cnn.CNNModelHelper的一个子类, 这一点很重要 def __init__(self, **kwargs): # 处理属于DetectionModelHelper的特定的参数, 其他的都会传到CNNModelHelper当中 self.train = kwargs.get('train', False) # train self.num_classes = kwargs.get('num_classes', -1) # cfg.MODEL.NUM_CLASSES assert self.num_classes &gt; 0, 'num_classes must be &gt; 0' for k in ('train', 'num_classes'): if k in kwargs: del kwargs[k]# TODO 貌似是因为下面要再次调用构造函数的原因? # 设置数据的排列顺序: batchsize, channels, heiht, width kwargs['order'] = 'NCHW' # TODO, 不懂这个选项的实际作用 kwargs['cudnn_exhaustive_search'] = False super(DetectionModelHelper, self).__init__(**kwargs) # TODO ?? 这样不会造成递归调用吗? 为什么要递归调用构造函数 self.roi_data_loader = None self.losses = [] self.metrics = [] self.do_not_update_params = [] # 位于该列表中的参数不会被更新 self.net.Proto().type = cfg.MODEL.EXECUTION_TYPE self.net.Proto().num_workers = cfg.NUM_GPUS * 4 self.prev_use_cudnn = self.use_cudnn self.gn_params = [] # 位于该列表中的元素是GroupNorm参数 损失函数相关1234567891011121314151617181920# ./detectron/modeling/detector.pyclass DetectionModelHelper(cnn.CNNModelHelper): #... def GetLossScale(self): # 当多 GPU 分布式训练时起作用, 根据 GPU 的数量调整损失的大小 return 1.0 / cfg.NUM_GPUS def AddLosses(self, losses): # losses 是一个列表, eg: ['loss_cls', 'loss_bbox'] if not isinstance(losses, list): # 如果不是列表, 则将其转换成列表 losses = [losses] # 对字符串进行转换, 使得 losses 包含相应blob的引用(将 'gpu_0/foo' 转换成 'foo') losses = [c2_utils.UnscopeName(str(l)) for l in losses] self.losses = list(set(self.losses + losses)) def AddMetrics(self, metrics): if not isinstance(metrics, list): metrics = [metrics] self.metrics = list(set(self.metrics + metrics))]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-模型测试]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E6%BC%94%2F</url>
    <content type="text"><![CDATA[源码文件: detectron/core/test_engine.py initialize_model_from_cfg() 函数该函数会根据全局配置信息(global cfg)创建模型并对其进行初始化, 该函数的接受参数weights_file为一权重文件的路径信息. 其他参数采用全局配置文件中的设置. 12345678910111213141516def initialize_model_from_cfg(weights_file, gpu_id=0): # 根据配置信息创建模型 model = model_builder.create(cfg.MODEL.TYPE, train=False, gpu_id=gpu_id) # 根据创建的模型和给定的权重文件对网络进行初始化. net_utils.initialize_gpu_from_weights_file( model, weights_file, gpu_id=gpu_id ) # TODO model_builder.add_inference_input(model) workspace.CreateNet(model.net) workspace.CreateNet(model.conv_body_net) if cfg.MODEL.MASK_ON: workspace.CreateNet(model.mask_net) if cfg.MODEL.KEYPOINTS_ON: workspace.CreateNet(model.keypoint_net) return model 该函数最开始使用全局配置信息cfg.MODEL.TYPE创建的一个模型引用model, 关于创建模型的的代码详细内容请查看模型创建源码解析. 然后利用网络工具文件(net_utils.py)中initialize_gpu_from_weights_file()方法对模型进行初始化]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-利用预训练模型检测自定义图片]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron2-%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[源码文件 tools/infer_simple.py 运行指令Detectron 是一个非常庞杂的代码项目, 因此, 在对 Detecron 内部的主要模型进行解析之前, 我们首先要知道如何使用已经训练好的模型. 也就是先要知道如何利用完善的 Detectron 目标检测模型框架. 根据官方的使用教程, 要利用 Detectron 检测用户提供的自定义图片, 需要在 shell 中运行下面的指令: 123456python tools/infer_simple.py \ --cfg configs/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml \ --output-dir /tmp/detectron-visualizations \ --image-ext igp \ --wts https://s3-us-west-2.amazonaws.com/detectron/35861858/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml.02_32_51.SgT4y1cO/output/train/coco_2014_train:coco_2014_valminusminival/generalized_rcnn/model_final.pkl \ demo 在上面的指令中, Detectron 会自动下载 --wts 参数指定了模型的下载链接, 最终下载的模型会根据 Detectron/detectron/core/config.py 中的 __C.DOWNLOAD_CACHE 参数决定, 该参数的默认值为 /tmp/detectron-download-cache, 可以根据你自己的需要进行修改, --output-dir 参数指定了返回的结果存放的位置, 推荐你修改成自己期望的路径, 结果在默认情况下会以 PDF 的格式返回. 最后的demo 指示的是待检测图谱存放的路径, 位于Detectron/demo/文件夹下, 这里可以直接指定的原因是因为在代码中使用了下面的方式定义此参数123parser.add_argument( 'im_or_folder', help='image or folder of images', default=None) # 注意第一个参数定义为'im_or_folder', 而不是'--im_or_folder' tools/infer_simple 文件总览接下来, 我们根据这个脚本文件, 逐步解析 Detectron 的工作原理. 为了更加有条理的解析, 我们会根据文件中的代码功能, 将文件按照模块进行解析, 主要包含以下几个部分: 导入的包及函数: 介绍导入的函数和变量的含义及作用 命令行参数: 介绍该文件使用的命令行参数的用途及注意事项 主程序: 最重要的一部分, 可能包含大量其他文件中的函数代码, 会重点讲解该文件. 文件代码的概览如下所示: 12345678910111213141516171819202122232425262728# ./tools/infer_simple# 导入的包及函数from __future__ import absolute_import#...from caffe2.python import workspace#...from detectron.utils.logging import setup_logging#...# 命令行参数def parse_args(): parser = argparse.ArgumentParser(description="End-to-end inference") parser.add_argument(...) #... return parser.parse_args()# 主程序def main(args): logger = logging.getLogger(__name__) merge_cfg_from_file(args.cfg) #...if __name__ == "__main__": workspace.GlobalInit(["caffe2", "--caffe2_log_level=0"]) setup_logging(__name__) # 调用 detectron/utils/logging.py中的函数 args = parse_args() main(args) 导入的包及函数首先看一下该文件导入了那些包和函数, 以及它们的作用: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# ./tools/infer_simple# python2兼容包from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionfrom __future__ import unicode_literals# 标准常用包, 下面的包为常用的一些包, 不多做介绍from collections import defaultdictimport argparseimport cv2import globimport loggingimport osimport sysimport timefrom caffe2.python import workspace# assert_and_infer_cfg函数会将所有的 cfg 选项参数设置为只读, 防止修改from detectron.core.config import assert_and_infer_cfg# 从config.py文件中导入了cfg选项, 该选项包含了所有 Detectron 模型的选择参数, 因此体量非常大(约1000行代码)from detectron.core.config import cfg# merge_cfg_from_file函数用于将一个 yaml config 文件中的 cfg 选项融合到全局 cfg 当中(即core/config.py中的cfg)from detectron.core.config import merge_cfg_from_file#from detectron.utils.io import cache_url#from detectron.utils.logging import setup_logging#from detectron.utils.timer import Timer#import detectron.core.test_engine as infer_engine#import detectron.datasets.dummy_datasets as dummy_datasets#import detectron.utils.c2 as c2_utils#import detectron.utils.vis as vis_utils 在上面的代码中, 首先导入了 cfg 相关的变量和函数, 它们大致作用已经在代码中的注释中介绍, 如果你还想深入了解这些函数的具体实现, 那么可以看关于全局配置选项及相关函数. 另外还有用于设置输出日志信息的函数 setup_logging, 详细解析可以看日志输出控制及训练状态跟踪. 命令行参数下面的代码定义了该文件可能会用到的命令行参数, 其中有些参数你已经在文章开始的运行指令中见到过, 下面我们就来看一下这些参数的定义及功能. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# Detectron/tools/infer_simple.pydef parse_args(): parser = argparse.ArgumentParser(description='End-to-end inference') parser.add_argument( '--cfg', dest='cfg', help='cfg model file (/path/to/model_config.yaml)', default=None, type=str ) parser.add_argument( '--wts', dest='weights', help='weights model file (/path/to/model_weights.pkl)', default=None, type=str ) parser.add_argument( '--output-dir', dest='output_dir', help='directory for visualization pdfs (default: /tmp/infer_simple)', default='/tmp/infer_simple', type=str ) parser.add_argument( '--image-ext', dest='image_ext', help='image file name extension (default: jpg)', default='jpg', type=str ) parser.add_argument( '--always-out', dest='out_when_no_box', help='output image even when no object is found', action='store_true' ) parser.add_argument( '--output-ext', dest='output_ext', help='output image file format (default: pdf)', default='pdf', type=str ) parser.add_argument( '--thresh', dest='thresh', help='Threshold for visualizing detections', default=0.7, type=float ) parser.add_argument( '--kp-thresh', dest='kp_thresh', help='Threshold for visualizing keypoints', default=2.0, type=float ) parser.add_argument( 'im_or_folder', help='image or folder of images', default=None )# 注意这里使用的是'im_or_folder', 而不是'--im_or_folder' if len(sys.argv) == 1: parser.print_help() sys.exit(1) return parser.parse_args() 主程序mian() 函数为该脚本文件的主要函数, 其调用了多个其他文件的函数及参数, 主要有以下几个: merge_cfg_from_file(): 将 yaml config 文件中的配置信息融合到 detectron/core/config.py 中的全局配置信息中. cache_url(): 下载url指定的文件到cache_dir当中, 同时返回缓存文件的路径, 如果缓存文件直接存在, 则可以直接返回. 如果传入的第一个参数不是url类型的, 也直接将其返回. assert_and_infer_cfg(): 当完成所有的 cfg 参数设置以后, 调用此函数, 默认情况下, 该函数会将全局的 cfg 标记为只读类型(immutable), 以此来保护在脚本执行过程中 cfg 选项的值不被修改.(如果允许修改, 则在debug的时候会很难) infer_engine.initialize_model_from_cfg(): 该函数会根据全局配置信息(global cfg)创建模型并对其进行初始化. 在将 caffe2 的工作空间中创建网络并加载 test-time 权重. 关于此函数的详细说明可以查看模型推演源码解析 dummy_datasets.get_coco_dataset(): 该函数用于加载 coco 数据集, 关于这部分的详细解析可以查看数据载入详细解析 vis_utils.vis_one_image(): 该函数用于将模型输出的数值结果以可视化的方式呈现, 关于这部分的详细解析可以查看Detectron 结果可视化 c2_utils.NamedCudaScopr(): 提供 GPU name scope 和 CUDA device scope 功能, 需要结合 with 使用, 位于detectron/utils/c2.py文件, 详细解析请看工具函数完整解读 代码解析如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778def main(args): logger = logging.getLogger(__name__) # 将指定的 yaml config 的选项融合到全局 cfg 当中去 merge_cfg_from_file(args.cfg) cfg.NUM_GPUS = 1 # 该函数用于下载args.weights指定的模型到cfg.DOWNLOAD_CACHE目录中, # 如果模型已经存在, 或者args.weights不是url类型, 则直接返回文件路径. 否则, 会在下载完成后返回文件路径 args.weights = cache_url(args.weights, cfg.DOWNLOAD_CACHE) # 将所有的 cfg 选项参数设置为只读, 防止修改, 这样做易于调试 assert_and_infer_cfg(cache_urls=False) # 确保 detectron/core/config.py 文件中的关键参数设置正确 assert not cfg.MODEL.RPN_ONLY, \ 'RPN models are not supported' assert not cfg.TEST.PRECOMPUTED_PROPOSALS, \ 'Models that require precomputed proposals are not supported' # 根据cfg信息创建模型, 并下载/加载指定的权重文件 model = infer_engine.initialize_model_from_cfg(args.weights) # 获取coco数据集的类别(classes). # 返回一个 AttrDict 类型, 其内部存储着 'classes: value', value 也是一个字典, 该字典为编号与类型组成的键值对 # 0:'__background__', 1:'person', ... dummy_coco_dataset = dummy_datasets.get_coco_dataset() if os.path.isdir(args.im_or_folder): # 如果args.im_or_folder给定的是一个文件夹的话, 则会利用glob模块来抓取其中的.jpg文件, # 并返回一个可遍历的 _iglob 对象, 其内部存储的是.jpg文件的文件路径. im_list = glob.iglob(args.im_or_folder + '/*.' + args.image_ext) else: # 如果不是文件夹, 则说明传入的是一张图片的路径, 则直接将其放在列表当中. im_list = [args.im_or_folder] # 不管是 _iglob 类型还是列表类型, 都可以用同样的方式遍历得到图片路径. for i, im_name in enumerate(im_list): # 根据指定的参数来决定最终的输出路径及输出文件名, 默认的outpu_ext类型为pdf文件 out_name = os.path.join( args.output_dir, '&#123;&#125;'.format(os.path.basename(im_name) + '.' + args.output_ext) ) # 记录相关日志信息 logger.info('Processing &#123;&#125; -&gt; &#123;&#125;'.format(im_name, out_name)) # 用opencv读取图片, 注意格式为 GBR im = cv2.imread(im_name) timers = defaultdict(Timer) # 为程序运行时间计时 t = time.time() # 创建一个 GPU name scope 和一个 CUDA device scope. with c2_utils.NamedCudaScope(0): # 调用 im_detect_all, 用model来处理im图片, 并返回结果. # 可以看到, 结果有3类, 分别对应目标检测, 实例分割, 和关键点检测任务. cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all( model, im, None, timers=timers ) # 记录相关日志信息, 以便打印 logger.info('Inference time: &#123;:.3f&#125;s'.format(time.time() - t)) for k, v in timers.items(): logger.info(' | &#123;&#125;: &#123;:.3f&#125;s'.format(k, v.average_time)) # 当检测第一张图片时, 打印一些提示信息. if i == 0: logger.info( ' \ Note: inference on the first image will be slower than the ' 'rest (caches and auto-tuning need to warm up)' ) # 将图片进行可视化 vis_utils.vis_one_image( im[:, :, ::-1], # BGR -&gt; RGB for visualization im_name, args.output_dir, cls_boxes, cls_segms, cls_keyps, dataset=dummy_coco_dataset, box_alpha=0.3, show_class=True, thresh=args.thresh, kp_thresh=args.kp_thresh, ext=args.output_ext, out_when_no_box=args.out_when_no_box ) 小结上面的代码是 Detectron 的一个非常简单的示例代码, 涵盖了模型创建, 模型初始化, 模型测试, 结果可视化等功能. 由于这里的实例代码仅仅是调用了封装好的接口, 因此我们虽然成功的通过预训练好的模型对自定义的图片进行了检测, 但是我们可能还是不太清楚其内部到底是怎么实现的. 实际上, 这个示例仅仅是一个“热身”, 如果你想要更加深入的了解 Detectron 的内部实现原理, 可以查看我的其他解析. PS: 查看这篇总览, 可以大致了解 Detectron 的源码结构, 根据你自己的需要来选择相应的解析文章.]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-日志输出控制及训练状态跟踪]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron4-%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E6%8E%A7%E5%88%B6%E5%8F%8A%E8%AE%AD%E7%BB%83%E7%8A%B6%E6%80%81%E8%B7%9F%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[TrainingStats 类training_stats = TrainingStats(model) 在训练文件 detectron/utils/train.py 中创建(create_model())并配置(setup_model_for_training)完模型以后, 调用了位于detectron/utils/training_stats.py 中class TrainingStats()类, 调用语句如下所示:123456# detectron/utils/train.pydef train_model(): #... training_stats = TrainingStats(model) #... 下面, 来看看这个类具体的内部实现:1234567891011121314151617181920212223242526# detectron/utils/training_stats.py# 该类用于跟踪关键的训练状态统计值class TrainingStats: def __init__(self, model): # TODO 这个window size是指什么? smoothing tracked values?? self.WIN_SZ = 20 # 输出logging的iterations间隔 self.LOG_PERIOD = 20 self.smoothed_losses_and_metrics = &#123; # from detectron.utils.logging import SmoothedValue # 该类用于跟踪一系列值, 同时提供访问smoothed values的借口(基于WIN_SZ或者global series average). key: SmoothedValue(self.WIN_SZ) for key in model.losses + model.metrics &#125; self.losses_and_metrics = &#123; key: 0 for key in model.losses + model.metrics &#125; self.smoothed_total_loss = SmoothedValue(self.WIN_SZ) self.smoothed_mb_qsize = SmoothedValue(self.WIN_SZ) self.iter_total_loss = np.nan self.iter_timer = Timer() # from detectron.utils.timer import Timer self.model = model#... SmoothedValue 类从上面的代码可以看到, TrainingStats 类中的成员大多为SmoothedValue类对象, 该类的定义位于detectron/utils/logging.py 中, 下面先来看看这个文件的内部实现:123456789101112131415161718192021222324252627# detectron/utils/logging.pydef log_json_stats(stats, sort_keys=True): # ...class SmoothedValue(object): # 该类用于跟踪一系列值, 同时提供访问滑动值smoothed values的借口(基于WIN_SZ或者global series average). def __init__(self, window_size): # from collections import deque self.deque = deque(maxlen = window_size) self.series = [] self.total = 0.0 self.count = 0 def AddValue(self, value): # 将指定的值value加入到对象中的各个成员变量中 self.deque.append(value) self.series.append(value) self.total += value self.count += 1 def GetMedianValue(self): return np.median(self.deque) # axis为None , 则按照一维数组来计算deque中的中位数 def GetAverageValue(self): return np.mean(self.deque) # 同理, 返回deque的平均值 def GetGlobalAverageValue(self): return self.total / self.count # 返回所有值的平均值, 而不仅仅只是窗口内的平均值#... 从上面的代码我们可以看出, 实际上SmoothedValue 类是用来维护滑动平均值的, 同时还会维护一个滑动中位数和总平均值. Timer()接着, 在初始化函数中, class TrainingStats类的成员变量 self.iter_timer是class Timer的类对象, 该类位于detectron/utils/timer.py文件中, 主要封装了python的time模块, 下面具体看一下实现细节1234567891011121314151617181920212223242526detectron/utils/timer.pyclass Timer(object): def __init__(self): self.reset() # 调用类自身的reset()函数 def tic(self): # 这里使用了time.time 而不是 time.clock, 原因是因为time.clock对于多线程任务来说可能存在一些问题 self.start_time = time.time() # 成员变量 start_time def toc(self, average=True): self.diff = time.time() - self.start_time # diff的值为当前时间与开始时间之间的间隔(单位为秒) self.total_time += self.diff # 每调用一次toc函数, totaltime都会统计一次时间间隔 self.calls += 1 # 记录调用toc的次数 self.average_time = self.total_time / self.calls if average: return self.average_time else: return self.diff def reset(self): # 将Timer内统计时间全部归0., 注意是浮点类型 self.total_time = 0. self.calls = 0. self.start_time = 0. self.diff = 0. self.average_time = 0. 再看 TrainingStats 类接下来, 我们继续看 TrainingStats 类中的其他方法:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# detectron/utils/timer.pyclass TrainingStats(object): def __init__(self, model): #... def IterTic(self): self.iter_timer.tic() # 调用Timer类的tic方法, 记录当前time.time()时间 def IterTic(self): return self.iter_timer.toc(average=False) # 返回距离上次掉要tic方法的时间间隔(单位为秒) def ResetIterTimer(self): self.iter_timer.reset() # 重置所有时间相关的统计数据 def UpdateIterStats(self): # 更新跟踪的迭代统计信息 for k in self.losses_and_metrics.keys(): if k in self.model.losses: # import detectron.utils.net as nu self.losses_and_metrics[k] = nu.sum_multi_gpu_blob(k) # 计算多个gpu上的数据和 else: self.losses_and_metrics[k] = nu.average_multi_gpu_blob(k) for k, v in self.smoothed_losses_and_metrics.items(): v.AddValue(self.losses_and_metrics[k]) self.iter_total_loss = np.sum( np.array([self.losses_and_metrics[k] for k in self.model.losses]) ) self.smoothed_total_loss.AddValue(self.iter_total_loss) self.smoothed_mb_qsize.AddValue( self.model.roi_data_loader._minibatch_queue.qsize() ) def LogIterStats(self, cur_iter, lr): # 记录跟踪的统计信息 if(cur_iter % self.LOG_PERIOD == 0 or cur_iter == cfg.SOLVER.MAX_ITER - 1): stats = self.GetStats(cur_iter, lr) log_json_stats(stats) def GetStats(self, cur_iter, lr): eta_seconds = self.iter_timer.average_time * ( cfg.SOLVER.MAX_ITER - cur_iter ) # 剩余时间 eta = str(datetime.timedelta(seconds=int(eta_seconds))) mem_stats = c2_py_utils.GetGPUMemoryUsageStats() mem_usage = np.max(mem_stats['max_by_gpu'][:cfg.NUM_GPUS]) stats = dict( iter=cur_iter, lr=float(lr), time=self.iter_timer.average_time, loss=self.smoothed_total_loss.GetMedianValue(), eta=eta, mb_qsize=int( np.round(self.smoothed_mb_qsize.GetMedianValue()), ), mem=int(np.ceil(mem_usage / 1024 / 1024)) # 将字节转换成GB ) for k, v in self.smoothed_losses_and_metrics.items(): stats[k] = v.GetMedianValue() return stats]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-模型创建]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-%E6%A8%A1%E5%9E%8B%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[源码文件 detectron/modeling/model_builder.py model_builder.py 文件总览该文件的路径为 ./detectron/modeling/model_builder.py, 顾名思义, 该文件主要用于模型的创建, Detectron 支持的模型种类有很多, 因此该文件的代码量较大, 将近700行. 通常情况下, 一个模型是下列元素的一个笛卡尔积(cartesian product): backbone: 如VGG16, ResNet, ResNeXt FPN: on or off(使用或者不使用) RPN only: 提供候选区域框 Fixed proposals for Fast R-CNN, RFCN, Mask R-CNN(可以带有keypoints) 端到端模型: RPN + Fast R-CNN, Mask R-CNN, … 不同的“head” 大量配置选项(configuration options) 最终的模型就是将上面这些“基本元素”组合起来构成的完整的模型. 可以看出, 这种构建模型的方式非常灵活, 但是缺点是刚开始的时候比较难理解. 不过放心, 我们一起来慢慢学习 :) 我们可以通过搭配不同的基本模型来组成一个新的模型, 例如, 如果我们想要搭建一个用 ResNet-50-C4 网络作为 backbone 的 Fast R-CNN 模型的话, 那么我们就可以在配置信息中进行定制:12345# .yamlMODEL: TYPE: generalized_rcnn CONV_BODY: ResNet.add_ResNet50_conv4_body ROI_HEAD: ResNet.add_ResNet_roi_conv5_head 下面我们对model_builder.py文件先进行一个概览, 了解一下该文件都有哪些函数, 以及实现了哪些功能.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# ./detectron/modeling/model_builder.pyfrom __future__ import absolute_import# ... 导入各种包及函数def generalized_rcnn(model): #... 返回一个通用模型, 可以处理 Fast, Faster, FPN, MASK 等模型def rfcn(model): # 调入 build_generic_detection_model 函数def retinanet(model): # 调入 build_generic_detection_model 函数#-------分割线------##Helper functions for building various re-usable network bits#-------分割线------#def create(model_type_func, train=False, gpu_id=0): #... 创建通用模型, 并将其分派给某个特定的模型搭建函数(model building functions)def get_func(func_name): #... 通过名字返回一个函数对象def build_generic_detection_model(...): def _single_gpu_build_func(model): #... 在单一的GPU上搭建模型def _narrow_to_fpn_roi_levels(blobs, spatial_scales): #... 返回用于 RoI 头部的 blobs 和 spatial scalesdef _add_fast_rcnn_head(...): #... 将 Fast R-CNN 的头部添加到模型中def _add_roi_mask_head(...): #... 将 mask prediction head 添加到模型中def _add_roi_keypoint_head(...): #... 将 keypoint prediction head 添加到模型中def build_generic_rfcn_model(...): def _single_gpu_build_func(model): #... 该函数已调入到 build_generic_detection_model 函数中def build_generic_retinanet_model(...): def _single_gpu_build_func(model): # #... 该函数已调入到 build_generic_detection_model 函数中#----------分割线----------## Network inputs#----------分割线----------#def add_training_inputs(model, roidb=None): #... 创建用于训练网络的 input ops 和 blobs. 必须在 model_builder.create() 之后调用def add_inference_inputs(model): #... 创建用于测试网络(inference)的 inputs blobs def create_input_blobs_for_net(net_def): #...# ----------分割线---------- ## DEPRECATED FUNCTIONALITY BELOW# ----------分割线---------- ## 余下的代码已经被弃用(deprecated), 故不做介绍# ...# 下面的模型创建代码没有通过 generic composable 来创建模型# 而是通过分开定义(硬编码, hardcoded)的方式独立创建, 模型之间比较独立. 根据以上函数功能及相互之间的关键, 我们将从以下几个方面对模型创建的源码进行解析: 包及函数的导入: 简单介绍导入的相关包和函数, 它们的功能, 以及在文件中的使用情况, 同时会给出相关的详细解析的链接 模型创建核心函数: 对 create(), get_func(), build_generic_detection_model() 等关键函数进行解析 模型头部解析: 对于不同的任务, 通常具有不同的网络模型 heads, 因此, 本部分主要介绍这些 heads 的创建. 网络模型输入: 除了模型之外, 还要定义相应的输入接口以便模型训练和模型推演. 包及函数的导入下面我们对文件导入的包和相关的函数做一个简单的介绍, 并给出其相应的详细解析的链接, 有兴趣的朋友可以点击链接直接查看相关的信息. 首先是一些常用包, 这部分简单看一下就可以, 了解一下使用了哪些常用包1234567891011from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionfrom __future__ import unicode_literalsimport copyimport importlibimport loggingfrom caffe2.python import corefrom caffe2.python import workspace 接下来是 Detectron 内部的包及函数, 我们简要介绍一下这些包和函数的相关作用, 以及本文件调用了包的哪些属性和函数. 12345678910111213from detectron.core.config import cfgfrom detectron.modeling.detector import DetectionModelHelperfrom detectron.roi_data.loader import RoIDataLoaderimport detectron.modeling.fast_rcnn_heads as fast_rcnn_headsimport detectron.modeling.keypoint_rcnn_heads as keypoint_rcnn_headsimport detectron.modeling.mask_rcnn_heads as mask_rcnn_headsimport detectron.modeling.name_compat as name_compatimport detectron.modeling.optimizer as optimimport detectron.modeling.retinanet_heads as retinanet_headsimport detectron.modeling.rfcn_heads as rfcn_headsimport detectron.modeling.rpn_heads as rpn_headsimport detectron.roi_data.minibatch as roi_data_minibatchimport detectron.utils.c2 as c2_utils 上面的包及函数的主要功能如下所示: from detectron.core.config import cfg: 导入全局配置信息, 详细解析:全局配置选项及相关函数 from detectron.modeling.detector import DetectionModelHelper: DetectionModelHelper 类, 用于表示 Detectron 模型, 详细解析:DetectionModelHelper from detectron.roi_data.loader import RoIDataLoader: RoIDataLoader 类, 完成了 Detectron 加载数据的功能, 详细解析:数据载入源码解析 import detectron.modeling.fast_rcnn_heads as fast_rcnn_head: 定义了 Fast R-CNN 的头部, 详细解析: Fast R-CNN Heads import detectron.modeling.keypoint_rcnn_heads as keypoint_rcnn_heads: 定义了 Keypoint R-CNN 的头部, 详细解析: Keypoint R-CNN Heads import detectron.modeling.mask_rcnn_heads as mask_rcnn_heads: 定义了 Mask R-CNN 的头部, 详细解析: Mask R-CNN Heads import detectron.modeling.name_compat as name_compat: 对旧版的名称做了一些修改, 本部分代码用于提供与旧版名称的兼容性. import detectron.modeling.optmizer as optim: 构建网络优化器 import detectron.modeling.retinanet_heads as retinaneet_heads: 定义了 RetinaNet 的头部, 详细解析: RetinaNet Heads import detectron.modeling.rfcn_heads as rfcn_heads: 定义了 RFCN 的头部. 详细解析: 其他网络的Heads定义 import detectron.modeling.rpn_heads as rpn_heads: 定义了 RPN 的头部. 详细解析: 其他网络的Heads定义 import detectron.roi_data.minibatch as roi_data_minibatch: 构建数据集的 mini batch. 详细解析: 数据加载解析 import detectron.utils.c2 as c2_utils: 详细解析: 工具函数解读 模型创建核心函数model_builder.create() 方法在调用detectron/utils/train.py文件中的train_model()方法时,在第一行代码中调用了同属该文件的create_model()方法, 而在该方法中, 核心的创建语句为model = model_builder.create(cfg.MODEL.TYPE, train=True), 其中, model_builder.create(...) 是位于文件 detectron/modeling/model_builder.py中create(...)方法, 该方法的详细实现如下所示: 12345678910111213141516171819202122232425262728# detectron/modeling/model_builder.pydef generalized_rcnn(model): #... 通用模型def rfcn(model): #...def retinanet(model): #...def create(model_type_func, train=False, gpu_id = 0): # 通用的模型创建函数, 该函数可以继续分派到特定的模型创建函数中 # 默认情况下, 该函数将以并行模式(并行数量取决于cfg.NUM_GPUS)生成数据 # 但是, 你可以将其限制在特定的GPU上进行(通过gpu_id), 在测试阶段使用optimizer.build_data_parallel_model() # model_type_func 通常为 cfg.MODEL.TYPE, 即: generalized_rcnn. # 在 test_engin.py 中的调用形式: # model = model_builder.create(cfg.MODEL.TYPE, train=False, gpu_id=gpu_id) # from detectron.modeling.detector import DetectionModelHelper model = DetectionModelHelper( name=model_type_func, # 对于示例: model_type_func=generalized_rcnn train=train, num_classes=cfg.MODEL.NUM_CLASSES, init_params=train ) model.only_build_forward_pass = Fasle model.target_gpu_id = gpu_id return get_func(model_type_func)(model) # get_func(...)函数解析就在下面#... 上面代码中 model 对象是 DetectionModelHelper 类的一个实例, 关于此类的详细解析可以看DetectionModelHelper 解析.接着, 设置了该对象的两个属性, 分别为 model.only_build_forward_pass 以及 model.target_gpu_id. 接着调用 get_func 获取到相应的函数, 并将 model 对象作为参数传递给了该函数, 然后将函数的返回值作为 create() 函数的返回值返回, 返回的是一个模型对象 model(常用名).在获得模型对象 model 后, 将其返回. 通常情况下, 会对返回的模型对象进行权重初始化, 如下所示:1234567from detectron.modeling import model_builderimport detectron.utils.net as net_utilsmodel = model_builder.create(cfg.MODEL.TYPE, train=False, gpu_id=gpu_id) # gpu_id = 0net_utils.initialize_gpu_from_weights_file( model, weights_file, gpu_id=gpu_id) # gpu_id = 0 get_func() 函数由上面的 create() 函数可知, 最终的返回语句在返回直接会利用 get_func() 函数获取名字对于的函数变量, get_func() 函数的解析如下 123456789101112131415161718192021222324252627282930313233# ./detectron/modeling/model_builder.pydef get_func(func_name): # 该函数会通过name返回一个函数对象, # func_name必须等于该module中的函数, 或者是与base 'modeling'相关的函数的路径 # 通常: func_name = cfg.MODEL.TYPE = generalized_rcnn if func_name == '': return None # import detectron.modeling.name_compat as name_compat # 因为名字做过改动, 这句话是为了兼容性而存在的 new_func_name = name_compat.get_new_name(func_name) if new_func_name != func_name: # 对于本例: new_func_name = func_name, 名字不变, 依然为: cfg.MODEL.TYPE = generalized_rcnn # 因此不会出现下面的警告 logger.warn( 'Remapping old function name:&#123;&#125; -&gt; &#123;&#125;'. format(func_name, new_func_name) ) func_name = new_func_name try: parts = func_name.split('.') if len(parts) == 1: return globals()[parts[0]] module_name = 'detectron.modeling.' + '.'.join(parts[:-1]) # 会根据module导入位于'detectrong/modeling'中的module # fast_rcnn_heads, FPN, mask_rcnn_heads 等等 module = importlib.import_module(module_name) return getattr(module, parts[-1]) except Exception: logger.error('Failed to find function: &#123;&#125;'.format(func_name)) raise 如果单纯看上面的函数, 大部分人都不太能理解网络到底是通过什么函数创建的, 因为这里我们好像没有看到任何有关 fast rcnn 或者 mask rcnn 的函数调用信息. 实际上, 这也是 Caffe2 的意思变成风格, 即通过配置文件信息来搭建网络, 首先, 我们要知道, 在当前文件中, 存在这大量的全局变量, 这些变量都得是数据变量, 有的是函数名变量. 因此, 本文件中的 get_func() 函数成了配置文件信息与模型函数之间的一道桥梁, 该函数可以根据传入的不同的func_name变量来获得相应的全局函数名, 然后, 将这些函数返回, 最终完成模型搭建. 用一个例子作说明.下面的语句是 Detectron 官网的标准示例之一.123456python tools/infer_simple.py \ --cfg configs/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml \ --output-dir /tmp/detectron-visualizations \ --image-ext jpg \ --wts https://s3-us-west-2.amazonaws.com/detectron/35861858/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml.02_32_51.SgT4y1cO/output/train/coco_2014_train:coco_2014_valminusminival/generalized_rcnn/model_final.pkl \ demo 对于上面的指令, 通过--cfg指定了配置文件的位置, 看一下看文件的简单构成:12345678910111213141516171819202122232425262728293031323334353637383940414243444546MODEL: TYPE: generalized_rcnn CONV_BODY: FPN.add_fpn_ResNet101_conv5_body NUM_CLASSES: 81 FASTER_RCNN: True MASK_ON: TrueNUM_GPUS: 8SOLVER: WEIGHT_DECAY: 0.0001 LR_POLICY: steps_with_decay BASE_LR: 0.02 GAMMA: 0.1 MAX_ITER: 180000 STEPS: [0, 120000, 160000]FPN: FPN_ON: True MULTILEVEL_ROIS: True MULTILEVEL_RPN: TrueFAST_RCNN: ROI_BOX_HEAD: fast_rcnn_heads.add_roi_2mlp_head ROI_XFORM_METHOD: RoIAlign ROI_XFORM_RESOLUTION: 7 ROI_XFORM_SAMPLING_RATIO: 2MRCNN: ROI_MASK_HEAD: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs RESOLUTION: 28 # (output mask resolution) default 14 ROI_XFORM_METHOD: RoIAlign ROI_XFORM_RESOLUTION: 14 # default 7 ROI_XFORM_SAMPLING_RATIO: 2 # default 0 DILATION: 1 # default 2 CONV_INIT: MSRAFill # default GaussianFillTRAIN: WEIGHTS: https://s3-us-west-2.amazonaws.com/detectron/ImageNetPretrained/MSRA/R-101.pkl DATASETS: ('coco_2014_train', 'coco_2014_valminusminival') SCALES: (800,) MAX_SIZE: 1333 BATCH_SIZE_PER_IM: 512 RPN_PRE_NMS_TOP_N: 2000 # Per FPN levelTEST: DATASETS: ('coco_2014_minival',) SCALE: 800 MAX_SIZE: 1333 NMS: 0.5 RPN_PRE_NMS_TOP_N: 1000 # Per FPN level RPN_POST_NMS_TOP_N: 1000OUTPUT_DIR: . 可以看到, 在该配置文件中, 网络模型的 CONV_BODY 为: FPN.add_fpn_ResNet101_conv5_body, Fast_RCNN 的头部(用于检测框)为: fast_rcnn_heads.add_roi_2mlp_head, Mask RCNN 的头部为(用于实例分割)为: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs. 我们可以在get_func()函数中添加一条输出语句, 来看看创建的网络是否和我们预期的一直, 添加代码如下: 123456789# ./detectron/modeling/model_builder.pydef get_func(func_name): if func_name == '': return None new_func_name = name_compat.get_new_name(func_name) print("查看func_name: ", func_name, ", 查看new_func_name: ", new_func_name) #... 然后运行上面指令(最好模型创建后的位置加上断点, 因为我们这里只想看模型的创建信息), 输出结果如下:1234查看func_name: generalized_rcnn, 查看new_func_name: generalized_rcnn查看func_name: FPN.add_fpn_ResNet101_conv5_body, 查看new_func_name: FPN.add_fpn_ResNet101_conv5_body查看func_name: fast_rcnn_heads.add_roi_2mlp_head, 查看new_func_name: fast_rcnn_heads.add_roi_2mlp_head查看func_name: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs, 查看new_func_name: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs 可以看到, 除了最开始的generalized_rcnn外, 模型还根据配置文件创建了其余的部分. 但是我们并没有显式的看到在哪里使用了这些配置信息, 那么, 到底是在哪里使用了这些配置信息呢? 实际上, 正是get_func()返回的函数generalized_rcnn()起到了关键的作用, 我们知道, get_func()返回的是一个函数地址, 因此, create()函数最后的语句return get_func(model_type_func)(model), 其实也可以看做是return generalized_rcnn(model). generalized_rcnn() 函数该函数正是本文件中模型创建部分的第一个函数, 其代码解析如下: 1234567891011# ./detectron/modeling/model_builder.pydef generalized_rcnn(model): return build_generic_detection_model( model, get_func(cfg.MODEL.CONV_BODY), add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD), add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD), add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD), freeze_conv_body=cfg.TRAIN.FREEZE_CONV_BODY ) 我们根据示例的指令来对上面的参数简单说明一下 model: 由 DetectionModelHelper 创建的一个实例对象. get_func(cfg.MODEL.CONV_BODY): 参数值为FPN.add_fpn_ResNet101_conv5_body, 因此会导入detectron.modeling.FPN, 同时返回FPN.add_fpn_ResNet101_conv5_body()函数. get_func(cfg.FAST_RCNN.ROI_BOX_HEAD): 参数值为fast_rcnn_heads.add_roi_2mlp_head, 因此会导入detectron.modeling.fast_rcnn_heads.add_roi_2mlp_head, 同时返回fast_rcnn_head.add_roi_2mlp_head()函数. get_func(cfg.MRCNN.ROI_MASK_HEAD): 参数值为mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs, 因此会导入detectron.modeling.mask_rcnn_heads, 同时返回mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs()函数. get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD): 参数值为空, 因此不会导入任何文件, 直接返回None. cfg.TRAIN.FREEZE_CONV_BODY: 参数值为默认值False. build_generic_detection_model() 函数可以看出, 上面的generalized_rcnn函数是直接调用了build_generic_detection_model() 函数, 该函数内部又新定义了一个函数, 概览如下: 1234567891011121314# ./detectron/modeling/model_builder.pydef build_generic_detection_model( model, add_conv_body_func, add_roi_box_head_hunc=None, add_roi_mask_head_func=None, add_roi_keypoint_head_func=None, freeze_conv_body=False): def _single_gpu_build_func(model): #... optim.build_data_parallel_model(model, _single_gpu_build_func) return model 可以看到, build_generic_detection_model()函数主要是利用函数内部的_single_gpu_build_func()完成模型的搭建, 顾名思义, 该函数主要用于在单个 GPU 上搭建模型, 但是也可以通过在多个不同 GPU 上循环调用来建立多个模型. 在函数的最后, 利用optim的build_data_parallel_model()函数. 该函数位于./detectron/modeling/optimizer.py文件中, 主要提供数据的并行载入功能. 下面我们结合函数中各个参数的含义, 给出build_generic_detection_model()函数代码的详细解析: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# ./detectron/modeling/model_builder.pydef build_generic_detection_model( model, add_conv_body_func, add_roi_box_head_hunc=None, add_roi_mask_head_func=None, add_roi_keypoint_head_func=None, freeze_conv_body=False): def _single_gpu_build_func(model): # 首先添加 conv body(也就是backbone), 如 ResNet-50, VGG等等 # 根据参数知, 本例中的add_conv_body_func, 实际上就是FPN.add_fpn_ResNet101_conv5_body() blob_conv, dim_conv, spatial_scale_conv = add_conv_body_func(model) # 固定backbone, 默认为不固定 if freeze_conv_body: # BlobReferenceList() 函数确保参数会以blob引用列表的形式返回. for b in c2_utils.BlobReferenceList(blob_conv): model.StopGradient(b, b) if not model.train: # == inference # 创建一个可以在一张图片上执行的 conv body # (不带有 RPN 或其他网络头) model.conv_body_net = model.net.Clone('conv_body_net') # 定义网络头损失函数的梯度字典, 用于存储相应的梯度 head_loss_gradients=&#123; 'rpn': None, 'box': None, 'mask': None, 'keypoints': None, &#125;# 以下带有_ON的配置大部分默认为False, 所以只有当用户自定义的配置文件显示打开时, 才回执行相关代码 if cfg.RPN.RPN_ON: # 添加 RPN head # rpn_heads为.py文件 # model 参数为函数参数 # 其余三个参数均来自于 add_conv_body_func(model) head_loss_gradients['rpn'] = rpn_heads.add_generic_rpn_outputs( model, blob_conv, dim_conv, spatial_scale_conv ) if cfg.FPN_ON: # 将添加了RPN head以后, # 将FPN的blobs和scales限制到RoI heads使用的大小 # _narrow_to_fpn_roi_levels函数位于本文件当中, 用于控制大小 # 参数同样来自于backbone网络 blob_conv, spatial_scale_conv = _narrow_to_fpn_roi_levels( blob_conv, spatial_scale_conv ) if not cfg.MODEL.RPN_ONLY: # 默认为 Fasle # 添加 Fast R-CNN head # _add_fast_rcnn_head为本文件的函数 # add_roi_box_head_func为函数参数 # 其余的3个参数为backbone的返回值 head_loss_gradients['box'] = _add_fast_rcnn_head( model, add_roi_box_head_func, blob_conv, dim_conv, spatial_scale_conv ) if cfg.MODEL.MASK_ON: # 添加 Mask 头部 # _add_roi_mask_head为本文件的函数 # add_roi_mask_head_func为函数参数 head_loss_gradients['mask'] = _add_roi_mask_head( model, add_roi_mask_head_func, blob_conv, dim_conv, spatial_scale_conv ) if cfg.MODEL.KEYPOINTS_ON: head_loss_gradients['keypoints'] = _add_roi_keypoint_head( model, add_roi_keypoint_head_func, blob_conv, dim_conv, spatial_scale_conv ) if model.train: loss_gradients = &#123;&#125; for lg in head_loss_gradients.values(): if lg is not None: loss_gradients.update(lg) return loss_gradients else: return None optim.build_data_parallel_model(model, _single_gpu_build_func) return model 模型头部解析在模型创建函数build_generic_detection_model()中, 将许多子功能单独作为一个函数实现, 例如限制RPN网络处理的blobs尺寸, 为模型添加各种头部等, 下面我们就对这部分代码做简要分析. 更详细的分析需要根据不同的论文及模型展开讨论, 这些讨论我会在讲解各个模型的时候进行, 因此, 这里我们就只做简单了解, 脑子里有个概念就可以. 先来看看用于控制 FPN 和 RoI 之间的图谱大小的代码12345678910111213141516def _narrow_to_fpn_roi_levels(blobs, spatial_scales): # 只返回用于RoI heads的 blobs 和 spatial scales # 输入的`blbs`和`spatial scales`也许会包含额外的用于RPN的部分, # 但是这部分并不用于RoI heads, 因此需要去掉 # 此处代码仅仅支持RPN和RoI的min levels相同的情况 assert cfg.FPN.RPN_MIN_LEVEL == cfg.FPN.ROI_MIN_LEVEL # RPN max level可以 &gt;= RoI max level assert cfg.FPN.RPN_MAX_LEVEL &gt;= cfg.FPN.ROI_MAX_LEVEL # 因为FPN RPN的max level可能大于FPN RoI max level, 因此, 我们需要这些大于的情况去除 # blobs 是按照 max/最粗糙 到 min/最精细 的级别排列的 # cfg.FPN.ROI_MAX_LEVEL 默认为5 # cfg.FPN.ROI_MIN_LEVEL 默认为2 num_roi_levels = cfg.FPN.ROI_MAX_LEVEL - cfg.FPN.ROI_MIN_LEVEL + 1 # 截断, 将前面的较粗糙的blobs和spatial_scales舍去 return blobs[-num_roi_levels:], spatial_scale_conv[-num_roi_levels:] 添加 Fast R-CNN 的网络头部1234567891011121314151617def _add_fast_rcnn_head( model, add_roi_box_head_func, blob_in, dim_in, spatial_scale_in): # 调用add_roi_box_head_func函数 # 该函数位于fast_rcnn_head.py中, 详细的讲解可以查看关于Fast R-CNN的代码解析. blob_frcn, dim_frcn = add_roi_box_head_func( model, blob_in, dim_in, spatial_scale_in ) # fast_rcnn_heads 为 fast_rcnn_heads文件 fast_rcnn_heads.add_fast_rcnn_outputs(model, blob_frcn, dim_frcn) if model.train: loss_gradients = fast_rcnn_heads.add_fast_rcnn_losses(model) else: loss_gradients = None return loss_gradients 添加 Mask R-CNN 头部, 代码逻辑和上面的 Fast R-CNN 差不多. 1234567891011121314151617181920212223242526272829def _add_roi_mask_head( model, add_roi_mask_head_func, blob_in, dim_in, spatial_scale_in): # 在添加 mask head 之前先捕获 model graph bbox_net = copy.deepcopy(model.net.Proto()) # 添加 mask head # 调用函数add_roi_mask_head_func blob_mask_head, dim_mask_head = add_roi_mask_head_func( model, blob_in, dim_in, spatial_scale_in ) # 添加 mask output # mask_rcnn_heads为.py文件 blob_mask = mask_rcnn_heads.add_mask_rcnn_outputs( model, blob_mask_head, dim_mask_head ) if not model.train: # == inference # 模型推演的时候会用到一系列 box predictions, 然后会预测 mask # 这需要将网络的box和mask预测分离开 # 因此我们将mask预测网络提取出来, 将它作为一个独立的网络存储起来 # 然后将整个网络重新存储成 bbox-only 网络 model.mask_net, blob_mask = c2_utils.SuffixNet( 'mask_net', model.net, len(bbox_net.op), blob_mask ) model.net._net = bbox_net loss_gradients = None else: loss_gradients = mask_rcnn_heads.add_mask_rcnn_losses(model, blob_mask) return loss_gradients 添加 keypoint 头部1234def _add_roi_keypoint_head( model, add_roi_keypoint_head_func, blob_in, dim_in, spatial_scale_in): #... 由于我不太关键关键点检测相关任务, 所以这部分的代码不讨论了, 不过整体逻辑和上面是一样的 这部分还有两个函数, 但是根据注释来看, 它们的功能都被build_generic_detection_model()函数代替了, 如下所示:1234567def build_generic_rfcn_model(model, add_conv_body_func, dim_reduce=False): # fold this function into build_generic_detection_model # ...def build_generic_retinanet_model(model, add_conv_body_func, freeze_conv_body=False): # fold this function into build_generic_detection_model # ... 网络模型输入首先是add_training_inputs函数, 该函数会创建由于网络训练的 input ops 和 blobs.通常情况下, 我们会同时创建 input ops 和剩下的网络, 但是, 创建 input ops 依赖于加载数据集, 在面对COCO数据集时, 这可能需要好几分钟. 然而, Detectron 的实现希望尽量避免等待, 这样一来在 debug 的时候, 可以更快的进行调试(so debugging can fail fast). 因此, 这里先创建了一个 不带有 input ops 的网络来加载数据集, 然后在加载了数据集以后, 才将 input ops 添加到网络中. 由于 Detectron 推迟了 input ops 的创建, 因此就额外进行一些操作来将 input ops 放置在网络 op list 的最开始. 注意, 该函数必在model_builder.create()被调用之后才能使用. 12345678910111213141516171819202122232425def add_training_inputs(model, roidb=None): assert model.train, 'Training inputs can only be added to a trainable model' if roidb is not None: # 如果你希望更容易的调试, 则可以将 cfg.DATA_LOADER.NUM_THREADS的值设为1 model.roi_data_loader = RoIDataLoader( roidb, num_loaders=cfg.DATA_LOADER.NUM_THREADS, minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE, blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY ) orig_num_op = len(model.net._net.op) blob_names = roi_data_minibatch.get_minibatch_blob_names(is_training=True) for gpu_id in range(cfg.NUM_GPUS): with c2_utils.NamedCudaScope(gpu_id): for blob_name in blob_names: workspace.CreateBlob(core.ScopedNamed(blob_name)) model.net.DequeueBlobs( model.roi_data_loader._blobs_queue_name, blob_names ) # A little op surgery to move input ops to the start of the net diff = len(model.net._net.op) - orig_num_op new_op = model.net._net.op[-diff:] + model.net._net.op[:-diff] del model.net._net.op[:] model.net._net.op.extend(new_op) 下面是创建用于模型推演的网络的 input blobs 123456789101112def add_inference_inputs(model): def create_input_blobs_for_net(net_def): for op in net_def.op: for blob_in in op.input: if not workspace.HasBlob(blob_in): workspace.CreateBlob(blob_in) create_input_blobs_for_net(model.net.Proto()) if cfg.MODEL.MASK_ON: create_input_blobs_for_net(model.mask_net.Proto()) if cfg.MODEL.KEYPOINTS_ON: create_input_blobs_for_net(model.keypoint_net.Proto()) 关于数据载入部分代码大多都是调用./detectron/roi_data/loader.py和./detectron/roi_data/minibatch.py文件中的类和函数实现的, 这里我们仅仅当做接口来使用, 如果你想要了解数据加载的具体实现方法, 可以查看这篇解析]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用PyTorch自己动手从零实现YOLOv3]]></title>
    <url>%2Fz_post%2FPyTorch-YOLO%2F</url>
    <content type="text"><![CDATA[学习一个算法最好的方式就是自己尝试着去实现它! 因此, 在这片博文里面, 我会为大家讲解如何用PyTorch从零开始实现一个YOLOv3目标检测模型, 参考源码请在这里下载. 在正式介绍 YOLOv3 之前, 我们先将其和 YOLO 的其他版本做一个简单的比较, 它们的网络结构对比如下所示: 这里我们假设大家对YOLOv3的各个细节都比较熟悉, 因此就不对YOLOv3做过多介绍, 如果对YOLOv3不太懂的话, 可以再看看原文, 或者看看我写的YOLOv3解析. 模型实现总共会分为以下六部分: (一) 配置文件以及解析 (二) 搭建YOLO模型框架 (三) 实现自定义网络层的前向和反向传播过程 (四) 数据类的设计与实现 (五) 训练/测试/检测脚本的实现 (六) 辅助函数及算法实现(目标函数, NMS算法等) (一) 配置文件以及解析配置文件官方代码使用了配置文件来创建网络, cfg 文件中描述了网络的整体结构, 它相当于 caffe 中的 .protxt 文件一样. 我们也将使用官方的 cfg 文件来创建我们的网络, 点击这里下载并它放在 config/ 文件夹中, 即 config/yolov3.cfg. 123mkdir configcd configwget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg 打开该文件, 将会看到类似于下面的信息:12345678910111213141516171819202122232425262728[convolutional]batch_normalize=1filters=64size=3stride=2pad=1activation=leaky[convolutional]batch_normalize=1filters=32size=1stride=1pad=1activation=leaky[convolutional]batch_normalize=1filters=64size=3stride=1pad=1activation=leaky[shortcut]from=-3activation=linear... convolutional 和 shortcut上面的信息中显示了4个 block, 其中 3 个是卷积网络层, 最后一个是 shortcut 网络层, shortcut 网络层是一种 skip connection, 就像 ResNet 中的一样, 其中的 from 参数为 -3 表示该层的输出是从往前数倒数第三层的图谱 直接相加 得到的. upsamplecfg文件中的 upsample 参数代表了双线性插值时使用的 stride 参数12[upsample]stride=2 routeroute 参数拥有 layers 属性, 它的值可以是一个, 也可以是两个, 如下所示. 当 layers 属性只含有一个值时, 它会输出指定的网络层的特征图谱, 在下面的例子中, layers=-4, 因此, 当前的 route 网络层会输出前面的倒数第 4 个网络层的特征图谱. 当 layers 属性含有两个值时, 它会输出两个网络层的特征图谱连接(concatenated)后的特征图谱, 在下面的例子中, 当前的 route 网络层会将前一层(-1)和第 61 层的特征图片沿着深度维度(depth dimension)进行连接(concatenated), 然后输出连接后的特征图谱.12345[route]layers = -4[route]layers = -1, 61 netcfg 文件中的另一种 block 类型是 net, 它提供了网络的训练信息, 如下所示:12345678910111213141516[net]# Testingbatch=1subdivisions=1# Training# batch=64# subdivisions=16width= 320height = 320channels=3momentum=0.9decay=0.0005angle=0saturation = 1.5exposure = 1.5hue=.1 解析配置文件我们定义了一个名为 parse_config.py 的文件, 其内部的 parse_model_config() 函数的参数是指定的 cfg 的文件路径, 它的功能是将 cfg 文件中的信息加载到模型中, 并且用 元素为字典的列表 的形式进行存储, 如下所示:123456789101112131415161718# ./utils/parse_config.pydef parse_model_config(path): f = open(path, 'r') #读取文件 module_defs = [] # 创建列表, 列表中的元素为字典 for line in f.readlines(): # 逐行读取 line = line.strip() # 消除行头尾的空白符(空格, 回车等) if not line or line.startswith('#'): # 如果遇到空行或者注释行, 则跳过 continue if line.startswith('['):# 遇到模块的起始, 在列表后添加新的字典 module_defs.append(&#123;&#125;) module_defs[-1]['type'] = line[1:-1].strip() # 根据参数值为字典赋值 if(module_defs[-1]['type']=="convolutional"): module_defs[-1]["batch_normalize"] = 0 else: key, value = line.split('=')# 根据参数值为字典赋值, 注意要去除空白符 module_defs[-1][key.strip()] = value.strip() return module_defs 调用该函数后, 会返回一个列表, 列表中的每个元素都是一个字典, 代表了配置文件中的以 [...] 开头的一个 block, 下面是列表中的部分元素示例:123model_config = parse_model_config("../config/yolov3-tiny.cfg")print(model_config[0])print(model_config[1]) 输出如下:123&#123;&apos;channels&apos;: &apos;3&apos;, &apos;hue&apos;: &apos;.1&apos;, &apos;batch&apos;: &apos;1&apos;, &apos;steps&apos;: &apos;400000,450000&apos;, &apos;burn_in&apos;: &apos;1000&apos;, &apos;max_batches&apos;: &apos;500200&apos;, &apos;learning_rate&apos;: &apos;0.001&apos;, &apos;exposure&apos;: &apos;1.5&apos;, &apos;policy&apos;: &apos;steps&apos;, &apos;height&apos;: &apos;416&apos;, &apos;width&apos;: &apos;416&apos;, &apos;subdivisions&apos;: &apos;1&apos;, &apos;angle&apos;: &apos;0&apos;, &apos;type&apos;: &apos;net&apos;, &apos;scales&apos;: &apos;.1,.1&apos;, &apos;momentum&apos;: &apos;0.9&apos;, &apos;decay&apos;: &apos;0.0005&apos;, &apos;saturation&apos;: &apos;1.5&apos;&#125;&#123;&apos;stride&apos;: &apos;1&apos;, &apos;activation&apos;: &apos;leaky&apos;, &apos;type&apos;: &apos;convolutional&apos;, &apos;filters&apos;: &apos;16&apos;, &apos;pad&apos;: &apos;1&apos;, &apos;size&apos;: &apos;3&apos;, &apos;batch_normalize&apos;: &apos;1&apos;&#125; (二) 数据类的设计与实现在搭建 YOLO 模型之前, 我们需要先创建处理数据输入的类, 在 PyTorch 中, 通常是通过集成 torch.utils.data.Dataset 类来实现的, 我们需要实现该类的 __getitem__() 和 __len__() 方法, 实现后, 会将子类的实例作为 DataLoader 的参数, 来构建生成 batch 的实例对象. 下面, 先只给出有关数据集类的实现, 具体的加载过程在后续的脚本解析中给出. class ImageFolder(Dataset) 类这里我们起名为 ImageFolder, 主要是因为原作者使用了这个名字, 实际上我不太建议使用这个名字, 因为会与 PyTorch 中 ImageFolder 类的名字冲突, 容易引起误会, 这里注意一下, 我们这里实现的 ImageFolder 类与 PyTorch 中的同名类并没有任何联系. 代码解析如下:1234567891011121314151617181920212223242526272829303132# ./utils/datasets.pyclass ImageFolder(Dataset): def __init__(self, folder_path, img_size=416): # 获取文件夹下的所有图片路径, glob是一个用于获取路径的通配符模块 self.files = sorted(glob.glob('%s/*.*' % folder_path)) # 设置数据集的图片大小属性, 所有的图片都会被放缩到该尺寸 self.img_shape = (img_size, img_size) def __getitem__(self, index): img_path = self.files[index % len(self.files)] # 根据index获取图片路径 # Extract image img = np.array(Image.open(img_path)) # 利用PIL Image读取图片, 然后转换成numpy数组 h, w, _ = img.shape # 获取图片的高和宽 dim_diff = np.abs(h - w) # 计算高宽差的绝对值 # 根据高宽差计算应该填补的像素数量（填补至高和宽相等） pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2 # 确定填补位置(填补到边长较短的一边) pad = ((pad1, pad2), (0, 0), (0, 0)) if h &lt;= w else ((0, 0), (pad1, pad2), (0, 0)) # 调用 np.pad 函数进行填补 input_img = np.pad(img, pad, 'constant', constant_values=127.5) / 255. # 将图片放缩至数据集规定的尺寸, 同时进行归一化操作 input_img = resize(input_img, (*self.img_shape, 3), mode='reflect') # 将通道维度放置在首位(C,H,W) input_img = np.transpose(input_img, (2, 0, 1)) # 将numpy数组转换成tenosr, 数据类型为 float32 input_img = torch.from_numpy(input_img).float() # 返回图片路径和图片 tensor return img_path, input_img def __len__(self): return len(self.files) class ListDataset(Dataset) 类ListDataset 类定义了训练时所需的数据集和标签, 该类的 __getitem__() 方法会返回三个变量, 分别是: 图片路径, 经过放缩处理后的图片(尺寸大小为指定尺寸), 以及经过处理后的 box 坐标信息. 其中, 图片的存储形式为: $(C\times H\times W)$, 标签的存储形式为: $(50 \times 5)$, 这 50 条数据不一定每一条都具有意义, 对于无意义的数据, 其值为 0, 训练时直接跳过即可, 对于有意义的数据, 每一条数据的形式为: $(class_id, x, y, w, h)$, 其中, $class_id$ 是每个 box 对应的目标类别编号, $x, y, w, h$ 是每个 box 的中心点坐标和宽高, 它们都是以小数形式表示的, 也就是相对于图片宽高的比例.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# ./utils/datasets.pyclass ListDataset(Dataset): def __init__(self, list_path, img_size=416): # list_path: data_config 文件中的 trian 或 val 指定的文件: trainvalno5k.txt 或者 5k.txt # 该文件中存放了用于训练或者测试的.jpg图片的路径, 同时根据此路径可以得到对应的 labels 文件 with open(list_path, 'r') as file: self.img_files = file.readlines() # 根据图片的路径得到 label 的路径, label 的存储格式为一个图片对应一个.txt文件 # 文件的每一行代表了该图片的 box 信息, 其内容为: class_id, x, y, w, h (xywh都是用小数形式存储的) self.label_files = [path.replace('images', 'labels').replace('.png', '.txt').replace('.jpg', '.txt') for path in self.img_files] self.img_shape = (img_size, img_size) # 获取图片目标大小, 之后会将图片放缩到此大小, 并相应调整box的数据 self.max_objects = 50 # 定义每一张图片最多含有的 box 数量 def __getitem__(self, index): # 根据index获取对应的图片路径 img_path = self.img_files[index % len(self.img_files)].rstrip() img = np.array(Image.open(img_path)) # 如果当前获取到的图片的通道数不为3, 则跳过当前图片, 直到获取到通道数为3的图片 while len(img.shape)!=3: index += 1 img_path = self.img_files[(index) % len(self.img_files)].rstrip() img = np.array(Image.open(img_path)) # 获取图片的高和宽, 并根据它们的差异对图片执行 padding 操作, 使图片宽高比为1 h, w, _ = img.shape dim_diff = np.abs(h - w) pad1, pad2 = dim_diff//2, dim_diff - dim_diff//2 pad = ((pad1, pad2), (0,0), (0,0)) if h&lt;=w else ((0,0), (pad1, pad2), (0,0)) input_img = np.pad(img, pad, 'constant', constant_values=128) / 255. # 暂存padding后的图片的宽和高 padded_h, padded_w, _ = input_img.shape # 将图片大小放缩到指定的存储, 并将通道数放置到高和宽之前 input_img = resize(input_img, (*self.img_shape, 3), mode='reflect') input_img = np.transpose(input_img, (2,0,1)) # 将图片转化成 tensor input_img = torch.from_numpy(input_img).float() # 获取图片对应的 label 文件的路径 label_path = self.label_files[index % len(self.img_files)].rstrip() labels = None # 根据图片 padding 之后的存储, 对 label 文件中的 box 坐标按比例进行缩放 if os.path.exists(label_path): labels = np.loadtxt(label_path).reshape(-1, 5) x1 = w * (labels[:, 1] - labels[:, 3] / 2) # 先获取box左上角和右下角的像素坐标 y1 = h * (labels[:, 2] - labels[:, 4] / 2) x2 = w * (labels[:, 1] + labels[:, 3] / 2) y2 = h * (labels[:, 2] + labels[:, 4] / 2) # 根据 padding 的大小, 更新这些坐标的值 x1 += pad[1][0] y1 += pad[0][0] x2 += pad[1][0] y2 += pad[0][0] # 重新将坐标转化成小数模式(相对应padding后的宽高的比例) labels[:, 1] = ((x1+x2)/2) / padded_w labels[:, 2] = ((y1+y2)/2) / padded_h labels[:, 3] *= w / padded_w labels[:, 4] *= h / padded_h filled_labels = np.zeros((self.max_objects, 5)) # 创建50×5的占位空间 if labels is not None: # 将更新后的box坐标填充到刚刚申请的占位空间中 filled_labels[range(len(labels))[:self.max_objects]] = labels[:self.max_objects] # 将 label 转化成 tensor filled_labels =torch.from_numpy(filled_labels) # 返回图片路径, 图片tensor, label tensor return img_path, input_img, filled_labels def __len__(self): return len(self.img_files) (三) 搭建YOLO模型框架在 models.py 文件中, 定义了 YOLO 的模型框架, 文件概览及类之间的调用关系如下: 12345678910111213141516171819202122232425262728# ./models.pyimport torch#...def create_modules(module_defs): # 根据配置文件的列表字典创建模型 # ... EmptyLayer() YOLOLayer()class EmptyLayer(nn.Module): # 'route' 和 'shortcut' 网络层的占位符(placeholder) # ...class YOLOLayer(nn.Module): # Detection Layer # ...class Darknet(nn.Module): # YOLOv3 object detection model def __init__(self, config_path, img_size=416): super(Darknet, self).__init__() self.module_defs = parse_model_config(config_path) # 这里调用了 create_modules 函数来根据配置文件的信息创建对应的网络 self.hyperparams, self.module_list = create_modules(self.module_defs) # ... # ... create_modules() 函数下面我们先来看看模型创建函数 create_modules 的代码解析: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# ./models.pydef create_modules(module_defs): # 参数 module_defs 是根据配置文件生成的列表字典, 列表中的每一个字典都代表一个网络层模块 hyperparams = module_defs.pop(0) # 第0个字段是 [net] 模块, 存储了模型的一些超参数 output_filters = [int(hyperparams["channels"])] # 获取输入层的输出通道数, # out_filers 是一个列表, 后续还会添加其他网络层的输出通道数 module_list = nn.ModuleList() for i, module_def in enumerate(module_defs): # 遍历配置文件中的每一个模块([net]模块已被弹出) modules = nn.Sequential() # 存储一个模块, 一个模块可能包含多个层, 如 卷积+激活 if module_def["type"] == "convolutional": bn = int(module_def["batch_normalize"]) filters = int(module_def["filters"]) kernel_size = int(module_def["size"]) pad = (kernel_size-1) // 2 if int(module_def["pad"]) else 0 # 维持卷积前后图片大小不变 modules.add_module( "conv_%d" % i, # 名字 nn.Conv2d( in_channels=output_filters[-1], # 前一层的输出就是这一层的输入 out_channels=filters, kernel_size=kernel_size, stride=int(module_def["stride"]) padding=pad, bias=not bn,# 当带有 BN 层时, 会抵消掉前一层的偏置项(可通过数学计算证明) ), ) if bn: # 添加 BatchNorm 网络层 modules.add_module("batch_norm_%d" % i, nn.BatchNorm2d(filters)) if module_def["activation"] == "leaky": # 添加激活层 modules.add_module("leaky_%d" % i, nn.LeakyReLU(0.1)) elif module_def["type"] == "maxpool": kernel_size = int(module_def["size"]) stride = int(module_def["stride"]) if kernel_size == 2 and stride == 1: padding = nn.ZeroPad2d((0,1,0,1)) # 在右边和下边添加 zero padding modules.add_module("_debug_padding_%d" % i, padding) # 定义 max_pool 网络层, 注意 maxpool 没有 filter 参数 maxpool = nn.MaxPool2d( kernel_size=kernel_size, stride=stride, padding=(kernel_size-1) // 2, ) modules.add_module("maxpool_%d" % i, maxpool) elif module_def["type"] == "upsample": # 根据 stride 扩大特征图谱的宽和高 # 目前, 新版本的 PyTorch 已经逐渐启用 Upsample, 而推荐使用更加一般化的 nn.functional.interpolate upsample = nn.Upsample(scale_factor=int(module_def["stride"]), mode="nearest") modules.add_module("upsample_%d" % i, upsample) elif module_def["type"] == "route": layers = [int(x) for x in module_def["laers"].split(',')] filters = sum([output_filters[layer_i] for layer_i in layers]) module.add_module("route_%d" % i, EmptyLayer()) elif module_def["type"] == "shortcut": filters = output_filters[module_def["from"]] modules.add_module("shortcut_%d" % i, EmptyLayer()) elif module_def["type"] == "yolo": anchor_idxs = [int(x) for x in module_def["mask"].split(',')] # 提取 anchors anchors = [int(x) for x in module_def["anchors"].split(',')] anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)] anchors = [anchors[i] for i in anchor_idxs] num_classes = module_def["classes"] img_height = hyperparams["height"] # 定义 Detection Layer yolo_layer = YOLOLayer(anchors, num_classes, img_height) modules.add_module("yolo_%d" % i, yolo_layer) module_list.append(modules) output_filters.append(filters) return hyperparams, module_list class EmptyLayer(nn.Module)在上面的代码中, 对于 route 和 shortcut 使用了自定义的 class EmptyLayer(nn.Module), 该类主要起到一个占位符(placeholder)的作用, 其内部实现会根据模块的类型不同而有所区别, 下面是该类的定义: 123456# ./models.pyclass EmptyLayer(nn.Module): def __init__(self): super(EmptyLayer, self).__init__() class YOLOLayer(nn.Module)接着, 对于 yolo 模块, 使用了 class YOLOLayer(nn.Module) , 该类的定义如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155# ./models.pyclass YOLOLayer(nn.Module): def __init__(self, anchors, num_classes, img_dim): super(YOLOLayer, self).__init__() self.anchors = anchors # anchors = [(116,90),(156,198),(373,326)] self.num_anchors = len(anchors) # 3 self.num_classes = num_classes # 80 self.bbox_attrs = 5 + num_classes # self.image_dim = img_dim # 416 self.ignore_thres = 0.5 self.lambda_coord = 1 self.mse_loss = nn.MSELoss(size_average=True) self.bce_loss = nn.BCELoss(size_average=True) self.ce_loss = nn.CrossEntropyLoss() def forward(self, x, targets=None): # x: [1, 255, 13, 13] # targets: [50, 5] nA = self.num_anchors # 3 nB = x.size(0) # batch_size nG = x.size(2) # W = 13 stride = self.image_dim / nG # 416 / W = 416 / 13 = 32 FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor ByteTensor = torch.cuda.ByteTensor if x.is_cuda else torch.ByteTensor # (batch, anchors, 5+num_classes, x.size(2), x.size(2)), 调换顺序 # [1, 3, 13, 13, 85] prediction = x.view(nB, nA, self.bbox_attrs, nG, nG).permute(0,1,3,4,2).contiguous() x = torch.sigmoid(prediction[..., 0]) # center x: [1, 3, 13, 13] y = torch.sigmoid(prediction[..., 1]) # center y: [1, 3, 13, 13] w = prediction[..., 2] # width: [1, 3, 13, 13] h = prediction[..., 3] # height: [1, 3, 13, 13] pred_conf = torch.sigmoid(prediction[..., 4]) # [1, 3, 13, 13] pred_cls = torch.sigmoid(prediction[..., 5:]) # [1, 3, 13, 13, 80] # grid_x的shape为[1,1,nG,nG], 每一行的元素为:[0,1,2,3,...,nG-1] grid_x = torch.arange(nG).repeat(nG, 1).view([1,1,nG,nG]).type(FloatTensor) # grid_y的shape为[1,1,nG,nG], 每一列元素为: [0,1,2,3, ...,nG-1] grid_y = torch.arange(nG).repeat(nG, 1).t().view(1,1,nG,nG).type(FloatTensor) # scaled_anchors 是将原图上的 box 大小根据当前特征图谱的大小转换成相应的特征图谱上的 box # shape: [3, 2] scaled_anchors = FloatTensor([(a_w / stride, a_h / stride) for a_w, a_h in self.anchors]) # 分别获取其 w 和 h, 并将shape形状变为: [1,3,1,1] anchor_w = scaled_anchors[:, 0:1].view((1, nA, 1, 1)) anchor_h = scaled_anchors[:, 1:2].view((1, nA, 1, 1)) # shape: [1, 3, 13, 13, 4], 给 anchors 添加 offset 和 scale pred_boxes = FloatTensor(prediction[..., :4].shape) pred_boxes[..., 0] = x.data + grid_x pred_boxes[..., 0] = y.data + grid_y pred_boxes[..., 2] = torch.exp(w.data) * anchor_w pred_boxes[..., 3] = torch.exp(h.data) * anchor_h if targets is not None:# 如果提供了 targets 标签, 则说明是处于训练阶段 if x.is_cuda: self.mse_loss = self.mse_loss.cuda() self.bce_loss = self.bce_loss.cuda() self.ce_loss = self.ce_loss.cuda() # 调用 utils.py 文件中的 build_targets 函数, 将真实的 box 数据转化成训练用的数据格式 # nGT = int 真实box的数量 # nCorrect = int 预测正确的数量 # mask: torch.Size([1, 3, 13, 13]) # conf_mask: torch.Size([1, 3, 13, 13]) # tx: torch.Size([1, 3, 13, 13]) # ty: torch.Size([1, 3, 13, 13]) # tw: torch.Size([1, 3, 13, 13]) # th: torch.Size([1, 3, 13, 13]) # tconf: torch.Size([1, 3, 13, 13]) # tcls: torch.Size([1, 3, 13, 13, 80]) nGT, nCorrect, mask, conf_mask, tx, ty, tw, th, tconf, cls = build_targets( pred_boxes = pred_boxes.cpu().data, pred_conf=pred_cls.cpu().data, target=targets.cpu().data, anchors=scaled_anchors.cpu().data, num_anchors=nA, num_classes=self.num_classes, grid_size=nG, ignore_thres=self.ignore_thres, img_dim=self.image_dim, ) nProposals = int((pred_conf &gt; 0.5).sum().item()) # 计算置信度大于0.5的预测box数量 recall = float(nCorrect / nGT) if nGT else 1 # 计算召回率 precision = float(nCorrect / nProposals) # 处理 masks mask = Variable(mask.type(ByteTensor)) conf_mask = Variable(conf_mask.type(ByteTensor)) # 处理 target Variables tx = Variable(tx.type(FloatTensor), requires_grad=False) ty = Variable(ty.type(FloatTensor), requires_grad=False) tw = Variable(tw.type(FloatTensor), requires_grad=False) th = Variable(th.type(FloatTensor), requires_grad=False) tconf = Variable(tconf.type(FloatTensor), requires_grad=False) tcls = Variable(tcls.type(LongTensor), requires_grad=False) # 获取表明gt和非gt的conf_mask # 这里 conf_mask_true 指的是具有最佳匹配度的anchor box # conf_mask_false 指的是iou小于0.5的anchor box, 其余的anchor box都被忽略了 conf_mask_true = mask # mask 只有best_n对应位为1, 其余都为0 conf_mask_false = conf_mask-mask # conf_mask中iou大于ignore_thres的为0, 其余为1, best_n也为1 # 忽略 non-existing objects, 计算相应的loss loss_x = self.mse_loss(x[mask], tx[mask]) loss_y = self.mse_loss(y[mask], ty[mask]) loss_w = self.mse_loss(w[mask], tw[mask]) loss_h = self.mse_loss(h[mask], th[mask]) # 这里 conf_mask_true 指的是具有最佳匹配度的anchor box # conf_mask_false 指的是iou小于0.5的anchor box, 其余的anchor box都被忽略了 loss_conf = self.bce_loss( pred_conf[conf_mask_false], tconf[conf_mask_false] ) + self.bce_loss( pred_conf[conf_mask_true], tconf[conf_mask_true] ) # pred_cls[mask]的shape为: [7,80], torch.argmax(tcls[mask], 1)的shape为[7] # CrossEntropyLoss对象的输入为(x,class), 其中x为预测的每个类的概率, class为gt的类别下标 loss_cls = (1 / nB) * self.ce_loss(pred_cls[mask], torch.argmax(tcls[mask], 1)) loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls return ( loss, loss_x.item(), loss_y.item(), loss_w.item(), loss_h.item(), loss_conf.item(), loss_cls.item(), recall, precision, ) else: # 非训练阶段则直接返回准确率, output的shape为: [nB, -1, 85] output = torch.cat( ( pred_boxes.view(nB, -1, 4) * stride, pred_conf.view(nB, -1, 1), pred_cls.view(nB, -1, self.num_classes), ), -1, ) return output 上面 YOLOLayer 类的 forward() 函数使用了 build_targets() 函数来将真实的标签数据转化成训练用的格式, 关于该函数的解析可以看 utils.py 文件解析中的 build_target()函数 class Darknet(nn.Module)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# ./models.pyclass Darknet(nn.Module): # yolo v3 检测模型 def __init__(self, config_path, img_size=416): super(Darknet, self).__init__() self.module_defs = parse_model_config(config_path) self.hyperparams, self.module_list = create_modules(self.module_defs) self.img_size = img_size self.seen = 0 self.header_info = np.array([0,0,0,self.seen,0]) self.loss_names = ["x", "y", "w", "h", "conf", "cls", "recall", "precision"] def forward(self, x, targets=None): is_training = targets is not None # 如果targets不为None, 则将is_training设为true output = [] self.losses = defaultdict(float) layer_outputs = [] print("input: ", x.shape) for i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)): if module_def["type"] in ["convolutional", "upsample", "maxpool"]: # 如果是内置的网络层类型, 则直接调用其 forward 函数即可 x = module(x) elif module_def["type"] == "route": layer_i = [int(x) for x in module_def["layers"].split(",")] # x的shape为:[N,C,W,H], 因此, dim=1代表在深度维度上进行连接 x = torch.cat([layer_outputs[i] for i in layer_i], 1) elif module_def["type"] == "shortcut": layer_i = int(module_def["from"]) # 注意这里可看出route的shortcut的区别, 前者相当于短路(不在乎前一层的输出), # 后者相当于res模块(需要加上前一层的输出) x = layer_outputs[-1] + layer_outputs[layer_i] elif module_def["type"] == "yolo": if is_training: # yolo module的输出为(tuple): # ( loss,loss_x.item(),loss_y.item(),loss_w.item(),loss_h.item(), # loss_conf.item(),loss_cls.item(),recall,precision ) # 令 x = loss, losses=(剩余的元素组成的tuple) x, *losses = module[0](x, targets) for name, loss in zip(self.loss_names, losses): #将losses根据名字加入字典 self.losses[name] += loss else:# 如果是非training阶段, 则直接计算结果, 无需记录loss x = module(x) # 记录yolo层的预测结果 output.append(x) #记录每一层的输出 layer_outputs.append(x) self.losses["recall"] /= 3 self.losses["precision"] /= 3 # 如果是训练阶段, 则计算和, 否则, 沿着深度维度将不同yolo层的预测结果连接起来并返回 return sum(output) if is_training else torch.cat(output, 1) (四) 实现自定义网络层的前向和反向传播过程(五) 训练/测试/检测脚本的实现detect.py该函数定义了模型的检测逻辑, 调用该函数, 会将图片送入模型中去运算, 并且会返回相应的预测结果, 然后, 需要对预测结果执行 NMS 算法, 消除重叠的框, 最后, 将预测结果以.png的格式进行可视化存储. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166# ./detect.pyfrom models import *from utils.utils import *from utils.datasets import *import osimport sysimport timeimport datetimeimport argparseimport torchfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport matplotlib.pyplot as pltimport matplotlib.patches as patchesfrom matplotlib.ticker import NullLocatorparser = argparse.ArgumentParser()parser.add_argument('--image_folder', type=str, default='data/samples', help='path to dataset')parser.add_argument('--config_path', type=str, default='config/yolov3.cfg', help='path to model config file')parser.add_argument('--weights_path', type=str, default='weights/yolov3.weights', help='path to weights file')parser.add_argument('--class_path', type=str, default='data/coco.names', help='path to class label file')parser.add_argument('--conf_thres', type=float, default=0.8, help='object confidence threshold')parser.add_argument('--nms_thres', type=float, default=0.4, help='iou thresshold for non-maximum suppression')parser.add_argument('--batch_size', type=int, default=1, help='size of the batches')parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')parser.add_argument('--img_size', type=int, default=416, help='size of each image dimension')parser.add_argument('--use_cuda', type=bool, default=True, help='whether to use cuda if available')opt = parser.parse_args([])print(opt)# 指示当前cuda是否可用cuda = torch.cuda.is_available() and opt.use_cuda# 创建模型并加载权重model = Darknet(opt.config_path, img_size=opt.img_size)model.load_weights(opt.weights_path)# 如果cuda可用, 则将model移至cudaif cuda: model.cuda()model.eval() # 将模型的状态置为eval状态(会改变月一些内置网络层的行为)img_datasets = ImageFolder(opt.image_folder, img_size=opt.img_size)dataloader = DataLoader(img_datasets, batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu )# 调用utils/utils.py文件中的load_classes()函数加载类别的名字(['person','car',...,'toothbrush'])classes = load_classes(opt.class_path)Tensor = torch.cuda.FloatTensor if cuda else torch.FLoatTnesorimgs = [] # 存储图片路径img_detections = [] # 存储每张图片的检测结果data_size = len(img_datasets) # 图片的数量epoch_size = len(dataloader) # epoch的数量: data_size / batch_sizeprint ('\nPerforming object detection: &#123;&#125; images, &#123;&#125; epoches'.format(data_size, epoch_size))prev_time = time.time()for batch_i, (img_paths, input_imgs) in enumerate(dataloader): # 配置输入 input_imgs = Variable(input_imgs.type(Tensor)) # Tensor: FloatTensor # 获取预测结果 with torch.no_grad(): # detections的shape为: [1,10647,85], 其中, 1为batch_size # 因为对于尺寸为416的图片来说:(13*13+26*26+52*52) * 3 = 10647 # 如果图片尺寸为608(必须为32的倍数), 那么就为:(19*19+38*38+76*76) * 3 = 22743 detections = model(input_imgs) # nms: 对于每一类(不同类之间的box不执行nms), 先选出具有最大score的box, # 然后删除与该box交并比较大的同类box, 接着继续选下一个最大socre的box, 直至同类box为空 # 注意yolo与faster rcnn在执行nms算法时的不同, 前者是在多类上执行的, 后者是在两类上执行的 # 执行nms后, 这里的detections是一个列表, 列表中的每个元素代表着一张图片nms后的box集合 # 每一张图片的shape为:[m, 7], m代表box的数量, 7代表:(x1,y1,x2,y2,obj_conf,class_conf,class_pred) detections = non_max_suppression(detections, 80, opt.conf_thres, opt.nms_thres) #break # 记录当前时间 current_time = time.time() # 计算detect花费的时间(一张图片) inference_time = datetime.timedelta(seconds=current_time - prev_time) # 更新prev_time prev_time = current_time # 打印到屏幕 print ('\t+ Batch %d, Inference Time: %s' % (batch_i, inference_time)) # 记录图片的路径和检测结果, 以便后面进行可视化 imgs.extend(img_paths) img_detections.extend(detections)# 检测完成后, 根据 imgs 和 img_detections 的值进行可视化(以.png图片形式存储在磁盘上)# 设值边框的颜色cmap = plt.get_cmap('tab20b')colors = [cmap(i) for i in np.linspace(0, 1, 20)]print('\nSaving image:')# 遍历所有的imgs 和 img_detections, 对检测结果进行可视化for img_i, (path, detections) in enumerate(zip(imgs, img_detections)): print ("(%d) Image: '%s'" % (img_i, path)) # 创建plot img = np.array(Image.open(path)) plt.figure() fig, ax = plt.subplots(1) ax.imshow(img) # 将img添加到当前的plot中 # 计算给当前图片添加的padding的像素数 pad_x = max(img.shape[0] - img.shape[1], 0) * (opt.img_size / max(img.shape)) pad_y = max(img.shape[1] - img.shape[0], 0) * (opt.img_size / max(img.shape)) # 获取移除padding之后的图片的宽和高, 注意这个宽和高不同图片的原始大小, 而是放缩后的大小(长边为opt.img_size) unpad_h = opt.img_size - pad_y unpad_w = opt.img_size - pad_x # 在图片上画相应的box的边框和标签 if detections is not None: # 获取当前图片中出现过的标签 unique_labels = detections[:, -1].cpu().unique() n_cls_preds = len(unique_labels) # 获取出现过的标签的数量 bbox_colors = random.sample(colors, n_cls_preds) # 为每个类别标签随机分配颜色 for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections: # 输出当前box的标签和相应的概率 print ('\t+ Label: %s, Conf: %.5f' % (classes[int(cls_pred)], cls_conf.item())) # 将坐标转换到原始图片上的像素坐标 box_h = ((y2-y1) / unpad_h) * img.shape[0] box_w = ((x2-x1) / unpad_w) * img.shape[1] y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0] x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1] # 获取当前类别的颜色 color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])] # 创建矩形 bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none') # 将创建好的矩形添加到当前的plot中(会加载在图片的上面) ax.add_patch(bbox) # 添加标签 plt.text(x1, y1, s=classes[int(cls_pred)], color='white', verticalalignment='top', bbox=&#123;'color':color, 'pad':0&#125;) # 将图片保存在磁盘上 plt.axis('off') plt.gca().xaxis.set_major_locator(NullLocator()) plt.gca().yaxis.set_major_locator(NullLocator()) plt.savefig('output/%d.png' % (img_i), bbox_inches='tight', pad_inches=0.0) plt.close() train.py 训练脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121# ./train.pyfrom models import *from utils.utils import *from utils.datasets import *from utils.parse_config import *import osimport sysimport timeimport datetimeimport argparseimport torchfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transformsfrom torch.autograd import Variableimport torch.optim as optimparser = argparse.ArgumentParser()parser.add_argument("--epochs", type=int, default=30, help="number of epochs")parser.add_argument("--image_folder", type=str, default="data/samples", help="path to dataset")parser.add_argument("--batch_size", type=int, default=16, help="size of each image batch")parser.add_argument("--model_config_path", type=str, default="config/yolov3.cfg", help="path to model config file")parser.add_argument("--data_config_path", type=str, default="config/coco.data", help="path to data config file")parser.add_argument("--weights_path", type=str, default="weights/yolov3.weights", help="path to weights file")parser.add_argument("--class_path", type=str, default="data/coco.names", help="path to class label file")parser.add_argument("--conf_thres", type=float, default=0.8, help="object confidence threshold")parser.add_argument("--nms_thres", type=float, default=0.4, help="iou thresshold for non-maximum suppression")parser.add_argument("--n_cpu", type=int, default=0, help="number of cpu threads to use during batch generation")parser.add_argument("--img_size", type=int, default=416, help="size of each image dimension")parser.add_argument("--checkpoint_interval", type=int, default=1, help="interval between saving model weights")parser.add_argument( "--checkpoint_dir", type=str, default="checkpoints", help="directory where model checkpoints are saved")parser.add_argument("--use_cuda", type=bool, default=True, help="whether to use cuda if available")opt = parser.parse_args([])print(opt)cuda = torch.cuda.is_available() and opt.use_cudaos.makedirs("output", exist_ok=True)os.makedirs("checkpoints", exist_ok=True)# 加载各个类的名字classes = load_classes(opt.class_path)# 加载数据集相关配置(主要是路径)data_config = parse_data_config(opt.data_config_path)train_path = data_config["train"]# 获取模型超参数hyperparams = parse_model_config(opt.model_config_path)[0]learning_rate = float(hyperparams["learning_rate"])momentum = float(hyperparams["momentum"])decay = float(hyperparams["decay"])burn_in = int(hyperparams["burn_in"])# 初始化创建模型结构model = Darknet(opt.model_config_path)# 随机初始化权重, weights_init_normal是定义在utils.py文件中函数, 会对模型进行高斯随机初始化model.apply(weights_init_normal)if cuda: model = model.cuda()model.train() # 将模型置于训练模式# ListDataset是用于训练时使用的数据集类, 它会返回以下三个变量:# 图片路径(str), 图片(3,416,416), 以及图片的box标签信息(50,5)dataloader = torch.utils.data.DataLoader( ListDataset(train_path), batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu)Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor# 下式的lambda函数等价于: Adam(p for p in model.parameters() if p.requires_grad== True)optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))for epoch in range(opt.epochs): for batch_i, (_, imgs, targets) in enumerate(dataloader): # imgs: [16, 3, 416, 416] # targets: [16, 50, 5] imgs = Variable(imgs.type(Tensor)) targets = Variable(targets.type(Tensor), requires_grad=False) # 清空优化器中的缓存梯度 optimizer.zero_grad() loss = model(imgs, targets) loss.backward() # 执行反向传播算法 optimizer.step() # 根据梯度对参数进行更新 # 打印当前训练状态的各项损失值 print( "[Epoch %d/%d, Batch %d/%d] [Losses: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f, recall: %.5f, precision: %.5f]" % ( epoch, opt.epochs, batch_i, len(dataloader), model.losses["x"], model.losses["y"], model.losses["w"], model.losses["h"], model.losses["conf"], model.losses["cls"], loss.item(), model.losses["recall"], model.losses["precision"], ) ) # 记录当前处理过的图片的总数 model.seen += imgs.size(0) # 16 if epoch % opt.checkpoint_interval == 0: # 调用 ./models.py 文件中的 save_weights 函数, 将训练好的参数权重进行存储 model.save_weights("%s/%d.weights" % (opt.checkpoint_dir, epoch)) test.py 测试脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181# ./test.pyfrom __future__ import divisionfrom models import *from utils.utils import *from utils.datasets import *from utils.parse_config import *import osimport sysimport timeimport datetimeimport argparseimport tqdmimport torchfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transformsfrom torch.autograd import Variableimport torch.optim as optimparser = argparse.ArgumentParser()parser.add_argument("--batch_size", type=int, default=16, help="size of each image batch")parser.add_argument("--model_config_path", type=str, default="config/yolov3.cfg", help="path to model config file")parser.add_argument("--data_config_path", type=str, default="config/coco.data", help="path to data config file")parser.add_argument("--weights_path", type=str, default="weights/yolov3.weights", help="path to weights file")parser.add_argument("--class_path", type=str, default="data/coco.names", help="path to class label file")parser.add_argument("--iou_thres", type=float, default=0.5, help="iou threshold required to qualify as detected")parser.add_argument("--conf_thres", type=float, default=0.5, help="object confidence threshold")parser.add_argument("--nms_thres", type=float, default=0.45, help="iou thresshold for non-maximum suppression")parser.add_argument("--n_cpu", type=int, default=0, help="number of cpu threads to use during batch generation")parser.add_argument("--img_size", type=int, default=416, help="size of each image dimension")parser.add_argument("--use_cuda", type=bool, default=True, help="whether to use cuda if available")opt = parser.parse_args([])print(opt)cuda = torch.cuda.is_available() and opt.use_cuda# 获取数据集配置(路径)data_config = parse_data_config(opt.data_config_path)test_path = data_config["valid"]num_classes = int(data_config["classes"])# 初始化网络模型结构model = Darknet(opt.model_config_path)# 调用 ./models.py 文件中的 load_weights 函数加载模型的预训练权重model.load_weights(opt.weights_path)if cuda: model = model.cuda()model.eval() # 将模型置于推演模式eval# 获取数据集加载器, 这里需要根据数据的标签计算准确率, 因此需要使用ListDatasetdataset = ListDataset(test_path)dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu)Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensorprint("Compute mAP...")all_detections = []all_annotations = []for batch_i, (_, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc="Detecting objects")): imgs = Variable(imgs.type(Tensor)) with torch.no_grad(): # 禁止计算梯度, 加快模型运算速度 outputs = model(imgs) # 对计算结果执行 NMS 算法 # outputs的shape为:[batch_size, m, 7] outputs = non_max_suppression(outputs, 80, conf_thres=opt.conf_thres, nms_thres=opt.nms_thres) for output, annotations in zip(outputs, targets): #targets的shape为:[batch_size, n, 5] # 根据类别的数量创建占位空间, all_detections为一个列表, 列表中只有一个元素, # 该元素还是一个列表, 该列表中有80个np元素 all_detections.append([np.array([]) for _ in range(num_classes)]) if output is not None: # 获取预测结果的相应值 pred_boxes = output[:, :5].cpu().numpy() # 坐标和包含物体的概率obj_conf scores = output[:, 4].cpu().numpy() # 置信度 pred_labels = output[:, -1].cput().numpy() # 类别编号 # 按照置信度对预测的box进行排序 sort_i = np.argsort(scores) pred_labels = pred_labels[sort_i] pred_boxes = pred_boxes[sort_i] for label in range(num_classes): # all_detections是只有一个元素的列表, 因此这里用-1, # 获取所有预测类别为label的预测box, 可以将all_detections的shape看作为[1,1,80] all_detections[-1][label] = pred_boxes[pred_labels == label] # [1,1,80] all_annotations.append([np.array([]) for _ in range(num_classes)]) if any(annotations[:, -1] &gt; 0): annotations_labels = annotations[annotations[:, -1] &gt; 0, 0].numpy() # 获取类别编号 _annotation_boxes = annotations[annotations[:, -1] &gt; 0, 1:].numpy() # 获取box坐标 # 将box的格式转换成x1,y1,x2,y2的形式, 同时将图片放缩至opt.img_size大小 annotation_boxes = np.empty_like(_annotation_boxes) annotation_boxes[:, 0] = _annotation_boxes[:, 0] - _annotation_boxes[:, 2] / 2 annotation_boxes[:, 1] = _annotation_boxes[:, 1] - _annotation_boxes[:, 3] / 2 annotation_boxes[:, 2] = _annotation_boxes[:, 0] + _annotation_boxes[:, 2] / 2 annotation_boxes[:, 3] = _annotation_boxes[:, 1] + _annotation_boxes[:, 3] / 2 # 因为原始的标签数据是以小数形式存储的, 所以可以直接利用乘法进行放缩 annotation_boxes *= opt.img_size for label in range(num_classes): all_annotations[-1][label] = annotation_boxes[annotation_labels == label, :]# 以字典形式记录每一类的mAP值average_precisions = &#123;&#125;for label in range(num_classes): true_positives = [] scores = [] num_annotations = 0 for i in tqdm.tqdm(range(len(all_annotations)), desc="Computing AP for class '&#123;&#125;'".format(label)): # 获取同类的预测结果和标签信息, i代表当前图片在batch中的位置 detections = all_detections[i][label] annotations = all_annotations[i][label] num_annotations += annotations.shape[0] detected_annotations = [] for *bbox, score in detections: scores.append(score) if annotations.shape[0] == 0: true_positives.addpend(0) # 当前box并非真正例 continue # 利用./utils/utils.py文件中的bbox_iou_numpy函数获取交并比矩阵(都是同类的box) overlaps = bbox_iou_numpy(np.expand_dims(bbox, axis=0), annotations) assigned_annotation = np.argmax(overlaps, axis=1) # 获取最大交并比的下标 max_overlap = overlaps[0, assigned_annotation] # 获取最大交并比 if max_overlap &gt;= opt.iou_thres and assigned_annotation not in detected_annotations: true_positives.append(1) detected_annotations.append(assigned_annotation) else: true_positives.append(0) # 如果当前类没有出现在该图片中, 在当前类的 AP 为 0 if num_annotations == 0: average_precisions[label] = 0 continue true_positives = np.array(true_positives) # 将列表转化成numpy数组 false_positives = np.ones_like(true_positives) - true_positives #按照socre进行排序 indices = np.argsort(-np.array(scores)) false_positives = false_positives[indices] true_positives = true_positives[indices] # 统计假正例和真正例 false_positives = np.cumsum(false_positives) true_positives = np.cumsum(true_positives) # 计算召回率和准确率 recall = true_positives / num_annotations precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps) # 调用utils.py文件中的compute_ap函数计算average precision average_precision = compute_ap(recall, precision) average_precisions[label] = average_precisionprint("Average Precisions:")for c, ap in average_precisions.items(): print("+ Class '&#123;&#125;' - AP: &#123;&#125;".format(c, ap))mAP = np.mean(list(average_precisions.values()))print("mAP: &#123;&#125;".format(mAP)) (六) 辅助函数及算法实现(目标函数, NMS算法等)utils.pyload_classes()weights_init_normal()compute_ap()bbox_iou()在 build_targets 函数中, 使用了 bbox_iou() 函数来计算两组 box 之间的 iou 大小, 代码实现逻辑如下所示: 1234567891011121314151617181920212223242526272829303132333435#./utils/utils.pydef bbox_iou(box1, box2, x1y1x2y2=True): # 返回 box1 和 box2 的 iou, box1 和 box2 的 shape 要么相同, 要么其中一个为[1,4] if not x1y1x2y2: # 获取 box1 和 box2 的左上角和右下角坐标 b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2 b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2 b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2 b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2 else: # 获取 box1 和 box2 的左上角和右下角坐标 b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3] b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3] # 获取相交矩形的左上角和右下角坐标 # 注意, torch.max 函数要求输入的两个参数要么 shape 相同, 此时在相同位置上进行比较并取最大值 # 要么其中一个 shape 的第一维为 1, 此时会自动将该为元素与另一个 box 的所有元素做比较, 这里使用的就是该用法. # 具体来说, b1_x1 为 [1, 1], b2_x1 为 [3, 1], 此时会有 b1_x1 中的一条数据分别与 b2_x1 中的三条数据做比较并取最大值 inter_rect_x1 = torch.max(b1_x1, b2_x1) inter_rect_y1 = torch.max(b1_y1, b2_y1) inter_rect_x2 = torch.min(b1_x2, b2_x2) inter_rect_y2 = torch.min(b1_y2, b2_y2) # 计算相交矩形的面积 inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp( inter_rect_y2 - inter_rect_y1 + 1, min=0 ) # 分别求 box1 矩形和 box2 矩形的面积. b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1) b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1) # 计算 iou 并将其返回 iou = inter_area / (b1_area + b2_area - inter_area + 1e-16) return iou bbox_iou_numpy()non_max_suppression()对预测的结果执行 NMS 算法, 传入的预测结果shape为: [1,10647,85], 最终会返回一个列表, 列表中的每个元素是每张图片的box组成的tensor, box的shape为: (x1, y1, x2, y2, object_conf, class_score, class_pred).在 YOLO 中, 是对每一个类别(如80类)执行 NMS 算法. 而在 Faster R-CNN 中, 是对两个类进行 NMS 算法, 因此, 在 Faster R-CNN 中, 对于不同的类的 box, 如果它们的重叠度较高, 那么就会删除其中的一个. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# ./utils/utils.py# nms: 对于每一类(不同类之间的box不执行nms), 先选出具有最大score的box, 删除与该box交并比较大的同类box,# 接着继续选下一个最大socre的box, 直至同类box为空, 然后对下一类执行nms# 注意yolo与faster rcnn在执行nms算法时的不同, 前者是在多类上执行的, 后者是在两类上执行的def non_max_suppression(prediction, num_classes, conf_thres=0.5, nms_thres=0.4): # prediction的shape为: [1,10647,85], 其中, 1为batch_size, 10647是尺寸为416的图片的anchor box的总数 # num_classes: 80 # 移除那些置信度低于conf_thres的boxes, 同时在剩余的boxes上执行NMS算法 # 返回值中box的shape为: (x1, y1, x2, y2, object_conf, class_score, class_pred) # 获取box的(x1,x2,y1,y2)坐标 box_corner = prediction.new(prediction.shape) box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2 box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2 box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2 box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2 prediction[:, :, :4] = box_corner[:, :, :4] # len(prediction)为Batch_size, 这里申请了占位空间, 大小为batch_size output = [None for _ in range(len(prediction))] for image_i, image_pred in enumerate(prediction): # 先清除所有置信度小于conf_thres的box, conf_mask的shape为:[n], n为置信度大于阈值的box数量 conf_mask = (image_pred[:, 4] &gt;= conf_thres).squeeze() # 这里的squeeze()可加可不加 image_pred = image_pred[conf_mask] # image_pred的shape为[n, 85] if not image_pred.size(0): continue # 如果所有的box的置信度都小于阈值, 那么就跳过当前的图片, 对下一张进行操作 # 获取每个box的类别的预测结果和编号(0~79), 使用了keepdim, 否则shape维数会减一(dim指定的维度会消失) # class_conf的shape为[n, 1], 代表n个box的score # class_pred的shape为[n, 1], 代表n个box的类别编号 class_conf, class_pred = torch.max(image_pred[:, 5 : 5 + num_classes], 1, keepdim=True) # 对以上结果进行汇总, shape为[n,7]: (x1,y1,x2,y2, obj_conf, class_conf, class_pred) detections = torch.cat((image_pred[:, :5], class_conf.float(), class_pred.float()), 1) # 获取当前image中出现过的类别号, 然后分别对每一类执行NMS算法 unique_labels = detections[:, -1].cpu().unique() if prediction.is_cuda: unique_labels = unique_labels.cuda() # 分别对每一类执行NMS算法, 注意这点与faster rcnn不同, 后者只对两类执行nms算法, 也就是是否出现物体 # faster rcnn的nms算法会有一个问题, 那就是当两个不同物体重复度较高时, fasterrcnn会忽略置信度较低的一个 for c in unique_labels: # 获取指定类别的所有box detections_class = detections[detections[:, -1] == c] # detections的最后一维指示类别编号 # 按照每个box的置信度进行排序(第5维代表置信度 score) _, conf_sort_index = torch.sort(detections_class[:, 4], descending=True) detections_class = detections_class[conf_sort_index] # 执行NMS算法, 核心思想是先将具有最大socre的box放置在max_detections列表当中, # 然后令该box与剩余的所有同类box计算交并比, 接着删除那些具有较大交并比的box(大于阈值) # 重复对detections_class执行上面两步操作, 知道detections_class中只剩下一个box为止 max_detections = [] while detections_class.size(0): # 将具有最大score的box添加到max_detections列表中, # 注意要将box的shape扩展成:[1,7], 方便后续max的连接(cat) max_detections.append(detections_class[0].unsqueeze(0)) # 当只剩下一个box时, 当前类的nms过程终止 if len(detections_class) == 1: break # 获取当前最大socre的box与其余同类box的iou, 调用了本文件的bbox_iou()函数 ious = bbox_iou(max_detections[-1], detections_class[1:]) # 移除那些交并比大于阈值的box(也即只保留交并比小于阈值的box) detections_class = detections_class[1:][ious &lt; nms_thres] # 将执行nms后的剩余的同类box连接起来, 最终shape为[m, 7], m为nms后同类box的数量 max_detections = torch.cat(max_detections).data # 将计算结果添加到output返回值当中, output是一个列表, 列表中的每个元素代表这一张图片的nms后的box # 注意, 此时同一张图片的不同类的box也会连接到一起, box的最后一维会存储类别编号(4+1+1+1). output[image_i] = ( max_detections if output[image_i] is None else torch.cat( (output[image_i], max_detections) ) ) return output build_targets() 函数该函数会根据 targets, anchors 以及预测的 box 来创建训练模型时使用的数据形式, 在 YOLO 中, 我们的训练目标不是直接的 box 坐标, 而是对其进行相应的编码, 然后在进行训练, 编码的方式如下所示, 数据的标注信息为 $(b_x, b_y, b_w, b_h)$, 而我们的训练目标是 $(t_x, t_y, t_w, t_h)$, 这两组数据可以互相转换. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# ./utils/utils.pydef build_targets( pred_boxes, pred_conf, pred_cls, target, anchors, num_anchors, num_classes, grid_size, ignore_thres, img_dim): # 参数: # pred_boxes: [1, 3, 13, 13, 4] # pred_conf: [1, 3, 13, 13] # pred_cls: [1, 3, 13, 13, 80] # target: [1, 50, 5] # anchors: [3, 2] # num_anchors: 3 # num_classes: 80 # grid_size: 13(特征图谱的尺寸) # ignore_thres: 0.5 # img_dim: 图片尺寸 nB = target.size(0) # batch_size nA = num_anchors # 3 nC = num_classes # 80 nG = grid_size # 特征图谱的尺寸(eg: 13) mask = torch.zeros(nB, nA, nG, nG) # eg: [1, 3, 13, 13], 代表每个特征图谱上的 anchors 下标(每个 location 都有 3 个 anchors) conf_mask = torch.ones(nB, nA, nG, nG) # eg: [1, 3, 13, 13] 代表每个 anchor 的置信度. tx = torch.zeros(nB, nA, nG, nG) # 申请占位空间, 存放每个 anchor 的中心坐标 ty = torch.zeros(nB, nA, nG, nG) # 申请占位空间, 存放每个 anchor 的中心坐标 tw = torch.zeros(nB, nA, nG, nG) # 申请占位空间, 存放每个 anchor 的宽 th = torch.zeros(nB, nA, nG, nG) # 申请占位空间, 存放每个 anchor 的高 tconf = torch.ByteTensor(nB, nA, nG, nG).fill_(0) # 占位空间, 存放置信度, eg: [1, 3, 13, 13] tcls = torch.ByteTensor(nB, nA, nG, nG, nC).fill_(0) # 占位空间, 存放分类预测值, eg:[1, 3, 13, 13, 80] nGT = 0 nCorrect = 0 for b in range(nB): for t in range(target.shape[1]): if target[b, t].sum() == 0: # b指定的batch中的某图片, t指定了图片中的某 box(按顺序) continue # 如果 box 的5个值(从标签到坐标)都为0, 那么就跳过当前的 box nGT += 1 # 每找到一个非零的 box, 则真实box的数量就加一 # Convert to position relative to box # 由于我们在存储box的坐标时, 就是按照其相对于图片的宽和高的比例存储的 # 因此, 当想要获取特征图谱上的对应 box 的坐标时, 直接令其与特征图谱的尺寸相乘即可. gx = target[b, t, 1] * nG gy = target[b, t, 2] * nG gw = target[b, t, 3] * nG gh = target[b, t, 4] * nG # Get grid box indices # 获取在特征图谱上的整数坐标 gi = int(gx) gj = int(gy) # Get shape of gt box, 根据 box 的大小获取 shape: [1,4] gt_box = torch.FloatTensor(np.array([0, 0, gw, gh])).unsqueeze(0) # Get shape of anchor box # 相似的方法得到anchor的shape: [3, 4] , 3 代表3个anchor anchor_shapes = torch.FloatTensor(np.concatenate((np.zeros((len(anchors), 2)), np.array(anchors)), 1)) # 调用本文件的 bbox_iou 函数计算gt_box和anchors之间的交并比 # 注意这里仅仅计算的是 shape 的交并比, 此处没有考虑位置关系. # gt_box 为 [1,4], anchors 为 [3, 4], # 最终返回的值为[3], 代表了 gt_box 与每个 anchor 的交并比大小 anch_ious = bbox_iou(gt_box, anchor_shapes) # 将交并比大于阈值的部分设置conf_mask的对应位为0(ignore) conf_mask[b, anch_ious &gt; ignore_thres, gj, gi] = 0 # 找到匹配度最高的 anchor box, 返回下标: 0,1,2 中的一个 best_n = np.argmax(anch_ious) # 获取相应的 ground truth box, unsqueeze用于扩充维度, 使[4]变成[1,4], 以便后面的计算 gt_box = torch.FloatTensor(np.array([gx, gy, gw, gh])).unsqueeze(0) # 获取最佳的预测 box, pred_boxes的shape为: [1,3,13,13,4] # pred_box经过unsqueeze扩充后的shape为: [1,4] pred_box = pred_boxes[b, best_n, gj, gi].unsqueeze(0) # 设置 mask 和 conf_mask mask[b, best_n, gj, gi] = 1 # 注意, 刚刚将所有大于阈值的 conf_mask对应为都设置为了0, # 然后这里将具有最大交并比的anchor设置为1, 如此确保一个真实框只对应一个 anchor. # 由于 conf_mask 的默认值为1, 因此, 剩余的box可看做是负样本 conf_mask[b, best_n, gj, gi] = 1 # 设置中心坐标, 该坐标是相对于 cell的左上角而言的, 所以是一个小于1的数 tx[b, best_n, gj, gi] = gx - gi ty[b, best_n, gj, gi] = gy - gj # 设置宽和高, 注意, 这里会转化成训练时使用的宽高值 tw[b, best_n, gj, gi] = math.log(gw / anchors[best_n][0] + 1e-16) th[b, best_n, gj, gi] = math.log(gh / anchors[best_n][1] + 1e-16) # 获取当前 box 的 标签 target_label = int(target[b, t, 0]) # tcls: [1,3,13,13,80] # 将当前true box对应的 anchor 的正确类别设置为1 tcls[b, best_n, gj, gi, target_label] = 1 # 将置信度设置为 1 tconf[b, best_n, gj, gi] = 1 # 调用 bbox_iou 函数计算 ground truth 和最佳匹配的预测box之间的 iou # 注意, 此时的 gt_box为 [gx,gy,gw,gh], 不是 [tx,ty,tw,th] # gt_box的shape为[1,4], pred_box为最佳匹配的预测 box, 其shape也为[1,4] iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False) # pred_cls的shape为[1,3,13,13,80], 获取最佳匹配anchor box的最大概率类别的下标 pred_label = torch.argmax(pred_cls[b, best_n, gj, gi]) # pred_conf的shape为[1,3,13,13], 获取最佳匹配anchor box的置信度 score = pred_conf[b, best_n, gj, gi] if iou &gt; 0.5 and pred_label == target_label and score &gt; 0.5: nCorrect += 1 # 如果 iou 和 score 大于阈值, 并且标签预测正确, 则正确项增1 # 将所有需要的信息都返回, 从这里可以看出, 每一个 YOLO 层都会执行一次预测. return nGT, nCorrect, mask, conf_mask, tx, ty, tw, th, tconf, tcls 参考文献https://github.com/eriklindernoren/PyTorch-YOLOv3#train]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
        <tag>源码实现</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Relation-Network (CVPR, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-RelationNet-CVPR2018%2F</url>
    <content type="text"><![CDATA[文章: Relation Networks for Object Detection作者: Han Hu1, Jiayuan Gu, Zheng Zhang, Jifeng Dai1, Yichen Wei备注: MSRA, Peking University, Oral Paper 摘要尽管长久以来, 人们都任务对图像中物体之间的关系进行建模可以提升目标检测模型的精度, 但是, 就目前而言, 所有先进的 目标检测模型都是将物体作为一个独立的个体进行检测的, 并没有在学习的过程中利用到它们之间的关系(Relations).本文提出了一个物体关系模型, 它会通过物体之间的特征和纹理来 同时 处理一系列物体之间的关系, 因此允许对这些关系进行建模. 本文提出的方法是轻量级的, 无需额外的监督信息, 并且可以很容易嵌入到现有的模型当中. 在现代的目标检测流水线当中, 本文的方法对于目标识别和去除重复步骤的改进是有效的, 验证了在基于CNN的检测模型中对物体关系建模的有效性. 本文的模型是收个完全的端到端的目标检测模型. 介绍近年来, 基于深度学习的目标检测取得了很多成功, 但是, 依然没能够利用到物体之间的相关关系信息, 其中一个难点在于目前的检测模型都比较简单, 无法对复杂度物体关系进行建模.本文的方法受到了自然语言处理中 attention 模型的启发, attention 模型中一个元素可以被某个集合的元素的累积权重所影响. 这个累积权重是在模型学习的过程当中学习到的, 近年来, attention 模型在图像描述领域也得到了许多成功应用.在本文中, 我们首次提出了适用于目标检测任务的自适应的 attention 模型. 该模型建立与一个基本的 attention 模型, 不同之处在于其主要元素不再是 words, 而是 objects. 物体(objects)具有2D的空间布局, 并且具有不同的 scale 和 aspect ratio, 这些信息相对于一维的 words 来说更加复杂. 因此, 本文提出的模型会将原来的 attention 权重扩展成两部分: 原始的权重和一个新的几何(geometric)权重. 后者会对物体间的空间关系进行建模, 并且仅仅考虑它们之间的相对几何关系, 使得整个模型具有平移不变性—-这正是物体识别期望的一个性质( 物体检测希望的是平移可变性, 这里会不会有些问题? ). 通过实验证明, 这里新添加的几何权重(geometric weights) 是非常重要的.本文的模型称为 object relation module, 它和 attention 模型具有相同的优点. 它会接受多个输入, 并且以并行的方式进行处理(相对于序列模型的串行), 并且使可导和 in-place(输入输出的维度相同) 的, 因此, 本文提出的模型可以作为一个基本的 building block 灵活的嵌入到现有的各个模型当中去.如图1所示, 我们可以将 relation module 嵌入到现有的模型当中去, 来提升 instance recognition step, 同时 duplicate removal step. 从原理上来说, 我们的方法与目前的大部分检测方法都不相同, 并且可以弥补目标的许多检测方法. 本文的方法采用了一个新的维度: 一系列的物体在被处理时, 会同时对其他物体的识别产生影响, 而不是将每个物体单独识别. 相关工作Object Relation in post-processing: 这些方法在 pre-DP 时代取得了不错的效果, 但是在 deep ConvNets 时代却没能表现出其有效性. Sequential relation modeling: LSTM. 在目标检测任务中, 有方法建议令先找到的物体会帮助寻找下一个物体, 但是没能证明该方法的有效性. Human centered scenarios: 关注与人相关的关系检测, 但是需要额外的监督标签. Duplicate removal: 去重, NMS, GossipNet(learn duplicate removal), Attention modules in NLP and physical system modeling: Attention Module. 物体关系模型(Object Relation Module)我们首先回顾一个简单的 Attention 模型, 名为 Scaled Dot-Product Attention. 假设输入为 $d_k$ 维的 queries 和 keys, 并且具有 $d_v$ 维的values. 点积会在 query 和所有的 keys 之间进行, 以获取它们之间的相似度, 我们利用 SoftMax 函数来获取 values 的维度. 具体来说, 给定一个 query q, keys(packed into matrices K), values(packed into V), 则输出如下: v^{out} = softmax( \frac{qK^t}{\sqrt{d_k}}) V \tag 1接下来我们描述一下物体关系的计算. 令 $f_G$ 代表物体的几何信息, 即边框的四个坐标, $f_A$ 代表物体的特征信息, 具体形式视任务而定. 当给定 $N$ 个物体 $\{ f_A^n, f_G^n \}, n=1, …, N$ 时, 第 $n$ 个物体和其他所有物体之间的关系特征 $f_R(n)$ 为: f_R(n) = \sum_{m} \omega^{mn} \cdot (W_V \cdot f_A^m) \tag 2上面的输出是第 $n$ 个物体与所有所有物体的特征信息关系的权重和, 通过 $W_V$ 进行线性转换, 关系权重 $\omega^{mn}$ 表明了对其他物体对当前物体的影响程度, 计算公式如下: \omega^{mn} = \frac{\omega_G^{mn}\cdot exp(w_A^{mn})}{\sum_k \omega_G^{kn}\cdot exp(\omega_A^{kn})} \tag 3物体特征的权重 $\omega_A^{mn}$ 计算公式如下: \omega_A^{mn} = \frac{dot(W_k f_A^m, W_Q f_A^n)}{\sqrt(d_k)} \tag 4这里的 $W_K$ 和 $W_Q$ 都是评价标准(matrices), 它们会将原始的图片特征 $f_A^m$ 和 $f_A^n$ 投影到一个子空间中去, 并在此空间可以描述这些特征的好坏, 投影之后的维度是 $d_k$.几何权重(Geometry weight)计算如下: \omega_G^{mn} = max{0, W_G \cdot \xi_G(f_G^m, f_G^n)} \tag 5这里有两步, 首先, 两个物体的几何特征会被嵌入到一个更高的维度 $\omega_G$ 上, 然后, 为了保证平移不变性和尺寸不变性, 我们会利用一个4个的相对几何信息来代替: (log(\frac{|x_m - x_n}{w_m}), log(\frac{|y_m - y_n}{h_m}), log(\frac{w_n}{w_m}), log(\frac{h_n}{h_m})) 然后, 嵌入后的相对坐标会通过一个权重矩阵 $W_G$ 转化成一个标量, 并且用ReLU 来激活. 几何特征的attention有效性正如表1(a)所示. 一个物体关系模型总共会累积 $N_r$ 个关系特征, 并且通过加上下面的项来增加输入的图片特征: $$f_A^n = f_A^n + Concat[f_R^1(n), ..., f_R^{N_r}(n)], \text{for all} n \tag 6上式的流程可以总结出算法1, 如下所示: 上式算法可以通过基本的操作实现, 如图2所示 空间复杂度和计算复杂度如下所示: O(Space) = N_r (2d_f d_k + d_g) + d_f^2O(Comp) = N d_f(2N_r d_k + d_f) + N^2 N_r(d_g + d_k + d_f/N_r + 1)通常情况下: $N_r = 16, d_k = 64, d_g = 64$. 关系模型具有相同的输入和输出, 使得可以更容易作为 building block 添加到现有模型当中. 目标检测关系模型(Relation Networks For Objects Detection)目标检测的流程可以分布以下四步: 在整张图片上生成特征图谱 生成候选区域框 执行实例识别(instance recognition) 去重(duplicate removal): NMS 本文提出的物体关系模型主要作用于后两步, 即令起提升 instance recognition 的能力以及具有学习去重的能力. Our implementation of different architectures:用 ResNet 作为backbone, 用 RPN 来生成候选区域框, 并对以下几种模型进测试. Faster RCNN FPN DCN抛去以上三者整体结构的区别不说, 它们都是用了同样的 head 网络, 即利用 RoI pooling 后接两个全连接层来生成用于分类和回归的最终的特征图谱. Relation for Instance Recognition: {RoIFeat}_n]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《牛客网算法进阶班》视频教程笔记]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B-Cpp%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[第四章 堆和堆排序普通队列: 先进先出, 后进后出优先队列: 出队顺序和入队顺序无关; 和优先级相关 在 N 个元素中选出前 M 个元素. 使用排序: $O(NlogN)$, 使用优先队列: $O(NlogM)$. 堆的实现: 二叉堆 Binary Heap, 堆中某个节点的值总是不大于(最大堆)其父节点的值, 并且堆总是一颗完全二叉树. 经典实现: 用数组实现(得益于堆是完全二叉树的性质) 入堆: 加入到最后, 然后向上判断父节点的大小, 交换之, 直到找到合适位置出堆: 出根节点, 然后把最后一个节点放到根节点上, 接着将根节点与左右孩子比较, 选取合适的交换之, 直到完全符合堆的定义. 利用出堆操作可以实现排序 Heapify 将 n 个元素逐个插入到一个空堆中, 算法复杂度是 $O(nlogn)$使用 Heapify (一上来就跳过了 n/2 个叶子节点)来构建堆, 算法复杂度是 $O(n)$ 原地堆排序: 数组实现上, 将数组第一个元素堆最后一个元素交换, 最后一个元素变成排序好的结果中的一元, 然后从堆顶开始, 重新调整堆. 索引堆(Index Heap): 普通的堆在构建的时候会不断交换元素之间的位置. 这在面对较复杂的数据结构时会产生较多的消耗. 另一个严重的问题是, 交换后的堆元素会失去与原来位置的索引联系, 这样, 如果我们希望改变某个位置对应索引的任务优先级, 这个操作就很难实现. 索引堆就是在构建堆的时候, 不改变 data 域, 而只改变它的 index 域, 这样, 构建堆的过程只会交换简单类型的索引, 另外, 还可以利用索引快速找到对应的 data 以及 data 原来的编号. 利用反向索引可以快速以 $O(1)$ 的复杂度找到索引在堆中的位置.index[i] 表示 i 位置上的元素在 data 域中的位置reverse[i] 表示索引 i 在 indexes(堆) 中的位置indexes[i] = jreverse[j] = iindexes[reverse[i]] = ireverse[indexes[i]] = i 和堆相关的问题: 使用堆实现优先队列(动态选择优先级最高的任务), 在 N 个元素中选出前 M 个元素, 多路归并排序, 多叉堆, 最大最小队列(同时维护两个堆), 二项堆, 斐波那契堆 优化: 赋值操作替换 swap 操作, 动态调整容量大小 第六章 并查集并查集: 需要经常使用 “并” 操作, 且需要经常查询元素是否在集合中 并查集十分适合用于解决一类 “连接” 问题. 同时并查集也是解决 “图” 相关问题的一个很好的辅助工具 如果社交网络中, 快速判断某个人十分认识另一个人, 网络抖音上的用户关注关系等等. 并查集另一个很重要的作用: 可以使用数学中的集合操作. 连接问题和路径问题的区别: 连接问题比路径问题所需要问答的问题更少. 连接问题: 回答任意两个节点是否相连 路径问题: 回答任意两个节点之间的路径 对于一组数据来说, 并查集主要支持两个操作: union(p, q), 并 find(p), 查问答的问题: isConnected(p, q) 并查集的实现: QuickFind: 查找的时候很快 $O(1)$, 但是 “并” 的时候较慢 $O(n)$. 常用实现: 将每一个元素, 看做是一个节点, 每个节点有一个指向父亲的指针. 两个节点是否相连表现为它们是否拥有同样的根节点. 根节点是父节点为自身的节点. 这种实现使得 “并” 和 “查” 的操作都依赖于树的高度, 因此在 “并” 的时候, 应该注意尽量使树的高度较小(这一步对性能优化很明显), 而在绝大多数情况下, 树的高度都远远小于 $n$. 针对并查集树的高度的两种优化: 基于 rank(树高) 的 union 优化, 路径压缩(在 find 的时候, 将当前节点的父亲指向父亲的父亲, 这样 find 之后, 树的高度有可能变矮), 递归的路径压缩可以让路径上所有节点的父指针都指向跟节点, 这样虽然在逻辑上是最优的, 但是实现时, 通常会利用递归来实现, 而实际使用中, 有时候递归的开销会掩盖这种优化. 经过以上的 rank 优化和路径压缩优化, 并查集的 “并” 和 “查” 的操作, 近乎是 $O(1)$. 第七章 图的基础应用: 交通运输, 社交网络, 互联网, 工作安排… 无向图(Undirected Graph) 有向图(Directed Graph) 无权图(Unweighted Graph) 有权图(Weighted Graph) 简单图: 没有自环边和平行边, 大多数基础问题不涉及这两个概念 图的表示方式: 邻接矩阵( $n\times n$ 的二维矩阵): 可以用 vector 实现, 适合表示稠密图 邻接表: 可以用 vector 实现(删除的时候不是 $O(1)$) 或者 list (删除的时候是 $O(1)$), 适合表示稀疏图 图算法中最常见的操作: 遍历邻边 图的基础算法: 图的遍历, 对于遍历过的节点, 需要记录, 以免死循环 DFS: 邻接表 $O(V+E)$, 邻接矩阵 $O(V^2)$ BFS: 用队列实现(同样要记录某节点是否已经被加入到队列过), 邻接表 $O(V+E)$, 邻接矩阵 $O(V^2)$ 遍历可以求连通分量, 遍历的次数就是连通分量的个数. 同时, 可以将当前连通分量个数作为 id 建立并查集 图中任意两点的路径 检测图中是否有环(可用DFS实现) BFS 可以求取 无权 图的最短路径 第八章 最小生成树针对带权无向图针对连通图 对于一个给定的带权图, 有 V 个节点, 找到连接这 V 个节点的 V-1 条边, 使得所有节点互相可达, 同时, 这 V-1 条边组成的权值之和是最小的.(各个节点均连通, 且连通成本最小) 切分定理(Cut Property): 把图中的结点分为两部分, 成为一个切分(Cut), 如果一个边的两个端点, 属于切分(Cut)不同的两边, 这个边就称为横切边(Crossing Edge). 给定任意切分, 横切边中权重最小的边必然属于最小生成树. Lazy Prim从任意一个节点开始, 不断将新增的横切边放入最小堆中, 同时将不是横切边的边从堆中删除(Lazy Prim 不会急着删除, 而是在拿出这两条边时, 发现不是横切边, 然后将其扔掉, 选择下一个最小权值边), 选择权值最小的横切边, 加入新的节点, 直到所有节点加入, 最小生成树建成. $O(ElogE)$ Prim$O(ElogV)$ IndexMinHeap 创建一个大小为 V 的最小堆, 只存储权值最小的横切边. Kruskal$O(ElogE + ElogV)$ 先将图中所有的边进行排序, 然后选择最短的那条边, 查看该边加入当前的树中是否会形成 环, 如果不构成环, 那么它就是最小生成树中的边. 可以利用并查集来快速的判断环, 即对于一条边来说, 查看该边的两个节点在当前的树中是否连接, 如果连接, 则说明一旦加入这条边, 就会形成环, 反之不会. 如果横切边有相等的边, 则选择任意一个即可, 此时, 图存在多个最小生成树. 相关问题: 对于一个图, 求它总共有多少颗生成树 Vyssotsky’s Algorithm: 将边逐渐的添加到生成树中, 一旦形成环, 就删除环中权值最大的边.(目前该操作实现起来不是很快) 第九章 最短路径从一个节点到另外一个节点耗费最小的路径. 相关问题: 路径规划, 工作任务规划. BFS: 可以求得某一点到其他任意一点的最点路径, 由此可以构成一个 单源最短路径 单源最短路径算法Dijkstra(迪杰斯特拉): 前提, 图中不能有负权边, 复杂度 $O(ElogV)$, 先找到没有访问过的节点的路费最小的节点, 然后查看该节点的邻边, 并更新当前所有路径的最小段路径长度. Bellman-Ford:含有负权边的图, 拥有负权环的图, 没有最短路径, 因为每在环中转一次, 花费都会变小. 因此, 该单源最短路径算法的前提是图中可以有负权边不能有负权环. Bellman-Ford 自身就可以检查是否有负权环.复杂度 $O(EV)$.基本思想: 如果一个图中没有负权环, 从一点到另外一点的最短路径, 最多经过所有的 V 个定点, 有 V-1 条边, 若多于 V-1 条边, 存在某一定点经过了两次, 即存在负权环.对一个点的一次松弛操作, 就是找到经过这个点的另外一条路径, 该路径多一条边, 但是权值更小.因此需要对所有的点都进行 V-1 次松弛操作 更多和最短路径相关的问题单元最短路径算法: 正无穷表示未访问, 或者可以用空指针表示Bellman-Ford: 利用队列数据结构, queue-based bellman-ford 算法拓扑排序求单源最短路径: 提前图是 有向无环图(要求更严格), 复杂度 $O(V+E)$ 所有对最短路径算法: 可以得到任意两个点之间的单源最短路径Floyed 算法: 可以处理有负权但是无负权环的图, 复杂度 $O(V^3)$ 最长路径算法: 图中不能有正权环 无权图的最长路径问题是 指数级难度的 对于有权图, 不能使用 Dijkstra 求最长路径问题 可以使用 Bellman-Ford 算法.]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>视频教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-各个网络层的封装实现(layers)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-layers%2F</url>
    <content type="text"><![CDATA[batch_norm.py misc.py nms.py roi_align.py roi_pool.py smooth_l1_loss.py]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InceptionV4 and Inception-ResNet]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-InceptionV4-InceptionResNet%2F</url>
    <content type="text"><![CDATA[文章:Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning作者: Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi 简述 InceptionV4 做了哪些改进 InceptionV4 使用了更复杂的结构重新设计了 Inception 模型中的每一个模块. 包括 Stem 模块, 三种不同的 Inception 模块以及两种不同的 Reduction 模块. 每一个模块的具体参数设置均不太一样, 但是整体来说都遵循的卷积分解和空间聚合的思想. 简述 Inception-Resnet-v1 做了哪些改进Inception ResNet v1 网络主要被用来与 Inception v3 模型性能进行比较, 因此它所用的 Inception 子网络的计算相对常规模块有所减少, 这是为了保证使得它的整体计算和内存消耗与 Inception v3 近似, 如此才能保证公平性. 具体来说, Inception ResNet v1 网络主要讲 ResNet 中的残差思想用到了 Inception 模块当中, 对于每一种不太的 Inception 模块, 都添加了一个短接连接来发挥残差模型的优势. 简述 Inception-ResNet-v2 做了哪些改进Inception ResNet v2 主要被设计来探索残差模块用于 Inception 网络时所尽可能带来的性能提升. 因此它是论文给出的最终性能最高的网络设计方案, 它和 Inception ResNet v1 的不同主要有两点, 第一是使用了 InceptionV4 中的更复杂的 Stem 结构, 第二是对于每一个 Inception 模块, 其空间聚合的维度都有所提升. 其模型结构如下所示:]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inception V3]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-InceptionV3%2F</url>
    <content type="text"><![CDATA[文章: Rethinking the Inception Architecture for Computer Vision作者: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna备注: Google, Inception V3 核心摘要近年来, 越来越深的网络模型使得各个任务的 benchmark 都提升了不少, 但是, 在很多情况下, 我们还需要考虑模型计算效率和参数量. 本文我们将通过适当地使用 factorized convolutions(卷积分解) 和 aggressive regularization 来尽可能的是增加计算效率. 介绍AlexNet, VGGNet 虽然很成功, 但是他们的计算成本太大, 模型参数量较多, 与之相比, Inception 模型不仅参数量小, 特征提取能力也较强. 但是, Inception 模型较为复杂, 这使得我们很难对模型进行修改. 在本文中, 我们会先描述一个一般化的原则和优化想法, 使得可以高效的扩大卷积网络的大小. General Design Principles接下来我们会叙述几条基于大规模多结构的神经网络的设计原则 避免使用 representational bottlenecks, 尤其是在网络的较浅层. 前馈神经网络可以被表示成一个有向无环图, 这定义了一个非常明确的信息流. 对于任何输入, 都可以获得很大的信息. 因此, 我们应避免使用 bottlenecks 过度压缩信息. 在通常情况下, 特征的尺寸应该从输入到输出平缓降低. 理论上来说, 降维后的信息不能完全提供足够的信息内容给后续的结构, 而仅仅只是对主要信息的一种粗略的概括. 高维表示更容易在网络本地进行处理. 空间聚合可以在降低的维度 embedding 中完成, 而不需要太多或任何表征能力的损失. 比如, 在执行一个更大的卷积操作(如3×3)之前, 我们可以在 spatial aggregation 之间先降低维度, 而这不会带来严重的负面影响. 我们检测其原因是因为相邻单元之间的相关性很强, 所以导致在降维的时候损失较小. 降维有助于加速训练. 权衡网络模型深度的宽度. 提升模型的宽度和深度都可以提升模型的性能, 但是, 最好的方式是结合这两种方式, 以便使得模型的复杂度可以均衡的分布在网络的深度和宽度中. 上面的原则不建议直接使用, 更好的办法是在你不确定如何提升模型性能时进行权衡和尝试. Factorizing Convolutions with Large Filter.GooLeNet 的成功原因之一得益于广泛的使用降维. 这可以看做是 factorizing convolutions(对卷积进行因式分解) 的一种特殊情况. 在一个视觉网络中, 某点的输出与它相邻的其他点的响应之间有很高的相关性. 因此, 我们可以在聚合之前将这些响应进行降维, 在这理论上, 应该能够产生相同的局部特征表示. 由于 Inception 网络是全卷积的, 每一个权重都会与多处响应相关联, 计算成本的降低会带来参数量的降低. 这意味着 通过恰当的因式分解, 我们可以得到更多解耦的参数, 从而可以带来更快的训练速度. 分解成更小的卷积(Factorization into smaller convolutions)较大的卷积核尺寸(如5×5, 7×7)往往意味着很高的计算成本. 例如, 5×5 的计算成本为 3×3 卷积核的 25/9 = 2.78 倍. 但是, 如果直接替换为 3×3 的卷积核, 那么就会在特征表达能力上造成一些损失. 幸运的是, 我们可以通过多层小卷积核添加的方式来替换大卷积核, 如图1所示, 他们的感受野是相当的, 但是前者的参数只有后者的 $\frac{9+9}{25} = 28 %$. 图4, 图5展示了用两个3×3来替换 5×5 卷积核的示意图. 但是这种替换会引出两个问题, 其一为是否为造成特征表达能力的降低, 其二是如果我们的主要目标时分解计算的线性部分, 那么是否还应该在第一层保持线性激活? 即是否在第一层使用非线性激活函数? 对此, 通过实验证明, 使用线性激活比使用非线性激活的效果差一些, 如图2所示. 空间分解为不对称卷积(Spatial Factorization into Asymmetric Convolutions)上面的结果说明大于 3×3 的卷积核通常都可以分解为一系列 3×3 卷积核堆叠. 那么如果继续分解, 我们可以将 3×3 的卷积核分解为 3×1 的卷积核和 1×3 的卷积核, 这样一来, 参数量就变成了6, 降低了 33%, 如图3所示(将 3×3 分解成两个 2×2 的卷积核, 只能降低 11% 的参数量). 理论上, 我们可以将任何 $n\times n$ 的卷积核用一个 $n\times 1$ 和一个 $1\times n$ 的卷积核替代, 如图6所示. 在实际使用中, 我们发现这种分解方式在网络的浅层并不能很好的工作, 但是在网络的中层可以取得很好的效果(特征图谱大小在 12~20 之间的网络层). 辅助分类器的效用(Utility of Auxiliary Classifiers)Inception V1 首次引入辅助分类器来提升深度网络的收敛性, 其最初动机是为了可以及时利用那些浅层网络中有用的梯度来帮助模型快速收敛, 从而缓解深度神经网络中的梯度消失问题. 有趣的是, 我们发现这个辅助分类器并不会加快训练初期的收敛速度: 对于带有辅助分类器和不带辅助分类器的两个网络, 在模型达到较高精度以前, 他们的性能看起来是差不多的. 但是 当到了训练后期, 带有辅助分支的网络开始超越没有任何辅助分支的网络, 进而达到更高的精度.并且, 在 Inception V1 中使用了两个辅助分支, 我们发现, 将浅层的辅助分支去除并不会对最终的模型质量产生任何不利影响. 有效缩小网格尺寸(Efficient Grid Size Reduction)传统的卷积网络通过池化操作来降低特征图谱的网格尺寸, 但是为了避免降低特征表达能力, 对于一个 $d\times d\times k$ 的特征图谱, 我们通常会先利用一个卷积层使它的通道数增加到 $2k$, 然后再利用池化层来降低它的图谱尺寸到 $\frac{d}{2}$, 因此, 这一步需要的计算量为 $2d^2 k^2$. 我们可以将卷积层和池化层的位置互换, 这样一来, 计算量就会降为 $2(\frac{d}{2})^2 k^2$, 但是, 这样会导致网络的特征表达能力下降, 造成 representational bottlenecks, 如图9所示. 因此, 我们推荐另一种降低计算量的方式, 如图10所示, 我们可以利用两个并行的 block P 和 block C 来达到目的, 其中 P 代表池化, C 代表卷积. Inception-v2表1展示了本文网络的整体布局 注意到我们将原来的 7×7 卷积转换成了3个 3×3 卷积. 图8 Model Regularization via Label Smoothing表3 展示了 ILSVRC 2012 的测试结果 表4 Training MethodologyPerformance on Lower Resolution Input表2 Experimental Results and Comparisons表5 InceptionV2 相比于 GoogLeNet 有什么区别InceptionV2 改进的主要有两点. 一方面加入了 BN 层, 减少了 Internal Covariate Shift 问题(内部网络层的数据分布发生变化), 另一方面参考了 VGGNet 用两个 $3\times 3$ 的卷积核替代了原来 Inception 模块中的 $5\times 5$ 卷积核, 可以在降低参数量的同时加速计算. InceptionV3 相比于 GoogLeNet 有什么区别 InceptionV3 最重要的改进是分解(Factorization), 这样做的好处是既可以加速计算(多余的算力可以用来加深网络), 有可以将一个卷积层拆分成多个卷积层, 进一步加深网络深度, 增加神经网络的非线性拟合能力, 还有值得注意的地方是网络输入从 $224\times 224$ 变成了 $299\times 299$, 更加精细设计了 $35\times 35$, $17\times 17$, $8\times 8$ 特征图谱上的 Inception 模块.具体来说, 首先将第一个卷积段的 $7\times 7$ 大小的卷积核分解成了 3 个 $3\times 3$ 大小的卷积核. 在第二个卷积段也由 3 个 $3\times 3$ 大小的卷积核组成. 第三个卷积段使用了 3 个 Inception 模块, 同时将模块中的 $5\times 5$ 卷积分解成了两个 $3\times 3$ 大小的卷积. 在第四个卷积段中, 使用了 5 个分解程度更高的 Inception 模块, 具体来说, 是将 $n\times n$ 大小的卷积核分解成 $1\times n$ 和 $n\times 1$ 大小的卷积核, 在论文中, 对于 $17\times 17$ 大小的特征图谱, 使用了 $n = 7$ 的卷积分解形式. 在第五个卷积段中, 面对 $8\times 8$ 大小的特征图谱, 使用了两个设计更加精细的 Inception 模块. 它将 $3\times 3$ 大小的卷积层分解成 $1\times 3$ 和 $3\times 1$ 的卷积层, 这两个卷积层不是之前的串联关系, 而是并联关系. Inception 模块的设计和使用原则是什么 在网络的浅层要避免过度的压缩特征信息, 特征图谱的尺寸应该温和的降低; 高维的特征信息更适合在本地进行处理, 在网络中逐渐增加非线性激活层, 这样可以使得网络参数减少, 训练速度更快; 低维信息的空间聚合不会导致网络表达能力的降低, 因此, 当进行大尺寸的卷积之前, 可以先对输入进行进行降维处理, 然后再进行空间聚合操作; 网络的深度和宽度需要反复权衡, 通过平衡网络中每层滤波器的个数和网络的层数使用网络达到最大性能.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SENet]]></title>
    <url>%2Fz_post%2FSENet%2F</url>
    <content type="text"><![CDATA[文章:作者:备注:]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RFB Net (ECCV, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-RFBNet-ECCV2018%2F</url>
    <content type="text"><![CDATA[文章: Receptive Field Block Net for Accurate and Fast Object Detection作者: Songtao Liu, Di Huang, and Yunhong Wang备注: Beihang University 核心亮点本文从感受野大小的角度出发, 提出了 RFB 模块, 可以融合多个感受野特征, 进而提升轻量级网络(SSD)的特征表达能力相比于不断增加模型复杂度(深度,宽度)来增强特征的表达能力, 本文通过一种人工设计的机制来增强轻量级模型的特征表达能力, 以期获得一种既快又好的检测模型. 摘要目前精确度最高的目标检测模型往往面临着巨大的计算开销, 而轻量级的目标检测模型在精度上却不够高. 本文通过利用人工设计来增强轻量级模型的特征, 以期获得一个既快又好的检测模型. 受到人类视觉系统感受野的启发, 文本提出了一个感受野模块(RF Block module), 它将 RFs 的 size 和 eccentricity 之间的关系考虑在内, 来增强特征的分辨能力和鲁棒性. 之后, 我们将 RFB 集成到了 SSD 之中, 建立了一个 RFB Net 检测器. 实验结果显示, 本文的 RFB Net 可以达到目前最高的性能表现. 介绍通过讨论 two-stage 和 one-stage 模型各自的特点和优势, 本文发现, 相比于不断增加模型复杂度(深度,宽度)来增强特征的表达能力, 另一种可选的做法通过一种人工设计的机制来增强轻量级模型的特征表达能力, 以期获得一种既快又好的检测模型. 另一方面, 多项研究发现, 感受野的大小是视网膜图谱离心率的函数, 并且在不同的图谱上, 离心率会逐渐升高, 如图1所示. 目前的深度网络模型, 大多将不同层之间的感受野设置成相同大小, 这就有可能降低提取到的特征的表达能力. Inception 系列虽然融合了多个尺寸的感受野特征, 但是所有的卷积核仍然是在同一个中心进行采样的. Deformable CNN 尝试自适应的改变卷积核采样点, 尽管采样网格十分灵活, 但是依然没有考虑感受野的 eccentricity 属性, 这使得所有处于感受野当中的像素点都都输出响应具有同等的贡献度, 这会导致一些更重要的信息没有被突出出来.本文根据人类视觉感受野的机制, 提出了 Receptive Field Block(RFB), 来增强轻量级的特征学习能力, 使得他们可以组建出更快更好的检测模型. 具体来说, RFB 通过使用不同大小的卷积核来实现多分支的 pooling 操作, 应用空洞卷积(dilated convolution)来控制它们的离心率(eccentricities), 并且进行 reshape 之后生成最终的特征表示, 如图2所示. 之后, 我们会将该模块集成到 SSD 网络之中, 形成一个更快更好的 one-stage 目标检测模型, 称为 RFB Net. 本文的贡献主要有以下三点: 提出了 RFB 模块, 用于提升轻量级 CNN 网络的特征表达能力 提出了基于 RFB Net 的目标检测模型, 并且通过实验证明了该模型可以在维持 one-stage 模型(SSD)复杂度的条件下增强模型的精度. 实验表明本文的 RFB Net 可以在实时运行的速度下在 VOC 和 COCO 数据集上达到 SOTA 的性能, 并且证明了 RFB 模型具有很好的泛化性能(可以连接到 MobileNet 之上). 相关工作Two-stage detector: RCNN, Fast, Faster, R-FCN, FPN, Mask R-CNNOne-stage detector: YOLO, SSD, DSSD, RetinaNetReceptive filed: Inception(多个感受野尺寸共同作用), ASPP, Deformable CNN. 图3展示了这三种方式与本文的 RFB 的区别. Receptive Field Block本文提出的 RFB 是一个多分支的卷积块, 其内部结构主要包含两个部分: 具有不同卷积核大小的多分支的卷积层, 以及紧跟其后的空洞池化或空洞卷积层. 前一部分和 Inception 相同, 复杂模拟不同尺寸的感受野, 后一部分生成 pRFs(population Receptive Fields) 尺寸和人类视觉离心率之间的关系. Multi-branch convolution layer: 本文使用 Inception V4 和 Inception-ResNet V2 来构成多分支卷积层.Dilated pooling or convolution layer: 也称为 astrous convolution layer. 图4展示了本文的 RFB 模块示意图. RFB Net Detection Architecture本文的 RFB Net 是基于 SSD 和 RFB 模块进行构建的, 其中, RFB 模块会嵌入到 SSD 网络中, 主要的改动在于将 SSD 顶层(head/top)的卷积层替换为 RFB 模块, 如图5所示. Lightweight backbone: 保持 SSD 的选择, 使用 VGG16 作为 backbone. (即使还有其他的选择, 但是为了与 SSD 形成对比, 决定选择 VGG16). RFB on multi-scale feature maps: 在 SSD 中, 使用了多个不同大小的卷积特征图谱参与预测, 在本文的实现中, 会将较大的特征图谱后接的卷积层替换为 RFB 模块. 如图5所示. Training Settings framework: Pytorch strategies: follow SSD, 包括数据增广, 难负样例挖掘等等 new conv-layers: MSRA initialization 实验Pascal VOC 2007 消融实验(Ablation Study) COCO Other BackBone]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaskrcnnBenchmark 源码解析-数据(data)]]></title>
    <url>%2Fz_post%2FPyTorch-MaskrcnnBenchmark-data%2F</url>
    <content type="text"><![CDATA[datasets evaluationsamplerstransforms buildcollate_batch]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>PyTorch</tag>
        <tag>MaskrcnnBenchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IdentityMappings (ECCV, 2016)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-ResNetIdentityMappings-ECCV2016%2F</url>
    <content type="text"><![CDATA[文章: Identity Mappings in Deep Residual Networks作者: Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun备注: MSRA 核心亮点摘要Identity Mappings在第一篇ResNet论文中提到, 1202层的ResNet出现了性能退化的问题. 本文主要是对residual block的一个改进, 也就是将BN和ReLU放到计算权重之前进行, 称为”预激活” , 如下图所示: 关于Deep ResNet的分析https://blog.csdn.net/wspba/article/details/60750007 用简单缩放来代替恒等连接设计一个简单的缩放: $h(x_l) = \lambda_l x_l$ 来代替恒等连接: x_{l+1} = \lambda_l x_l + F(x_l, W_l)于是,继续通过递归我们可以得到: x_L =(\prod_{i=l}^{L-1}) x_l + \sum_{i=l}^{L-1}{\hat F(x_i, W_i)}对上面的式子求导, 可以得到: 可以看到, 在该式子中, 由于 $\lambda$ 连乘项的存在, 可能会使这个因子变的很大或者消失, 从而阻断从短接反向传来的信号, 进而对优化造成困难 关于Skip Connections的其他实验Constant scaling考虑对 $F$ 的缩放, 训练结果显式优化变的更加困难, 因此不建议缩放 因为 $F$ 对应的是连加项, 不会出现连乘项, 所以不能说因子很指数增长或消失 Exclusive gatingShortcut-only gating1×1 卷积shortcut在ResNet34的时候, 使用了1×1的卷积(即方案C), 并且取得了较好的结果, 表明1×1卷尺短接还是有效果的. 但是当残差单元变多时, 并不能起到很好的效果 值得注意的是1××\times1的卷积捷径连接引入了更多的参数，本应该比恒等捷径连接具有更加强大的表达能力。事实上，shortcut-only gating 和1××\times1的卷积涵盖了恒等捷径连接的解空间(即，他们能够以恒等捷径连接的形式进行优化)。然而，它们的训练误差比恒等捷径连接的训练误差要高得多，这表明了这些模型退化问题的原因是优化问题，而不是表达能力的问题 Dropout shortcut这个在统计学上相当于给短接强加了一个 $\lambda=0.5$ 的缩放, 这和constant scaling很类似, 同样阻碍了信号的传播 激活函数的使用通过重新安排激活函数(ReLU和/或BN)来使得 $f$ 成为一个恒等映射. 最原始的残差连接如下图a所示, b~e展示了其他形式. 图中所有单元的组成成分相同, 只是顺序不同, e形式取得了最后的结果, 也就是full pre-activation形式 对以上形式讨论如下: BN after addition: 图b, 此种做法正好反其道而行之, 此时 $f$ 不仅包含了 ReLU, 还包含了BN, 最终导致的结果就是阻碍了信息的传递, 是性能下降 ReLU before addition: 图c, 这是一种很直接的做法, 也很天真, 直接将ReLU移动到加法之前, 这导致了F的输出非负, 然我们我们希望残差函数的值是在政府无穷区间内的 Post-activation or Pre-activation: 如图c和d, 图d通过一种非对称的转换, 使得当前块的激活函数成为一个块的预激活项, 具体转换如下图所示: 对上图的解释就是, 在原始的设计中, 激活函数会对两条路径的下一个残差单元造成影响: y_{l+1} = f(y_l) + F(f(y_l), W_{l+1})而通过这种非对称的转换, 能够让激活函数 $\hat f$ 对于任意的 $l$ , 都只对$F$ 路径造成影响: y_{l+1} = y_l + F(\hat f(y_l), W_{l+1})于是, 新的激活函数就变成了一个恒等映射. 后激活与预激活的区别是有元素级加法的存在而造成的,一个含有N层的平铺网络，包含有N−1个激活层(BN/ReLU)，而我们如何考虑它们是否是后激活或者预激活都不要紧。但是对附加的分支层来说，激活函数的位置就变得很重要了。只使用ReLU预激活的结果与原始ResNet-110/164的已经很接近。 只是用ReLU的预激活vs完全预激活 从图d中, 我们可以看到, ReLU层不与BN层连接使用，因此无法共享BN所带来的好处, 因此, 很自然的,我们将BN层移到ReLU的前面, 最终, 性能获得了较大的提升, 超过了原始ResNet-110/164 分析文章发现预激活的影响具有两个方面: 由于$f$变成了恒等映射,优化变的更加简单 在预激活中使用BN能提高模型的正则化能力]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R2CNN++ (Arxiv, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-R2CNNPlus-Arxiv20170%2F</url>
    <content type="text"><![CDATA[文章: R2CNN++: Multi-Dimensional Attention Based Rotation Invariant Detector with Robust Anchor Strategy作者: Xue Yang, Kun Fu, Hao Sun, Jirui Yang, Zhi Guo, Menglong Yan, Tengfei Zhang, Sun Xian备注: Institute of Electronics, Chinese Academy of Sciences, Beijing (Suzhou), China 核心亮点自然场景下的物体检测相对来说已经取得了很多成果, 但是在面对高空场景下的物体检测时, 就会面临诸多难点, 比如尺寸不一, 方向不同, 物体密集等等. 这篇文章提出了一种新颖的多类别检测器, 可以有效的检测高空场景下的小物体, 任意方向物体, 以及密集物体. 具体来说, 模型采用了一种名为 inception fusion network 的特征融合策略, 可以综合考虑诸多因素的影响, 进而提升检测小物体和任意方向物体的能力, 同时, 使用 pixel attention network 和 channel attention network 来降低噪声特征, 增强物体特征. 另外, 本文还重定义了 rotating bounding box, 解决了物体方向的问题. 摘要]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ResNeXt (CVPR, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-ResNeXt-CVPR2017%2F</url>
    <content type="text"><![CDATA[文章: Aggregated Residual Transformations for Deep Neural Networks作者: Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, Kaiming He备注: UC San Diego, FAIR 核心亮点本文提出了一种新的网络模型架构 ResNeXt, 通过利用多路分支的特征提取方法, 提出了一种新的基于 ResNet 残差模块的网络组成模块, 并且引入了一个新的维度 cardinality. 该网络模型可以在于对应的 ResNet 相同的复杂度下, 提升模型的精度(相对于最新的 ResNet 和 Inception-ResNet).同时, 还通过实验证明, 可以在不增加复杂度的同时, 通过增加维度 cardinality 来提升模型精度, 比更深或者更宽的 ResNet 网络更加高效. 摘要本文提出了一个简单的, 高度模型化的针对图像分类问题的网络结构. 本文的网络是通过重复堆叠 building block 组成的, 这些 building block 整合了一系列具有相同拓扑结构的变体(transformations). 本文提出的简单的设计思路可以生成一种同质的, 多分支的结构. 这种方法产生了一个新的维度, 我们将其称为基(变体的数量, the size of the set of transformations). 在 ImageNet-1K 数据集上, 我们可以在保证模型复杂度的限制条件下, 通过提升基的大小来提高模型的准确率. 更重要的是, 相比于更深和更宽的网络, 提升基的大小更加有效. 我们将本文的模型命名为 ResNeXt, 本模型在 ILSVRC2016 上取得了第二名. 本文还在 ImageNet-5K 和 COCO 数据集上进行了实验, 结果均表明 ResNeXt 的性能比 ResNet 好. 介绍目前, 计算机视觉任务已经慢慢从特征工程转向了网络工程, 但是, 随着网络深度的增加, 设计良好的网络结构, 变的异常困难. VGG-nets 保留了简单同时有效的网络结构, 它通过将多个卷积层堆叠的方式来组成神经网络, 这种堆叠式结构在 ResNet 中也得到了保留, 并在这种结构的基础上, 开发出了性能强劲的网络模型.与 VGG-nets 不同的是, Inception 系列的模型通过精心的拓扑结构设计, 也取得了很好的模型准确度. Inception 模型的一个重要的属性就是 split-transform-merge strategy. 在 Inception 模块中, 输入数据会被划分成一些更低维度的 embeddings(通过1×1卷积), 然后通过一系列特定的卷积层(3×3, 5×5)进行转换, 最后通过 concatenation 融合起来. 这种方式所使用的空间复杂度是用单层卷积的空间复杂度的一个子集. 因此, Inception 模块可以利用更低的复杂度获取更高的特征表示能力. 尽管通过精心的布置和组合, Inception 模块组成的网络可以取得较好的性能表现, 但是, 当面对一个新的任务或数据集时, 往往无法很快的找到合适的模块组合和参数设置.本文提出了一种基于 VGG/ResNet 的 repeating layers 策略的模型, 同时还利用了 split-transform-merge 策略, 如图1所示(二者复杂度相同, 但是右边具有更高的精度). 本文的方法引入了一个新的维度 cardinality, 实验表明, 通过提升该维度, 可以更有效的提升模型的精度(相比于更深和更宽, ResNeXt 101 的精度高于 ResNet-200, 但是仅仅只有其一半的复杂度), 我们将模型命名为 ResNeXt (暗示 next dimension). 模板(Template)本文提出的模型设计思路遵循 VGG/ResNets 的 repeating layers 策略. 首先包含一组堆叠的残差模块, 这些残差模块具有相同的拓扑结构, 并且服从两条基本规则: (1), 如果处理的特征图谱具有相同的尺寸大小, 这些这些 block 的超参数设置相同(filters); (2), 每次当特征图谱的尺寸缩小两倍时, 卷积核的深度也会放大两倍. 第二条规则使得每一个 block 的复杂度(FLOPs, floating-point operations)是差不多相同的. 根据这两条规则, 我们只需要设计出一个模板(template), 进而模板中所有的模块都会相应的确定(相比于 Inception 设计更加简单), 如表1所示. 回顾简单神经元最简单的神经元是通过内积计算的, 而实际上, 内积也可以被看做是一个 aggregating tansformation: \sum_{i=1}^D w_i x_i \tag 1该公式的计算操作会通过一个神经元输出, 如图2所示. 上面的操作可以被重新定义成一组关于 splitting, transforming 以及 aggregating 的组合(conbination). Splitting: 向量 $\vec x$ 被划分成了低维度的 embedding, 每一个维度为 $x_i$ Transforming: 低维度的相同表示通过权重 $w_i$ 进行 transform. Aggregating: 通过求和公式 $\sum_{i=1}^D$ 将 transformations 连接起来. 聚合变换(Aggregated Transformations)根据上面的简单神经元的讨论, 下面我们考虑将 elementary trasformation($w_i x_i$) 用一个更加一般化的函数来替代, 这个函数本身也可以是一个神经网络, 如下所示: F(x) = \sum_{i=1}^C T_i (x) \tag 2上式中的 $T_i(x)$ 可以是任意形式的函数, 通常情况下, $T_i(x)$ 会将 $x$ 映射到一个更低的维度上去, 形成一个 embedding. $C$ 代表了 Transformations 的个数, 我们将其定义为 cardinality.在本文中, 我们使用了一种简单的方式来设计 transformation function: 所有的 $T_i$ 都具有相同的拓扑结构(图1右侧).我们将(2)式的 aggregated transformation 写成残差函数的形式: y = x + \sum_{i=1}^C T_i(x) \tag 3图3展示了本文模型与 Inception-ResNet 之间的关系, 图3(a)中的一些操作和图3(b)很相似, 而图3(b)看起来很像是包含 branching 和 concatenating 的 Inception-ResNet block. 但是与 Inception 和Inception=ResNet 模块不同的是, 本文的模型在不同的 paths 之间共享同样的拓扑结构, 因此, 我们的模型在设计方面需要的成本更小. 图3(c)和图4展示了 group convolutions(Alex Net). 模型容量(Model Capacity)实验表明, 本文的模型可以在维持模型复杂度和参数量的前提下提升模型的准确率. 当我们在维持复杂度的前提下调节 cardinalities C 的时候, 我们希望尽可能的不去改动其他的超参数. 我们选择去调节 bottleneck 的宽度(如图1右侧中的4-d), 因为这可以独立于 block 的 input 和 output.在图1左侧中, 原始的 ResNet bottleneck block 的参数量为 $256\cdot 64 + 3\cdot 3\cdot 64\cdot 64 + 64\cdot 256 \approx 70k$ 以及成比例的 FLOPs. 而我们的 template (图1右侧) 的参数量为: C\cdot ( 256\cdot d + 3\cdot 3\cdot d\cdot d + d\cdot 256) \tag 4当 $C=32, d=4$ 是, 上式约为 $70k$. 表2展示了 cardinality $C$ 和 bottleneck width $d$ 之间的关系. 实现细节(Implementation details) input image: 224×224 randomly cropped from resized image resized image: scale and aspect ratio augmentation shortcuts: option B in ResNet 在conv3,4,5中的 downsampling 操作通过 stride 为2的 3×3 卷积完成 SGD mini-batch size: 256 on 8 GPUs (32 per GPU) weight decay: 0.0001 momentum: 0.9 learning rate: 0.1, 会降低3次, 每次降低10倍(每次更新学习率都会使得错误率出现断崖式下跌) 权重初始化: Xavier module: 图3(c) BN: 在图3(c)中的卷积层之后 ReLU: 在 block 的输出中, ReLU 在 shortcut 之后使用, 其情况下, 均在 BN 之后使用. 图3中的三种形式通过合理安排 BN 和 ReLU 的位置可以互相等价. 我们选择图3(c)是因为它更加简洁, 速度更快. 实验(Experiments)Experiments on ImageNet-1KCardinality vs. Width: Increasing Cardinality vs. Deeper/Wider表4显示出提升 Cardinality 可以降低错误率, 但是加深或者加宽(channel 维度升高) ResNet 提升的精度幅度较小. 下标展示了残差结构的 shortcut 分别在 ResNet 和 ResNeXt 中的影响: Performance: ResNeXt: 0.95s per mini-batchResNet-101: 0.70s per mini-batch Comparisons with SOTA results: Experiments on ImageNet-5K Experiments on CIFAR Experiments on COCO object detection ResNeXt 在 ResNet 上做了哪些改进ResNeXt 实际上是将 ResNet Block 当中的输入数据的通道划分到了不同的组, 每个组的计算过程相对独立, 最终将所有组的计算结果进行空间聚合, 作为最终的输出. ResNeXt 可以在不增加参数量的情况下进一步提高 ResNet 的特征提出能力, 从而表现出更好的网络性能. ResNeXt 的卷积方式实际上可以看做是通道分组卷积.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R2CNN (Arxiv, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-R2CNN-Arxiv2017%2F</url>
    <content type="text"><![CDATA[文章: R2CNN: Rotational Region CNN for Orientation Robust Scene Text Detection.作者: Yingying Jiang, Xiangyu Zhu, Xiaobing Wang, Shuli Yang, Wei Li, Hua Wang, Pei Fu and Zhenbo Luo备注: Samsung R&amp;D Institute China - Beijing 论文地址: 核心亮点摘要物体检测在自然场景和空间场景里都起了重要作用.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-roidb数据结构]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron1-roidb%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[roidb数据结构roidb的类型是list, 其中的每个元素的数据类型都是dict, roidb列表的长度为数据集的数量(即图片的数量), roidb中每个元素的详细情况如下表所示: for entry in roidb 数据类型 详细说明 entry[&#39;id&#39;] int 代表了当前image的img_id entry[&#39;file_name&#39;] string 表示当前图片的文件名(带有.jpg后缀) entry[&#39;dataset&#39;] string 指明所属的数据集? entry[&#39;image&#39;] string 当前image的文件路径 entry[&#39;flipped&#39;] bool 当前图片是否进行翻转 entry[&#39;height&#39;] int 当前图片的高度 entry[&#39;width&#39;] int 当前图片的宽度 entry[&#39;has_visible_keypoints&#39;] bool 是否含有关键点 entry[&#39;boxes&#39;] float32, numpy数组(num_objs, 4) num_objs为当前图片中的目标物体个数, 4代表bbox的坐标 entry[&#39;segms&#39;] 二维列表[[],[],…] 列表中每个元素都还是一个列表, 其中存储着每个物体的ploygon实例标签 entry[&#39;gt_classes&#39;] int32, numpy数组(num_objs) 指明当前图片中每一个obj的真实类别 entry[&#39;seg_areas&#39;] float32, numpy数组(num_objs) 代表当前图片中每一个obj的掩膜面积 entry[&#39;gt_overlaps&#39;] float32, scipy.sparse.csr_matrix数据(num_objs, 81) 代表每一个obj与81个不同类别的overlap entry[&#39;is_crowd&#39;] bool, numpy数组(num_objs) 代表当前掩膜是否为群落 entry[‘box_to_gt_ind_map’] int32, numpy数组(num_objs) 该列表存储着box的顺序下标值, 同样是一维数组, 直接拼接,将每一个roi映射到一个index上, index是在entry[‘gt_classes’]&gt;0的rois列表的下标 combined_roidb_for_training() 方法在目标检测类任务中, 有一个很重要的数据结构roidb, 它将作为基本的数据结构在数据队列中存在, Detectron 的数据载入类 RoIDdataLoader 也是将该数据结构作为成员变量使用的, 因此, 有必要对这个数据结构展开分析. 首先, 在运行训练脚本时, 就会调用到 detectron/utils/train.py 中的 train()函数, 而train()函数内部又会调用当前文件的add_model_training_inputs() 函数, 在这个函数内部, 就会调用到 detectron/datasets/roidb 文件中的 combined_roidb_for_training() 函数, 该函数的返回值正是roidb, 这是贯穿整个训练过程的训练数据, 故我们对此函数进行分析. 该函数代码解析如下: 12345678910111213141516171819202122232425# detectron/datasets/roidb.py# 加载并连接一个或多个数据集的roidbs, along with optional object proposals# 每个roidb entry都带有特定的元数据类型, 对其进行准备工作后进行训练def combined_roidb_for_training(dataset_names, proposal_files): def get_roidb(dataset_name, proposal_file): # 注意 dataset_name 没有 's' # from detectron.datasets.json_dataset import JsonDataset # 可以看到, roidb 是利用JsonDataset类对象的get_roidb()方法获取的 # 因此, 我们先在下面看一下这个类的实现细节 ds = JsonDataset(dataset_name) roidb = ds.get_roidb( gt=True, proposal_file=proposal_file, crowd_filter_thresh=cfg.TRAIN.CROWD_FILTER_THRESH ) if cfg.TRAIN.USE_FLIPPED: logger.info("Appending horizontally-flipped training examples...") extend_with_flipped_entries(roidb, ds) logger.info("Loaded dataset: &#123;:s&#125;".format(ds.name)) return roidb if isinstance(dataset_names, basestring): #... #... get_roidb() 方法在上面的函数中我们可以发现, combined_roidb_for_training函数内部又定义了另一个函数get_roidb(), 而该函数主要是基于detectron/datasets/json_dataset.py中的JsonDataset类及该类的成员方法get_roidb实现的, 因此, 我们先跳到json_dataset.py文件中去看看这个类的内部实现是怎样的: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# detectron/datasets/json_dataset.pyclass JsonDataset(object): # 这个类的设计主要是基于COCO的json格式数据集 # 当我们需要训练自己的数据集时, 最好的方式就是将自己的数据集的格式改为 # COCO数据集的json格式, 这样一来, 我们就无需重写数据载入代码了. def __init__(self, name): assert dataset_catalog.contains(name), \ "Unknown dataset name: &#123;&#125;".format(name) assert... #... # 准备数据集的类别信息 category_ids = self.COCO.getCatIds() # 1~80, 对应80个类 # coco的loadCats函数, 必须指定需要加载的cat的id, 否则返回空列表 # 若指定后, 则返回id对应的类别信息, 每个类别信息是一个字典, 包括'name','id','supercategory'三个字段 # 获取每个类的名字, person, bicycle,bus等等, 返回的名字在列表中的位置与id在cat_ids列表中的位置一致 categories = [c['name'] for c in sefl.COCO.loadCats(category_ids)] # 建立类别的name 与 id之间的对应关系, 其中cat_name为key,cat_id为值 self.category_to_id_map = dict(zip(categories, category_ids)) # 注意, 没有'__background__' self.classes = ['__background__'] + categories # 将'__background__'添加到categories类别名字列表中 self.num_classes = len(self.classes) # coco下标最大值为90,但实际上只有80个类, 有的地方跳过了, 因此id不是连续的, self.json_category_id_to_contiguous_id = &#123; v: i + 1 # key为coco的非连续id, value为1~80的连续id, 均为整数 for i, v in enumerate(self.COCO.getCatIds()) &#125; self.contiguous_category_id_to_json_id = &#123; v: k # key为1~80的连续id, value为coco的非连续id, 均为整数 for k, v in self.json_category_id_to_contiguous_id.items() &#125; self._init_keypoints() # 调用类内的keypoints初始化方法. def get_roidb( self, gt=False, proposal_file=None, min_proposal_size=2, proposal_limit=-1, crowd_filter_thresh=0 ): """ 返回json dataset对应的roidb数据, 提供以下四种选项: - 在roidb中包含gt boxes - 添加位于proposal file里面的特定proposals - 基于最短边长的proposals过滤器 - 基于群落区域交集的proposals过滤器 """ assert gt is True or crowd_filter_thresh == 0, \ "Crowd filter threshold must be 0 if gt " \ "annotations are not included." # 这里调用了COCO的官方API, 关于COCO数据集的结构和标注格式解析, 可以查看我的另一篇文章 # 没有指定筛选条件, 获取数据集标签中所有的图片id image_ids = self.COCO.getImgIds() image_ids.sort() # 将id按照从小到大的顺序排列 # roidb为列表结构, 列表中的每一项是一个字典, 代表着对应imageid的标签内容. # 键值包括:coco_url, license, width, filename, height, flickr_url, id, date_captured roidb = copy.deepcopy(self.COCO.loadImgs(image_ids)) for entry in roidb: # 调用了本类的私有函数 _prep_roidb_entry(), entry为字典. # 主要是为entry赋初值, 占位符等等, 包含box, segms,等各种字段, 详细信息可以看下面的函数解析 # 注意, 这里的字段值都是预测值相关的值, 因此也会局域gt_overlap等字段 self._prep_roidb_entry(entry) if gt: # 如果参数声明是gt信息, 则会调用_add_gt_annotations # 访问标注文件, 以便添加相关字段信息, 具体看下面的相关函数解析 self.debug_timer.tic() for entry in roidb: # 注意, 是单独对每个entry调用该函数, 因此每次会载入指定imgid的相关标签 # 关于_add_gt_annotations函数具体解析可以看后面的部分 self._add_gt_annotations(entry) logger.debug( '_add_gt_annotations took &#123;:.3f&#125;s'. format(self.debug_timer.toc(average=False)) ) if proposal_file is not None: self.debug_timer.tic() # 加载proposals文件到roidb中, 关于此函数的详细解析可以看后文 self._add_proposals_from_file( roidb, proposal_file, min_proposal_size, proposal_limit, crowd_filter_thresh ) logger.debug( '_add_proposals_from_file took &#123;:.3f&#125;s'. format(self.debug_timer.toc(average=False)) ) # 类外部的函数, 用于计算与每个roidb相关的box的类别 _add_class_assignments(roidb) return roidb _prep_roidb_entry() 方法数据准备函数 _prep_roidb_entry() 的实现解析123456789101112131415161718192021222324252627282930313233343536373839404142434445# detectron/datasets/json_dataset.pyclass JsonDataset(object): def __init__(...): #... def get_roidb(...): #... # 该函数主要将空的元数据添加到roidb entry中 def _prep_roidb_entry(self, entry): # entry的'dataset'关键字, 值为self. entry['dataset'] = self im_path = os.path.join(self.image_directory, self.image_prefix+entry['file_name']) assert os.path.exists(im_path), "Image \"&#123;&#125; \" not found".format(im_path) # entry的'image'关键字, 值为当前imageid对应的image路径 entry['image'] = im_path entry['flipped'] = False # 禁止反转 entry['has_visible_keypoints'] = False # 下面entry键的对应值均为空, 暂为占位键 # entry的'boxes'关键字,值为n×4的numpy数组, n代表box的数量,这里暂时为0 entry['boxes'] = np.empty((0,4), dtype=np.float32) entry['segms'] = [] # entry的'segms'关键字, 值为一个列表,暂时为空 # entry的'gt_classes'关键字, 是个一维数组, 维度与box的数量n对应,暂时为0 entry['gt_classes'] = np.empty((0), dtype=np.int32) # 代表掩膜的面积, 供n项, 与boxes数目相对 entry['seg_areas'] = np.empty((0), dtype=np.float32) # TODO, 这里是一个矩阵压缩, 矩阵大小为n×c, c为类别数量, 没太搞懂要压缩成什么? entry['gt_overlaps'] = scipy.sparse.csr_matrix( np.empty((0, self.num_classes), dtype=np.float32) ) # 同样是n行1列, n与boxes数目对应, 表示是否为`一群物体` entry['is_crowd'] = np.empty((0), dtype=np.bool) # shape大小与roi相关, 将每一个roi映射到一个index上 # index是在entry['gt_classes']&gt;0的rois列表的下标 TODO还是不太清楚映射关系 entry['box_to_gt_ind_map'] = np.empty((0), dtype=np.int32) # 关键点信息, 默认情况下不设置 if self.keypoints is not None: entry['gt_keypoints'] = np.empty( (0, 3, self.num_keypoints), dtype=np.int32 ) # 删除那些从json file中获取到的不需要的字段 for k in ['date_captured', 'url', 'license', 'file_name']: if k in entry: del entry[k] _add_gt_annotations() 方法加载标注文件的函数 _add_gt_annotations()的实现解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# detectron/datasets/json_dataset.pyclass JsonDataset(object): def __init__(...): #... def get_roidb(...): #... def _prep_roidb_entry(self, entry): #... # 该函数将标注文件的元数据添加到roidb entry中 def _add_gt_annotations(self, entry): # 获取指定imgid的annid列表 (对应多个box) ann_ids = self.COCO.getAnnIds(imgIds=entry['id'], iscrowd=None) # 根据annids的id列表, 获取这些id对应的标注信息, objs是一个列表 # 列表中的每一个元素都是一个字典,字典的内容是标注文件中的内容,包含bbox,segmentation等字段 objs = self.COCO.loadAnns(ann_ids) # 下面的代码会对bboxes进行清洗, 因为有些是无效的数据 valid_objs=[] # 存储有效的objs valid_segms=[] # 存储有效的segms width = entry['width'] # 获取entry中的width字段, 代表图片的宽度 height = entry['height'] # 获取entry中的height字段, 代表图片的高度 for obj in objs: # crowd区域采用RLE编码 # import detectron.utils.segms as segm_utils # 用于判断当前的segmentation是polygon编码还是rle编码, 前者是列表类型, 后者是字典类型 # 返回True为polygon编码, 返回Fasle为rle编码 if segm_utils.is_poly(obj['segmentation']): # poly编码必须含有&gt;=3个点才能组成一个多边形, 因此需要&gt;=6个坐标点 # 类似于这样的检查操作只在PLOYGON中存在, 在面对RLE时无需检查, 可以直接接受后面的检查 obj['segmentation'] = [ p for p in obj['segmentation'] if len(p) &gt;=6 ] if obj['area'] &lt; cfg.TRAIN.GT_MIN_AREA: continue # 如果面积不达标, 则认为该标注无效, 不将其加入valid列表 if 'ignore' in obj and obj['ignore'] == 1: continue # import detectron.utils.boxes as box_utils # 将[x1,y1,w,h]的边框格式转换成[x1,y1,x2,y2]的格式 x1, y1, x2, y2 = box_utils.xywh_to_xyxy(obj['bbox']) # 将[x1,y1,x2,y2]的边框坐标限制在图片的[width,height]范围内, 防止越界 x1, y1, x2, y2 = box_utils.clip_xyxy_to_image( x1, y1, x2, y2, height, width ) if obj['area'] &gt; 0 and x2 &gt; x1 and y2 &gt; y1: # 若数据有效, 则加入到列表当中 obj['clean_bbox'] = [x1, y1, x2, y2] valid_objs.append(obj) valid_segms.append(obj['segmentation']) # 将数据的segms存在列表中(RLE/PLOYGON) num_valid_objs = len(valid_objs) # num_valid_objs持有objs的有效个数 # 注意, 下面的数据内容都被初始化为0 # boxes为 有效objs数×4 的numpy数组, 用来表示每个objs的边框坐标 boxes = np.zeros((num_valid_objs,4), dtype=entry['seg_areas'].dtype) # 每个objs的真实类别 gt_classes = np.zeros((num_valid_objs), dtype=entry['gt_classes'].dtype) gt_overlaps = np.zeros( # 形状为 有效objs数×num_class数 的numpy数组, 表示与每个类的IoU大小 (num_valid_objs, self.num_classes), dtype=entry['gt_overlaps'].dtype ) # 掩膜面积 seg_areas = np.zeros((num_valid_objs), dtype=entry['seg_areas'].dtype) # 是否crowd is_crowd = np.zeros((num_valid_objs), dtype=entry['is_crowd'].dtype) # 这个是??? box_to_gt_ind_map = np.zeros( (num_valid_objs), dtype=entry['box_to_gt_ind_map'].dtype ) if self.keypoints is not None: gt_keypoints = np.zeros( (num_valid_objs, 3, self.num_keypoints), dtype=entry['gt_keypoints'].dtype ) # 图片是否有可视的关键点? im_has_visible_keypoints = False for ix, obj in enumerate(valid_objs):# ix为下标, obj为下标对应元素 # category_id为coco类别id,json_category_id_to_contiguous_id 为字典类型 # 其中, key为coco的非连续id, value为1~80的连续id, 均为整数, 所以这里是将coco的非连续id转换成对应的连续id cls = self.json_category_id_to_contiguous_id[obj['category_id']] boxes[ix, :] = obj['clean_box'] # 将当前obj的box填入boxes列表 gt_classes[ix] = cls # 将连续id填入gt_classes列表 seg_areas[ix] = obj['area'] # 将area填入seg_areas列表 is_crowd[ix] = obj['iscrowd'] box_to_gt_ind_map[ix] = ix # 该列表存储着box的顺序下标值 if self.keypoints is not None: # ... if obj['iscrowd']: # 如果当前物体是crowd的话, 则将所有类别的overlap都设置为-1, # 这样一来在训练的时候, 这些物体都会被排除在外!! gt_overlaps[ix, :] = -1.0 else: gt_overlaps[ix, cls] = 1.0 # 仅仅将对应类的overlap设置为1, 其他为0 # 将gt的boxes添加到entry中, 注意axis为0, 则会按照第0维拼接, 即最后是一个n×4的数组 # 注意, entry['boxes']初始时候是空的, 因此这就相当于是只添加了真实的框 entry['boxes'] = np.append(entry['boxes'], boxes, axis=0) # 由于segms是以列表形式存储, 所以利用列表的extend方法来将valid_segms添加到其中 entry['segms'].extend(valid_segms) # gt_classes的类型内一维numpy数组(维度为有效obj的数量), 因此这里不用指定axis的值, 直接按照一维数组拼接即可 entry['gt_classes'] = np.append(entry['gt_classes'], gt_classes) # 同理, 一维numpy数组(维度为有效obj的数量), 无须指定axis的值 entry['seg_areas'] = np.append(entry['seg_areas'], seg_areas) # gt_overlaps为 num_objs × num_classes的numpy数组, 表示每个obj与任意一个类的重叠度 # 因为entry['gt_overlaps']的类型为scipy.sparse.csr.csr_matrix, 因此这里需要调用toarray方法将其转换成numpy数组, 然后再与gt_overlaps拼接, #由于entry['gt_overlaps']的维度为 0 × 81 , 因此拼接后的维度为num_objs × num_classes的numpy数组 entry['gt_overlaps'] = np.append( entry['gt_overlaps'].toarray(), gt_overlaps, axis=0 ) # 再将其包装成scipy.sparse.csr.csr_matrix类型 entry['gt_overlaps'] = scipy.sparse.csr_matrix(entry['gt_overlaps']) # 一维numpy数组, 可直接拼接 entry['is_crowd'] = np.append(entry['is_crowd'], is_crowd) # 该列表存储着box的顺序下标值, 同样是一维数组, 直接拼接 entry['box_to_gt_ind_map'] = np.append( entry['box_to_gt_ind_map'], box_to_gt_ind_map ) if self.keypoints is not None: entry['gt_keypoints'] = np.append( entry['gt_keypoints'], gt_keypoints, axis=0 ) entry['has_visible_keypoints'] = im_has_visible_keypoints _add_proposals_from_file()123456789101112131415# detectron/datasets/json_dataset.pyclass JsonDataset(object): def __init__(...): #... def get_roidb(...): #... def _prep_roidb_entry(self, entry): #... def _add_gt_annotations(self, entry): #... # def _add_proposals_from_file( self, roidb, proposal_file, min_proposal_size, top_k, crowd_thresh ): 续解combined_roidb_for_training() 方法接下来, 重新回到刚才detectron/datasets/roidb.py 文件 的 combined_roidb_for_training 函数中, 继续往下看:123456789101112131415161718192021222324252627282930313233343536373839404142# detectron/datasets/roidb.py# 加载并连接一个或多个数据集的roidbs, along with optional object proposals# 每个roidb entry都带有特定的元数据类型, 对其进行准备工作后进行训练def combined_roidb_for_training(dataset_names, proposal_files): def get_roidb(dataset_name, proposal_file): # 注意没有 's' # from detectron.datasets.json_dataset import JsonDataset # 可以看到, roidb 是利用JsonDataset类对象的get_roidb()方法获取的 # 注意gt参数是True, 所以表明加载的是训练集的真实数据及其标签 ds = JsonDataset(dataset_name) roidb = ds.get_roidb( gt=True, proposal_file=proposal_file, crowd_filter_thresh=cfg.TRAIN.CROWD_FILTER_THRESH ) # 如果图片翻转属性为真, 则对加载好以后的数据集进行翻转操作 if cfg.TRAIN.USE_FLIPPED: logger.info("Appending horizontally-flipped training examples...") extend_with_flipped_entries(roidb, ds) logger.info("Loaded dataset: &#123;:s&#125;".format(ds.name)) # 以上, 数据集加载操作完成, 将roidb数据结构返回 return roidb if isinstance(dataset_names, basestring): dataset_names=(dataset_names, ) if isinstance(proposal_files, basestring): proposal_files = (proposal_files, ) if len(proposal_files) == 0: proposal_files = (None, ) * len(dataset_names) assert len(dataset_names) == len(proposal_files) roidbs = [get_roidb(*args) for args in zip(dataset_names, proposal_files)] roidb = roidbs[0] for r in roidbs[1:]: roidb.extend(r) roidb = filter_for_training(roidb) logger.info("Computing bounding-box regression targets...") # 为训练bounding-box 回归其添加必要的information add_bbox_regression_targets(roidb) logger.info("done") _compute_and_log_stats(roidb) return roidb]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-数据加载]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[Coordinator 类由于 RoIDataLoader 类将 Coordinator 类对象作为成员变量, 因此我们先看一下这个类的作用和底层实现, 该类位于detectron/utils/coordinator.py文件中, 定义如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344#detectron/utils/coordinator.py# 从名字可以看出, 该类的作用主要是协调各个数据载入管道之间的信息同步# 实现上, 该类主要封装了threading多线程模块的一些功能class Coordinator(object): def __init__(self): # import threading self._event = threading.Event() def request_stop(self): log.debug("Coordinator stopping") self._event.set() def should_stop(self): # 当Event()对象使用set()方法后, is_set()方法返回镇 return self._event.is_set() #... @contextlib.contextmanager 上下文环境管理器 def stop_on_exception(self): try: yield except Exception: if not self.should_stop(): traceback.print_exc() self.request_stop()def coordinated_get(coordinator, queue): while not coordinator.should_stop(): try: # 从队列中获取数据 return queue.get(block=True, timeout=1.0) except Queue.Empty: continue raise Exception("Coordinator stopped during get()")def coordinated_put(coordinator, queue, element): while not coordinator.shuold_stop(): try: queue.put(element, block=True, timeout=1.0) return except Queue.Full: continue raise Exception("Coordinator stopped during put()") RoIDataLoader 类在之前分析的tools/train_net.py 文件中, 关于数据载入的部分被封装在了detectron/roi_data/loader.py文件中的RoIDataLoader类中, 而数据载入对于任何模型和工程来说, 都是非常重要的一步, 下面, 我们就具体看看这个类的底层实现是怎么样的. 文件开头, 有一段非常详细的注释: 1234567891011121314151617181920212223# detectron/roi_data/loader.py"""Detectron data loader. The design is generic and abstracted away from anydetails of the minibatch. A minibatch is a dictionary of blob name keys andtheir associated numpy (float32 or int32) ndarray values.Outline of the data loader design:loader thread\loader thread \ / GPU 1 enqueue thread -&gt; feed -&gt; EnqueueOp... -&gt; minibatch queue -&gt; ...loader thread / \ GPU N enqueue thread -&gt; feed -&gt; EnqueueOploader thread/&lt;---------------------------- CPU -----------------------------|---- GPU ----&gt;A pool of loader threads construct minibatches that are put onto the sharedminibatch queue. Each GPU has an enqueue thread that pulls a minibatch off theminibatch queue, feeds the minibatch blobs into the workspace, and then runsan EnqueueBlobsOp to place the minibatch blobs into the GPU's blobs queue.During each fprop the first thing the network does is run a DequeueBlobsOpin order to populate the workspace with the blobs from a queued minibatch.""" 从上面的注释我们可以看出, 这个文件定义了Detectron的数据载入器data loader, 这个类的设计是一种抽象的一般化的设计, 并且会与所有minibatch的细节隔离开来. 在这个类中, minibatch被记录为一个字典结构, 它的key值为blob name, 其value值为对应的numpy ndarray. 每一个GPU都具有一个enqueue线程, 可以从minibatch queue中获取数据, 然后会将minibatch blobs喂到workspace中去, 之后运行 EnqueueBlobsOp 来将minibatch blobs 放置到 GPU的blob queue中. 在每一次前向传播过程中, 模型最先做的事情就是运行 DequeueBlobsOp 来构建工作空间. 下面, 看一下RoIDataLoader类的具体实现:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# detectron/roi_data/loader.pyclass RoIDataLoader(object): def __init__( self, roidb, num_loaders = 4, minibatch_queue_size=64, blobs_queue_capacity=8 ): self._roidb = roidb self._lock = threading.Lock() self._perm = deque(range(len(self._roidb))) self._cur = 0 # _perm cursor # minibatch队列会在CPU内存当中持有准备好的训练数据 # 当训练N&gt;1个GPUs时, 在minibatch队列中的每一个元素 # 实际上是只是一部分minibatch, 对整个minibatch贡献了 # 1/N的样例 # from six.moves import queue as Queue self._minibatch_queue = Queue.Queue(maxsize=minibatch_queue_size) # TODO, 其他参数的初始化 # from detectron.utils.coordinator import Coordinator self.coordinator = Coordinator() # 加载mini-batches, 并且将它们放进mini-batch 队列中. def minibatch_loader_thread(slef): # coordinator的上下文管理器, 当有异常出现时会调用coordinator.request_stop()方法 with self.coordinator.stop_on_exception(): while not self.coordinator.should_stop(): # RoIDataLoader的成员函数, 返回用于下一个minibatch的blobs, # 函数内部调用了另一个成员函数_get_next_minibatch_inds() # 该函数返回下一个minibatch的roidb的下标 # 还调用了detectron/roi_data/minibatch.py文件中的get_minibatch方法 # 该方法会在给定roidb的情况下, 从中构造一个minibatch blobs = self.get_next_minibatch() # from collections import OrderedDict # Blobs必须根据self.get_output_names()在队列中进行排序 ordered_blobs = OrderedDict() for key in self.get_output_names(): assert blobs[key].dtype in (np.int32, np.float32), \ "Blob &#123;&#125; of dtype &#123;&#125; must have dtype of" \ "np.int32 or np.float32".format(key, blobs[key].dtype) ordered_blobs[key] = blobs[key] # from detectron.utils.coordinator import coordianted_put # 此处是将minibatch中数据blobs放入队列的关键代码 coordinated_put(self.coordinator, self._minibatch_queue, ordered_blobs) logger.info("Stopping mini-batch loading thread") # 将mini-batches从mini-batch队列中转移到BlobsQueue中. def enqueue_blobs_thread(self, gpu_id, blob_names): with self.coordinator.stop_on_exception(): while not self.coordinator.should_stop(): if self._minibatch_queue.qsize == 0: logger.warning("Mini-batch queue is empty") blobs = coordinated_get(self.coordinate, self._minibatch_queue)]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cascade R-CNN (CVPR, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-CascadeR-CNN-CVPR2018%2F</url>
    <content type="text"><![CDATA[文章: Cascade R-CNN: Delving into High Quality Object Detection作者: Zhaowei Cai, Nuno Vasconcelos机构: UC San Diego 核心亮点本文针对检测问题中区分正负样本的 IoU 阈值选择问题提出了一种新的目标检测框架, Cascade R-CNN周所周知, 在 two-stage 的目标检测模型当中, 需要设置 IoU 阈值来区分正样本和负样本, 通常, 阈值选的越高, 正样本的框就与真实框越接近, 但是这样就会使得正样本的数量大大降低, 训练时容易产生过拟合问题, 而如果阈值选的较低, 就会产生大量的假正例样本. 根据经验和实验证明可知, 当输入的 proposals 和真实框的 IoU 的值, 与训练器训练时采用的 IoU 的阈值比较接近的时候, 训练器的性能会比较好, 为此, 作者提出了一种级联式的阈值训练方法, 先在较低的阈值上训练检测器, 得到具有更高 IoU 的候选框输出, 然后在此基础上进行训练, 不断提升 IoU 的阈值, 这样一来, 最终生成的候选框质量会变得更高 (与真实框的 IoU 更大). 作者提出这种框架的启发来自于图1(c), 整体来说, 输入的 proposals 的 IoU 在经过检测器边框回归以后, 其输出的边框与真实框会有更大的 IoU, 因此可以将这个具有更大 IoU 的框作为下一个检测器的输入, 同时调高训练时的 IoU, 进而得到质量更高的框 摘要在目标检测任务中, 交并比 (IoU, Intersection over Union) 常常被用来区分正样本和负样本. 如果一个检测器在训练时, IoU 阈值设置的比较低时(如0.5), 通常会导致产生更多的噪声检测. 但是, 如果一味的提高 IoU 阈值, 检测器的性能也会有所下降. 产生这一现象的因素主要有两点: 1), 由于阈值升高后, 大量样本都会无法被当做正样本训练, 使得正样本的数量大大降低, 从而容易在训练时产生过拟合; 2, 在 inference 阶段,检测器优化的(人为设定的) IoU 阈值和假设的(真实的) IoU 阈值之间的不匹配. 为了解决上述问题, 本文提出了一个 multi-stage 的目标检测模型架构, 称为 Cascade R-CNN. 它由一系列经过训练的检测器组成, 这些检测器的 IoU 阈值不断增加, 从而对假阳性样本更加具有选择性. 这些检测器会被阶段性 (stage by stage) 的训练, 而如果当前检测器的输出是一个好的分布, 就会用于训练下一个阶段的检测器, 从而得到更好的检测器. 对逐渐改进的假设进行重采样, 保证所有的检测器都具有一组同等大小的正样本集合, 从而缓解了过拟合问题. 相同的 cascade 流程会继续应用在 inference 阶段, 确保可以令每一个 stage 的检测器质量与假设之间更加匹配. Cascade R-CNN 的一个简单实现在 COCO 数据集上胜过了其他所有的单模型检测器. 并且, 实验表明, Cascade R-CNN 可以应用在多种模型架构之中, 并且无论 baseline detector 的性能是强还是弱, Cascade R-CNN 总是能够进一步提升模型的性能 (consistent gains). 介绍目标检测任务需要同时解决分类和定位两个问题, 这两个问题都不太好解决, 因为往往检测器会面对许多 close false positives, 简单来说就是指许多密集重复的无用框 (很接近正样本的假正例). 检测器必须要找到真正的正样本, 同时还要抑制这些假正例. 在 two-stage 检测模型中, 我们将分类和候选框生成任务分为两个阶段执行, 此时需要设置一个 IoU 阈值来标记候选框的正负, 通常情况下, 我们设置一个固定的 IoU 阈值 ($\mu$) 进行训练和预测, 但是, 这种设置(如, $\mu=0.5$)实际上建立了一个相等宽松的正样本要求. 结果就是当阈值设置较低时, 往往会产生出很多的噪声候选框, 如图1(a)所示. 大多数人的假设都会使得假正例通过 $IoU \geq 0.5$ 的限制. 虽然在 $\mu = 0.5$ 的准则下获得的样本更加丰富多样, 但是它们也会使得检测器难以有效的拒绝这些假正例. 在本文中, 我们将假设质量(quality of an hypothesis)定义为 proposals 与真实框之间的 IoU, 而将检测器质量(quality of the detector)定义为训练时使用的 IoU 阈值 $\mu$. 我们的目标是研究一个目前为止较少研究的问题, 即找到高质量的检测器 IoU 阈值, 该检测器会输出更少的 close false positives (注意, 我们是希望得到更少的假正例, 而不是希望负样本的数量变低, 这两个是有区别的, 不要搞混), 如图1(b)所示. 本文的基本思想是, 如果只使用一个单一的模型, 那么我们就只能在一个单一的级别上优化检测器的 IoU 阈值. 这是著名的 cost-sensitive 学习迭代. 我们与之不同的地方在于, 我们是基于 IoU 阈值来进行优化的, 而不是基于假正例样本率. 核心思想如图1(c)和(d)所示, 图中展示了三种 IoU 阈值下的检测器的定位和检测性能. 定位性能是关于输入的候选框 IoU 的函数, 检测性能是关于 IoU 阈值的函数(COCO 数据集). 从图1(c)可以看出, 当输入的 proposals 的 IoU 在0.5~0.6之间时, 训练时回归器采用 $\mu=0.5$ 可以获得最大的 IoU 输出(预测结果的框与真实框的 IoU 越大, 说明这些框的质量越好), 而当输入的 proposals 的 IoU 在 0.6~0.75 之间时, 训练时采用 $\mu=0.6$ 时的性能最好, 再之后就是 $\mu=0.7$ 时的性能最好. 可以得出, 只有 proposal 自身的阈值和训练器训练时用的阈值较为接近时, 训练器的性能才更好. 从图1(d)中可以看出, 使用 $\mu = 0.5$ 的检测器相比于 $\mu = 0.6$ 的检测器, 在面对 IoU 较低的 proposals 样本时, $\mu = 0.5$ 的检测器性能较好, 在面对 IoU 较高的 proposals 样本时, $\mu = 0.6$ 的检测器性能较好. 一般来说, 在一个 IoU 水平上优化的检测器在其他水平上不一定是最优的. 这些观察表明, 更高质量的检测结构要求检测器和它处理的假设之间具有更紧密的质量匹配(closer quality match). 一般来说, 检测器只有在面对高质量的 proposals(与gt有高iou值) 时, 才能生成高质量的检测结果. 但是, 为了生成一个高质量的检测器, 仅仅在训练阶段提升 $\mu$ 的值是不够的. 实际上, 如图1(d)中的 $\mu = 0.7$ 的检测器所示, 一味的升高 $\mu$ 会降低检测性能(全程低于 $\mu = 0.5$ 和 $\mu = 0.6$ 的检测器). 其问题是因为从 proposal detector 中得到的假设分布通常对于 low quality 的 proposals 严重失衡. 一般来说, 当我们设置更大的 IoU 阈值以后, 就会使得参与训练的正样本的数量减少, 这对于神经网络来说很容易导致过拟合现象的发生. 另一种难点就在于 检测器的质量与 inference 阶段时的假设质量不匹配. 如图1所示, 高质量的检测器仅仅只对高质量的假设是最优的. 当它们在面对其他质量水平的假设时, 检测可能不是最优的. 在这片文章中, 为了解决上述问题, 我们提出了一种新的检测框架: Cascade R-CNN. 它是 R-CNN 的一种 multi-stage 扩展, 在该模型中, 处于级联网络更深处的检测器对于难分辨的假正例(close false positive)具有更强的选择性. Cascade R-CNN 是 按阶段训练的 (stage by stage), 它会用一个 stage 的输出来训练下一个检测器. 这是通过观察图1(c)中, 每一个检测器输出的 IoU 总是比输入的 IoU 更好而受到的启发. Cascade R-CNN 的流程很像 boostrapping 方法. 但是不同之处在于 Cascade R-CNN 的冲采样过程不是为了挖掘难反例. 相反, 通过调节 bounding boxes, 每一个 stage 都会去寻找更好(容量更少)的 close false positives 集合来训练下一个 stage. 在具体操作时, 一系列的检测器会在一组递增的 IoU 阈值集合上训练, 以此避免过拟合问题(直接在大的 IoU 上训练会导致过拟合). 在测试阶段, 会执行同样的流程. 这种逐步改进的假设与每个阶段的检测器质量的匹配度会更好. 举例说明:有三个串联起来的用0.5/0.6/0.7的阈值训练出来的detector，有一个 IoU 约为0.55的proposal，经过0.5的detector，输出的物体框的 IoU 变为0.75；将此框再经过 0.6 的detector，输出的 IoU 变为 0.82；再经过 0.7 的detector，最终IoU变为 0.87. 这比任何一个单独的detector的结果都要好。同时，因为每经过一个 detector，其输出的 proposal 的 IoU 都更高，样本质量更好了，那么即使我下一个 detector 阈值设置得比较高，也不会有太多的样本被刷掉，这样就可以保证样本数量避免过拟合问题。 Cascade R-CNN 很容易实现并且可以端到端的训练. 可以使用任何基于 R-CNN 的 two-stage 目标检测模型进行搭建. 可以获得 consistent gains(2~4 points). 并且可以和其他各种 trick 叠加. Related WorkR-CNN, SPP-Net, Fast R-CNN, Faster R-CNN, RPN, R-FCN, MS-CNN, YOLO, SSD, RetinaNet Object Detection在本文章, 我们将 Faster R-CNN 模型进行扩展, 如图3(a)所示, 第一阶段是一个 proposal sub-network (H0), 将其作用于整个图片, 会生成 主要的检测假设(即 anchor box proposals). 在第二个阶段, 这些生成的候选框 (hypotheses) 会被一个 roi detection sub-network (H1) 处理, 我们将其记为 detection head. 最终, 分类 score (C) 和 bounding box (B) 会被分配到每一个候选区域框 (hypothesis)上. 本文主要是构建一种 multi-stage 的模型框架, 如图3(d)所示. Bounding Box Regressionbounding box $b = (b_x, b_y, b_w, b_h)$ 包含了某个图像区域块 $x$ 的四个坐标. 边框回归(bbox regression)的任务就是利用回归器 $f(x, b)$ 将一个 box $b$ 回归对目标 box $g$ 上. 这是通过训练样本 $(g_i, b_i)$ 学习得到的, 以使得 L1 损失函数 $L_{loc} (f(x_i, b_i), g_i)$ 最小化. 为了保证尺寸不变性和位置不变性, $L_{loc}$ 通常是通过学习偏移量而不是直接学习坐标. 由于 bounding box 的偏移量都是归一化的, 所以数值都比较小, 因此, regression loss 通常会远小于 classification loss. 可以从图1中看到, 在得到了 anchor boxes 后, Faster R-CNN 只进行了一次 box regression. 因此, 有一些工作认为单次的 box regression 是不够的, 故而提出了 iterative bounding box regression, 记为 iterative BBox, 用该方法作为后处理步骤来对 bbox 进行精化. f'(x, b) = f\circ f\circ ... \circ f(x,b)它的实现结构如图3(b)所示(因为是后处理操作, 所以只在 inference 阶段执行), 该方法中使用的所有的 head 都相同. 这种方法, 忽略了两个问题: 第一, 对于具有更高 IoU 的输入来说, 较低的阈值 ($\mu=0.5$) 往往是一种次优解 (如图1所示); 第二, 如图2所示, bounding box 的分布在每次迭代后都会发生很大的变化, 但是固定的阈值使得模型每次更新时都是以初始分布为目标的. 基于这些问题, iterative BBox 需要大量的人工工程设计, 以 proposals 累积, box 投票等形式存在, 其收益也不太可靠. 通常, 应用两次 $f$ 以上并不会获得更多的收益. Detection Quality分类器 $h(x)$ 会给一个图片区域块(image patch) $x$ 分配一个类别(M+1 类, 0 代表背景). 给定训练集 $(x_i, y_i)$, 它将会通过最小化分类交叉熵 $L_{cls}(h(x_i), y_i)$ 来进行学习, 式中 $y_i$ 代表了 $x_i$ 的类别.因为一个 bounding box 通常会包含一个目标物体和一些背景, 因此很难决定一个检测框是 positive 还是 negative 的. 通常我们利用 IoU 来解决这个问题. 当给定 IoU 一个阈值 $\mu$, 如果图片区域块(image patch)和真实框的 IoU 大于该阈值, 就认为他是正样本. 因此, 候选区域框(hypothesis)的标签可以看做是 $\mu$ 的函数. y = \begin{cases} g_y, && IoU(x, g) \geq \mu \\ 0, && otherwise \end{cases}上式中, $g_y$ 是真实目标 $g$ 的分类标签. 这个 IoU 阈值 $\mu$ 就定义了检测器的质量(quality of a detector). 目标检测问题具有挑战性的原因之一就是无论设置什么样的阈值, 检测设置都是具有高度对抗性的. 具体来说, 当 $\mu$ 较高时, 正样本会包含较少的背景, 但是这样又难以收集到足够的正样本进行训练. 当 $\mu$ 较低时, 可以获得更加丰富多样正样本训练集合, 但是检测器却难以拒绝不好分辨的假正例样本. 通常情况下, 我们很难要求单个分类器在所有 IoU 级别上都能很好的执行. 在 inference 阶段, 由于 proposal 检测器(RPN)生成的大多数候选框(hypotheses)具有较低的质量, 因此, 检测器必须对低质量的 hypotheses 具有更强的鉴别能力. 在这些相互冲突的需求之间, 一个标准的折衷方案是令 $\mu = 0.5$. 但是, 这相对来说是一个比较低的阈值, 会导致生成很多假正例检测结果, 如图1(a)所示.一个简单解决方案就是将多个分类器集成, 如图3(c)所示. 但是该方法会使得分类器的性能过强而陷入过拟合状态 Cascaded R-CNN下面我们将介绍 Cascade R-CNN 目标检测模型, 如图3(d)所示. Cascaded Bounding Box Regression如图1(c)所示, 我们很难令一个单一的回归器在所有的 quality levels(输入的框的 IoU 级别) 上获得完美的表现. 我们可以将较难的回归任务分解成一系列较小的步骤, 在 Cascaded R-CNN 中, 我们将其组织成如图3(d)中的结构, 其依赖于一系列专门的回归函数, 写成公式表达如下: f(x,b) = f_T \circ f_{T-1} \circ ... \circ上式中, $T$ 是 cascade stages 的数量.该式和图3(b)所示的 iterative BBox 方法有很多不同之处. 第一, iterative BBox 是一种用来提升 bounding boxes 的后处理步骤, 而 cascaded regression 是一种用于在不同 stages 改变假设分布的重采样过程. 第二, 由于会同时在训练和预测阶段使用 cascade 策略, 因此训练和预测阶段之间的分布没有差异性. 第三, 在不同的 stages 上, 会对重新采样后的分布会训练不同的回归器 $\{f_T, f_{T-1}, …, f_1 \}$. 这些特点使得我们的模型可以产生更加精确的 BBox, 而不需要过多的 human engineering. Cascaded Detection如图4所示, RPN 网络最初生成的假设分布更多的集中在 low quality 的box上, 这不可避免的会导致对高质量分类器的无效学习. Cascade R-CNN 通过将级联回归用作重采样机制来解决这个问题. 这是受到图1(c)的启发, 即在给定阈值下训练的回归器会生成更高质量的 bbox. 因此, 从 $(x_i, b_i)$ 开始, 级联回归会先后的进行重采样来获得更高的 IoU proposals. 这样一来, 即使检测器的质量(IoU阈值)升高了, 我们也可以将连续阶段中的正样本比例保持在大致恒定的大小. 如图4所示, 在每一次重采样之后, 分布都会倾向于高质量(高IoU)的样本. 这会导致两个现象. 第一, 因此在所有级别的 IoU 上都有大量的正样本, 因此不会出现过拟合. 第二, 对较深阶段的检测器进行了优化, 使用具有较高的 IoU 阈值. 注意到, 通过增加 IoU 阈值, 一些异常的值将被逐渐删除, 如图2所示, 这样可以实现更好的训练有素的专用检测器序列. 在每一个阶段 $t$ 中, R-CNN 都包含一个分类器 $h_t$ 和一个回归器 $f_t$ (针对 $u^t$ 进行优化, $u^t &gt; u^{t-1}$), 通过最小化下面的 loss 进行学习 L(x^t, g) = L_{cls} (h_t(x^t), y^t) + \lambda [y^t \geq 1] L_{loc}(f_t(x^t, b^t), g)上式中, $b^t = f_{t-1} (x^{t-1}, b^{t-1})$, $g$ 是 $x^t$ 的真实物体标签, $\lambda = 1$ 是平衡系数(trade-off coefficient). 在 Inference 阶段, hypotheses 的质量会逐渐提高, 通过使用相同的 cascade procedure 以后, 更高质量的检测只需要作用在更高质量的 hypotheses 之上即可. Experimental Results实现细节:所有的 cascade detection stages 具有相同的结构(the head of the baseline network).Cascade R-CNN 总共具有 四个 stages, 一个 RPN 以及三个 U = {0.5, 0.6, 0.7} 的 detection network.第一阶段的 sampling 策略和 Faster R-CNN 中相同, 后面阶段的重采样使用的是前一阶段输出的结果.除了标准的水平翻转以外, 没有使用其他的 data augmentation 技术.Inference 是在 single image scale 上进行的.End-to-end training Baseline Networks: Faster R-CNN, R-FCN, FPN. Faster R-CNN: 该网络具有两层 fc 层. 为了降低参数量, 我们使用 “attend refine repeat” 来剪去不重要的链接. lr: 起始 0.002, 在 60k 和 90k 次迭代的时候降低 10 倍, 在 100k 次迭代的时候停止, 2 个 synchronized GPUs, 每一个持有 4 张图片, 每张图片提供 128 个 RoIs. R-FCN: 没有使用 OHEM. lr: 起始 0.003, 160k 和 240k 次迭代的时候降低 10 倍, 280k 次迭代的时候定值, 4 个 synchronized GPUs, 每一个持有一张图片, 每张图片提供 256 个 RoIs. FPN: 使用了 RoIAlign. lr: 0.005 用于最开始的 120k 次迭代, 0.0005 用于后面的 60k 次迭代, 8 个 synchronized GPUs, 每一个持有一张图片, 每张图片提供 256 RoIs. Quality Mismatch下图5(a), 可以看出, 虚线始终位于对应实线的上方, 说明应用了 Cascade R-CNN 以后, 模型产生的框的 mAP 变高了. 从图(b)中可以看出, 当输入的框的 IoU 较大时(通过不断添加真实框来增大输入的 IoU 的大小), $\mu$ 值较大的检测器可以获得更高的 IoU. 图6显示了所有的 Cascade R-CNN 检测器在所有 stage 上面的 mAP值, 从图6可以看出, 经过 Cascade R-CNN 以后, 输入的框的 IoU提升了, 是的阈值为 $\mu = 0.7$ 的检测器的 mAP 提升了, 不仅如此, 我们还可以看到, 在经过 Cascade R-CNN 以后, 即使是对具有更高 IoU 的输入, $\mu =0.5$ 的检测器也比 stage-1 阶段的 mAP值高, 这说明本文提出的 Cascade R-CNN 框架可以有效的提升检测器的性能. 在图7(a)中, 我们将本文的 Cascade R-CNN 与 Iterative Box 进行了对比, 在图1中, 我们可以看出, 使用单个回归器不断迭代的方式会降低输出的 IoU 大小. 相反, 使用本文的 Cascade R-CNN 方法, 可以在新的 stage 中生成更高的 IoU.在图7(b)中, 使用同一个检测器, 但是赋予不同的 $\mu$ 值时, 当 $\mu=0.6$ 时 mAP 最高, 当 $\mu=0.7$ 时 mAP最高, 而融合吼的模型结果也没有获得较大的提升. 从表1可以看出, Iterative BBox 和 intergral loss 检测器相对于 baseline 方法都可以提升模型的精度, 但是本文的 Cascade R-CNN 具有最好的精度表现. 消融实验 Stage-wise Comparison: 表2总结了每个 stage 的性能表现, 注意到, stage-1 已经超过了 baseline detector, 这是因为经过 multi-stage 学习后, stage-1 的检测能力也得到了一定的提升. 总体趋势显示越深的 cascade stage 具有越高的 quality localization. (但是考虑到模型复杂度和训练难度问题, 也不能叠加太多 stage, 一般2,3层差不多) IoU Thresholds: 表3前两行显示, 相对于每一个阶段使用固定的 IoU 阈值 (如0.5), 采用递增式的 IoU 阈值可以获得更好的效果 (对于 close false positives 更具有选择性). 但是同样的, 即使使用相同的 IoU 阈值来训练每一个阶段, 也比 baseline 的 mAP 高. Regression Statistics: 表3第一行和第三行对了使用和不使用 sequential regression statictics 时的模型性能差异. 表4总结了 stages 的个数对模型的影响. 添加两层 stages 可以大幅度提升 baseline 的精度, 第三层可以小幅度的的提升模型精度, 但是当叠加到第4层时, 模型精度就会收到一定影响并有略微下降.(尽管如此, 具有4个 stages 的检测器在较高的 IoU (AP90)下可以取得最好的精度表现) Comparison with the state-of-the-art: 表5显示了本文的 Cascade R-CNN 模型与现有模型之间的性能对比. 表6显示了在不同的 baseline 模型上应用 Cascade R-CNN 之后的性能表现 表7显示在不同的 backbone 网络中, Cascade R-CNN 仍然能够大幅度提升模型的 mAP]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-模型训练]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%2F</url>
    <content type="text"><![CDATA[运行Faster-RCNN指令123python tools/train_net.py \ --cfg configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml \ OUTPUT_DIR /tmp/detectron-output 上面两行指令第一行指定了config文件的位置, 第二行指定了输出文件的位置. 在tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml文件中, 主要包含了以下几个关键信息: MODEL: 包含模型类型, 卷积网络的骨干, 样本类别数目 SOLVER: 包含一些参数的值, 如: 权重衰减系数, LR_POLICY, GAMMA, MAX_ITER等等 FPN: 包含若干布尔值, 指示是否开启FPN, MULTILEVEL_ROIS/RPN 等等 FAST_RCNN: 与ROI相关的一些信息 TRAIN: 指定初始化权重文件的url, 以及数据集相关信息 TEST: 指定TEST数据集相关信息, NMS阈值 OUTPUT_DIR: . 被命令行的参数覆盖 上图为tools/train_net.py文件函数调用的关系图, 几乎所有的模型都是通过这个脚本运行的, 源码分析如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# tools/train_net.pyfrom __future import ... # 导入__future__的相关包, 兼容python2#...import cv2 #由于cv2自身的bug, cv2必须在caffe2之前被导入#...from caffe2.python import workspace# 导入detectron相关from detectron.core.config import assert_and_infer_cfgfrom detectron.core.config import cfgfrom detectron.utils.logging import setup_logging# helpful utilities for working with caffe2import detectron.utils.c2 as c2_utils# 训练文件import detectron.utils.train# 导入Detectron需要的相关contirb ops(nccl ops)c2_utils.import_contrib_ops()# 导入Detectron opsc2_utils.import_detectron_ops()cv2.ocl.setUseOpenCL(False) #源码注释已经说得很清楚, 就是为了安全而特意禁用opencldef parse_args(): # 定义了各种命令行参数, 一般只需要关注--cfg参数, 其他默认即可def main(): # 初始化caffe2的全局环境, #如果希望看到更加详细的初始化信息, 可以将log_level设置为1 workspace.GlobalInit( ['caffe2', '--caffe2_log_level=0', '--caffe2_gpu_memory_tracking=1'] ) ## 设置logging, __name__ = '__main__', 使用了python的logging模块, logger = setup_logging(__name__) #... # 解析命令行参数 args = parse_args() #... if args.cfg_file is not None: # from detectron.core.config import merge_cfg_from_file merge_cfg_from_file(args.cfg_file) if args.opts is not None: # from detectron.core.config import merge_cfg_from_list merge_cfg_from_list(args.opts) assert_and_infer_cfg() # 获取并显示当前的nvidia相关信息 smi_output, cuda_ver, cudnn_ver = c2_utils.get_nvidia_info() logger.info(...) #... # 设置随机种子, 以便每次训练时的网络状态都不同 np.random.seed(cfg.RNG_SEED) # 最重要的一行代码, 执行训练! # import detectron.utils.train checkpoints = detectron.utils.train.train_model() # 测试训练好的模型 if not args.skip_test: test_model(...)def test_model(...): # 测试训练好的模型 #...if __name__ == "__main__": main() train.py 文件可以看到, 上面只是一个启动训练代码的脚本文件, 接下来看一下detectron/utils/train.py文件中的train_model()函数的详细情况: 123456#detectron/utils/train.pydef train_model(): """循环训练模型""" model, weights_file, start_iter, checkpoints, output_dir = create_model() #... create_model()在这里, train_model()函数的开始调用了create_model()函数, 在进行后面的代码分析之前, 需要先看看这个函数具体做了什么, 返回了什么:1234567891011121314151617181920212223242526272829303132333435363738394041#detectron/utils/train.pydef train_model(): #...def handle_critical_error(model,msg): #...def create_model(): """创建模型, 并且寻找保存的checkpoints用以继续训练""" logger = logging.getLogger(__name__) start_iter = 0 checkpoints = &#123;&#125; # from detectron.core.config import get_output_dir # def get_output_dir(datasets, training=True) # 这里只是用了数据集的名字, 并不是使用数据集 # 在OUTPUT文件夹(由config定义)会创建一个新的文件夹, 并返回该路径: # &lt;output-dir&gt;/&lt;train|test&gt;/&lt;dataset-name&gt;/&lt;model-type&gt;/ # 对于本例来说, cfg.TRAIN.DATASETS = ('coco_2014_train',) output_dir = get_output_dir(cfg.TRAIN.DATASETS, train = True) # 默认为R-50.pkl的 url 下载地址 weights_file = cfg.TRAIN.WEIGHTS if cfg.TRAIN.AUTO_RESUME: #TODO, 这个参数在哪里?? #... # 对于本例, cfg.MODEL.TYPE = generalized_rcnn logger.info("Building model: &#123;&#125;".format(cfg.MODEL.TYPE)) # from detectron.modeling import model_builder # def create(model_type_func, train=False, gpu_id=0) # 创建一个一般化的模型, 然后将其转化成特定的模型 # 函数内部使用了detectron/modeling/detector.py 中的DetectionModelHelper类 # 同时将cfg.MODEL.NUM_CLASSES信息传递给了该类 # cfg.MODEL.TYPE = generalized_rcnn # TODO: 此行代码涉及的文件和代码较多, 暂时先不深入探讨, 可以认为是创建了一个模型 model = model_builder.create(cfg.MODEL.TYPE, train=True) if cfg.MEMONGER: # TODO, 这个参数在哪里? optimize_memory(model) workspace.RunNetOnce(model.param_init_net) return model, wright_file, start_iter, checkpoints, output_dir setup_model_for_training(...)接着回到刚才的train_model()函数:12345678910111213141516171819#detectron/utils/train.pydef train_model(): """循环训练模型""" # 由上面的函数可知: # model为DetectionModelHelper类创建的模型对象 # weights_file即为cfg文件里定义的权重文件的url # start_iter = 0 # checkpoints =&#123;&#125; 字典类型哦! # output_dir为根据cfg.OUTPUT_DIR和DATASETS名字创建的输出目录 model, weights_file, start_iter, checkpoints, output_dir = create_model() if "final" in checkpoints: # 如果已经训练完成, 则直接返回 return checkpoints # 这里调用了本文件的函数, 主要是为训练模型做准备工作 setup_model_for_training(model, weights_file, output_dir) #... 具体看一下setup_model_for_training函数的内部实现 1234567891011121314151617181920212223242526272829303132333435363738394041#detectron/utils/train.py# 加载保存的权重文件, 同时在 C2 workspace 中创建 networkdef setup_model_for_training(model, weights_file, output_dir): logger = logging.getLogger(__name__) #调用了本文件的函数, 主要用于加载训练数据集, 并且将训练输入绑定到model中 # def add_model_training_inputs(model), 无返回值 # 核心代码: # from detectron.datasets.roidb import combined_roidb_for_trainig # roidb = combined_roidb_for_training(cfg.TRAIN.DATASETS, cfg.TRAIN.PROPOSAL_FILES) # model_builder.add_training_inputs(model, roidb = roidb) # 添加roidb, 内部会调用model_builder.add_training_inputs, # 该函数会为model创建用于训练网络的input ops 和blobs, 需要在调用了model_builder.create()之后调用 # 创建位于detectron.roi_data.loader中的RoIDataLoader对象进行数据载入 # model.roi_data_loader = RoIDataLoader() # TODO: 数据集加载过程涉及文件较多,后面会单独解析, 此处不太多讨论 add_model_training_inputs(model) # import detectron.utils.net as nu if weights_file: # 从权重文件中初始化模型, 覆盖随机初始化参数权重, 并且指定gpu nu.initialize_gpu_from_weights_file(model, weights_file, gpu_id=0) # 多GPU训练时,训练同步GPU之间的参数信息 # if cfg.NUM_GPUS = 1 直接return, 所以这句话在单GPU下可有可无 nu.broadcast_parameters(model) # 正式创建caffe2网络 workspace.CreateNet(model.net) #...log info # 本文件内的函数: def dump_proto_files(model, output_dir) # 保存训练网络的参数初始化的prototxt 描述信息 # 分别为output_dir里面的net.pbtxt和param_init_net.pbtxt文件 dump_proto_files(model, output_dir) # 载入mini-batches, 同时enqueuing blobs model.roi_data_loader.register_sigint_handler() model.roi_data_loader.start(prefill=True) return output_dir add_model_training_inputs(model)12345678910#detectron/utils/train.pydef add_training_inputs(model): logger = logging.getLogger(__name__) logger.info('Loading dataset: &#123;&#125;'.format(cfg.TRAIN.DATASETS)) roidb = combined_roidb_for_training( cfg.TRAIN.DATASETS, cfg.TRAIN.PROPOSAL_FILES ) logger.info('&#123;:d&#125; roidb entries'.format(len(roidb))) model_builder.add_training_inputs(model, roidb=roidb) 再看 train_model()接着回到刚才的train_model()函数:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#detectron/utils/train.pydef train_model(): """循环训练模型""" # 调用本文件的create_model()函数, 由上面的函数可知: # model为DetectionModelHelper类创建的模型对象 # weights_file即为cfg文件里定义的权重文件的url # start_iter = 0 # checkpoints =&#123;&#125; 字典类型哦! # output_dir为根据cfg.OUTPUT_DIR和DATASETS名字创建的输出目录 model, weights_file, start_iter, checkpoints, output_dir = create_model() if "final" in checkpoints: # 如果已经训练完成, 则直接返回 return checkpoints # 这里调用了本文件的函数, 主要是为训练模型做准备工作, 加载权重, 创建网络等等 setup_model_for_training(model, weights_file, output_dir) # from detectron.utils.training_stats import TrainingStats # def __init__(self, model) # 跟踪模型训练时的关键统计数据 training_stats = TrainingStats(model) # TODO SNAPSHOT_ITERS参数在哪? CHECKPOINT_PERIOD = int(cfg.TRAIN.SNAPSHOT_ITERS/cfg.NUM_GPUS) #循环训练过程cfg.SOLVER.MAX_ITER=60000次 for cur_iter in range(start_iter, cfg.SOLVER.MAX_ITER): # model.roi_data_loader是位于detectron.roi_data.loader中的RoIDataLoader对象 # def has_stopped(self): return self.coordinator.should_stop() # coordinator是位于detectron.utils.coordinator中的Coordinator类的对象, 该类用于多线程处理数据队列 if model.roi_data_loader.has_stopped(): handle_critical_error(model, 'roi_data_loader failed') # from detectron.utils.training_stats import TrainingStats # 用于训练计时, 计时开始 training_stats.IterTic() #更新学习率 lr = model.UpdateWorkspaceLr(cur_iter, lr_policy.get_lr_at_iter(cur_iter)) # 运行网络!关键步骤 workspace.RunNet(model.net.Proto().name) if cur_iter == start_iter: #首次迭代打印模型信息 # import detectron.utils.net as nu nu.print_net(model) training_stats.IterToc() # 计时结束 training_stats.UpdateIterStats() training_stats.LogIterStats(cur_iter, lr) # 迭代到指定次数以后, 自动保存模型 if (cur_iter+1) % CHECKPOINT_PERIOD ==0 and cur_iter&gt;start_iter: checkpoints[cur_iter] = os.path.join(output_dir, "model_iter&#123;&#125;.pkl".format(cur_iter)) nu.save_model_to_weights_file(checkpoints[cur_iter], model) if cur_iter == start_iter + training_stats.LOG_PERIOD: training_stats.ResetIterTimer() # 判断损失函数是否出现了nan值, 如果出现,则报错,注意,nan不是inf, nan值代表不存在的值, 如log(-1), 而log(0)是inf, 不是nan if np.isnan(training_stats.iter_total_loss): handle_critical_error(model, "loss is NaN") checkpoints['final'] = os.path.join(output_dir, 'model_final.pkl') nu.save_model_to_weights_file(checkpoints['final'], model) model.roi_data_loader.shutdown() return checkpoints 以上,便是train_model()函数的整体流程, 执行该函数后,训练过程就已经开始, 在detectron中, 所有的模型可数据都是用这个脚本训练的, 根据config文件的具体参数来决定载入哪个model, 或者使用哪个数据集. 但是上面的过程太过笼统, 给人一种隔了一堵墙的感觉. 因此, 我们需要更加深入了理解detectron是如何处理数据的, 又是如何将数据送到模型中去的, 另外, 每个模型的定义又是怎样的. 这些信息我会在后面的文章里一一解读.]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron源码解析]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron%2F</url>
    <content type="text"><![CDATA[roidb数据结构 数据载入 模型训练 风格说明./tools/infer_simple.py 中的.代表的是当前目录, 默认情况下为Detectron. 通常对于较少函数参数, 会直接写出来, 如get_func(func_name), 而对于参数较多的函数, 有时会省略, 如build_generic_detection_model(...) 根目录dirs:— build: 有关cython构建的文件 — cmake: 各种编译配置文件 — configs: 使用模型时的config文件 — demo: 一些图片的demo — Detectron.egg-info: 源码信息 — detectron: 最主要的文件夹, 存放几乎所有的模型源文件 — docker: 顾名思义, 存放了Dorkerfile&emsp;|— Dockerfile — projects&emsp;|— gn.jpg&emsp;|— README.md — tools files:— CMakeLists.txt — CONTRIBUTING.md — FAQ.md — GETTING_STARTED.md — INSTALL.md — LICENSE — Makefile — MODEL_ZOO.md — NOTICE — README.md — requiresments.txt — setup.py core目录detectron目录]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Speed Accuracy TradeOffs (CVPR, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-Speed-Acc-CVPR2017%2F</url>
    <content type="text"><![CDATA[文章: Speed/accuracy trade-offs for modern convolutional object detectors作者: Jonathan Huang, Vivek Rathod, Chen Sun, Menglong Zhu, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, Kevin Murphy备注: Google 核心亮点本文实现了一个灵活统一的目标检测框架, 并对三个主流的目标检测模型做了详细客观的分析和讨论通过该框架, 本文对目前主流的各个模型(Faster, R-FCN, SSD)影响精确度和速度的各个因素展开了详细的分析和讨论, 以此希望能够帮助从业者在面对真实应用场景时, 能够选择适当的模型来解决问题. 同时, 本文还发现了一些新的现象(减少 proposals box 的数量), 使得可以在保持精度的前提下, 提升模型的速度. 论文细节摘要本篇文章的目的主要是为在给定平台和应用环境下选择一个合适的目标检测模型提供指导, 即要达到合适的 speed/memory/accuracy 平衡. 为此, 我们研究了多种方法来平衡现代卷积网络检测模型的速度, 准确度, 内存消耗等. 近年来有大量成功的检测模型被提出, 但是, 我们很难直接将这些模型互相比较, 因为它们采用的特征提取器不同(eg, VGG, ResNet), 采用的图片尺寸不同, 硬件设备和软件平台也不同. 因此, 本文提供了一个基于 FasterRCNN, R-FCN, SSD 的统一实现版本, 我们称之为- meta-architectures, 然后通过使用不同的特征提取器, 不同的关键参数来跟踪这些模型之间的差异. 最终的模型有两个极端, 一是极度关注速度, 要求最终的模型可以运行在移动设备上, 二是极度关注准确度, 要求能够在 COCO 数据集上达到最高的分数. 介绍目前有众多成功的模型, 但是却很难决定哪种场景下使用哪种模型, mAP 评价标准并不能反映所有问题, 还需要同时考虑模型的运行速度和内存消耗.目前, 只有很少的模型讨论的运行速度(R-FCN, SSD, YOLO), 但是它们大多都只是声称它们达到了某个 fps, 并没有深入的展开关于速度和精度之间的讨论.在这篇文章中, 我们希望以一种详尽而公平的方式来探讨这些模型的速度的精度之间的平衡关系. 在评估时, 我们不使用任何 tricks(ensembling, multi-crop, flipping等等), 仅仅评估单一模型的性能, 对于时间的测量, 我们仅关注预测阶段的运行时间, 而不在意训练时长.本文的贡献主要有以下几点: 提供了一个关于现代卷积检测系统的具体调研报告, 并阐述了这些先进模型在设计模式上共有的通性. 用 TensorFlow 实现了一个灵活统一的检测框架 meta-architectures, 包含 FasterRCNN, R-FCN 和 SSD 三种模型 本文发现, 通过使用较少的候选区域框可以大大提高 FasterRCNN 的检测速度, 并且在精度上不会有太大损失. 同时, 我们还发现 SSDs 的性能表现在面对不同的特征提取器时, 不像 FasterRCNN 和 R-FCN 那么敏感. 并且我们在 acc/speed 曲线上确定了 sweet spots, 这些点上的 acc 只有在牺牲 speed 的情况下才能够提升. 我们尝试了一些以前从未出现过的 meta-architecture 和 feature-extractor 的结合方式, 并讨论了如何利用这些方式来训练 winning entry of the 2016 COCO object detection challenge. Meta-architectures在我们的文章中, 我们主要讨论三种主流模型: SSD, FasterRCNN 和 R-FCN. 在这三个模型的原文中各自使用了特定的特征提取器(eg, VGG, ResNet). 现在我们将模型和特征提取器解耦, 重新审视这些模型结构. SSD将画框和分类预测同时进行, 代表一众 one-stage 检测方法 FasterRCNNFasterRCNN 是自 2015 年以来最主流的 two-stage 目标检测模型, 它首先提出了 RPN 网络, 使得候选框推荐的步骤可以整合到神经网络中去, FasterRCNN 也衍生出了多种的版本, 代表着经典的 two-stage 模型. R-FCN尽管 FasterRCNN 比 FastRCNN 快了一个数量级, 但是相对于 one-stage 方法, 它仍然很慢. 为此, 有人提出了 R-FCN 检测模型, 它和 FasterRCNN 模型类似, 但是将候选框的划取阶段移到了网络模型的最后一层, 使得有更多的卷积层可以共享计算结果, 同时还提出了 PSRoI(position-sensitive), 大大加快了模型的运算速度. Experimental setup各个模型的实现在所用框架, 优化程度, 数据集等都有所不同, 因此, 单单比较 COCO 或 ImageNet 的 mAP 是不全面的. 因此, 为了更好地比较各个模型之间的差异, 我们用 TensorFLow 实现了一个目标检测框架, 从而可以让我们较为客观公平的进行对比. Architectural configurationFeature extractors: VGG-16, ResNet-101, Inception v2, Inception v3, Inception ResNet v2, MobileNet.对于 FasterRCNN 和 R-FCN 来说, 我们需要确定使用特征提取器的哪一层卷积特征图谱来预测候选区域框. 我本文的实验中, 我们尽可能的使用原文中的设置, 如果原文没有提到的, 我们则尽可能的选择相类似的设置.在 SSD 中, 因为使用了多个不同尺度的特征图谱来预测 box 的位置和分类, 因此, 特征图谱的选择是至关重要的. 在 VGG 中, 原文使用了 conv4_3, fc7, 以及后续的几层卷积层, 与原文不同的是, 我们在每一个附加层之后都使用了 BN 层. Number of proposalsFasterRCNN &amp; R-FCN : 10~300 (trade-off) Output stride setting for Resnet and Inception ResNet采用stride 16, 将 conv5_1 的stride从2变为1, 并在后面使用 Atrous 卷积(Dilation 卷积) 来弥补缩小的感受野. 另外, 通过改变 conv4_1 的stride, 还测试了 stride 8 的情况. 相比于 stride 16, stride 8 的 mAP 提升了 5%, 但是运行时间也变慢了 63%. Matching 同样采用原文推荐的参数设置来将候选框与真实框匹配. Box encoding: 与原文相同: (b_a;a) = [10\cdot \frac{x_c}{w_a}, 10\cdot \frac{y_c}{h_a}, 5\cdot \log w, 5\cdot \log h] 需要注意的是, 标量 10 和 5 在原文的代码实现中都有使用, 即使在原文中没有提及. Location loss: Smooth L1 Input size configuration: M=300 / 600. Training and hyperparameter tuning; 对于 FasterRCNN 和 R-FCN, 我们用 TF 的 crop_and_resize 操作来代替 RoIPooling 和 PSRoIPooling, 该操作是利用双线性插值进行反向投影的, 其求导机制和原文中的类似. Benchmarking procedure: 32GB RAM, Intex Xeon E5-1650 v2 processor, Nvidia GTX Titan X. 下面的表2总结了本文使用的特征提取器 Results 分析通常来说, R-FCN 和 SSD 模型要比 Faster RCNN 模块快得多, 但是 Faster RCNN 的精确度更高. 但是, FasterRCNN 可以通过降低候选区域框的数量来提升速度. The effect of the feature extractor: 整体来说, 越强的特征提取器与 mAP 分数成正比, 但是对于 SSD 来说, 这种提升并不明显 (为什么 Inception v2 的 FasterRCNN 和 R-FCN 的 mAP 值那么低?) The effect of object size: The effect of image size: 当 image size 从 600 降到 300 时, 精度度平均会降低 15.88%, 同时 inference time 也会降低 27.4%. The effect of the number of proposals: proposals 可以大幅度降低测试时间, 同时 mAP 值只会降低一点(Inception ResNet v2, 300 -&gt; 10, 35.4% -&gt; 29%). 我们找到的 sweet point 大约是 50 个候选区域框, 此时可以在保持 300 候选区域框精度的 96% 的前提下, 将测试速度提升 3 倍. FLOPs analysis:FLOPs(multiply-adds) Memory analysis: Good localization at .75 IOU means good localization at all IOU thresholds: 表4总结了我们模型的性能(融合了5个FasterRCNN), 并且突出了如何在 COCO 评价标准上提升性能.在模型融合时, 我们选取了5个FasterRCNN模型, 每个模型都是基于ResNet 和 Inception Resnet的, 他们的 stride 不同, 并且使用了不同的损失函数, 以及不完全相同的训练数据. 最终使用ResNet论文中的附录A的方法融合这些模型的检测结果. 表5总结了最后选定的模型的性能表现. 模型融合以及 multi-crop inference 大约使模型的精度提升了7个百分点. 表6比较了单个模型和模型融合之间的性能差异]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DCN-ICCV 2017]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DCN-ICCV2017%2F</url>
    <content type="text"><![CDATA[文章: Deformable Convolutional Networks作者: ifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, Yichen Wei机构: Microsoft Research Asia 核心亮点1) 引入了可以自调节感受野大小的deformable convolution和deformable RoI 模块该模块通过额外学习一组采样偏移量来决定卷积操作和RoI pooling操作的采样位置, 通过这种方式, 是的网络模型可以根据输入的图谱自动调节感受野的大小的分布. 2) 上面的两种deformable模块均可以无痛的添加到现有模型中由于deformable convolution和deformable RoI 模块并不会改变原始的输入输出大小, 因此可以很轻易的替换到现有网络中, 并且可以有其他多种提升精度的trick想叠加, 在多个视觉任务上(检测, 分割)都表现出色. 论文细节摘要卷积神经网络由于其模型内部固定的几何结构, 使得它固有的受限于模型的几何变换. 在这片文章中, 作者引入了两种新的模块来增强CNN模型的transformation modeling能力, 分别为 可变形的卷积模块 和 可变形的RoI池化模块(deformable convolution and deformable RoI pooling). 这两个模块都是基于增强模型中的空间采样点的思想提出的, 并且是通过 在没有额外监督标签下, 从目标任务学习偏移量来增加空间采样位置的. 这些新的模块可以 轻易的替换掉CNN网络中的原始部分, 并且可以轻易地进行端到端的训练. 下面, 我们将会展示在CNN网络中 学习 密集的空间形变, 有助于提升传统的视觉任务, 如物体检测, 语义分割等等. 介绍在视觉识别任务中, 有一个很关键的点在于怎样才能最大程度的适应物体的几何变换, 如物体尺寸, 姿态, 观察角度, 局部形变等等. 在通常情况下, 具有两种做法, 第一 是建立足够的数据集来包含这些可能的形变, 以便让网络能够学习到足够的形变知识. 这一类方法的典型应用就是数据增广. 第二种 方法就是使用支持形变不变性的特征表示或算法, 如SIFT(CNN具有平移不变性, 但不具有形变不变性).上面的两种方法有一些明显的缺点. 首先, 就是要求对形变类型已知, 只有在这种假设成立的前提下, 才能有选择的应用最合适的数据增广方法. 第二, 即使在知道形变可能类型时, 利用人工设计特征算子依然是一个不容易的工作, 尤其适当形变类型较为复杂时. CNN虽然取得了很大成功, 但是CNN仍然面临这这两问题. 它们对物体形变的适应能力实际上大多来自于海量数据集, 大型模型, 以及一些简单的人工设计模块的支持(如 max-pooling for small translation-invariance).总而言之, CNN 天生的局限于对大型的, 位置的转换任务进行建模, 这种限制来自于CNN模型本身的结构模块(不论是卷积层还是fc层, 层的参数及输出向量都是固定的). 因此, 在CNN内部, 缺少相应的内部机制来处理几何形变的问题. 举个例子来说, 在同一层卷积层中所有激活单元感受野大小都是一样的, 而这并不是high level的卷积层所期望看到的, 因为正常来说, 不同位置与物体之间的联系紧密程度是不同的. 另外, 目前大多数方法都是基于主边框进行回归预测的, 这实际上是一种次优化的方法, 尤其是对于非规则物体来说.在这篇文章中, 我们提出了两个新的模块可以增强CNN对物体集合形变的适应能力. 首先是 可形变卷积模块, 它将 2D的偏移量 添加到规则的网格采样位置中, 它可以使得采样网络能够自由变形, 如图1所示. 图中的不同的偏移量都是通过额外的卷积层从之前的特征图谱中学习到的. 因此, 可形变是以一种局部的, 密集的, 自适应的方法建立在输入特征之上的. 第二部分是 可形变RoI pooling. 它为前一个 RoI pooling 的常规 bin 划分中的每个 bin 位置都添加天一亮. 同样, RoI pooling的offset也是从前面的特征图谱和 RoIs 中学习得到的, 从而支持对具有不同形状的对象进行自适应的局部定位.以上两种可形变模块都是轻量级的, 并且只引入了很少的参数和计算量, 可以很容易的替换掉标准的CNN网络中去. 产生的网络我们称之为可形变卷积网络(Deformable ConvNets). Deformable Convolutional Networks特征图谱和卷积操作都是 3D 的. 可形变操作模块都是在 2D 空间领域进行操作的. 不同通道上的可形变操作是一样的, 因此, 为了简单起见, 这些模块都用 2D 进行描述, 并且可以轻易扩展到 3D. Deformable Convolution一个2D的卷积操作由可以分为两步: 使用某个规则网格 $R$ 在输入的特征图谱上进行采样 将采样点的值与卷积核对应位置的权重相乘再求和, 既得输出图谱某点的值网格 $R$ 定义了感受野的大小和 dilation 的选择, 例如下面的公式定义了一个 dilation 为 1 的 3× 3 大小的卷积核.R=\{ (-1,-1), (-1,0), ..., (0,1), (1,1) \} 对应输出的 feature map 上的每个点的值, 可通过下式计算: y(p_0) = \sum_{p_n\in R} w(p_n)\cdot x(p_0 + p_n) \tag 1上式中, $p_0$ 对应的是输出特征图谱上的点坐标, $y(p_0)$ 对应的是该点的值, $p_n$ 对应的是常规偏移量集合 $R$ 中的坐标偏移量, $w(p_n)$ 代表该偏移量对应的权重值, $x(p_0 + p_n)$ 代表输入特征图谱在坐标 $p_0+p_n$ 上的值. 可以看出, 这里的 $R$ 实际上也代表了输出特征图谱 $p_0$ 点的感受野范围. 在deformable 卷积中, 常规坐标偏移量集合 $R$ 会与另一个额外的偏移量集合 $\{\Delta p_n | n =1,…N\}, 其中, N=|R|$ 共同决定卷积核感受野的采样坐标, 于是, 输出特征图谱上面的点的计算公式变成: y(p_0) = \sum_{p_n\in R} w(p_n) \cdot x(p_0 + p_n + \Delta p_n) \tag 2可以看到, 现在的采样点不再是一个规则的矩形了. 在实现中, 偏移量 $\Delta p_n$ 是浮点数类型, 我们将通过双线性插值来实现(将卷积的输出通过插值的方法计算): x(p) = \sum_q G(q,p)\cdot x(q)上式中, $p$ 代表任意一个浮点坐标值( $p=p_0+p_n+\Delta p_n$ ). $q$ 代表输入特征图谱 $x$ 中的所有整数点坐标(实际计算时, 只有 $p$ 周围的四个整数坐标点有用). $G(\cdot, \cdot)$ 代表双线性插值函数. 注意 $G$ 具有两个维度, 它被分成两个一维的核, 如下所示, 式子中 $g(a, b) = max(0, 1 - |a - b|)$ G(q, p) = g(q_x, p_x) \cdot g(q_y, p_y) \tag 4如图2所示可形变卷积的过程, 我们通过在相同的输入特征图谱上使用卷积层来获得偏移量. 形变卷积核具有与当前卷积层相同的空间分辨率和 dilation. (如图2中的 $3\times 3$ with dilation 1). 最终输出的偏移量具有和输入特征图谱相同的空间分辨率在同一个卷积层当中, 卷积核的空间大小和dilation都是相同的. 图中的通道维数 $2N$ 对应着 $N$ 个二维偏移量. 在训练的时候, 会同时学习生成输出特征图谱和偏移量的卷积核. 在学习偏移量时, 通过公式(3)(4)用BP算法更新偏移量参数. 注意, 同一层的多个卷积核各自持有一个offset Deformable RoI PoolingRoI pooling 目前被广泛的运用于各种目标检测模型当中, 它可以将不同尺度的矩形区域转换成固定尺寸的图谱. RoI Pooling: 给定一个特征图谱 $x$ 和一个大小为 $w\times h$ , 左上角坐标为 $p_0$ 的RoI, 对其使用RoI pooling, 将其划分成 $k\times k$ 大小的网格, 并且输出一个 $k\times k$ 大小的特征图谱 $y$. 那么, 对与 $y$ 中坐标为 $(i,j), 0\leq i,j \leq k$ 的网格bins来说, 其输出的值为 y(i,j) = \sum_{p\in bin(i,j)} x(p_0 + p) / n_ij \tag 5上式中, $n_ij$ 是bin中含有的像素点的个数. 同理, 我们可以将上面的标准RoI格式写成deformable RoI公式, 如下所示: y(i,j) = \sum_{p\in bin(i,j)} x(p_0 + p + \Delta p_{ij}) / n_{ij} \tag 6. 上式同样包含浮点型坐标 $\Delta p_{ij}$, 因此也用双线性插值实现. 图3说明了如何获得offsets. 首先, 利用标准的RoI pooling生成池化后的特征图谱. 在特征图谱上, 会用一个 $fc$ 层来生成归一化的offsets $\Delta \hat p_{ij}$, 然后通过对应元素相乘(element-wise product) $\Delta p_{ij} = \gamma \cdot \Delta \hat p_{ij} \odot (w,h)$ 将其转换成上式中的offsets $\Delta p_{ij}$. 式中, $\gamma$ 是一个预先定义的标量(默认为0.1), 来控制offset的大小. 注意, 为了使偏移量学习不受 RoI 大小的影响, 需要对偏移量进行归一化. Position-Sensitive(PS) RoI Pooling PS RoI pooling是全卷积的. 通过卷积层, 所有的输入特征图谱首先会被转换成 $k^2$ 大小的score maps.(对于每一类都有这样的一个maps, 因此共有 $C+1$ 个score maps), 如图4的底部分支所示. //TODO Deformable ConvNets可以看出, 不论是Deformable convolution还是 Deformable RoI pooling, 它们的输出都和常规版本的卷积核RoI的输出大小相同. 因此, 我们可以很自然的用Deformable模块替换现有目标检测模型中的常规模块. 在训练时, 为了学习offsets参数而新增的卷积层和fc层都被初始化为0, 它们的学习率被设置为现有目标检测模型学习率的 $\beta$ 倍(通常为1, 在FasterRCNN中, fc的 $\beta$ 设为0.01). 它们通过双线性插值运算的反向传播算法进行训练, 最终生成的模型称为 deformable ConvNets. 为了将deformable convnets整合到现有的先进检测模型中, 我们可以将 two-stage 目标检测模型看成以下 两部分:第一部分是一个深层的全卷积网络, 用于生成整个图片的特征图谱. 第二部分, 是根据特征任务设计的具体的浅层网络, 它从feature maps中获取最终计算结果. 下面来详细说明一下这两个部分.Deformable Convolution for Feature Extraction: 本文使用了两个先进的特征提取模型: ResNet-101 和 Inception-ResNet. 两个模型均在ImageNet数据集上预训练.这两个模型都包含多个卷积块, 一个平均池化层和一个1000路的fc层用于分类. 我们将平均池化层和fc层移除. 然后添加一个 1×1 的卷积层(随机初始化)将通道维数降为 1024 维. 根据前人工作(R-FCN), 我们将最后一个卷积块的stride从32降为16, 以此来提升特征图谱的resolution, 具体来说, 就是在最后一个卷积块的最开始, 将stride从2变成1, 为了弥补这种改变, 同时会将这一个卷积块里面的卷积层的 dilation 从1变成2.我们会将 deformable convolution 应用于最后的几层卷积层(kernel size &gt; 1). 通过实验我们发现, 对3层的卷积层应用 deformable convolution 可以很好的权衡不同的任务, 如表1所示. Segmentation and Detection Networks在上述特征提取网络的基础上, 我们可以将 deformable convolution 应用于特定的任务. 下面中的 $C$ 代表目标物体的类别数量 DeepLab: 实例分割任务的 sota 方法. 它在特征图上添加了一个 $1\times 1$ 的卷积层, 然后生成 $(C+1)$ 个表示每个像素分类 scores 的图谱. 然后, 后面的 Softmax 层会输出每个像素的概率. Category-Aware RPN: 和 Faster R-CNN 中的 RPN 差不多, 只不过用 $(C+1)$ 类别的分类卷积层替换掉了原始 RPN 中的二分类卷积层. Faster R-CNN: sota 的 two-stage 目标检测方法 R-FCN: 另一个 sota 目标检测方法. Understanding Deformable ConvNets该工作的思想是用额外的偏移量增加卷积和RoI池中的空间采样位置，并从目标任务中学习偏移量. 当可变性卷积叠加时, 复合变形产生的影响是很大的, 如图5所示, 在标准卷积中的感受野和采样点在顶层(深层)特征图谱上都是固定的, 但是在可形变卷积中, 它们会根据对象的尺度和形状进行自适应的调整. 更多的例子如图6所示. 表2提供了一些数值证明了Deformable ConvNets的有效性. 从中可以看出: Deformable filter的感受野大小是和物体大小相关的, 这说明卷积核的形变已经从图片中学到了很多的有效信息 背景区域的卷积核大小介于中等尺寸物体和大型物体之间, 这说明在识别背景区域时, 一个相对较大的感受野是有必要的. Deformable RoI pooling的有效性如图7所示, 标准的 RoI pooling 中 bins 的网格结构不再成立. 取而代之的是, 部分区域的 bins 会偏移原来的位置, 移动到附近的目标对象的前景区域, 这增强了网络的定位能力, 尤其是对非刚性物体来说. In Context of Related WorksSpatial Transform Networks(STN),Active Convolution,Effective Receptive Field,Atrous convolution,Deformable Parts Models(DPM),DeepID-Net,Spatial manipulation in RoI pooling.Transformation invariant features and their learning 实验Semantic Segmentation: 使用 PASCAL VOC 和 CityScapes 数据集. Object Detectin: 使用 PASCAL VOC 和 COCO 数据集. 默认的ResNet-101使用了 dilation为2, size为3×3的 atrous convolution. 我们还尝试了更多其它的可能参数, 如下表3所示. 表中数据说明: 当使用较大的dilatioin时, 所有任务的准确度都有所提升, 说明默认网络的感受野太小了(较大了dilation可以提供较大的感受野) 不同的任务和模型其最优的dilatioin参数不同, 但是deformable convolution总是能取得最高的准确度 对于具有RoI结构的网络来说, deformable RoI同样有效 如下表4所示, 可以看出, deformable结构对于目标检测任务同样有效: 表5贴出了deformable模型的复杂度和运行时间, 可以看到, 模型增加的参数量和运行时间都是在可接受范围内的]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Softer-NMS-Arvix 2018]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SofterNMS-Arxiv2018%2F</url>
    <content type="text"><![CDATA[作者: Yihui He, Xiangyu Zhang, Kris Kitani, Marios Savvides发表:机构: CMU &amp; Face++ 核心亮点提出了一种新的边框回归损失函数和NMS算法作者提出了一种 基于KL散度的边框回归损失函数, 可以同时学习到边框的形变量和位置变化量. 最终产生的位置变化量会与位置的精确度有很强的联系, 然后将其使用在本文提出的 新的NMS 算法上, 以此提高准确度. 论文细节摘要在目前的目标检测模型中, NMS是十分重要的一步处理步骤. 但是, 有时候, 较精确的候选框可能并没有很高的socre, 这时候使用NMS就会导致物体位置的预测精度降低. 在这篇文章中, 作者提出了一种 新的边框回归损失函数, 可以同时学习到边框的形变量和位置变化量. 最终产生的位置变化量会与位置的精确度有很强的联系, 然后将其使用在本文提出的 新的NMS 算法上, 以此提高准确度. 在MS-COCO数据集上, 将 VGG-16 Faster RCNN的 AP 从 23.6 提高到了 29.1, 将 ResNet-50 FPN Fast RCNN 的 AP 从 36.8 提高到了 37.8 . 介绍目前, 目标检测模型主要分为one-stage和two-stage两种, 本文主要关注two-stage模型. 本文主要关注候选区域框可能出现的以下两种问题: 第一, 当物体周围所有的dounding box都是不准确的, 如图1(a)所示. 第二, 较准确的box的score不高, 而不准确box的score较高, 如图1(b)所示. 上面两种问题都说明了box的位置和box的score不是强相关的. 收到这两种问题的启发, 本文提出使用 KL loss 来作为物体边框回归loss. 具体来说, 首先将bounding box的预测值和真实值分别建模成高斯分布和Dirac delta function(狄拉克 $\delta$ 函数). 然后, 训练模型, 以期降低来自于这两个分布的KL散度边框回归损失函数. 最后, 提出一个基于权重平均的soft NMS算法, 简言之就是当box具有较高的confidence事, 它就会得到较大的权重, 而不管它的分类score是多少. 利用KL Loss来训练边框回归模型 本文的检测模型的头部结构如图2所示. 我们的目的是估计边框的位置置信度, 具体来说, 我们的网络将会预测下面的高斯分布而不仅仅是边框回归: P_\theta (x) = \frac{1}{2\pi \sigma^2}e^{-\frac{(x-x_e)^2}{2\sigma^2}}上式中, $x_e$ 代表预测的边框的位置期望, $\sigma$ 代表标准差. 这些值将从Fast RCNN的头部(fc7)产生, 注意, fc7使用的是绝对值激活函数(而不是ReLU), 主要目的是尽量避免大量的 $\sigma$ 值为0., 当 $\sigma \rightarrow 0$ 时, 说明网络对当前预测的边框位置期望持有很大的置信度. 同样, 真实边框也可以写成高斯函数的形式, 实际上就是如下Dirac delta 函数: P_D(x) = \delta (x - x_g)其中, $x_g$ 是真实边框的位置.我们的目标时找到使得 $P_\theta (x)$ 和 $P_D(x)$ 之间KL散度最小的参数 $\hat\theta$, 即: \hat\theta = \arg\min_{\theta} D_{KL}(P_D(x) || P_{\theta}(x))综上, 本文的模型将使用KL散度作为边框回归损失函数 $L_{reg}$, 分类损失函数 $L_{cls}$ 维持不变(与其他模型一样) L_{reg} = D_{KL}(P_D(x) || P_{\theta}(x)) = ... = \frac{(x_g - x_e)^2}{2\sigma^2} + \frac{1}{2}log(\sigma^2) + \frac{1}{2}log(2\pi) + H(P_D(x))如图3所示, 当预测位置 $x_e$ 不准确时, 我们就希望方差 $\sigma^2$ 越小越好, 这样一来, 损失函数 $L_{reg}$ 就会变小. //TODO Softer-NMS在获取到预测位置的标准偏差以后, 通过平均权重将bounding boxes融合, 如下面的算法流程所示, 主要使用两行代码来修改原始的NMS算法. 首先, 使用标准的NMS或者soft NMS算法来候选框进行选择. 然后, 对于每一个box $M$, 我们计算它基于周围及自身box的权重均值的新的location. 举个例子, 对于第 $i$ 个box 的坐标 $x1$来说, 它的新坐标 $x1_i$ 计算如下: x1_i = \frac{\sum_j x1_j / \sigma^2_x1,j}{\sum_j 1/ \sigma^2_x1,j}, \text{subject to } IoU(x1_j, x1_i) > N_t当bounding box的iou大于一定阈值 $N_t$ 时, 就会被考虑加入到权重均值当追溯去. 在这里, 我们不需要设置分类score的阈值, 因为即使是较低的socre有时它的localization socre却较高. 图4展示了在应用softerNMS以后, 我们有时候可以避免文章开头提高的两种错误情况.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Non-local Neural Networks (CVPR, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-NonLocal-CVPR2018%2F</url>
    <content type="text"><![CDATA[文章: Non-local Neural Networks作者: Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He 核心亮点1) 提出了 non-local operations 来解决 CNN 网络中的 long-range dependencies 问题传统 CNN 的卷积操作由于输出神经元只会与输入图谱上的一部分区域有关系, 因此, 在面对那些 long-range dependencies 的时候, 往往不能捕获到足够的信息来表征数据, 为此, 作者提出了 non-locl operations, 其相当于构造了一个和特征图谱尺寸一样大的卷积核, 从而可以维持更多信息. 2) non-local module 可以作为一种通用的模块应用在各项任务上作者通过实验证明, non-local 的有效性不仅仅局限于某一类特殊任务(如视频分类), 同时还可以轻易的整合到其他现有模型中, 如将其整合到 MaskRCNN 中, 可以当做是一种 trick 来提供 MaskRCNN 在目标检测/分割, 姿态识别等任务上的性能表现. 论文细节摘要不论是卷积网络还是递归网络, 它们都是作用在某一块局部区域 (local neighborhood) 的operations. 在本文中, 我们提出了 non-local operations 作为一种通用的神经网络的 building blocks 来捕捉基于 long-range 的依赖关系. 受到经典的 non-local means 方法的启发, 本文的 non-local operation 会将某一位置的响应当做是一种从特征图谱所有位置的加权和来计算. 该 building block 可以插入到现在计算机视觉的许多模型当中, 进而可以提升分类, 检测, 分割等视觉任务的性能表现. 介绍在深度神经网络中, 捕获 long-range dependencies 信息是十分重要的, 如面向序列数据的 LSTM, 面向图像数据的更大的感受野等. 但是不论是 convolutional 还是 recurrent 操作, 它们都是在一个 local neighborhood 上进行计算的. 因此, 只能通过不断的重复执行才能够捕获到足够的 long-range dependencies 信息(卷积计算之间的重叠区域). 这种 Repeating local operations 具有很多缺点. 第一, 计算的低效性; 第二, 会造成很多优化时的困难; 最后, 会产生多次反射, 这使得很难在相距较远两个位置的点传递反向和前向的计算结果.(???, 这三个缺点具体什么意思?)在本篇文章中, 我们提出了一种用于捕获 long-range dependencies 信息的简单, 高效, 通用的神经网络构建模块, 称为 non-local. 本文的 non-local 是从经典的 non-local mean operation 泛化而来的. 直观来说, non-local operaions 会计算输入的特征图谱上所有点加权和的响应(如图1). 这些点既可以代表空间位置, 也可以代表时间, 时空等, 暗示着 non-local 可以应用于图片, 序列和视频相关任务. 使用 non-local operaions 具有以下几点优点: 相比于 CNN 和 RNN 的逐步计算的劣势, non-local 操作 可以直接从任意两点中获取到 long-range dependencies. 根据实验结果可知, non-local operations 是十分高效的, 并且即使在只有几层网络层时, 也能取得很好的效果. 最后, 本文的 nocal operaions 会维持输入变量的尺寸大小, 并且可以很容易的与现有的其他 operations 结合使用.我们用 video classification 任务来展示 non-local 的有效性. 在视频数据中, long-range interactions 不仅出现在 空间位置上的 distant pixels, 还会出现在时间维度上的 distant pixels. 通过一个单一的 non-local block (basic unit), 便可以捕获到这些 spacetime dependencies, 如果将多个 non-local block 组合起来形成 non-local neural networks, 便可以提高 video classification 任务的准确度(不加任何tricks). 另外, non-local 网络要比 3D 卷积网络的计算性价比更高. 为了说明 non-local 的一般性, 我们还在 COCO 数据集上进行了目标检测/分割, 姿态识别等任务的实验, 在基于 MaskRCNN 的网络基础上, 我们的 non-local blocks 可以用较少的计算开销进一步提升模型的精度. 相关工作Non-local image: Non-local means 是一种经典的过滤算法, 它会计算整幅图片的像素值的加权平均和, 使得一些较远元素可以贡献一些位置上的响应. FeedForward modeling for sequences: 近年来很多前馈网络被用于解决语音和自然语言处理, 它们通过更大的感受野来实现 long-range dependencies. Self-attention: 本文的工作和机器翻译中的 self-attention 机制有关. Interaction networks Video classification architectures Non-local Neural Networks下面首先给出 non-local operations 的一般性定义, 然后会给出几种特定的变体 Formulation根据 non-local mean operation, 我们可以在深度卷积网络中定义如下的一般化的 non-local operation: y_i = \frac{1}{\zeta (x)} \sum_{\forall j}f(x_i, x_j) g(x_j) \tag 1上式中, $i$ 代表了 output 的 position 响应, 而 $j$ 枚举了所有可能的 position. $x$ 是 input signal (一般为特征图谱), $y$ 是 output signal (与 $x$ 的 size 相同). $f$ 会返回一个标量, $g$ 也会返回一个标量, $\zeta (x)$ 的作用是对响应进行归一化. 该公式的 non-local 特性主要体现在考虑了所有可能的 position ($\forall j$), 而卷积网络只会考虑 output position 周围位置的像素点.non-local 是一个非常灵活的模块, 它可以被添加到深度神经网络的浅层网络当中去(不像fc那样处于深层网络), 这使得我们可以构建更加丰富的模型结构来结合 non-local 和 local 信息. Instantiations接下来, 我们举例说明几种常用的 $f$ 和 $g$. 有趣的是, 通过实验(表2a)发现, 本文的 non-local 模块对于 $f$ 和 $g$ 的选择并不是特别敏感, 这意味着 non-local 的通用性正是提升各个模型在不同任务上性能表现的主要原因.为了简化, 我们考虑将 $g$ 写成线性形式: $g(x_j) = W_g x_j$, 这里的矩阵 $W_g$ 正是模型需要学习的参数, 在实现时, 通常会通过 1×1(或 1×1×1) 的卷积 来实现. 接下来, 我们来讨论 $f$ 的选择 Gaussian: 最容易想到的选择 f(x_i, x_j) = e^{x_i^T x_j}在这里, $x_i^T x_j$ 是两个向量的点积, 则会返回一个标量, 有时候也可以使用欧几里得距离, 不过点积的实现更加容易. 归一化因子 $\zeta (x) = \sum_{\forall j} f(x_i, x_j)$ Embedded Gaussian: 这是高斯函数的一个简单扩展 f(x_i, x_j) = e^{\theta (x_i)^T} \phi(x_j)在上式中, $\theta (x_i) = W_{\theta} x_i$ , $\phi(x_j) = W_{\phi} x_j$ , 分别为两种 embeddings. 同时, 归一化因子 $\zeta(x) = \sum_{\forall j} f(x_i, x_j)$. Dot product: $f$ 也可以定义成点乘 f(x_i, x_j) = \theta(x_i)^T \phi(x_j)这里我们采用了 embedded 版本, 并且令归一化因子 $\zeta = N$, $N$ 是 $x$ 中 positions 的数量, 而不是 $f$ 的和. Concatenation: Concatenation 曾被用于 Relation Network 来解决 visual reasoning 问题, 形式如下 f(x_i, x_j) = ReLU(w^T_f[\theta (x_i), \phi (x_j)])上式中, $[\cdot, \cdot]$ 代表这 concatenation 操作, $w_f$ 代表着将 concatenated vector 映射到标量的权重向量, 同样, 令 $\zeta(x) = N$. Non-local Block我们将上面介绍的公式(1) (non-local operation)包装进一个 non-local block 中, 使其可以整合到许多现有的网络结构当中, 我们将 non-local 定义成如下格式: z_i = W_z y_i + x_i上式中, $y_i$ 即为公式(1)的返回结果, 而 $+x_i$ 代表着残差连接. 残差连接使得我们可以将一个全新的 non-local block 插入到任何预训练的模型中, 而不会坡缓其原始的行为(eg, $W_z$ 初始化为0). 一个关于 non-block 的实例如图2所示. 当将 non-local block 应用于一个 high-level 的特征图谱时, 其带来的计算成本是很低的, 如在图2中, 通常情况下, $T=4, H=W=14 or 7$. Implementation of Non-local Blocks: 我们将 $W_g, W_{\theta}, W_{\phi}$ 的 channels 设置为 $x$ channels 的一半. 另一个 subsampling 的 trick 是将公式(1)改为: $y_i = \frac{1}{\zeta (\hat x)} \sum_{\forall j} f(x_i, \hat x_j) g(\hat x_j)$, 其中 $\hat x$ 是 $x$ 的 subsampled 版本. 这个 trick 可以使计算量减少 1/4, 并且不会改变 non-local 的行为, 仅仅只会令计算变得更加稀疏. 通过在图2中的 $\phi$ 和 $g$ 之后加一层 max pooling layer 即可实现. Video Classification Models略 Experiments on Video Classification Extension: Experiments on COCOObject detection and instance segmentationn: 我们修改了 MaskRCNN 的 backbone, 在其 res4 的后面添加了一个 non-local block. 与原文不同是, 我们使用了端到端的联合训练(原文是将 RPN 和 RoIAlign等分开训练), 这使得我们的 baseline 提高了.表5显示了在 COCO 数据集上的 box 和 mask AP. 我们可以看到, 一个单独的 non-local block 可以提升所有 Res50/101 和 X152 的baseline. 另外, 下面的性能提升只需要付出很小的计算代价(不超过原模型的 5%), 我们同样尝试了使用更多的 non-local 模块, 但是发现这会降低模型的性能. 表6显示了 non-local 在姿态识别任务上的性能提升.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CoupleNet-Coupling Global Structure with Local Parts for Object Detection]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-CoupleNet-ICCV2017%2F</url>
    <content type="text"><![CDATA[核心亮点在进行区域分类时, 同时使用了全局信息,上下文信息和局部信息综合判断提出了一个新颖的全卷积网络, 并称之为CoupleNet, 它可以在目标检测中结合使用全局和局部信息. 具体来说, CoupleNet会将由RPN网络产生的候选区域送入到coupling module中, 该模块包含两个分支. 第一条分支利用position-sensitive RoI pooling来捕获物体的局部信息, 另一条分支利用RoI pooling对全局上下文信息进行编码. 接着, 我们设计了不同的coupling策略和归一化方法来使用这些不同分支格子的优势. 论文细节摘要尽管R-FCN在保证检测准确度的同时, 取得了更快的检测速度, 但是position-sensitive score maps的设计依然忽略了图中的整体结构的全局信息. 为了充分利用并结合局部和全局信息, 本文提出了一个新颖的全卷积网络, 并称之为CoupleNet, 它可以在目标检测中结合使用全局和局部信息. 具体来说, CoupleNet会将由RPN网络产生的候选区域送入到coupling module中, 该模块包含两个分支. 第一条分支利用position-sensitive RoI pooling来捕获物体的局部信息, 另一条分支利用RoI pooling对全局上下文信息进行编码. 接着, 我们设计了不同的coupling策略和归一化方法来使用这些不同分支格子的优势. 最终, 本文的模型达到了SOTA. 介绍典型的基于候选区域的检测算法如FasterRCNN使用了单独的网络来生成候选区域, 这使得检测速度很慢, 而R-FCN利用PSRoI pooling(position-sensitive RoI)对其进行了改进, 在保证精度的情况下获得了更快的检测速度. 但是, R-FCN网络依然没能利用到全局结构信息, 如图1所示, 当只利用局部信息时, 检测框内物体对沙发的预测概率只有0.08, 这显然是是不合理的, 而如果只利用全局信息, 也只能得到0.45的预测概率, 但是如果结合这两部分信息, 就能得到0.78的预测结果, 我们更乐意接受这个结果. 本文的主要贡献有以下三点: 本文提出了一个统一的全卷积网络, 可以联合地学习到目标检测任务中的局部信息, 全局信息和相关的上下文信息 本文设计了多个不同的归一化方法和coupling策略, 用以挖掘全局信息和局部信息之间的兼容性和互补性 本文的模型在三个主流数据集(VOC07,VOC12,COCO)取得了SOTA CoupleNet网络结构 CounpleNet的网络结构如图2所示, 主要包含两条不同的分支: 一个局部的part-sensitive全卷积网络, 用于学习特定物体的局部信息, 记为local FCN; 一个全局的region-sensitive全卷积网络, 用于对物体整体结构的全局信息和上下文信息进行编码, 记为global FCN.本文首先利用ResNet-101 (移除了最后的全局平均层和fc层)对图片进行卷积操作, 得到相应的特征图谱, 并利用RPN网络得到相应的候选区域, RPN网络与后续的CoupleNet共享特征图谱计算结果. 然后conv5上对应的候选区域会流向两个不同的分支: local FCN 和 global FC. 最后, 从 local FCN 和 gocal FCN 中得到的结果会被结合在一起, 作为最终的物体socre输出. Local FCN 为了在local FCN高效的捕获特定区域的信息, 本文通过利用通道数为 $k^2(C+1)$ 的 $1\times 1$ 的卷积层构建了一系列的 part=sensitive socre map, 其中 $k$ 代表我们将物体划分成 $k\times k$ 个局部部位(local parts), $C+1$ 代表类别. 因此, 对于任意一个类别, 都会有 $k^2$ 个通道, 并且每一个通道会负责物体的一个特定局部部位. 最终的类别score将由这 $k^2$ 个结果投票产生. 这里, 我们使用了 R-FCN 的 position-sentitive RoI pooling 层来提取物体的特定部位, 并且是三简单的平均池化来进行投票. 如此一来, 我们就会得到一个 $C+1$ 维度的向量, 代表着当前候选区域属于每一类的概率. 这个过程相当于是把一个对物体类别的强分类器转换成了许多弱分类器, 如此便可以起到ensemble part models的作用, 使得分类更加准确. 如图3(a)所示, 对于一个被裁剪的人像来说, 神经网络对人的全局信息无法很高的响应, 但是如果仅从局部特征角度出发, 如人的鼻子, 眼睛等, local FCN可以十分高效的捕获到这些特定区域的特征. 因此, 我们认为 local FCN 更加关注物体的内部结构和组成要素等信息, 这些信息可以高效的反映出物体的局部属性, 特别是当物体被遮挡或者整体边界不完整的情况. 但是, 对于那些具有简单空间结构以及那些包括了相当多背景区域的物体来说(如, 餐桌), 单单只靠 local FCN 很难做出鲁棒性较高的预测结构. 因此有必要加入全局结构信息来增强网络的分辨能力. Global FCN对于 global FCN, 本文通过使用整体的区域级别的特征来描述物体的全局信息. 首先, 我们将一个 1024 维度的 $1\times 1$ 卷积层接在ResNet101的最后一个残差模块之后, 用于降低维度. 由于候选区域的尺寸不唯一, 因此, 本文会插入一个 RoI pooling 层来提取固定长度的特征向量作为物体的全局结构信息. 第二, 本文使用了两个卷积层(分别为 $k\times k$ 和 $1\times 1$)来更进一步的抽象物体的全局信息. 最后, $1\times 1$ 的卷积结果会被送入分类器, 分类器的输出也是一个 $C+1$ 维度的向量(与local FCN一样). 此外, 上下文信息是视觉识别任务中最基本,最重要的元素之一. 例如, 船通常是在水里的, 而不太可能是在空中的. 尽管, 在深层网络中, 较深的网络的特征图谱具有更大的感受野, 可以相对获得更多的空间上下文信息, 但是实际中深层特征图谱所包含的上下文信息要理理论上少很多. 因此, 很有必要显式的去收集物体的周围信息, 以减少错分类的可能性. 为了增强 global FCN 的特征表达能力, 本文将上下文信息引入到网络中作为一种有效的附加信息. 具体来说, 本文将物体的RoI区域扩大为原来的2倍. 然后将这两种RoI(原始的和扩大后的)通过RoIpooling后再连接在一起(concatenated), 接着送入之后的子网络.(如图2后下部分所示, 实际上, global分支可以看做是一种特殊的FasterRCNN). 由于RoI pooling操作, global FCN可以将物体区域作为物体的整体特征进行描述, 因此, 它可以轻松的处理那些完整的物体, 如图3(b)所示. Coupling structure为了让global FCN 和 local FCN 返回的结果在数量级上匹配, 本文对它们的输出使用了归一化操作. 主要利用了两种方案来进行归一化: L2归一化层或者 $1 \times 1$ 卷积层. 同时, 如何将local和global输出结合起来也是一个关键问题. 在本文中, 我们探究了三种不同的coupling方法: 对应位相加(element-wise sum), 对应位相乘(element-wise product), 以及对应位取最大(element-wise maximum). 实验结果表明, 使用 $1\times 1$ 卷积配合对应位相加可以取得最好的实验效果. 实验使用L2归一化效果很差(甚至比不使用归一化的结果还要差), 推测原因可能是L2归一化以后会使得score之间的gap变小, 进而造成错分类. 而使用 $1\times 1$ 卷积进行归一化时, 网络会自动学习并调节local和global归一化以后的尺寸大小. 对于coupling策略的选择, 对应位相加是一种很有效的连接方式, 在ResNet也使用了这种连接, 而对应位相乘有时候会造成梯度的不稳定, 从而导致训练难以收敛. 对应位取最大则会丢失掉更多的信息, 同时也就丢失了结合局部和全局信息的优势. 正如我们之前讨论的那样, CoupleNet在面对遮挡, 截断以及包括大量背景的目标时(如沙发,人,桌子,椅子等等), 可以表现出很强的识别能力.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 算法题全解]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-%E9%A2%98%E7%9B%AE%E5%85%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[001. Two SumDescription: 求出能组合出目标数的两个元素Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 解法一: 穷举时间复杂度: $O(n^2)$空间复杂度: $O(1)$ 12345678910111213class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; for(int i = 0; i&lt;nums.size(); i++)&#123; for(int j = i+1; j&lt;nums.size(); j++)&#123; if(nums[i] + nums[j] == target)&#123; vector&lt;int&gt; res =&#123;i,j&#125;; return res; &#125; &#125; &#125; &#125;&#125;; 解法二 : 哈希表, 两次遍历注意, 题目中说数组的解恰好只有一个, 这是一种很强的假设, 解法二在面对有多个解时, 也只会输出一个这里要特别注意: 同一个元素不能使用两次, 但是数组中的元素是可以重复的, 重复的元素看作是两个元素. hash表中最终存储的将会是重复元素的最后一个下标, 因此, 在进行比较时, 使用 i!= nums_map[target-nums[i]] 来判断它们是否为同一个元素, 而不能使用nums_map[nums[i]] != nums_map[target-nums[i]] 时间复杂度: $O(n)$ 遍历两次空间复杂度: $O(n)$ 123456789101112131415class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; nums_map; for(int i = 0 ;i&lt;nums.size(); i++)&#123; nums_map.insert(&#123;nums[i], i&#125;); &#125; for(int i = 0 ; i&lt;nums.size(); i++)&#123; if(nums_map.count(target-nums[i]) == 1 &amp;&amp; i!= nums_map[target-nums[i]])&#123; vector&lt;int&gt; res = &#123;i, nums_map[target-nums[i]]&#125;; //这里一定要用i,而不能用nums_map[nums[i]] , 上面也同理 return res; &#125; &#125; &#125;&#125;; 解法三: 哈希表 一次遍历事实上, 可以将hash表的插入和查找对应元素的操作放在 一个循环里, 这样就只需要进行一次遍历 时间复杂度: $O(n)$ 遍历一次空间复杂度: $O(n)$ 12345678910111213class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; nums_map; for(int i = 0 ;i&lt;nums.size(); i++)&#123; if(nums_map.count(target-nums[i]) == 1 &amp;&amp; i!= nums_map[target-nums[i]])&#123; vector&lt;int&gt; res = &#123;i, nums_map[target-nums[i]]&#125;; return res; &#125; nums_map.insert(&#123;nums[i], i&#125;); &#125; &#125;&#125;; 扩展问题How would you approach the problem if the input array is very large (but limited range) and cannot fit in the memory ? This is a follow-up question for this problem. 002. Add Two NumbersDescription: 链表数之和You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example: Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 解法一: 顺序相加, 注意进位从链表的第一个节点开始, 将两个节点的值和进位位想加, 如果大于10, 则当前结果节点的值对10取余, 同时将进位位置1, 如果小于10, 则直接赋值给当前结果节点, 同时将进位位置0. 特别注意 l1 和 l2 的长度问题, 当二者节点遇到 nullptr 时, 将较长的剩余部分重新赋给l1, 并继续判断 最后, 需要注意是否有进位位, 如果有, 则要申请一个新节点, 并将其置为1 时间复杂度: $O(\max(m,n))$空间复杂度: $O(1)$ (这种做法会破坏原有链的结构) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; int carry = 0; ListNode* head = new ListNode(0); //创建指向最终结果的头指针 if(l1!=nullptr) head-&gt;next = l1; // 虽然题目指明为非空链表, 但是最好还是做一下判断 else head-&gt;next = l2; ListNode* pre=head; // pre用于保存l1的上一个指针 while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; l1-&gt;val = l1-&gt;val + l2-&gt;val + carry; if(l1-&gt;val &gt; 9)&#123; l1-&gt;val %= 10; carry = 1; &#125;else&#123; carry = 0; &#125; pre = l1; l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; if(l2!=nullptr)&#123; // 此时说明l2比l1长, 用l1的上一个指针指向当前l2剩余的部分, l1 = pre; l1-&gt;next = l2; l1 = l1-&gt;next; &#125; while(l1!=nullptr)&#123; // 此时l1为剩余(l1或l2) 的部分, 只需要考虑是否有进位即可 l1-&gt;val = l1-&gt;val + carry; if(l1-&gt;val &gt; 9)&#123; l1-&gt;val %= 10; carry = 1; &#125;else&#123; carry = 0; // 如果没有进位, 一定要将此处置0, 否则会引起错误 break; &#125; pre = l1; l1 = l1-&gt;next; &#125; if(carry == 1)&#123; // 对应 999 + 001 的特殊情况, 此时进位会不断传递, 最终数字位数加1, 最高位为1 ListNode* newnode = new ListNode(1); l1 = pre; l1-&gt;next = newnode; &#125; return head-&gt;next; &#125;&#125;; 解法二: 顺序相加, 维持原链表时间复杂度: $O(\max(m,n))$空间复杂度: $O(\max(m,n))$ (这种做法需要额外申请空间, 但不会破坏原有链的结构) 该解法思路与解法一一致, 只不过每次都申请一个新的节点, 确保不会改变原有链表的结构. 1234567891011121314151617181920212223242526class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode *dummy = new ListNode(0); ListNode *pre = dummy; int carry = 0; while(l1!=nullptr || l2!=nullptr)&#123; ListNode *cur = new ListNode(0); int a = l1==nullptr ? 0 : l1-&gt;val; int b = l2==nullptr ? 0 : l2-&gt;val; cur-&gt;val = a + b + carry; carry = cur-&gt;val / 10; cur-&gt;val = cur-&gt;val % 10; pre-&gt;next = cur; pre = cur; if(l1!=nullptr) l1 = l1-&gt;next; if(l2!=nullptr) l2 = l2-&gt;next; &#125; if(carry &gt; 0)&#123; pre-&gt;next = new ListNode(carry); &#125; return dummy-&gt;next; &#125;&#125;; 扩展问题What if the the digits in the linked list are stored in non-reversed order? For example: $(3 \to 4 \to 2) + (4 \to 6 \to 5) = 8 \to 0 \to 7 (3→4→2)+(4→6→5)=8→0→7$ 思路: 先将链表转置 , 再用上面的方法求解 转置时间复杂度: $O(n)$转置空间复杂度: $O(1)$ 003. Longest Substring Without Repeating CharactersDescription: 寻找无重复字符的最长子串Given a string, find the length of the longest substring without repeating characters. Example 1:123Input: &quot;abcabcbb&quot;Output: 3Explanation: The answer is &quot;abc&quot;, with the length of 3. Example 2:123Input: &quot;bbbbb&quot;Output: 1Explanation: The answer is &quot;b&quot;, with the length of 1. Example 3:123Input: &quot;pwwkew&quot;Output: 3Explanation: The answer is &quot;wke&quot;, with the length of 3. Note that the answer must be a substring, “pwke” is a subsequence and not a substring. 解法一:暴力时间复杂度: $O(n^3)$ 对于每一个字符, 子串的添加以及查重过程时间复杂度为 $O(n^2)$ , 总共n个字符, 所以为 $O(n^3)$空间复杂度: $O(min(n,m))$ 需要将当前子串存在起来以便查询是否相等, n为字符串length, m为字符集size 解法二: 前后两个指示变量时间复杂度: $O(2n) = O(n)$空间复杂度: $O(min(n,m))$ 思路: 首先构造一个哈希表, 用来存储当前子串中出现的字符, 这样, 新来的字符可以直接查询哈希表来判断字符是否存在, 构建哈希表空间复杂度为 O(min(n,m)) ( $m$ 为字符集合的大小,一般为26(字母), 128(ASCII), 256(ASCII), $n$ 为字符串的长度) 然后, 使用两个指示变量, 分别指向当前未重复子串的首字符, 和超尾字符, 进行如下几个判断: 如果超尾字符与当前子串中的字符不重复, 那么将超尾字符加入到当前子串中,并将length加1 如果超尾字符与当前子串中的字符重复, 利用哈希表查的重复字符的所在位置, 将当前子串的首字符直接跳向该重复字符的下一个位置( 这样可以保证只遍历一遍 ), 并将包括重复字符在内的之前所有字符都从哈希表中删除(之前的字符不再可能组成更长的子串了), 同时将超尾字符加入, length赋予新值: 超尾位置-重复位置-1; 判断首字符与超尾字符是否相等, 如果相等, 将超尾字符加1, 并将length置为1 看当前length是否比maxlength大, 并重复以上过程,直到超尾字符超出size 12345678910111213141516171819class Solution &#123;public: int lengthOfLongestSubstring(string s)&#123; int hash[256]=&#123;0&#125;; int max_len = 0; for(int l=0, r=0; r&lt;s.size(); )&#123; if(hash[s[r]] == 0)&#123; hash[s[r]] = 1; max_len = std::max(max_len, r-l+1); r++; &#125;else&#123; hash[s[l]] = 0; l++; &#125; &#125; return max_len; &#125;&#125;; 解法三: 只需一次遍历时间复杂度: $O(n)$, 只需一次遍历空间复杂度: $O(min(m,n)$, 与解法二相同 当我们在 [i,j) 之间发现了一个重复的下标为 j&#39; 的字符时, 我们不用一点点的增加 i 的值, 而是可以直接将 i 的值跳到 j&#39;+1 处. 故, 我们可以只利用一次遍历就找到最长的不重复子串. 123456789101112131415161718class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; unordered_map&lt;char, int&gt; s_hash; int max_length = 0; for(int i = 0 ,j=0 ; j&lt; s.size() ; j++)&#123; if(s_hash.count(s[j]))&#123; // 这里未删除 i 之前的, 所以即使这里的哈希可以查到, 也不一定就是重复. i = max(i,s_hash[s[j]]+1); //如果遇到重复的, 就将当前的i指向重复的下一个 // (这里用max的原因是, 没有删除当前i到重复字符之间的其他字符, 这些字符 // 后续还可能被检测到, 所以这里只取max的, 也就是i不会倒退) //s_hash.erase(s[j]); // 该语句是多余的 &#125; s_hash[s[j]] = j; max_length = max_length &gt; (j-i+1) ? max_length : (j-i+1); &#125; return max_length; &#125;&#125;; 用数组做哈希表:12345678910111213141516class Solution &#123;public: int lengthOfLongestSubstring(string s)&#123; int hash[256];// 哈希表中存在的值代表下标 for(auto &amp;item : hash) item = -1; // 赋初值 int max_len = 0; for(int i=0, j=0; j &lt; s.size(); j++)&#123; if(hash[s[j]] != -1)&#123; // 当哈希表中值不为-1时, 说明存在重复 i = std::max(hash[s[j]] + 1, i); // 注意这里必须保证 i 不会倒退, 因此要使用 max &#125; max_len = std::max(max_len, j-i+1); hash[s[j]] = j; &#125; return max_len; &#125;&#125;; 哈希表, 键为字符, 值为字符在字符串中的位置, 如果键不为空, 说明之前出现过重复字符, 此时, 令起始下标i更新, 注意, 如果, i大于之前键的值, 说明已经包在外面了, i 则不变, 核心思路就是 i 不会回退. 时间复杂度 $O(n)$, 空间复杂度 $O(n)$ 1234567891011class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: h_dict = &#123;&#125; max_len = 0 i = 0 for j, c in enumerate(s): if c in h_dict: i = max(i, h_dict[c] + 1) max_len = max(max_len, j - i + 1) h_dict[c] = j return max_len 004. Median of Two Sorted ArraysDescription: 寻找两个有序数组的中位数There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1:1234nums1 = [1, 3]nums2 = [2]The median is 2.0 Example 2:1234nums1 = [1, 2]nums2 = [3, 4]The median is (2 + 3)/2 = 2.5 解法一: 根据中位数的特性题目要求需要时间复杂度为 $O(log (m+n))$.空间复杂度: $O(1)$, 未使用额外空间 首先我们思考中位数的作用: 中位数可以将一个数组分成两个长度相同的部分, 并且一部分中的数字总比另一部分中的小. 那么对于两个数组的情况, 我们需要做的就是找到一个数字, 可以使这两个数组分别分成两部分, 这两部分长度相等(当个数为奇数时, 前一部分多一个元素), 同时前一部分的元素小于等于后一部分的元素. 首先,我们将数组 A 分成两部分, 由于 A 有 m 个数字, 所以它可以有 m 种不同的分法, 我们以下标 i 对应的数字为界限, 将A分成两部分, 前一部分的长度为 i (从0到 i-1 ), 后一部分的长度为 m-i (从 i 到 m-1): A[1,2,...,i-1] | A[i, i+1, ..., m-1]. 同理,数组 B 也可以做如下分割: B[1,2,...,j-1] | B[j, j+1, ..., n-1]. 这里需要注意一个细节, 我们需要确保 A[i] 这个数字可以将两个数组等长的分割, 那么 A 数组的长度 必须小于等于 B 数组的长度. 因为如果 A 数组的长度大于 B 数组的长度, 那么就会出现一种情况: A[i] 前的数字个数已经大于两数组总个数的一半, 此时无论如何也做不到等长分割, 因此, 我们需要先对数组长度判断, 令 A 数组代表的是较短的数组, 利用 swap() 方法可以在 $O(1)$ 时间复杂度内完成. 当两个数组 A 和 B 都被分到了两部分以后, 将它们合起来, 第一部分的数字为 A[1,2,...,i-1] 和 B[1,2,...,j-1], 第二部分的数字为 A[i, i+1, ..., m-1] 和 B[j, j+1, ..., n-1], 我们并不关系两部分内部的顺序, 我们只关心一件事, 那就是: 第一部分和第二部分的长度相等, 并且第一部分的数字都比第二部分小, 于是, i 和 j和取值就必须满足下列关系: i+j = m-i + n-j 或 m-i + n-j + 1 (加1的原因是因为有可能数组总长为奇数, 我们令前一部分比后一部分多1个元素) i=0 或 A[i-1] &lt;= B[j] (前者说明 A 中元素全部被分配到后半段, 即前半段元素均由 B 中元素组成) i=m 或 B[j-1] &lt;= A[i] (前者说明 A 中元素全部在前半段, 即后半段元素均由 B 中元素组成) 由于上式 i+j = m-i + n-j 或 m-i + n-j + 1 , 因此有 j = (m+n+1)/2 - i ; (向下取整). 故而可以只对 i 进行判断 i 是否越界, 只要 i 满足条件, j就不会等于0或n(前提条件是 A 数组长度小于等于 B 数组长度) 根据上面的分析, 解题过程如下: 根据两数组的长度, 将短的一方设为A数组 (j要对应较长的那个数组, 否则的话j有可能小于0 ), 令start=0, end=A.size 令 i=(start+end)/2 计算j = (m+n+1)/2 - i 判断当前 i 和 j 是否满足条件,有三种情况(对这三种情况不断重复, 直到i,j位置刚刚好): i &gt; 0 并且 A[i-1] &gt; B[j], 说明 i 的位置过大, 令 end = i-1. i &lt; m 并且 B[j-1] &gt; A[i], 说明 i 的位置过小, 令 start = i+1; 其他情况(i==0 或 A[i-1] &lt;= B[j] 并且 i==m 或 B[j-1] &lt;= A[i]), 说明 i 和 j的位置刚刚好. 当i,j位置刚好时, 根据数组整体长度的奇偶, 返回正确的中位数: 奇数: 返回前半段的最大元素 偶数: 返回前半段最大元素和后半段最小元素的平均值 非递归写法123456789101112131415161718192021222324252627282930313233class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &gt; nums2.size()) nums1.swap(nums2); int m = nums1.size(); int n = nums2.size(); int start = 0, end=m; while(start&lt;=end)&#123; //当 start = end 时, 此时 i=start=end, 不能忽略 int i = (start+end) / 2; int j = (n+m+1)/2 - i; if(i&gt;0 &amp;&amp; nums1[i-1] &gt; nums2[j]) //注意, i=0时说明位置恰好 end = i-1; //i太大 else if(i&lt;end &amp;&amp; nums2[j-1] &gt; nums1[i]) start = i+1; // i太小 else&#123; int leftmax;// 取左边最大的 if(i==0) leftmax=nums2[j-1]; else if(j==0) leftmax=nums1[i-1]; else leftmax = max(nums1[i-1], nums2[j-1]) ; if( (n+m)%2 == 1) return leftmax; int rightmin; // 取右边最小的 if(i==m) rightmin = nums2[j]; else if(j==n) rightmin = nums1[i]; else rightmin = min(nums1[i] ,nums2[j]); return (leftmax+rightmin) / 2.0; &#125; &#125; // return 0.0; //因为, 两数组不会同时为空, 所以这句话主要用于调试 &#125;&#125;; 递归写法写法一:123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &lt;= nums2.size()) return helper(nums1, 0 , nums1.size(),nums2); else return helper(nums2, 0 , nums2.size(),nums1); &#125; double helper(vector&lt;int&gt;&amp; nums1, int start1, int end1, vector&lt;int&gt;&amp; nums2)&#123; int i = (start1+end1)/2; int j = (nums1.size()+nums2.size()+1)/2 - i; // if(start1 &gt; end1) return 0.0; 因为数组一定是有效的, 因此不会出现这种情况 if( (i==0 || nums1[i-1]&lt;=nums2[j]) &amp;&amp; (i==nums1.size() || nums2[j-1]&lt;=nums1[i]))&#123; // 如果找到i int res11, res12; int res21, res22; // 首先将左边部分的两个数组分别赋值, 如果i或j为0, 说明对应数组在左边 //只有0个元素 , 将其赋值为INT_MIN(因为要取max(res11, res21)) if(i==0) res11= INT_MIN; else res11=nums1[i-1]; if(j==0) res21= INT_MIN; else res21=nums2[j-1]; //同理, 对右边进行处理, 取min(res12, res22) if(i==nums1.size()) res12= INT_MAX; else res12=nums1[i]; if(j==nums2.size()) res22= INT_MAX; else res22=nums2[j]; // 根据数组奇偶个数返回结果 if((nums1.size() + nums2.size())%2 == 1 )&#123; return max(res11, res21); &#125; else&#123; return ( max(res11,res21)+min(res12,res22) ) / 2.0; &#125; &#125;else if(nums1[i-1] &gt; nums2[j])&#123; return helper(nums1, start1, i-1, nums2); &#125;else&#123; return helper(nums1, i+1, end1, nums2); &#125; &#125;&#125;; 写法二: 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &gt; nums2.size()) return helper(nums2, nums1, 0, nums2.size()); else return helper(nums1, nums2, 0, nums1.size()); &#125; double helper(vector&lt;int&gt; &amp;nums1, vector&lt;int&gt; &amp;nums2, int start, int end)&#123; //if (start&gt;end) return 0.0; 因为数组一定是有效的, 因此不会出现这种情况 int m = nums1.size(); int n = nums2.size(); int i = (start+end)/2; int j = (m+n+1)/2 - i; if(i&gt;0 &amp;&amp; nums1[i-1] &gt; nums2[j]) return helper(nums1, nums2, start, i-1); else if(i&lt;m &amp;&amp; nums2[j-1] &gt; nums1[i]) return helper(nums1, nums2, i+1, end); else&#123; int leftmax; if(i==0) leftmax = nums2[j-1]; else if(j==0) leftmax = nums1[i-1]; else leftmax = max(nums1[i-1], nums2[j-1]); if((m+n)&amp;1 == 1) return leftmax; int rightmin; if(i==m) rightmin = nums2[j]; else if(j==n) rightmin = nums1[i]; else rightmin = min(nums1[i], nums2[j]); return (leftmax+rightmin)/2.0; &#125; &#125;&#125;; 005. 最长回文子串Description: 最长回文子串Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. Example 1: Input: “babad”Output: “bab”Note: “aba” is also a valid answer.Example 2: Input: “cbbd”Output: “bb” 解法一：最长公共子串时间复杂度: $O(n^2)$空间复杂度: $O(n)$ 先将字符串 s 利用 reverse 逆置成 s&#39;, 然后查找 s 和 s&#39; 的最长公共子串, 即为最长的回文子串. 解法二： 穷举时间复杂度: $O(n^3)$空间复杂度: $O(1)$ 对于字符串中的每一个字符, 共有 $\frac{n(n-1)}{2}$ 种包含该字符的子串, 所以如果对所有可能的子串判断, 需要 $O(n^3)$ 的时间复杂度 解法三： 动态规划时间复杂度: $O(n^2)$空间复杂度: $O(n^2)$ 我们令 DP 数组为一个 $n\times n$ 的矩阵, $dp(i,j)$ 代表从 s[i] 开始, 到 s[j] 结束的子串是否为回文串, 如果是, 则为 true. 那么, $dp(i,j)$ 为真的条件就是必须满足 $dp(i+1, j-1)=true$ 并且 $s[i]=s[j]$. dp 数组的初始值为: $dp(i,i)=true$, $dp(i,i+1)= s[i]==s[i+1]$. 由于需要遍历 dp 矩阵中每一个位置的值, 因此时间复杂度为 $O(n^2)$, 空间复杂度很明显为 $O(n^2)$. 解法三： 扩展中心法时间复杂度: $O(n^2)$空间复杂度: $O(1)$ 或者 $O(n)$ 以每一个字符为中心, 向两边扩展, 将当前能够扩展的长度 len 和最大扩展长度 max_len 作比较, 记录较大者, 同时记录较大者的所对应的中心字符的下标 max_index. 最后, 根据最大扩展的长度max_len 和中心字符的下标 max_index 计算最大回文子串的开始位置和总长度 此处注意, 回文子串有奇偶两种情况, 可采用以下举措之一解决: 分别检查奇数和偶数的情况, 这样多检查一次(虽然多检查一次, 但和下面的检查总次数差不多, 因为下面虽然只检查一次, 但次数较多) 向字符内插入特殊符号 ‘#’, 这样不管偶数奇数, 都可以当做奇数处理, 缺点是占用了额外的 $O(n)$ 空间. 注意: 既然已经使用了空间复杂度为 $O(n)$ 的方法, 实际上更应该将其该写成马拉车算法 12345678910111213141516171819202122232425262728293031// 空间复杂度 $O(1)$class Solution &#123;public: string longestPalindrome(string s) &#123; int max_len = 0; int start = 0; for(int i=0; i &lt; s.size(); i++)&#123; int len1=0,len2=0; int left=i, right = i; //通过left和right , 是的对奇偶的分别处理更方便 while( left &gt;=0 &amp;&amp; right&lt;s.size() &amp;&amp; s[left] == s[right])&#123; left--; right++; &#125; len1 = right-left-1; // 注意, 这里一定是-1, 而不是+1 left=i; right=i+1; while( left&gt;=0 &amp;&amp; right&lt;s.size() &amp;&amp; s[left] == s[right])&#123; left--; right++; &#125; len2 = right-left-1; int len = max(len1, len2); if(len&gt;max_len)&#123; max_len = len; start = i- (len-1)/2; &#125; &#125; return s.substr(start, max_len); &#125;&#125;; 另一种写法: 1234567891011121314151617181920212223242526272829303132333435363738// 空间复杂度 $O(1)$class Solution &#123;public: string longestPalindrome(string s) &#123; int max_i = 0; int max_len = 0; for(int i = 0; i&lt;s.size(); i++)&#123; int left, right; left = i, right = i; while(s[left] == s[right])&#123; // 奇数情况 left--; right++; if(left &lt; 0 || right == s.size())&#123; break; &#125; &#125; if(max_len &lt; right-left-1)&#123; max_len = right-left-1; max_i = i; &#125; left = i, right = i+1; // 下面要对 right 判断, 防止越界 while(right !=s.size() &amp;&amp; s[left] == s[right])&#123;// 偶数 left--; right++; if(left &lt; 0 || right == s.size())&#123; break; &#125; &#125; if(max_len &lt; right-left-1)&#123; max_len = right-left-1; max_i = i+1;//偶数时令max_i指向偏右的下标 &#125; &#125; return s.substr(max_i-max_len/2, max_len); &#125;&#125;; 1234567891011121314151617181920212223242526272829303132// 空间复杂度 $O(n)$class Solution &#123;public: string longestPalindrome(string s) &#123; char* cs = new char[s.size() * 2+1]; cs[0]='#'; for(int i=0; i&lt;s.size() ; i++)&#123; //插入 '#' cs[i*2+1] = s[i]; cs[i*2+2] = '#'; &#125; int max_len=0; int max_index = 0; for(int i =0; i&lt;s.size()*2+1 ; i++)&#123; int len=0; //记录当前扩展长度len for(int j=1; i-j&gt;=0 &amp;&amp; i+j&lt;s.size()*2+1 ;j++)&#123; if(cs[i-j] == cs[i+j])&#123; //两边字符若相等, 则len长度增1 len++; &#125;else break; &#125; if(len &gt; max_len)&#123; max_len = len; max_index = i; &#125; &#125; int start = (max_index - max_len)/2; //根据maxlen和index 计算回文子串开始坐标 int len = max_len; delete cs; return s.substr(start, len); &#125;&#125;; 解法五: 马拉车(Manacher) 算法时间复杂度: $O(n)$空间复杂度: $O(n)$ There is even an O(n), O(n) algorithm called Manacher’s algorithm, explained here in detail. However, it is a non-trivial algorithm, and no one expects you to come up with this algorithm in a 45 minutes coding session. But, please go ahead and understand it, I promise it will be a lot of fun. 马拉车算法的核心思想还是从中心扩展发出发, 不过他必须使用 ‘#’ 字符先对原始字符串插入, 如下所示: 接下来, 在每一次 for 循环当中, 都需要保存这么几个值(命名是个人习惯, 可以用其他名字代替): P: P 为最大右边界下标值, 对应的是所有已检测的回文子串中, 右边界下标最大的那个 P_center: 该值是P对应的回文子串的中心下标 max_len: 对应当前最大回文子串的半径(aba的半径为1, a的半径为0) max_index: 对应当前最大回文子串的中心下标 然后, 还需要构建一个和插入’#’后的字符串长度相关的数组 p_len, 里面存放着对应位置的回文串半径, 用以后续的计算, 这一步是关键, 有了这个数组 ,才能实现利用之前计算结果 接下来, 遍历 “新字符串”(即插入’#’之后的字符串) 的每一个字符, 设当前下标为 i, 则有如下情况, 分别处理: P&gt;i, 说明 i 在 P 的范围内, 可以利用前面的计算结果 P&lt;=i, 说明 i 不在 P 的范围内, 无法利用前面的计算结果, 只能逐个判断 对上面两种情况具体分析如下: 第一种情况: P&gt;i 找到i相对于 P_center 的对称位置, 设为j, 那么如果Len[j]&lt;P-i, 如下图所示: 则以i为中心的回文串的长度至少和以j为中心的回文串一样 , 即Len [i]&gt;=Len[j] , 因此可以直接从Len[j]+1开始判断回文 如果Len[j]&gt;=P-i, 如下图所示: 由对称性, 说明以i为中心的回文串可能会延伸到P之外, 而大于P的部分我们还没有进行匹配, 所以要从P+1位置开始一个一个进行匹配, 直到发生失配 第二种情况: P&lt;=i 如果i比P还要大, 说明对于中点为i的回文串还一点都没有匹配, 这个时候, 就只能老老实实地一个一个匹配了 在这一次循环完成之前, 更新上面提及的四个变量 循环结束后, 根据 max_index 和 max_len 的值返回最长回文子串 时间复杂度分析: 对于每一个字符, 由于如果直接比较过, 那么就可以利用之前比较的结果直接判断, 所以每个字符都只进行了一次比较, 故而时间复杂度为 $O(n)$ C++ 实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123;public: string longestPalindrome(string s) &#123; int cs_size = s.size()*2+1; char* cs = new char[cs_size]; cs[0] = '#'; for(int i = 0;i&lt;s.size(); i++)&#123; cs[i*2 + 1] = s[i]; cs[i*2 + 2] = '#'; &#125; int P = 0; int P_center = 0; int max_index = 0; int max_len = 0; int* p_len = new int[cs_size]; for(int i =0; i&lt;cs_size; i ++)&#123; if( i &lt; P)&#123; // 如果i&lt;P, 说明可以复用前面的计算结果 int j = P_center*2 - i; // j对i关于P_center的对称点 if(P-i &gt; p_len[j])&#123; // 如果i与P之间的距离比 j 的回文串长度还大, //说明可以直接从p_len[j] + 1开始比较, 之前的子串一定是回文串 int k = p_len[j] + 1; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125;else&#123; // 如果距离没有p_len[j] + 1大, 则从超出P的部分开始比较 int k = P - i; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125; &#125;else&#123; //如果i不在P范围内, 则必须从1开始逐个比较, 无法利用之前的计算结果 int k = 1; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125; if(p_len[i] &gt; max_len)&#123; max_len = p_len[i]; max_index = i; &#125; if(i+p_len[i] &gt; P)&#123; P = i+p_len[i]; P_center = i; &#125; &#125; delete cs; delete p_len; int start = (max_index - max_len)/2; int len = max_len; return s.substr(start, len); &#125;&#125;; Python 实现解法一: 扩展中心法, 需要额外注意奇数和偶数的情况, 可以通过插入字符将所有的回文串变成奇数情况, 时间复杂度 $O(n^2)$, 空间复杂度 $O(1)$ 或 $O(n)$, 取决于是否插入字符 解法二: Manacher, 基于扩展中心法, 在符合条件的情况下, 可以利用之前的结果来加速判断流程, 时间复杂度接近于 $O(n)$, 空间复杂度 $O(n)$. 1234567891011121314151617181920212223242526272829# Manacher 算法实现(python)class Solution: def longestPalindrome(self, s: str) -&gt; str: T = '#'.join('$&#123;&#125;^'.format(s)) palin_len = [0] * len(T) max_P = 0 max_center = 0 max_len = 0 for i in range(1, len(T) - 1): if i &lt; max_P: # 当 i 处于最长回文的范围内, 则可利用之前的信息 j = max_center - (i-max_center) p_len = min(palin_len[j], max_P - i) l = i - p_len - 1 r = i + p_len + 1 else: # 否则, 只能老老实实逐个匹配 l = i - 1 r = i + 1 while (l &gt;= 0 and r &lt; len(T) and T[l] == T[r]): l -= 1 r += 1 palin_len[i] = r - i - 1 # 记录当前字符的回文串长度(半边的长度) if (max_P &lt; r): # 更新 max_P 和 max_center max_P = r - 1 max_center = i if (max_len &lt; r - i): # 更新最长的回文串信息(超头, 超尾) max_len = r - i res_start = l res_end = r return T[res_start+1:res_end].replace('#', '') # 返回时注意去除 '#' 符号 006. Z 字形变换-中等题目链接: https://leetcode-cn.com/problems/zigzag-conversion/ 解法找到字符串下标的对应关系如下: 第一行和最后一行: 字符之间的下标间隔刚好是 2 * numRows - 2 其他行: 字符之间的下标间隔分两种情况交替出现: 1: 字符距离最后一行字符的下标距离的 2 倍 2: 字符距离第一行字符的下标距离的 2 倍 注意一种特殊情况, 就是当numRows为 1 时, 此时2 * numRows - 2的值为0, 会陷入死循环, 实际上, numRows的值为 1 时, 最终的结果就是原字符串, 直接返回即可 12345678910111213141516171819class Solution: def convert(self, s: str, numRows: int) -&gt; str: if numRows == 1: return s res = '' for i in range(numRows): if i == 0 or i == numRows-1: index = i while (index &lt; len(s)): res += s[index] index += 2 * numRows - 2 else: index = i step1 = (numRows - 1 - i ) * 2 step2 = (i) * 2 while (index &lt; len(s)): res += s[index] index += step1 step1, step2 = step2, step1 return res 007. Reverse IntegerDescription: 将数字逆置Given a 32-bit signed integer, reverse digits of an integer. Example 1:12Input: 123Output: 321 Example 2:12Input: -123Output: -321 Example 3:12Input: 120Output: 21 解法一: 取余数这道题本身不难, 只要不断对x的绝对值取余数, 就可以得到反转的整数, 但是, 该题的核心考察点在于边界条件的判断, 稍不注意, 很容易漏解(如果不进行边界判断, 即使写出了解决方法, 面试官也很不满意) x为0 x反转后的值,超过了int型数据的表示范围, 检查方法是先用long存储, 然后看情况决定返回值正负. 1234567891011121314151617class Solution &#123;public: int reverse(int x) &#123; if(x==0) return x; int abs_x = abs(x); int sign_x = x&gt;0? 1:-1; long res = 0; // 为了看int是否越界,特意将res声明为long型 while( abs_x!=0 )&#123; res = res*10 + abs_x%10; if(res &gt; INT_MAX || res &lt; INT_MIN) return 0; //这一句就是最主要的考察点,看int是否越界 abs_x = abs_x/10 ; &#125; if(sign_x ==-1) return 0-res; return res; &#125;&#125;; 008. String to Integer (atoi)Description: 将字符串转换成整数解法一: 考虑多种情况此题时间复杂度为 $O(n)$ , 重点考察是否考虑的全面, 主要有以下几种情况, 缺一不可: +123 dd // 返回123 +123d // 返回123 d-123 // 返回0 -123+ //返回-123 -123+4 // 返回-123 323123423423423 // 返回INT_MAX -1231238923894234 // 返回INT_MIN 1234-5 // 返回1234 123456789101112131415161718192021222324252627282930class Solution &#123;public: int myAtoi(string str) &#123; int sign =1; bool is_first = true; //记录当前非数字字符是否是第一个非空格字符, 如果是, 返回0 bool has_sign = false; // 记录正负号的出现次数, 出现多于1次的, 返回0 long res = 0; //记录当前的int值, 要出现int范围, 返回对应的INT for(int i =0 ; i&lt;str.size(); i++)&#123; if(str[i] == ' ' &amp;&amp; is_first) continue; // 空格, 且没有出现任何非空格字符(如出现了, 则空格也会跟着变成循环停止的标志) else if( !has_sign &amp;&amp; (str[i] == '+' || str[i] == '-') )&#123; // 判断符号 has_sign = true; is_first = false; sign = str[i]=='+' ? 1:-1; &#125;else if(str[i] &lt;= '9' &amp;&amp; str[i] &gt;= '0')&#123; has_sign = true; is_first = false; res = res*10 + int(str[i] - '0') * sign; // 数字累加, 注意这里使用了sign, 因此无需在后面判断正负, 直接加就可以 if (res &gt; INT_MAX) return INT_MAX; // 超限 else if(res &lt; INT_MIN) return INT_MIN; &#125;else if(is_first)&#123; //首字符为非法字符, 返回0 return 0; &#125;else&#123; break; &#125; &#125; return int(res); &#125;&#125;; 009. 回文数-简单题目链接: https://leetcode-cn.com/problems/palindrome-number/ 解法一: 转换成字符串进行标准的中心扩展法进行判断需要两次遍历, 一次转换, 一次判断 略 解法二: 利用数学计算利用数学计算得到新的回文值, 然后将二者进行比较, 这样进需要一次遍历 123456789class Solution: def isPalindrome(self, x: int) -&gt; bool: if (x &lt; 0): return False new_x = 0 ori_x = x while (x &gt; 0): new_x = new_x * 10 + x % 10 x = x // 10 return True if new_x == ori_x else False 010 Regular Expression MatchingDescription: 正则表达式匹配Given an input string (s) and a pattern (p), implement regular expression matching with support for ‘.’ and ‘*’. ‘.’ Matches any single character.‘*’ Matches zero or more of the preceding element.The matching should cover the entire input string (not partial). Note:s could be empty and contains only lowercase letters a-z.p could be empty and contains only lowercase letters a-z, and characters like . or *. Example 1:12345Input:s = &quot;aa&quot;p = &quot;a&quot;Output: falseExplanation: &quot;a&quot; does not match the entire string &quot;aa&quot;. Example 2:12345Input:s = &quot;aa&quot;p = &quot;a*&quot;Output: trueExplanation: &apos;*&apos; means zero or more of the precedeng element, &apos;a&apos;. Therefore, by repeating &apos;a&apos; once, it becomes &quot;aa&quot;. Example 3:12345Input:s = &quot;ab&quot;p = &quot;.*&quot;Output: trueExplanation: &quot;.*&quot; means &quot;zero or more (*) of any character (.)&quot;. Example 4:12345Input:s = &quot;aab&quot;p = &quot;c*a*b&quot;Output: trueExplanation: c can be repeated 0 times, a can be repeated 1 time. Therefore it matches &quot;aab&quot;. Example 5:1234Input:s = &quot;mississippi&quot;p = &quot;mis*is*p*.&quot;Output: false 解法一: 递归实现( 速度很慢, 只超过0.97%的提交)采用递归法, 首先判断当前字符串 p 是否已经走到尽头, 如果是, 则看 s 是否走到尽头, 返回 true 或者 false.然后在第一个字符的匹配情况, 并记录之.然后看是否存在 ‘‘, 并根据情况进行递归调用.若不存在 ‘‘, 则按正常匹配处理. 1234567891011121314151617181920212223class Solution &#123; bool helper(string &amp;s, int i, string &amp;p, int j) &#123; int n = s.size(), m = p.size(); if (j == m) return (i == n); bool firstMatch = (i != n and (s[i] == p[j] or p[j] == '.')); if (j &lt; m - 1 and p[j+1] == '*') &#123; //只有长度大于 2 的时候, 才考虑 * //两种情况 //pattern 直接跳过两个字符. 表示 * 前边的字符出现 0 次 //pattern 不变, 例如 text = aa , pattern = a* return helper(s, i, p, j+2) or (firstMatch and helper(s, i+1, p, j)); &#125; else &#123; // return firstMatch and helper(s, i+1, p, j+1); &#125; &#125;public: bool isMatch(string s, string p) &#123; return helper(s, 0, p, 0); &#125;&#125;; 解法二: 动态规划This problem has a typical solution using Dynamic Programming. We define the state P[i][j] to be true if s[0..i) matches p[0..j) and false otherwise. Then the state equations are: P[i][j] = P[i - 1][j - 1], if p[j - 1] != ‘*’ &amp;&amp; (s[i - 1] == p[j - 1] || p[j - 1] == ‘.’); P[i][j] = P[i][j - 2], if p[j - 1] == ‘*’ and the pattern repeats for 0 times; P[i][j] = P[i - 1][j] &amp;&amp; (s[i - 1] == p[j - 2] || p[j - 2] == ‘.’), if p[j - 1] == ‘*’ and the pattern repeats for at least 1 times. Putting these together, we will have the following code. 12345678910111213141516class Solution &#123;public: bool isMatch(string s, string p) &#123; bool dp[s.size()+1][p.size()+1]&#123;0&#125;; //!! 这里注意一定要初始化, 否则在下面的循环中, dp[2][0] 是循环不到的, 但是dp[2][2]会访问dp[2][0]的值, 如果不进行初始化, 就会发生 RuntimeError !!! dp[0][0]=true; for(int i =0; i&lt;s.size()+1; i++)&#123; for(int j = 1;j&lt;p.size()+1;j++)&#123; if(p[j-1] == '*') // 注意这里是j-1 dp[i][j] = ( j &gt; 1 &amp;&amp; dp[i][j-2] )|| ( i&gt;0 &amp;&amp; (s[i-1] == p[j-2] || p[j-2] == '.') &amp;&amp; dp[i-1][j]); // 注意这里是j-2, i-1, 一定要知道这些是为什 else dp[i][j] = i&gt;0 &amp;&amp; dp[i-1][j-1] &amp;&amp; (s[i-1] == p[j-1] || p[j-1] == '.'); &#125; &#125; return dp[s.size()][p.size()]; &#125;&#125;; 011. Container With Most WaterDescriptionGiven n non-negative integers a1, a2, …, an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. The below vertical lines are represented by array [1,8,6,2,5,4,8,3,7]. In this case, the max area of water (blue section) the container can contain is 49. 解法一: 暴力时间复杂度: $O(n^2)$ 用max_area标记当前最大容器的取值, 然后两个for循环遍历所有容器的可能取值 1234567891011121314class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int max_area = 0; for(int i=0; i&lt;height.size(); i++)&#123; for(int j = i+1; j &lt; height.size(); j++)&#123; if(max_area &lt; min( height[i],height[j] ) * (j-i))&#123; max_area = min( height[i],height[j] ) * (j-i); &#125; &#125; &#125; return max_area; &#125;&#125;; 解法二: 用两个指针时间复杂度: $O(n)$空间复杂度: $O(1)$ 分别用两个指针指向数组的第一个元素和最后一个元素, 并计算当前的area, 然后移动指针元素值较小的一方, 移动过程中更新max_area的值 原理: 首先假设容器可以具有最大长度的宽, 也就是分别指向首尾元素, 这时候 , 我们想查看是否还有比当前最大容积更大的容器, 那么, 我们必须维持较高的垂直边不动, 而将较低的垂直边移动, 因为只有这样, 我们才 有可能 (注意不是一定)获得比当前容积更大的容器, 这个时候虽然宽变小了, 但是高度却可能增加(因为新增的边有可能大于当前较低边的高). 如果移动较高的边, 那么新增的边由于受到当前较低边的作用, 只有可能减小容器的面积 123456789101112131415161718class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int low = 0, high = height.size()-1; int max_area = 0; while(low&lt;high)&#123; int area = min( height[low], height[high] ) * (high-low); if(max_area &lt; area)&#123; max_area = area; &#125; if(height[low] &lt; height[high]) low++; else high--; &#125; return max_area; &#125;&#125;; 012. 整数转罗马数字-中等题目链接: https://leetcode-cn.com/problems/integer-to-roman/ 解法: 字典映射(哈希)1234567891011class Solution: def intToRoman(self, num: int) -&gt; str: i2r_dict = &#123;1000: 'M', 900: 'CM', 500: 'D', 400: 'CD', 100: 'C', 90:'XC', 50:'L', 40:'XL', 10:'X', 9:'IX', 5:'V', 4:'IV', 1:'I'&#125; i2r = [1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1] res = '' for i in range(len(i2r)): while(i2r[i] &lt;= num): res += i2r_dict[i2r[i]] num -= i2r[i] return res 013. Roman to IntegerDescriptionRoman numerals are represented by seven different symbols: I, V, X, L, C, D and M. Symbol ValueI 1V 5X 10L 50C 100D 500M 1000For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9.X can be placed before L (50) and C (100) to make 40 and 90.C can be placed before D (500) and M (1000) to make 400 and 900.Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999. Example 1: Input: “III”Output: 3Example 2: Input: “IV”Output: 4Example 3: Input: “IX”Output: 9Example 4: Input: “LVIII”Output: 58Explanation: L = 50, V= 5, III = 3.Example 5: Input: “MCMXCIV”Output: 1994Explanation: M = 1000, CM = 900, XC = 90 and IV = 4. 解法一: 顺序扫描时间复杂度: $O(n)$ 顺序扫描, 如果当前字符比下一个字符小, 说明是 ‘4’ 或 ‘9’ 的情况, 用下一个字符的值减去当前字符的值 12345678910111213141516171819202122232425class Solution &#123;public: int romanToInt(string s) &#123; unordered_map&lt;char, int&gt; roman_char; roman_char['I'] = 1; roman_char['V'] = 5; roman_char['X'] = 10; roman_char['L'] = 50; roman_char['C'] = 100; roman_char['D'] = 500; roman_char['M'] = 1000; int res = 0; for(int i =0; i&lt;s.size() ; i++)&#123; if( i&lt;s.size()-1 &amp;&amp; roman_char[s[i]] &lt; roman_char[s[i+1]])&#123; res += roman_char[s[i+1]]-roman_char[s[i]]; i++; &#125; else res += roman_char[s[i]]; &#125; return res; &#125;&#125;; 扩展问题: 异常检测上面的解法虽然可以通过OJ, 但是此题还需要进行特别的异常诊断, 即要能够判断出当前输入的罗马输出是否合法! 如 “IVIV” 就是典型的不合法输入, 对于此输入, 上面的程序会输出 , 这显然不正确 014. Longest Common PrefixDescription: 最长公共前缀Write a function to find the longest common prefix string amongst an array of strings.If there is no common prefix, return an empty string “”. Example 1:12Input: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]Output: &quot;fl&quot; Example 2:123Input: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]Output: &quot;&quot;Explanation: There is no common prefix among the input strings. Note:All given inputs are in lowercase letters a-z. 解法一: 顺序比较时间复杂度: $O(S)$, $S$ 为所有字符串中的字符总数空间复杂度: $O(1)$, 没有使用额外的空间 暴力求解, 先求第一个字符串与第二个字符串最长公共前缀, 然后利用该前缀与第三个字符串比较, 知道公共前缀为空或者比较完所有字符串. 12345678910111213141516class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if(strs.size()==0 || strs[0].size()==0) return ""; string prefix = strs[0]; for(int i=0; i&lt;strs.size() &amp;&amp; !prefix.empty(); i++)&#123; int j=0; while(j&lt;prefix.size()&amp;&amp;j&lt;strs[i].size() &amp;&amp;prefix[j] == strs[i][j])&#123; j++; &#125; prefix = prefix.substr(0, j); &#125; return prefix; &#125;&#125;; 解法二: 垂直比较时间复杂度: $O(S)$, $S$ 为所有字符串中的字符总数, 最好情况下复杂度为 $O(n\min(s)$, $\min(s)$ 为字符串数组中的最短字符串长度.空间复杂度: $O(1)$, 没有使用额外的空间 顺序比较所有字符串的值, 直到遇到第一次不相等的位置, 然后输出前面的公共前缀, 需要额外注意处理以下几种特殊情况:输入 输入为: [] 或 [“”] 应该直接返回”” 输入为: [“abc”] 应该直接返回”abc” 123456789101112131415161718class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if(strs.size() ==0 || strs[0]=="") return ""; if(strs.size() ==1 ) return strs[0]; for(int i =0 ;; i++)&#123; for(int k = 1; k&lt;strs.size(); k++)&#123; if(strs[0][i] != strs[k][i])&#123; if(i&gt;0) return strs[0].substr(0,i); else return ""; &#125; &#125; &#125; return ""; &#125;&#125;; 015. 3SumDescription: 三数和为零Given an array nums of n integers, are there elements a, b, c in nums such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. Note:The solution set must not contain duplicate triplets. Example:1234567Given array nums = [-1, 0, 1, 2, -1, -4],A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 解法一: 固定一个数, 剩余两个数用双指针法求时间复杂度: $O(n^2+nlogn)=O(n^2)$空间复杂度: $O(1)$, 无需额外空间 解题步骤: 对整个数组排序, $O(nlogn)$; 固定下标 i, 令下标j=i+1, 令 k=nums.size()-1. 如果 nums[i] 为正数, 说明不可能组成和为零的三元组, 直接返回当前结果; 为了消除重复, 对于相同的相邻元素, 我们只选其中的一个参与组合. 注意: 这里的重复是指三元组的值的重复, 而不是下标重复, 也就是说, 对于下标不同但值相同的元素, 也算作重复. 重复(2)(3)(4)过程直到循环终止. 排序的必要性: 这里我们排序的主要目的是为了消除重复, 如果题目允许重复, 那么可以不进行排序, 而采用基于哈希表的 TwoSum 来求解. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Solution &#123;public: int partition(vector&lt;int&gt;&amp; nums, int low, int high)&#123; if(nums[low] != nums[(low+high)/2])&#123; // 注意这里用异或交换的陷阱 nums[low] = nums[low] + nums[(low+high)/2]; nums[(low+high)/2] = nums[low] - nums[(low+high)/2]; nums[low] = nums[low] - nums[(low+high)/2]; &#125; // 主要是将中将的数字和首位交换, 个人觉得可有可无, 因为时间复杂度是一样的 int P = nums[low]; while(low &lt; high)&#123; while(low&lt;high &amp;&amp; P&lt;=nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P&gt;=nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125; void quickSort(vector&lt;int&gt;&amp; nums, int low, int high)&#123; int mid = partition(nums, low, high); if(low&lt;mid ) quickSort(nums, low, mid-1); if(mid&lt;high) quickSort(nums, mid+1, high); &#125; vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(nums.size()&lt;3) return res; quickSort(nums, 0, nums.size()-1); for(int i =0; i&lt;nums.size(); i++)&#123; if(nums[i]&gt; 0) break; //剪枝, 如果当前数字为正, 那么后面就不可能再有符合条件的三元组, 可以提前退出 if(i&gt;0 &amp;&amp; nums[i] == nums[i-1] ) continue; //去除重复, 遇到除第一个外相同的三元组最小的数字, 则跳过 int low = i+1, high = nums.size()-1; while(low &lt; high)&#123; if(low&gt;i+1 &amp;&amp; nums[low] == nums[low-1])&#123; // 仍然是去除重复, low++; continue; &#125; int sum = nums[low] + nums[i] + nums[high]; if(sum&gt;0) high--; else if(sum&lt;0) low++; else&#123; vector&lt;int&gt; tmp&#123;nums[low], nums[i], nums[high]&#125;; res.push_back(tmp); low++; // 这一点千万别漏了, 要继续判断, 因为以当前数字开始的三元组可能不止一个 &#125; &#125; &#125; return res; &#125;&#125;; 更好的写法:12345678910111213141516171819202122232425vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; result; if(nums.size()&lt;=2)return result; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size() - 2; i++) &#123; int a = nums[i]; if(a &gt; 0) break; if (i &gt; 0 &amp;&amp; a == nums[i - 1]) continue;// 这里不能用nums[i]==nums[i+1], 因为会丢掉类似于 -1,-1,2 的解. for (long j = i + 1, k = nums.size() - 1; j &lt; k;) &#123; int b = nums[j]; int c = nums[k]; int value = a + b + c; if (value == 0) &#123; result.push_back(vector&lt;int&gt;(&#123;a, b, c&#125;)); while (j &lt; k &amp;&amp; b == nums[++j]); // 主要是这里的写法很优雅, 其他地方和上面差不多 while (j &lt; k &amp;&amp;c == nums[--k]); &#125; else if (value &gt; 0) &#123; k--; &#125; else &#123; j++; &#125; &#125; &#125; return result; &#125; 解法二: python写法123456789101112131415161718192021class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: nums.sort() target = 0 res = [] for p1 in range (len(nums) - 2): if (nums[p1] &gt; 0): return res if (p1 &gt; 0 and nums[p1] == nums[p1-1]): continue p2 = p1 + 1 p3 = len(nums) -1 while (p2 &lt; p3): if (p2-1 != p1 and nums[p2] == nums[p2-1]): p2 += 1 continue tmp = nums[p1] + nums[p2] + nums[p3] if (tmp &gt; 0): p3 -= 1 elif (tmp &lt; 0): p2 += 1 else: res.append([nums[p1], nums[p2], nums[p3]]) p2 += 1 return res 016. 3Sum ClosestDescription题目链接 Given an array nums of n integers and an integer target, find three integers in nums such that the sum is closest to target. Return the sum of the three integers. You may assume that each input would have exactly one solution. Example:Given array nums = [-1, 2, 1, -4], and target = 1.The sum that is closest to the target is 2. (-1 + 2 + 1 = 2). 解法一: 排序+双指针时间复杂度: $O(n^2)$ 先排序, 然后固定中间位, 移动两边 123456789101112131415161718class Solution: def threeSumClosest(self, nums: List[int], target: int) -&gt; int: nums.sort() sum3 = nums[0] + nums[1] + nums[2] for center in range(1, len(nums) - 1): p1 = 0 p2 = len(nums) -1 while (p1 != center and p2 != center): tmp3sum = nums[p1] + nums[center] + nums[p2] if (abs(tmp3sum - target) &lt; abs(sum3 - target)): sum3 = tmp3sum if (tmp3sum &lt; target): p1 += 1 elif (tmp3sum &gt; target): p2 -= 1 else: break return sum3 017. Letter Combinations of a Phone NumberDescription: 九键字母组合Given a string containing digits from 2-9 inclusive, return all possible letter combinations that the number could represent.A mapping of digit to letters (just like on the telephone buttons) is given below. Note that 1 does not map to any letters. Example:12Input: &quot;23&quot;Output: [&quot;ad&quot;, &quot;ae&quot;, &quot;af&quot;, &quot;bd&quot;, &quot;be&quot;, &quot;bf&quot;, &quot;cd&quot;, &quot;ce&quot;, &quot;cf&quot;]. Note:Although the above answer is in lexicographical order, your answer could be in any order you want. C++解法一: 递归时间复杂度: $O(n4^n)$, $n$ 为数字的长度*空间复杂度: $O(4^n)$ 1234567891011121314151617181920212223242526class Solution &#123;public: void back_tracking(vector&lt;string&gt;&amp; res, const vector&lt;string&gt;&amp; digit_letters, string&amp; tmp,string digits, int index)&#123; if(index == digits.size())&#123; res.push_back(tmp); &#125; else &#123; for(int i=0; i&lt;digit_letters[digits[index]-'0'].size(); i++)&#123; tmp.push_back(digit_letters[digits[index]-'0'][i]); back_tracking(res, digit_letters, tmp, digits, index+1); tmp.pop_back();// 移除当前末尾元素, 以便可以加下一个 &#125; &#125; &#125; vector&lt;string&gt; letterCombinations(string digits) &#123; vector&lt;string&gt; res; if(digits.size() &lt;=0) return res; //res.push_back(""); //在递归解法中, 不需要改语句. const vector&lt;string&gt; digit_letters&#123;"","","abc","def","ghi","jkl", "mno","pqrs","tuv","wxyz"&#125;; string tmp=""; back_tracking(res, digit_letters, tmp, digits, 0); return res; &#125;&#125;; 解法二: 非递归时间复杂度: $O(n4^n)$, $n$ 为数字数组的长度*空间复杂度: $O(4^n)$ 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;string&gt; letterCombinations(string digits) &#123; vector&lt;string&gt; res; if(digits.size() &lt;=0) return res; res.push_back(""); //对res向量初始化,以便开始, 如果不初始化, 则size为0,后面的循环无法进行 const vector&lt;string&gt; digit_letters&#123;"","","abc","def","ghi","jkl", "mno","pqrs","tuv","wxyz"&#125;; for(int i =0 ;i&lt;digits.size(); i++)&#123; int num = digits[i] - '0'; if(digit_letters[num] == "") continue; vector&lt;string&gt; tmp; // 申请一个临时vector, 用于存放加上当前数字字符的string集合 for(int k = 0; k &lt; digit_letters[num].size(); k++)&#123; for(int l =0; l &lt; res.size(); l++)&#123; tmp.push_back(res[l]+digit_letters[num][k]); &#125; &#125; res.swap(tmp); // 将res于tmp交换, swap仅仅是改变指针, 比'='更快, 因为'='包含了复制 &#125; return res; &#125;&#125;; Python解法一: 利用reduce实现123456789101112131415class Solution: def letterCombinations(self, digits): """ :type digits: str :rtype: List[str] """ if digits=="": return [] digit_letters = &#123;'0':"", '1':"", '2':"abc", '3':"def", '4':"ghi", '5':"jkl", '6':"mno", '7':"pqrs", '8':"tuv", '9':"wxyz"&#125; from functools import reduce # 在python3中, reduce()函数已经从全局命名空间移除, 现在存在于functools模块中,使用时需要导入 return reduce(lambda res,digit:[x+y for x in res for y in digit_letters[digit]], digits, [""]) 018. 四数之和解法:转换成两数之和时间复杂度 $O(n^3)$ 先排序从前往后, 固定一个数字, 这样, 该数字后的剩余数列变成了一个 3sum 问题然后再固定一个数字, 这样, 剩余数列就变成了一个 2sum 问题 注意1: 要注意重复四元组的判断, 判断方式是当 i &gt; 0 and nums[i] == nums[i-1] 时, 跳过该数字.注意2: 一定要使用早停, 否则程序的运行时间回大大升高 123456789101112131415161718192021222324252627class Solution: def fourSum(self, nums: List[int], target: int) -&gt; List[List[int]]: def twoSum(nums, target, k, res, tmp_res): if(len(nums) &lt; k or nums[0] * k &gt; target or nums[-1] * k &lt; target): return if (k == 2): i = 0 j = len(nums) - 1 while (i &lt; j): if (i &gt; 0 and nums[i-1] == nums[i]): i += 1 continue tmp = nums[i] + nums[j] if (tmp &lt; target): i += 1 elif (tmp &gt; target): j -= 1 else: res.append(tmp_res + [nums[i], nums[j]]) i += 1 else: for i in range(len(nums)): if (i &gt; 0 and nums[i-1] == nums[i]): #i += 1 这里不论加不加 i 效果都一样, 为什么? continue twoSum(nums[i+1:], target-nums[i], k-1, res, tmp_res+[nums[i]]) res = [] twoSum(sorted(nums), target, 4, res, []) return res 019. Remove Nth Node From End of ListDescription: 移除链表的倒数第 N 个字符Given a linked list, remove the n-th node from the end of list and return its head. Example:123Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5. Note:Given n will always be valid. Follow up:Could you do this in one pass? 解法一: 遍历两次第一次遍历求出链表长度, 第二次遍历在对应位置删除节点 解法二: 双指针, 只遍历一次时间复杂度: $O(n)$ 且只遍历一次 空间复杂度: $O(1)$ 维护两个指针, 两指针之间的距离刚好相差n, 当第二个指针到达链表尾部时, 第一个指针刚好指向倒数第n个节点, 直接删除该节点即可. 12345678910111213141516171819202122232425/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; ListNode* first = head; ListNode* second = head; while (n--) &#123; first = first-&gt;next; &#125; if (first == nullptr) return head-&gt;next; // 链表长度为n, 删除倒数第n个节点 while (first-&gt;next != nullptr) &#123; second = second-&gt;next; first = first-&gt;next; &#125; second-&gt;next = second-&gt;next-&gt;next; return head; &#125;&#125;; 下面是有一种写法, 新申请了一个节点空间, 用于指向head节点, 可以使代码看起来更容易理解, 对边界条件的判断也更加方便 123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; if(head == nullptr || n &lt;= 0) return head; //链表为空, 或者n&lt;=0时, 直接返回head ListNode* dummy = new ListNode(0); dummy-&gt;next = head; ListNode* first = dummy; ListNode* second = dummy; for(int i = 0; i &lt; n ; i++)&#123; second = second-&gt;next; if(second == nullptr) return dummy-&gt;next;// n超出了链表的长度 &#125; while(second-&gt;next!=nullptr)&#123; first = first-&gt;next; second = second-&gt;next; &#125; first-&gt;next = first-&gt;next-&gt;next; return dummy-&gt;next; &#125;&#125;; 020. Valid ParenthesesDescriptionGiven a string containing just the characters &#39;(&#39;, &#39;)&#39;, &#39;{&#39;, &#39;}&#39;, &#39;[&#39; and &#39;]&#39;, determine if the input string is valid.An input string is valid if:Open brackets must be closed by the same type of brackets.Open brackets must be closed in the correct order.Note that an empty string is also considered valid. Example 1:12Input: &quot;()&quot;Output: true Example 2:12Input: &quot;()[]&#123;&#125;&quot;Output: true Example 3:12Input: &quot;(]&quot;Output: false Example 4:12Input: &quot;([)]&quot;Output: false Example 5:12Input: &quot;&#123;[]&#125;&quot;Output: true 解法一: 栈时间复杂度: $O(n)$空间复杂度: $O(n)$ 写法一:123456789101112131415161718class Solution &#123;public: bool isValid(string s) &#123; stack&lt;char&gt; s_brack; for(int i = 0; i&lt;s.size(); i++)&#123; char c='\0'; if(s[i] == ')') c='('; else if(s[i] == ']') c='['; else if(s[i] == '&#125;') c='&#123;'; if(!s_brack.empty() &amp;&amp; c == s_brack.top()) s_brack.pop(); else s_brack.push(s[i]); &#125; if(!s_brack.empty()) return false; return true; &#125;&#125;; 写法二:123456789101112131415161718class Solution &#123;public: bool isValid(string s) &#123; stack&lt;char&gt; parent; for(auto c : s)&#123; if(c=='(' || c=='&#123;' || c=='[') parent.push(c); else if(parent.empty()) return false; else if((c==')' &amp;&amp; parent.top()=='(') || (c=='&#125;' &amp;&amp; parent.top()=='&#123;') || (c==']' &amp;&amp; parent.top()=='['))&#123; parent.pop(); &#125;else return false; &#125; return parent.empty() ? true : false; &#125;&#125;; 021. Merge Two Sorted ListsDescriptionMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists. Example: Input: 1-&gt;2-&gt;4, 1-&gt;3-&gt;4Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 解法一: 遍历融合时间复杂度: $O(min(m,n))$ 空间复杂度: $O(1)$ 12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if(l1 == nullptr) return l2; if(l2 == nullptr) return l1; ListNode* head=nullptr; if(l1-&gt;val &lt; l2-&gt;val) &#123; head = l1; l1 = l1-&gt;next; &#125; else&#123; head = l2; l2 = l2-&gt;next; &#125; ListNode* cur = head; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur= cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l2==nullptr) cur-&gt;next = l1; else if(l1 == nullptr) cur-&gt;next = l2; return head; &#125;&#125;; 上面开关头结点的过程过于复杂, 可以用dummy指针简化这个过程 1234567891011121314151617181920212223242526272829303132/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if(l1 == nullptr) return l2; if(l2 == nullptr) return l1; ListNode* dummy=new ListNode(0); ListNode* cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur = cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l2==nullptr) cur-&gt;next = l1; else if(l1 == nullptr) cur-&gt;next = l2; return dummy-&gt;next; &#125;&#125;; 022. Generate ParenthesesDescription解法一: 暴力先求出所有可能性, 然后验证每一种可能性是否正确 解法二: 回溯有关递归的时间空间复杂度分析起来都不太容易, 这里只上答案(//TODO 具体怎么来没搞懂) 时间复杂度: $O(\frac{4^n}{\sqrt n})$空间复杂度: $O(\frac{4^n}{\sqrt n})$ 以及 $O(n)$ 的空间来存储组合序列 考虑合法括号组合的规律: 必须首先出现左括号, 然后才能出现右括号, 如果当前的string里面的右括号数量大于左括号数量, 那么就一定会出现)(这种不匹配的情况. 核心思路: 从头开始构建组合, 每次接入一个字符, 接入的字符只有两种可能性, 即左括号或者右括号, 而一旦接入的字符使得当前字符中右括号数量大于左括号, 就会变得不合法组合,其它均为合法. 根据此性质, 进行如下递归: 维护两个变量left_rest, right_rest分别代表 剩余 可以添加的括号的 数量. 采用递归算法, 每次添加一个 ‘(‘ 或者一个 ‘)’, 添加时需要考虑下面几种情况: 为了保证当前string内左括号数量多于右括号数量, left_rest一定要小于right_rest 如果left_rest = right_rest = 0, 则说明此时没有可以添加的括号了. 1234567891011121314151617class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; vector&lt;string&gt; res; helper(res, "", n, n); return res; &#125; void helper(vector&lt;string&gt; &amp;res, string out, int left_rest, int right_rest)&#123; //注意这里的 out 不能生命成引用形式 //if(left_rest &gt; right_rest) return; if(left_rest == 0 &amp;&amp; right_rest ==0) res.push_back(out); else&#123; if(left_rest&gt;0) helper(res, out+'(', left_rest-1, right_rest); if(right_rest&gt;0 &amp;&amp; right_rest &gt; left_rest) helper(res, out+')', left_rest, right_rest-1); &#125; &#125;&#125;; 解法三: Closure Number时间复杂度: $O(\frac{4^n}{\sqrt n})$, 同解法4空间复杂度: $O(\frac{4^n}{\sqrt n})$, 同解法4 该方法可以看做是一种插入法, 选定一组括号 (), 由此便消耗了一组括号的数量, 此时还剩下 n-1 组括号, 我们将这 n-1 组括号插入到选定的括号中, 即 (left)right, 其中, left 和 right 都是有效的括号组合, 它们的括号组数加起来刚好为 n-1, 因此, left 的括号组数的情况共有 n 种情况: [0, …, n-1], 对应的 right 的组数有 n-1-left 组. 具体代码实现如下所示: 123456789101112131415class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; vector&lt;string&gt; res; if(n==0)&#123; res.push_back(""); &#125;else&#123; for(int c=0; c&lt;n; c++) for(string left : generateParenthesis(c)) for(string right : generateParenthesis(n-1-c)) res.push_back("("+left+")"+right); &#125; return res; &#125;&#125;; 解法四: 用栈来模拟递归首先是最厚的括号包裹状态, 即一开始左边是连续的左括号, 右边是连续的右括号, 然后执行以下逻辑： 右括号不能比左括号多; 弹出右括号, 直到遇到第一个左括号, 如果左括号改成右括号仍然合法, 则把它改成右括号; 否则, 左括号继续弹出; 改完之后一个劲加左括号, 直到所有可以用的左括号都加完为止; 然后再一个劲的加右括号, 直到加完位置; 循环一直执行到不能弹出括号为止, 即直到栈为空. 这里刚好凸显了一件事情, 那就是要注意尽可能不要将自增或自减操作写在 while() 条件句里面, 否则会造成一些很难发现的错误, 下面代码中的注释会说明 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; int left = n; int right = n; vector&lt;string&gt; res; string s; // 注意, 将left写在while里面的问题时, 当left为0时才会结束while // 但是此时会使得 left 变成 -1, 因此, 需要再left++, 或者讲left--写在 while 里面 while (left--) &#123; s += '('; &#125; left++; while (right--) &#123; s += ')'; &#125; right++; res.push_back(s); while (!s.empty()) &#123; if (s.back() == ')') &#123; s.pop_back(); right++; &#125; else if (left+1 &lt; right) &#123; left++; right--; s.back() = ')'; while (left--) s.push_back('('); left++; while (right--) s.push_back(')'); right++; res.push_back(s); &#125; else &#123; s.pop_back(); left++; &#125; &#125; return res; &#125;&#125;; 023. Merge k Sorted ListsDescription: 合并 k 个有序链表Merge k sorted linked lists and return it as one sorted list. Analyze and describe its complexity. Example:1234567Input:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 解法一: 基于比较的合并时间复杂度: $O(k \times N)$ k为需要合并和链表个数, 在比较时需要遍历k个链表的头结点, 以便找出最小的. 每插入一个节点, 就要重新遍历一次, 故需要遍历 $N$ 次, $N$ 为所有链表的节点总数.空间复杂度: $O(1)$ 将该问题看做是两个有序链表的合并问题, 只不过每次选择最小的节点时, 需要从vector.size()个节点中选择, 同时还要注意及时移除vector中已经走到头的空链表, 并判断size当前的大小, 当vector中的size大小为1时, 说明其余链表都已经合并完成, 此时退出循环, 直接将该链表接入即可. 另外要注意vector为空, 以及vector中全是nullptr链表的特殊情况. 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.size() == 0) return nullptr; //处理[]的情况 ListNode* dummy = new ListNode(0); ListNode* cur_node = dummy; while(lists.size() &gt; 1)&#123; int min_node_index = 0; for(int i = 0; i&lt;lists.size() ;i++)&#123; if(lists[i] == nullptr) &#123; lists.erase(lists.begin()+i); i--; //移除第i个元素后, 下一个元素会自动成为第i个元素,因此, 将当前i-- continue; // continue后, i会++, 最终i指向了下一个元素 &#125; if(lists[min_node_index]-&gt;val &gt; lists[i]-&gt;val)&#123; min_node_index = i; &#125; &#125; if(lists.size() == 0) return nullptr; //主要是应对 [[], []] 的情况, 本身vector的size大于0, 但是经过erase以后size就变成0了, 此时应返回nullptr cur_node-&gt;next = lists[min_node_index]; cur_node = cur_node-&gt;next; lists[min_node_index] = lists[min_node_index]-&gt;next; if(lists[min_node_index] == nullptr) lists.erase(lists.begin()+min_node_index); &#125; cur_node-&gt;next = lists[0]; return dummy-&gt;next; &#125;&#125;; 解法二: 用小顶堆对解法一的比较操作进行优化时间复杂度: $O(logk \times N)$, N 代表所有链表的节点总数.空间复杂度: $O(k)$ 由于要构造堆, 所以需要额外空间 由于我们只需要找到k个节点里面数值最小的那一个, 因此可以利用Priority Queue (实际上就是大顶堆和小顶堆)对上面的比较操作进行优化, 使得比较操作的复杂度从 $k$ 降到 $logk$. 由于每个节点都会进入小顶堆一次, 所有总共需要执行 $N$ 次入堆操作, 故最终的复杂度的 $logk\times N$. 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: // 用函数对象进行比较 struct cmp&#123; bool operator()(ListNode *node1, ListNode *node2)&#123; return node1-&gt;val &gt; node2-&gt;val; &#125; &#125;;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; priority_queue&lt;ListNode *, vector&lt;ListNode *&gt;, cmp&gt; min_heap; // 用 lambda 表达式进行比较 // auto cmp = [](ListNode* node1, ListNode* node2) &#123; // return node1-&gt;val &gt; node2-&gt;val; // 小顶堆 // &#125;; //priority_queue&lt;ListNode *, vector&lt;ListNode *&gt;, decltype(cmp)&gt; min_heap(cmp); for(auto node_head : lists) if(node_head!=nullptr) min_heap.push(node_head); if(min_heap.empty()) return nullptr; ListNode *dummy = new ListNode(0); ListNode *cur = dummy; while(!min_heap.empty())&#123; ListNode *tmp = min_heap.top(); min_heap.pop(); cur-&gt;next = tmp; cur = cur-&gt;next; if(tmp-&gt;next != nullptr) min_heap.push(tmp-&gt;next); &#125; return dummy-&gt;next; &#125;&#125;; 解法三: 转化成双列表合并问题时间复杂度: $O(k \times N)$空间复杂度: $O(1)$ 双列表合并问题的时间复杂度为 $O(m+n)$ , 可以将多链表合并问题看做是k次双列表合并. 解法四: 对解法三进行优化时间复杂度: $O(logk \times N)$空间复杂度: $O(1)$ 对列表合并时, 每次都是两两合并(不是解法三中的逐一合并), 这样, 只需要经过 $logk$ 次两两合并就可完成所有合并过程. 迭代实现:12345678910111213141516171819202122232425262728293031323334class Solution &#123;private: ListNode* mergeTwoLists(ListNode *l1, ListNode *l2)&#123; ListNode *dummy = new ListNode(0); ListNode *cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur = cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l1==nullptr) cur-&gt;next = l2; else cur-&gt;next = l1; return dummy-&gt;next; &#125;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.empty()) return nullptr; int len = lists.size(); int interval = 1; while(interval &lt; len)&#123; for(int i=0; i+interval&lt;len; i+= 2*interval)&#123;//i应满足: 0,2,4... / 0,4,.. / 0 lists[i] = mergeTwoLists(lists[i], lists[i+interval]);//i+interval必须&lt;len, 否则溢出 &#125; interval *= 2; //区间大小翻倍 &#125; return lists[0]; &#125;&#125;; 递归实现: 递归实现需要额外的 $O(logk)$ 的栈空间(调用递归的次数)12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: ListNode* mergeTwoLists(ListNode *l1, ListNode *l2)&#123; ListNode *dummy = new ListNode(0); ListNode *cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur = cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l1==nullptr) cur-&gt;next = l2; else cur-&gt;next = l1; return dummy-&gt;next; &#125; ListNode* partition(vector&lt;ListNode*&gt;&amp; lists, int start, int end)&#123; if(start==end)&#123; return lists[start]; &#125;else if(start &lt; end)&#123; int mid = (start+end)/2; ListNode* l1 = partition(lists, start, mid); ListNode* l2 = partition(lists, mid+1, end); return mergeTwoLists(l1, l2); &#125;else return nullptr; &#125;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.empty()) return nullptr; return partition(lists, 0, lists.size()-1); &#125;&#125;; 将双链表合并也写成递归形式:123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: ListNode* mergeTwoLists(ListNode *l1, ListNode *l2)&#123; if(l1==nullptr) return l2; else if(l2==nullptr) return l1; else if(l1-&gt;val &lt; l2-&gt;val)&#123; l1-&gt;next = mergeTwoLists(l1-&gt;next, l2); return l1; &#125;else&#123; l2-&gt;next = mergeTwoLists(l1, l2-&gt;next); return l2; &#125; &#125; ListNode* partition(vector&lt;ListNode*&gt;&amp; lists, int start, int end)&#123; if(start==end)&#123; return lists[start]; &#125;else if(start &lt; end)&#123; int mid = (start+end)/2; ListNode* l1 = partition(lists, start, mid); ListNode* l2 = partition(lists, mid+1, end); return mergeTwoLists(l1, l2); &#125;else return nullptr; &#125;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.empty()) return nullptr; return partition(lists, 0, lists.size()-1); &#125;&#125;; 024. 两两交换链表中的节点-中等题目链接: https://leetcode-cn.com/problems/swap-nodes-in-pairs/ 解法: 按照题目要求逻辑进行交换12345678910111213141516171819202122232425# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: def swapPairs(self, head: ListNode) -&gt; ListNode: if head == None or head.next == None: return head dummy = ListNode(0) dummy.next = head first = dummy.next second = dummy.next.next pre = dummy while (True): pre.next = second first.next = second.next second.next = first pre = first if (first.next != None and first.next.next != None): second = first.next.next first = first.next else: break return dummy.next 025. K 个一组翻转链表题目链接: https://leetcode-cn.com/problems/reverse-nodes-in-k-group/ 解法一组一组逆置, 难点在于要将前一组逆置后的尾节点记录, 同时将该尾节点指向当前组逆置后的头结点, 另外, 当最后一组不足 $k$ 个元素时, 需要复原最后一组. 12345678910111213141516171819202122232425262728293031323334353637383940414243# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: def reverseKGroup(self, head: ListNode, k: int) -&gt; ListNode: if head is None: return head dummy = ListNode(0) cur = head first = True while(cur != None): pre = None tmp_rail = cur for i in range(k): if cur == None: # 最后一组不足k个时, 要将逆置的链表复原 h = pre r = tmp_rail c = pre p = None while(c is not None): post = c.next c.next = p p = c c = post pre = p tmp_rail = h break post = cur.next # 逆置链表 cur.next = pre pre = cur cur = post if (first): # 如果是第一次, 需要用 dummy 标记头部 dummy.next = pre key_head = tmp_rail first = False else: # 如果是后面的组, 那么需要将前一组的尾部指向改组的头部, 同时将该组的尾部标记 key_head.next = pre key_head = tmp_rail tmp_rail.next = None # 末尾指向 None, 不然会陷入训练 return dummy.next 026. Remove Duplicates from Sorted ArrayDescriptionGiven a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. 解法一:遍历, 两种写法, 后者相当精简 123456789101112131415161718192021class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; int same = nums[0]; int length = 1; for(int i=1; i&lt;nums.size(); i++)&#123; if(nums[i] == same)&#123; nums.erase(nums.begin()+i); i--; continue; &#125; else&#123; same = nums[i]; length++; &#125; &#125; return length; &#125;&#125;; 123456789101112class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.empty()) return 0; int length=1; for(auto n:nums)&#123; if(n&gt;nums[length-1]) nums[length++]=n; &#125; return length; &#125;&#125;; 027. 移除元素题目链接: https://leetcode-cn.com/problems/remove-element/ 解法一次遍历, 双指针法, 当 “快” 指针不等于目标值时, 将其赋值给 “慢” 指针, 最终直接返回 “慢” 指针的位置即可 12345678class Solution: def removeElement(self, nums: List[int], val: int) -&gt; int: index = 0 for i in range(len(nums)): if nums[i] != val: nums[index] = nums[i] index += 1 return index 028. Implement strStr()字符串匹配算法, 更详细的解析请看字符串匹配算法解析 description: KMP, 判断是否为子串Return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. Example 1: Input: haystack = “hello”, needle = “ll”Output: 2Example 2: Input: haystack = “aaaaa”, needle = “bba”Output: -1Clarification: What should we return when needle is an empty string? This is a great question to ask during an interview. For the purpose of this problem, we will return 0 when needle is an empty string. This is consistent to C’s strstr() and Java’s indexOf(). 解法一: 暴力解法二: KMP求解next数组: 求解某个位置 $k$ 的next数组值是一个循环的过程, 需要不断检查以 位置 $k-1$ 的next值 为下标的元素的 下一位元素 与 当前位置 $k$ 元素 是否相等, 如果相等, 则 next[k] = next[k-1]+1, 如果不相等, 则 029. Divide Two IntegersDescription: 实现除法Given two integers dividend and divisor, divide two integers without using multiplication, division and mod operator.Return the quotient after dividing dividend by divisor.The integer division should truncate toward zero. Example 1:12Input: dividend = 10, divisor = 3Output: 3 Example 2:12Input: dividend = 7, divisor = -3Output: -2 Note:Both dividend and divisor will be 32-bit signed integers.The divisor will never be 0.Assume we are dealing with an environment which could only store integers within the 32-bit signed integer range: $[−2^{31}, 2^{31 − 1}]$. For the purpose of this problem, assume that your function returns 2^{31 − 1} when the division result overflows. 解法一: 循环加法时间复杂度: $O(dividend)$ 这种方法很容易时间超限: 当被除数很大(INT_MAX), 除数很小(1), 则需要循环INT_MAX次才能完成计算. 解法二: 左移法时间复杂度: $O(log(dividend))$, dividend 为被除数的大小. 对除数进行左移, 相当于每次乘以2, 直到左移后大于被除数, 用被除数减去左移后的数字, 记录左移对应除数的倍数, 然后再次将从除数开始左移, 直到被除数小于除数. 以上是除法的基本实现思路, 但是在具体实现时, 还需要特别考虑下面的情况 当被除数为 INT_MIN, 除数为 -1 时, 此时的返回值为 INT_MAX+1. (根据题目要求, 溢出时刻直接返回 INT_MAX) 当除数为 0 时, 也应该看做是溢出情况. 处理上面情况最方便的方法使用 long 长整型, 而不是 unsigned int 无符号类型. 因为 unsigned int 类型在进行乘以 2 的操作时, 很容易也溢出, 最终造成程序的死循环, 为了防止溢出, 最好使用 long, 具体请看代码. 123456789101112131415161718192021class Solution &#123;public: int divide(int dividend, int divisor) &#123; if(divisor==0 || (dividend==INT_MIN&amp;&amp;divisor==-1)) return INT_MAX; int res=0; int sign = ((dividend&lt;0) ^ (divisor&lt;0)) ? -1:1;// 用异或来获取符号 long did = labs(dividend); // long与int在有些环境中字节中一样, 此时最好用long long long dis = labs(divisor); while(did &gt;= dis)&#123; long temp = dis, multiple = 1; while( did &gt;= temp&lt;&lt;1 )&#123; temp = temp&lt;&lt;1; multiple = multiple&lt;&lt;1; &#125; did -= temp; res+= multiple; &#125; return res*sign; &#125;&#125;; 扩展: 这道题如果不允许使用 long 或者long long 怎么解?031. Next PermutationDescription: 实现 next_permutation 函数逻辑Implement next permutation, which rearranges numbers into the lexicographically next greater permutation of numbers.If such arrangement is not possible, it must rearrange it as the lowest possible order (ie, sorted in ascending order).The replacement must be in-place and use only constant extra memory.Here are some examples. Inputs are in the left-hand column and its corresponding outputs are in the right-hand column.1231,2,3 → 1,3,23,2,1 → 1,2,31,1,5 → 1,5,1 解法一: next_permutation 实现时间复杂度: $O(n)$空间复杂度: $O(1)$ STL中的 next_permutation 函数和 prev_permutation 两个函数提供了对于一个特定排列P, 求出其后一个排列P+1和前一个排列P-1的功能. next_permutation 的实现方法如下: 先 从后往前 找第一个小于后一个数的元素 nums[i]: nums[i]&lt;nums[i+1] 再 从后往前 找第一个大于 nums[i] 的数 nums[j]: nums[j]&gt;nums[i] 交换 nums[i] 和 nums[j] 将 i 之后的元素逆置(reverse) 12345678910111213class Solution &#123;public: void nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); &#125;&#125;; 033. Search in Rotated Sorted ArrayDescription: 在循环有序数组中查找元素Suppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand. (i.e., [0,1,2,4,5,6,7] might become [4,5,6,7,0,1,2]). You are given a target value to search. If found in the array return its index, otherwise return -1. You may assume no duplicate exists in the array. Your algorithm’s runtime complexity must be in the order of $O(log n)$. Example 1:12Input: nums = [4,5,6,7,0,1,2], target = 0Output: 4 Example 2:12Input: nums = [4,5,6,7,0,1,2], target = 3Output: -1 解法一: 二分查找时间复杂度: $O(logn)$空间复杂度: $O(1)$ 对于数组[4,5,6,7,0,1,2], 可以将其看成是两段: [4,5,6,7] 和 [0,1,2], 可以看出, 前一段中的任意一个数字都大于后一段中的数字, 于是, 令low=0, high=size()-1, 进行二分查找, 其中 mid 对应的数字要么落在前半段(nums[low] &lt;= nums[mid]), 要么落在后半段. 如果落在的前半段, 则看 target 的值是否在 low与mid之间. 是则 high = mid-1, 否则 low = mid+1 反之, 如果落在后半段, 则看 target 的值是否在 mid 与 high 之间, 是则 low=mid+1 , 否则high = mid-1 1234567891011121314151617181920212223242526class Solution &#123;public: int search(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size()-1; //数组前半段的数字永远大于后半段的数字 while(low&lt;=high)&#123; //当low==high时, mid=low=high, 如果不等于target, 则之后会退出循环 int mid = (low+high)/2; if(target == nums[mid]) return mid; if(nums[low] &lt;= nums[mid])&#123; //说明当前mid落在数组的前半段(), 这里等于号必须带, 否则会漏解 //判断target是否在low与mid之间, 这里low需要带等于号, //因为target有可能=nums[low], mid无需带等于号 if(target &gt;= nums[low] &amp;&amp; target &lt; nums[mid]) high = mid-1; else low = mid+1; &#125;else&#123; // 只有当nums[low]完全小于nums[mid]时, mid才落在后半段 if(target &gt; nums[mid] &amp;&amp; target &lt;= nums[high]) low = mid+1; else high = mid-1; &#125; &#125; return -1; &#125;&#125;; 解法二: 二分查找时间复杂度: $O(logn)$空间复杂度: $O(1)$ 该方法同样是二分查找, 只不过与上面有一点不同, 对于数组nums=[4,5,6,7,0,1,2]来说, 如果 target &lt; nums[0], 说明 target 位于数组的后半段, 那么可以将数组看做是nums=[INT_MIN,INT_MIN,INT_MIN,INT_MIN,0,1,2] , 这样一来, 就变成了最常规的有序数组, 反之, 如果 target 位于数组的前半段, 那么可以将数组看做是nums=[4,5,6,7,INT_MAX,INT_MAX,INT_MAX]. 注意, 这里并不会改变数组内部的值, 我们只是利用一个临时变量num来代替当前的nums[mid]的值, 然后利用 num 与 target 比较进行二分查找. 1234567891011121314151617181920212223class Solution &#123;public: int search(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size()-1; while(low&lt;=high)&#123; int mid = (low+high)/2; int num; if(target &lt; nums[0])&#123; //target在后半段, 所以将前半段都看做INT_MIN if(nums[mid] &lt; nums[0]) num = nums[mid]; // nums[mid]在后半段 else num = INT_MIN; // nums[mid]在前半段, &#125;else&#123; //target在前半段, 所以将后半段都看作是INT_MAX if(nums[mid] &lt; nums[0]) num = INT_MAX; // nums[mid]在后半段 else num = nums[mid]; // nums[mid]在前半段 &#125; if(num == target) return mid; else if(target &lt; num) high = mid-1; else low = mid+1; &#125; return -1; &#125;&#125;; 更精简的写法:12345678910111213141516171819class Solution &#123;public: int search(vector&lt;int&gt;&amp; nums, int target) &#123; int n = nums.size(); int low=0, high=n-1; while(low&lt;=high)&#123; int mid = (low+high)/2; int num; if(target&lt;nums[0]) num = nums[mid]&lt;nums[0] ? nums[mid] : INT_MIN; else num = nums[mid]&lt;nums[0] ? INT_MAX : nums[mid]; if(target &gt; num) low = mid+1; else if(target &lt; num) high = mid-1; else return mid; &#125; return -1; &#125;&#125;; 034. Find First and Last Position of Element in Sorted ArrayDescription: 在有序数组中查找目标的开始位置和结束位置Given an array of integers nums sorted in ascending order, find the starting and ending position of a given target value. Your algorithm’s runtime complexity must be in the order of O(log n). If the target is not found in the array, return [-1, -1]. Example 1:12Input: nums = [5,7,7,8,8,10], target = 8Output: [3,4] Example 2:12Input: nums = [5,7,7,8,8,10], target = 6Output: [-1,-1] 解法一: 二分查找时间复杂度: $O(logn)$空间复杂度: $O(1)$ 先用常规的二分查找找到target, 然后分别用二分查找找到最左边的target和最右边的target下标. 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size() - 1; vector&lt;int&gt; res&#123;-1,-1&#125;; int mid=-1; while(low &lt;= high)&#123; //正常的二分查找, 先找到target mid = (low+high)/2; if(nums[mid] == target) break; else if(nums[mid] &lt; target) low = mid+1; else high = mid-1; &#125; if(mid==-1 || nums[mid] != target) return res; // 数组为空或者数组内没有target //以mid为中心, 分别查找下标最小的target和下标最大的target int llow=low, lhigh=mid; // 左边的二分查找low,high初始化 int rlow=mid, rhigh=high; // 右边的二分查找low,high初始化 while(llow&lt;=lhigh)&#123; int mid = (llow+lhigh)/2; if(nums[mid] == target)&#123; if(mid==llow || nums[mid-1] != target)&#123; //关键: 只有当等于target并且左边没有元素或者左边元素不等于target时, 当前mid才是最左边的target res[0] = mid; break; &#125;else lhigh = mid-1; &#125;else if(nums[mid] &lt; target) llow = mid+1; else lhigh = mid-1; &#125; while(rlow&lt;=rhigh)&#123; int mid = (rlow+rhigh)/2; if(nums[mid] == target)&#123; if(mid==rhigh || nums[mid+1] != target)&#123; //同理, 找最右边的target res[1] = mid; break; &#125;else rlow = mid+1; &#125;else if(nums[mid] &lt; target) rlow = mid+1; else rhigh = mid-1; &#125; return res; &#125;&#125;; 解法二: 二分查找同样是二分查找, 更加精炼, 先找到最左边的target, 然后以最左边为low, 开始找最右边的target, 需要注意的是不能在nums[mid] == target时就退出循环. 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size()-1; vector&lt;int&gt; res&#123;-1, -1&#125;; while(low &lt; high)&#123; //找起始位置, 注意这里不能是 &lt;=, 而必须是=, 否则会死循环 int mid = (low+high)/2; //偏向左边, 很重要, 否则会死循环 if(nums[mid] &lt; target) low = mid+1; else high = mid; //注意, 这里不是mid-1, 因为现在是在找最左边的target, 故不能在=target时退出, 因此也不能直接令high=mid-1, 否则会丢失mid=target的情况 &#125; if(nums.size()==0 || nums[low] != target) return res; res[0]=low; high = nums.size()-1;// low 已经指向起始位置, 这里只需重置high while(low &lt; high)&#123; // 找终止位置 int mid = (low+high+1)/2; //使mid偏向右边, 这很重要 if(nums[mid] &gt; target) high = mid-1; else low = mid; &#125; res[1]=high; return res; &#125;&#125;; 解法三: STL 函数时间复杂度: $O(logn)$空间复杂度: $O(1)$ 直接利用 STL 的 lower_bound() 和 upper_bound() 函数分别找到其实位置和终止位置即可, 在使用这两个函数时, 需要注意以下几点: lower_bound() 函数返回首个 不小于 target 的迭代器, 如果数组中所有元素 都小于 target, 则会返回超尾迭代器. upper_bound() 函数返回首个 大于 target 的迭代器, 如果数组中所有元素 都小于等于 target, 则会返回超尾迭代器. 注意 upper_bound() 返回的迭代器是首个 大于 目标值的迭代器, 因此需要将其减一才是我们要找的 target 的终止位置. 12345678910class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; if(nums.empty()) return vector&lt;int&gt;&#123;-1,-1&#125;; auto lower = std::lower_bound(nums.begin(), nums.end(), target); if(lower==nums.end() || *lower != target) return vector&lt;int&gt;&#123;-1,-1&#125;; auto upper = std::upper_bound(nums.begin(), nums.end(), target); return vector&lt;int&gt;&#123;lower-nums.begin(), upper-nums.begin()-1&#125;; &#125;&#125;; 036. Valid SudokuDescription: 验证一个矩阵是否是数独数据Determine if a 9x9 Sudoku board is valid. Only the filled cells need to be validated according to the following rules: Each row must contain the digits 1-9 without repetition.Each column must contain the digits 1-9 without repetition.Each of the 9 3x3 sub-boxes of the grid must contain the digits 1-9 without repetition. 解法一: 利用flag数组存储判断矩阵时间复杂度: $O(9^2)$空间复杂度: $O(3\times 9^2)$ 虽然要申请三个二维数组, 但都是常数级. 用三个 9×9 大小的矩阵, 分别储存每一行上, 每一列上, 每一个子块上1-9数字是否出现.12345678910111213141516171819class Solution &#123;public: bool isValidSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; // 下面三个矩阵分别存储了 行上1-9是否出现, 列上1-9是否出现, sub-box上1-9是否出现的bool值 // 如果row_flag[1][3] 为真, 则说明第1行(从第0行算起)上已经具有数字4(数字比下标大1)了 bool row_flag[9][9] &#123;0&#125;, col_flag[9][9] &#123;0&#125;, sub_flag[9][9] &#123;0&#125;; for(int i = 0 ; i&lt;board.size(); i++)&#123; for(int j = 0; j&lt;board[i].size(); j++)&#123; if(board[i][j] == '.') continue; // 如果为 '.' 则可以直接跳过此次判断 int num = board[i][j] - '0' - 1; //这里-1主要是为了能够直接将num作为下标使用 int k = i/3*3 + j/3; if(row_flag[i][num] || col_flag[j][num] || sub_flag[k][num]) return false; row_flag[i][num]=col_flag[j][num]=sub_flag[k][num]=true; &#125; &#125; return true; &#125;&#125;; 解法二: 位操作时间复杂度: $O(n^2)=O(9^2)$空间复杂度: $O(3\times 9)$ 这是目前看到的最好的方法, 核心思想就是用一个 short 类型变量的某一位来作为 flag, 这样, 我们可以进一步节省空间的使用, 将空间复杂度从 $O(n^2)$ 降低到 $O(n)$. 12345678910111213141516171819class Solution &#123;public: bool isValidSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; vector&lt;short&gt; row(9,0); vector&lt;short&gt; col(9,0); vector&lt;short&gt; block(9,0); for(int i=0; i&lt;9; i++)&#123; for(int j=0; j&lt;9; j++)&#123; int idx = 1 &lt;&lt; (board[i][j]-'0'); if(row[i]&amp;idx || col[j]&amp;idx || block[i/3*3+j/3]&amp;idx) return false; row[i] |= idx;//将对应位置为1, 标记已经出现过 col[j] |= idx; block[i/3*3+j/3] |= idx; &#125; &#125; return true; &#125;&#125;; 038. Count and SayDescriptionThe count-and-say sequence is the sequence of integers with the first five terms as following: 1 11 21 1211 1112211 is read off as “one 1” or 11.11 is read off as “two 1s” or 21.21 is read off as “one 2, then one 1” or 1211. Given an integer n where 1 ≤ n ≤ 30, generate the nth term of the count-and-say sequence. Note: Each term of the sequence of integers will be represented as a string. 解法一: 依次查看上一次的数字时间复杂度: $O(nm)$ m为数字字符串的长度空间复杂度: $O(m)$ 每次根据上一次的数字更新当前的数字字符串, 如此迭代直到达到指定次数 12345678910111213141516171819202122class Solution &#123;public: string countAndSay(int n) &#123; string res="1"; int i=1; while(i&lt;n)&#123; string tmp; for(int u=0; u&lt;res.size(); u++)&#123; char c=res[u]; int count = 1; while(u+1&lt;res.size() &amp;&amp; res[u+1]==c)&#123; count++; u++; &#125; tmp += to_string(count)+c; &#125; res.swap(tmp); i++; &#125; return res; &#125;&#125;; 041. First Missing Positive寻找数组中缺失的最小的正数 DescriptionGiven an unsorted integer array, find the smallest missing positive integer. Example 1: Input: [1,2,0]Output: 3Example 2: Input: [3,4,-1,1]Output: 2Example 3: Input: [7,8,9,11,12]Output: 1Note: Your algorithm should run in O(n) time and uses constant extra space. 解法一: 下标与正数对应时间复杂度: $O(n)$空间复杂度: $O(1)$ (但是对改变了原始的数组, 这是一个小缺陷) 将下标与正数相应对, 例如对于正数5, 我们就将放置在nums[4]上, 这样一来, 再次遍历数组的时候, 当遇到第一个与下标不对应的数字时, 该下标对应的正数(i+1)就是缺少的正数. 放置正数到正确位置上时, 需要注意几点: swap之后需要继续将原来位置上(nums[4])的数放置到正确的位置上, 这里需要一个while循环 在检查数组时, 如果所有数组内所有数字都处在正确位置上, 那么就应该返回nums.size+1 (包括了数组为空的情况: 返回0+1=1) 写法一: for+while 123456789101112131415class Solution &#123;public: int firstMissingPositive(vector&lt;int&gt;&amp; nums) &#123; for(int i = 0; i &lt; nums.size(); i++)&#123; // 注意这些条件: 前两个是为了令交换下标合法, 后一个是防止相同的数交换, 造成死循环 while(nums[i] &gt; 0 &amp;&amp; nums[i]&lt;nums.size() &amp;&amp; nums[i] != nums[nums[i]-1]) std::swap(nums[i], nums[nums[i]-1]); &#125; for(int i =0; i&lt;nums.size(); i++)&#123; if(nums[i] != i + 1) return i+1; &#125; return nums.size()+1; &#125;&#125;; 写法二: while1234567891011121314151617class Solution &#123;public: int firstMissingPositive(vector&lt;int&gt;&amp; nums) &#123; int i = 0; while(i&lt;nums.size())&#123; if(nums[i] &gt; 0 &amp;&amp;nums[i]&lt;nums.size() &amp;&amp; nums[i] != nums[nums[i]-1]) std::swap(nums[i], nums[nums[i]-1]); // 如果进行了swap, 就不要i++ else i++; &#125; for(int i =0; i&lt;nums.size(); i++)&#123; if(nums[i] != i + 1) return i+1; &#125; return nums.size()+1; &#125;&#125;; 解法二: 哈希时间复杂度: $O(n)$ (3次for循环, 毫无争议的 $O(n)$ )空间复杂度: $O(1)$ (但是对改变了原始的数组, 这是一个小缺陷) 注意: 虽然这里的时间复杂度是毫无争议的 $O(n)$ , 但是不一定会上面的速度快, 因为上面只有两次循环, 内第一次内部的循环次数一般情况下都不会很大. 从哈希的角度理解: 可以将数组下标看成是hash的key for any array whose length is l, the first missing positive must be in range [1,…,l+1], so we only have to care about those elements in this range and remove the rest. we can use the array index as the hash to restore the frequency of each number within the range [1,…,l+1] 123456789101112131415161718192021222324class Solution &#123;public: int firstMissingPositive(vector&lt;int&gt;&amp; nums) &#123; // 丢失的最小正数只可能在 [1,2,...,nums.size()+1] 之间 // 这里的pushback是必须的, 因为下面会将不符合要求的元素都置为0, //因此nums[0]需要与0对应, 以代表所有的非法元素, //这点与上面基于swap的方法不同, 上面的swap是让nums[0] 与 1 对应. nums.push_back(0); int length = nums.size(); for(int i =0 ; i&lt;length; i++)&#123; if(nums[i] &lt; 0 || nums[i] &gt;= length) nums[i] = 0; // 将所有不符合丢失正数的数移除, 这一步必须单独用一个for循环做 &#125; for(int i = 0; i&lt;length; i++)&#123; nums[nums[i]%length] += length; &#125; for(int i = 1 ; i&lt;length; i++)&#123; if(nums[i]/length == 0) return i; &#125; return length; &#125;&#125;; 042 Trapping Rain Water数组中每个值代表柱状体的高度, 每个柱状体的宽度都为1, 根据数组内的值组成的高低不同的块, 能够存储多少个bin (1×1)的水 DescriptionGiven n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. Thanks Marcos for contributing this image! Example: Input: [0,1,0,2,1,0,1,3,2,1,2,1]Output: 6 解法一: 左右指针时间复杂度: $O(n)$空间复杂度: $O(1)$ 分别用两个变量left和right指向左边和右边的柱子, 并再用两个变量maxleft和maxright维护左边最高的柱子和右边最高的柱子, 统计的时候, 先固定left和right当中柱子高度较高的那一个, 然后统计较低柱子上存储的水量. 利用, 如果当前left的高度小于right的高度, 则我们计算left上面能够存储的水量, 有两种情况, 当left柱子的高度大于等于maxleft时, 则left柱子上没法存储水, 因为谁会从左边全部流失(右边比左边高, 所以不会从右边流失). 如果left的高度小于maxleft时, 由于水无法从左边流失, 也不能从右边流失, 因此当前柱子上就会存储水, 存储的水量为maxleft-height[left] (不考虑maxright, 因为maxright大于maxleft). 注意: 此题中的柱子是有 宽度 的, 这一点很重要, 如果柱子的宽度为0 , 那么就是另一种情况了. 1234567891011121314151617181920class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; int len = height.size(); int left = 0, right = len-1; int res = 0, maxleft = 0, maxright = 0; while(left &lt;= right)&#123; if(height[left] &lt;= height[right])&#123; //固定较大的一个柱子 if(height[left] &gt; maxleft) maxleft = height[left];// 如果当前柱子的高度大于左边max柱子的高度, 那么该柱子所处位置一定存不下水 else res = res + maxleft - height[left]; // 反之, 该柱子位置上可以存储的水的量为 坐标max高度减去当前的高度 left++; &#125;else&#123; if(height[right] &gt; maxright) maxright = height[right]; else res = res + maxright - height[right]; right--; &#125; &#125; return res; &#125;&#125;; 更简洁的写法:123456789101112131415161718192021class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; if (height.empty()) return 0; int left = 0, right = height.size() -1; int maxLH = height[left], maxRH = height[right]; int res = 0; while (left &lt; right) &#123; maxLH = std::max(maxLH, height[left]); maxRH = std::max(maxRH, height[right]); if (height[left] &lt; height[right]) &#123; res += maxLH - height[left]; left++; &#125; else &#123; res += maxRH - height[right]; right--; &#125; &#125; return res; &#125;&#125;; 044. Wildcard MatchingDescription: 通配符匹配Given an input string (s) and a pattern (p), implement wildcard pattern matching with support for ‘?’ and ‘*’. ‘?’ Matches any single character.‘*’ Matches any sequence of characters (including the empty sequence).The matching should cover the entire input string (not partial). Note: s could be empty and contains only lowercase letters a-z.p could be empty and contains only lowercase letters a-z, and characters like ? or *.Example 1: Input:s = “aa”p = “a”Output: falseExplanation: “a” does not match the entire string “aa”.Example 2: Input:s = “aa”p = ““Output: trueExplanation: ‘‘ matches any sequence.Example 3: Input:s = “cb”p = “?a”Output: falseExplanation: ‘?’ matches ‘c’, but the second letter is ‘a’, which does not match ‘b’.Example 4: Input:s = “adceb”p = “ab”Output: trueExplanation: The first ‘‘ matches the empty sequence, while the second ‘‘ matches the substring “dce”.Example 5: Input:s = “acdcb”p = “a*c?b”Output: false 解法一: 迭代时间复杂度: $O(m+n)$空间复杂度: $O(1)$ 对于每次循环迭代, i和j其中至少有一个前进一步, 所以时间复杂度为 $O(m+n)$. 1234567891011121314151617181920212223242526272829class Solution &#123;public: bool isMatch(string s, string p) &#123; int n = s.size(); int m = p.size(); int i = 0, j = 0; int star_index = -1, match = -1; while (i &lt; n) &#123; if (j &lt; m and (s[i] == p[j] or p[j] == '?')) &#123; // 单个字符匹配, i, j继续匹配下一个 i++; j++; &#125; else if (j &lt; m and p[j] == '*') &#123; star_index = j; // 如果当前字符为 *, 则有可能如0或若干个字符匹配, 首先假设至于0个字符匹配 match = i; // 只与0个字符匹配时, 记录当前i的值, 然后将j++, i不变 j++; &#125; else if (star_index != -1) &#123; // 如果前面两个条件都不满足, 说明之间的匹配方法不正确, 此时重新从前一个 * 开始匹配 match++; // 令 * 与之前标记的未匹配的i进行匹配, 然后将标记往后移一位 i = match; // 令 i 和 j 都等于下一个字符, 继续匹配过程 j = star_index+1; &#125; else &#123; return false; &#125; &#125; for (int jj = j ; jj &lt; m; jj++) &#123; // 当 i==n 退出循环时, j 有可能还未达到m, 因为有可能是 ***** 的形式 if (p[jj] != '*') return false; &#125; return true; &#125;&#125;; 解法二: DP时间复杂度: $O(nm)$, $n$ 为s的长度, $m$ 为p的长度空间复杂度: $O(n)$ 12345678910111213141516171819class Solution &#123;public: bool isMatch(string s, string p) &#123; int pLen = p.size(), sLen = s.size(), i, j, k, cur, prev; if(!pLen) return sLen == 0; bool matched[2][sLen+1]; fill_n(&amp;matched[0][0], 2*(sLen+1), false); matched[0][0] = true; for(i=1; i&lt;=pLen; ++i) &#123; cur = i%2, prev= 1-cur; matched[cur][0]= matched[prev][0] &amp;&amp; p[i-1]=='*'; if(p[i-1]=='*') for(j=1; j&lt;=sLen; ++j) matched[cur][j] = matched[cur][j-1] || matched[prev][j]; else for(j=1; j&lt;=sLen; ++j) matched[cur][j] = matched[prev][j-1] &amp;&amp; (p[i-1]=='?' || p[i-1]==s[j-1]) ; &#125; return matched[cur][sLen]; &#125;&#125;; 解法三: DP时间复杂度: $O(nm)$, $n$ 为s的长度, $m$ 为p的长度空间复杂度: $O(nm)$ 采用和第 10 题相同的思路, 令dp[i][j]代表s[0, i)和p[0,j)是否匹配, 该解法的空间复杂度比解法二高. 123456789101112131415161718192021class Solution &#123;public: bool isMatch(string s, string p) &#123; int n = s.size(); int m = p.size(); bool dp[n+1][m+1]; std::fill_n(&amp;dp[0][0], (n+1)*(m+1), false); // 用 fill_n 初始化 dp[0][0] = true; for (int i = 0; i &lt; n+1; i++) &#123; for (int j = 1; j &lt; m+1; j++) &#123; if (p[j-1] == '*') &#123; dp[i][j] = (i &gt; 0 and dp[i-1][j]) or (dp[i][j-1]); &#125; else &#123; dp[i][j] = i &gt; 0 and dp[i-1][j-1] and (s[i-1] == p[j-1] or p[j-1] == '?'); &#125; &#125; &#125; return dp[n][m]; &#125;&#125;; 046. Permutations全排列, 注意是distict的数字, 故而不需要进行重复检查 Description: 不含重复数字的全排列Given a collection of distinct integers, return all possible permutations. Example: Input: [1,2,3]Output:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 解法一: 递归时间复杂度: $O(A^n_n)$ , 每一种情况都是 $O(1)$ , 共有 $O(A^n_n)$ 种情况. (对吗?) 用一个变量pos指向nums的第一个位置, 然后将pos与后面所有位置上的数字交换(包括自己), 最终会得到n种可能性, 这n种可能性就是出现在第一位置上的所有可能字符的情况集合, 然后将第一位固定, 并将pos指向下一位, 此时问题转换成了n-1个字符的全排列, 按照这种想法一致递归下去, 就可以找到所有位置上的所有组合情况(用pos==nums.size()判断) 123456789101112131415161718192021class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(nums.size()==0) return res; permute_helper(res, 0, nums); return res; &#125; void permute_helper(vector&lt;vector&lt;int&gt; &gt; &amp;res, int pos, vector&lt;int&gt; &amp;nums)&#123; if(pos == nums.size()) res.push_back(nums); // 当pos走到最后时, 说明一种情况诞生, 将其添加到res中 else&#123; for(int i = pos; i&lt;nums.size(); i++)&#123; std::swap(nums[pos], nums[i]); permute_helper(res, pos+1, nums); std::swap(nums[pos], nums[i]); // 能够去掉这句话的前提是对res内的字符串进行重复检查, 具体可看牛客分析 //在面对含有重复字符的情况时, 最好加上这句话 &#125; &#125; &#125;&#125;; 解法二: 迭代时间复杂度: $O(n^3)$空间复杂度: $O(A_n^n)$ 全排列的size 对于n个数的全排列问题, 可以想象成已经获得了n-1个数的全排列, 然后将第n个数插入到n-1个数的n个空位上( 如将3插入到12的空位上分别为: 312,132,123). 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; permute(vector&lt;int&gt; &amp;num) &#123; vector&lt;vector&lt;int&gt;&gt; res(1,vector&lt;int&gt;()); for(int i=0; i&lt;num.size(); i++)&#123; vector&lt;vector&lt;int&gt;&gt; tmp_res(std::move(res)); // move之后, res内部会自动被清空, 而且move的效率较高 for(int j=0; j&lt;tmp_res.size(); j++)&#123; for(int k=0; k&lt;=tmp_res[0].size(); k++)&#123; // 注意这里是&lt;=, 因为还要往尾部插 vector&lt;int&gt; tmp(tmp_res[j]); tmp.insert(tmp.begin()+k, num[i]); res.push_back(tmp); &#125; &#125; &#125; return res; &#125;&#125;; 解法三: 利用C++的内置函数 next_permutation关于 next_permutation() 的详细解析请看这里 STL中的 next_permutation 函数和 prev_permutation 两个函数提供了对于一个特定排列P, 求出其后一个排列P+1和前一个排列P-1的功能. 1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(next_permutation(nums.begin(), nums.end())); return res; &#125;&#125;; 这道题利用 prev_permutation 也可以解决, 但是这里就多了一步 reverse 的操作, 这里贴出来只是帮助理解 STL 函数的内部实现, 对于 Permutation2 题也是同理:1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end(), greater&lt;int&gt;()); // 倒序排序 do&#123; res.push_back(nums); &#125;while(prev_permutation(nums.begin(), nums.end()));//使用 prev return res; &#125;&#125;; 解法四: 自己实现 next_permutation用迭代器作为参数:1234567891011121314151617181920212223class Solution &#123; template &lt;typename T&gt; bool nextPermutation(T first, T last) &#123; auto i = last - 2; auto j = last - 1; while (i &gt;= first &amp;&amp; *i &gt;= *(i+1)) i--; if (i &gt;= first) &#123; while (j &gt;= first &amp;&amp; *i &gt;= *j) j--; std::iter_swap(i, j); std::reverse(i+1, last); &#125; return i&gt;=first ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); std::vector&lt;std::vector&lt;int&gt;&gt; res; do &#123; res.push_back(nums); &#125; while (nextPermutation(nums.begin(), nums.end())); return res; &#125;&#125;; 用数组作为参数:1234567891011121314151617181920212223class Solution &#123;private: bool nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(nextPermutation(nums)); return res; &#125;&#125;; prev_permutation 实现:1234567891011121314151617181920212223class Solution &#123;private: bool prevPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&lt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&lt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end(), greater&lt;int&gt;()); do&#123; res.push_back(nums); &#125;while(prevPermutation(nums)); return res; &#125;&#125;; next_permutation python 实现:12345678910111213141516171819class Solution: def nextPermutation(self, nums: List[int]) -&gt; None: n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &gt;= nums[i+1]): i -= 1 # 找到i if (i &gt;= 0): while (j &gt; i and nums[i] &gt;= nums[j]): j -= 1 # 找到 j nums[i], nums[j] = nums[j], nums[i] # 交换, 并将 i 之后的进行逆置 nums[i+1:] = nums[i+1:][::-1] return True if i != -1 else False def permute(self, nums: List[int]) -&gt; List[List[int]]: nums.sort() res = [] res.append(nums.copy()) # 注意这里一定要用copy, 否则后续的更改会影响前面的nums的值 while(self.nextPermutation(nums)): res.append(nums.copy()) return res prev_permutation python 实现12345678910111213141516171819class Solution: def prevPermutation(self, nums: List[int]) -&gt; None: n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &lt;= nums[i+1]): i -= 1 # 找到i if (i &gt;= 0): while (j &gt; i and nums[i] &lt;= nums[j]): j -= 1 # 找到 j nums[i], nums[j] = nums[j], nums[i] # 交换, 并将 i 之后的进行逆置 nums[i+1:] = nums[i+1:][::-1] return True if i != -1 else False def permute(self, nums: List[int]) -&gt; List[List[int]]: nums.sort(reverse=True) res = [] res.append(nums.copy()) # 注意这里一定要用copy, 否则后续的更改会影响前面的nums的值 while(self.prevPermutation(nums)): res.append(nums.copy()) return res 047. Permutations IIDescription: 带有重复元素的全排列解法一: 递归+set时间复杂度:空间复杂度: set 插入元素的时间复杂度为 $O(logn)$, $n$ 为当前 set 的大小. 1234567891011121314151617181920class Solution &#123;private: void helper(set&lt;vector&lt;int&gt;&gt; &amp;res, int pos, vector&lt;int&gt; &amp;nums)&#123; int len = nums.size(); if(pos==len) res.insert(nums); for(int i=pos; i&lt;len; i++)&#123; if(i!=pos &amp;&amp; nums[i]==nums[pos]) continue; swap(nums[pos], nums[i]); helper(res, pos+1, nums); swap(nums[pos], nums[i]); &#125; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; set&lt; vector&lt;int&gt;&gt; res; helper(res, 0, nums); return vector&lt;vector&lt;int&gt;&gt;(res.begin(), res.end()); &#125;&#125;; 解法二: STL 的 next_permutation 函数关于 next_permutation() 的详细解析请看这里 1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(next_permutation(nums.begin(), nums.end())); return res; &#125;&#125;; 使用 prev_permutation() 也可解决, 不过需要记得要倒序排序.1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end(), greater&lt;int&gt;()); // 倒序排序 do&#123; res.push_back(nums); &#125;while(prev_permutation(nums.begin(), nums.end())); // prev return res; &#125;&#125;; 解法三: 自己实现 next_permutation()python 实现:12345678910111213141516171819class Solution: def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]: def nextPermutation(nums): n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &gt;= nums[i+1]): i -=1 if (i&gt;=0): while (j &gt; i and nums[i] &gt;= nums[j]): j -=1 nums[i], nums[j] = nums[j], nums[i] nums[i+1:] = nums[i+1:][::-1] return True if i != -1 else False nums.sort() res = [] res.append(nums.copy()) while (nextPermutation(nums)): res.append(nums.copy()) return res 用迭代器做参数:123456789101112131415161718192021222324class Solution &#123; template &lt;typename T&gt; bool nextPermutation(T first, T last) &#123; auto i = last - 2; auto j = last - 1; while (i &gt;= first &amp;&amp; *i &gt;= *(i+1)) i--; if (i &gt;= first) &#123; while (j &gt;= first &amp;&amp; *i &gt;= *j) j--; std::iter_swap(i, j); std::reverse(i+1, last); &#125; return i&gt;=first ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); std::vector&lt;std::vector&lt;int&gt;&gt; res; do &#123; res.push_back(nums); &#125; while(nextPermutation(nums.begin(), nums.end())); return res; &#125;&#125;; 用数组做参数: 1234567891011121314151617181920212223class Solution &#123;private: bool nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(nextPermutation(nums)); return res; &#125;&#125;; 048. Rotate ImageDescription: 图片旋转 90 度You are given an n x n 2D matrix representing an image. Rotate the image by 90 degrees (clockwise). Note: You have to rotate the image in-place, which means you have to modify the input 2D matrix directly. DO NOT allocate another 2D matrix and do the rotation. Example 1: Given input matrix =[ [1,2,3], [4,5,6], [7,8,9]], rotate the input matrix in-place such that it becomes:[ [7,4,1], [8,5,2], [9,6,3]]Example 2: Given input matrix =[ [ 5, 1, 9,11], [ 2, 4, 8,10], [13, 3, 6, 7], [15,14,12,16]], rotate the input matrix in-place such that it becomes:[ [15,13, 2, 5], [14, 3, 4, 1], [12, 6, 8, 9], [16, 7,10,11]] 解法一: 逆置+转置时间复杂度: $O(n^2)$, 因为转置的复杂度为 $O(n^2)$ 将图像矩阵看做是线性代数中的行列式, 首先将所有的行逆置(行与行交换), 然后对整个矩阵转置. 原理: 利用线性代数行列式的运算法则可证明(数学归纳法) clockwise rotatefirst reverse up to down, then swap the symmetry1231 2 3 7 8 9 7 4 14 5 6 =&gt; 4 5 6 =&gt; 8 5 27 8 9 1 2 3 9 6 3 12345678910class Solution &#123;public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; std::reverse(matrix.begin(), matrix.end()); //逆置 for(int i = 0; i&lt;matrix.size(); i++)&#123; for(int j=i+1; j&lt;matrix[i].size();j++) // 转置, 注意j=i+1 std::swap(matrix[i][j], matrix[j][i]); &#125; &#125;&#125;; 解法二: 转置+列逆置先求转置, 再对列逆置(列与列交换): 1234567891011class Solution &#123;public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; for(int i = 0; i&lt;matrix.size(); i++)&#123; for(int j=i+1; j&lt;matrix[i].size();j++) std::swap(matrix[i][j], matrix[j][i]); &#125; for(auto &amp;vec_i : matrix) std::reverse(vec_i.begin(), vec_i.end()); &#125;&#125;; 补充: 逆时针旋转90度先使用列逆置(列与列交换), 然后对矩阵使用转置 1231 2 3 3 2 1 3 6 94 5 6 =&gt; 6 5 4 =&gt; 2 5 87 8 9 9 8 7 1 4 7 1234567void anti_rotate(vector&lt;vector&lt;int&gt; &gt; &amp;matrix) &#123; for (auto vi : matrix) reverse(vi.begin(), vi.end()); for (int i = 0; i &lt; matrix.size(); ++i) &#123; for (int j = i + 1; j &lt; matrix[i].size(); ++j) swap(matrix[i][j], matrix[j][i]); &#125;&#125; 补充: 图片旋转 180 度(上下翻转)将所有的行逆置1231 2 3 7 8 94 5 6 =&gt; 4 5 67 8 9 1 2 3 1reverse(matrix.begin(), matrix.end()) 补充: 图片左右翻转将所有的列逆置1231 2 3 3 2 14 5 6 =&gt; 6 5 47 8 9 9 8 7 1for (auto vi : matrix) reverse(vi.begin(), vi.end()); 049. Group AnagramsDescription: 找出同字母的异序词, 并按字母分组输出Given an array of strings, group anagrams together. Example: Input: [“eat”, “tea”, “tan”, “ate”, “nat”, “bat”],Output:[ [“ate”,”eat”,”tea”], [“nat”,”tan”], [“bat”]]Note: All inputs will be in lowercase.The order of your output does not matter. 解法一: 哈希表+sort用哈希表来存, 键为有序的字符序列, 值为string数组, 里面存着各个与有序字符序列包含字符相同的其他序列 时间复杂度: $O(nmlogm)$ , 其中, n为输入字符串数组的长度, m为每个字符串的长度, 对于n个字符串, 要进行n次哈希表的插入, 同时每次插入时, 需要对字符串进行排序, 排序复杂度为 $O(mlogm)$. 空间复杂度: $O(mn)$ 123456789101112131415class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; std::unordered_map&lt;string,vector&lt;string&gt;&gt; res_map; for(auto str: strs)&#123; string str_value = str; std::sort(str.begin(), str.end()); res_map[str].push_back(str_value); //key 为字母有序string, value为含有这些字母的序列 &#125; vector&lt;vector&lt;string&gt;&gt; res_vec; for(auto str : res_map) res_vec.push_back(str.second); //将map中的所有的string转移到vec返回结果中 return res_vec; &#125;&#125;; 解法二: 哈希表(不使用sort)时间复杂度: $O(nm)$ , 其中, n为string个数, m为每个string的字母数.空间复杂度: $O(nm)$ 由于上面的解法二需要使用排序, 故而时间上不够优化, 因此, 这里我们可以设计新的键来代替sort, 基本思想是对26个字母, 分别赋予一个素数值, 然后, 计算键的时候, 将对应字母的素数 相乘 即可, 这样一来, 每一种字符串的key都是唯一的( 因为最终的乘积可以唯一的表示成素数相乘的序列 ). 12345678910111213141516171819202122// 该解法是错误的class Solution &#123;public: int primer[26] = &#123;2, 3, 5, 7, 11 ,13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101&#125;; int get_sum_id(string str)&#123; int sum = 1; for(auto c : str)&#123; sum * = primer[(int)(c-'a')]; &#125; return sum; &#125; vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; std::unordered_map&lt;int,vector&lt;string&gt;&gt; res_map; for(auto str: strs)&#123; res_map[get_sum_id(str)].push_back(str); //key 为字母有序string, value为含有这些字母的序列 &#125; vector&lt;vector&lt;string&gt;&gt; res_vec; for(auto str : res_map) res_vec.push_back(str.second); //将map中的所有的string转移到vec返回结果中 return res_vec; &#125;&#125;; 解法三: 另一种生成 key 的解法(不用sort)应该将字符count作为键, 所谓字符count就是统计每个字符出现的次数, 然后根据该信息就可以生成唯一的一个字符串, 例如, 对于 “abbb”, 来说, ‘a’ 出现了一次, ‘b’ 出现了三次, 因此, 其字符count就应该为: (1,3,0,…0), 总共有 26 个元素, 为了将其转换成字符串, 需要用一个特殊符号来做分隔符, 因此可以生成如下的字符串: &quot;#1#3#0#0...#0&quot;(这也是通常的内置 hash 的键的实现方法之一).该解法的时间复杂度为 $O(mn)$, 其中, $n$ 为遍历字符串数组的时间, $m$ 为获取 key 的时间, 无需进行排序. 123456789101112131415161718192021222324class Solution &#123;private: string get_key(string str)&#123; int str_count[26]&#123;0&#125;; for(auto c : str) str_count[c-'a']++; string str_key; for(auto i : str_count) str_key += "#" + to_string(i); return str_key; &#125;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; unordered_map&lt;string, vector&lt;string&gt;&gt; res_hash; for(auto str : strs)&#123; string s = get_key(str); res_hash[s].push_back(str); &#125; vector&lt;vector&lt;string&gt;&gt; res; for(auto s : res_hash) res.push_back(s.second); return res; &#125;&#125;; 050. Pow(x, n)实现幂乘操作 DescriptinImplement pow(x, n), which calculates x raised to the power n (x^n). Example 1: Input: 2.00000, 10Output: 1024.00000Example 2: Input: 2.10000, 3Output: 9.26100Example 3: Input: 2.00000, -2Output: 0.25000Explanation: 2-2 = 1/22 = 1/4 = 0.25Note: -100.0 &lt; x &lt; 100.0n is a 32-bit signed integer, within the range $[−2^{31}, 2^{31} − 1]$ 解法一: 递归时间复杂度: $O(logn)$空间复杂度: $O(1)$ 当n为偶数时: $x^n = x^{n/2} \times x^{n/2}$当n为奇数时: $x^n = x\times x^{n/2} \times x^{n/2}$ 这里需要注意一点: abs(INT_MIN) 的值仍然是负值, 因为 int 只有 32 位, abs(INT_MIN) 时, 仍然是 32 位, 因此不会变成正值, 解决方法是先把该值赋给 long 型变量, 然后对 long 型变量调用 abs() 函数, 另一种解决方法是利用 unsigned int:12345678int min = INT_MIN; // -2147483648long min_abs1 = abs(min); // 2147483648, 这里 min_abs1 的值仍然是 INT_MIN, 因为调用 abs 的时候, 仍然是32位long min_abs2 = min;min_abs2 = abs(min_abs2); // 2147483648, 这里是对64位调用 abs, 所以成功转化成正数// 解决方法二是利用 unsigned intunsigned int abs_min = abs(min) //2147483648 12345678910class Solution &#123;public: double myPow(double x, int n) &#123; if(n==0) return 1.0; unsigned int un = abs(n); //注意这里必须是 unsigned类型, 就算是long , 也必须带unsigned, 主要是因为abs(INT_MIN)仍为负数INT_MIN! if(n &lt; 0) x = 1/x; return (un%2==0) ? myPow(x*x, un/2) : x*myPow(x*x, un/2); &#125;&#125;; 解法二: 非递归时间复杂度: $O(logn)$空间复杂度: $O(1)$ n 要么为偶数, 要么为奇数, 我们每一次都将 n 的值减半, 并且将 x 与自身相乘, 每次当 n 为奇数时, 我们都将 res 与 x 相乘, 最终, res 的值就是我们要求的幂乘. 举例来说,对于 x=2, n=10 , 每次将x和自身相乘, 同时将 n 减半, n 和 x 的值分别为:12n: 10, 5, 2, 1, 0x: 2, 4, 16, 256, 65536 可以看到, 我们将 n 为奇数时的 x 相乘, 就是最终的幂乘: $4\times 256 = 2^{10} = 1024$. 当 n 为奇数时也是同理, 如下所示: 12n: 11, 5, 2, 1, 0x: 2, 4, 16, 256, 65536 最终幂乘: $2\times 4\times \times 256 = 2^{11} = 2048$ 123456789101112131415class Solution &#123;public: double myPow(double x, int n) &#123; if(n&lt;0) x = 1/x; long ln = n; ln = abs(ln); double res=1; while(ln&gt;0)&#123; if(ln%2==1) res = res * x; x = x * x; ln = ln/2; &#125; return res; &#125;&#125;; 053. Maximum Subarray连续子数组的最大和 DescriptionGiven an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum. Example: Input: [-2,1,-3,4,-1,2,1,-5,4],Output: 6Explanation: [4,-1,2,1] has the largest sum = 6.Follow up: If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle. 解法: 记录当前最大值时间复杂度: $O(n)$根据数组性质, 设置两个变量, 一个记录当前的最大值, 一个记录当前的子序列之和. 首先, 如果当前子序列之和为负, 那么就是说, 从当前位置开始的子序列, 比从之前位置开始的子序列大, 那么就可以不考虑从之前位置开始的子序列, 之前累计的和也被抛弃 1234567891011121314class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; int sum = 0; int max_sum = INT_MIN; //数组有可能全负, 所以不能赋值为0 for(auto num : nums)&#123; if(num &gt; max_sum) max_sum = num; //主要是为了预防数组中全是负数的情况 sum += num; if(sum!=0 &amp;&amp; sum&gt;max_sum) max_sum = sum; // sum!=0 , 为了预防数组全负时, 0一定大于sum, 造成的错解 if(sum &lt;0) sum =0; &#125; return max_sum; &#125;&#125;; 更简洁的写法: 1234567891011121314151617class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) return 0; int tmpRes = nums[0]; int res = nums[0]; for (int i = 1; i &lt; nums.size(); i++) &#123; if (tmpRes &lt; 0) &#123; tmpRes = nums[i]; &#125; else &#123; tmpRes += nums[i]; &#125; res = std::max(res, tmpRes); &#125; return res; &#125;&#125;; 054. Spiral Matrix以顺时针螺旋顺序返回矩阵元素, 顺时针打印矩阵 DescriptionGiven a matrix of m x n elements (m rows, n columns), return all elements of the matrix in spiral order. Example 1: Input:[ [ 1, 2, 3 ], [ 4, 5, 6 ], [ 7, 8, 9 ]]Output: [1,2,3,6,9,8,7,4,5]Example 2: Input:[ [1, 2, 3, 4], [5, 6, 7, 8], [9,10,11,12]]Output: [1,2,3,4,8,12,11,10,9,5,6,7] 解法: 按层次输出(由外而内)时间复杂度: $O(n)$空间复杂度: $O(n)$ 输出形式如下(按层次编码, 以4×6的矩阵为例), 需要注意边界控制条件: \begin{matrix} 1_{top}&1_{top}&1_{top}&1_{top}&1_{top}&1_{top} \\ 1_{left}&2_{top}&2_{top}&2_{top}&2_{top}&1_{right} \\ 1_{left}&2_{bottom}&2_{bottom}&2_{bottom}&2_{bottom}&1_{right} \\ 1_{bottom}&1_{bottom}&1_{bottom}&1_{bottom}&1_{bottom}&1_{bottom} \end{matrix}12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; res; if(matrix.size()==0 || matrix[0].size() ==0) return res; int row_layer = (matrix.size()+1)/2; int col_layer = (matrix[0].size()+1)/2; int layer = min( row_layer, col_layer); // 计算总共的层数 int cur_layer =0; // 用于记录当前所处哪一层 int len_row = matrix.size(); int len_col = matrix[0].size(); //分别为行和列的size while(cur_layer &lt; layer)&#123; //top 输出上边 for(int j =cur_layer; j&lt;len_col-cur_layer; j++) res.push_back(matrix[cur_layer][j]); //right 输出右边 for(int i = cur_layer+1; i&lt;len_row-1-cur_layer; i++) res.push_back(matrix[i][len_col - 1 - cur_layer]); //bottom 输出下边, 这里注意为了防止重复输出, 需要确保上边和下边的行数不同,即: // cur_layer!=len_row-1-cur_layer for(int j= len_col - 1 -cur_layer; cur_layer!=len_row-1-cur_layer &amp;&amp; j &gt;=cur_layer ;j--) res.push_back(matrix[len_row - 1 -cur_layer][j]); //left 输出左边, 同样, 要确保左边和右边的列数不同, 即: cur_layer!=len_col-1-cur_layer for(int i = len_row-2-cur_layer; cur_layer!=len_col-1-cur_layer &amp;&amp; i&gt;cur_layer; i--) res.push_back(matrix[i][cur_layer]); cur_layer++; &#125; return res; &#125;&#125;; 另一种写法:12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; std::vector&lt;int&gt; res; if (matrix.empty() or matrix[0].empty()) return res; int n = matrix.size(); int m = matrix[0].size(); int rowUp = -1; // 记录上边界 int rowDown = n; // 下边界 int colLeft = -1; // 左边界 int colRight = m; // 右边界 while (rowUp &lt; rowDown and colLeft &lt; colRight) &#123; rowUp++; rowDown--; if (rowUp &gt; rowDown) break; // 如果越界, 则直接退出 colLeft++; colRight--; if (colLeft &gt; colRight) break; // 越界则退出 for (int j = colLeft; j &lt;= colRight; j++) &#123; res.emplace_back(matrix[rowUp][j]); &#125; for (int i = rowUp+1; i &lt;= rowDown-1; i++) &#123; res.emplace_back(matrix[i][colRight]); &#125; for (int j = colRight; rowUp != rowDown and j &gt;= colLeft; j--) &#123; res.emplace_back(matrix[rowDown][j]); &#125; for (int i = rowDown-1; colLeft != colRight and i &gt;= rowUp+1; i--) &#123; res.emplace_back(matrix[i][colLeft]); &#125; &#125; return res; &#125;&#125;; 055. Jump Game数组的数字为最大的跳跃步数, 根据数组判断是否能跳到最后一位上 DescriptionGiven an array of non-negative integers, you are initially positioned at the first index of the array. Each element in the array represents your maximum jump length at that position. Determine if you are able to reach the last index. Example 1: Input: [2,3,1,1,4]Output: trueExplanation: Jump 1 step from index 0 to 1, then 3 steps to the last index.Example 2: Input: [3,2,1,0,4]Output: falseExplanation: You will always arrive at index 3 no matter what. Its maximum jump length is 0, which makes it impossible to reach the last index. 解法一: 回溯时间复杂度: $O(2^n)$ 总共有 $2^n$ 种跳法来跳到最后一个位置上(对于任意一个位置, 有经过和不经过两个种可能性)空间复杂度: $O(n)$ 试遍所有的可能性, 正常来说会超时, 并且也肯定不是最佳答案 123456789101112131415161718class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; return helper(nums, 0); &#125; bool helper(vector&lt;int&gt; &amp;nums, int position)&#123; int final_position = nums.size()-1; if(position == final_position) return true; int furthest = std::min(position+nums[position], final_position); for(int i = position+1; i&lt;=furthest; i++)&#123; //这里有个小小的优化, 就是令i从最大步长开始, i--, 这种优化虽然最坏情况时一样的 //但在实际使用中, 会比从position+1开始要快一点(但是依然超时) if(helper(nums, i)) return true; &#125; return false; &#125;&#125;; 解法二: top-down 动态规划(递归)时间复杂度: $O(n^2)$ , 对于每个点来说, 都是要找到下一个good_position, 则需要进行 $(O)$ 的查找, 又因为总共有 $O(n)$个元素, 所以复杂度为 $O(n^2)$.空间复杂度: $O(2n)$, 递归需要 $O(n)$ , memo需要 $O(n)$. 设计一个数组, 用来记录当前下标对应位置是否可又达到终点, 如果能, 则该位置为good position, 如果不能, 则为bad position, 刚开始的时候都是unknown position(除了最后一个位置为good). 123456789101112131415161718192021222324class Solution &#123;public: enum class Status&#123;GOOD, BAD, UNKNOWN&#125;; bool canJump(vector&lt;int&gt;&amp; nums) &#123; vector&lt;Status&gt; memo; for(int i=0; i&lt;nums.size()-1; i++) memo.push_back(Status::UNKNOWN); memo.push_back(Status::GOOD); return helper(nums, memo, 0); &#125; bool helper(vector&lt;int&gt; &amp;nums, vector&lt;Status&gt; &amp;memo, int position)&#123; int final_position = nums.size()-1; if(memo[position] != Status::UNKNOWN) return memo[position]==Status::GOOD ? true : false; int furthest = std::min(position+nums[position], final_position); for(int i = furthest; i&gt;position; i--)&#123; if(helper(nums, memo, i))&#123; memo[position] = Status::GOOD; //注意是position, 不是i return true; &#125; &#125; memo[position] = Status::BAD; return false; &#125;&#125;; 解法三: down-top 动态规划(非递归)时间复杂度: $O(n^2)$ , 对于每个点来说, 都是要找到下一个good_position, 则需要进行 $(O)$ 的查找, 又因为总共有 $O(n)$个元素, 所以复杂度为 $O(n^2)$.空间复杂度: $O(n)$, 无需递归 , 只需要memo, $O(n)$. 动态规划的非递归版本. 1234567891011121314151617181920212223class Solution &#123;public: enum class Status&#123;GOOD, BAD, UNKNOWN&#125;; bool canJump(vector&lt;int&gt;&amp; nums) &#123; //if(nums.size() ==0) return false; vector&lt;Status&gt; memo; for(int i=0; i&lt;nums.size()-1; i++) memo.push_back(Status::UNKNOWN); memo.push_back(Status::GOOD); int final_position = nums.size()-1; for(int i=nums.size()-2; i&gt;=0; i--)&#123; int furthest = std::min(i+nums[i], final_position); //for(int j = i+1; j&lt;=furthest; j++)&#123; for(int j = furthest; j&gt;i;j--)&#123; if(memo[j] == Status::GOOD)&#123; // 只要有一个GOOD, 当前i位置就为GOOD, 而无需考虑BAD的情况 memo[i] = memo[j]; break; &#125; &#125; &#125; return memo[0] == Status::GOOD ? true : false; &#125;&#125;; 解法四: 贪心时间复杂度: $O(n)$空间复杂度: $O(1)$ 由上面的down-top递归可以看出, 当前下标位置的点是否为good点, 实际上只取决于当前点是否能够达到右边坐标中(从右往左走)最左边的good(可以看上面的break语句), 如果能够达到, 则当前点一定为good点, 因此, 我们只需要用一个变量left_most_good来维护当前点右边的最左good点下标即可, 无需任何其他空间和操作.(速度极快) 123456789101112class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; int left_most_good = nums.size()-1; for(int i = nums.size()-2; i&gt;=0; i--)&#123; if(i+nums[i] &gt;= left_most_good)&#123; left_most_good = i; &#125; &#125; return left_most_good==0; &#125;&#125;; 另一种贪心的形式: 记录当前能够达到的最大位置 123456789class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; int i =0; for(int reach=0; i&lt;nums.size() &amp;&amp; i&lt;=reach; i++ ) reach = max(i+nums[i], reach); return i==nums.size(); // 或者用 reach &gt;= nums.size()-1 判断 &#125;&#125;; 056. Merge Intervals融合区间 DescriptionGiven a collection of intervals, merge all overlapping intervals. Example 1: Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6].Example 2: Input: [[1,4],[4,5]]Output: [[1,5]]Explanation: Intervals [1,4] and [4,5] are considerred overlapping. 解法一: sort+O(n)时间复杂度: $O(nlogn)$, 主要是排序空间复杂度: $O(n)$ 最简单的实现方法, 先按照interval.start用sort排序, 排好序以后, 能够融合的interval都会聚到一起, 这个时候, 因为start是呈递增的, 只需要看end的大小关系就可以. 最简单的实现方法就是sort之后, 通过额外申请空间来存储融合后的interval, 最后返回 1234567891011121314class Solution &#123;public: vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; if(intervals.size()==0) return vector&lt;Interval&gt;&#123;&#125;; vector&lt;Interval&gt; res; std::sort(intervals.begin(), intervals.end(), [](Interval a, Interval b)&#123;return a.start &lt; b.start;&#125;); res.push_back(intervals[0]); for(auto iv : intervals)&#123; if(res.back().end &lt; iv.start) res.push_back(iv); else res.back().end = std::max(res.back().end, iv.end); &#125; return res; &#125;&#125;; 解法二: sort+O(1)时间复杂度: $O(nlogn)$ , 主要是排序空间复杂度: $O(1)$ 上面的方法在逻辑上不够好, 因为既然已经申请了额外的内存来存储放回结果, 说明我们不希望改变原vector内部的数据, 但是sort之后, 数据顺序已经被破坏了, 既然已经破坏了, 那最好就是直接使用原地融合的办法, 来减少内存的开销1234567891011121314151617181920class Solution &#123;public: vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; if(intervals.size()==0) return vector&lt;Interval&gt;&#123;&#125;; //vector&lt;Interval&gt; res; 既然决定使用sort, 就说明已经改变了intervals, 此时不应该在额外申请空间, 而应该进行原地融合. std::sort(intervals.begin(), intervals.end(), [](Interval a, Interval b)&#123;return a.start &lt; b.start;&#125;); auto cur_iv = intervals.begin(); auto next_iv = intervals.begin()+1; for(; next_iv!=intervals.end(); next_iv++)&#123; if( (*cur_iv).end &lt; (*next_iv).start )&#123; cur_iv++; (*cur_iv) = (*next_iv); &#125;else&#123; (*cur_iv).end = std::max( (*cur_iv).end, (*next_iv).end ); &#125; &#125; intervals.erase(cur_iv+1, intervals.end()); return intervals; &#125;&#125;; 解法三: 不使用sort有时, 我们要求不能改变原向量intervals的内容, 此时, 就不能使用sort (除非牺牲大量空间留副本,但单肯定不推荐). //TODO, 未细看, 但时间复杂度应该会高于 O(nlogn)https://leetcode.com/problems/merge-intervals/discuss/153979/Elegant-c++-solutions.-One-without-modifying-intervals-and-one-inplace123456789101112131415161718192021222324252627Without modifying intervalsSince we can't sort interval, we want to instead ensure our destination vector is sorted. A insertion sort is required then. Insertion should be done as follows;Find first destination interval that ends after the incoming interval starts. Called itIf no such interval is found or the incoming interval end is less than found intervals start then we can just insert and be done.Otherwise there must be an overlap, but it could be more than one. Do another search, this time for the first interval whose start is greater than incoming interval end. Called lastEverything from [it, last) can be merged together with incoming interval into a single interval vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; std::vector&lt;Interval&gt; ret; for (auto&amp; interval : intervals) &#123; auto it = std::lower_bound(ret.begin(), ret.end(), interval.start, [](const Interval&amp; l, int r) &#123; return l.end &lt; r; &#125;); if (it == ret.end() || interval.end &lt; it-&gt;start) // No overlap, insert as is ret.insert(it, interval); else &#123; // There is an overlap, there might be more, so find the upper bound too it-&gt;start = std::min(it-&gt;start, interval.start); auto last = std::upper_bound(it, ret.end(), interval.end, [](int l, const Interval&amp; r) &#123; return l &lt; r.start; &#125;); it-&gt;end = std::max((last - 1)-&gt;end, interval.end); ret.erase(it + 1, last); &#125; &#125; return ret; &#125; 062. 不同路径题目链接: https://leetcode-cn.com/problems/unique-paths/ DescriptionA robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below). The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below). How many possible unique paths are there? 解法一: DP时间复杂度: $O(mn)$空间复杂度: $O(mn)$ 这是一道经典的DP问题, 当机器人处于某一点时, 它只能从上面或者左边到达该点, 因此很容易得出path[i][j] = path[i-1][j] + path[i][j-1];, 其中 path[i][j]指到达 $(i,j)$ 点的可能路径数量. 123456789101112class Solution &#123;public: int uniquePaths(int m, int n) &#123; vector&lt;vector&lt;int&gt;&gt; path(m, vector&lt;int&gt;(n,1)); for(int i = 1 ;i&lt;m; i++)&#123; for(int j=1 ; j&lt;n; j++)&#123; path[i][j] = path[i-1][j] + path[i][j-1]; &#125; &#125; return path[m-1][n-1]; &#125;&#125;; 解法二: 优化的DP时间复杂度: $O(mn)$空间复杂度: $O(n)$ 通过分析知道, 当前点的可能路径数量只与上面点和左边点的值有关, 在上面的方法中, 我们用一个 $m\times n$ 的数组来存储当前点上面和左边的值, 实际上, 我们 只需要用一行数组 就可以完成这个功能, 首先, 求出第一行的所有点的值, 这里只会用每个点左边的值, 然后, 对于第二行的第一个点来说, 它只会用到上面的值, 也就是第一行的第一个值, 因此可以通过行数组直接得到, 然后, 对于第二行的第二个值, 它可以从第二行的第一个值, 以及第二行的第二个值得到, 这些值都是已知的, 所以可以直接求的, 由于在求得以后, 我们就再也不需要第一行的第二个值了, 所以我们可以用这个存储空间来存储第二行的第二个值, 如此递归执行, 我们只需要 $O(n)$ 的空间即可. Python 实现:1234567class Solution: def uniquePaths(self, m: int, n: int) -&gt; int: dp = [1] * n for i in range(1, m): for j in range(1, n): dp[j] = dp[j] + dp[j-1] return dp[-1] 123456789101112class Solution &#123;public: int uniquePaths(int m, int n) &#123; vector&lt;int&gt; path(n,1); for(int i = 1; i&lt;m; i++)&#123; for(int j = 1; j&lt;n; j++)&#123; path[j] = path[j] + path[j-1]; &#125; &#125; return path[n-1]; &#125;&#125;; 解法三: 排列组合(最优)时间复杂度: $O(n)$空间复杂度: $O(1)$ 实际上, 仔细分析该问题, 可以把该问题看成是一个典型的排列组合问题. 首先, 将机器人向右走记为 1, 将机器人向下走记为 0. 题目问有多少种不同的走法, 实际上就是在问1/0序列的不同排列有多少种, 并且, 1/0 的长度必须为 $(m -1 + n - 1)$. 因此, 这个问题可以看做是从 $(m-1+n-1)$ 个空槽位上选择 $(m-1)$ 个槽位, 将其置为1, 并将剩余的 $n-1$ 个槽位置为0, 故而就是组合问题: $C_{m-1+n-1}^{m-1}$ . 又因为 $C_{m-1+n-1}^{m-1} = C_{m-1+n-1}^{n-1}$ , 所以为了防止溢出, 我们可以选择小的进行计算 注意, 在排列如何时, 因为涉及到除法, 所以一定要注意计算法则的先后顺序, 具体请看代码 C++ 实现1234567891011class Solution &#123;public: int uniquePaths(int m, int n) &#123; long res = 1; //需要注意的是, 由于下面的计算操作是会有先乘一个数, 再初以一个数的操作, 因此很有可能乘完后超过int上限, 所以需要声明为long整型 for(int i = 1; i&lt; std::min(m,n); i++)&#123; res = res * (m-1+n-1 - i+1) / i; // 这里如果写成 res *= (m-1+n-1+i+1) / i, 则会报错, 因为这样会先计算除法, 这样有可能会出现浮点数, 但是排列组合是不会出现浮点数的, 切记! &#125; return res; &#125;&#125;; Python 实现123456class Solution: def uniquePaths(self, m: int, n: int) -&gt; int: res = 1 for i in range(1, min(m, n)): res = res * (m-1+n-1 - i+1) / (i) return int(res) 直接调用 scipy 计算包:12from scipy.special import comb, perm # comb 组合, perm 排序return comb(m-1+n-1, min(m, n) - 1) 迭代器(超时):123456class Solution: def uniquePaths(self, m: int, n: int) -&gt; int: from itertools import combinations data = range(m-1+n-1) combs = (combinations(data, min(m, n)-1)) # 返回一个迭代器 return sum(1 for _ in combs) # 注意, 迭代器迭代一轮就停止了, 不会重新回到头部, 即不能重复使用 063. 不同路径 II解法: 动态规划设置 dp 数组, 由于只需要上方和左方的元素, 因此 dp 数组可以只设为 2 x n 的大小, dp 数组中的值代表走到当前点总共的路径数. 12345678910111213141516class Solution: def uniquePathsWithObstacles(self, obstacleGrid: List[List[int]]) -&gt; int: if len(obstacleGrid) == 0: return 0 length = len(obstacleGrid[0]) dp = [[0] * (length+1), [0] * (length+1)] if obstacleGrid[0][0] != 1: dp[0][0] = 1 for i in range(len(obstacleGrid)): for j in range(len(obstacleGrid[0])): if obstacleGrid[i][j] == 1: dp[1][j] = 0 continue dp[1][j] = dp[1][j-1] + dp[0][j] dp = dp[::-1] return dp[0][-2] # 注意, 这里由于上面替换了 dp 的 0 和 1, 所以结果存在 dp[0] 中, 而不是 dp[1] 中 解法二: 空间优化的动态规划实际上, 并不需要 2xn 大小的数组, 只需要一个 n 长度的一维数组就够了, 思路和 62 题一直, 具体实现如下所示:1234567891011121314class Solution: def uniquePathsWithObstacles(self, obstacleGrid: List[List[int]]) -&gt; int: if len(obstacleGrid) == 0: return 0 m = len(obstacleGrid) n = len(obstacleGrid[0]) dp = [0] * n for i in range(m): for j in range(n): if obstacleGrid[i][j] == 1: dp[j] = 0 elif i == 0 and j == 0: dp[j] = 1 elif j == 0: dp[j] = dp[j] elif i == 0: dp[j] = dp[j-1] else: dp[j] = dp[j] + dp[j-1] return dp[-1] 064. 最小路径和题目链接: https://leetcode-cn.com/problems/minimum-path-sum/ 解法: 动态规划申请dp[2][n]数组, dp[1][j]代表走到grid[i][j]所需的最小步数. 1234567891011121314151617#sys.maxintclass Solution: def minPathSum(self, grid: List[List[int]]) -&gt; int: if (len(grid) == 0): return 0 m = len(grid) n = len(grid[0]) dp = [[0] * n, [0] * n] for i in range(m): for j in range(n): if j == 0: dp[1][j] = dp[0][j] + grid[i][j] elif i == 0: dp[1][j] = dp[1][j-1] + grid[i][j] else: dp[1][j] = min(dp[0][j], dp[1][j-1]) + grid[i][j] dp = dp[::-1] return dp[0][n-1] # 由于上面dp[::-1]交换了顺序, 所以最终的结果存在dp[0]当中 解法: 动态规划空间复杂度优化实际上, 当前点只依赖与前一个点和上一个点的值, 因此, 我们可以通过一个以为数组就能够存储足够的信息, 故而可以将空间占用量减半 123456789101112131415class Solution: def minPathSum(self, grid: List[List[int]]) -&gt; int: if (len(grid) == 0): return 0 m = len(grid) n = len(grid[0]) dp = [0] * n for i in range(m): for j in range(n): if j == 0: dp[j] = dp[j] + grid[i][j] elif i == 0: dp[j] = dp[j-1] + grid[i][j] else: dp[j] = min(dp[j], dp[j-1]) + grid[i][j] return dp[n-1] # 由于上面dp[::-1]交换了顺序, 所以最终的结果存在dp[0]当中 066. Plus One数组代表一个整数, 模拟整数的加法 DescriptionGiven a non-empty array of digits representing a non-negative integer, plus one to the integer. The digits are stored such that the most significant digit is at the head of the list, and each element in the array contain a single digit. You may assume the integer does not contain any leading zero, except the number 0 itself. Example 1: Input: [1,2,3]Output: [1,2,4]Explanation: The array represents the integer 123.Example 2: Input: [4,3,2,1]Output: [4,3,2,2]Explanation: The array represents the integer 4321. 解法一: 直接模拟时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt;&amp; digits) &#123; int carry = 0, last_i = digits.size()-1; digits[last_i] += 1; if(digits[last_i] &gt; 9) &#123; digits[last_i] = 0; carry=1; &#125; for(int i = last_i-1; i&gt;=0 &amp;&amp; carry ; i--)&#123; digits[i] += carry; if(digits[i] &gt; 9) digits[i] = 0; else carry = 0; &#125; if(carry == 1) digits.insert(digits.begin(), 1); return digits; &#125;&#125;; 另一种写法:12345678910111213141516class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt;&amp; digits) &#123; int carry = 0; int one = 1; int cur = digits.size()-1; for(int cur=digits.size()-1; cur&gt;=0; cur--)&#123; digits[cur] += one + carry; one = 0; carry = digits[cur] / 10; digits[cur] = digits[cur] % 10; &#125; if(carry) digits.insert(digits.begin(), 1); return digits; &#125;&#125;; 解法二: 不使用加法(更快更简单, 击败100%)123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt; &amp;digits) &#123; //未考虑前缀0的情况 for(int i = digits.size() - 1; i &gt;= 0; i--) &#123; if(digits[i] != 9) &#123; digits[i] ++; break; &#125; digits[i] = 0; &#125; if(digits[0] == 0) digits.insert(digits.begin(), 1); return digits; &#125;&#125;; 069. Sqrt(x)实现开方算法 DescriptionImplement int sqrt(int x). Compute and return the square root of x, where x is guaranteed to be a non-negative integer. Since the return type is an integer, the decimal digits are truncated and only the integer part of the result is returned. Example 1:12Input: 4Output: 2 Example 2:123Input: 8Output: 2Explanation: The square root of 8 is 2.82842..., and since the decimal part is truncated, 2 is returned. 解法一: 二分法时间复杂度: $O(logn)$空间复杂度: $O(1)$ 123456789101112131415161718class Solution &#123;public: int mySqrt(int x) &#123; double low=0, high=x; double res = high; while( std::abs(res*res - x) &gt; 0.00001 )&#123; if(res*res &gt; x)&#123; high = res; res = (low+high)/2; &#125;else&#123; low = res; res = (low+high)/2; &#125; &#125; if(ceil(res)*ceil(res)==x) return ceil(res); // 为了能够正确截断, 必须加上此句 return int(res); &#125;&#125;; 解法二: 牛顿迭代法时间复杂度: $O(logn)$空间复杂度: $O(1)$ 相当于求解 $f(res)=res^2 - x = 0$ 中 $res$ 的解. 则对于任意一点 $(res, f(res))$, 都有切线方程: f(res) - 0 = f'(res)(res-res')其中, $res’$ 是该直线与 $x$ 轴的交点. 令新的 $res$ 为该值, 就可以不断逼近 $f(res)$ 的零点, $res’$ 的值为: res' = res- \frac{f(res)}{f'(res)} = res- \frac{res^2-x}{2\times res} = \frac{res^2 + x}{2\times res}1234567891011class Solution &#123;public: int mySqrt(int x) &#123; double res = x; while( std::abs(res*res - x) &gt; 0.00001 )&#123; res = (res*res+x) / (2*res); &#125; if(ceil(res)*ceil(res)==x) return ceil(res); // 为了能够正确截断, 必须加上此句 return int(res); &#125;&#125;; 解法三: 按位检索时间复杂度: $O(logn)$空间复杂度: $O(1)$ 由于本题要返回的是整数, 而上面的两种方法都是针对double类型的精确开根方法, 时间复杂度为 $O(logn)$, 实际上, 当只需要返回整数时, 我们可以按整数的位进行检索, 而整数总共只有32位(传入的x位int型, 所以开根后不可能超过int), 因此时间复杂度只有 $O(32)$ , 也就是 $O(1)$. 注意: 由于该方法是首先找到比 x 大的那一位, 因此有可能超过int上限, 所以要换成long整型 找到后依然需要进行二分查找来找到最终的返回值 12345678910111213141516class Solution &#123;public: int mySqrt(int x) &#123; long res=0; int h=0; while( long(1&lt;&lt;h) * long(1&lt;&lt;h) &lt;= x) h++; long b = 1&lt;&lt;(h-1); while( b &gt; 0)&#123; if( (res+b) * (res+b) &lt;= x) res += b; b = b/2; &#125; return res; &#125;&#125;; 070. Climbing Stairs实际上就是斐波那契数列, 更具体分析可看牛客的跳台阶 DescriptionYou are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Note: Given n will be a positive integer. Example 1: Input: 2Output: 2Explanation: There are two ways to climb to the top. 1 step + 1 step 2 stepsExample 2: Input: 3Output: 3Explanation: There are three ways to climb to the top. 1 step + 1 step + 1 step 1 step + 2 steps 2 steps + 1 step 解法一: 递归解法二: 迭代123456789101112131415class Solution &#123;public: int climbStairs(int n) &#123; if(n==0) return 0; if(n==1) return 1; int n1 = 1; int n2 = 2; for(int i=3; i&lt;=n; i++)&#123; int temp = n2; n2 = n1+n2; n1 = temp; &#125; return n2; &#125;&#125;; 073. Set Matrix ZeroesDescriptionGiven a m x n matrix, if an element is 0, set its entire row and column to 0. Do it in-place. Example 1: Input:[ [1,1,1], [1,0,1], [1,1,1]]Output:[ [1,0,1], [0,0,0], [1,0,1]]Example 2: Input:[ [0,1,2,0], [3,4,5,2], [1,3,1,5]]Output:[ [0,0,0,0], [0,4,5,0], [0,3,1,0]]Follow up: A straight forward solution using O(mn) space is probably a bad idea.A simple improvement uses O(m + n) space, but still not the best solution.Could you devise a constant space solution? 解法一: 穷举时间复杂度: $O(nm)$空间复杂度: $O(nm)$ 记录所有出现0的位置, 然后根据这些位置坐标将对应的行和列上的值置为0. 12345678910111213141516171819202122232425class Solution &#123;public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; rows; vector&lt;int&gt; cols; for(int i=0; i&lt;matrix.size(); i++)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; if(matrix[i][j] == 0)&#123; rows.push_back(i); cols.push_back(j); &#125; &#125; &#125; for(auto i:rows)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; matrix[i][j] = 0; &#125; &#125; for(auto j:cols)&#123; for(int i=0; i&lt;matrix.size(); i++)&#123; matrix[i][j] = 0; &#125; &#125; &#125;&#125;; 解法二: 穷举(减少空间复杂度)时间复杂度: $O(nm)$空间复杂度: $O(n+m)$ 上面在记录位置坐标时没有进行重复检查, 实际上, 对于已经记录过的行或列, 可以不用再记录, 此时, 空间复杂度可以降为 $O(m+n)$. 1234567891011121314151617181920212223242526class Solution &#123;public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; rows; vector&lt;int&gt; cols; for(int i=0; i&lt;matrix.size(); i++)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; if(matrix[i][j] == 0)&#123; // 记录行或列坐标之前先进行重复检查 if(std::count(rows.begin(), rows.end(), i)==0) rows.push_back(i); if(std::count(cols.begin(), cols.end(), j)==0) cols.push_back(j); &#125; &#125; &#125; for(auto i:rows)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; matrix[i][j] = 0; &#125; &#125; for(auto j:cols)&#123; for(int i=0; i&lt;matrix.size(); i++)&#123; matrix[i][j] = 0; &#125; &#125; &#125;&#125;; 解法三: 穷举(无空间复杂度)时间复杂度: $O(nm\times (m+n))$空间复杂度: $O(1)$ 遍历矩阵时, 如果遇到 $(i,j)$ 上的值为0, 那么就将对应的行和列上的所有非0值全部置为一个矩阵范围外的值NAN(解答里面用的是-100000, 实际上这种解法存在问题, 因为理论上矩阵中的元素可以是表示范围内的任何值 ). 之后将所有的NAN值置为0, 就可以完成置0任务, 并且没有使用额外的空间. 由于每次找到一个0时, 都要遍历这个位置上的行和列, 因此时间复杂度较高 解法四: 用第一行和第一列记录时间复杂度: $O(nm)$空间复杂度: $O(1)$ 用第一行和第一列的值记录是否应该将对应的行和列置为0, 此时由于第一行和第一列被用作了标记数组, 因此第一行和第一列的0不能用来判断是否应该置为全0, 所以需要额外设置两个变量记录.1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; bool is_row=false, is_col = false; // 用第一行和第一列的值来做标记, 因此需要额外的记录第一行和第一列本身是有应该全0 for(int i=0; i&lt;matrix.size(); i++)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; if(matrix[i][j] == 0)&#123; if(i==0) is_row=true; if(j==0) is_col=true; matrix[i][0] = 0; matrix[0][j] = 0; &#125; &#125; &#125; for(int i=1; i&lt;matrix.size(); i++)&#123; if(matrix[i][0]!=0) continue; for(int j=0; j&lt;matrix[0].size(); j++)&#123; matrix[i][j] = 0; &#125; &#125; for(int j=1; j&lt;matrix[0].size(); j++)&#123; if(matrix[0][j]!=0) continue; for(int i=0; i&lt;matrix.size(); i++)&#123; matrix[i][j] = 0; &#125; &#125; if(is_row)&#123; //需要特别判断第一行和第一列是否应该置为0 for(int j=0; j &lt;matrix[0].size();j++) matrix[0][j]=0; &#125; if(is_col)&#123; for(int i=0; i&lt; matrix.size(); i++) matrix[i][0]=0; &#125; &#125;&#125;; 075. Sort Colors对0,1,2 (颜色: RGB) 进行排序 DescriptionHere, we will use the integers 0, 1, and 2 to represent the color red, white, and blue respectively. Note: You are not suppose to use the library’s sort function for this problem. Example: Input: [2,0,2,1,1,0]Output: [0,0,1,1,2,2]Follow up: A rather straight forward solution is a two-pass algorithm using counting sort.First, iterate the array counting number of 0’s, 1’s, and 2’s, then overwrite array with total number of 0’s, then 1’s and followed by 2’s.Could you come up with a one-pass algorithm using only constant space? 解法一: 两次遍历时间复杂度: $O(n)$空间复杂度: $O(1)$ 第一次遍历统计0,1,2的个数, 第二次遍历根据0,1,2的个数覆盖数组原有值 解法二: 一次遍历时间复杂度: 大于 $O(n)$空间复杂度: $O(1)$ 设置mid, low, high三个指示变量, 如果mid==0, 则将其与low交换, 如果mid==2, 则将其与high交换, 直到mid&gt;high为止. 12345678910111213141516class Solution &#123;public: void sortColors(vector&lt;int&gt;&amp; nums) &#123; int low=0, mid=0, high=nums.size()-1; while(mid&lt;=high)&#123; if(nums[mid]==2) std::swap(nums[mid], nums[high--]); else if(nums[mid]==0) std::swap(nums[mid++], nums[low++]); //这里 mid 可以直接++ 的原因是因为mid已经将0和2的情况进行处理, // 所以现在 low 指向的值只可能是 1, 因此交换后无需再对nums[mid]判断, 直接++即可 else mid++; &#125; &#125;&#125;; 076. Minimum Window Substring求包含子串字符的最小窗口 DescriptionGiven a string S and a string T, find the minimum window in S which will contain all the characters in T in complexity O(n). Example: Input: S = “ADOBECODEBANC”, T = “ABC”Output: “BANC”Note: If there is no such window in S that covers all characters in T, return the empty string “”.If there is such window, you are guaranteed that there will always be only one unique minimum window in S. 解法: 两个变量记录当前窗口大小时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617181920class Solution &#123;public: string minWindow(string s, string t) &#123; vector&lt;int&gt; hmap(256,0); for(auto c:t) hmap[int(c)]++; int count = t.size(), begin=0, end=0, head=0, cur_window=INT_MAX; while(end&lt;s.size())&#123; // 这里可以直接写成 if(hmap[int(s[end++])]-- &gt; 0) count--; 但是可读性很差, 不建议这样写. if(hmap[int(s[end])] &gt; 0) count--; hmap[int(s[end])]--; end++; while(count==0)&#123; //end 超尾 if( (end-begin) &lt; cur_window) cur_window = end - (head=begin); // 同样, 可以直接写成 if(hmap[int(s[begin++])]++ &gt; 0) count++; 但是可读性很差 if(hmap[int(s[begin])] == 0) count++; hmap[int(s[begin])]++; begin++; &#125; &#125; return cur_window==INT_MAX ? "" : s.substr(head, cur_window); &#125;&#125;; 子串相关题目的模板解法https://leetcode.com/problems/minimum-window-substring/discuss/26808/Here-is-a-10-line-template-that-can-solve-most-&#39;substring&#39;-problems 对于大多数的子串相关的问题, 通常可以描述为给定一个字符串, 要求找到满足某些限制条件的子串, 这类都可以用下面的基于哈希表和两个辅助指示变量的模板来求解: 123456789101112131415161718192021int findSubstring(string s)&#123; vector&lt;int&gt; hmap(128,0); int count; // 用于检查子串是否合法 int begin=0, end=0; // 两个指示变量, 分别指向子串的头和尾(end会在++后退出循环, 因此最后end会变成超尾) int len_sub; // 子串的长度 for()&#123; &#125;//对hasp map进行初始化 while(end&lt;s.size())&#123; //if(hmap[s[end++]]-- ? ) &#123; &#125; //修改count //上面的语句可读性很差, 最后拆开来写, 后面也同理, 拆开写 if(hmap[int(s[end])] ? ) &#123; &#125; //修改count hmap[int(s[end])]--; //注意顺序 end++; while( count? )&#123; // 检查count是否满足条件 // update len_sub if(hmap[int(s[begin])] ?) &#123; &#125; //修改count hmap[int(s[begin])]++; begin++; &#125; &#125;&#125; 例如, 对于问题 Longest Substring At Two Distinct Characters 的模板解法如下: 对于问题 Longest Substring Without Repeating Characters 的模板解法如下:12345678910int lengthOfLongestSubstring(string s)&#123; vector&lt;int&gt; map(256,0); int begin=0,end=0,len_sub=0,count=0; while(end&lt;s.size())&#123; if(map[int(s[end])] &gt; 0) count++; map[int(s[end])]++; end++; while(count&gt;0) if(map[int(s[begin])] &gt; 1) count; &#125;&#125; 077. CombinationsDescription: 输出所有的组合Given two integers n and k, return all possible combinations of k numbers out of 1 … n. Example:12345678910Input: n = 4, k = 2Output:[ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 解法一: 回溯时间复杂度:空间复杂度: 标准的回溯(深度游戏遍历)解法 123456789101112131415161718192021class Solution &#123;private: void dfs_helper(vector&lt;vector&lt;int&gt;&gt; &amp;res, vector&lt;int&gt; &amp;out, int n, int k, int level)&#123; int count = out.size(); if(count==k)&#123; res.push_back(out); &#125; for(int i=level; i&lt;n; i++)&#123; out.push_back(i+1); dfs_helper(res, out, n, k, i+1); out.pop_back(); &#125; &#125;public: vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; out; dfs_helper(res, out, n, k, 0); return res; &#125;&#125;; 解法二: 迭代TODO: 未看懂 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; out(k, 0); int i = 0; while (i &gt;= 0) &#123; out[i]++; if (out[i] &gt; n) i--; else if (i == k - 1) res.push_back(out); else &#123; i++; out[i] = out[i - 1]; &#125; &#125; return res; &#125;&#125;; 078. Subsets返回给定数字序列的子集, 序列中每个元素都不同(这是一个很重要的条件!!) DescriptionGiven a set of distinct integers, nums, return all possible subsets (the power set). Note: The solution set must not contain duplicate subsets. Example: Input: nums = [1,2,3]Output:[ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], []] 解法一: 迭代直接求出子集时间复杂度: $O(2^n)$ , 对于任意一个元素, 有包含和不包含两种情况空间复杂度: $O(2^n)$ 由于序列中的每个元素都不同, 因此, 对于任意一个元素, 只需要将其添加都前面序列所组成的子集的每一个子序列的末尾即可, 无需考虑是否包含重复元素的情况. 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res &#123;vector&lt;int&gt;&#123;&#125;&#125;; for(auto n : nums)&#123; int len = res.size(); for(int i=0; i&lt;len; i++)&#123; vector&lt;int&gt; sub_item = res[i]; // c++中, =为复制赋值, move函数为移动赋值 sub_item.push_back(n); res.push_back(sub_item); &#125; &#125; return res; &#125;&#125;; 解法二: 回溯https://leetcode.com/problems/subsets/discuss/27281/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partitioning)回溯法可以解决一系列相关问题, 先看Subsets的求解 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; sub_item; back_track(res, sub_item, 0, nums); return res; &#125; void back_track(vector&lt;vector&lt;int&gt;&gt; &amp;res, vector&lt;int&gt; sub_item, int start, vector&lt;int&gt; &amp;nums)&#123; res.push_back(sub_item); for(int i=start; i&lt;nums.size(); i++)&#123; sub_item.push_back(nums[i]); back_track(res, sub_item, i+1, nums); sub_item.pop_back(); &#125; &#125;&#125;; 其他问题: Subsets II (contains duplicates) : https://leetcode.com/problems/subsets-ii/悠悠 11:05:53Permutations : https://leetcode.com/problems/permutations/悠悠 11:06:01Permutations II (contains duplicates) : https://leetcode.com/problems/permutations-ii/悠悠 11:06:09Combination Sum : https://leetcode.com/problems/combination-sum/悠悠 11:06:16Combination Sum II (can’t reuse same element) : https://leetcode.com/problems/combination-sum-ii/悠悠 11:06:23Palindrome Partitioning : https://leetcode.com/problems/palindrome-partitioning/ 解法三: bit控制时间复杂度: $O(n\times 2^n)$ , 最慢的方法.空间复杂度: $O(2^n)$因为对于任意一个数只有两种可能性, 出现在子序列中, 或者不出现在子序列中, 因此对于长度为 n 的(无相同元素的)序列来说, 共有 $2^n$ 个子序列, 我们先为这些子序列申请空间, 然后根据位操作(刚好有0,1两种情况)来决定对应位置上的字符出现还是不出现. 在实现时, 观察到, 第一个元素每隔两个子序列出现一次, 第二个元素每隔四个子序列出现两次, 第三个元素每隔八个子序列出现四次… 依次类推, 我们可以根据当前元素的位置来决定当前元素是否出现(间隔的前一半出现, 后一半不出现) 123456789101112131415class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; int len_subsets = std::pow(2,nums.size()); vector&lt;vector&lt;int&gt;&gt; res(len_subsets, vector&lt;int&gt;&#123;&#125;); for(int i =0; i&lt;nums.size(); i++)&#123; for(int j=0; j&lt;len_subsets; j++)&#123; if(j&gt;&gt;i &amp; 1 == 1)&#123; res[j].push_back(nums[i]); &#125; &#125; &#125; return res; &#125;&#125;; 079. Word Search判断指定单词是否存在于字符矩阵中(可以通过上下左右邻接字符相连的才算是一个单词) Description: 判断指定单词是否存在于字符矩阵中Given a 2D board and a word, find if the word exists in the grid. The word can be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once. Example: board =[ [‘A’,’B’,’C’,’E’], [‘S’,’F’,’C’,’S’], [‘A’,’D’,’E’,’E’]] Given word = “ABCCED”, return true.Given word = “SEE”, return true.Given word = “ABCB”, return false. 解法一: dfs+回溯时间复杂度: $O(mn 4^k)$, 暴力求解, $mn$ 为字符矩阵的宽和高, 也即 cell 数量, 对于 dfs 中的每个 cell, 有4个扩展方向, 一共需要扩展 $k$ 次($k$ 为单词的长度).空间复杂度: $O(mn)$ , 回溯时, 用#来记录已经遍历过的点, 无需申请额外空间来记录. 但是递归程序需要占用 $O(mn)$ 的空间复杂度. 123456789101112131415161718192021222324252627class Solution &#123;public: bool exist(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word) &#123; if(board.size()==0 || board[0].size()==0) return false; for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[0].size(); j++)&#123; if(dfs(board, word, 0, i, j)) return true; &#125; &#125; return false; &#125; bool dfs(vector&lt;vector&lt;char&gt;&gt; &amp;board, string word, int start, int x, int y)&#123; char cur_c = board[x][y]; if(cur_c != word[start]) return false; if(start == word.size()-1) return true; board[x][y]='#'; bool res=false, b_down=false, b_left=false, b_right=false; if(x&gt;0) res = dfs(board, word, start+1, x-1, y); if(!res &amp;&amp; x&lt;board.size()-1) res = dfs(board, word, start+1, x+1, y); if(!res &amp;&amp; y&gt;0) res = dfs(board, word, start+1, x, y-1); if(!res &amp;&amp; y&lt;board[0].size()-1) res = dfs(board, word, start+1, x, y+1); board[x][y]=cur_c; return res; &#125;&#125;; 另一种写法:123456789101112131415161718192021222324252627282930313233343536class Solution &#123;private: bool dfs(vector&lt;vector&lt;char&gt;&gt; &amp;board, string &amp;word, int i, int j, int pos)&#123; if(board[i][j] != word[pos]) return false; if(pos == word.size()-1) return true; // 注意是size-1 int direct[4][2] = &#123;&#123;0,-1&#125;,&#123;0,1&#125;,&#123;-1,0&#125;,&#123;1,0&#125;&#125;; int m = board.size(); int n = board[0].size(); char c = board[i][j]; board[i][j] = '#'; // 标记成已访问 for(auto d : direct)&#123; int x=i+d[0]; int y=j+d[1]; if(x&gt;=0 &amp;&amp; x&lt;m &amp;&amp; y&gt;=0 &amp;&amp; y&lt;n &amp;&amp; board[x][y]!='#')&#123; if(dfs(board, word, x, y, pos+1)) return true; &#125; &#125; board[i][j] = c; // 退出前重置访问状态 return false; &#125;public: bool exist(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word) &#123; if(board.empty() || board[0].empty()) return false; if(word.empty()) return true; int m = board.size(); int n = board[0].size(); for(int i=0; i&lt;m; i++)&#123; for(int j=0; j&lt;n; j++)&#123; if(dfs(board, word, i, j, 0)) return true; &#125; &#125; return false; &#125;&#125;; 084. 柱状图中最大的矩形-困难求最大面积的矩形 DescriptionGiven n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Example:Input: [2,1,5,6,2,3]Output: 10 解法一: 穷举时间复杂度: $O(n^2)$, 超时空间复杂度: $O(1)$ 列出以每一个i上的值为矩形高度的矩形面积, 然后取得最大值12345678910111213141516171819class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; int max_area = 0; for(int i =0; i&lt;heights.size(); i++)&#123; int low = i; while(low&gt;=0 &amp;&amp; heights[low] &gt;=heights[i]) low--; low++; int high = i; while(high&lt;heights.size() &amp;&amp; heights[high] &gt;= heights[i]) high++; high--; int cur_area = heights[i]* (high-low+1); if(max_area&lt;cur_area) max_area = cur_area; &#125; return max_area; &#125;&#125;; 解法二: 解法一的改进-空间换时间时间复杂度: $O(n)$, 前面省略常数项(因为不好确定常数项的值)空间复杂度: $O(2n)$ 从解法一中我们可以看出, 核心的要点就在于求取每一个i对应的矩形的左端和右端, 如下图所示: 那么, 如果我们可以在 $O(1)$ 的时间内获取到左端和右端的值, 则时间复杂度就可以降低到 $O(n)$, 因此, 首先想到的是用数组将每个i对应的左端和右端的值保存起来. 于是, 我们需要先求取这两个数组(左端,右端)的值, 在对左端和右端求值时, 我们要确保时间复杂度不能超过 $O(n)$, 因此, 我们不能每次都重新从i出发分别向左向右遍历(如解法一那样), 反之, 我们可以利用左端和右端中已经求好的值, 对于左端来说, 我们可以利用左端数组跳跃式的向左前进, 对于右端来说, 我们可以利用右端数组跳跃式的向右前进(这里不太好用语言描述, 具体请看程序代码). 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; int *left = new int[heights.size()]; int *right = new int[heights.size()]; left[0]=-1; for(int i=1; i&lt;heights.size(); i++)&#123; int p = i-1; while(p&gt;=0 &amp;&amp; heights[p] &gt;= heights[i]) p = left[p]; left[i] = p; &#125; right[heights.size()-1] = heights.size(); for(int i=heights.size()-2; i&gt;=0; i--)&#123; int p = i+1; while(p&lt;heights.size() &amp;&amp; heights[p] &gt;= heights[i]) p = right[p]; right[i] = p; &#125; int max_area = 0; for(int i =0; i&lt;heights.size(); i++)&#123; int low = left[i]; int high = right[i]; int cur_area = heights[i]*(high-low-1); if(max_area&lt;cur_area) max_area = cur_area; &#125; return max_area; &#125;&#125;; 解法三: 最优-栈时间复杂度: $O(n)$, 无常数项空间复杂度: $O(n)$, 无常数项 上面的解法二, 虽然时间复杂度为 $O(n)$, 但实际上其时间复杂度是略微高于 $O(n)$, 因为在求取左端右端时, 每次跳跃的次数是大于等于1, 而不是仅为1次的.(只不过大O记法不考虑常数项). 而对于空间复杂度来说, 实际上是 $O(2n)$. 下面我们从另外一个角度出发: 不再以当前i对应的高度为最低, 向左右两边探索, 改为以当前i对应的高度为最低, 仅仅向左边探索, 实现算法如下: 首先, 构造一个空栈 从heights数组的第一个bar开始, 遍历所有的bar值(0~n-1), 并执行以下逻辑: 如果当前栈为空, 或者当前数组bar值大于等于栈顶bar值, 则将bar值下标入栈 否则, 将栈顶出栈, 并以栈顶下标对应的bar值作为最低的高度, 求该高度对应的面积, 因为当前数组bar值小于栈顶下标对应的bar值, 因此可以将当前bar值下标作为right_index, 又因为栈顶bar值下标的前一个元素, 要么小于栈顶, 要么等于栈顶, 不论哪种情况, 都可以将其下标作为left_index(因为栈顶退出对, 次栈顶就会成为新的栈顶, 所以可以包括bar值相等的情况), 得到了高度, right_index, left_index, 即可计算当前栈顶对应的面积, 并与max_area判断, 更新max_area的值 最后, 如果遍历完以后栈顶不为空(说明后面有几个连续的bar值相等, 或者bar只呈递增排序), 则依次强制弹出栈顶计算面积, 并更新max_area. 复杂度分析: 由于入栈出栈的元素仅为heights数组元素, 可以栈的size就是heights数组的大小, 即空间复杂度为 $O(n)$, 时间复杂度从代码中可看出约为 $O(n)$. 1234567891011121314151617181920212223242526272829class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; std::stack&lt;int&gt; s; int max_area = 0; int cur_area = 0; int height_index=0; int i=0; while(i&lt;heights.size())&#123; if(s.empty() || heights[i] &gt;= heights[s.top()]) s.push(i++); else&#123; height_index = s.top(); s.pop(); cur_area = heights[height_index] * ( s.empty()? i : i-s.top()-1 ); // 注意, 如果栈为空, 则说明当前i对应的bar值是前i个bar值中最小的, 所以宽为i, 否则宽为i-s.top()-1 if(cur_area &gt; max_area) max_area = cur_area; &#125; &#125; while(!s.empty())&#123; height_index = s.top(); s.pop(); cur_area = heights[height_index] * ( s.empty()? i : i-s.top()-1 ); // 注意, 如果栈为空, 则说明当前i对应的bar值是前i个bar值中最小的, 所以宽为i, 否则宽为i-s.top()-1 if(cur_area &gt; max_area) max_area = cur_area; &#125; return max_area; &#125;&#125;; 085. 最大矩形-困难-待完善题目链接: https://leetcode-cn.com/problems/maximal-rectangle/ 解法一: 动态规划时间复杂度: $O(mn)$空间复杂度: $O(1)$ 该思路来自于题目 “最大正方形”, 不同的地方在于, 横向和纵向分别可以形成高为 1 和宽为 1 的长条矩形, 这种情况也要考虑在内. 其余的和最大正方形相同, 使用右上角作为dp, 同时沿着对角线进行更新, 可以只使用常数量的空间复杂度. 更新: 该解法存在问题, 因为 dp 原本是有三种可能的, 但是每次只保留了当前最大面积的可能, 故而会漏解, 通过 OJ 是因为 OJ 的样例不全, 对于下面的例子就无法输出正确答案:1[[&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;],[&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;],[&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;]] 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution: def maximalRectangle(self, matrix: List[List[str]]) -&gt; int: if len(matrix) == 0: return 0 m = len(matrix) n = len(matrix[0]) res = 0 i = 0 j = 0 while i &lt; m or j &lt; n: if i &lt; m: ii = i jj = 0 i += 1 elif j &lt; n: ii = 0 jj = j j += 1 dp = [0, 0] while ii &lt; m and jj &lt; n: if matrix[ii][jj] == '0': dp = [0, 0] else: w, h = dp kw, kh = 1, 1 while (kw &lt;= w and matrix[ii][jj-kw] == '1'): # 求宽 kw += 1 while (kh &lt;= h and matrix[ii-kh][jj] == '1'): # 求高 kh += 1 row = 1 while (row &lt;= ii and matrix[ii-row][jj] == '1'): # 纵向的矩形 row += 1 col = 1 while (col &lt;= jj and matrix[ii][jj-col] == '1'): # 横向的矩形 col += 1 index = max(zip([col, row, kw*kh], range(3)))[1] dp = [[col, 1], [1, row], [kw, kh]][index] #print(ii, jj, dp, kw, kh) ii += 1 jj += 1 res = max(res, dp[0]*dp[1]) return res 088. Merge Sorted Array融合两个有序数组, 其中第一个数组的元素长度为n, 第二个为m, 题目假设第一个数组的空间为n+m. Description解法一: 后移+插入融合1234567891011121314151617181920212223class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) &#123; for(int i =n+m-1; i&gt;=n; i--) nums1[i]=nums1[i-n]; //for(int i =n; i&lt;n+m; i++) 注意, 这样写是有问题的, 例如对于 [1,2,3,4,0], 这种情况, 从前往后的复制方法会造成元素覆盖 // nums1[i]=nums1[i-n]; int i =n, j=0, k=0; while(i&lt;n+m &amp;&amp; j&lt;n)&#123; if(nums1[i] &lt; nums2[j])&#123; nums1[k] = nums1[i]; k++; i++; &#125;else&#123; nums1[k] = nums2[j]; k++; j++; &#125; &#125; while(i&lt;n+m) nums1[k++] = nums1[i++]; while(j&lt;n) nums1[k++] = nums2[j++]; &#125;&#125;; 090. Subsets IIDescription: 含重复元素的数组的子集Given a collection of integers that might contain duplicates, nums, return all possible subsets (the power set). Note: The solution set must not contain duplicate subsets. Example:12345678910Input: [1,2,2]Output:[ [2], [1], [1,2,2], [2,2], [1,2], []] 解法一: 迭代时间复杂度: $O(2^n)$, 时间复杂度为子集的个数时间复杂度: $O(n)$, 空间复杂度为最长子集的长度 先排序, 然后对于一个元素, 如果这个元素与前一个元素相等, 那么在插入的时候, 就不能从第一个子集插入, 因为这样会重复, 因此要从不会造成重复的元素开始插入, 具体可看代码. 1234567891011121314151617181920class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); vector&lt;vector&lt;int&gt;&gt; res &#123;vector&lt;int&gt; &#123;&#125;&#125;; int pre_start = 0; for (int i = 0; i &lt; nums.size(); i++) &#123; int j = (i&gt;0 and nums[i]==nums[i-1]) ? pre_start : 0; // 从不会重复的元素开始 或者 从头开始 int len = res.size(); for ( ; j &lt; len; j++) &#123; auto sub_item = res[j]; sub_item.emplace_back(nums[i]); res.emplace_back(sub_item); &#125; pre_start = len; // 更新该值 &#125; return res; &#125;&#125;; 解法二: 回溯时间复杂度: $O(2^n)$, 时间复杂度为子集的个数时间复杂度: $O(n)$, 空间复杂度为递归的深度 先排序, 然后同样, 如果遇到相等元素, 则跳过, 以避免重复 123456789101112131415161718192021class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; sub_item; back_trace(res, sub_item, 0, nums); return res; &#125; void back_trace(vector&lt;vector&lt;int&gt;&gt;&amp; res, vector&lt;int&gt;&amp; sub_item, int start, vector&lt;int&gt;&amp; nums) &#123; res.push_back(sub_item); for (int i = start; i &lt; nums.size(); i++) &#123; if (i &gt; start and nums[i] == nums[i-1]) continue; sub_item.emplace_back(nums[i]); back_trace(res, sub_item, i+1, nums); sub_item.pop_back(); &#125; &#125;&#125;; 091. Decode WaysDescriptionA message containing letters from A-Z is being encoded to numbers using the following mapping: ‘A’ -&gt; 1‘B’ -&gt; 2…‘Z’ -&gt; 26Given a non-empty string containing only digits, determine the total number of ways to decode it. Example 1: Input: “12”Output: 2Explanation: It could be decoded as “AB” (1 2) or “L” (12).Example 2: Input: “226”Output: 3Explanation: It could be decoded as “BZ” (2 26), “VF” (22 6), or “BBF” (2 2 6). 解法一(最优): DP constant space时间复杂度: $O(n)$空间复杂度: $O(1)$ 存在问题: 下面的程序在面对测例:230001或230时, 输出的不是0. 但是仍然能通过OJ, 但实际上下面的解法在面对上面的样例时会返回错误答案, 因为没有对 0 进行特殊处理. 1234567891011121314151617class Solution &#123;public: int numDecodings(string s) &#123; if(s.size()==0 || s.front()=="0") return 0; // 注意, 不能用s.front() == "0" int f1=1, f2=1; for(int i=1; i&lt;s.size(); i++)&#123; if(s[i]=='0') f1=0; //注意, 不能用s[i] == "0" if(s[i-1]=='1' || (s[i-1]=='2' &amp;&amp; s[i]&lt;='6'))&#123; f1 = f1+f2; // 令f1为前i-1字符的可能组合+前i-2字符的可能组合 f2 = f1-f2; // 令f2为前i-1字符的可能组合, 也就是对于下一个i来说的前i-2的可能组合 &#125; else f2 = f1; // 如果当前字符不能与前一个字符组合, 则当前字符f1不变, 而f2有变为下一个i的前i-2的可能组合, 即让新f2等于旧的f1 &#125; return f1; &#125;&#125;; 修复了上述的问题, 现在遇到 0 时会进行额外的判断, 0 不能单独编码, 必须与前面的字符组合, 如果无法组合, 则应该返回0, 如 230001, 就应该返回 0, 代码如下:123456789101112131415161718192021222324252627class Solution &#123;public: int numDecodings(string s) &#123; int n = s.size(); if(n==0 || s[0] == '0') return 0; //if(n==1) return 1; vector&lt;int&gt; dp(n, 0); dp[0] = 1; int i = 1; while(i&lt;n)&#123; if(s[i]=='0')&#123; if(s[i-1] =='2' || s[i-1] == '1') // 0 不能单独编码, 必须与前面的数字组合, 因此这里是 dp[i-2] dp[i] = i&gt;1 ? dp[i-2] : 1; else // 如果 0 前面的值大于 2, 则无法组成编码, 应返回 0 return 0; &#125; else if(s[i-1]=='1' ||(s[i-1]=='2' &amp;&amp; s[i] &lt;= '6'))&#123; int prev_two = i&gt;1 ? dp[i-2] : 1; dp[i] = dp[i-1] + prev_two; &#125;else&#123; dp[i] = dp[i-1]; &#125; i++; &#125; return dp[n-1]; &#125;&#125;; 上面的代码使用了 DP 数组, 空间复杂度为 $O(n)$, 实际上我们并不需要这么多空间, 只需要常数空间就可以完成数组, 即只需要当前 dp 值的前两个 dp 值即可. 代码如下:123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: int numDecodings(string s) &#123; int n = s.size(); if(n==0 || s[0] == '0') return 0; //if(n==1) return 1; vector&lt;int&gt; dp(n, 0); int f1 = 1; // 代表当前dp值之前一位的dp值 int f2 = 1; // 代表当前dp值之前两位的dp值 dp[0] = 1; int i = 1; while(i&lt;n)&#123; if(s[i]=='0')&#123; if(s[i-1] =='2' || s[i-1] == '1')&#123; // 0 不能单独编码, 必须与前面的数字组合, 因此这里是 dp[i-2] int tmp = f1; f1 = f2; // 令当前dp值为f2 (当前的dp值会成为下一个f1值) f2 = tmp; &#125; else // 如果 0 前面的值大于 2, 则无法组成编码, 应返回 0 return 0; &#125; else if(s[i-1]=='1' ||(s[i-1]=='2' &amp;&amp; s[i] &lt;= '6'))&#123; f1 = f1 + f2; f2 = f1 - f2; // 上面两个式子相当于: // int tmp = f1; f1 = f1+f2; f2 = tmp; //int prev_two = i&gt;1 ? dp[i-2] : 1; //dp[i] = dp[i-1] + prev_two; &#125;else&#123; f2 = f1; // 当前dp值不变, 所以只需要更新 f2 即可 &#125; i++; &#125; return f1; &#125;&#125;; 另一种写法, 更好理解:123456789101112131415161718192021222324252627class Solution &#123;public: int numDecodings(string s) &#123; if (s.empty() || s[0] == '0') return 0; int dp1 = 1; // 记录当前字符前一位的可能组合数 int dp2 = 1; // 记录当前字符前两位的可能组合数 long res = 1; // 记录当前字符的可能组合数 for (int i = 1; i &lt; s.size(); i++) &#123; if (s[i] == '0') &#123; if (s[i-1] == '1' or s[i-1] == '2') &#123; // d res = dp2; &#125; else &#123; return 0; &#125;d &#125; else if (s[i-1] == '1' or (s[i-1] == '2' and s[i] &lt; '7' and s[i] &gt; '0')) &#123; res = dp1 + dp2; &#125; else &#123; res = dp1; &#125; dp2 = dp1; dp1 = res; &#125; return res; &#125;&#125;; 解法二: 递归时间复杂度: $O(n^2)$ 1234567891011121314151617class Solution &#123;public: int numDecodings(string s) &#123; if(s.size()==0) return 0; return recurve(0,s); &#125; int recurve(int pos, string &amp;s)&#123; if(pos==s.size()) return 1; if(s[pos]=='0') return 0; int tmp_res = recurve(pos+1, s); if(pos&lt;s.size()-1 &amp;&amp; (s[pos]=='1' || (s[pos]=='2'&amp;&amp;s[pos+1]&lt;='6'))) tmp_res += recurve(pos+2, s); return tmp_res; &#125;&#125;; 094. Binary Tree Inorder Traversal中序遍历二叉树 DescriptionGiven a binary tree, return the inorder traversal of its nodes’ values. Example:12345678Input: [1,null,2,3] 1 \ 2 / 3Output: [1,3,2] Follow up: Recursive solution is trivial, could you do it iteratively? 解法一: 递归1234567891011121314151617181920212223/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root==nullptr) return res; inorder(root, res); return res; &#125; void inorder(TreeNode* root, vector&lt;int&gt; &amp;res)&#123; if(root-&gt;left!=nullptr) inorder(root-&gt;left, res); res.push_back(root-&gt;val); if(root-&gt;right!=nullptr) inorder(root-&gt;right, res); &#125;&#125;; 解法二: 非递归标准的中序非递归遍历算法 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root==nullptr) return res; std::stack&lt;TreeNode*&gt; s_tree; while(!s_tree.empty() || root!=nullptr)&#123; while(root!=nullptr)&#123; s_tree.push(root); root= root-&gt;left; &#125; if(!s_tree.empty())&#123; root = s_tree.top(); s_tree.pop(); res.push_back(root-&gt;val); root = root-&gt;right; &#125; &#125; return res; &#125;&#125;; 095. 不同的二叉搜索树 II题目链接: https://leetcode-cn.com/problems/unique-binary-search-trees-ii/ 解法一: 递归思想与95题类似, 只不过此时我们需要将左右子树的可能情况都列举出来 1234567891011121314151617181920212223242526# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def generateTrees(self, n: int) -&gt; List[TreeNode]: def generate_trees(start, end): # 递归函数 if start &gt; end: return [None] all_trees = [] for i in range(start, end+1): # 以每个节点作为根节点 left = generate_trees(start, i-1) # 获取所有可能的左子树 right = generate_trees(i+1, end) # 获取所有可能的右子树 for l in left: # 将左右子树逐个连接起来 for r in right: root = TreeNode(i) root.left = l root.right = r all_trees.append(root) return all_trees return generate_trees(1, n) if n else [] 解法二: 动态规划首先我们每次新增加的数字大于之前的所有数字, 所以新增加的数字出现的位置只可能是根节点或者是根节点的右孩子, 右孩子的右孩子, 右孩子的右孩子的右孩子等等, 总之一定是右边. 其次, 新数字所在位置原来的子树, 改为当前插入数字的左孩子即可, 因为插入数字是最大的. 123456789101112131415161718192021222324252627282930313233343536373839404142434445# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def generateTrees(self, n: int) -&gt; List[TreeNode]: def tree_copy(root): if root is None: return None new_root = TreeNode(root.val) if root.left: new_root.left = tree_copy(root.left) if root.right: new_root.right = tree_copy(root.right) return new_root all_trees = [None] for i in range(1, n+1): tmp_trees = [] for root in all_trees: # 新插入的节点作为新的根 r1 = tree_copy(root) new_root = TreeNode(i) new_root.left = r1 tmp_trees.append(new_root) for j in range(1, n): # 逐个找到可以插入新节点的节点 j_root = tree_copy(root) jr_root = j_root k = 0 if jr_root is None: break for k in range(j): # pre = jr_root jr_root = jr_root.right new_node = TreeNode(i) pre.right = new_node new_node.left = jr_root tmp_trees.append(j_root) if jr_root is None: break all_trees = tmp_trees return all_trees if n &gt; 0 else [] 096. 不同的二叉搜索树题目链接: https://leetcode-cn.com/problems/unique-binary-search-trees/ 解法一: 递归模拟每个节点作为根节点时的状态, 将左子树的可能性与右子树的可能性相乘, 最后将所有节点的可能性相加 解法二: 动态规划思路和解法一一致, 将所有节点为根的情况一一计算并相加 时间复杂度 : 上述算法的主要计算开销在于包含 dp[i] 的语句. 因此, 时间复杂度为这些语句的执行次数, 也就是 $\sum_{i=2}^{n} i = \frac{(2+n)(n-1)}{2}$. 因此, 时间复杂度为 $O(N^2)$空间复杂度 : 上述算法的空间复杂度主要是存储所有的中间结果, 因此为 $O(N)$ 123456789class Solution: def numTrees(self, n: int) -&gt; int: dp = [0] * (n+1) dp[0] = 1 dp[1] = 1 for i in range(2, n+1): for j in range(1, i+1): dp[i] += dp[j-1] * dp[i-j] return dp[-1] 解法三: 卡特兰数根据解法二分析的递推公式, 完全符合卡特兰数的定义, 关于卡特兰数的介绍请看算法经典题型整理 时间复杂度: $O(n)$空间复杂度: $O(1)$ 123456class Solution: def numTrees(self, n: int) -&gt; int: res = 1 for i in range(1, n): res *= (4*i + 2) / (i+2) return int(res) 098. Validate Binary Search TreeDescriptionGiven a binary tree, determine if it is a valid binary search tree (BST). Assume a BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node’s key.The right subtree of a node contains only nodes with keys greater than the node’s key.Both the left and right subtrees must also be binary search trees.Example 1: Input: 2 / \ 1 3Output: trueExample 2: 5 / \ 1 4 / \ 3 6Output: falseExplanation: The input is: [5,1,4,null,null,3,6]. The root node’s value is 5 but its right child’s value is 4. 解法一: 递归用一个指针来指向当前节点在顺序上的前一个节点, 判断是否为BST 123456789101112131415class Solution &#123;public: bool isValidBST(TreeNode* root) &#123; TreeNode* pre_node = nullptr; return isBST(root, pre_node); &#125; bool isBST(TreeNode* root, TreeNode * &amp;pre_node)&#123; // 注意!!! 要维持递归时的pred_node, 因此必须使用 * &amp;, 否则每次的pre_node = root;实际上只是改变了pred_node的副本 if(root==nullptr) return true; if(isBST(root-&gt;left, pre_node) == false) return false; if(pre_node!=nullptr &amp;&amp; pre_node-&gt;val &gt;= root-&gt;val) return false; pre_node = root; if(isBST(root-&gt;right, pre_node)==false) return false; return true; &#125;&#125;; 下面的代码是典型错误解法: 因为, 我们不知只要考虑左子树节点值要小于当前节点值, 还要满足的另外一个条件是左子树本身也是一个二叉搜索树, 下面的代码没有进行该判断. 1234567891011121314151617181920212223242526/*Input[10,5,15,null,null,6,20]OutputtrueExpectedfalse*/class Solution &#123;public: bool isValidBST(TreeNode* root) &#123; if(root==nullptr) return true; bool b=true; if(root-&gt;left!=nullptr)&#123; if(root-&gt;left-&gt;val &gt;= root-&gt;val) return false; b = isValidBST(root-&gt;left); &#125; if(b==false) return b; if(root-&gt;right!=nullptr)&#123; if(root-&gt;right-&gt;val &lt;= root-&gt;val) return false; b = isValidBST(root-&gt;right); &#125; return b; &#125;&#125;; 解法二: 迭代(中序)中序遍历二叉搜索树时, 返回的是一个有序的数组, 因此, 我们可以在遍历时, 一旦发现不有序, 就返回 false, 需要注意一点的是, 本题中二叉搜索树中的节点值是唯一的. 12345678910111213141516171819202122class Solution &#123;public: bool isValidBST(TreeNode* root) &#123; TreeNode* prev = nullptr; stack&lt;TreeNode*&gt; s; while(root!=nullptr || !s.empty())&#123; while(root!=nullptr)&#123; s.push(root); root = root-&gt;left; &#125; if(!s.empty())&#123; root = s.top(); s.pop(); if(prev!=nullptr &amp;&amp; prev-&gt;val &gt;= root-&gt;val) return false; prev = root; root = root-&gt;right; &#125; &#125; return true; &#125;&#125;; 101. Symmetric Tree判断一个二叉树是否为对称的.(与自身镜像相等) DescriptionGiven a binary tree, check whether it is a mirror of itself (ie, symmetric around its center). For example, this binary tree [1,2,2,3,4,4,3] is symmetric:12345 1 / \ 2 2 / \ / \3 4 4 3 But the following [1,2,2,null,3,null,3] is not:12345 1 / \2 2 \ \ 3 3 Note:Bonus points if you could solve it both recursively and iteratively. 解法一: 递归时间复杂度: $O(n)$ , 遍历了整个树中的每个节点一次空间复杂度: $O(n)$ , 调用递归的次数与树的高度有关, 在最差的情况下, 树的高度为n. 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; if(root==nullptr) return true; return isSymHelper(root-&gt;left, root-&gt;right); &#125; bool isSymHelper(TreeNode* subRoot1, TreeNode* subRoot2)&#123; if(subRoot1 == nullptr &amp;&amp; subRoot2 == nullptr) return true; if(subRoot1 == nullptr || subRoot2 == nullptr) return false; if(subRoot1-&gt;val != subRoot2-&gt;val) return false; bool b1 = isSymHelper(subRoot1-&gt;left, subRoot2-&gt;right); bool b2 = isSymHelper(subRoot1-&gt;right, subRoot2-&gt;left); return b1&amp;&amp;b2; &#125;&#125;; 更整洁的写法:1234567891011121314class Solution &#123; bool is_sym(TreeNode* t1, TreeNode* t2)&#123; if(t1==nullptr &amp;&amp; t2==nullptr) return true; if(t1==nullptr || t2==nullptr) return false; if(t1-&gt;val == t2-&gt;val) return is_sym(t1-&gt;left, t2-&gt;right) &amp;&amp; is_sym(t2-&gt;left, t1-&gt;right); else return false; &#125;public: bool isSymmetric(TreeNode* root) &#123; if(root==nullptr) return true; return is_sym(root-&gt;left, root-&gt;right); &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$ , 遍历了整个树中的每个节点一次空间复杂度: $O(n)$ , 层次遍历创建了两个队列, 其大小总和刚好为n. (有一种说法是: 层次遍历我们最多只会同时保存两层的节点数, 而最后一层的节点数最多为 $logn$, 所以空间复杂度实际上是 $O(logn)$ (常数项被约掉), 这种说法对吗??) 层次遍历, 注意不应该左子树和右子树做非空检查, 因此判断是否对称时, 需要包含节点为空的情况.(因为不需要知道当前的深度, 所以也不用维护深度信息) 123456789101112131415161718192021class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; if(root==nullptr) return true; queue&lt;TreeNode*&gt; q1; queue&lt;TreeNode*&gt; q2; q1.push(root-&gt;left); q2.push(root-&gt;right); TreeNode * cur1, * cur2; while(!q1.empty() &amp;&amp; !q2.empty())&#123; cur1 = q1.front(); q1.pop(); cur2 = q2.front(); q2.pop(); if(cur1==nullptr &amp;&amp; cur2 ==nullptr) continue; if(cur1==nullptr || cur2 == nullptr) return false; if(cur1-&gt;val != cur2-&gt;val) return false; q1.push(cur1-&gt;left); q1.push(cur1-&gt;right); q2.push(cur2-&gt;right); q2.push(cur2-&gt;left); &#125; return true; &#125;&#125;; 解法三: 迭代时间复杂度: $O(n)$空间复杂度: $O(n)$ 只是用一个队列, 对每一层都进行回文检查123456789101112131415161718192021222324252627282930class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; if (root == nullptr) return true; std::queue&lt;TreeNode*&gt; queueTree; queueTree.push(root); while (!queueTree.empty()) &#123; int len = queueTree.size(); std::vector&lt;double&gt; vec; for (int i = 0; i &lt; len; i++) &#123; auto node = queueTree.front(); queueTree.pop(); if (node == nullptr) &#123; vec.push_back(0.5); &#125; else &#123; vec.push_back(node-&gt;val); queueTree.push(node-&gt;left); queueTree.push(node-&gt;right); &#125; &#125; int n = vec.size(); for (int i = 0; i &lt; n/2; i++) &#123; if (vec[i] != vec[n - i - 1]) &#123; return false; &#125; &#125; &#125; return true; &#125;&#125;; 102. Binary Tree Level Order Traversal按层次输出二叉树节点的值(每层的值要分开) Description解法一: 层次遍历时间复杂度: $O(n)$ , 每个节点遍历一次空间复杂度: $O(n)$ , 存储了n个节点的值 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(root == nullptr) return res; std::queue&lt;TreeNode*&gt; q; TreeNode * cur_node; q.push(root); while(!q.empty())&#123; int len = q.size(); vector&lt;int&gt; layer; for(int i=0; i&lt;len; i++)&#123; cur_node = q.front(); q.pop(); layer.push_back(cur_node-&gt;val); if(cur_node-&gt;left != nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right != nullptr) q.push(cur_node-&gt;right); &#125; res.push_back(layer); &#125; return res; &#125;&#125;; 103. Binary Tree Zigzag Level Order Traversal按之字形打印二叉树 DescriptionGiven a binary tree, return the zigzag level order traversal of its nodes’ values. (ie, from left to right, then right to left for the next level and alternate between). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its zigzag level order traversal as:[ [3], [20,9], [15,7]] 解法一：利用reverse时间复杂度为 $O(n^2)$ 空间复杂度为 $O(n)$ 然后每次访问节点时, 都判断当前节点的层数, 如果为奇数层, 则将该层直接push back到结果向量中, 如果为偶数, 则将该层数据进行reverse后再push back到结果向量中. 通过while里面内置for循环, 来保证每次for循环都会将一整层的节点放进队列中, 无需额外的数组来存储depth信息1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(pRoot == NULL) return res; queue&lt;TreeNode*&gt; que; que.push(pRoot); bool even = false; while(!que.empty())&#123; vector&lt;int&gt; vec; //将vec声明在内部, 省去每次的clear操作, clear操作需要对vector进行遍历, 并将每个元素置为null？ const int size = que.size(); //当前存的节点数目就是这一层所有的节点, 之前层的到已经被取出, 并且这一层的子节点还没有开始入队列 for(int i=0; i&lt;size; ++i)&#123; //将该层所有节点的子节点入队列, 同时当到达该层最后一个节点时终止 TreeNode* tmp = que.front(); que.pop(); vec.push_back(tmp-&gt;val); if(tmp-&gt;left != NULL) que.push(tmp-&gt;left); if(tmp-&gt;right != NULL) que.push(tmp-&gt;right); &#125; if(even) //根据奇偶标识判断是否需要reverse std::reverse(vec.begin(), vec.end()); res.push_back(vec); even = !even; &#125; return res; &#125;&#125;; 解法二: 最优(不用reverse)时间复杂度: $O(n)$空间复杂度: $O(n)$ 在解法二中, 复杂度高的原因是因每次遇到偶数层的时候都要进行 reverse, 实际上, 当我们知道了该层的节点个数以后, 我们可以直接开辟一个指定大小的 vector, 然后根据下标随机访问来填入该层的节点值, 这样一来就不用进行 reverse, 并且空间复杂度与解法二相同 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; zigzagLevelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(root == nullptr) return res; std::queue&lt;TreeNode*&gt; q; q.push(root); bool is_odd = true; TreeNode* cur_node; while(!q.empty())&#123; int layer_len = q.size(); vector&lt;int&gt; cur_layer(layer_len); for(int i=0; i&lt;layer_len; i++)&#123; cur_node = q.front(); q.pop(); if(is_odd==true) cur_layer[i] = cur_node-&gt;val; else cur_layer[layer_len-1-i ] = cur_node-&gt;val; if(cur_node-&gt;left!=nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right!=nullptr) q.push(cur_node-&gt;right); &#125; res.push_back(cur_layer); is_odd = !is_odd; &#125; return res; &#125;&#125;; 解法三: 利用双端队列时间复杂度: $O(n)$空间复杂度: $O(n)$ 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; zigzagLevelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if (root == nullptr) return res; std::deque&lt;TreeNode*&gt; dqTree; dqTree.push_back(root); int depth = 0; while (!dqTree.empty()) &#123; depth++; int len = dqTree.size(); vector&lt;int&gt; tmpRes; for (int i = 0; i &lt; len; i++) &#123; if (depth &amp; 1) &#123; auto node = dqTree.front(); dqTree.pop_front(); tmpRes.push_back(node-&gt;val); if (node-&gt;left != nullptr) dqTree.push_back(node-&gt;left); if (node-&gt;right != nullptr) dqTree.push_back(node-&gt;right); &#125; else &#123; auto node = dqTree.back(); dqTree.pop_back(); tmpRes.push_back(node-&gt;val); if (node-&gt;right != nullptr) dqTree.push_front(node-&gt;right); if (node-&gt;left != nullptr) dqTree.push_front(node-&gt;left); &#125; &#125; res.push_back(tmpRes); &#125; return res; &#125;&#125;; 104. Maximum Depth of Binary Tree求二叉树的最大深度(树的深度) DescriptionGiven a binary tree, find its maximum depth. The maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node. Note: A leaf is a node with no children. Example: Given binary tree [3,9,20,null,null,15,7],12345 3 / \9 20 / \ 15 7 return its depth = 3. 解法一: 层次遍历时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int maxDepth(TreeNode* root) &#123; if(root == nullptr) return 0; std::queue&lt;TreeNode*&gt; q; q.push(root); int depth = 0; TreeNode* cur_node; while(!q.empty())&#123; int layer_len = q.size(); depth++; for(int i=0; i&lt;layer_len; i++)&#123; cur_node = q.front(); q.pop(); if(cur_node-&gt;left!=nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right!=nullptr) q.push(cur_node-&gt;right); &#125; &#125; return depth; &#125;&#125;; 解法二: 递归12345678910111213class Solution &#123;private: int height(TreeNode *root)&#123; if(root == nullptr) return 0; int left_height = height(root-&gt;left); int right_height = height(root-&gt;right); return 1+max(left_height, right_height); &#125;public: int maxDepth(TreeNode* root) &#123; return height(root); &#125;&#125;; 105. Construct Binary Tree from Preorder and Inorder TraversalDescription: 根据先序和中序遍历构造二叉树Given preorder and inorder traversal of a tree, construct the binary tree. Note:You may assume that duplicates do not exist in the tree.(如果没有该条件则通常无法还原唯一的二叉树) For example, given preorder = [3,9,20,15,7]inorder = [9,3,15,20,7]Return the following binary tree:12345 3 / \9 20 / \ 15 7 解法一: 递归时间复杂度: $O(n^2)$, 在中序遍历中查找根节点的复杂度为 $O(n)$, 先序序列中总共有 $n$ 个根节点, 所以需要查找 $n$ 次空间复杂度: 根据树的结构, 最坏情况下的递归深度为 $O(n)$. 先取先序遍历中的第一个节点为根节点, 然后在中序遍历冲查找该节点, 以该节点为界限将数组分成两边, 分别为左子树和右子树, 根据左子树和右子树的长度在先序遍历中也划分对应长度的两个数组, 然后将两个数组分别作为左子树的先序和中序, 以及右子树的先序和中序进行递归构建. 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: TreeNode* helper(vector&lt;int&gt; &amp;preorder, int i, int j, vector&lt;int&gt; &amp;inorder, int k, int l)&#123; // tree 8 4 5 3 7 3 // preorder 8 [4 3 3 7] [5] // inorder [3 3 4 7] 8 [5] if(i &gt;= j || k &gt;= l)&#123;// 注意, 这里的 j 和 l 均为超尾下标 return nullptr; &#125; int root_val = preorder[i]; auto in_index = find(inorder.begin()+k, inorder.begin()+l, root_val); int dis = in_index - inorder.begin() - k; TreeNode *root = new TreeNode(root_val); root-&gt;left = helper(preorder, i+1, i+1+dis, inorder, k, k+dis); root-&gt;right = helper(preorder, i+1+dis, j, inorder, k+dis+1, l); return root; &#125;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; return helper(preorder, 0, preorder.size(), inorder, 0, inorder.size()); &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$空间复杂度: $O(n)$ 先将 preorder[i] 压入栈中, 如果当前 preorder 的元素与 inorder 中的元素不匹配, 则将 preorder 中的值构造成节点压入栈中, 并且新构造的节点一定是栈顶的左孩子. 重复该过程直到元素值匹配为止: preorder[i] = inorder[index] 当先序和中序的值匹配时, 则将节点出栈, 直到不再匹配为止. TODO: 该解法还没彻底搞清, 暂时搁置 1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; stack&lt;TreeNode*&gt; s; if(preorder.empty()) return nullptr; TreeNode *root = new TreeNode(preorder[0]); s.push(root); int index = 0; for(int i=1; i &lt; preorder.size(); i++)&#123; TreeNode* cur = s.top(); if(cur-&gt;val != inorder[index])&#123; cur-&gt;left = new TreeNode(preorder[i]); s.push(cur-&gt;left); &#125;else&#123; while(!s.empty() &amp;&amp; s.top()-&gt;val == inorder[index])&#123; cur = s.top(); s.pop(); index++; &#125; if(index &lt; inorder.size())&#123; cur-&gt;right = new TreeNode(preorder[i]); s.push(cur-&gt;right); &#125; &#125; &#125; return root; &#125;&#125;; 108. Convert Sorted Array to Binary Search Tree根据 有序数组 构造平衡二叉搜索树(不唯一, 只要符合规则即可) DescriptionGiven an array where elements are sorted in ascending order, convert it to a height balanced BST. For this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1. Example:123456789Given the sorted array: [-10,-3,0,5,9],One possible answer is: [0,-3,9,-10,null,5], which represents the following height balanced BST: 0 / \ -3 9 / / -10 5 解法一: 递归构造时间复杂度: $O(n)$空间复杂度: $O(n)$, 递归了n次(每个节点都被访问了一次) 由于题目给的条件是 有序数组 , 因此大大降低了了构造难度, 可以每次将数组的中间位置作为根节点, 然后分别将两边的数组作为一个新的子数组进行构造, 无需考虑插入新节点引起的二叉搜索树不平衡的问题.12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) &#123; return construct_BST(nums, 0, nums.size()-1); &#125; TreeNode* construct_BST(vector&lt;int&gt;&amp; nums, int low, int high)&#123; if(low&gt;high) return nullptr; int mid = (low+high)/2; TreeNode* root = new TreeNode(nums[mid]); root-&gt;left = construct_BST(nums, low, mid-1); root-&gt;right = construct_BST(nums, mid+1, high); return root; &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$, 只不过需要遍历两次树的size空间复杂度: $O(n)$, 层次遍历的队列和中根遍历的栈 先用层次遍历构造一个完全二叉树(以却确保树是平衡的), 然后在利用中根遍历对树中的每个元素进行赋值. 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;public: TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) &#123; int tree_len = nums.size(); if(tree_len == 0) return nullptr; std::queue&lt;TreeNode*&gt; q; TreeNode* root = new TreeNode(0); q.push(root); tree_len--; TreeNode* cur_node; int layer_len = 1; while(tree_len&gt;0)&#123; layer_len *= 2; for(int i=0; i&lt;layer_len &amp;&amp; tree_len&gt;0; i++)&#123; cur_node = q.front(); q.pop(); TreeNode* left = new TreeNode(0); cur_node-&gt;left = left; q.push(cur_node-&gt;left); tree_len--; if(tree_len&gt;0)&#123; TreeNode *right = new TreeNode(0); cur_node-&gt;right = right; q.push(cur_node-&gt;right); tree_len--; &#125; &#125; &#125; std::stack&lt;TreeNode*&gt; s; cur_node = root; int i = 0; while(!s.empty() || cur_node!=nullptr)&#123; while(cur_node!=nullptr)&#123; s.push(cur_node); cur_node = cur_node-&gt;left; &#125; if(!s.empty())&#123; cur_node = s.top(); s.pop(); cur_node-&gt;val =nums[i++]; cur_node = cur_node-&gt;right; &#125; &#125; return root; &#125;&#125;; 解法三: 迭代(只中根遍历一次)【链接】Loading…https://leetcode.com/problems/convert-sorted-array-to-binary-search-tree/discuss/35218/Java-Iterative-Solution 111. minimum depth of binary tree题目描述Given a binary tree, find its minimum depth. The minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node. Note: A leaf is a node with no children. Example:1234567Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7 解法一:层次优先遍历,遇到的首个叶子结点(左右子树为空)即为最短的深度 注意: 利用while内嵌for循环的方式, 可以省去对每个结点depth的维护, 只需要每次进入for循环之前, depth++即可(因为一个for循环会将当前层所有的结点都入队列, for循环结束后, 意味着进入了下一层, 所以depth++即可) 123456789101112131415161718192021class Solution &#123;public: int run(TreeNode *root) &#123; queue&lt;TreeNode*&gt; q_node; if(root==nullptr) return 0; q_node.push(root); int depth = 0; while(!q_node.empty())&#123; const int size = q_node.size(); depth++; for(int i = 0; i&lt; size; i++)&#123; TreeNode* node = q_node.front(); q_node.pop(); if(node-&gt;left!=nullptr) q_node.push(node-&gt;left); if(node-&gt;right!=nullptr) q_node.push(node-&gt;right); if(node-&gt;left==nullptr &amp;&amp; node-&gt;right == nullptr) return depth; &#125; &#125; return -1; &#125;&#125;; 解法二(递归):让当前结点为空, 则当前结点深度为0, 若当前结点左子树为空, 则当前结点深度等于左子树深度, 反之 ,等于右子树深度. 若当前结点左右子树均不为空, 则当前结点的 最小深度 等于左右子树深度 较小者 加1 123456789101112131415class Solution &#123;public: int run(TreeNode* root) &#123; if(root== nullptr) return 0; if(root-&gt;left==nullptr) return run(root-&gt;right) + 1; else if(root-&gt;right ==nullptr) return run(root-&gt;left) + 1; else&#123; int depth1=run(root-&gt;left); int depth2=run(root-&gt;right); return depth1&lt;depth2 ? depth1+1 : depth2+1; &#125; &#125;&#125;; 114. 二叉树展开为链表-中等给定一个二叉树，原地 将它展开为链表。题目链接: https://leetcode-cn.com/problems/flatten-binary-tree-to-linked-list/ 解法一: 先序遍历先序遍历需要申请一个全局变量来维护最后访问的节点, 同时注意将右子树做一个备份, 因为在遍历左子树的时候, 有可能会改变根节点的右节点, 这样会导致访问错误的地址. 该解法貌似存在一些问题, 下面的两种实现均不能通过 OJ Python 实现:1234567891011121314151617181920212223# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def flatten(self, root: TreeNode) -&gt; None: """ Do not return anything, modify root in-place instead. """ def helper(root, last): if root == None: return if last != None: last.right = root last.left = None last = root copy_right = root.right helper(root.left, last) helper(copy_right, last) last = None helper(root, last) C++ 实现:1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */TreeNode* last = nullptr;class Solution &#123;public: void flatten(TreeNode* root) &#123; if (root == nullptr) return; if (last != nullptr) &#123; last-&gt;right = root; last-&gt;left = nullptr; &#125; last = root; auto right_copy = root-&gt;right; flatten(root-&gt;left); flatten(right_copy); return; &#125;&#125;; 解法二: 后序遍历, 递归依据二叉树展开为链表的特点, 使用后序遍历完成展开.Python 实现:123456789101112131415161718192021222324# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def flatten(self, root: TreeNode) -&gt; None: """ Do not return anything, modify root in-place instead. """ def helper(root): if root == None: return helper(root.left) helper(root.right) if root.left != None: # 后序遍历 pre = root.left # 令 pre 指向左子树 while pre.right: pre = pre.right # 找到左子树中的最右节点 pre.right = root.right # 令左子树中的最右节点的右子树 指向 根节点的右子树 root.right = root.left # 令根节点的右子树指向根节点的左子树 root.left = None # 置空根节点的左子树 root = root.right # 令当前节点指向下一个节点 helper(root) C++ 实现:12345678910111213141516171819202122232425262728/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */TreeNode* last = nullptr;class Solution &#123;public: void flatten(TreeNode* root) &#123; if (root == nullptr) return; flatten(root-&gt;left); flatten(root-&gt;right); if (root-&gt;left != nullptr) &#123; auto pre = root-&gt;left; while (pre-&gt;right != nullptr) pre = pre-&gt;right; pre-&gt;right = root-&gt;right; root-&gt;right = root-&gt;left; root-&gt;left = nullptr; &#125; root = root-&gt;right; return; &#125;&#125;; 解法三: 非递归, 不使用辅助空间及全局变量前面的递归解法实际上也使用了额外的空间, 因为递归需要占用额外空间. 下面的解法无需申请栈, 也不用全局变量, 是真正的 In-Place 解法. C++ 解法:12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: void flatten(TreeNode* root) &#123; while (root != nullptr) &#123; if (root-&gt;left != nullptr) &#123; auto most_right = root-&gt;left; // 如果左子树不为空, 那么就先找到左子树的最右节点 while (most_right-&gt;right != nullptr) most_right = most_right-&gt;right; // 找最右节点 most_right-&gt;right = root-&gt;right; // 然后将跟的右孩子放到最右节点的右子树上 root-&gt;right = root-&gt;left; // 这时候跟的右孩子可以释放, 因此我令左孩子放到右孩子上 root-&gt;left = nullptr; // 将左孩子置为空 &#125; root = root-&gt;right; // 继续下一个节点 &#125; return; &#125;&#125;; Python 解法:123456789101112131415161718192021# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def flatten(self, root: TreeNode) -&gt; None: """ Do not return anything, modify root in-place instead. """ while (root != None): if root.left != None: most_right = root.left while most_right.right != None: most_right = most_right.right most_right.right = root.right root.right = root.left root.left = None root = root.right return 116. Populating Next Right Pointers in Each Node令每个节点中的 next 指针指向它的右兄弟, 如果没有右兄弟, 那么就置为 nullptr, 注意, 题目给定的树是满二叉树 DescriptionGiven a binary tree struct TreeLinkNode { TreeLinkNode left; TreeLinkNode right; TreeLinkNode * next;}Populate each next pointer to point to its next right node. If there is no next right node, the next pointer should be set to NULL. Initially, all next pointers are set to NULL. Note: You may only use constant extra space.Recursive approach is fine, implicit stack space does not count as extra space for this problem.You may assume that it is a perfect binary tree (ie, all leaves are at the same level, and every parent has two children).Example: Given the following perfect binary tree, 1 / \ 2 3 / \ / \4 5 6 7After calling your function, the tree should look like: 1 -&gt; NULL / \ 2 -&gt; 3 -&gt; NULL / \ / \4-&gt;5-&gt;6-&gt;7 -&gt; NULL 解法一: 层次遍历时间复杂度: $O(n)$空间复杂度: $O(n)$ 显而易见可以用层次遍历, 只需额外设置一个节点指针来维护当前节点的前一个节点(左兄弟节点). 但是, 题目中要求只能使用常数空间, 因此该解法不是最优解. 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for binary tree with next pointer. * struct TreeLinkNode &#123; * int val; * TreeLinkNode *left, *right, *next; * TreeLinkNode(int x) : val(x), left(NULL), right(NULL), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: Node* connect(Node* root) &#123; if (root==nullptr) return nullptr; std::queue&lt;Node*&gt; treeQ; treeQ.push(root); while (!treeQ.empty()) &#123; int len = treeQ.size(); for (int i = 0; i &lt; len; i++) &#123; auto node = treeQ.front(); treeQ.pop(); Node* nextNode; if ( i &lt; len -1) &#123; nextNode = treeQ.front(); &#125; else &#123; nextNode = nullptr; &#125; node-&gt;next = nextNode; if (node-&gt;left != nullptr) &#123; treeQ.push(node-&gt;left); &#125; if (node-&gt;right != nullptr) &#123; treeQ.push(node-&gt;right); &#125; &#125; &#125; return root; &#125;&#125;; 解法二: 利用 next 指针的特性时间复杂度: $O(n)$, 每个节点都要访问一次(仅访问一次)空间复杂度: $O(1)$ 由于是满二叉树, 因此我们可以轻易的利用next指针自身的特性来实现层次遍历. 1234567891011121314151617181920class Solution &#123;public: Node* connect(Node* root) &#123; Node* curFirst = root; while (curFirst != nullptr) &#123; Node* curNode = curFirst; while (curNode != nullptr) &#123; if (curNode-&gt;left != nullptr) &#123; curNode-&gt;left-&gt;next = curNode-&gt;right; &#125; if (curNode-&gt;next != nullptr &amp;&amp; curNode-&gt;right != nullptr) &#123; curNode-&gt;right-&gt;next = curNode-&gt;next-&gt;left; &#125; curNode = curNode-&gt;next; &#125; curFirst = curFirst-&gt;left; &#125; return root; &#125;&#125;; 118. Pascal’s TrianglePascal 三角形 DescriptionGiven a non-negative integer numRows, generate the first numRows of Pascal’s triangle. Example:123456789Input: 5Output:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 解法一: 按照三角形的性质进行赋值赋值时, 每一行的两端都是1, 无需重复赋值, 注意控制好边界条件 1234567891011121314class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; generate(int numRows) &#123; vector&lt;vector&lt;int&gt;&gt; res; for(int i =0; i&lt;numRows; i++)&#123; vector&lt;int&gt; temp(i+1, 1); for(int j=1; j&lt;i; j++)&#123; // 两边默认为1, 无需重复赋值 temp[j] = res[i-1][j-1]+res[i-1][j];// i和j的值只有在大于1时才会进入循环, 所以无需担心i-1或j-1&lt;0 &#125; res.push_back(temp); &#125; return res; &#125;&#125;; 121. 买卖股票的最佳时机-简单获取最大的股票利润题目链接: https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/ DescriptionSay you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1:123Input: [7,1,5,3,6,4]Output: 5Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price. Example 2:123Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 解法一: 穷举计算所有可能性, $O(n^2)$ 解法二: 一次遍历时间复杂度: $O(n)$空间复杂度: $O(1)$ 维护两个变量 min_price 和 max_profit, 每次检查元素, 一方面如果当前价格更低, 则更改 min_price 变量, 另一方面如果当前利润超过 max_profit, 则更新之. 1234567891011121314class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size() == 0) return 0; int min_price=prices[0], max_profit=0; for(int i=0; i&lt;prices.size(); i++)&#123; if(prices[i] &lt;= min_price)&#123; min_price = prices[i]; &#125; if(prices[i]-min_price &gt; max_profit) max_profit = prices[i]-min_price; &#125; return max_profit; &#125;&#125;; 同样也是一次遍历, 下面的写法更加简洁, 我们这里记录一个变量 buy, 用来指示可能的买入下标, 之后, 如果下一个价格比 buy 对应的价格高, 我们就尝试更新最大利润, 否则, 就改变 buy 到当前的价格下标1234567891011121314class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int maxfit = 0; int buy = 0; for(int i=1; i&lt;prices.size(); i++)&#123; if(prices[buy] &lt; prices[i])&#123; maxfit = max(maxfit, prices[i] - prices[buy]); &#125;else buy = i; &#125; return maxfit; &#125;&#125;; 实际上, 我们只需要用一个变量记录迄今为止遇到的最小的股票值即可, 然后对于每一个新值, 我们都更新最高利润和最小值即可, 代码如下:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.empty()) return 0; int low = prices[0]; int res = 0; for (auto const p : prices) &#123; res = std::max(res, p - low); low = std::min(low, p); &#125; return res; &#125;&#125;; 解法三: 通用 DP 解法详细分析见后面的 “股票问题通用解法” C++ 实现:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.size() &lt;= 1) return 0; int dp[2] = &#123;-prices[0], 0&#125;; // 持有, 不持有 base case for (int i = 1; i &lt; prices.size(); i++) &#123; int hold = std::max(dp[0], -prices[i]); int not_hold = std::max(dp[1], dp[0] + prices[i]); dp[0] = hold; dp[1] = not_hold; &#125; return std::max(dp[0], dp[1]); &#125;&#125;; Python 实现:12345678class Solution: def maxProfit(self, prices: List[int]) -&gt; int: if len(prices) &lt;= 1: return 0 dp = [-prices[0], 0] # 持有, 不持有 for price in prices[1:]: # 持有: 要么之前买过, 要么第一次买入; 不持有: 要么维持之前不持有的状态, 要么今天买了 dp = [max(dp[0], -price), max(dp[1], dp[0] + price)] return max(dp) 122. 买卖股票的最佳时机 II-简单可以多次交易, 统计最大利润和题目链接: https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/ DescriptionSay you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Note: You may not engage in multiple transactions at the same time (i.e., you must sell the stock before you buy again). Example 1:123Input: [7,1,5,3,6,4]Output: 7Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4.Then buy on day 4 (price = 3) and sell on day 5 (price = 6), profit = 6-3 = 3. Example 2:123Input: [1,2,3,4,5]Output: 4Explanation: Buy on day 1 (price = 1) and sell on day 5 (price = 5), profit = 5-1 = 4. Note that you cannot buy on day 1, buy on day 2 and sell them later, as you are engaging multiple transactions at the same time. You must sell before buying again. Example 3:123Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 解法一: 用变量维护最低价格时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 寻找递增序列, 一旦出现递减的情况, 则说明应该及时卖出, 并将 min_price 重新赋值. 因为最后一个元素后面没有值来判断是否递减, 因此需要对最后一个元素进行单独判断12345678910111213141516171819class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size() ==0) return 0 ; int min_price = prices[0]; int sum_profit = 0, pre_price=prices[0]; for(int i=1; i&lt;prices.size(); i++)&#123; if(prices[i] &lt; pre_price)&#123; //如果小于之前的price, 则说明此时应该卖出 sum_profit += pre_price-min_price; //计算卖出利润 min_price = prices[i]; &#125; pre_price = prices[i]; if(i==prices.size()-1 &amp;&amp; prices[i] &gt; min_price) //到了最后一个元素, 查看是否应该卖出 sum_profit += prices[i] - min_price; &#125; return sum_profit; &#125;&#125;; 同样和上一道题一样, 利用 buy 可以更加整洁的实现:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int max_profit = 0; int buy = 0; for(int i=1; i&lt;prices.size(); i++)&#123; if(prices[buy] &lt; prices[i]) max_profit += prices[i] - prices[buy]; buy = i; &#125; return max_profit; &#125;&#125;; 解法二: 每两个相邻数字当做一次交易时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 实际上和解法一本质相同, 只不过在累加利润上有一点小区别.该解法是将每两个相邻数字看做是一次交易, 如果后者大于前者, 说明应该执行交易, 并累加交易所的利润.12345678910Cclass Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int sum_profit = 0; for(int i =1 ; i&lt;prices.size(); i++)&#123; if(prices[i] &gt; prices[i-1]) sum_profit += prices[i] - prices[i-1]; &#125; return sum_profit; &#125;&#125;; 解法三: 通用 DP 解法详细分析见后面的 “股票问题通用解法” Python 实现:12345678class Solution: def maxProfit(self, prices: List[int]) -&gt; int: if len(prices) &lt;= 1: return 0 dp = [-prices[0], 0] # 持有, 不持有, base case for price in prices[1:]: # 更新状态[max(维持持有; 之前不持有, 今天买入), max(维持不持有; 之前持有, 今天卖出)] dp = [max(dp[0], dp[1]-price), max(dp[1], dp[0]+price)] return max(dp) C++ 实现:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.size() &lt;=1) return 0; int dp[2] = &#123;-prices[0], 0&#125;; // base case for (int i = 1; i &lt; prices.size(); i++) &#123; int hold = std::max(dp[0], dp[1]-prices[i]); // update int not_hold = std::max(dp[1], dp[0]+prices[i]); dp[0] = hold; dp[1] = not_hold; &#125; return std::max(dp[0], dp[1]); &#125;&#125;; 123. 买卖股票的最佳时机 III-困难题目链接: https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/ 解法三: 通用 DP 解法时间复杂度: $O(2n)$空间复杂度: $O(2k)$, dp 数组的空间是否可以进一步压缩? 答案是不行的, 表面上看起来, dp[k] 只会用到 dp[k-1] 即相邻的状态, 但是实际上, 这里用到的是上一轮循环中的结果, 我们必须把这一轮训练的结果都存储下来, 才能进行到下一轮, 因此这里的空间复杂度不能优化了. 详细分析见后面的 “股票问题通用解法” Python 实现:123456789101112131415class Solution: def maxProfit(self, prices: List[int]) -&gt; int: if len(prices) &lt;= 1: return 0 k = 2 # k 代表最大的可交易次数, 该解法可以轻松扩展至 k 次的情况 dp = [None] * (k+1) dp[0] = [0, 0] # 至多 0 次交易, 则均为0(不能持有) for i in range(1, k+1): # base case, 至多 1 次交易时, dp 的状态 dp[i] = [-prices[0], 0] for price in prices[1:]: for i in range(1, k+1): # 至多进行 i 次交易, 以买入计算交易次数 # 持有: 本次不买入(维持持有), 本次买入, 交易次数增加(之前不持有, 本次消费利润) # 不持有: 维持不持有, 或者之前持有, 本次卖出(只计入买入次数即可) dp[i] = [max(dp[i][0], dp[i-1][1]-price), max(dp[i][1], dp[i][0]+price)] return max(dp[k]) C++ 实现:12345678910111213141516class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.size() &lt;= 1) return 0; int k = 2; std::vector&lt;std::pair&lt;int, int&gt;&gt; dp(k+1, &#123;-prices[0], 0&#125;); // base case: [hold, not_hold] for (int i = 1; i &lt; prices.size(); i++) &#123; for (int j = 1; j &lt; k+1; j++) &#123; int hold = std::max(dp[j].first, dp[j-1].second-prices[i]); // 买入计入交易次数 int not_hold = std::max(dp[j].second, dp[j].first+prices[i]); // 卖出不计入次数 dp[j].first = hold; dp[j].second = not_hold; &#125; &#125; return std::max(dp[k].first, dp[k].second); &#125;&#125;; 124. Binary Tree Maximum Path Sum求二叉树中, 以任意节点为起始的路径和(这里是将二叉树看成无向图来计算路径的)的最大值, 例如对于下面的二叉树, 具有最大值的为:2-&gt;1-&gt;3 = 6123 1 / \2 3 Description: 求最长路径加权和Given a non-empty binary tree, find the maximum path sum. For this problem, a path is defined as any sequence of nodes from some starting node to any node in the tree along the parent-child connections. The path must contain at least one node and does not need to go through the root. Example 1:12345Input: [1,2,3] 1 / \ 2 3Output: 6 Example 2:1234567Input: [-10,9,20,null,null,15,7] -10 / \ 9 20 / \ 15 7Output: 42 解法一: 递归这道题的难点在于能否解读出题目的求值过程实际上是一个后序遍历的过程. 对于本题来说, 我们需要求得每个节点所在的路径的最大值, 以下面的例子来说:12345 4 / \ 11 13 / \7 2 我们需要求的最大和的路径为: 7-&gt;11-&gt;4-&gt;13. 而根据二叉树的遍历性质, 我们假设现在已经遍历到节点7, 此时, 左右子树均为空, 所以左右子树的最大和为0, 那么此时节点7所在的路径的最大和为: 左子树+右子树+当前节点值 = 7. 然后, 回溯到了节点11, 此时同理, 节点11所在的路径的最大和为: 左子树+右子树+当前节点值 = 11.(忽略节点2的遍历过程). 接下来对于节点4, 同理也应为: 左子树+右子树+当前节点值. 右子树返回的值很容易看出是13, 但是左子树应该返回多少呢? 由于我们希望求得当前的最大和, 因此, 左子树就应该返回它的最大和, 但是, 不能统计两条路径, 而应该选择以左节点为根节点的左右子树的较大者, 因此, 应该返回的是: max(左节点左子树, 左节点右子树)+左节点的值, 因此, 返回的是: 7+11 = 18. 于是, 节点4对应的最大和就为: 18+13+4. 可以看到, 这实际上就是一个后序遍历的过程. 12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int maxPathSum(TreeNode* root) &#123; int res=INT_MIN; helper(root, res); return res; &#125; int helper(TreeNode* cur_node, int &amp;res)&#123; if(cur_node==nullptr) return 0; int left = std::max(helper(cur_node-&gt;left, res), 0); int right = std::max(helper(cur_node-&gt;right, res), 0); res = std::max(res, left+right+cur_node-&gt;val); return std::max(left, right)+cur_node-&gt;val; &#125;&#125;; 解法二: 迭代后序遍历的迭代实现 125 Valid Palindrome判断是否为回文子串 DescriptionGiven a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases. Note: For the purpose of this problem, we define empty string as valid palindrome. Example 1: Input: “A man, a plan, a canal: Panama”Output: trueExample 2: Input: “race a car”Output: false 解法一: 前后两个指示变量, 向中间遍历判断时间复杂度: $O(n)$, 遍历一次空间复杂度: $O(1)$, 只额外用了两个变量 需要注意的是将大小写字母转换成同大写或者同小写的形式再进行判断 写法一:123456789101112131415161718192021222324class Solution &#123;public: bool isPalindrome(string s) &#123; for(int i=0, j=s.size()-1; i&lt;j; )&#123; if(is_alphanumeric(s[i]) == false)&#123; i++; continue; &#125; if(is_alphanumeric(s[j]) == false)&#123; j--; continue; &#125; if(std::tolower(s[i]) != std::tolower(s[j])) return false; i++; j--; &#125; return true; &#125; bool is_alphanumeric(char c)&#123; if(c&gt;='0' &amp;&amp; c&lt;='9') return true; else if(c&gt;='a' &amp;&amp; c&lt;='z') return true; else if(c&gt;='A' &amp;&amp; c&lt;='Z') return true; else return false; &#125;&#125;; 写法二: 12345678910111213141516171819class Solution &#123;public: bool isPalindrome(string s) &#123; for(int i=0, j=s.size()-1; i&lt;=j;i++,j-- )&#123; while(i&lt;s.size() &amp;&amp; is_alphanumeric(s[i]) == false) i++; while(j&gt;=0 &amp;&amp; is_alphanumeric(s[j]) == false) j--; if(std::tolower(s[i]) != std::tolower(s[j])) return false; &#125; return true; &#125; bool is_alphanumeric(char c)&#123; if(c&gt;='0' &amp;&amp; c&lt;='9') return true; else if(c&gt;='a' &amp;&amp; c&lt;='z') return true; else if(c&gt;='A' &amp;&amp; c&lt;='Z') return true; else return false; &#125;&#125;; 127. Word Ladder实际上是图的BFS(广度优先搜索) DescriptionGiven two words (beginWord and endWord), and a dictionary’s word list, find the length of shortest transformation sequence from beginWord to endWord, such that: Only one letter can be changed at a time.Each transformed word must exist in the word list. Note that beginWord is not a transformed word.Note: Return 0 if there is no such transformation sequence.All words have the same length.All words contain only lowercase alphabetic characters.You may assume no duplicates in the word list.You may assume beginWord and endWord are non-empty and are not the same.Example 1:123456789Input:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]Output: 5Explanation: As one shortest transformation is &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;,return its length 5. Example 2:12345678Input:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]Output: 0Explanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation. 解法一: BFS时间复杂度: $O(nl)$, 其中, $l$ 为单词的长度, $n$ 是单词的数量, 因为广度优先遍历会对每个节点遍历一次, 而每个节点计算邻居时, 需要对 $l$ 个字母进行替换(替换26种, 常数级别), 另外, unordered_set 的 find 复杂度也为常数.空间复杂度: $O(n)$ 需要额外借助队列进行广度优先遍历, 另外还使用了 unordered_set 来存储单词表 我们可以将此题看做是图的广度优先搜索, 首先, 以 beginWord 为图的起始节点, 然后, 那些所有与 beginWord 只有一个字母不相同的单词都可以看做是 beginWord 的邻居节点, 依次类推, 直到找到一个单词, 与 endWord 相同为止, 此时, 返回当前 endWord 与 beginWord 的距离. (距离的记录方式和二叉树层次遍历时的方式差不多, 都是利用当前队列中的元素大小来控制深度的). 需要注意的地方有以下几点: 这里的图和树不太一样, 这里图没有链表指针来指示, 因此, 在每次将某一个单词入队列以后, 都需要在单词列表中删除掉这个单词(或者额外设置标记也行), 以防止重复搜索 题目给的是没有重复单词的单词表, 因此推荐使用 set 结构来进行删除 (erase) 操作, vector 结构的删除 (erase) 操作的时间复杂度较高. 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) &#123; std::unordered_set&lt;string&gt; word_dict; for(auto word : wordList) word_dict.insert(word); std::queue&lt;string&gt; to_visit; //word_dict.erase(beginWord); //beginWord本来就不在字典中 to_visit.push(beginWord); int dist = 1; while(!to_visit.empty())&#123; int len = to_visit.size(); for(int i =0; i&lt;len; i++)&#123; string word = to_visit.front(); to_visit.pop(); if(word == endWord) return dist; add_next_word(word, word_dict, to_visit); &#125; dist++; &#125; return 0; &#125; void add_next_word(string &amp;word, std::unordered_set&lt;string&gt; &amp;word_dict, std::queue&lt;string&gt; &amp;to_visit)&#123; // word_dict.erase(word); for(int i=0; i&lt;word.size(); i++)&#123; char letter = word[i]; for(int k=0; k&lt;26; k++)&#123; word[i] = 'a'+k; if(word_dict.find(word) != word_dict.end())&#123; to_visit.push(word); word_dict.erase(word); &#125; &#125; word[i] = letter; &#125; &#125;&#125;; 128. Longest Consecutive Sequence返回无序数组中, 可以组成的最长的连续子串的长度 DescriptionGiven an unsorted array of integers, find the length of the longest consecutive elements sequence. Your algorithm should run in O(n) complexity. Example: Input: [100, 4, 200, 1, 3, 2]Output: 4Explanation: The longest consecutive elements sequence is [1, 2, 3, 4]. Therefore its length is 4. 解法一: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 先排序, 然后在从头往后遍历, 并用一个变量维护当前的最长连续序列的长度. 解法二: 利用哈希表时间复杂度: $O(n)$空间复杂度: $O(n)$ 利用 unordered_set 将所有的数字存储起来, 然后遍历每一个数字 num, 查看这个数字是否为所在连续序列的开头(即查看 num-1 是否存在). 若 num 就是所在连续序列的开头, 则查看当前序列的长度, 并更新最大长度. 故而时间复杂度为 $O(n+n) = O(n)$. 同时, 因为使用了 unordered_set, 所以空间复杂度为 $O(n)$.123456789101112131415161718class Solution &#123;public: int longestConsecutive(vector&lt;int&gt;&amp; nums) &#123; unordered_set&lt;int&gt; sets(nums.begin(), nums.end()); int longest = 0; for(auto num : sets)&#123; if(sets.find(num-1) == sets.end())&#123; int cur_len = 1; while(sets.find(num+1) !=sets.end())&#123; num++; cur_len++; &#125; if(longest &lt; cur_len) longest = cur_len; &#125; &#125; return longest; &#125;&#125;; 解法三: 另一种哈希表用法时间复杂度: $O(n)$空间复杂度: $O(n)$ 主题思想与解法二相同, 不过是从另一角度来使用 unordered_map, 首先, 依然利用 unordered_map 将 nums 存储起来, 然后遍历 nums, 对于 nums 中的每一个 num, 查看其是否存在于 unordered_map 中, 如果存在, 则分别向左向右查找当前数字 num 所在序列的最左端和最右端的数字, 同时, 将在 unordered_map 中遍历过的数字都移除(因为每个数字只可能唯一的属于一个连续序列). 之后, 利用最左端和最右端来更新最长连续序列的长度. 这样, 遍历的时间复杂度也为 $O(n+n) = O(n)$ 12345678910111213141516171819class Solution &#123;public: int longestConsecutive(vector&lt;int&gt;&amp; nums) &#123; unordered_set&lt;int&gt; sets(nums.begin(), nums.end()); int longest = 0; for(auto num : nums)&#123; if(sets.find(num)!=sets.end())&#123; sets.erase(num); int pre = num-1, next = num+1; while(sets.find(pre)!=sets.end()) sets.erase(pre--); while(sets.find(next)!=sets.end()) sets.erase(next++); if(longest &lt; next-pre) longest = next-pre-1; &#125; &#125; return longest; &#125;&#125;; 130. Surrounded Regions类似于围棋, 将被包裹住(4连通)的字符 O 全部转换成字符 X. DescriptioinGiven a 2D board containing ‘X’ and ‘O’ (the letter O), capture all regions surrounded by ‘X’. A region is captured by flipping all ‘O’s into ‘X’s in that surrounded region. Example: X X X XX O O XX X O XX O X XAfter running your function, the board should be: X X X XX X X XX X X XX O X XExplanation: Surrounded regions shouldn’t be on the border, which means that any ‘O’ on the border of the board are not flipped to ‘X’. Any ‘O’ that is not on the border and it is not connected to an ‘O’ on the border will be flipped to ‘X’. Two cells are connected if they are adjacent cells connected horizontally or vertically. 解法一: 递归时间复杂度: $O(n)$, n 为 board 中的元素个数空间复杂度: $O(n)$, 递归深度优先遍历的递归次数最坏情况下为 n 次. 根据题目的要求, 我们可以从 board 的四个边界开始, 每遇到一次 O 就执行深度优先遍历, 将其相邻的所有 O 都变成另一个字符(如 #). 然后, 在顺序遍历整个 board, 将 board 中所有的 O 变成 X, 将所有的 # 变成 O, 即得解. 123456789101112131415161718192021222324252627282930class Solution &#123;public: void solve(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; if(board.size()==0 || board[0].size()==0) return; for(int i=0, j=0; j&lt;board[i].size(); j++) //上边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=1, j=board[i].size()-1; i&lt;board.size()-1; i++) //右边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=board.size()-1, j=0; j&lt;board[i].size(); j++) //下边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=1, j=0; i&lt;board.size()-1; i++) //左边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[i].size(); j++)&#123; if(board[i][j]=='O') board[i][j]='X'; else if(board[i][j]=='#') board[i][j]='O'; &#125; &#125; &#125; void dfs_helper(int i, int j, vector&lt;vector&lt;char&gt;&gt; &amp;board)&#123; board[i][j]='#'; if(i&gt;0 &amp;&amp; board[i-1][j]=='O') dfs_helper(i-1, j, board); if(j&gt;0 &amp;&amp; board[i][j-1]=='O') dfs_helper(i, j-1, board); if(i&lt;board.size()-1 &amp;&amp; board[i+1][j]=='O') dfs_helper(i+1, j, board); if(j&lt;board[i].size()-1 &amp;&amp; board[i][j+1]=='O') dfs_helper(i, j+1, board); //注意是 j&lt;board[i].size()-1, 不是 board.size()-1 &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$, n 为 board 中的元素个数空间复杂度: $O(n)$, 额外申请队列的大小为 n 思想和解法一相同, 不过采用 BFS 迭代实现, 利用一个队列来实现 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: void solve(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; if(board.size()==0 || board[0].size()==0) return; for(int i=0, j=0; j&lt;board[i].size(); j++) //上边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=1, j=board[i].size()-1; i&lt;board.size()-1; i++) //右边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=board.size()-1, j=0; j&lt;board[i].size(); j++) //下边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=1, j=0; i&lt;board.size()-1; i++) //左边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[i].size(); j++)&#123; if(board[i][j]=='O') board[i][j]='X'; else if(board[i][j]=='#') board[i][j]='O'; &#125; &#125; &#125; void bfs_helper(int i, int j, vector&lt;vector&lt;char&gt;&gt; &amp;board)&#123; std::queue&lt;int&gt; bfs_q; int len = board[i].size(); bfs_q.push(i*len +j); board[i][j]='#'; while(!bfs_q.empty())&#123; i = bfs_q.front()/len; j = bfs_q.front()%len; bfs_q.pop(); if(i&gt;0 &amp;&amp; board[i-1][j]=='O')&#123; board[i-1][j]='#';bfs_q.push( (i-1)*len+j); &#125; //注意这里一定要更改了字符以后再存入队列, 负责可能引起字符重复入队列, 最终内存超限 if(j&gt;0 &amp;&amp; board[i][j-1]=='O') &#123; board[i][j-1]='#'; bfs_q.push( i*len+j-1); &#125; if(i&lt;board.size()-1 &amp;&amp; board[i+1][j]=='O') &#123; board[i+1][j]='#'; bfs_q.push( (i+1)*len + j );&#125; if(j&lt;board[i].size()-1 &amp;&amp; board[i][j+1]=='O') &#123; board[i][j+1]='#'; bfs_q.push( i*len + j+1); &#125; &#125; &#125;&#125;; 131. Palindrome Partitioning划分回文子串 Description解法一: 回溯+验证回文子串时间复杂度: $O(n\times 2^n)$, 其中, 可能的 partition 情况最多有 $2^n$ 种, 而对于每一种都要进行复杂度为 $O(n)$ 的回文子串检查空间复杂度: $O(n\times 2^n)$ ? 数组 res 的大小最坏情况下可达 $(n\times 2^n)$. 12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; partition(string s) &#123; vector&lt;vector&lt;string&gt;&gt; res; vector&lt;string&gt; part_res; dfs(s, 0, part_res, res); return res; &#125; void dfs(string s, int start, vector&lt;string&gt; &amp;part_res, vector&lt;vector&lt;string&gt;&gt; &amp;res)&#123; if(start == s.size())&#123; res.push_back(part_res); &#125; for(int i=start; i&lt;s.size(); i++)&#123; if(is_palin(start, i, s))&#123; part_res.push_back(s.substr(start, i-start+1)); dfs(s, i+1, part_res, res); part_res.pop_back(); &#125; &#125; &#125; bool is_palin(int start, int end, string s)&#123; while(start &lt; end)&#123; if(s[start]!=s[end]) return false; start++;end--; &#125; return true; &#125;&#125;; 解法二: 回溯+DP时间复杂度: $O(2^n)$, 利用 DP 建立一个 $n\times n$ 的 bool 数组, 其中 dp[i][j] 代表字符串从第 i 个字符开始, 到第 j 个字符组成的子串是否为回文串. 因此, 检查回文串时无需执行 $O(n)$ 的检查.空间复杂度: $O(n\times 2^n + n^2)$, 需要额外的数组空间来实现 DP. 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; partition(string s) &#123; vector&lt;vector&lt;string&gt;&gt; res; vector&lt;string&gt; part_res; vector&lt;vector&lt;bool&gt;&gt; dp(s.size(), vector&lt;bool&gt;(s.size(), false)); for(int j=0; j&lt;s.size(); j++)&#123; for(int i=0; i&lt;=j; i++)&#123; // 注意这两个for循环的顺序和控制条件, dp算法一定要保证在计算当前元素时, 之前的元素已经计算完成并且存入到了数组当中, 否则建立出的dp数组会出现漏解 if(s[i]==s[j] &amp;&amp; (j-i&lt;=2 || dp[i+1][j-1]==true)) dp[i][j]=true; &#125; &#125; dfs(s, 0, part_res, res, dp); return res; &#125; void dfs(string s, int start, vector&lt;string&gt; &amp;part_res, vector&lt;vector&lt;string&gt;&gt; &amp;res, vector&lt;vector&lt;bool&gt;&gt; &amp;dp )&#123; if(start == s.size())&#123; res.push_back(part_res); &#125; for(int i=start; i&lt;s.size(); i++)&#123; if(dp[start][i]==true)&#123; part_res.push_back(s.substr(start, i-start+1)); dfs(s, i+1, part_res, res, dp); part_res.pop_back(); &#125; &#125; &#125; bool is_palin(int start, int end, string s)&#123; while(start &lt; end)&#123; if(s[start]!=s[end]) return false; start++;end--; &#125; return true; &#125;&#125;; 134. Gas Station加油站问题, 根据油量和消耗量判断是否能走完一圈 DescriptionThere are N gas stations along a circular route, where the amount of gas at station i is gas[i]. You have a car with an unlimited gas tank and it costs cost[i] of gas to travel from station i to its next station (i+1). You begin the journey with an empty tank at one of the gas stations. Return the starting gas station’s index if you can travel around the circuit once in the clockwise direction, otherwise return -1. Note: If there exists a solution, it is guaranteed to be unique.Both input arrays are non-empty and have the same length.Each element in the input arrays is a non-negative integer.Example 1: Input:gas = [1,2,3,4,5]cost = [3,4,5,1,2] Output: 3 Explanation:Start at station 3 (index 3) and fill up with 4 unit of gas. Your tank = 0 + 4 = 4Travel to station 4. Your tank = 4 - 1 + 5 = 8Travel to station 0. Your tank = 8 - 2 + 1 = 7Travel to station 1. Your tank = 7 - 3 + 2 = 6Travel to station 2. Your tank = 6 - 4 + 3 = 5Travel to station 3. The cost is 5. Your gas is just enough to travel back to station 3.Therefore, return 3 as the starting index.Example 2: Input:gas = [2,3,4]cost = [3,4,3] Output: -1 Explanation:You can’t start at station 0 or 1, as there is not enough gas to travel to the next station.Let’s start at station 2 and fill up with 4 unit of gas. Your tank = 0 + 4 = 4Travel to station 0. Your tank = 4 - 3 + 2 = 3Travel to station 1. Your tank = 3 - 3 + 3 = 3You cannot travel back to station 2, as it requires 4 unit of gas but you only have 3.Therefore, you can’t travel around the circuit once no matter where you start. 解法: 最优时间复杂度: $O(n)$空间复杂度: $O(1)$ 首先要知道, 如果总油量大于总消耗量, 那么就一定存在一个起始点, 使得可以走完全程. 因此, 设置两个变量 total_left 和 cur_left, 前者存储从0点开始的总的剩余量, 后者存储从起点 start 开始的剩余量. 当 cur_left&lt;=0 时, 说明从 start 开始一直到当前位置之间的任何一个加油站都不能够成为起点, 因此将 start 置为下一个位置, 重新开始, 并令 cur_left=0. 在遍历完所有加油站以后, 如果总的剩余量不小于0, 则此时 start 所指的位置就一定是解.(由题意知, 该解是唯一解). 1234567891011121314151617class Solution &#123;public: int canCompleteCircuit(vector&lt;int&gt;&amp; gas, vector&lt;int&gt;&amp; cost) &#123; int total_left = 0; int cur_left =0; int start=0; for(int i=0; i&lt;gas.size(); i++)&#123; total_left += gas[i]-cost[i]; cur_left += gas[i]-cost[i]; if(cur_left&lt;0)&#123; start = i+1; cur_left=0; &#125; &#125; return total_left &lt; 0 ? -1:start; &#125;&#125;; 136. Single Number数组中有一个数字出现了1次(奇数次), 其他均出现了2次(偶数次), 找到出现1次(奇数次)的数字. DescriptionGiven a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? Example 1: Input: [2,2,1]Output: 1Example 2: Input: [4,1,2,1,2]Output: 4 解法一: 哈希时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 哈希表额外空间 遍历数组, 对于每一个数, 如果当前的数存在于hash表中, 则将表中哈希删除, 如果不存在, 则添加到哈希表中, 最终, 哈希表中存在的值就是只出现一次的值 解法二: 数学公式2\times (a + b + c) - (a+b+a+b+c) = c. 将数组中的元素转换为 set(无重复元素), 然后利用上面的公式纠结时间复杂度: $O(n + n)=O(n)$, 转换为 set 需要 $O(n), 公式求解遍历也需要 $O(n)$空间复杂度: $O(n)$. set 所占额外空间 解法三: 异或任何数和0异或不变, 和自身异或变为0123456789class Solution &#123;public: int singleNumber(vector&lt;int&gt;&amp; nums) &#123; int res=0; for(auto num : nums) res ^= num; return res; &#125;&#125;; 其他更多扩展问题可看剑指Offer第40题. 138. Copy List with Random Pointer复杂链表的复制, 复制带有随机指针的链表 DescriptionA linked list is given such that each node contains an additional random pointer which could point to any node in the list or null. Return a deep copy of the list. 解法一: 复制+拆分时间复杂度: $O(n)$, 遍历三次链表空间复杂度: $O(1)$, 不包括复制链表占用的空间 先将每个节点复制到对应节点的后面, 然后给随机指针进行赋值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*// Definition for a Node.class Node &#123;public: int val; Node* next; Node* random; Node() &#123;&#125; Node(int _val, Node* _next, Node* _random) &#123; val = _val; next = _next; random = _random; &#125;&#125;;*/class Solution &#123;public: Node* copyRandomList(Node* head) &#123; if (head == nullptr) return nullptr; Node* node = head; Node* copyNode = nullptr; while (node != nullptr) &#123; // 复制节点 copyNode = new Node(node-&gt;val, node-&gt;next, node-&gt;random); node-&gt;next = copyNode; node = node-&gt;next-&gt;next; &#125; node = head; while (node != nullptr) &#123; // 设值 random 的值 copyNode = node-&gt;next; if (node-&gt;random != nullptr) &#123; copyNode-&gt;random = node-&gt;random-&gt;next; &#125; node = node-&gt;next-&gt;next; &#125; node = head; Node* copyHead = head-&gt;next; while (node != nullptr) &#123; // 拆分两个链表 copyNode = node-&gt;next; node-&gt;next = node-&gt;next-&gt;next; if (copyNode-&gt;next != nullptr) &#123; copyNode-&gt;next = copyNode-&gt;next-&gt;next; &#125; node = node-&gt;next; // 不要忘了让 node 指向下一个节点 &#125; return copyHead; &#125;&#125;; 解法二: 一次遍历时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 需要申请链表长度的哈希表 利用一个哈希表来存储已经访问过的节点, 哈希表的键值为: {cur_node, copy_node}, 其中, cur_node 代表旧链表中的节点, copy_node 代表新链表中的节点. 顺序遍历旧链表, 对于旧链表中的每一个节点, 查看其 next 节点是否存在于哈希表 visit 中, 如果存在, 则将 copy_node 的 next 指针指向该节点(键)对应的复制节点(值). 对于 random 指针也是同理 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: RandomListNode *copyRandomList(RandomListNode *head) &#123; if(head==nullptr) return nullptr; RandomListNode *cur_node = head; RandomListNode *copy_node = new RandomListNode(head-&gt;label); unordered_map&lt;RandomListNode *, RandomListNode *&gt; visit; // key: old_node, value: copy_node visit.insert(&#123;cur_node, copy_node&#125;); //注意不要少了花括号 while(cur_node!=nullptr)&#123; RandomListNode *next_node=nullptr; if(cur_node-&gt;next==nullptr) copy_node-&gt;next = nullptr; else if(visit.find(cur_node-&gt;next)==visit.end())&#123; next_node = new RandomListNode(cur_node-&gt;next-&gt;label); copy_node-&gt;next = next_node; visit.insert(&#123;cur_node-&gt;next, next_node&#125;); &#125;else copy_node-&gt;next = visit[cur_node-&gt;next]; RandomListNode *random_node=nullptr; if(cur_node-&gt;random==nullptr) copy_node-&gt;random = nullptr; else if(visit.find(cur_node-&gt;random) == visit.end())&#123; random_node = new RandomListNode(cur_node-&gt;random-&gt;label); copy_node-&gt;random = random_node; visit.insert(&#123;cur_node-&gt;random, random_node&#125;); &#125;else copy_node-&gt;random = visit[cur_node-&gt;random]; cur_node = cur_node-&gt;next; copy_node = copy_node-&gt;next; &#125; return visit[head]; &#125;&#125;; 解法三: 递归时间复杂度: $O(n)$空间复杂度: $O(n)$, 除了哈希表所占空间外, 递归还需额外空间, 但是可以近似看做是 $O(n)$ 123456789101112131415class Solution &#123; unordered_map&lt;RandomListNode *, RandomListNode *&gt; visit;public: RandomListNode *copyRandomList(RandomListNode *head) &#123; if(head==nullptr) return nullptr; if(visit.find(head)!=visit.end()) return visit[head]; RandomListNode *node = new RandomListNode(head-&gt;label); visit.insert(&#123;head, node&#125;); node-&gt;next = copyRandomList(head-&gt;next); node-&gt;random = copyRandomList(head-&gt;random); return node; &#125;&#125;; 139. Word Break判断字符串是否可以划分成字典里面的单词 DescriptionGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, determine if s can be segmented into a space-separated sequence of one or more dictionary words. Note: The same word in the dictionary may be reused multiple times in the segmentation.You may assume the dictionary does not contain duplicate words.Example 1: Input: s = “leetcode”, wordDict = [“leet”, “code”]Output: trueExplanation: Return true because “leetcode” can be segmented as “leet code”.Example 2: Input: s = “applepenapple”, wordDict = [“apple”, “pen”]Output: trueExplanation: Return true because “applepenapple” can be segmented as “apple pen apple”. Note that you are allowed to reuse a dictionary word.Example 3: Input: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]Output: false 解法一: 回溯时间复杂度: 超时空间复杂度: $O(1)$ 123456789101112131415161718192021class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; // 纯回溯实现, 复杂度很高, 很容易超时 unordered_set&lt;string&gt; word_dict(wordDict.begin(), wordDict.end()); return helper(s,-1,word_dict); &#125; bool helper(string &amp;s, int seg, unordered_set&lt;string&gt; &amp;word_dict)&#123; if(seg==s.size()-1) return true; string temp=""; for(int i=seg+1; i&lt;s.size(); i++)&#123; temp+=s[i]; if(word_dict.find(temp) != word_dict.end() &amp;&amp; helper(s, i, word_dict)==true)&#123; return true; &#125; &#125; return false; &#125;&#125;; 解法二: DP时间复杂度: $O(n^2)$, $n$ 为字符串的长度空间复杂度: $O(n)$, dp 数组额外空间, unordered_set 额外空间 1234567891011121314151617181920class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_set&lt;string&gt; word_dict(wordDict.begin(), wordDict.end()); if(wordDict.size()==0) return false; vector&lt;bool&gt; dp(s.size(), false); for(int i=0; i&lt;s.size(); i++)&#123; for(int j=i; j&gt;=0; j--)&#123; if(j-1&lt;0 || dp[j-1]==true)&#123; string temp = s.substr(j, i-j+1); if(word_dict.find(temp) != word_dict.end())&#123; dp[i]=true; break; // break to next i &#125; &#125; &#125; &#125; return dp.back(); &#125;&#125;; 解法三: DP时间复杂度: $O(nm)$, $n$ 为字符串的长度, $m$ 为字典的 size空间复杂度: $O(n)$, dp 数组额外空间 12345678910111213141516171819class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_set&lt;string&gt; word_dict(wordDict.begin(), wordDict.end()); if(wordDict.size()==0) return false; vector&lt;bool&gt; dp(s.size(), false); for(int i=0; i&lt;s.size(); i++)&#123; for(int j=0; j&lt;wordDict.size(); j++)&#123; if(i&gt;=wordDict[j].size()-1)&#123; int len = wordDict[j].size(); string temp= s.substr(i-len+1, len); if(temp == wordDict[j] &amp;&amp; ((i-len)&lt;0 || dp[i-len]==true))// 这里注意, .size() 返回的类型并不是int, 如果使用i-wordDict[j].size() &lt;0, 就会造成runtime error, 正确做法是进行强制的类型转换, 或者用一个int变量代表之. dp[i]=true; &#125; &#125; &#125; return dp.back(); &#125;&#125;; 更简洁的写法:123456789101112131415class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; vector&lt;bool&gt; dp(s.size(), false); for (int i = 0; i &lt; s.size(); i++) &#123; for (auto const&amp; word : wordDict) &#123; int lenW = word.size(); if (!dp[i] and i+1 &gt;= lenW and word == s.substr(i-lenW+1, lenW)) &#123; dp[i] = (i-lenW+1 == 0) ? true : dp[i-lenW]; &#125; &#125; &#125; return dp[s.size() - 1]; &#125;&#125;; 140. Word Break IIDescriptionGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, add spaces in s to construct a sentence where each word is a valid dictionary word. Return all such possible sentences. Note: The same word in the dictionary may be reused multiple times in the segmentation.You may assume the dictionary does not contain duplicate words.Example 1: Input:s = “catsanddog”wordDict = [“cat”, “cats”, “and”, “sand”, “dog”]Output:[ “cats and dog”, “cat sand dog”]Example 2: Input:s = “pineapplepenapple”wordDict = [“apple”, “pen”, “applepen”, “pine”, “pineapple”]Output:[ “pine apple pen apple”, “pineapple pen apple”, “pine applepen apple”]Explanation: Note that you are allowed to reuse a dictionary word.Example 3: Input:s = “catsandog”wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]Output:[] 解法一: DP直接使用回溯法, 有大量重复计算, 导致时间超时, 无法通过 OJ, 因此考虑 DP 思想. 将中间的计算结果缓存起来, 再次遇到的时候无需重复计算, 只需直接使用即可.利用一个哈希表将每个字符串与该字符串能拆分出的句子联系起来, 其中, key 为字符串, value 为字符串拆分后的句子. 假设我们已经求出一个字符串的解为 res, 并将其存入到哈希表中, 此时, 如果在该字符串的前面再加上一个单词(单词表的中任意一个), 那么新的解就应该为: word+&quot; &quot;+res[i]. 代码实现如下. 注意, 这里我们要对 wordDict 进行遍历来查找可以拆分的情况, 如果是对字符串 s 查找可拆分情况, 那么哈希表中的键将会大幅增加, 例如对于&quot;aaaaaaaaaaa&quot;这种情况. 12345678910111213141516171819202122class Solution &#123;public: vector&lt;string&gt; wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_map&lt;string, vector&lt;string&gt;&gt; hash_dict; return DP_helper(s, wordDict, hash_dict); &#125; vector&lt;string&gt; DP_helper(string s, vector&lt;string&gt; &amp;wordDict, unordered_map&lt;string, vector&lt;string&gt;&gt; &amp;hash_dict)&#123; if(hash_dict.find(s)!=hash_dict.end()) return hash_dict[s]; if(s=="") return &#123;""&#125;; //这里必须返回具有一个元素("")的vector, 否则下面的push_back语句不会执行 vector&lt;string&gt; res; for(auto word : wordDict)&#123; if(s.substr(0, word.size()) != word) continue; vector&lt;string&gt; res_word = DP_helper(s.substr(word.size()), wordDict, hash_dict); //s.substr(word.size()) 代表截取剩余的字符, 所以有可能出现空字符的情况 for(auto str : res_word)&#123; // 如果返回的是空的vector, 则不会执行该语句, 因此, 不能返回空vector, 当遇到空字符串时, 因该返回 &#123;""&#125;, 即只有一个元素的vector, 该元素为"". res.push_back(word + (str==""? "":" ") + str); //这里根据 str的值来决定是否加空格, 如果str为空, 说明是word是最后一个字符, 则其后不应该添加空格 &#125; &#125; hash_dict[s] = res; return res; &#125;&#125;; 内存超限的写法: 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;string&gt; wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_map&lt;string, vector&lt;string&gt;&gt; hash; for (int i = 0; i &lt; s.size(); i++) &#123; vector&lt;string&gt; res; for (auto const&amp; word : wordDict) &#123; int lenW = word.size(); if (i+1 &gt;= lenW and s.substr(i-lenW+1, lenW) == word) &#123; if (i+1 == lenW) &#123; res.push_back(word); &#125; else &#123; string tmp_s = s.substr(0, i-lenW+1); if (hash.find(tmp_s) != hash.end()) &#123; auto tmp_words = hash[tmp_s]; for (auto str : tmp_words) &#123; res.push_back(str + " " + word); &#125; &#125; &#125; &#125; &#125; hash[s.substr(0, i+1)] = res; &#125; if (hash.find(s) != hash.end()) return hash[s]; return &#123;""&#125;; &#125;&#125;; 141. Linked List CycleDescriptionGiven a linked list, determine if it has a cycle in it. Follow up:Can you solve it without using extra space? 解法一: Floyd Cycle(Floyd 判圈算法)时间复杂度: $O(n+k)$, 可以认为是$O(n)$, $n$ 为链表长度, $k$ 为环长空间复杂度: $O(1)$ 从头结点开始, slow每次走一步, fast每次走两步, 那么只要有环, slow和fast就一定会在环中的某个节点处相遇, 如果无环, 则fast一定先到达空指针 12345678910111213class Solution &#123;public: bool hasCycle(ListNode *head) &#123; if (head == nullptr or head-&gt;next == nullptr) return false; ListNode* fast = head; ListNode* slow = head; do &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; while (slow != fast and fast!=nullptr and fast-&gt;next != nullptr); return slow == fast ? true : false; &#125;&#125;; 1234567891011121314151617181920212223/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool hasCycle(ListNode *head) &#123; if(head==nullptr) return false; ListNode* slow=head, *fast=head-&gt;next; while(fast!=nullptr &amp;&amp; slow != fast)&#123; slow= slow-&gt;next; if(fast-&gt;next == nullptr) return false; fast = fast-&gt;next-&gt;next; &#125; if(fast==nullptr) return false; return true; &#125;&#125;; 更多扩展见牛客第55题, 链表中环的入口节点 142. Linked List Cycle IIDescription: 求链表中环的开始节点Given a linked list, return the node where the cycle begins. If there is no cycle, return null. Note: Do not modify the linked list. Follow up:Can you solve it without using extra space? 解法一: Floyd 的乌龟和兔子(Floyd 判环算法)时间复杂度: $O(n)$空间复杂度: $O(1)$ 此题更多解析可以看剑指offer第55题 12345678910111213141516171819202122232425262728293031/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *detectCycle(ListNode *head) &#123; if(head==nullptr) return nullptr; ListNode *slow = head; ListNode *fast = head; do&#123; slow = slow-&gt;next; fast = fast-&gt;next; if(fast==nullptr) return fast;// 不存在环 fast = fast-&gt;next; if(fast==nullptr) return fast;// 不存在环 &#125;while(slow!=fast); fast = slow; slow = head; while(fast!=slow)&#123; slow = slow-&gt;next; fast = fast-&gt;next; &#125; return slow; &#125;&#125;; 144. Binary Tree Preorder TraversalDescription: 先根遍历Given a binary tree, return the preorder traversal of its nodes’ values. Example:123456Input: [1,null,2,3] 1 \ 2 / 3 Output: [1,2,3]Follow up: Recursive solution is trivial, could you do it iteratively? 解法一: 递归12345678910111213141516class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; std::vector&lt;int&gt; res; preorder(root, res); return res; &#125; void preorder(TreeNode* root, vector&lt;int&gt;&amp; res) &#123; if (root == nullptr) return; res.push_back(root-&gt;val); preorder(root-&gt;left, res); preorder(root-&gt;right, res); return; &#125;&#125;; 解法二: 迭代12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; std::vector&lt;int&gt; res; std::stack&lt;TreeNode*&gt; s; while (!s.empty() or root != nullptr) &#123; if (root != nullptr) &#123; res.push_back(root-&gt;val); s.push(root); root = root-&gt;left; &#125; else &#123; root = s.top(); s.pop(); root = root-&gt;right; &#125; &#125; return res; &#125;&#125;; 145. 二叉树的后序遍历Description题目链接: https://leetcode-cn.com/problems/binary-tree-postorder-traversal/ Given a binary tree, return the postorder traversal of its nodes’ values. Example:123456Input: [1,null,2,3] 1 \ 2 / 3 Output: [3,2,1]Follow up: Recursive solution is trivial, could you do it iteratively? 解法一: 递归C++ 实现12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; std::vector&lt;int&gt; res; postorder(root, res); return res; &#125; void postorder(TreeNode* root, std::vector&lt;int&gt;&amp; res) &#123; if (root == nullptr) return; postorder(root-&gt;left, res); postorder(root-&gt;right, res); res.push_back(root-&gt;val); return; &#125;&#125;; Python 实现123456789101112131415161718# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: def post_order(root, res): if (root.left is not None): post_order(root.left, res) if (root.right is not None): post_order(root.right, res) res.append(root.val) return res res = [] if root is None: return res post_order(root, res) return res 解法二: 迭代用一个变量 pre 来维护上一个输出的节点, 当上一个输出的节点是当前节点的右孩子的时候, 说明左右都遍历完了. C++ 实现12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; std::vector&lt;int&gt; res; std::stack&lt;TreeNode*&gt; s; TreeNode* pre = nullptr; while (!s.empty() or root != nullptr) &#123; while (root != nullptr) &#123; s.push(root); root = root-&gt;left; &#125; if (!s.empty()) &#123; auto node = s.top(); // 注意这里要用 node, 因为要将有可能进入 else, 此时没有对 root 赋新值, 所以使用 root 的话会陷入死循环 if (node-&gt;right != nullptr and pre != node-&gt;right) &#123; root = node-&gt;right; &#125; else &#123; res.emplace_back(node-&gt;val); pre = node; s.pop(); &#125; &#125; &#125; return res; &#125;&#125;; Python 实现1234567891011121314151617181920212223# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def postorderTraversal(self, root: TreeNode) -&gt; List[int]: res = [] stack = [] pre = None while(root or stack): # root 非空, 或者, 栈非空 while(root): # 左儿子一直入栈 stack.append(root) root = root.left node = stack[-1] # 取栈尾, 注意此时不一定访问栈尾 if node.right is None or node.right == pre: # 只有当右儿子为空或者右儿子已经被访问过时, 才能访问当前节点 res.append(node.val) pre = stack.pop() # 标记访问的节点, 以便进行右儿子的判断 else: root = node.right # 继续循环入栈 return res 146. LRU Cache实现一个 LRU 缓存器, 即 Least Recently Used (最近最少使用). DescriptionDesign and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations: get and put. get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.put(key, value) - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item. Follow up:Could you do both operations in O(1) time complexity? Example: LRUCache cache = new LRUCache( 2 ); // 2 is capacity cache.put(1, 1);cache.put(2, 2);cache.get(1); // returns 1cache.put(3, 3); // evicts key 2cache.get(2); // returns -1 (not found)cache.put(4, 4); // evicts key 1cache.get(1); // returns -1 (not found)cache.get(3); // returns 3cache.get(4); // returns 4 解法一: 利用哈希表和双端链表时间复杂度: $O(n)$, get和put均为 $O(n)$ 空间复杂度: $O(n)$, 哈希表和双端链表 利用哈希表(unordered_map)来存储键值对, 用于实现 $O(1)$ 复杂度的查找和返回特定键对应的值.利用双端链表(list)来维护LRU逻辑, 即每次访问(get)时, 如果键存在, 那么在返回之前, 还应当将list中的键移到最顶端(最后), 首先, 顺序遍历找到该键($O(n)$复杂度), 然后将其删除($O(1)$复杂度), 接着, 将其插入到最后一位上($O(1)$复杂度). 对于插入(put)的情况, 首先判断是否已经存在($O(1)$复杂度), 如果已经存在, 那么将其value值更新并将其移动至最顶端($O(n)$复杂度). 否则, 判断当前是否溢出, 如果溢出, 则将list中的首部key值删除, 并将对应的hash键值对也删除($O(1)$复杂度), 然后执行插入逻辑($O(1)$复杂度). 如果没有溢出, 则直接插入. C++ 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class LRUCache &#123;private: int L_capacity; std::unordered_map&lt;int, int&gt; kv_map; std::list&lt;int&gt; key_l;public: LRUCache(int capacity) &#123; L_capacity = capacity; &#125; int get(int key) &#123; if(kv_map.find(key) != kv_map.end())&#123;// 访问了key, 将其移到最顶端 for(auto it=key_l.begin(); it!=key_l.end(); it++)&#123; if(*it == key)&#123; key_l.erase(it); break; &#125; &#125; key_l.push_back(key); // 访问了key, 将其移到最顶端 return kv_map[key]; &#125; return -1; &#125; void put(int key, int value) &#123; if(kv_map.find(key) != kv_map.end())&#123;// 访问了key, 将其移到最顶端 for(auto it=key_l.begin(); it!=key_l.end(); it++)&#123; if(*it == key)&#123; key_l.erase(it); break; &#125; &#125; key_l.push_back(key);// 访问了key, 将其移到最顶端 kv_map[key]=value; //更新value值, 因为有可能同样的key对应的value不同 &#125;else if(key_l.size() == L_capacity)&#123; int evict_key = key_l.front(); key_l.pop_front(); // 删除最少访问的key kv_map.erase(evict_key); // 删除最少访问的key key_l.push_back(key); kv_map.insert(&#123;key, value&#125;); &#125;else&#123; key_l.push_back(key); kv_map.insert(&#123;key, value&#125;); &#125; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache obj = new LRUCache(capacity); * int param_1 = obj.get(key); * obj.put(key,value); */ Python 实现:123456789101112131415161718192021222324252627282930313233class LRUCache: def __init__(self, capacity: int): self.capacity = capacity self.cache = [] self.kv_dict = &#123;&#125; def get(self, key: int) -&gt; int: if key in self.kv_dict: # get 时, 如果存在, 则先将 key 更新成最近访问, 然后返回对应value self.cache.remove(key) self.cache.insert(0, key) return self.kv_dict[key] else: return -1 def put(self, key: int, value: int) -&gt; None: if key in self.kv_dict: # key 已存在, 此时容量不会爆, 只需更新最近访问值即可 self.kv_dict[key] = value self.cache.remove(key) self.cache.insert(0, key) elif len(self.cache) &gt;= int(self.capacity): # 容量要爆, 需要先删除最后的不常访问元素, 然后添加新元素 old_key = self.cache.pop() del self.kv_dict[old_key] self.cache.insert(0, key) self.kv_dict[key] = value else: # 容量不爆且原来没有, 则直接加入即可 self.cache.insert(0, key) self.kv_dict[key] = value# Your LRUCache object will be instantiated and called as such:# obj = LRUCache(capacity)# param_1 = obj.get(key)# obj.put(key,value) Follow Up时间复杂度: $O(1)$空间复杂度: $O(n)$ 上面的解法一的 $O(n)$ 复杂度主要是在查找满足键的迭代器上面, 而对于list来说, 有一个非常重要的性质, 那就是list的元素迭代器在list被修改后 仍然保持不变, 永远不会失效(永远删除该节点), 因此, 我们可以做一个小小的改动, 就是让哈希表中存储的不再是value, 而是直接对应list中的迭代器, 这样, 就可以直接访问迭代器进行元素的移除操作. C++ 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class LRUCache &#123; int capacity; std::list&lt;std::pair&lt;int, int&gt;&gt; linkList; std::unordered_map&lt;int, std::list&lt;std::pair&lt;int, int&gt;&gt;::iterator&gt; hash;public: LRUCache(int capacity) &#123; this-&gt;capacity = capacity; &#125; int get(int key) &#123; if (hash.find(key) != hash.end()) &#123; auto it = hash[key]; auto keyValue = *it; linkList.erase(it); linkList.push_front(keyValue); hash[key] = linkList.begin(); return (*hash[key]).second; &#125; else &#123; return -1; &#125; &#125; void put(int key, int value) &#123; if (linkList.size() &lt; capacity) &#123; if (hash.find(key) != hash.end()) &#123; linkList.erase(hash[key]); &#125; linkList.push_front(std::make_pair(key, value)); hash[key] = linkList.begin(); &#125; else &#123; if (hash.find(key) != hash.end()) &#123; // 如果已经存在, 则将其移动到list最前 linkList.erase(hash[key]); &#125; else &#123; auto keyValue = linkList.back(); hash.erase(keyValue.first); linkList.pop_back(); &#125; linkList.push_front(std::make_pair(key, value)); hash[key] = linkList.begin(); &#125; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache* obj = new LRUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */ Python 实现有两种方法, 一种是使用普通的字典和双端链表实现, 另一种是使用OrderedDict 使用OrderedDict 1234567891011121314151617181920212223class LRUCache: def __init__(self, capacity: int): self.capacity = capacity self.ordered_dict = collections.OrderedDict() def get(self, key: int) -&gt; int: if key in self.ordered_dict: self.ordered_dict.move_to_end(key) return self.ordered_dict[key] else: return -1 def put(self, key: int, value: int) -&gt; None: self.ordered_dict[key] = value self.ordered_dict.move_to_end(key) if len(self.ordered_dict) &gt; self.capacity: self.ordered_dict.popitem(last=False) # False 弹出最不常用的# Your LRUCache object will be instantiated and called as such:# obj = LRUCache(capacity)# param_1 = obj.get(key)# obj.put(key,value) 使用普通字典 + 双端链表 作者：liye-3链接：https://leetcode-cn.com/problems/two-sum/solution/shu-ju-jie-gou-fen-xi-python-ha-xi-shuang-xiang-li/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class ListNode: def __init__(self, key=None, value=None): self.key = key self.value = value self.prev = None self.next = Noneclass LRUCache: def __init__(self, capacity: int): self.capacity = capacity self.hashmap = &#123;&#125; # 新建两个节点 head 和 tail self.head = ListNode() self.tail = ListNode() # 初始化链表为 head &lt;-&gt; tail self.head.next = self.tail self.tail.prev = self.head # 因为get与put操作都可能需要将双向链表中的某个节点移到末尾, 所以定义一个方法 def move_node_to_tail(self, key): # 先将哈希表key指向的节点拎出来, 为了简洁起名node # hashmap[key] hashmap[key] # | | # V --&gt; V # prev &lt;-&gt; node &lt;-&gt; next pre &lt;-&gt; next ... node node = self.hashmap[key] node.prev.next = node.next node.next.prev = node.prev # 之后将node插入到尾节点前 # hashmap[key] hashmap[key] # | | # V --&gt; V # prev &lt;-&gt; tail ... node prev &lt;-&gt; node &lt;-&gt; tail node.prev = self.tail.prev node.next = self.tail self.tail.prev.next = node self.tail.prev = node def get(self, key: int) -&gt; int: if key in self.hashmap: # 如果已经在链表中了久把它移到末尾（变成最新访问的） self.move_node_to_tail(key) res = self.hashmap.get(key, -1) if res == -1: return res else: return res.value def put(self, key: int, value: int) -&gt; None: if key in self.hashmap: # 如果key本身已经在哈希表中了就不需要在链表中加入新的节点 # 但是需要更新字典该值对应节点的value self.hashmap[key].value = value # 之后将该节点移到末尾 self.move_node_to_tail(key) else: if len(self.hashmap) == self.capacity: # 去掉哈希表对应项 self.hashmap.pop(self.head.next.key) # 去掉最久没有被访问过的节点, 即头节点之后的节点 self.head.next = self.head.next.next self.head.next.prev = self.head # 如果不在的话就插入到尾节点前 new = ListNode(key, value) self.hashmap[key] = new new.prev = self.tail.prev new.next = self.tail self.tail.prev.next = new self.tail.prev = new 148. Sort List对链表进行排序, 要求时间复杂度为 $O(nlogn)$, 空间复杂度为常数 DescriptionSort a linked list in O(n log n) time using constant space complexity. Example 1:12Input: 4-&gt;2-&gt;1-&gt;3Output: 1-&gt;2-&gt;3-&gt;4 Example 2:12Input: -1-&gt;5-&gt;3-&gt;4-&gt;0Output: -1-&gt;0-&gt;3-&gt;4-&gt;5 解法一: 递归 自顶向下时间复杂度: $O(nlogn)$空间复杂度: $O(logn)$ 首先对于链表的排序最先想到的就是归并排序, 因为题目的要求是空间复杂度为常数, 因为不能使用递归实现(递归会占用额外空间), 但是, 递归是一种很好理解的排序方法, 因此, 这里我们先给链表归并排序的递归实现. 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* sortList(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return head; //链表中至少应有两个元素, 否则不能进行融合, 会产生运行时错误 ListNode *slow=head, *fast=head, *pre=head; // 两指针, 找到最中间的元素, 用slow指向 while(fast!=nullptr &amp;&amp; fast-&gt;next!=nullptr)&#123; pre = slow; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; pre-&gt;next = nullptr; // 将前后两个链断开 ListNode* sort1 = sortList(head); // 将前一半排序 ListNode* sort2 = sortList(slow); // 将后一半排序 return merge_sort(sort1, sort2); // 融合两个有序链表 &#125; ListNode* merge_sort(ListNode* l1, ListNode* l2)&#123; ListNode* dummy = new ListNode(0); ListNode* cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; l2 = l2-&gt;next; &#125; cur = cur-&gt;next; &#125; if(l1!=nullptr) cur-&gt;next = l1; if(l2!=nullptr) cur-&gt;next = l2; // 将最后的一个非空元素加入排序链表 return dummy-&gt;next; &#125;&#125;; 解法二: 迭代 自底向上时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 先两两合并, 再四四合并, 逐渐向上, 直到完全合并. 注意这里之所以可以在 $O(1)$ 的空间复杂度内进行归并排序, 是因为采用了链表的底层结构, 使得 merge 操作可以在 $O(1)$ 的空间复杂度下进行. 但是对于一般的归并排序, 采用的是数组结构, 数组结构在进行 merge 时, 要么在 $O(n)$ 的空间复杂度下执行, 要么每次插入都需要移动其他元素, 增加时间复杂度. 接下来, 我们考虑如何实现归并排序的迭代算法, 代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123;private: ListNode* splitList(ListNode* l1, int blockSize) &#123; while (blockSize &gt; 1 and l1 != nullptr) &#123; l1 = l1-&gt;next; blockSize--; &#125; // 找到 l1 的尾部 if (l1 == nullptr) return l1; ListNode* l2 = l1-&gt;next; // l1 尾部的下一个就是 l2 的头部 l1-&gt;next = nullptr; // split l1 and l2 return l2; &#125; ListNode* mergeList(ListNode* l1, ListNode* l2, ListNode* dummy) &#123; ListNode* cur = dummy; while (l1 != nullptr and l2 != nullptr) &#123; if (l1-&gt;val &lt;= l2-&gt;val) &#123; cur-&gt;next = l1; l1 = l1-&gt;next; &#125; else &#123; cur-&gt;next = l2; l2 = l2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = (l1 != nullptr) ? l1 : l2; while (cur-&gt;next != nullptr) cur = cur-&gt;next; return cur; // 该节点是下一段链表的 dummy 节点 &#125;public: ListNode* sortList(ListNode* head) &#123; ListNode* node = head; int length = 0; while (node != nullptr) &#123; length++; node = node-&gt;next; &#125; ListNode* dummy = new ListNode(0); dummy-&gt;next = head; for (int blockSize = 1; blockSize &lt; length ; blockSize &lt;&lt;= 1) &#123; ListNode* curDummy = dummy; ListNode* curHead = dummy-&gt;next; while (curHead != nullptr) &#123; ListNode* l1 = curHead; ListNode* l2 = splitList(l1, blockSize); curHead = splitList(l2, blockSize); // 获取下一段链表的头节点, 并将l2的尾部置为nullptr curDummy = mergeList(l1, l2, curDummy); // 合并, 并获取当前段的最后一个非空节点 &#125; &#125; return dummy-&gt;next; &#125;&#125;; 149. Max Points on a LineDescription 最大的共线点个数Given n points on a 2D plane, find the maximum number of points that lie on the same straight line. Example 1: Input: [[1,1],[2,2],[3,3]]Output: 3Explanation:^|| o| o| o+——————-&gt;0 1 2 3 4Example 2: Input: [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]Output: 4Explanation:^|| o| o o| o| o o+—————————-&gt;0 1 2 3 4 5 6 解法一: 哈希表时间复杂度: $O(n^2)$, 求取任意两点间的斜率空间复杂度: $O(n)$, 哈希表, 存储斜率 由于要求共线点个数, 就必须获取任意两点间的斜率, 因此, 时间复杂度最少为 $O(n^2)$. 算法流程如下: 对于每一个点来说, 构造一个哈希表, 表中的键为斜率, 表中的值为对应斜率的点的个数, 这里注意, 当我们求完第i个点与第j个点之间的斜率之后, 就不用再求第j个点与第i个点之间的斜率情况了(即令int j = i+1, 而不是int j = 0) 对于重点的情况, 需要单独设置一个变量来记录, 之后将该重复次数加入到该点所在的每条直线上(因为重点也算是共线) 对于斜率不存在的情况, 可以考虑利用INT_MAX来作为键值 精度: 在求取斜率时, 会进行除法, 而在计算机内部, 除法在精度上始终会有一定误差, 会造成斜率相同的两对点在计算成浮点数以后斜率不同, 因此, 要 避免使用除法, 解决办法是利用 最大公约数, 求取y2-y1与x2-x1之间的最大公约数, 然后对进行约分, 用约分后的值作为键来存储, 就不会造成精度上的损失, 但是, 此时需要用pair作为键, 故不能用unordered_map(C++没有为pair类型提供对应的哈希函数), 而只能用map(键只有重载了&lt;和&gt;就可以使用map, 搜索的时间复杂度为 $O(logn)$), 另一种可选做法是利用string类型, 将两个int数值转换成string后再拼接, 此时就可以使用unordered_map了(搜索的时间复杂度为 $O(1)$, 但是int和string的类型转换也需要消耗时间). 当采用公约数以后, 因为没有了除法, 因此可以不用特殊处理斜率不存在的情况, 代码更加简洁. 12345678910111213141516171819202122232425262728293031323334353637383940C/** * Definition for a point. * struct Point &#123; * int x; * int y; * Point() : x(0), y(0) &#123;&#125; * Point(int a, int b) : x(a), y(b) &#123;&#125; * &#125;; */class Solution &#123;public: int maxPoints(vector&lt;Point&gt;&amp; points) &#123; int res=0; for(int i=0; i&lt;points.size(); i++)&#123; int duplicate = 1; map&lt;pair&lt;int,int&gt;, int&gt; lines_hash; //这里用map的原因是因为unordered_map的键的类型只能是基本类型, 不能是pair for(int j=i+1; j&lt;points.size(); j++)&#123; if(points[i].x==points[j].x &amp;&amp; points[i].y==points[j].y)&#123; duplicate++; &#125;else&#123; int a = points[j].y-points[i].y; int b = points[j].x-points[i].x; int d = gcd(a, b); lines_hash[&#123;a/d, b/d&#125;]++; &#125; &#125; res = max(res, duplicate); // 如果points里面只有一个点, 则哈希表中不会有键值, 因此需要先处理只有一个点的情况 for(auto line : lines_hash)&#123; res = max(res, duplicate+line.second); &#125; &#125; return res; &#125; int gcd(int a, int b)&#123; // 求a与b的最大公约数 return (b==0) ? a : gcd(b, a%b); &#125;&#125;; 用 string 做键, 使用哈希表而不是map: 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int gcd(int a, int b) &#123; return b == 0 ? a : gcd(b, a%b); &#125; int maxPoints(vector&lt;Point&gt;&amp; points) &#123; int n = points.size(); int res = 0; for (int i = 0; i &lt; n; i++) &#123; std::unordered_map&lt;std::string, int&gt; line_hash; int duplicate = 1; for (int j = i + 1; j &lt; n; j++) &#123; if (points[i].x == points[j].x and points[i].y == points[j].y) &#123; duplicate++; continue; &#125; int a = points[j].y - points[i].y; int b = points[j].x - points[i].x; int d = gcd(a, b); std::string slope = std::to_string(a/d) + std::to_string(b/d); line_hash[slope]++; &#125; res = std::max(res, duplicate); for (auto it : line_hash) &#123; res = std::max(res, duplicate + it.second); &#125; &#125; return res; &#125;&#125;; 150. Evaluate Reverse Polish Notation计算逆波兰表达式 DescriptionEvaluate the value of an arithmetic expression in Reverse Polish Notation. Valid operators are +, -, *, /. Each operand may be an integer or another expression. Note: Division between two integers should truncate toward zero.The given RPN expression is always valid. That means the expression would always evaluate to a result and there won’t be any divide by zero operation.Example 1: Input: [“2”, “1”, “+”, “3”, ““]Output: 9Explanation: ((2 + 1) 3) = 9Example 2: Input: [“4”, “13”, “5”, “/“, “+”]Output: 6Explanation: (4 + (13 / 5)) = 6Example 3: Input: [“10”, “6”, “9”, “3”, “+”, “-11”, ““, “/“, ““, “17”, “+”, “5”, “+”]Output: 22Explanation: ((10 (6 / ((9 + 3) -11))) + 17) + 5= ((10 (6 / (12 -11))) + 17) + 5= ((10 (6 / -132)) + 17) + 5= ((10 0) + 17) + 5= (0 + 17) + 5= 17 + 5= 22 解法一: 栈时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 需要一个额外的栈来存储中间结果 用栈来实现, 从到开始扫描字符串vector, 如果当前字符串不为运算符, 则直接入栈, 如果为运算符 , 则取栈顶两个元素进行运算然后将计算结果入栈. 最终, 栈中只剩一个结果值 需要注意的是: 首先要确保输入的逆波兰表达式是没有问题的, 其次还有要进行零除判断, 这几点本题没有考查, 但仍需注意 1234567891011121314151617181920212223class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; stack&lt;int&gt; polish; for(auto token : tokens)&#123; int a,b,c; if(token.back()=='+' || token.back()=='-' || token.back()=='*' || token.back()=='/')&#123; // 用back的原因是数字有可能是 -13 这种形式 b = polish.top(); polish.pop(); a = polish.top(); polish.pop(); &#125; switch(token.back())&#123; case '+': c=a+b; break; case '-': c=a-b; break; case '*': c=a*b; break; case '/': c= (b==0) ? 0 : a/b; break; default: c = c=std::stoi(token); &#125; polish.push(c); &#125; return polish.top(); &#125;&#125;; 解法二: 栈+异常解法与上面相同, 不同借助了异常, 显得更加简洁 12345678910111213141516171819202122232425262728class Solution &#123;public: int evalRPN(vector&lt;string&gt; &amp;tokens) &#123; stack&lt;int&gt; rpn; for(int i =0; i&lt;tokens.size(); i++)&#123; try&#123; rpn.push(stoi(tokens[i])); &#125; catch (exception e)&#123; int num1 = rpn.top(); rpn.pop(); int num2 = rpn.top(); rpn.pop(); switch(tokens[i][0])&#123; case '+': rpn.push(num2+num1);break; case '-': rpn.push(num2-num1);break; case '*': rpn.push(num2*num1);break; case '/': rpn.push(num2/num1);break; &#125; &#125; &#125; if(rpn.size()==1) return rpn.top(); else return 0; &#125;&#125;; 解法三: 栈+lambda思路与解法一一直, 另一种写法: 借助哈希表和lambda表达式, 使程序更加整洁 12345678910111213141516171819202122class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; unordered_map&lt;string, function&lt;int(int, int)&gt;&gt; op_map=&#123; &#123;"+", [](int a, int b)&#123;return a+b;&#125;&#125;, //注意要用双引号, 因为token是stirng类型, 而不是char类型 &#123;"-", [](int a, int b)&#123;return a-b;&#125;&#125;, &#123;"*", [](int a, int b)&#123;return a*b;&#125;&#125;, &#123;"/", [](int a, int b)&#123;return (b==0) ? 0 : a/b;&#125;&#125; &#125;; stack&lt;int&gt; polish; for(auto token : tokens)&#123; if(!op_map.count(token)) polish.push(std::stoi(token)); else&#123; int b = polish.top(); polish.pop(); int a = polish.top(); polish.pop(); polish.push(op_map[token](a, b)); &#125; &#125; return polish.top(); &#125;&#125;; 解法四: 栈+lambda+异常123456789101112131415161718192021222324class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; std::unordered_map &lt;std::string, std::function&lt;int(int, int)&gt;&gt; op = &#123; &#123;"+", [](int a, int b)&#123;return a+b;&#125;&#125;, &#123;"-", [](int a, int b)&#123;return a-b;&#125;&#125;, &#123;"*", [](int a, int b)&#123;return a*b;&#125;&#125;, &#123;"/", [](int a, int b)&#123;return b == 0 ? 0 : a/b;&#125;&#125; &#125;; std::stack&lt;int&gt; polish; for (auto const&amp; token : tokens) &#123; try &#123; polish.push(std::stoi(token)); &#125; catch (exception e) &#123; int b = polish.top(); polish.pop(); int a = polish.top(); polish.pop(); polish.push(op[token](a, b)); &#125; &#125; return polish.top(); &#125;&#125;; 152. Maximum Product Subarray求连续子序列的最大乘积 DescriptionGiven an integer array nums, find the contiguous subarray within an array (containing at least one number) which has the largest product. Example 1: Input: [2,3,-2,4]Output: 6Explanation: [2,3] has the largest product 6.Example 2: Input: [-2,0,-1]Output: 0Explanation: The result cannot be 2, because [-2,-1] is not a subarray. 解法一: 递归时间复杂度: $O(n)$, 遍历一次空间复杂度: $O(n)$, 递归 $n$ 次 这道题和连续子序列的最大和比较相似, 但是更难一些, 我们需要考虑负负得正这种情况, 因此, 我们不仅仅要维护最大值, 还要维护最小值. 考虑利用递归的方法来实现, 假设我们现在已经知道了以第 i-1 个数为结尾的连续子序列的最大乘积值max和最小乘积值min, 那么如果数组中新来一个数 nums[i], 则以第 i 个数为结尾的连续子序列的最大乘积就一定是max * nums[i], min*nums[i], nums[i]之中的最大者, 最小值为这三者的最小者. 由于我们还不知道最终的连续子序列是以第几个字符为结尾的, 因此我们利用一个变量res来维护当前找到的最大的子序列乘积, 并且随着循环的进行不断更新这个值, 最终, res的值就是我们要求的解, 代码如下: 123456789101112131415161718192021class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0 ) return 0; int res=nums[0]; helper(nums, nums.size()-1, res); return res; &#125; pair&lt;int, int&gt; helper(vector&lt;int&gt; &amp;nums, int index, int &amp;res)&#123; //注意这里要设置一个引用res来不断更新最大值 if(index == 0) return make_pair(nums[0], nums[0]); pair&lt;int, int&gt; max_min = helper(nums, index-1, res); int a = max_min.first * nums[index]; int b = max_min.second * nums[index]; int c = nums[index]; max_min.first = max(a, max(b,c)); max_min.second = min(a, min(b,c)); res = max(res, max_min.first); return max_min; &#125;&#125;; 解法二 迭代实现时间复杂度: $O(n)$空间复杂度: $O(1)$ 思路和解法一相同, 只不过换成了迭代实现123456789101112131415161718class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) return 0; int max_neg = nums[0]; int max_pos = nums[0]; int res = nums[0]; for (int i = 1; i &lt; nums.size(); i++) &#123; int num = nums[i]; int a = num * max_neg; int b = num * max_pos; max_neg = std::min(num, std::min(a, b)); max_pos = std::max(num, std::max(a, b)); if (max_pos &gt; res) res = max_pos; &#125; return res; &#125;&#125;; 解法三: DP 迭代时间复杂度: $O(n)$空间复杂度: $O(n)$, 该解法需要额外数组, 实际上这是不必要的, 详细可看解法二 上面的递归写法, 可以转换成DP迭代, 为此需要两个dp数组, 一个用来保存以第i个元素为结尾的连续子序列的最大值, 另一个保存最小值. 代码如下: 写法一: new数组12345678910111213141516171819202122class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0 ) return 0; int res=nums[0]; int *dp_max = new int[nums.size()](); int *dp_min = new int[nums.size()](); dp_max[0] = nums[0]; dp_min[0] = nums[0]; for(int i = 1; i&lt;nums.size(); i++)&#123; int a = dp_max[i-1]*nums[i]; int b = dp_min[i-1]*nums[i]; int c = nums[i]; dp_max[i] = max(a, max(b,c)); dp_min[i] = min(a, min(b,c)); res = max(res, dp_max[i]); &#125; delete[] dp_max; delete[] dp_min; return res; &#125;&#125;; 写法二: vector数组:1234567891011121314151617181920CCclass Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0 ) return 0; int res=nums[0]; vector&lt;int&gt; dp_max(nums.size(), 0); vector&lt;int&gt; dp_min(nums.size(), 0); dp_max[0] = nums[0]; dp_min[0] = nums[0]; for(int i = 1; i&lt;nums.size(); i++)&#123; int a = dp_max[i-1]*nums[i]; int b = dp_min[i-1]*nums[i]; int c = nums[i]; dp_max[i] = max(a, max(b,c)); dp_min[i] = min(a, min(b,c)); res = max(res, dp_max[i]); &#125; return res; &#125;&#125;; 155. Min Stack获取栈中最小的元素 DescriptionDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) — Push element x onto stack.pop() — Removes the element on top of the stack.top() — Get the top element.getMin() — Retrieve the minimum element in the stack.Example:MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); —&gt; Returns -3.minStack.pop();minStack.top(); —&gt; Returns 0.minStack.getMin(); —&gt; Returns -2. 解法一: 两个栈时间复杂度: $O(1)$空间复杂度: $O(n)$, 两个栈 申请两个栈, 一个栈正常操作, 另一个栈只有当当前元素小于或等于栈顶元素时才入栈 1234567891011121314151617181920212223242526272829303132333435363738class MinStack &#123;private: stack&lt;int&gt; s1; stack&lt;int&gt; s2;public: /** initialize your data structure here. */ MinStack()&#123; &#125; void push(int x) &#123; s1.push(x); if(s2.empty() || x &lt;= s2.top()) s2.push(x); &#125; void pop() &#123; if(s1.top() == s2.top()) s2.pop(); s1.pop(); &#125; int top() &#123; return s1.top(); &#125; int getMin() &#123; return s2.top(); &#125;&#125;;/** * Your MinStack object will be instantiated and called as such: * MinStack obj = new MinStack(); * obj.push(x); * obj.pop(); * int param_3 = obj.top(); * int param_4 = obj.getMin(); */ 160. Intersection of Two Linked Lists两个链表的第一个公共节点 DescriptionWrite a program to find the node at which the intersection of two singly linked lists begins. For example, the following two linked lists:12345A: a1 → a2 ↘ c1 → c2 → c3 ↗ B: b1 → b2 → b3 begin to intersect at node c1. Notes: If the two linked lists have no intersection at all, return null.The linked lists must retain their original structure after the function returns.You may assume there are no cycles anywhere in the entire linked structure.Your code should preferably run in O(n) time and use only O(1) memory. 解法一：栈时间复杂度: $O(m+n)$, 遍历两个链表空间复杂度: $O(m+n)$, 两个栈 分析公共子节点的特点, 首先, 是单向链表, 因此, 从第一个公共子节点开始, 后面的都是一样的, 所以最好是能从链表的最后一项还是比较. 但由于是单向链表, 因此只能从头访问, 从能访问最后的节点. 就像是先进先出一样 因此, 考虑用两个辅助栈来帮助实现～ 1234567891011121314151617181920212223242526272829303132/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) &#123; stack&lt;ListNode*&gt; s1; stack&lt;ListNode*&gt; s2; for(ListNode* cur = pHead1; cur!=nullptr; cur = cur-&gt;next)&#123; s1.push(cur); &#125; for(ListNode* cur = pHead2; cur!=nullptr; cur = cur-&gt;next)&#123; s2.push(cur); &#125; ListNode* firstCN = nullptr; while(!s1.empty() &amp;&amp; !s2.empty())&#123; if(s1.top() == s2.top())&#123; firstCN = s1.top(); s1.pop(); s2.pop(); &#125;else break; &#125; return firstCN; &#125;&#125;; 解法二: 常数空间复杂度时间复杂度: $O(m+n)$, 遍历两次空间复杂度: $O(1)$, 不使用额外空间 首先遍历得到两个链表的长度, 然后先让长链表前进长度差个节点, 接着两个链表共同向前遍历, 当相遇时即为第一个公共节点. 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) &#123; int lengthA = 0; ListNode* nodeA = headA; while (nodeA != nullptr) &#123; nodeA = nodeA-&gt;next; lengthA++; &#125; int lengthB = 0; ListNode* nodeB = headB; while (nodeB != nullptr) &#123; nodeB = nodeB-&gt;next; lengthB++; &#125; ListNode* longNode = lengthA &gt; lengthB ? headA : headB; ListNode* shortNode = lengthA &gt; lengthB ? headB : headA; int l = std::abs(lengthA - lengthB); while (l--) &#123; longNode = longNode-&gt;next; &#125; while (shortNode != longNode) &#123; shortNode = shortNode-&gt;next; longNode = longNode-&gt;next; &#125; return shortNode; &#125;&#125;; 162. Find Peak ElementDescription: 局部最大值A peak element is an element that is greater than its neighbors. Given an input array nums, where nums[i] ≠ nums[i+1], find a peak element and return its index. The array may contain multiple peaks, in that case return the index to any one of the peaks is fine. You may imagine that nums[-1] = nums[n] = -∞. Example 1: Input: nums = [1,2,3,1]Output: 2Explanation: 3 is a peak element and your function should return the index number 2.Example 2: Input: nums = [1,2,1,3,5,6,4]Output: 1 or 5Explanation: Your function can return either index number 1 where the peak element is 2, or index number 5 where the peak element is 6. 解法一: $O(n)$ 复杂度$O(n)$ 的时间复杂度, 不合符题目要求, 仅仅记录一下. 12345678910111213class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() ==0) return -1; if(nums.size() ==1 || nums[0] &gt; nums[1]) return 0; for(int i=1; i&lt;nums.size()-1; i++)&#123; if(nums[i] &gt; nums[i-1] &amp;&amp; nums[i] &gt; nums[i+1]) return i; &#125; if(nums[nums.size()-2] &lt; nums[nums.size()-1]) return nums.size()-1; &#125;&#125;; 解法二: $O(logn)$ 复杂度二分查找, 分为以下几种情况: If num[i-1] &lt; num[i] &gt; num[i+1], then num[i] is peak If num[i-1] &lt; num[i] &lt; num[i+1], then num[i+1…n-1] must contains a peak If num[i-1] &gt; num[i] &gt; num[i+1], then num[0…i-1] must contains a peak If num[i-1] &gt; num[i] &lt; num[i+1], then both sides have peak 12345678910111213141516class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() ==0) return -1; int low = 0; int high = nums.size()-1; int mid; while(low &lt; high-1)&#123; //避免low和high相邻, 使得mid-1或mid+1可能非法 mid = (low+high)/2; if(nums[mid-1] &lt; nums[mid] &amp;&amp; nums[mid] &gt; nums[mid+1]) return mid; else if(nums[mid] &lt; nums[mid+1]) low = mid+1; else high = mid-1; &#125; return nums[low]&gt;nums[high] ? low : high; // 当low或high相邻时, 即为两端时的情况 &#125;&#125;; 1234567891011121314class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) return -1; int low = 0; int high = nums.size()-1; while (low &lt; high) &#123; int mid = (low + high) / 2; // 向下取整 if (nums[mid] &gt; nums[mid+1]) high = mid; else low = mid + 1; &#125; return low; &#125;&#125;; 递归实现:1234567891011121314151617class Solution &#123;public: int helper(vector&lt;int&gt;&amp; nums, int low, int high) &#123; if (low == high) &#123; return low; &#125; int mid = (low + high) / 2; if (nums[mid] &gt; nums[mid+1])&#123; return helper(nums, low, mid); &#125; else &#123; return helper(nums, mid+1, high); &#125; &#125; int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; return helper(nums, 0, nums.size()-1); &#125;&#125;; 166. Fraction to Recurring DecimalDescription: 无限循环小数Given two integers representing the numerator and denominator of a fraction, return the fraction in string format. If the fractional part is repeating, enclose the repeating part in parentheses. Example 1: Input: numerator = 1, denominator = 2Output: “0.5”Example 2: Input: numerator = 2, denominator = 1Output: “2”Example 3: Input: numerator = 2, denominator = 3Output: “0.(6)” 解法一: 用余数作为哈希表的key时间复杂度: $O(logn)$, 每次都会乘以10再取余数空间复杂度: $O(logn)$, 余数的哈希表 首先, 获取最终浮点数的符号和整数部分, 此处由于可能出现分子为-2147483648, 而分母为-1的情况, 为此, 建议使用long长整型来避免溢出.在计算小数部分时, 将余数作为key, 小数当前位置作为value存入哈希表中, 然后将余数乘以10, 再计算当前小数位的值, 并将取余得到新的余数.题目指明浮点数是无限循环小数, 则如果小数部分没有循环, 那么一定会出现余数为0的情况, 此时, 返回当前的res即可. 如果小数存在循环, 那么循环一定出现在余数相同的时刻, 此时, 将添加后扩号, 并根据哈希表中的value添加前括号. 123456789101112131415161718192021222324252627282930class Solution &#123;public: string fractionToDecimal(int numerator, int denominator) &#123; if(numerator == 0 || denominator == 0) return "0"; string res; if(numerator&lt;0 ^ denominator&lt;0) res+="-"; long numer = (numerator &lt; 0) ? (long)(numerator)*-1 : (long)numerator; // 注意, 不能写成 (long)(numerator*-1) long denom = (denominator &lt; 0) ? (long)(denominator)*-1 : (long)denominator; long integral = numer/denom; res += std::to_string(integral); // 添加整数部分 long rmd = numer % denom; if(rmd!=0) res += "."; // 存在小数 unordered_map &lt;long, long&gt; hash; while(rmd!=0)&#123; if(hash.find(rmd) != hash.end())&#123; // 判断余数 res.insert(hash[rmd], "("); res += ")"; break; &#125; hash[rmd] = res.size(); rmd = rmd*10; long quotient = rmd/denom; res += std::to_string(quotient); rmd = rmd%denom; &#125; return res; &#125;&#125;; 169 Majority ElementDescription: 找出数组中超过一半的数字Given an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times. You may assume that the array is non-empty and the majority element always exist in the array. Example 1: Input: [3,2,3]Output: 3Example 2: Input: [2,2,1,1,1,2,2]Output: 2 题目中指明了该数字一定存在, 所以无需进行count检查, 如果该数字有可能不存在, 则根据情况需要进行 $O(n)$ 复杂度的count检查(即检查当前的数字是否出现了大于 n/2 次). 解法一: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 先排序, 然后取中间元素, 即为 majority element.(如有需要可进行count检查, $O(n)$) 解法二: 哈希时间复杂度: $O(n)$空间复杂度: $O(n)$ 每个元素的值为哈希的 key, 每个元素出现的次数为哈希的 value, 如果某个 key 的 value 大于 n/2, 则该元素即为 majority element.哈希法记录的元素的出现次数, 所以无需进行 count 检查. 12345678910class Solution &#123;public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; unordered_map&lt; int, int&gt; hash; for(auto num: nums)&#123; hash[num]++; if(hash[num] &gt; nums.size()/2) return num; &#125; &#125;&#125;; 解法三: 同增异减如果数组中存在这样一个数, 那么这个数的出现次数一定大于其他所有数的出现次数总和, 因此, 设置两个变量, 一个 cur_num 用来存储当前数组中的可能解, 另一个 count 为统计差值. 即每遇到一个和可能解相同的元素, 就 count++, 否则, count—. 如果 count=0, 则说明当前的可能解已经注定不是最终的解, 则令新的元素为可能解.最终, 对可能解进行 $O(n)$ 的 count 检查, 判断是否存在 majority element (题目假设一定存在, 所以可以不做此检查). 12345678910111213141516171819class Solution &#123;public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; int major = 0; int count = 0; for (auto const num : nums) &#123; if (num == major) &#123; count++; &#125; else &#123; count--; if (count &lt; 0) &#123; major = num; count = 1; &#125; &#125; &#125; return major; // 因为题目保证major一定存在, 所以可以直接返回, 否则的话还需要再判断major的个数是否大于 n/2 &#125;&#125;; 解法四: 随机如果确定数组中存在 majority element 的话, 则我们可以从数组中随机选取一个元素, 并判断这个元素是否为 majority element. 这种解法依赖于统计学的概率知识, 实际的时间复杂度与数组的组成规律有关. 171. Excel Sheet Column NumberDescription: Excel列表数字Given a column title as appear in an Excel sheet, return its corresponding column number. For example: A -&gt; 1 B -&gt; 2 C -&gt; 3 ... Z -&gt; 26 AA -&gt; 27 AB -&gt; 28 ... Example 1: Input: “A”Output: 1Example 2: Input: “AB”Output: 28Example 3: Input: “ZY”Output: 701 解法一: 遍历字符串时间复杂度: $O(n)$空间复杂度: $O(1)$ 12345678910class Solution &#123;public: int titleToNumber(string s) &#123; int res=0; for(auto c : s)&#123; res += res*25 + int(c-'A') + 1; &#125; return res; &#125;&#125;; 172. Factorial Trailing ZeroesDescription: 阶乘的尾部含有0的个数解法一: 统计5的个数首先, 求出阶乘值在取余求0个数的方法肯定不可以, 阶乘会轻松溢出(n=13时就已经 int 溢出了) 时间复杂度: $O(logn)$, 以5位基数空间复杂度: $O(1)$ 因为尾部的0只可能来自于 $2\times 5$ 这样的数, 对于 $n$ 的阶乘 $1\times 2\times 3\times, …, n$ 来说, $2$ 一定是充足的, 所以我们只需要统计 $5$ 的个数就可以.统计时, 每个5个数字会出现一次5, 每隔25个数字会额外出现一次5, 每个125个数字又会额外出现一次5…, 如此循环下去, 最终5的个数就是尾部0的个数. 1234567891011class Solution &#123;public: int trailingZeroes(int n) &#123; int res = 0; for(long i =5; n/i &gt;0; i*=5)&#123; //注意这里的i的字节数一定要大于n, 因为n有可能为INT_MAX, 而 n/i &gt;0 时, i必须&gt;n res += n/i; &#125; return res; &#125;&#125;; 解法二: 另一个角度时间复杂度: $O(logn)$, 以5位基数空间复杂度: $O(1)$ (迭代), $O(logn)$ (递归需额外空间) 核心思想是相同的, 同样是统计5的出现个数, 只不过这里我们是先求出 n 中 5 的倍数, 然后再求 n/5 中 5 的倍数, 实际上这里就是相当于求 n 中 25 的倍数. 因此, 和解法一是相同的, 只不过解法二因为是通过减小 n, 而不是增大 i (5,25,125,..)的方式来统计 5 个数, 因此解法二有个好处就是可以不使用 long 类型的变量, 下面分别是该方法的递归实现和迭代实现. 递归:123456class Solution &#123;public: int trailingZeroes(int n) &#123; return n &lt; 5 ? 0 : n / 5 + trailingZeroes(n / 5); &#125;&#125;; 迭代:1234567891011class Solution &#123;public: int trailingZeroes(int n) &#123; int res=0; while(n&gt;=5)&#123; res += n/5; n /= 5; &#125; return res; &#125;&#125;; 179. Largest NumberDescription: 排列数字使其字符串形式的数字为最大Given a list of non negative integers, arrange them such that they form the largest number. Example 1: Input: [10,2]Output: “210”Example 2: Input: [3,30,34,5,9]Output: “9534330” 解法一: 构造比较函数, 快排排序时间复杂度: $O(nlogn)$, 快排时间复杂度空间复杂度: $O(logn)$, 快排空间复杂度, 如果使用其他排序算法, 可将空间复杂度降为 $O(1)$ 我们可以构造一个新的比较函数来决定两个元素的先后关系, 对于任意两个元素 a 和 b, 首先将其转换成字符串形式 s_a 和 s_b, 我们知道, 若整形 a&gt;b, 则一定有 s_a &gt; s_b, 因此我们可以比较 s_a+s_b 和 s_b+s_a 的大小关系, 根据题目要求, 我们要进行递减排序. 得到比较函数以后, 利用快排排序即可. 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public: string largestNumber(vector&lt;int&gt;&amp; nums) &#123; q_sort(nums, 0, nums.size()-1); if(nums.size()!=0 &amp;&amp; nums[0] == 0) return "0"; // 对于输入[0, 0, 0] 应该返回 "0", 而不是"000", 必须要放在排序后, nums[0] == 0 说明所有元素均为0 string res; for(auto num: nums)&#123; res += std::to_string(num); &#125; return res; &#125; bool str_geq(int a, int b)&#123; string s_a = std::to_string(a); string s_b = std::to_string(b); if(s_a+s_b &gt;= s_b+s_a) return true; //注意是递减排序, 所以为 &gt;= else return false; &#125; int partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low &lt; high)&#123; while(low&lt;high &amp;&amp; str_geq(P, nums[high])) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; str_geq(nums[low], P)) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125; void q_sort(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int mid = partition(nums, low, high); if(mid&gt;low) q_sort(nums, low, mid-1); if(mid&lt;high) q_sort(nums, mid+1, high); &#125;&#125;; 解法二: 利用 STL sort() 函数时间复杂度: $O(nlogn)$, 快排时间复杂度空间复杂度: $O(logn)$, 快排空间复杂度, 如果使用其他排序算法, 可将空间复杂度降为 $O(1)$ 思路与解法一一致, 只不过省略了排序算法的实现, 使用了 STL 的 sort 函数. 需要注意, 在 C++ STL 的 sort 函数中, bool 返回真的时候, 必须是绝对大于或者绝对小于, 对于等于的情况, 只能返回 false(因为当返回 true 时, 元素会继续下一个, 这样对于极端情况, 如所有元素都一样时, 会出现越界, 从而导致段错误) 123456789101112131415161718bool str_geq(int a, int b)&#123; string s_a = std::to_string(a); string s_b = std::to_string(b); if(s_a+s_b &gt; s_b+s_a) return true; // 这里用 &gt;= 会产生运行时错误, 用 &gt; 则可以通过, 为什么? else return false;&#125;class Solution &#123;public: string largestNumber(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end(), str_geq); if(nums.size()!=0 &amp;&amp; nums[0] == 0) return "0"; // 对于输入[0, 0, 0] 应该返回 "0", 而不是"000", 必须要放在排序后, nums[0] == 0 说明所有元素均为0 string res; for(auto num: nums)&#123; res += std::to_string(num); &#125; return res; &#125; &#125;; 188. 买卖股票的最佳时机 IV题目链接: https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iv/ 解法: 通用 DP 解法注意, 本题由于 k 的大小可以非常大, 所以在声明 dp 数组前, 一定要先判断 k 的大小, 如果超过范围, 则要转换为无限次的股票买卖, 否则会导致爆栈. C++ 实现:123456789101112131415161718192021222324252627282930class Solution &#123;public: int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; if (prices.size() &lt;= 1) return 0; //std::vector&lt;std::pair&lt;int, int&gt;&gt; dp(k+1, &#123;-prices[0], 0&#125;); // 这里有一个隐藏很深的 bug, 就如果 k 的值很大, 就会直接把栈爆掉!! // 所以应该按照 k 值做优化, 将 vector 声明在 if 语句内部 if (k &lt; prices.size() / 2) &#123; std::vector&lt;std::pair&lt;int, int&gt;&gt; dp(k+1, &#123;-prices[0], 0&#125;); for(int i=1;i&lt;prices.size();i++) &#123; for(int j=1; j &lt; k+1; j++) &#123; int hold = std::max(dp[j].first, dp[j-1].second-prices[i]); int not_hold = std::max(dp[j].second, dp[j].first+prices[i]); dp[j].first = hold; dp[j].second = not_hold; &#125; &#125; return dp[k].second; //max(dp[k].first, dp[k].second); &#125; else &#123; std::pair&lt;int, int&gt; dp = &#123;-prices[0], 0&#125;; for (int i=1; i&lt;prices.size(); i++) &#123; int hold = std::max(dp.first, dp.second-prices[i]); int not_hold = std::max(dp.second, dp.first+prices[i]); dp.first = hold; dp.second = not_hold; &#125; return dp.second; &#125; &#125;&#125;; Python 实现:1234567891011121314class Solution: def maxProfit(self, k: int, prices: List[int]) -&gt; int: if len(prices) &lt;= 1: return 0 if (k &lt; len(prices) // 2) : dp = [[-prices[0], 0] for i in range(k+1)] for price in prices[1:]: for i in range(1, k+1): dp[i] = [max(dp[i][0], dp[i-1][1]-price), max(dp[i][1], dp[i][0]+price)] return dp[k][1] else: dp = [-prices[0], 0] for price in prices[1:]: dp = [max(dp[0], dp[1]-price), max(dp[1], dp[0]+price)] return dp[1] 189. 旋转数组Description: 循环右移数组Given an array, rotate the array to the right by k steps, where k is non-negative. Example 1: Input: [1,2,3,4,5,6,7] and k = 3Output: [5,6,7,1,2,3,4]Explanation:rotate 1 steps to the right: [7,1,2,3,4,5,6]rotate 2 steps to the right: [6,7,1,2,3,4,5]rotate 3 steps to the right: [5,6,7,1,2,3,4] Example 2: Input: [-1,-100,3,99] and k = 2Output: [3,99,-1,-100]Explanation:rotate 1 steps to the right: [99,-1,-100,3]rotate 2 steps to the right: [3,99,-1,-100] Note:Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.Could you do it in-place with O(1) extra space? 解法一: 暴力时间复杂度: $O(nk)$空间复杂度: $O(1)$ 所有的数字每次移动一步, 攻移动 k 次. 超时 解法二: 使用额外数组时间复杂度: $O(n)$空间复杂度: $O(n)$ 申请一个长度相等的数组, 复制原数组中的 $i$ 号元素到新数组中的 $i+k$ 号位置. 解法三: 循环置换时间复杂度: $O(n)$, 遍历一次空间复杂度: $O(1)$ 每次直接将元素放置在正确的位置, 放置前, 需要用一个临时变量将被放置的元素保存起来以防止覆盖, 然后将临时变量的元素再直接放到正确的位置, 循环进行, 知道临时变量指向了最开始的变量, 然后再继续从下一个元素开始这个过程. 在代码中设置一个 count 变量, 用来统计放置的次数, 当次数等于数组长度时, 说明已经完成移动. 123456789101112131415161718class Solution &#123;public: void rotate(vector&lt;int&gt;&amp; nums, int k) &#123; int count=0; for(int start=0; count&lt;nums.size(); start++)&#123; int cur_pos = start; int cur_val = nums[start]; do&#123; int next_pos = (cur_pos + k) % nums.size(); int temp = nums[next_pos]; nums[next_pos] = cur_val; cur_pos = next_pos; cur_val = temp; count++; &#125;while(start!=cur_pos); &#125; &#125;&#125;; 解法四: reverse时间复杂度: $O(n)$, 调用三次 reverse 函数空间复杂度: $O(1)$ 12345678class Solution &#123;public: void rotate(vector&lt;int&gt;&amp; nums, int k) &#123; std::reverse(nums.begin(), nums.end()-k); std::reverse(nums.end()-k, nums.end()); std::reverse(nums.begin(), nums.end()); &#125;&#125;; 190. Reverse BitsDescription: 按位逆置Reverse bits of a given 32 bits unsigned integer. Example: Input: 43261596Output: 964176192Explanation: 43261596 represented in binary as 00000010100101000001111010011100, return 964176192 represented in binary as 00111001011110000010100101000000.Follow up:If this function is called many times, how would you optimize it? 解法一: 按位进行32次操作每次取 n 的最后一位, 如果为 1, 则令res左移一位并加一, 如果为0, 则只左移一位. 进行32次(n的32位). 12345678910class Solution &#123;public: uint32_t reverseBits(uint32_t n) &#123; uint32_t res= 0; for(int i=0; i&lt;32; i++)&#123; res = (res&lt;&lt;1) | ((n&gt;&gt;i)&amp;1); //res = (res&lt;&lt;1) | (n&amp;1); n = (n&gt;&gt;1); &#125; return res; &#125;&#125;; 解法二: 按位二分进行5次操作先将前16位和后16位交换(利用位移和位操作实现)然后再将16位中的前8位和后8位交换然后再将8位中的前4位和后4位交换然后再将4位中的前2位和后2位交换最后将2位中的前1位和后1位交换. 上述交换全部采用位操作实现, 因此, 速度上有所优化. 1234567891011class Solution &#123;public: uint32_t reverseBits(uint32_t n) &#123; n = (n&gt;&gt;16) | (n&lt;&lt;16); n = ( ((n &amp; 0xff00ff00)&gt;&gt;8) | ((n &amp; 0x00ff00ff)&lt;&lt;8) ); n = ( ((n &amp; 0xf0f0f0f0)&gt;&gt;4) | ((n &amp; 0x0f0f0f0f)&lt;&lt;4) ); n = ( ((n &amp; 0xcccccccc)&gt;&gt;2) | ((n &amp; 0x33333333)&lt;&lt;2) ); n = ( ((n &amp; 0xaaaaaaaa)&gt;&gt;1) | ((n &amp; 0x55555555)&lt;&lt;1) ); return n; &#125;&#125;; 191. Number of 1 BitsDescription: 统计二进制中1的个数Write a function that takes an unsigned integer and returns the number of ‘1’ bits it has (also known as the Hamming weight). Example 1: Input: 11Output: 3Explanation: Integer 11 has binary representation 00000000000000000000000000001011Example 2: Input: 128Output: 1Explanation: Integer 128 has binary representation 00000000000000000000000010000000 解法一: 逐位统计时间复杂度: $O(1)$, 循环32次空间复杂度: $O(1)$ 查看每一位上的二进制是否为1, 若为1, 则count++ 12345678910class Solution &#123;public: int hammingWeight(uint32_t n) &#123; int count=0; for(int i=0; i&lt;32; i++)&#123; if( (n &amp; (1&lt;&lt;i)) != 0) count++; &#125; return count; &#125;&#125;; 解法二: 和 $n-1$ 按位与时间复杂度: $O(1)$, 循环次数为二进制中1的个数.空间复杂度: $O(1)$ 1234567891011class Solution &#123;public: int hammingWeight(uint32_t n) &#123; int count=0; while(n!=0)&#123; count++; n = n&amp;(n-1); &#125; return count; &#125;&#125;; 198. 打家劫舍-简单Description: 房屋小偷获取最大收益You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night. Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police. Example 1: Input: [1,2,3,1]Output: 4Explanation:Rob house 1 (money = 1) and then rob house 3 (money = 3).Total amount you can rob = 1 + 3 = 4.Example 2: Input: [2,7,9,3,1]Output: 12Explanation:Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1).Total amount you can rob = 2 + 9 + 1 = 12. 解法一: DP时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 依据 DP 的思想, 对于一个任意价格的房子, 我们有两种选择: 偷或不偷. 如果选择不偷, 那么前 $(i+1)$ 个房子的最大收益, 就应该是前 $i$ 个房子的最大收益(偷或者不偷第 $i$ 个房子收益中的较大者), 如果选择偷, 那么就不能偷第 $i$ 个房子.根据上面的描述, 我们可以维护两个变量 cur_rob 和 cur_nrob, 前者代表偷第 $i$ 个房子的收益, 后者代表不偷第 $i$ 个房子的收益, 则最大收益就应该为二者中的较大者. 详细代码如下: 12345678910111213class Solution &#123;public: int rob(vector&lt;int&gt;&amp; nums) &#123; int cur_rob=0; int cur_nrob=0; for(int i =0; i&lt;nums.size(); i++)&#123; int temp = cur_nrob; cur_nrob = std::max(cur_rob, cur_nrob); cur_rob = temp+nums[i]; &#125; return std::max(cur_rob, cur_nrob); &#125;&#125;; 解法二: 根据房屋的编号奇偶性时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 因为偷取的房屋不能相邻, 因此我们可以维护两个变量, even 是前偶数个房屋的最大收益, odd 是前奇数个房屋的最大收益, 对于任意的一个新来的房屋, 如果该新房屋的编号为奇数, 那么它的最大收益就是 odd+new 和 even 当中的较大者(因为不能相邻, 所以只能令 odd+new). 对于偶数的情况同理. 最终返回 odd 和 even 的较大者.(因为有可能包含最后一个元素, 也有可能不包含) 代码如下: 123456789101112class Solution &#123;public: int rob(vector&lt;int&gt;&amp; nums) &#123; int odd=0; int even=0; for(int i=0; i&lt;nums.size(); i++)&#123; if(i%2==0) even = std::max(odd, even+nums[i]); else odd = std::max(odd+nums[i], even); &#125; return std::max(odd, even); &#125;&#125;; 200. Number of IslandsDescription: 区块的个数Given a 2d grid map of ‘1’s (land) and ‘0’s (water), count the number of islands. An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water. Example 1: Input:11110110101100000000 Output: 1Example 2: Input:11000110000010000011 Output: 3 解法一: DFS 遍历时间复杂度: $O(n)$, 至多遍历两次 grid空间复杂度: $O(1)$ 遍历 grid 中的每一个元素, 如果为1, 则将与之相连的所有的1都置为0, 并且区块个数加1, 这样, 最坏的情况就是 grid 中的所有数字均为1, 此时, 需要遍历两边数组. 1234567891011121314151617181920212223242526272829class Solution &#123;public: int numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123; int res = 0; for(int i =0 ;i&lt;grid.size(); i++)&#123; for(int j=0; j&lt;grid[i].size(); j++)&#123; if(grid[i][j] == '1')&#123; fill(grid, i, j); res++; &#125; &#125; &#125; return res; &#125; void fill(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int i, int j) &#123; grid[i][j] = '2'; int n = grid.size(); int m = grid[0].size(); int dirs[4][2] = &#123;&#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;&#125;; for (auto dir : dirs) &#123; int x = i + dir[0]; int y = j + dir[1]; if (x &gt;=0 &amp;&amp; x &lt; n &amp;&amp; y &gt;=0 &amp;&amp; y &lt; m &amp;&amp; grid[x][y] == '1') &#123; fill(grid, x, y); &#125; &#125; &#125;&#125;; 202. Happy NumberDescription: 判断一个数字是否是 Happer NumberWrite an algorithm to determine if a number is “happy”. A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Example: Input: 19Output: trueExplanation:12 + 92 = 8282 + 22 = 6862 + 82 = 10012 + 02 + 02 = 1 解法一: 模拟计算过程时间复杂度: $O(logn)$, 基数为10空间复杂度: 未知, 取决于无序集合的size. 按照题目中的逻辑, 模拟整个计算过程, 如果出现1, 则返回 true, 如果出现循环(即在集合中发现已存在元素), 则返回 false. 1234567891011121314151617class Solution &#123;public: bool isHappy(int n) &#123; unordered_set&lt;int&gt; num_set; while(n!=1 &amp;&amp; num_set.find(n)==num_set.end())&#123; num_set.insert(n); int temp = 0; while(n!=0)&#123; temp += (n%10) * (n%10); n = n/10; &#125; n = temp; &#125; if(n==1) return true; return false; &#125;&#125;; 解法二: Floyd 判圈算法时间复杂度: $O(logn)$, 时间复杂度不变空间复杂度: $O(1)$ 利用 Floyd 判圈算法维护两个变量 slow 和 fast, fast 每次都比 flow 多走一步, 那么, 当 fast==1 时, 说明应该返回 true, 当 slow==fast 时, 说明存在循环, 应该返回 false. 123456789101112131415161718192021class Solution &#123;public: bool isHappy(int n) &#123; int slow=n, fast=n; do&#123; slow = digitSquareSum(slow); fast = digitSquareSum(fast); fast = digitSquareSum(fast); &#125;while(fast!=1 &amp;&amp; slow!=fast); if(fast == 1) return true; return false; &#125; int digitSquareSum(int n)&#123; int temp = 0; while(n!=0)&#123; temp += (n%10) * (n%10); n = n/10; &#125; return temp; &#125;&#125;; 204. Count PrimesDescription: 素数的个数Count the number of prime numbers less than a non-negative number, n. Example: Input: 10Output: 4Explanation: There are 4 prime numbers less than 10, they are 2, 3, 5, 7. 解法一: 填充非素数时间复杂度: $O(n)$, 至多遍历两次 $n$ 大小的数组, 可优化为只遍历一次.空间复杂度: $O(n)$, 申请了 $n$ 大小的一维布尔数组来标识是否为负数 如上图, 我们从 $2\times 2$ 开始填充, 将所有能与2相乘切乘积小于 $n$ 的数对应下标置为 false, 然后从 $3\times 3$ 开始填充(注意不是从 $3\times 2$, 因为这样会与前面的 $2\times 3$ 重复), 接着从 $4\times 4$ 开始填充, 因此, 填充的开始位置最大为 $\sqrt{n}$. 另外需要注意的是, 0 和 1 均不是素数. 123456789101112131415161718class Solution &#123;public: int countPrimes(int n) &#123; if(n==0 || n==1) return 0; int div_n = sqrt(n)+1; // 注意这里是开根号 vector&lt;bool&gt; is_primes(n, true); for(int i=2; i&lt;div_n; i++)&#123; for(int j=i*i; j&lt;n; j+=i)&#123; is_primes[j]=false; &#125; &#125; int res_count=0; for(auto primes : is_primes)&#123; if(primes==true) res_count++; &#125; return res_count-2; //去掉0和1的情况 &#125;&#125;; 优化1: 因为任何一个合数都可以拆分成素数的乘积, 因此我们只在当前元素为素数的时候才开始填充, 例如, 对于4, 我们不填充16, 20, ..等数字, 因为这些数字在开始元素为2的时候已经填充过了. 因此, 可以避免这些重复填充, 减少迭代次数, 代码如下(多加了一条if语句). 12345678910111213141516class Solution &#123;public: int countPrimes(int n) &#123; if(n==0 || n==1) return 0; int div_n = sqrt(n)+1; // 注意这里是开根号 vector&lt;bool&gt; is_primes(n, true); for(int i=2; i&lt;div_n; i++)&#123; if(is_primes[i])&#123; for(int j=i*i; j&lt;n; j+=i)&#123; is_primes[j]=false; &#125; &#125; &#125; return std::count(is_primes.begin(), is_primes.end(), true)-2; //去掉0和1的情况 &#125;&#125;; 优化2: 只遍历一次. 首先我们将判断数组isPrime的初始状态设为true, 这样, 每次只在遇到奇数时才检查其是否为素数, 如果该奇数是素数, 那么就将该奇数的倍数全部置为非素数, 同时, 将速度的count加1. 这样, 不仅可以减少判断次数(不再判断偶数), 同时可以在一次遍历的时间内完成素数统计. 12345678910111213141516171819class Solution &#123;public: int countPrimes(int n) &#123; std::vector&lt;bool&gt; isPrime(n, true); // 默认全是素数 int upper = std::sqrt(n); // 控制 i*i, 防止越界 if (n &lt;= 2) return 0; // 判断 0 ~ n-1 是否为素数, 当 n = 2 时, 返回0 int count = 1; // 2 也为素数 for (int i = 3; i &lt; n; i+=2) &#123; // 只有奇数才有可能是速度, 并且 1 不是素数 if (isPrime[i]) &#123; count++; if (i &gt; upper) continue; // 这里必须进行判断, 否则 i*i 有可能越界 for (int j = i*i; j &lt; n; j+=i) &#123; // 将 i 的倍数全部置为非素数 isPrime[j] = false; &#125; &#125; &#125; return count; &#125;&#125;; 206. Reverse Linked ListDescription: 逆置链表Reverse a singly linked list. Example: Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULLOutput: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 解法一: 迭代时间复杂度: $O(n)$, 遍历一次链表空间复杂度: $O(1)$, 借助3个复制指针完成逆置 123456789101112131415161718192021222324/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head==nullptr) return head; ListNode* pre = nullptr; ListNode* cur = head; ListNode* next = head-&gt;next; while(cur!=nullptr)&#123; next = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = next; &#125; return pre; &#125;&#125;; 解法二: 递归时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 迭代需要占用 $O(n)$ 大小的栈空间 12345678910class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return head; ListNode *P = reverseList(head-&gt;next); //令下一个开始的节点逆置, 返回新链表的头结点 head-&gt;next-&gt;next = head; // 将当前节点逆置 head-&gt;next=nullptr; // 将当前节点的下一个置空, 主要是处理新的尾节点, 其他节点的next会在递归中正确赋值 return P; //返回新的头结点 &#125;&#125;; 207. Course ScheduleDescription: 课程表 / 判断有向图是否存在环There are a total of n courses you have to take, labeled from 0 to n-1. Some courses may have prerequisites, for example to take course 0 you have to first take course 1, which is expressed as a pair: [0,1] Given the total number of courses and a list of prerequisite pairs, is it possible for you to finish all courses? Example 1:Input: 2, [[1,0]]Output: trueExplanation:There are a total of 2 courses to take. To take course 1 you should have finished course 0. So it is possible. Example 2:Input: 2, [[1,0],[0,1]]Output: falseExplanation:There are a total of 2 courses to take. To take course 1 you should have finished course 0, and to take course 0 you should also have finished course 1. So it is impossible. 解法一: BFS / 拓扑排序时间复杂度: $O(V+E)$, 统计入度时需要 $O(V)$, 处理队列需要 $O(E)$, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, 入度数组和队列分别需要 $(V)$, 邻接表需要 $O(V+E)$. 首先将图的边表示结构转换成邻接表形式(用vector来实现邻接表, 使其支持随机访问). 然后再申请一个 $O(V)$ 大小的数组来存储每个节点的入度. 在拓扑排序时, 先将所有入度为0的节点添加都一个队列当中, 然后从队列顶端拿出一个节点, 将该节点的所有直接后序节点的入度都减1, 然后再将所有入度为0的节点入队列. 如此迭代下去, 直至所有队列为空. 此时, 如果还有某个节点的入度不为0, 则说明存在环, 应该返回 false, 否则, 返回 true. 1234567891011121314151617181920212223242526class Solution &#123;public: bool canFinish(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;(0)); vector&lt;int&gt; in_degree(numCourses, 0); for(auto p : prerequisites)&#123; graph_c[p.second].push_back(p.first); in_degree[p.first]++; &#125; queue&lt;int&gt; q; // 入度为0的节点队列 for(int i=0; i&lt;numCourses; i++)&#123; if(in_degree[i]==0) q.push(i); //将所有入度为0的节点入队列 &#125; while(!q.empty())&#123; int cur_c = q.front(); q.pop(); for(auto next_c : graph_c[cur_c])&#123; // next_c为cur_c的直接后序课程 in_degree[next_c]--; // 后序节点的入度减1 if(in_degree[next_c]==0) q.push(next_c);//如果减为0, 则入队列 &#125; &#125; for(auto in : in_degree)&#123; if(in!=0) return false; &#125; return true; &#125;&#125;; 解法二: DFS时间复杂度: $O(V+E)$, 复杂度和 BFS 算法近似, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, visit数组和递归栈分别需要 $(V)$, 邻接表需要 $O(V+E)$. 首先, 和 BFS 一样, 建立关于图的邻接表结构, 然后, 申请 $O(V)$ 大小的访问数组visit, 初始值全部为0, 表示所有节点均为访问. 然后, 根据 DFS 算法的执行过程. 将当前正在访问的节点置为-1, 将已经访问过且确认无环的节点置为1. 则则DFS过程中, 如果访问到了一个已经被置为-1的节点, 则说明该节点是当前循环内的正在访问的节点, 因此, 构成了一个环, 返回 false. 如果遇到了一个被置为1的节点, 因为已经确认该节点无环, 因此可以直接返回 true. 12345678910111213141516171819202122232425class Solution &#123;public: bool canFinish(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;(0)); vector&lt;int&gt; visit(numCourses, 0); for(auto p : prerequisites) graph_c[p.second].push_back(p.first); for(int i=0; i&lt;numCourses; i++)&#123; // 因为当前的图并不是一个连通图, 所以必须遍历所有的节点 if(canFinishDFS(graph_c, visit, i) == false) return false; &#125; return true; &#125; bool canFinishDFS(vector&lt;vector&lt;int&gt;&gt; &amp;graph_c, vector&lt;int&gt; &amp;visit, int i)&#123; if(visit[i] == -1) return false; if(visit[i] == 1) return true; visit[i] = -1; // 将当前节点置为正在访问状态 for(auto node : graph_c[i])&#123; if(canFinishDFS(graph_c, visit, node) == false) return false; // 当前节点上存在环 &#125; visit[i] = 1; // 将当前节点置为已经访问过且确认无环状态 return true; // 确认节点i无环, 返回true &#125;&#125;; 208. Implement Trie (Prefix Tree)Description: 实现字典树(前缀树)Implement a trie with insert, search, and startsWith methods. Example:12345678Trie trie = new Trie();trie.insert("apple");trie.search("apple"); // returns truetrie.search("app"); // returns falsetrie.startsWith("app"); // returns truetrie.insert("app"); trie.search("app"); // returns true 解法一https://www.cnblogs.com/grandyang/p/4491665.html 时间复杂度: $O(k)$, 插入, 查找, 找前缀均只需要 $O(k)$复杂度, $k$ 为字符串长度空间复杂度: 与字符串的公共部分的多少有关, 公共部分越多, 越节省空间, 反之, 空间复杂度较高. 最差情况下为 $O(wk)$, 其中, $w$ 为单词的个数, $k$ 为单词的最长长度. 字母字典树是一个26叉树, 树的根节点没有字符, 其他节点有且仅有一个字符, 我们模仿二叉树的定义, 构建一个26叉树的数据结构, 用子节点的编号代表字母(即0号节点代表字母a, 1号代表b,…,25号代表z), 另外需要定义一个布尔值来标识当前节点是否构成一个单词. 插入时, 根据字符串遍历树, 如果当前字符不存在, 则新建一个. 查找和找前缀时, 如果不存在则直接返回false. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class TrieNode&#123;public: TrieNode *child[26]; bool is_word; TrieNode():is_word(false)&#123; for(auto &amp;c : child)&#123; // 对c进行改动, 需要用引用&amp; c = nullptr; &#125; &#125;&#125;;class Trie &#123;private: TrieNode *root;public: /** Initialize your data structure here. */ Trie() &#123; root = new TrieNode(); &#125; /** Inserts a word into the trie. */ void insert(string word) &#123; TrieNode *p = root; for(auto letter : word)&#123; int i = letter - 'a'; if(p-&gt;child[i] == nullptr) p-&gt;child[i]=new TrieNode(); p = p-&gt;child[i]; &#125; p-&gt;is_word = true; &#125; /** Returns if the word is in the trie. */ bool search(string word) &#123; TrieNode *p = root; for(auto letter : word)&#123; int i = letter - 'a'; if(p-&gt;child[i]==nullptr) return false; p = p-&gt;child[i]; &#125; return (p-&gt;is_word == true) ? true : false; &#125; /** Returns if there is any word in the trie that starts with the given prefix. */ bool startsWith(string prefix) &#123; TrieNode *p = root; for(auto letter : prefix)&#123; int i = letter - 'a'; if(p-&gt;child[i]==nullptr) return false; p = p-&gt;child[i]; &#125; return true; &#125;&#125;;/** * Your Trie object will be instantiated and called as such: * Trie obj = new Trie(); * obj.insert(word); * bool param_2 = obj.search(word); * bool param_3 = obj.startsWith(prefix); * / 210. Course Schedule IIDescription: 判断有向图是否有环, 若无环, 则返回拓扑序列There are a total of n courses you have to take, labeled from 0 to n-1. Some courses may have prerequisites, for example to take course 0 you have to first take course 1, which is expressed as a pair: [0,1] Given the total number of courses and a list of prerequisite pairs, return the ordering of courses you should take to finish all courses. There may be multiple correct orders, you just need to return one of them. If it is impossible to finish all courses, return an empty array. Example 1:Input: 2, [[1,0]]Output: [0,1]Explanation:There are a total of 2 courses to take. To take course 1 you should have finished course 0. So the correct course order is [0,1] . Example 2:Input: 4, [[1,0],[2,0],[3,1],[3,2]]Output: [0,1,2,3] or [0,2,1,3]Explanation:There are a total of 4 courses to take. To take course 3 you should have finished both courses 1 and 2. Both courses 1 and 2 should be taken after you finished course 0. So one correct course order is [0,1,2,3]. Another correct ordering is [0,2,1,3] . 解法一: BFS, 拓扑排序时间复杂度: $O(V+E)$, 统计入度时需要 $O(V)$, 处理队列需要 $O(E)$, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, 入度数组和队列分别需要 $(V)$, 邻接表需要 $O(V+E)$, 相比于第207题, 多了一个拓扑序列的数组, 大小为 $O(V)$. 和第207题差不多, 不过在判断是否有环的同时, 还要记录正确的拓扑序列并返回. 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; findOrder(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;()); // 构建图的邻接表 vector&lt;int&gt; in_degree(numCourses);// 构建入度数组 for(auto c_pair : prerequisites)&#123; graph_c[c_pair.second].push_back(c_pair.first); in_degree[c_pair.first]++; &#125; queue&lt;int&gt; q; //入度为0的队列 for(int i=0; i&lt;numCourses; i++)&#123; if(in_degree[i]==0) q.push(i); &#125; vector&lt;int&gt; res; // 记录拓扑序列 while(!q.empty())&#123; int cur_c = q.front(); q.pop(); res.push_back(cur_c); for(auto &amp;next_c : graph_c[cur_c])&#123; in_degree[next_c]--; // 后修课的入度减1 if(in_degree[next_c]==0) q.push(next_c); &#125; &#125; if(res.size() == numCourses) return res; else return vector&lt;int&gt;(); &#125;&#125;; 解法二: DFS时间复杂度: $O(V+E)$, 复杂度和 BFS 算法近似, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, visit数组和递归栈分别需要 $(V)$, 邻接表需要 $O(V+E)$, 拓扑序列需要 $O(V)$. 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; findOrder(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;()); // 构建图的邻接表 vector&lt;int&gt; visit(numCourses, 0);// 构建入度数组 for(auto c_pair : prerequisites)&#123; graph_c[c_pair.second].push_back(c_pair.first); &#125; vector&lt;int&gt; res; for(int i=0; i&lt;numCourses; i++)&#123; //非连通图, 需要遍历所有节点 if(findOrderDFS(graph_c, i, visit, res)==false) return vector&lt;int&gt;(); &#125; std::reverse(res.begin(), res.end()); //等于dfs来说, 最后的课程会先加入结果数组, 因此, res中的序列逆置后才是最终的拓扑序列. return res; &#125; bool findOrderDFS(vector&lt;vector&lt;int&gt;&gt; &amp;graph_c, int i, vector&lt;int&gt; &amp;visit, vector&lt;int&gt; &amp;res)&#123; if(visit[i]==-1) return false; // 重复访问, 存在环 if(visit[i]==1) return true; // 已经访问过且确认无环, 可直接返回 visit[i] = -1; // 置为正在访问状态 for(auto next_c : graph_c[i])&#123; if(findOrderDFS(graph_c, next_c, visit, res) == false) return false; &#125; visit[i] = 1; //确认无环 res.push_back(i); // return true; &#125;&#125;; 212. Word Search IIDescription: 返回字符矩阵中含有的所有单词Given a 2D board and a list of words from the dictionary, find all words in the board. Each word must be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once in a word. Example: Input:words = [“oath”,”pea”,”eat”,”rain”] and board =[ [‘o’,’a’,’a’,’n’], [‘e’,’t’,’a’,’e’], [‘i’,’h’,’k’,’r’], [‘i’,’f’,’l’,’v’]] Output: [“eat”,”oath”] 解法一: 穷举时间复杂度: $O(w mn 4^k)$, 暴力求解, $mn$ 为字符矩阵的宽和高, 也即 cell 数量, 对于 dfs 中的每个 cell, 有4个扩展方向, 一共需要扩展 $k$ 次($k$ 为单词的长度). 总共有 $w$ 个单词, 因此复杂度为$O(w mn 4^k)$空间复杂度: $O(mn)$ , 和79题相同, 回溯时, 用#来记录已经遍历过的点, 无需申请额外空间来记录. 但是递归程序需要占用 $O(mn)$ 的空间复杂度. 该题和79题类似, 只不过给定的是一个单词列表, 而不是一个单词, 因此, 可以对这个单词列表循环调用79题的解. 不过时间复杂度过高, 无法通过 OJ. 解法二: 字典树时间复杂度: $O(mn 4^k)$, 暴力求解, $mn$ 为字符矩阵的 cell 数量, 对于 dfs 中的每个 cell, 有4个扩展方向, 一共需要扩展 $k$ 次($k$ 为单词的长度).空间复杂度: $O(mn)$ , 和79题相同, 回溯时, 用#来记录已经遍历过的点, 无需申请额外空间来记录. 但是递归程序需要占用 $O(mn)$ 的空间复杂度. 另外, 还有构建字典树所需的空间复杂度, 这部分复杂度与具体的字符串数组有关, 当字符串公共部分较多时, 复杂度较低, 反之, 复杂度较高, 最差情况下为 $O(wk)$, 即无公共前缀 相对于第79题来说, 本题增加的复杂度主要体现在需要同时查看 $w$ 个单词的字符, 查询这些单词字符的复杂度约为 $O(wk)$, 其中, $k$ 为单词的最大长度, 那么, 我们能否将这里的复杂度降低成 $k$ 呢? 如果降低成 $k$ 的话, 就相当是在查找一个单词, 那么整体的复杂度就和79题相同, 变成了 $O(mn 4^k)$.实际上, 字典树正是这种数据结构! 在由 $w$ 个字符串构成的字典树中查询某个字符串或者字符子串的复杂度为 $k$. 因此, 我们可以借助字典树来降低整体的时间复杂度. 代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class TrieNode&#123;public: TrieNode *child[26]; string str; TrieNode():str("")&#123; for(auto &amp;node : child) node=nullptr; &#125;&#125;;class Trie&#123;public: TrieNode *root; Trie():root(new TrieNode())&#123;&#125;; void insert(string s)&#123; TrieNode *p = root; for(auto c : s)&#123; int i = c - 'a'; if(p-&gt;child[i] == nullptr) p-&gt;child[i] = new TrieNode(); p = p-&gt;child[i]; &#125; p-&gt;str = s; &#125;&#125;;class Solution &#123;public: vector&lt;string&gt; findWords(vector&lt;vector&lt;char&gt;&gt;&amp; board, vector&lt;string&gt;&amp; words) &#123; vector&lt;string&gt; res; if(words.size()==0 || board.size()==0 || board[0].size()==0) return res; vector&lt;vector&lt;bool&gt;&gt; visit(board.size(), vector&lt;bool&gt;(board[0].size(), false)); Trie T; for(auto word : words) T.insert(word); for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[i].size(); j++)&#123; if(T.root-&gt;child[board[i][j] - 'a'] != nullptr)&#123; search(board, T.root-&gt;child[board[i][j]-'a'], i, j, visit, res); &#125; &#125; &#125; return res; &#125; void search(vector&lt;vector&lt;char&gt;&gt; &amp;board, TrieNode *node, int i, int j, vector&lt;vector&lt;bool&gt;&gt; &amp;visit, vector&lt;string&gt; &amp;res)&#123; if(!node-&gt;str.empty())&#123; res.push_back(node-&gt;str); node-&gt;str.clear(); // 重新置为空 node-&gt;str = ""; 防止重复push_back &#125; int direct[4][2] = &#123; &#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125; &#125;; visit[i][j] = true; // 将当前位置设置为已访问, 因为题目要求同一个位置只能在一个字符串中被访问一次 for(auto d : direct)&#123; int new_i = i + d[0]; int new_j = j + d[1]; if(new_i&gt;=0 &amp;&amp; new_j&gt;=0 &amp;&amp; new_i&lt;board.size() &amp;&amp; new_j&lt;board[0].size() &amp;&amp; visit[new_i][new_j]==false &amp;&amp; node-&gt;child[board[new_i][new_j] - 'a'] != nullptr)&#123; search(board, node-&gt;child[board[new_i][new_j] - 'a'], new_i, new_j, visit, res); &#125; &#125; visit[i][j] = false; &#125;&#125;; 213. 打家劫舍 II-中等题目链接: https://leetcode-cn.com/problems/house-robber-ii/ 解法: 动态规划C++ 实现:在 198 题打家劫舍的基础上进行扩展, 由题意知, 该题的难点在于第一家和最后一家是紧挨着的, 因此, 我们可以分两种情况进行讨论, 第一种情况是允许偷第一家, 那么就一定不能偷最后一家, 第二种情况是允许偷最后一家, 那么就一定不能偷第一家. 注意, 这里用的是允许偷, 而不是一定偷, 偷与不偷的取舍会在动态规划中自行决定.12345678910111213141516171819202122232425class Solution &#123;public: int rob(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 1) return nums[0]; int dp1[2] = &#123;0, 0&#125;; int dp2[2] = &#123;0, 0&#125;; for (int i = 0; i &lt; nums.size(); i++) &#123; if (i &lt; nums.size()-1) &#123; // 可以偷第一家, 就一定不能偷最后一家 int rob = dp1[1] + nums[i]; int not_rob = std::max(dp1[0], dp1[1]); dp1[0] = rob; dp1[1] = not_rob; &#125; if (i &gt; 0) &#123; // 可以偷最后一家, 就一定不能偷第一家 int rob = dp2[1] + nums[i]; int not_rob = std::max(dp2[0], dp2[1]); dp2[0] = rob; dp2[1] = not_rob; &#125; &#125; int m1 = std::max(dp1[0], dp1[1]); int m2 = std::max(dp2[0], dp2[1]); return std::max(m1, m2); &#125;&#125;; Python 实现:123456789101112131415class Solution: def rob(self, nums: List[int]) -&gt; int: if len(nums) == 1: return nums[0] dp1 = [0, 0] dp2 = [0, 0] for i, num in enumerate(nums): if i &lt; len(nums)-1: # 允许偷第一家, 不能偷最后一家 rob = dp1[1] + num not_rob = max(dp1[0], dp1[1]) dp1 = [rob, not_rob] if i &gt; 0: # 允许偷最后一家, 不能偷第一家 rob = dp2[1] + num not_rob = max(dp2[0], dp2[1]) dp2 = [rob, not_rob] return max(dp1[0], dp1[1], dp2[0], dp2[1]) 215. Kth Largest Element in an ArrayDescription: 找出无序数组中第k大的数Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element. Example 1: Input: [3,2,1,5,6,4] and k = 2Output: 5Example 2: Input: [3,2,3,1,2,4,5,5,6] and k = 4Output: 4 解法一: 小顶堆时间复杂度: $O(nlogk)$, 堆的插入复杂度为 $O(logk)$, 最多需要进行 $n$ 次插入.空间复杂度: $O(k)$, 堆的大小 构建一个大小为 $k$ 的小顶堆, 对于任意一个新来的元素, 如果该元素大于堆顶, 将则堆顶退出, 并将该元素插入. 最终, 堆内的元素就是数组的最大的前 $k$ 个元素, 而堆顶刚好为第 $k$ 大的元素. 123456789101112131415class Solution &#123;public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt; heap_k; for(auto num : nums)&#123; if(heap_k.size() &lt; k)&#123; heap_k.push(num); &#125;else if(num &gt; heap_k.top())&#123; heap_k.pop(); heap_k.push(num); &#125; &#125; return heap_k.top(); &#125;&#125;; 解法二: 部分排序(nth_element)http://www.voidcn.com/article/p-qyrpnkse-gx.html 最优解法 时间复杂度: 平均为 $O(n)$. nth_element 的时间复杂度为 $T(n) = T(n/2) + O(n) = O(n) + O(n/2) + O(n/4) + …$, 也就是 $O(n)$.空间复杂度: $O(1)$, 不占用额外空间 直接调用 STL 的部分排序算法nth_element.nth_element算法将重新排列区间[first, last)的序列元素, 算法执行完毕后, 会使得 第 $k$ 个位置的元素在最终的算法执行完毕后, 和整个区间完全排序后该位置的元素相同. 这个新的nth元素之前的所有元素均 &lt;= (&gt;=) nth元素之后的所有元素.但是该算法并不保证位于第 $k$ 个元素两边区间的元素有序. 该算法和 partial_sort 算法之间一个很大的区别在于: nth_element对于除第 $k$ 位置的元素之外的区间元素的顺序不做保证, 而partial_sort排序后会使得前 $m$ 个数的子区间是有序的. 正因为如此, 在需要无序的前 top_k 个值时, nth_element 相对于 partial_sort 要更快.(只需要找第 $k$ 个值, 其前面的元素即为 top_k, 时间复杂度为 $O(n)$). 如果需要有序, 也可以先使用 nth_element, 再对前 k 个数组排序, 总的复杂度为 $O(n+klogk)$ 1234567class Solution &#123;public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; std::nth_element(nums.begin(), nums.begin()+k-1, nums.end(), std::greater&lt;int&gt;()); return nums[k-1]; &#125;&#125;; 解法三: 基于 Partition时间复杂度: $O(n)$空间复杂度: $O(1)$ 该解法和解法二思路相同, 只不过是我们自己手动实现 Partition 的算法逻辑, 而不是调用 STL 函数. 123456789101112131415161718192021222324252627class Solution &#123;public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; int low=0, high=nums.size()-1; int pth = Partition(nums, low, high); while(pth != k-1)&#123; if(pth &gt; k-1) high = pth-1; else low = pth+1; pth = Partition(nums, low, high); &#125; return nums[pth]; &#125; int Partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P&gt;= nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P&lt;=nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125;&#125;; 217. Contains DuplicateDescription: 判断数组中是否有重复元素Given an array of integers, find if the array contains any duplicates. Your function should return true if any value appears at least twice in the array, and it should return false if every element is distinct. Example 1: Input: [1,2,3,1]Output: trueExample 2: Input: [1,2,3,4]Output: falseExample 3: Input: [1,1,1,3,3,4,3,2,4,2]Output: true 解法一: 暴力时间复杂度: $O(n^2)$, 暴力求解, 双重循环空间复杂度: $O(1)$, 无需额外空间 时间超限, 无法通过 OJ 解法二: 排序+遍历时间复杂度: $O(nlogn)$, 先排序, 然后遍历看是否有相邻元素相等, 即 $O(nlogn + n)$, 也就是 $O(nlogn)$.空间复杂度: $O(1)$, 基于不同的排序算法决定, 使用堆排序则为 $O(1)$. 解法三: unordered_set(哈希)时间复杂度: $O(n)$, 遍历一遍数组, 在 unordered_set 中查询的复杂度为常数空间复杂度: $O(n)$, unordered_set占用额外空间 12345678910111213class Solution &#123;public: bool containsDuplicate(vector&lt;int&gt;&amp; nums) &#123; std::unordered_set&lt;int&gt; nums_set; for(auto num : nums)&#123; if(nums_set.find(num) == nums_set.end()) nums_set.insert(num); else return true; &#125; return false; &#125;&#125;; 218. The Skyline ProblemDescription: 天际线问题A city’s skyline is the outer contour of the silhouette formed by all the buildings in that city when viewed from a distance. Now suppose you are given the locations and height of all the buildings as shown on a cityscape photo (Figure A), write a program to output the skyline formed by these buildings collectively (Figure B). The geometric information of each building is represented by a triplet of integers [Li, Ri, Hi], where Li and Ri are the x coordinates of the left and right edge of the ith building, respectively, and Hi is its height. It is guaranteed that 0 ≤ Li, Ri ≤ INT_MAX, 0 &lt; Hi ≤ INT_MAX, and Ri - Li &gt; 0. You may assume all buildings are perfect rectangles grounded on an absolutely flat surface at height 0. For instance, the dimensions of all buildings in Figure A are recorded as: [ [2 9 10], [3 7 15], [5 12 12], [15 20 10], [19 24 8] ] . The output is a list of “key points” (red dots in Figure B) in the format of [ [x1,y1], [x2, y2], [x3, y3], … ] that uniquely defines a skyline. A key point is the left endpoint of a horizontal line segment. Note that the last key point, where the rightmost building ends, is merely used to mark the termination of the skyline, and always has zero height. Also, the ground in between any two adjacent buildings should be considered part of the skyline contour. For instance, the skyline in Figure B should be represented as:[ [2 10], [3 15], [7 12], [12 0], [15 10], [20 8], [24, 0] ]. 解法一: multiset时间复杂度: $O(nlogn)$, 拆分三元组到二元组为 $O(n)$, 排序为 $O(nlogn)$, 更新轮廓节点为 $O(nlogn)$ (插入高度为 $O(log)$, 总共有 $O(n)$ 组高度).空间复杂度: $O(n)$, 存储高度的二元组 vector, 以及维护当前建筑物高度顺序的 multiset. 首先我们将表示建筑物的所有三元组(Li, Ri, Hi)进行拆分, 将其分成(Li, -Hi), (Ri, Hi)的两个二元组, 将这些二元组存放在一个数组 vector 中, 然后按照 x 轴的下标进行排序, 注意如果当一个建筑物的右侧和另一个建筑物的左侧重叠时, 我们为了不丢失当前建筑物的高度, 必须先考虑将另一个建筑物的左侧添加进 multiset 里, 然后获取最高高度. 接着在下一次循环时, 再将重合的右侧边界对应的建筑物剔除, 因此我们需要令二元组中的左侧为负, 使其在排序时可以排到前面.得到有序的建筑物二元组序列以后, 我们遍历该序列, 如果遇到了某个建筑物的左侧边界, 则将该边界对应建筑物的高度加入到 multiset 中, 如果遇到了某个建筑物的右侧边界, 则将对应建筑物的高度剔除. 假设我们已经得到了前 i 个坐标的建筑物组成的轮廓坐标点, 现在来到第 i+1 个坐标, 只有可能对应下面几种情况: i+1 坐标上新来的建筑物(遇到该建筑物左侧就行)完全被之前的建筑物覆盖, 此时不更新 res 轮廓. 说明添加了该建筑物后, 并不改变当前建筑群的最高高度. i+1 坐标上新来的建筑物比当前建筑群最高的高度还要高, 则需要记录当前的点. i+1 坐标上没有新来建筑物, 但是有一个建筑物遇到了右侧边界, 此时建筑群的高度会变成第二高建筑物的高度, 同样需要记录当前的坐标点. i+1 坐标上既没有新来建筑物, 也没有遇到建筑物右侧, 此时无需记录任何值, 可继续探测 i+2 坐标. 123456789101112131415161718192021222324252627282930class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; getSkyline(vector&lt;vector&lt;int&gt;&gt;&amp; buildings) &#123; vector&lt;pair&lt;int, int&gt;&gt; heights, res; // height 用于存放建筑物的高度, res存放结果 multiset&lt;int&gt; m; // 用 multiset 数据结构来维护当前x坐标之前的建筑物高度 for(auto &amp;b : buildings)&#123; //用负高度代表当前的边是左侧的边. 因为后面有排序, 所以必须令左侧为负, 而不能令右侧为负. //因为当x坐标相同时, 当前的building的右侧还不能剔除, //否则, 有可能"低估" 轮廓高度所以要将左侧的排在前面 heights.push_back(&#123;b[0], -b[2]&#125;); heights.push_back(&#123;b[1], b[2]&#125;); &#125; std::sort(heights.begin(), heights.end()); // 按照x坐标排序, 当x一样时, 按照高度排序 int pre = 0; // pre代表之前的最高建筑物的高度, 初始为0 int cur; // cur 代表当前的最高建筑物的高度, 会在for循环中赋值. m.insert(0); // 开始的时候, m中的最高高度为0 for(auto &amp;h : heights)&#123; if(h.second &lt; 0) m.insert(-h.second); // 如果是左侧边, 则加入当前建筑物高度集合, 并自动排序 else m.erase(m.find(h.second)); // 如果遇到了右侧边, 则将对应的建筑物从当前建筑物集合内剔除 // 注意, 这里在使用erase时, 是先找到key值匹配的某一个元素的迭代器(多个存在多个匹配), 然后再删除 // 如果直接使用 erase(key) 的话, 则会将满足key值的所有元素都擦除, 这样会导致程序出错. cur = * m.rbegin(); // 获取当前的最大高度 if(cur != pre)&#123; // 说明此时要么新加入了更高的高度, 要么被用于最高高度的建筑物被剔除, 需要更新轮廓点 res.push_back(&#123;h.first, cur&#125;); //新更新的轮廓点的x坐标即为当前h的x坐标. pre = cur; // 更新pre &#125; &#125; return res; &#125;&#125;; 解法二: priority_queue(堆)在解法一中, 用了 multiset, 之所以不用 priority_queue 的原因是因为, C++ 的 priority_queue 容器并没有提供erase或者find之类的方法, 因此, 在删除指定高度时, 比较麻烦. 而 multiset 不仅完成堆的功能(最后一个元素就是最大的), 同时还支持在对数复杂度时间内删除指定的高度. 因此, 如果想要使用 priority_queue 的话, 就需要调整算法的逻辑, 下面是使用 priority_queue 的解法: 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; getSkyline(vector&lt;vector&lt;int&gt;&gt;&amp; buildings) &#123; std::vector&lt;std::pair&lt;int, int&gt;&gt; res; int cur = 0, cur_X, cur_H = -1, len = buildings.size(); std::priority_queue&lt;std::pair&lt;int, int&gt;&gt; liveBlg; while (cur &lt; len or !liveBlg.empty()) &#123; cur_X = liveBlg.empty() ? buildings[cur][0] : liveBlg.top().second; if (cur &gt;= len or buildings[cur][0] &gt; cur_X) &#123; while (!liveBlg.empty() &amp;&amp; (liveBlg.top().second &lt;= cur_X)) &#123; liveBlg.pop(); &#125; &#125; else &#123; cur_X = buildings[cur][0]; while (cur &lt; len &amp;&amp; buildings[cur][0] == cur_X) &#123; liveBlg.push(&#123;buildings[cur][2], buildings[cur][1]&#125;); cur++; &#125; &#125; cur_H = liveBlg.empty() ? 0 : liveBlg.top().first; if (res.empty() or (res.back().second != cur_H)) &#123; res.push_back(&#123;cur_X, cur_H&#125;); &#125; &#125; return res; &#125;&#125;; 221. 最大正方形题目链接: https://leetcode-cn.com/problems/maximal-square/ 解法一: 动态规划时间复杂度：$O(mn)$空间复杂度: $O(n)$ 申请一个长度为矩阵列数的一维数组dp, dp[j]代表以matrix[i][j]为结尾的正方形的边长, 于是当我们计算矩阵中以某个点为右下角的正方形边长时, 就可以利用右上角已经计算过的变量直接获取相应的信息, 这里在使用dp时, 需要注意的一点是, 由于仅仅需要右上角的值, 因此, 每次新的dp生成时, 都要向后移一位, 前面补0. 123456789101112131415161718192021class Solution: def maximalSquare(self, matrix: List[List[str]]) -&gt; int: if len(matrix) == 0: return 0 m = len(matrix) n = len(matrix[0]) dp = [0] * (n+1) res = 0 for i in range(m): for j in range(n): if matrix[i][j] != '0': # 注意, 字符 '0' 在 bool 中是 True 的, 所以不能直接用 if matrix[i][j] edge = dp[j] k = 1 while (k &lt;= edge and matrix[i-k][j]!='0' and matrix[i][j-k]!='0'): # 利用之前已经求得的正方形基础上算当前正方形边长 k += 1 dp[j] = k # 更新正方形边长 else: dp[j] = 0 res = max(res, dp[j]) # 更新 res dp = [0] + dp[0:-1] # dp 数组最前方加0, 其他元素后移, 最后一个元素再后面用不到, 舍去 return res*res 解法二: 优化的动态规划时间复杂度：$O(mn)$空间复杂度: $O(1)$ 由于仅仅需要右上角的值, 因此我们可以把dp压缩到一个常数, 此时matrix的便利方式就不能是先行后列了, 而应该是沿着对角线进行遍历才行. Python 实现:1234567891011121314151617181920212223242526272829303132class Solution: def maximalSquare(self, matrix: List[List[str]]) -&gt; int: if len(matrix) == 0: return 0 m = len(matrix) n = len(matrix[0]) res = 0 i = 0 j = 0 while i &lt; m or j &lt; n: if i &lt; m: ii = i jj = 0 i += 1 elif j &lt; n: ii = 0 jj = j j += 1 dp = 0 while ii &lt; m and jj &lt; n: if matrix[ii][jj] == '0': dp = 0 else: edge = dp k = 1 while (k &lt;= edge and matrix[ii-k][jj] == '1' and matrix[ii][jj-k] == '1'): k += 1 dp = k res = max(res, dp) ii += 1 jj += 1 return res*res C++ 实现:1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int maximalSquare(vector&lt;vector&lt;char&gt;&gt;&amp; matrix) &#123; if (matrix.size() == 0) return 0; int m = matrix.size(); int n = matrix[0].size(); int res = 0, i = 0, j = 0, ii = 0, jj = 0; while (i &lt; m or j &lt; n) &#123; if (i &lt; m) &#123; ii = i; jj = 0; i++; &#125; else if (j &lt; n) &#123; ii = 0; jj = j; j++; &#125; int dp = 0; while (ii &lt; m and jj &lt; n) &#123; if (matrix[ii][jj] == '0') dp = 0; else &#123; int k = 1; while (k &lt;= dp and matrix[ii-k][jj] == '1' and matrix[ii][jj-k] == '1') &#123; k++; &#125; dp = k; &#125; ii++; jj++; res = std::max(res, dp); &#125; &#125; return res*res; &#125;&#125;; 226. 翻转二叉树题目链接: https://leetcode-cn.com/problems/invert-binary-tree/ 谷歌: 我们90％的工程师使用您编写的软件(Homebrew), 但是您却无法在面试时在白板上写出翻转二叉树这道题, 这太糟糕了. 解法一: 递归Python 实现: 编写递归函数, 先翻转两个子树, 再把左右子树翻转12345678910111213141516171819# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: def invert(root): if root == None: return invert(root.right) invert(root.left) root.right, root.left = root.left, root.right return invert(root) return root 先翻转左右节点, 再翻转子树也可以:12345678910111213141516171819# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: def invert(root): if root == None: return root.right, root.left = root.left, root.right invert(root.right) invert(root.left) return invert(root) return root C++ 实现(先根, 其他同理):1234567891011121314151617181920/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* invertTree(TreeNode* root) &#123; if (root == nullptr) return root; std::swap(root-&gt;right, root-&gt;left); invertTree(root-&gt;left); invertTree(root-&gt;right); return root; &#125;&#125;; 解法二: 迭代该题用递归非常好解, 所以如果面试问道, 一定会考察迭代解法. 核心思想就是遍历二叉树的每一个节点, 然后把节点的的左右子树交换即可, 故而有先根, 中根, 后根遍历三种解法, 分别如下: 先根遍历Python 实现:1234567891011121314151617181920# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: stack = [] node = root while node != None or len(stack) &gt; 0: while node != None: node.left, node.right = node.right, node.left # 先根遍历 stack.append(node) node = node.right # 左右子树已经交换了, 所以要入栈原来的左子树, 就需要入栈right node = stack.pop() node = node.left # 注意, 由于已经将左右子树交换了, 所以这里的左子树实际是原来未入栈的右子树 return root 实际上, 树的左右孩子是等价的, 因此, 即使这里入栈交换后的left, 也没有问题, 只要保证后面即将入栈的和之前入栈是相反的孩子即可. 12345678910111213141516171819# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: stack = [] node = root while node != None or len(stack) &gt; 0: while node != None: node.left, node.right = node.right, node.left # 先根遍历 stack.append(node) node = node.left # 实际上, 树的左右孩子是等价的, 因此, 即使这里入栈交换后的left, 也没有问题, node = stack.pop() node = node.right # 只要保证这里即将入栈的和之前入栈是相反的孩子即可 return root C++ 实现:1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* invertTree(TreeNode* root) &#123; std::stack&lt;TreeNode*&gt; s; auto node = root; while (node != nullptr or !s.empty()) &#123; while (node != nullptr) &#123; std::swap(node-&gt;left, node-&gt;right); s.push(node); node = node-&gt;left; &#125; node = s.top(); s.pop(); node = node-&gt;right; &#125; return root; &#125;&#125;; 中根遍历Python 实现:1234567891011121314151617181920# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: stack = [] node = root while node != None or len(stack) &gt; 0: while node != None: stack.append(node) node = node.left # 中根遍历 node = stack.pop() node.left, node.right = node.right, node.left node = node.left # 注意, 由于已经将左右子树交换了, 所以这里的左子树实际是原来未入栈的右子树 return root C++ 实现:1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* invertTree(TreeNode* root) &#123; std::stack&lt;TreeNode*&gt; s; auto node = root; while (node != nullptr or !s.empty()) &#123; while (node != nullptr) &#123; s.push(node); node = node-&gt;left; &#125; node = s.top(); s.pop(); std::swap(node-&gt;left, node-&gt;right); node = node-&gt;left; &#125; return root; &#125;&#125;; 后根遍历Python 实现:123456789101112131415161718192021222324# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: stack = [] node = root pre = None while node != None or len(stack) &gt; 0: while node != None: stack.append(node) node = node.left # 实际上, 树的左右孩子是等价的, 因此, 即使这里入栈交换后的left, 也没有问题, if pre == stack[-1].right or stack[-1].right == None: # 只有当右子树为空或者已经访问过时, 才能访问根 r_node = stack.pop() # 注意, 访问根时, 不能将根的值赋给 node, 否则外部node会陷入死循环 pre = r_node r_node.left, r_node.right = r_node.right, r_node.left # 交换左右子树 else: node = stack[-1].right return root C++ 实现:1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* invertTree(TreeNode* root) &#123; std::stack&lt;TreeNode*&gt; s; auto node = root; TreeNode* pre = nullptr; while (node != nullptr or !s.empty()) &#123; while (node != nullptr) &#123; s.push(node); node = node-&gt;left; &#125; auto tmpnode = s.top(); if (tmpnode-&gt;right == nullptr or tmpnode-&gt;right == pre) &#123; s.pop(); pre = tmpnode; std::swap(tmpnode-&gt;right, tmpnode-&gt;left); &#125; else &#123; node = tmpnode-&gt;right; &#125; &#125; return root; &#125;&#125;; 227. Basic Calculator IIDescription: 基本计算器(二)Implement a basic calculator to evaluate a simple expression string. The expression string contains only non-negative integers, +, -, * , / operators and empty spaces . The integer division should truncate toward zero. Example 1: Input: “3+2*2”Output: 7Example 2: Input: “ 3/2 “Output: 1Example 3: Input: “ 3+5 / 2 “Output: 5 解法一: 栈时间复杂度: $O(n)$, 遍历字符串一遍, 遍历栈一遍空间复杂度: $O(n)$, 栈的大小 因为本题没有带括号, 因此优先级关系比较明朗, 可以简单的用栈来实现. 对于任意一个符号, 如果是加号或者减号, 就直接将其后面的数字入栈, 其中减号的情况需要给入栈数字加负号. 如果是乘号或除号, 将先从栈顶取出一个数字, 然后将该数字与符号后的数字进行计算, 并将计算结果入栈. 如此遍历, 直到遍历完所有字符, 最终将栈中的所有数字相加.此题需要注意两个地方, 一是对于第一个数字, 需要在特别的将该数字前的符号对应成加号. 二是需要处理字符串中出现的空格. 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: int calculate(string s) &#123; stack&lt;int&gt; cal_s; for(int i=0; i&lt;s.size(); )&#123; while(i!=s.size() &amp;&amp; s[i] == ' ') i++; // 跳过空格 if(i==s.size()) break; // 达到字符串尾部, 直接跳出 char op; if(cal_s.empty()) op = '+'; else op = s[i++]; int num = 0; while(s[i] == ' ') i++; // 跳过空格 while( i!=s.size() &amp;&amp; s[i] &lt;= '9' &amp;&amp; s[i] &gt;= '0')&#123; num = num*10 + s[i++] - '0'; &#125; int pre_num=0; switch(op)&#123; case '+': cal_s.push(num); break; case '-': cal_s.push(-num); break; case '* ': pre_num = cal_s.top(); cal_s.pop(); cal_s.push(pre_num * num); break; case '/': pre_num = cal_s.top(); cal_s.pop(); cal_s.push(pre_num / num); break; default: return op; //error &#125; &#125; int res = 0; while(!cal_s.empty())&#123; res += cal_s.top(); cal_s.pop(); &#125; return res; &#125;&#125;; 解法二: 字符串流时间复杂度: $O(n)$, 遍历每个字符空间复杂度: $O(1)$, 无需额外空间 字符串流可以自动的格式化读取字符串信息, 简化了代码编写量 123456789101112131415161718192021222324class Solution &#123;public: int calculate(string s) &#123; std::istringstream in("+"+s+"+"); long long sum = 0, pre_num = 0, num; char op; while(in&gt;&gt;op) &#123; if (op == '+' or op == '-') &#123; sum += pre_num; in &gt;&gt; pre_num; int sign = (op == '+' ? 1 : -1); pre_num * = sign; &#125; else &#123; in &gt;&gt; num; if (op == '*') &#123; pre_num * = num; &#125; else if (op == '/') &#123; pre_num /= num; &#125; &#125; &#125; return static_cast&lt;int&gt;(sum); &#125;&#125;; 230. Kth Smallest Element in a BSTDescription: 找出二叉搜索树中的最小元素Given a binary search tree, write a function kthSmallest to find the kth smallest element in it. Note:You may assume k is always valid, 1 ≤ k ≤ BST’s total elements. Example 1:1234567Input: root = [3,1,4,null,2], k = 1 3 / \ 1 4 \ 2Output: 1 Example 2:123456789Input: root = [5,3,6,2,4,null,null,1], k = 3 5 / \ 3 6 / \ 2 4 / 1Output: 3 Follow up:What if the BST is modified (insert/delete operations) often and you need to find the kth smallest frequently? How would you optimize the kthSmallest routine? 解法一: 非递归中根遍历时间复杂度: $O(k)$, 遍历到第 $k$ 个元素为止空间复杂度: $O(k)$, 栈中最多存储 $k$ 个元素. 非递归中根遍历二叉搜索树, 当遍历到第k个元素时, 将其返回. 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; if(k&lt;1) return INT_MIN;// error stack&lt;TreeNode*&gt; s; TreeNode* cur = root; int count=0; while(cur!=nullptr || !s.empty())&#123; while(cur!=nullptr)&#123; s.push(cur); cur = cur-&gt;left; &#125; if(!s.empty())&#123; cur = s.top(); s.pop(); if(++count == k)&#123; return cur-&gt;val; &#125; cur = cur-&gt;right; &#125; &#125; return INT_MIN;// error &#125;&#125;; 解法二: 递归中根遍历时间复杂度: $O(k)$空间复杂度: $O(k)$ 12345678910111213141516171819class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; int count = 0; int res = 0; helper(root, count, k, res); return res; &#125; void helper(TreeNode * root, int &amp;count, int &amp;k, int &amp;res)&#123; if(count==k || root == nullptr) return; // 如果已经统计了k个, 则直接返回 helper(root-&gt;left, count, k, res); if(count==k) return; // 如果已经统计了k个, 则直接返回 // 加上该语句可省去后面的过程, 加速迭代结束, 当然不加也可以 else if(++count == k)&#123; // 访问当前节点 res = root-&gt;val; return; &#125; if(count!=k) helper(root-&gt;right, count, k, res); // 如果已经统计了k个, 则不再遍历右子树 &#125;&#125;; 更简洁的写法: 12345678910111213141516171819class Solution &#123; void helper(TreeNode* root, int&amp; count, int k, int&amp; res) &#123; if (root == nullptr) return; helper(root-&gt;left, count, k, res); count++; if(k == count) &#123; res = root-&gt;val; return; &#125; helper(root-&gt;right, count, k, res); &#125;public: int kthSmallest(TreeNode* root, int k) &#123; int count = 0; int res = 0; helper(root, count, k, res); return res; &#125;&#125;; 解法三: 二叉搜索时间复杂度: $O(logn)+ O(n)$, 搜索的复杂度为树的高度, 但是计算count的复杂度为 $O(n)$.空间复杂度: $O(logn)$, 递归占用的空间, 若采用非递归实现, 则空间复杂度为 $O(1)$. 二叉搜索, 统计当前节点之前的元素个数, 如果大于 $k$, 则继续在左子树中搜索第 $k$ 小的元素, 如果 count 小于 $k$ , 则在右子树中搜索第 $k-count-1$ 小的元素. 123456789101112131415161718class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; int count = countNode(root-&gt;left); // 左子树元素个数 if(count+1 &gt; k)&#123; return kthSmallest(root-&gt;left, k); &#125;else if(count+1 &lt; k)&#123; return kthSmallest(root-&gt;right, k - count - 1); &#125;else&#123; return root-&gt;val; &#125; &#125; int countNode(TreeNode* root)&#123; if(root==nullptr) return 0; return 1+countNode(root-&gt;left)+countNode(root-&gt;right); &#125;&#125;; 解答Follow up方法一: 根据解法三我们可以知道, 在计算子树节点个数的时候 int count = countNode(root-&gt;left);, 有很多的重复计算, 因此, 我们可以修改树的结构定义, 使得每个节点都持有其左子树中的节点个数, 那么在查找第 $k$ 小的元素的时候, 就可以用 $O(1)$ 的时间复杂度获取到左子树的节点个数, 因此, 最终查询第 $k$ 小的时间复杂度变为 $O(logn)$. 方法二: 在中根遍历的同时, 用一个大小为 $k$ 的大顶堆(priority_queue), 这些可以将二叉搜索树中最小的 $k$ 个数存储起来, 并且可以用 $O(1)$ 的时间复杂度获取到第 $k$ 小的元素. (二叉搜索树的中根遍历下, 未遍历到的都是较大的元素, 因此无需遍历整个树, 只需要遍历到第 $k$ 个元素即可). 在对树进行修改时, 同步更新大顶堆, 前者时间复杂度为 $O(logn)$, 后者为 $O(logk)$. 234. Palindrome Linked ListDescription: 回文链表判断Given a singly linked list, determine if it is a palindrome. Example 1:12Input: 1-&gt;2Output: false Example 2:12Input: 1-&gt;2-&gt;2-&gt;1Output: true Follow up:Could you do it in O(n) time and O(1) space? 解法一: 借助辅助数组时间复杂度: $O(n)$, 两次遍历空间复杂度: $O(n)$, 额外数组 最简单的做法就是遍历链表, 将其转换成一个可随机访问的数组, 然后进行回文串的判断. 解法二: 不借助辅助数组时间复杂度: $O(n)$空间复杂度: $O(1)$ 先利用两个指针变量slow和fast找到链表的中点(slow每次走一步, fast每次走两步), 然后将后半段逆置, 接着将前半段和后半段进行比较. 最后根据具体需要将链表后半段复原. (在实际工作中, 不存在 $O(1)$ 空间复杂度的解法, 因为通常情况下是不允许修改链表的值的). 不复原链表: 12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* node) &#123; ListNode* prev = nullptr; while(node != nullptr) &#123; auto tmp = node-&gt;next; node-&gt;next = prev; prev = node; node = tmp; &#125; return prev; &#125; bool isPalindrome(ListNode* head) &#123; ListNode* fast = head; ListNode* slow = head; while (fast != nullptr &amp;&amp; fast-&gt;next != nullptr) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; if (fast != nullptr) &#123; // 奇数个节点, 始终令slow指向后半段的开始节点 slow = slow-&gt;next; &#125; slow = reverseList(slow); // 令slow指向后半段逆置后的开始节点 fast = head; while(slow != nullptr &amp;&amp; fast-&gt;val == slow-&gt;val) &#123; fast = fast-&gt;next; slow = slow-&gt;next; &#125; return slow == nullptr ? true : false; &#125;&#125;; 复原链表: 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;public: bool isPalindrome(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return true; ListNode* slow = head; ListNode* fast = head-&gt;next; while(fast!=nullptr &amp;&amp; fast-&gt;next!=nullptr)&#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; ListNode * rail = slow; // 记录前半段的最后一个节点, 以便复原链表 slow = slow-&gt;next; // 令slow指向回文串后半段的第一个节点 ListNode *rhead = reverseList(slow); // 令fast 指向回文串后半段逆置后的连接头(奇数回文串时, 中间的节点算作前半段) slow = head; fast = rhead; bool res=true; while(slow!=nullptr &amp;&amp; fast!=nullptr)&#123; if(slow-&gt;val != fast-&gt;val)&#123; res = false; break; &#125; slow = slow-&gt;next; fast = fast-&gt;next; &#125; rail-&gt;next = reverseList(rhead); // 复原链表 return res; &#125; ListNode *reverseList(ListNode *cur)&#123; ListNode* next = cur-&gt;next; ListNode* pre = nullptr; while(cur != nullptr)&#123; cur-&gt;next = pre; pre = cur; cur = next; if(next!=nullptr) next = next-&gt;next; &#125; return pre; &#125;&#125;; 236. Lowest Common Ancestor of a Binary TreeDescription: 查找二叉树中任意两个节点的公共祖先Given a binary tree, find the lowest common ancestor (LCA) of two given nodes in the tree. According to the definition of LCA on Wikipedia: “The lowest common ancestor is defined between two nodes p and q as the lowest node in T that has both p and q as descendants (where we allow a node to be a descendant of itself).” Given the following binary tree: root = [3,5,1,6,2,0,8,null,null,7,4]1234567 _______3______ / \ __5__ __1__/ \ / \6 2 0 8 / \ 7 4 Example 1:123Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1Output: 3Explanation: The LCA of nodes 5 and 1 is 3. Example 2:123Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 4Output: 5Explanation: The LCA of nodes 5 and 4 is 5, since a node can be a descendant of itself according to the LCA definition. Note: All of the nodes values will be unique. p and q are different and both values will exist in the binary tree. 解法一: 递归时间复杂度: $O(n)$, 需遍历 $n$ 个节点.(任何情况下都需遍历n个节点)空间复杂度: $O(n)$, 需进行 $n$ 次递归调用.( $n$ 包含空节点) 对于最小公共祖先来说, 它相对于其他祖先有一个特点, 即节点 p 和 q 只可能是以下面三种情况分布在树中: p和q分别处于当前节点的左子树 和 右子树之中. p为当前节点, q处于当前节点的左子树 或 右子树之中 q为当前节点, p处于当前节点的左子树 或 右子树之中 而对于其他祖先来说, 绝对不可能出现上面三种情况, 因为 p和q一定处于其他祖先的同一侧子树之中., 即要么都处在右子树中, 要么都处在左子树中. 因此我们可以用p和q在当前节点构成的子树中的分布情况来判断是否为最小祖先. **注意, 题目中说了p, q一定存在, 并且树中节点都是唯一的, 因此, 下面的代码无需对p, q进行存在性检查. 123456789101112131415161718192021222324252627282930/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode * left; * TreeNode * right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: TreeNode* res = nullptr;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; res = nullptr; recurseHelper(root, p, q); return res; &#125; bool recurseHelper(TreeNode * root, TreeNode * p, TreeNode * q)&#123; if(root == nullptr) return false; // 遇到空节点, 说明没有目标节点 int left = recurseHelper(root-&gt;left, p, q) ? 1 : 0; // 左子树中有p或q int right = recurseHelper(root-&gt;right, p, q) ? 1 : 0; // 右子树中有p或q int mid = (root==p || root==q) ? 1 : 0; // 找到了p或q, 这里相当于做了存在性检查 if( left+right+mid &gt;= 2) res = root; // 如果左,右或当前节点中有两个以上为true, 则说明当前节点为最小公共祖先 return (left+right+mid)&gt;0; // 只要不是空节点, 就可以返回 true. &#125;&#125;; 上面用了是将res作为成员函数进行赋值, 更好的做法是用指针引用.123456789101112131415161718class Solution &#123;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; TreeNode* res = nullptr; lcaHelper(root, p, q, res); return res; &#125; bool lcaHelper(TreeNode* root, TreeNode* p, TreeNode* q, TreeNode*&amp; res) &#123; if (root == nullptr) return false; int left= lcaHelper(root-&gt;left, p, q, res) ? 1 : 0; int right = lcaHelper(root-&gt;right, p, q, res) ? 1 : 0; int mid = (root == p || root == q) ? 1 : 0; if (left+right+mid &gt;= 2) res = root; return (left+right+mid) &gt; 0; &#125;&#125;; 解法二: 迭代(存储父节点)时间复杂度: $O(n)$, 最坏需遍历 $n$ 个节点.空间复杂度: $O(n+n+n) = O(n)$, 栈, 哈希表, 集合的空间复杂度在最坏情况下均为 $O(n)$ 如果我们能够获取到父节点, 那么我们就可以反向遍历q和p来访问他们的祖先节点. 那么, 第一个公共的祖先节点就一定是 LCA node. 我们可以将节点的父节点指针保存在一个字典(hash)当中. 具体的算法流程如下所示: 从根节点开始遍历整个树(任意一种遍历算法都可以, 只要能找到p和q即可); 直到找到节点p和q之前, 将所有节点的父节点都保存在字典(hash)中; 一旦我们找到了q和q, 我们就将所有p的祖先节点放入了一个集合(set)当中; 然后, 我们反向遍历q的祖先节点, 当找到一个存在时集合中的祖先节点时, 该节点就是第一个公共的租店节点, 也就是 LCA node, 将其返回. 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; std::stack&lt;TreeNode*&gt; s; std::unordered_map&lt;TreeNode*, TreeNode*&gt; hash; std::set&lt;TreeNode*&gt; ancestors; if (root != nullptr) &#123; s.push(root); hash.insert(&#123;root, nullptr&#125;); &#125; else return nullptr; while(hash.find(p) == hash.end() || hash.find(q) == hash.end()) &#123; TreeNode* node = s.top(); s.pop(); if (node-&gt;left != nullptr) &#123; hash.insert(&#123;node-&gt;left, node&#125;); s.push(node-&gt;left); &#125; if (node-&gt;right != nullptr) &#123; hash.insert(&#123;node-&gt;right, node&#125;); s.push(node-&gt;right); &#125; &#125; TreeNode* parent = p; while (parent != nullptr) &#123; ancestors.insert(parent); parent = hash[parent]; &#125; TreeNode* lcaNode = q; while (ancestors.find(lcaNode) == ancestors.end()) &#123; lcaNode = hash[lcaNode]; &#125; return lcaNode; &#125;&#125;; 解法三: 迭代(不存储父节点)时间复杂度: $O(n)$, 最坏需遍历 $n$ 个节点.空间复杂度: $O(n)$, 采用后序遍历, 只需维护一个栈, 空间复杂度在最坏情况下为 $O(n)$ 在解法二中, 我们是通过反向遍历的方法来查找 LCA 的, 实际上我们可以省去这一步, 直接要一个指针时刻指向可能的 LCA, 当我们找到p和q两个节点时, 我们可以直接返回当前的 LCA. 具体算法步骤如下: 从根节点开始; 将(root, root_state)压入栈中, root_state定义了根节点的剩余的子节点是否可以被遍历; 当栈非空时, 查看栈顶元素(parent_node, parent_state); 在遍历parent_node的任何子节点之前, 首先确认parent_node是否是节点p或q; 当首次找到p或q时, 将标志变量one_node_found设置为True. 同时根据栈中的节点跟踪 LCA (栈中的所有元素都是当前节点的祖先); 当再次找到p或q时, 说明我们已经将两个节点都找到了, 此时返回 LCA node. 无论何时访问parent_node的子节点, 都需要将(parent_node, updated_parent_state)更新到栈中. A node finally gets popped off from the stack when the state becomes BOTH_DONE implying both left and right subtrees have been pushed onto the stack and processed. If one_node_found is True then we need to check if the top node being popped could be one of the ancestors of the found node. In that case we need to reduce LCA_index by one. Since one of the ancestors was popped off Whenever both p and q are found, LCA_index would be pointing to an index in the stack which would contain all the common ancestors between p and q. And the LCA_index element has the lowest ancestor common between p and q. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123; enum class State &#123; BOTH_PENDING = 2, // 代表左右子节点均未访问 LEFT_DONE = 1, // 代表已经访问了一个节点 BOTH_DONE = 0 // 代表两个子节点都已经访问, 当前节点可以出栈 &#125;;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; std::stack&lt;std::pair&lt;TreeNode*, State&gt; &gt; s; s.push(std::make_pair(root, State::BOTH_PENDING)); bool one_node_found = false; // 标记是否找到p或q TreeNode* LCA = nullptr; // 跟踪LCA TreeNode* child_node = nullptr; while (!s.empty()) &#123; auto top = s.top(); TreeNode* parent_node = top.first; State parent_state = top.second; if (parent_state != State::BOTH_DONE) &#123; if (parent_state == State::BOTH_PENDING) &#123; if (parent_node == p || parent_node == q) &#123; // 找到了 p 或 q 中的一个, 如果是第二次找到, 则可以返回LCA // 如果是第一次找到, 则更新 LCA. if (one_node_found) &#123; return LCA; &#125; else &#123; one_node_found = true; LCA = parent_node; &#125; &#125; // 当状态为 BOTH_PENDING, 说明左右子树都没遍历, 应先遍历左子树 child_node = parent_node-&gt;left; &#125; else &#123; // 如果状态为 LEFT_DONE, 说明已经遍历完左子树, 该遍历右子树 child_node = parent_node-&gt;right; &#125; s.pop(); parent_state = static_cast&lt;State&gt;(static_cast&lt;int&gt;(parent_state) - 1); s.push(std::make_pair(parent_node, parent_state)); if (child_node != nullptr) &#123; s.push(std::make_pair(child_node, State::BOTH_PENDING)); &#125; &#125; else &#123; // state 为 BOTH_DONE, 说明当前节点可以出栈 // 如果当前节点为LCA, 则需要更新LCA auto node = s.top().first; s.pop(); if (LCA == node &amp;&amp; one_node_found) &#123; LCA = s.top().first; &#125; &#125; &#125; return nullptr; &#125;&#125;; 237. Delete Node in a Linked ListDescription: 删除链表中的某个节点Write a function to delete a node (except the tail) in a singly linked list, given only access to that node. Given linked list — head = [4,5,1,9], which looks like following:14 -&gt; 5 -&gt; 1 -&gt; 9 Example 1:123Input: head = [4,5,1,9], node = 5Output: [4,1,9]Explanation: You are given the second node with value 5, the linked list should become 4 -&gt; 1 -&gt; 9 after calling your function. Example 2:123Input: head = [4,5,1,9], node = 1Output: [4,5,9]Explanation: You are given the third node with value 1, the linked list should become 4 -&gt; 5 -&gt; 9 after calling your function. Note:The linked list will have at least two elements.All of the nodes’ values will be unique.The given node will not be the tail and it will always be a valid node of the linked list.Do not return anything from your function. 解法一: 复制+跳过节点时间复杂度: $O(1)$空间复杂度: $O(1)$ 这是一道非常取巧(也可以说是投机)的题, 题目给的参数是需要删除的节点指针, 同时该指针不会是最后一个节点, 因此我们可以利用先复制, 再跳过的方式实现删除. 123456789101112131415c/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: void deleteNode(ListNode* node) &#123; node-&gt;val = node-&gt;next-&gt;val; // 题目假设node 不是最后一个节点 node-&gt;next = node-&gt;next-&gt;next; // 跳过node节点 &#125;&#125;; 238. Product of Array Except SelfDescription: 计算数组内其他元素之积(不能使用除法)Given an array nums of n integers where n &gt; 1, return an array output such that output[i] is equal to the product of all the elements of nums except nums[i]. Example:12Input: [1,2,3,4]Output: [24,12,8,6] Note: Please solve it without division and in O(n). Follow up:Could you solve it with constant space complexity? (The output array does not count as extra space for the purpose of space complexity analysis.) 解法一: 借助辅助数组时间复杂度: $O(n)$, 遍历两次数组空间复杂度: $O(n)$, 额外申请 $n$ size 的数组(不计算 res 的空间占用) 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; productExceptSelf(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; from_begin(n); vector&lt;int&gt; from_end(n); from_begin[0] = 1; from_end[n-1] = 1; for(int i = 1; i&lt;n; i++)&#123; from_begin[i] = from_begin[i-1] * nums[i-1]; // from_begin[i] 为 nums[i] 之前的所有元素的乘积 from_end[ n-i-1] = from_end[n-i] * nums[n-i]; // from_end[i] 为 nums[i] 之后所有元素的乘积 &#125; for(int i=0 ;i&lt;n ; i++)&#123; from_end[i] = from_begin[i] * from_end[i]; // 用 nums[i] 之前的所有元素的乘积和 nums[i] 之后所有元素的乘积相乘 &#125; return from_end; &#125;&#125;; 解法二: 用一个变量代替数组时间复杂度: $O(n)$, 两次遍历空间复杂度: $O(1)$, 用变量代替数组 对解法一进行改写, 具体的做法是用一个变量来维护 from_begin 数组中的值(当然也可以选择代替 from_end) 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; productExceptSelf(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); // vector&lt;int&gt; from_begin(n); vector&lt;int&gt; from_end(n); // from_begin[0] = 1; from_end[n-1] = 1; for(int i = 1; i&lt;n; i++)&#123; // from_begin[i] = from_begin[i-1] * nums[i-1]; // from_begin[i] 为 nums[i] 之前的所有元素的乘积 from_end[ n-i-1] = from_end[n-i] * nums[n-i]; // from_end[i] 为 nums[i] 之后所有元素的乘积 &#125; int from_begin = 1; // 用一个变量代替 from_begin 数组的作用 for(int i=0 ;i&lt;n ; i++)&#123; from_end[i] = from_begin * from_end[i]; // 用 nums[i] 之前的所有元素的乘积和 nums[i] 之后所有元素的乘积相乘, 作为结果 from_begin = from_begin * nums[i]; // 维护 from_begin的值 &#125; return from_end; &#125;&#125;; 解法三: 用两个变量代替数组时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$, 不计算结果数组的空间 观察到解法二的做法, 虽然将空间复杂度压缩到 $O(1)$, 但是仍然使用了两次for循环, 实际上, 我们可以同时用变量from_begin和变量from_end替换掉对应的数组, 并且同一个for循环中更新这两个变量, 如下所示.12345678910111213141516class Solution &#123;public: vector&lt;int&gt; productExceptSelf(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int from_begin = 1; int from_end = 1; vector&lt;int&gt; res(n,1); for(int i=0; i&lt;n; i++)&#123; // 同时从前后分别计算, from_begin记录i之前的元素之和, from_end记录i之后的元素之和 res[i] = from_begin * res[i]; from_begin = from_begin * nums[i]; res[n-i-1] = from_end * res[n-i-1]; from_end = from_end * nums[n-i-1]; &#125; return res; &#125;&#125;; 239. Sliding Window MaximumDescription: 滑动窗口的最大值Given an array nums, there is a sliding window of size k which is moving from the very left of the array to the very right. You can only see the k numbers in the window. Each time the sliding window moves right by one position. Return the max sliding window. Example:123456789101112Input: nums = [1,3,-1,-3,5,3,6,7], and k = 3Output: [3,3,5,5,6,7]Explanation:Window position Max--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 Note:You may assume k is always valid, 1 ≤ k ≤ input array’s size for non-empty array. Follow up:Could you solve it in linear time? 解法一: 双端队列时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(k)$, 双端队列的 size 为 $k$. 使用双端队列deque, 从下标0开始, 一直到n-1, 每次进行如下步骤: 当前元素是否比队列中最后一个元素大, 如果大, 说明队列元素以后也不可能再成为较大值, 直接pop, 如此循环, 直到队列为空或者遇到比当前值大的元素 判断队列中队首的元素是否过期(若队空则直接下一步, 无需判断), 若过期, 则pop, 否则, 不管( 只看队首, 队内的元素是否过期不影响算法, 因为就算过期后面也会将其淘汰) 将当前元素的下标存到队尾 将新的队首元素存到结果向量max_res中 注意: 队列里面存的是下标, 而不是元素本身的值, 后面在提到队列的元素值时, 均是指队列中存储的下标对应的元素值. 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; if(nums.size()==0 || k ==0) return vector&lt;int&gt;&#123;&#125;; int n = nums.size(); deque&lt;int&gt; dq; vector&lt;int&gt; res; for(int i=0; i&lt;n; i++)&#123; if(dq.empty()) dq.push_back(i); else&#123; if(dq.front() &lt; i-k+1) dq.pop_front(); //过期元素, 出队列 while(!dq.empty() &amp;&amp; nums[dq.back()] &lt;= nums[i]) dq.pop_back(); // 将队列中小于当前元素的都出队列(因为它们不可能成为max) dq.push_back(i); // 将当前元素入队列. &#125; if(i &gt;= k-1) res.push_back(nums[dq.front()]); &#125; return res; &#125;&#125;; 240. Search a 2D Matrix IIDescription: 矩阵搜索Write an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties: Integers in each row are sorted in ascending from left to right.Integers in each column are sorted in ascending from top to bottom. Example:123456789Consider the following matrix:[ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30]] Given target = 5, return true. Given target = 20, return false. 解法一: 从左下角开始时间复杂度: $O(n+m)$, 最多走 $n+m$ 步, $n$ 和 $m$ 分别为矩阵的宽和高空间复杂度: $O(1)$ 123456789101112131415class Solution &#123;public: bool searchMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int target) &#123; if(matrix.size()==0 || matrix[0].size()==0) return false; int i=matrix.size()-1; int j=0; // 从左下角开始搜索 while(i&gt;=0 &amp;&amp; j&lt;matrix[0].size())&#123; if(matrix[i][j] &lt; target) j++; else if(matrix[i][j] &gt; target) i--; else return true; &#125; return false; &#125;&#125;; 242. Valid Anagram变位词: 改变某个词或短语的字母顺序后构成的新词或短语 Description: 判断变位词Given two strings s and t , write a function to determine if t is an anagram of s. Example 1:12Input: s = &quot;anagram&quot;, t = &quot;nagaram&quot;Output: true Example 2:12Input: s = &quot;rat&quot;, t = &quot;car&quot;Output: false Note:You may assume the string contains only lowercase alphabets. Follow up:What if the inputs contain unicode characters? How would you adapt your solution to such case? 解法一: 排序时间复杂度: $O(nlogn)$, 对两个字符串进行排序空间复杂度: $O(1)$, 可以原地排序, 不占用额外空间 对两个字符串排序后, 看是否相等. 该方式可以无缝的解决 Follow up 中的问题. 解法二: 哈希表时间复杂度: $O(n1+n2)$, $n1$, $n2$ 分别为两个字符串的长度, 二者必须相等, 否则一定不是变位词.空间复杂度: $O(1)$, 哈希表的 size 为 26, 常数级 构造一个字母哈希表, 先统计 12345678910111213141516171819202122class Solution &#123;public: bool isAnagram(string s, string t) &#123; if(s.size() != t.size()) return false; int ana_hash[26]=&#123;0&#125;; for(auto c : s)&#123; ana_hash[c-'a']++; &#125; for(auto c : t)&#123; ana_hash[c-'a']--; if (ana_hash[c-'a'] &lt; 0) return false; &#125; /* 因为长度相等, 所以一旦不是异构词, 就一定会出现某个哈希位上的值小于0的情况, 因此无需在这里再次判断 for(auto i : ana_hash)&#123; if(i != 0) return false; &#125; */ return true; &#125;&#125;; 解答 Follow up:用 unordered_map 来代替数组哈希表, 此时复杂度与输入的字符种类数目有关, 哈希表的空间复杂度变成 $O(n)$. 268. Missing NumberDescription: 缺失的数字Given an array containing n distinct numbers taken from 0, 1, 2, …, n, find the one that is missing from the array. Example 1: Input: [3,0,1]Output: 2Example 2: Input: [9,6,4,2,3,5,7,0,1]Output: 8Note:Your algorithm should run in linear runtime complexity. Could you implement it using only constant extra space complexity? 解法一: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 或 $O(n)$ 解法二: 哈希表时间复杂度: $O(n)$, 两次遍历, 第一次构建哈希, 第二次查询缺失数字空间复杂度: $O(n)$, 哈希表所占空间 另一种解法: 用下表做哈希, 将数字放置在与下标相同的位置上, 最终放错位置的元素的下标就是缺失的数字, 如果位置都正确, 则缺失 n. 复杂度与哈希表相同, 代码实现如下: 12345678910111213141516171819class Solution &#123;public: int missingNumber(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); for (int i = 0; i &lt; n; ) &#123; if (i != nums[i] &amp;&amp; nums[i] &lt; n) &#123; std::swap(nums[i], nums[nums[i]]); &#125; else &#123; i++; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if (i != nums[i]) &#123; return i; &#125; &#125; return n; &#125;&#125;; 解法三: 异或时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$, 无需额外空间 因为题目是从 0, 1, 2, ..., n 共 $n+1$ 个数字中选出了 $n$ 个不相同的数字, 因此, 如果将 $n+1$ 大小的数组和 $n$ 大小的数组合并成一个大数组, 那么在大数组中, 除了那个缺失的数字以外, 所有的数字都恰好出现了两次, 因此题目变成了求数组中出现一次的唯一数字, 此时可以利用异或在 $O(n)$ 时间复杂度内解决. 该解法还可以解决丢失两个数字, 丢失三个数字的情况, 具体可参考用异或解决奇数偶数数字的问题. 1234567891011class Solution &#123;public: int missingNumber(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int res = n; for(int i=0; i&lt;n; i++)&#123; res = res ^ i ^ nums[i]; &#125; return res; &#125;&#125;; 解法四: 高斯求和公式时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$, 无需任何额外空间 前 $n$ 项和的求和公式为: $1+2+3+\cdots+n = \frac{(n+1)n}{2}$因此, 我们只需要计算出当前数组的和, 然后在计算当前和与高斯和之间的差即可. 1234567891011class Solution &#123;public: int missingNumber(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int gauss_sum = n*(n+1)/2; int sum = 0; for(auto num : nums) sum += num; return gauss_sum - sum; &#125;&#125;; 279. Perfect SquaresDescription: 找到最少的平方和个数Given a positive integer n, find the least number of perfect square numbers (for example, 1, 4, 9, 16, …) which sum to n. Example 1:123Input: n = 12Output: 3Explanation: 12 = 4 + 4 + 4. Example 2:123Input: n = 13Output: 2Explanation: 13 = 4 + 9. 解法一: 四平方和定理(最优)时间复杂度: $O(\sqrt n)$, 最坏情况为 $O(\sqrt n)$, 最好情况为 $O(1)$.空间复杂度: $O(1)$, 无需额外空间 四平方和定理: 任何一个正整数, 都可以表示成四个整数的平方和(如果不算 0 的话, 就是可以用小于等于 4 个整数的平方和来表示任意一个整数). 对于题目, 要求我们返回组合平方和的数字的 最少 个数(不算0), 因此, 这里还可以使用到两个特别的性质来加速计算: 如果 $n$ 可以被 4 整除, 那么 $n$ 和 $n/4$ 的最少平方和数字个数相同. 如果 $n \% 8=7$, 那么 $n$ 的最少平方和个数一定为 4. 因此, 本题的解法流程如下: 循环整除 4, 降低 $n$ 的大小; 判断是否有 $n \% 8 =7$, 如果有, 则直接返回 4; 查看 $n$ 是否能够拆分成两个数(其中一个可以为0), 如果可以, 则返回 !!i + !!j, 即返回正整数的个数. 此处需要注意, i 需要从 0 开始遍历, 因为对于 $3^2+4^2 = 0^2 + 5^2 = 25$ 来说, 我们希望返回的是后者(即返回最少的平方和个数); 如果上面都不行, 则只可能反正 3(因为 $n&gt;0$). 1234567891011121314class Solution &#123;public: int numSquares(int n) &#123; while(n%4 == 0) n = n/4; if(n%8 == 7) return 4; for(int i=0; i*i&lt;=n; i++)&#123; // i必须从0开始, 否则会找到其他组合, eg: 3^2 + 4^2 = 0^2 + 5^2 int j = sqrt(n - i * i); if(i*i + j*j == n) return !!i+!!j; // 返回1(只有一个正整数)或2(两个都是正整数) &#125; return 3; //既不是4, 也不是1,2, 返回3(因为n&gt;0, 所以不可能返回0) &#125;&#125;; 解法二: DP时间复杂度: $O(n\sqrt n)$, 外层循环约为 $n$ 次, 内层循环约为 $\sqrt n$ 次.空间复杂度: $O(n)$, 需要额外申请 $n+1$ 大小的 DP 数组. 对于解法一来说, 虽然它的时间和空间复杂度最优, 但是其中使用到了很多不常用的定理和性质, 如果不知道这些定理和性质, 很难想到解法一的实现. 因此, 我们更容易想到的是使用动态规划来解决这道题, 具体解题步骤如下: 申请 $n+1$ 大小的 DP 数组, 并令 dp[0]=0, 令其他元素为 INT_MAX, dp[i] 的值代表组成数字 $i$ 所需的最少的平方和数字个数; 由于我们已经求得 dp[0] 的值, 因此, 对于 j=1, 2, ... 来说, 我们可以顺势求得 dp[0+j*j] = dp[0]+1=1. 对于已经求得的 dp[i], 我们可以求得 dp[i+j*j] = min(dp[i+j*j], dp[i]+1), 这里的 min 是为了保证组成数字的平方和个数最少. 最终, 返回 dp.back() 即为组成 $n$ 的最少的平方和个数. 12345678910111213class Solution &#123;public: int numSquares(int n) &#123; vector&lt;int&gt; dp(n+1, INT_MAX); dp[0]=0; // 赋初值 for(int i=0; i&lt;n+1; i++)&#123; for(int j=1; i+j*j &lt; n+1; j++)&#123; dp[i+j*j] = std::min(dp[i+j*j], dp[i]+1); &#125; &#125; return dp.back(); &#125;&#125;; 解法三: DP时间复杂度: $O(n\sqrt n)$, 外层循环约为 $n$ 次, 内层循环约为 $\sqrt n$ 次.空间复杂度: $O(n)$, 需要额外申请 $n+1$ 大小的 DP 数组. 复杂度和解法二没有区别, 但是我们可以从另一个角度来实现 DP 算法, 具体流程如下: 申请只含有一个元素的 DP 数组 dp[0]=0; 根据 dp[0] 的值计算 dp[1].(计算方法和解法二类似, 具体请看代码) 根据 dp[0]~dp[i-1] 的值计算 dp[i]. 当 i==n 时, 返回 dp[i]. 123456789101112131415class Solution &#123;public: int numSquares(int n) &#123; vector&lt;int&gt; dp(1,0); while(dp.size()&lt;=n)&#123; int m = dp.size(); int val = INT_MAX; for(int j=1; j*j &lt;= m; j++)&#123; //这里必须 &lt;= m, 否则会缺少 dp[0]+1 的情况. val = std::min(val, dp[m - j*j] + 1); &#125; dp.push_back(val); &#125; return dp.back(); &#125;&#125;; 解法四: 递归http://www.cnblogs.com/grandyang/p/4800552.html 12345678910111213// Recrusionclass Solution &#123;public: int numSquares(int n) &#123; int res = n, num = 2; while (num * num &lt;= n) &#123; int a = n / (num * num), b = n % (num * num); res = min(res, a + numSquares(b)); ++num; &#125; return res; &#125;&#125;; 283. Move ZeroesDescription: 将 0 移动到最后, 保持其他元素相对位置不变Given an array nums, write a function to move all 0’s to the end of it while maintaining the relative order of the non-zero elements. Example: Input: [0,1,0,3,12]Output: [1,3,12,0,0]Note: You must do this in-place without making a copy of the array.Minimize the total number of operations. 解法一: 交换法时间复杂度: $O(n)$空间复杂度: $O(1)$, 无需额外空间 利用交换将不符合要求的元素交换, 具体做法如下: 令 i 指向第一个 0 元素; 令 j 指向 i 之后的第一个非 0 元素; (注意 j 必须在 i 的后面才能执行交换) 交换 i 和 j 指向的元素, 更新 i 和 j 的值. 重复以上步骤, 直到 j 越界. 1234567891011121314151617class Solution &#123;public: void moveZeroes(vector&lt;int&gt;&amp; nums) &#123; int i = 0, j = 0; while(nums[i]!=0) i++; j = i; while(nums[j]==0) j++; while(j &lt; nums.size())&#123; std::swap(nums[i], nums[j]); while(nums[i]!=0) i++; j = i; while(nums[j]==0) j++; &#125; return; &#125;&#125;; 解法二: 更简洁的交换法时间复杂度: $O(n)$空间复杂度: $O(1)$ 这道题可以从另一个角度来理解, 即可以看做是要将所有的非 0 元素保持相对位置不变地移动到数组的前面, 那么我们可以遍历数组, 并用一个变量 i 来记录当前元素之前的非 0 元素的个数, 那么如果当前元素为非 0 元素, 则可以令当前元素与 nums[i] 交换, 同时 i++, 这样便可以同时保证将非 0 元素移动到数组前以及保持相对位置不变两个条件.123456789101112class Solution &#123;public: void moveZeroes(vector&lt;int&gt;&amp; nums) &#123; for(int i=0, j=0; j&lt;nums.size(); j++)&#123; if(nums[j] != 0)&#123; std::swap(nums[i], nums[j]); i++; // 非0元素个数加1 &#125; &#125; return; &#125;&#125;; 287. Find the Duplicate NumberDescription: 寻找重复元素Given an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), prove that at least one duplicate number must exist. Assume that there is only one duplicate number, find the duplicate one. Example 1:12Input: [1,3,4,2,2]Output: 2 Example 2:12Input: [3,1,3,4,2]Output: 3 Note: You must not modify the array (assume the array is read only). You must use only constant, O(1) extra space. Your runtime complexity should be less than O(n2). There is only one duplicate number in the array, but it could be repeated more than once. 解法一: 哈希表时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 哈希表额外空间 这道题用哈希表很容易解, 但是这是最简单的解法之一(更简单的还有暴力法), 因此这里贴出来只用做参考. 1234567891011class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; unordered_set&lt;int&gt; nums_set; for(auto num : nums)&#123; if(nums_set.find(num) != nums_set.end()) return num; nums_set.insert(num); &#125; &#125;&#125;; 另一种解法是不建立哈希表, 而是利用数组的元素值和元素下标建立对应关系, 即将所有的数字放置在数字对应的下标位置上, 这样, 最终重复的元素就会出现的下标为 0 的位置上, 当然, 期间如果已经发现重复, 则可以直接返回, 代码如下: 123456789101112131415class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size() - 1; for (int i = 1; i &lt; n + 1; i++) &#123; if (nums[0] != nums[nums[0]]) &#123; std::swap(nums[0], nums[nums[0]]); &#125; else &#123; return nums[0]; &#125; &#125; return nums[0]; &#125;&#125;; 解法二: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 或者 $O(n)$ 先对数组排序, 然后遍历查找重复元素, 但是这种解法会改变原有数组中的元素分布, 题目要是数组是只读的, 因此该解法也只作为参考贴出 123456789class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); for(int i=0; i&lt;nums.size(); i++)&#123; if(nums[i] == nums[i+1]) return nums[i]; // 一定存在重复元素, 因此 i+1 不会越界 &#125; &#125;&#125;; 解法三: Floyd 的乌龟和兔子(Floy 判圈算法)Floyd’s Tortoise and Hare, 该算法是用来判断链表中是否含有环的. 对于此题, 我们换一个角度来解读, 数组中总共有 $n+1$ 个数, 这些数都是 $[1,n]$ 中的正整数, 因此, 至少会存在一个重复的数, 根据题目的假设, 有且仅有一个重复的数字, 那么, 我们假设该数字为 $k$, 于是, 我们可以将该数组表示成下面的形式(表中的 $x$ 代表该元素的值不为 $k$ ): 下标 $0$ $1$ $2$ … $k$ … $n$ 元素 $x$ $k$ … $k$ $x$ … $x$ 如果我们将上面的 (下标, 元素) 看做是链表结构中的 (val, next), 那么可以看出, 当某一个节点(上面假设为节点 1)的 next 指向 k 以后, k 又会重新指向另一个元素, 但是, 经过一定步数以后, 一定 又会重新指向 k (因为元素存在重复), 这在链表中称之为 “环”, 因此, 这道题就变成了求链表中环的开始节点, 该题正好是剑指offer第55题和 LeetCode第142题 这道题有一个很关键的条件就是, 元素的值是在1~n之间, 因此, 下标 0 位置上的元素值一定不为 0, 只有这样, 我们才可以将下标 0 选做起点, 如果选取其他的下标坐标起点, 那么有可能在第一步就死循环了. 12345678910111213141516171819202122232425262728class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; int slow = 0; // int fast = 0; // 实际上 fast 和 slow 可以指向环前的任意节点, 不影响最终结果. do&#123; // 因为一定存在环, 所以fast不会越界 slow = nums[slow]; fast = nums[fast]; fast = nums[fast]; &#125;while(slow!=fast); int len=1; // 求环长度 fast = nums[fast]; while(slow!=fast)&#123; fast = nums[fast]; len ++; &#125; slow = 0; fast = 0; while(len--)&#123; fast = nums[fast]; // 先让fast走环长的距离 &#125; while(slow!=fast)&#123; // 再次相遇时即为环的开始节点 slow = nums[slow]; fast = nums[fast]; &#125; return slow; &#125;&#125;; 更简洁的写法:上面在求环的开始节点时, 是先求环长, 再让 fast 走环长距离, 然后 slow 和 fast 同步前进, 最终相遇点即为开始点, 这么写比较容易理解, 但难免有些繁琐. 实际上, 我们只需要令 slow 从头开始, 即 slow=0, 接着令 fast 和 slow 同步前进, 那么相遇点就是开始节点. 原因是因为, 二者是从同一点出发的, fast 的步长较快, 当二者相遇时, 他们一定是在环中的某一点相遇, 这个时候再把slow重新放回起点, 那么fast领先slow的距离就等于: 环外的距离 + 若干圈 + 当前圈内已经走的距离. 而此时 fast 距离环入口还有一段距离, 因为第一次相遇点的位置, 因此, 我们如果此时从起点出发, 最终正好可以弥补这一部分距离, 因此, 最终会在环入口相遇. 一句话总结: 令fast和slow一起开始, fast步长是slow步长的二者, 找到二者相遇的点, 然后令slow重新回到起点, 此时步长一致, 再次相遇时即为环的入口点 12345678910111213141516171819class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; int slow = 0; // head; int fast = 0; // head-&gt;next; 指向head也没错, 因为, 最终仍会slow=fast do&#123; // 因为一定存在环, 所以fast不会越界 slow = nums[slow]; fast = nums[fast]; fast = nums[fast]; &#125;while(slow!=fast); slow = 0; while(slow != fast)&#123; slow = nums[slow]; fast = nums[fast]; &#125; return slow; &#125;&#125;; 289. Game of LifeDescription: 游戏人生According to the Wikipedia’s article: “The Game of Life, also known simply as Life, is a cellular automaton devised by the British mathematician John Horton Conway in 1970.” Given a board with m by n cells, each cell has an initial state live (1) or dead (0). Each cell interacts with its eight neighbors (horizontal, vertical, diagonal) using the following four rules (taken from the above Wikipedia article): Any live cell with fewer than two live neighbors dies, as if caused by under-population. Any live cell with two or three live neighbors lives on to the next generation. Any live cell with more than three live neighbors dies, as if by over-population.. Any dead cell with exactly three live neighbors becomes a live cell, as if by reproduction. Write a function to compute the next state (after one update) of the board given its current state. The next state is created by applying the above rules simultaneously to every cell in the current state, where births and deaths occur simultaneously. Example:1234567891011121314Input:[ [0,1,0], [0,0,1], [1,1,1], [0,0,0]]Output:[ [0,0,0], [1,0,1], [0,1,1], [0,1,0]] Follow up: Could you solve it in-place? Remember that the board needs to be updated at the same time: You cannot update some cells first and then use their updated values to update other cells. In this question, we represent the board using a 2D array. In principle, the board is infinite, which would cause problems when the active area encroaches the border of the array. How would you address these problems? 解法一: 状态机时间复杂度: $O(mn)$, 遍历两次二维数组空间复杂度: $O(1)$, 无需额外空间 根据细胞的更新规则, 我们可以设计出下面的状态转移:0: 从 0 到 0;1: 从 1 到 1:2: 从 1 到 0;3: 从 0 到 1; 因此, 本解法需要遍历两边 board 矩阵, 第一遍先计算每个 cell 的状态, 第二遍根据状态赋予 cell 不同的值, 具体来说就是如果当前状态 board[i][j]%2==0, 那么就令 board[i][j]=0, 反之, 令 board[i][j]=1. 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: void gameOfLife(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123; if(board.size()==0 || board[0].size()==0) return; int n = board.size(); int m = board[0].size(); int direct[8][2]=&#123;&#123;-1,-1&#125;, &#123;-1, 0&#125;, &#123;-1, 1&#125;, &#123; 0,-1&#125;, &#123; 0, 1&#125;, &#123; 1,-1&#125;, &#123; 1, 0&#125;, &#123; 1, 1&#125;&#125;; for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; int count_1 = 0; for(int k=0; k&lt;8; k++)&#123; int i_k = i+direct[k][0]; int j_k = j+direct[k][1]; if(i_k&gt;=0 &amp;&amp; i_k&lt;n &amp;&amp; j_k&gt;=0 &amp;&amp; j_k&lt;m &amp;&amp; (board[i_k][j_k]==1 || board[i_k][j_k]==2) ) count_1++; &#125; if( (count_1&lt;2 || count_1&gt;3) &amp;&amp; board[i][j]==1) board[i][j] = 2; // 2:1-&gt;0, 0:0-&gt;0 else if(count_1==3 &amp;&amp; board[i][j]==0) board[i][j] = 3; // 3:0-&gt;1 // 剩余情况维持不变 &#125; &#125; for(auto &amp;cells : board)&#123; // 如果要对board进行修改, 需要使用引用号 &amp; for(auto &amp;cell : cells) if(cell%2==1) cell=1; else cell=0; &#125; &#125;&#125;; Follow up 常数空间复杂度: 正如解法一 无边界限制: 修改边界空间条件, 使其变成 “循环” 二维矩阵. 295. Find Median from Data StreamDescription: 返回数据流的中位数Median is the middle value in an ordered integer list. If the size of the list is even, there is no middle value. So the median is the mean of the two middle value. For example,[2,3,4], the median is 3[2,3], the median is (2 + 3) / 2 = 2.5 Design a data structure that supports the following two operations: void addNum(int num) - Add a integer number from the data stream to the data structure. double findMedian() - Return the median of all elements so far. Example:12345addNum(1)addNum(2)findMedian() -&gt; 1.5addNum(3)findMedian() -&gt; 2 Follow up: If all integer numbers from the stream are between 0 and 100, how would you optimize it? If 99% of all integer numbers from the stream are between 0 and 100, how would you optimize it? 解法一: 传统排序时间复杂度: $O(nlogn)$, 添加数字时不排序, 返回中位数时排序空间复杂度: $O(n)$, 排序需要额外空间 添加数字时, 直接添加, 时间复杂度为 $O(1)$, 每次需要输出中位数时, 都对数组内当前所有元素排序, 时间复杂度为 $O(nlogn)$, 该方法超时. 解法二: 插入排序时间复杂度: $O(n)$, 二分搜索位置需要 $O(logn)$, 插入需要 $O(n)$.空间复杂度: $O(n)$ 每次新来一个数字时, 都执行插入排序, 先利用二分搜索(因为当前数组已经有序)找到应该插入的位置, 时间复杂度为 $O(logn)$, 然后将数字插入到该位置, 插入的时间复杂度是 $O(n)$, 由于已经排序好, 因此返回中位数的时间复杂度是 $O(1). 该解法 同样超时. 解法三: 大顶堆+小顶堆时间复杂度: $O(5\times logn) = O(logn)$空间复杂度: $O(n)$, 大顶堆和小顶堆的大小之和为 $n$. 元素首先加入大顶堆($O(logn)$), 得到前面数字的最大值, 然后将该最大值弹出($O(logn)$)并加入到小顶堆当中($O(logn)$), 以维护当前小顶堆的元素合法(例如, 新的大顶堆堆顶的元素大于当前小顶堆堆顶元素, 这就不合法了), 然后, 看看当前大顶堆和小顶堆的元素个数是否符合要求, 如果不符合的话, 就小顶堆的堆顶弹出($O(logn)$)并加入大顶堆($O(logn)$). 由此可知, 添加元素的时间复杂度为: $O(5\times logn)$. 返回中位数时可以直接获取堆顶, 而无需更改堆结构, 故而为 $O(1)$. 所以, 最终的时间复杂度就为 $O(5\times logn) = O(logn)$ 1234567891011121314151617181920212223242526272829303132class MedianFinder &#123;private: priority_queue&lt;int&gt; max_heap; // 大顶堆, 维护前 (n+1)/2 个元素 priority_queue&lt;int, vector&lt;int&gt;, std::greater&lt;int&gt;&gt; min_heap; //小顶堆, 维护后n/2个元素public: /** initialize your data structure here. */ MedianFinder() &#123; &#125; void addNum(int num) &#123; max_heap.push(num); // 先将当前元素添加到大顶堆中, 找到前半段最大元素 min_heap.push(max_heap.top()); max_heap.pop(); // 调节最小堆, 这一步是必须的, 是为了同时确保大顶堆和小顶堆的元素正确 // 数字会随着元素size的变化而不断在大顶堆和小顶堆之间切换 if(max_heap.size() &lt; min_heap.size())&#123; //调节后, 平衡大顶堆和小顶堆的size max_heap.push(min_heap.top()); min_heap.pop(); &#125; &#125; double findMedian() &#123; return (max_heap.size() + min_heap.size())%2==1 ? double(max_heap.top()) : (max_heap.top() + min_heap.top())*0.5; &#125;&#125;;/** * Your MedianFinder object will be instantiated and called as such: * MedianFinder obj = new MedianFinder(); * obj.addNum(num); * double param_2 = obj.findMedian(); */ 解法四: multiset+指示器时间复杂度: $O(logn+1) = O(logn)$空间复杂度: $O(n)$, multiset 容器需要 $n$ 大小的空间. 用两个迭代指示器分别指向当前数组内的中位数(元素数目为奇数时, 二者指向同一点), 那么当新来一个元素时, 这个元素只可能有三种插入情况: 插在两指示器的前面 插在两指示器的后面 插在两指示器的中间(只在未插入前元素数目为偶数时才可以) 由于迭代指示器是随着元素移动而移动的(这点和下标就有区别了), 因此, 我们可以通过对指示器操作来使其指向新的中位数, 对应三种情况分别为: 前面元素变多, 说明指示器应该后挪(最多一位) 后面元素变多, 说明指示器应该前挪(最多一位) 插在中间, 说明当前插入的元素正是中位数, 令指示器指向即可. 当然, 上面只是核心思想, 具体的挪动算法还要分元素数目的奇偶性来分情况讨论, 代码如下所示: 1234567891011121314151617181920212223242526272829303132333435363738class MedianFinder &#123;private: std::multiset&lt;int&gt; data; std::multiset&lt;int&gt;::iterator low_mid, high_mid; // 迭代指示器会随着容器的变动而变动, 这个性质是该解法可行的重要因素之一public: /** initialize your data structure here. */ MedianFinder():low_mid(data.end()), high_mid(data.end()) &#123; &#125; void addNum(int num) &#123; const size_t n = data.size(); data.insert(num); if(n == 0)&#123; low_mid = data.begin(); high_mid = data.begin(); &#125;else if(n &amp; 1==1)&#123; // 插入之前元素数量为奇数, low_mid=high_mid if(num &lt; *low_mid) // 会插入到 low_mid/high_mid 之前, 因此, 前半段元素增加 low_mid--; else // 如果 &gt;=, 则会插入到low_mid/high_mid 之后 high_mid++; &#125;else&#123; // 插入之前元素数量为偶数, low_mid+1 = high_mid if(num &gt;= *low_mid &amp;&amp; num &lt; *high_mid)&#123; //插入的元素刚好在中间, 注意前面要用 &gt;=, 后面用 &lt;, 因为相等时, 会插在后面 low_mid++; high_mid--; // 两个指针都想中间靠拢. &#125;else if(num &lt; *low_mid)&#123; // 插入元素会插在前面, 则前面元素数量增加 high_mid--; // 令high_mid=low_mid; &#125;else&#123; // 插在了后面 low_mid++; // 令low_mid=high_mid; &#125; &#125; &#125; double findMedian() &#123; return (*low_mid + *high_mid) * 0.5; &#125;&#125;; 上面的指示器实际上可以简化成一个(因为两个指示器只能互相挨着或者重叠), 因此, 我们可以只维护一个指示器, 简化代码如下(但是不太好理解): 12345678910111213141516171819202122232425262728class MedianFinder &#123; multiset&lt;int&gt; data; multiset&lt;int&gt;::iterator mid;public: MedianFinder() : mid(data.end()) &#123; &#125; void addNum(int num) &#123; const int n = data.size(); data.insert(num); if (!n) // first element inserted mid = data.begin(); else if (num &lt; *mid) // median is decreased mid = (n &amp; 1 ? mid : prev(mid)); else // median is increased mid = (n &amp; 1 ? next(mid) : mid); &#125; double findMedian() &#123; return data.size() &amp; 1 == 1 ? (*mid) : (*mid + *next(mid)) * 0.5 ; &#125;&#125;; Follow Up If all integer numbers from the stream are between 0 and 100, how would you optimize it? 用bucket? If 99% of all integer numbers from the stream are between 0 and 100, how would you optimize it? 297. Serialize and Deserialize Binary TreeDescription: 序列化和反序列化二叉树Serialization is the process of converting a data structure or object into a sequence of bits so that it can be stored in a file or memory buffer, or transmitted across a network connection link to be reconstructed later in the same or another computer environment. Design an algorithm to serialize and deserialize a binary tree. There is no restriction on how your serialization/deserialization algorithm should work. You just need to ensure that a binary tree can be serialized to a string and this string can be deserialized to the original tree structure. Example:123456789You may serialize the following tree: 1 / \ 2 3 / \ 4 5as &quot;[1,2,3,null,null,4,5]&quot; Clarification: The above format is the same as how LeetCode serializes a binary tree. You do not necessarily need to follow this format, so please be creative and come up with different approaches yourself. Note: Do not use class member/global/static variables to store states. Your serialize and deserialize algorithms should be stateless. 解法一: DFS时间复杂度: $O(n)$, 在序列化和反序列化递归中, 各遍历每个节点一次空间复杂度: $O(n\times v + n) = O(n)$, 其中, $n$ 为节点个数, $v$ 为节点上的值所占空间大小, 最后的一个 $n$ 代表递归调用所占的空间大小. 使用 ostringstream 和 istringstream 来缓存字符串, 中间用空格分隔, 利用流操作 &lt;&lt; 和 &gt;&gt; 可以方便的对字符串进行存入和读取, 而无需额外进行分词操作. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Codec &#123;private: void serialize(TreeNode *root, ostringstream &amp;out)&#123; // 函数重载 if(root==nullptr) out &lt;&lt; "# "; else&#123; out &lt;&lt; root-&gt;val &lt;&lt; " "; serialize(root-&gt;left, out); serialize(root-&gt;right, out); &#125; &#125; TreeNode *deserialize(istringstream &amp;in)&#123; string cur_val; in &gt;&gt; cur_val; if(cur_val=="#") return nullptr; else&#123; TreeNode *node = new TreeNode(std::stoi(cur_val)); node-&gt;left = deserialize(in); node-&gt;right = deserialize(in); return node; &#125; &#125;public: // Encodes a tree to a single string. string serialize(TreeNode* root) &#123; ostringstream out; serialize(root, out); return out.str(); &#125; // Decodes your encoded data to tree. TreeNode* deserialize(string data) &#123; istringstream in(data); return deserialize(in); &#125;&#125;;// Your Codec object will be instantiated and called as such:// Codec codec;// codec.deserialize(codec.serialize(root)); 解法二: BFS时间复杂度: $O(n)$, 在序列化和反序列化中, 每个节点都遍历一次空间复杂度: BFS 的会按照层次遍历的顺序将树的节点序列化, 序列化的代码比较好写, 只需对普通的层次遍历稍加改动即可. 反序列化的代码有一点麻烦, 需要控制树节点的左右子节点的值, 具体如下. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Codec &#123;public: // Encodes a tree to a single string. string serialize(TreeNode* root) &#123; ostringstream out; if(root==nullptr) return ""; queue&lt;TreeNode*&gt; q; q.push(root); while(!q.empty())&#123; TreeNode *node = q.front(); q.pop(); if(node!=nullptr)&#123; out &lt;&lt; node-&gt;val &lt;&lt; " "; q.push(node-&gt;left); q.push(node-&gt;right); &#125;else out &lt;&lt; "# "; &#125; return out.str(); &#125; // Decodes your encoded data to tree. TreeNode* deserialize(string data) &#123; if(data.empty()) return nullptr; istringstream in(data); queue&lt;TreeNode *&gt; q; string val; in &gt;&gt; val; TreeNode *res = new TreeNode(std::stoi(val)); TreeNode *cur = res; q.push(cur); while(!q.empty())&#123; TreeNode *node = q.front(); q.pop(); if(!(in&gt;&gt;val)) break; if(val!="#")&#123; cur = new TreeNode(std::stoi(val)); node-&gt;left = cur; q.push(cur); &#125; if(!(in&gt;&gt;val)) break; if(val!="#")&#123; cur = new TreeNode(std::stoi(val)); node-&gt;right = cur; q.push(cur); &#125; &#125; return res; &#125;&#125;; 300. Longest Increasing SubsequenceDescription: 求最长递增序列(可以不连续)的长度Given an unsorted array of integers, find the length of longest increasing subsequence. Example:123Input: [10,9,2,5,3,7,101,18]Output: 4Explanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4. Note: There may be more than one LIS combination, it is only necessary for you to return the length. Your algorithm should run in O(n2) complexity. Follow up:Could you improve it to O(n log n) time complexity? 解法一: 暴力时间复杂度: $O(2^n)$空间复杂度: $O(n^2)$ 对于任意一个数字, 只有两种情况, 即处于最长递增数组内, 或者不处于最长递增数组内, 需要同时将这两种情况考虑, 然后选择最长的情况. 该方法时间超限. 解法二: Recursion with memorization [Memory Limit Exceeded]解法三: DP分析题目可以得出, 第 $i$ 个下标对应的数字是否存在于递增序列中, 与该下标之后的元素是无关的, 因此, 很自然的想到利用 DP 的方法来解决这道题. 我们令 dp[i] 代表 包含第 $i$ 个下标对应元素的递增序列的长度. 在求取 dp[i+1] 时, 我们需要遍历前面 dp[0~i] 个数组元素才能决定 dp[i+1] 的值, 因此, 时间复杂度为 $O(n^2)$, 空间复杂度为 $O(n)$. (比递归方法好很多). 12345678910111213141516171819class Solution &#123;public: int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; vector&lt;int&gt; dp(nums.size(), 1); int res_max=1; // 记录最长的递增序列长度, 因为最少有一个元素, 所以长度最少为1 for(int i=1; i&lt;nums.size(); i++)&#123; int max_val = 0; for(int j=0; j&lt;i; j++)&#123; if(nums[i] &gt; nums[j])&#123; // 只有当当前元素大于前面的元素时, 才能构成递增序列 max_val = std::max(max_val, dp[j]);//当前元素与nums[j]可以组成递增序列 &#125; &#125; dp[i] = max_val+1; // 将当前元素加入, 因此, 长度增1 res_max = std::max(res_max, dp[i]); //用当前长度更新最长长度的值 &#125; return res_max; &#125;&#125;; 解法四: DP+二分搜索(最优)时间复杂度: $O(nlogn)$, 每次搜索的复杂度为 $O(logn)$, 总共需要搜索 $n$ 次空间复杂度: $O(m)$, $m$ 为最长递增序列的长度. 同样还是 DP 解法, 但是我们重新赋予 dp[] 数组另一个含义, 我们令 dp[] 数组内储存的元素的数量刚好等于当前最长递增序列的数量, 注意, dp[] 数组内的值不一定是递增序列的值. 核心算过过程如下所示: 初始时, 令 dp[] 数组为空, 即 dp=[]; 对于每一个元素 num, 我们查找 num 在 dp 数组中的 upper_bound 迭代器(首个大于 num 的元素的迭代器), 假设取名为 upper;(注意, dp 数组是有序的, 所以这里的查询复杂度为 $O(logn)$) 查看 upper-1 指向的元素是否和 num 相等, 如果相等, 则说明该元素已经存在, 那么就跳过该元素, 重新回到步骤2; 如果 num 大于 dp 数组内的所有元素, 则将 num 添加进 dp 数组; 否则, 就将 dp 数组中大于 num 的第一个元素的值赋为 num. 重复步骤2,3,4, 直到遍历完数组为止. 为了更好的解释这种解法, 我们通过举例进行说明, 假定输入的数字序列为: [4,10,3,4,10,3,2], 那么我们的 dp[] 数组的变化情况如下: dp=[],初始时, 数组为空;dp=[4], 遍历元素4, 加入到数组中;dp=[4,10], 遍历元素10, 10大于所有元素, 将其添加到数组中;dp=[3,10], 遍历元素3, 发现第一个大于3的值为4, 将其赋值为3;dp=[3,4], 遍历元素4, 发现第一个大于4的的值为10, 将其赋值为4;dp=[3,4,10], 遍历元素10, 10大于所有元素, 将其添加到数组中;dp=[3,4,10], 遍历元素3, 3在数组中已经存在, 跳过该元素;dp=[2,4,10], 遍历元素2, 发现第一个大于2个值为3, 将其赋值为2. 综上, 我们可以看到, dp 数组的长度始终等于当前数组的最长子序列的长度, 故而, 直接返回 dp.size() 即为最终的结果. 注意, dp 内的值不一定为递增子序列的值. 1234567891011121314151617class Solution &#123;public: int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; vector&lt;int&gt; dp; for(auto num : nums)&#123; auto upper = std::upper_bound(dp.begin(), dp.end(), num); if(upper!=dp.begin() &amp;&amp; *(upper-1) == num) continue; // 如果num在dp数组中已经存在, 则跳过该num. if(upper==dp.end())&#123; dp.push_back(num); // 当前num比dp数组内的所有值都大, 则添加进dp数组 &#125;else&#123; *upper = num; // 用更小的值替代当前dp数组内的值 &#125; &#125; return dp.size(); // 最终, dp数组的长度即为最长递增序列的长度 &#125;&#125;; 309. 最佳买卖股票时机含冷冻期题目链接: https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ 解法一: 动态规划时间: $O(n)$, 空间: $O(1)$ 难点主要在于想到动态规划的方程, 将每一天的状态分成持有股票和不持有股票两种, 则每一天状态的更新方式如下: 持有(取较大者): 保持昨天的持有 前天 不持有(包含前天卖出的情况), 今天买入; 不持有(取较大者): 则为昨天持有, 今天卖出 保持昨天的不持有 C++ 实现:123456789101112131415161718class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.size() &lt;= 1) return 0; // 对于任意一天的股票, 均由持有和不持有两种状态, 记录两种状态下当前的余额 // 由于存在冷冻期, 因此, 我们要先求出第一天和第二天的状态, 然后从第三天开始根据前天和昨天的状态进行判断 int dp_q[2] = &#123;-prices[0], 0&#125;; // 第一天, 若持有, 则需要买入, 若不持有, 则余额为 0(没有支出) // 第二天, 若持有, 则为保持前一天的持有, 或者前一天不持有, 第二天买入; 若不持有, 则为第一天买入, 第二天卖出, 或者保持第一天的不持有 int dp_z[2] = &#123;std::max(-prices[0], -prices[1]), std::max(prices[1] - prices[0], 0)&#125;; for (int i = 2; i &lt; prices.size(); i++) &#123; // 对于任意一天的状态来说, 若持有, 则为保持昨天的持有, 或者前天不持有(包含前天卖出的情况), 今天买入; 若不持有, 则为昨天持有, 今天卖出, 或者保持昨天的不持有 int dp[2] = &#123;std::max(dp_z[0], dp_q[1]-prices[i]), std::max(dp_z[0]+prices[i], dp_z[1])&#125;; dp_q[0] = dp_z[0]; dp_q[1] = dp_z[1]; // 进入下一天, 昨天变前天 dp_z[0] = dp[0]; dp_z[1] = dp[1]; // 进入下一天, 今天变昨天 &#125; return std::max(dp_z[0], dp_z[1]); &#125;&#125;; Python 实现:123456789class Solution: def maxProfit(self, prices: List[int]) -&gt; int: if len(prices) &lt;= 1: return 0; dp_q = [-prices[0], 0] # first day, [y, n] dp_z = [max(-prices[0], -prices[1]), max(0, prices[1] - prices[0])] # second day, [y, n] for price in prices[2:]: dp = [max(dp_z[0], dp_q[1]-price), max(dp_z[1], dp_z[0]+price)] dp_q, dp_z = dp_z, dp return max(dp_z) 315. Count of Smaller Numbers After SelfDescription: 统计右边比当前数字小的个数You are given an integer array nums and you have to return a new counts array. The counts array has the property where counts[i] is the number of smaller elements to the right of nums[i]. Example:1234567Input: [5,2,6,1]Output: [2,1,1,0]Explanation:To the right of 5 there are 2 smaller elements (2 and 1).To the right of 2 there is only 1 smaller element (1).To the right of 6 there is 1 smaller element (1).To the right of 1 there is 0 smaller element. 解法一: multiset时间复杂度: $O(n\times(logn+n+logn)=O(n^2)$空间复杂度: $O(n+n) = O(n)$ 先介绍一下利用 multiset 的解法, multiset 的底层实现使用了红黑树, 所以在插入和查找的时候复杂度都为 $O(logn)$, 但是求 distance 时, 由于 multiset 的迭代器不是随机访问的, 因此复杂度为 $O(n)$, 故而最后的时间复杂度为 $O(n^2)$. 该方法在 OJ 上超时, 此处仅用于记录. 1234567891011121314151617 class Solution &#123;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; multiset&lt;int&gt; nums_set; int n = nums.size(); vector&lt;int&gt; res(nums.size(), 0); for(int i=n-1; i&gt;=0; i--)&#123; auto itlow = nums_set.lower_bound(nums[i]); res[i] = std::distance(nums_set.begin(), itlow); // multiset 求distance的复杂度为线性, 因此, 总复杂度为 O(n^2) nums_set.insert(nums[i]); &#125; return res; &#125;&#125;; 解法二: 有序数组时间复杂度: $O(n\times (logn+n) = O(n^2)$, 在有序数组中找指定位置需要 $O(logn)$, 将当前元素插入到数组的指定位置需要 $O(n)$, 这个过程需要进行 $n$ 次.空间复杂度: $O(n+n) = O(n)$, 一个有序数组, 一个结果数组, 大小都为 $n$. 我们从后往前遍历, 将遍历过的数字维护成一个有序数组, 然后对于任意一个新来的数字, 我们可以在有序数组中查询小于该数字的元素个数, 查询的时间复杂度为 $O(logn)$, 然后我们需要将该数字也插入到有序数组中并保持有序, 插入操作需要的时间复杂度为 $O(n)$, 总共有 $n$ 个数字, 因此需要执行 $n$ 次, 故时间复杂度约为 $O(n^2)$, (虽然是 $O(n^2)$, 但是仍然没超时, 考虑是因为只有一个 $logn$, 而解法一具有两个 $logn$.) 代码如下: 123456789101112131415class Solution &#123;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; order_nums; vector&lt;int&gt; res(n, 0); for(int i=n-1; i&gt;=0; i--)&#123; //计算第一个不小于nums[i]的数字之前的数字个数 int d = std::lower_bound(order_nums.begin(), order_nums.end(), nums[i]) - order_nums.begin(); res[i] = d; //将数字个数填进结果数字 order_nums.insert(order_nums.begin()+d, nums[i]); // 当 nums[i] 插入到合适位置, 保持order_nums有序 &#125; return res; &#125;&#125;; 解法三: 二叉搜索树(BST)时间复杂度: $O(nlogn)$, 内部只有一个 $logn$ 复杂度的插入操作, 没有其他操作, 但是由于不是平衡的, 所以在最坏情况下的复杂度为 $O(n^2)$, 最好情况即为平衡树, 复杂度为 $O(nlogn)$.空间复杂度: $O(n+n)$, res 数组和二叉树结构各占 $n$ 大小的空间. 如果采用递归实现插入, 则可能额外需要 $n$ 大小的递归空间. 在解法一中, 通过 multiset 红黑树的结构使得插入时的复杂度为 $logn$, 但是最终需要进行的操作过多, 导致时间超时, 为此, 我们可以自己实现一个二叉搜索树, 从后往前的遍历数组, 并且在插入元素的时候就统计出小于当前元素的节点的个数(为此我们需要在树的结构中额外添加一个变量 smaller, 只是小于当前节点的元素个数), 故而只需要一次 $logn$, 且没有其他多于操作, 代码如下: 12345678910111213141516171819202122232425262728293031323334class Solution &#123; struct TreeNode&#123; int val; int smaller; TreeNode *left; TreeNode *right; TreeNode(int v, int s):val(v), smaller(s), left(nullptr), right(nullptr)&#123;&#125;; &#125;; int insert(TreeNode *&amp;root, int val)&#123; // 注意, 这要insert函数中, root的值要影响函数外的指针, 所以要用引用&amp; if(root==nullptr)&#123; root = new TreeNode(val, 0); return 0; // &#125; if(val &lt; root-&gt;val)&#123; root-&gt;smaller++; // 如果新来的数比当前root的的值还小, 则smaller增1 return insert(root-&gt;left, val); // 递归插入到左子树中 &#125;else&#123; // 递归插入到右子树中, 返回的小于元素的数量为: 根左侧的数量+右子树的数量+根(0:1) return root-&gt;smaller + insert(root-&gt;right, val) + (root-&gt;val==val ? 0 : 1); // 这里要千万注意三目运算符的优先级, 一定要用括号整个括起来才行!!! &#125; &#125;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; res(n, 0); TreeNode *root = nullptr; for(int i=n-1; i&gt;=0; i--)&#123; // 如果题目问的是左侧, 则i从0开始 res[i] = insert(root, nums[i]); &#125; return res; &#125;&#125;; 解法四: 归并排序时间复杂度: $O(nlogn)$空间复杂度: $O(n+n) = O(n)$ 由于解法三构造的二叉树并不是一个平衡的二叉树, 导致在树的极端情况下, 时间复杂度为 $O(n^2)$, 而要手动实现二叉树的平衡逻辑, 又有些复杂, 不适合解此题. 所以, 我们可以考虑此题的另一种解法, 即利用归并排序来解决. 【链接】Loading…https://leetcode.com/problems/count-of-smaller-numbers-after-self/discuss/76607/C%2B%2B-O(nlogn)-Time-O(n)-Space-MergeSort-Solution-with-Detail-Explanation 322. Coin ChangeDescription: 硬币凑面额You are given coins of different denominations and a total amount of money amount. Write a function to compute the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return -1. Example 1:123Input: coins = [1, 2, 5], amount = 11Output: 3Explanation: 11 = 5 + 5 + 1 Example 2:12Input: coins = [2], amount = 3Output: -1 解法一: DP时间复杂度: $O(nm)$, $n$ 为总面额的大小, $m$ 为硬币的数量.空间复杂度: $O(n)$, DP 数组的大小为总面额的大小. 当我们求组成面额 $i$ 时所需的最少硬币数时, 我们可以用面额 $j$ 和面额 $i-j$ ($j\in[0,i]$)所需的硬币数之和来代替, 因此, 也就是说只与 $i$ 之前的面额数有关, 所以我们可以考虑使用 DP 算法来求解. 我们令 dp[i] 代表组成面额 $i$ 时所需的最少的硬币数, 要求 dp[i], 我们可以根据硬币的面额来求解, 假设硬币的面额是 $j$, 那么就有 dp[i] = min(dp[j] + dp[i-j]), 其中 dp[j]=1, 因为组成这种面额只需要一个硬币就可以了, 我们根据此公式就可以写出相应的 DP 代码, 如下所示. 12345678910111213141516class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; // 因为不可能为负值, 所以使用无符号整数, 防止溢出 // 额外多了一个0面额, 初值也可以设置为 amount+1, 因为最多的硬币数就是amount个1元. vector&lt;unsigned int&gt; dp(amount+1, amount+1); dp[0] = 0; // 为面额0赋初值 for(int i=1; i&lt;amount+1; i++)&#123; for(int ci=0; ci&lt;coins.size(); ci++)&#123; int j = coins[ci]; if(i &gt;= j) dp[i] = std::min(dp[i], 1+dp[i-j]); // 注意不能少了if语句, 否则会运行时错误 &#125; &#125; return dp[amount] &gt; amount ? -1 : dp[amount]; &#125;&#125;; 你可能会觉得我们进行了一些无用计算, 例如如果 $i$ 为 11, 而 coins 为 [1,5], 那么我们是否只需要计算 dp[6] 就可以了呢? 实际上, 如果有面额为 1 的硬币存在, 那么我们就必须计算所有的小于 $i$ 的dp值, 因为这些都是解, 至于是否为最小数量, 则需要利用 min 来不断筛选. 解法二: DP 递归实现时间复杂度: $O(nm)$, $n$ 为总面额的大小, $m$ 为硬币的数量.空间复杂度: $O(n+n)=O(n)$, DP 数组的大小为总面额的大小, 另外, 递归还需额外占用一定空间. 123456789101112131415161718class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; vector&lt;int&gt; dp(amount+1, INT_MAX); dp[0] = 0; return coin_dfs(coins, amount, dp); &#125; int coin_dfs(vector&lt;int&gt; &amp;coins, int target, vector&lt;int&gt; &amp;dp)&#123; if(target &lt; 0) return -1; // invalid combination if(dp[target] != INT_MAX) return dp[target]; // already computed, return it for(int i=0; i&lt;coins.size(); i++)&#123; int tmp = coin_dfs(coins, target-coins[i], dp); if(tmp&gt;=0) dp[target] = min(dp[target], 1+tmp); &#125; dp[target] = (dp[target] == INT_MAX) ? -1 : dp[target]; return dp[target]; &#125;&#125;; 解法三: 对暴力解法剪枝时间复杂度: $O(logn+mlogm)$, 每次都用当前面额除以硬币面额, 故时间复杂度为 $O(logn)$, $O(mlogm)$ 为对硬币面额的排序复杂度, 当 $m&lt;&lt;n$ 时, 可忽略不计.空间复杂度: $O(logn)$, 无需申请额外空间, 仅仅是递归过程需要占用空间. 下面的方法利用余数对暴力解法进行剪枝, 剪枝后的程序运行速度十分快, 远远快于前两个算法. 123456789101112131415161718192021222324252627class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; int res = INT_MAX; // results count int n = coins.size(); int cur = 0; // current count std::sort(coins.begin(), coins.end()); // sort from small to large helper(coins, amount, n-1, cur, res); return res==INT_MAX ? -1 : res; &#125; void helper(vector&lt;int&gt; &amp;coins, int target, int start, int cur, int &amp;res)&#123; if(target%coins[start]==0)&#123; // 如果可以整除, 说明找到了合适的组合 res = min(res, cur+target/coins[start]); return; &#125; for(int i=target/coins[start]; i&gt;=0; i--)&#123; if(cur+i &gt;= res-1) // 如果当前的硬币数已经超过了 res-1, 说明之后肯定需要更多的硬币, // 因为后面的硬币面额变小了, 所以需要至少cur+i+1个硬币才能凑齐 // 因此, 无需再进行循环, 直接跳出即可 break; if(start&gt;0) // start不能为负值, 因此start要大于0才能继续递归 helper(coins, target-i*coins[start], start-1, cur+i, res); &#125; &#125;&#125;; 关于此算法的更详细解释(http://www.cnblogs.com/grandyang/p/5138186.html):难道这题一定要DP来做吗, 我们来看网友hello_world00提供的一种解法, 这其实是对暴力搜索的解法做了很好的优化, 不仅不会TLE, 而且击败率相当的高！对比Brute Force的方法, 这里在递归函数中做了很好的优化. 首先是判断start是否小于0, 因为我们需要从coin中取硬币, 不能越界. 下面就是优化的核心了, 看target是否能整除coins[start], 这是相当叼的一步, 比如假如我们的目标值是15, 如果我们当前取出了大小为5的硬币, 我们做除法, 可以立马知道只用大小为5的硬币就可以组成目标值target, 那么我们用cur + target/coins[start] 来更新结果res. 之后的for循环也相当叼, 不像暴力搜索中的那样从start位置开始往前遍历coins中的硬币, 而是遍历 target/coins[start] 的次数, 由于不能整除, 我们只需要对余数调用递归函数, 而且我们要把次数每次减1, 并且再次求余数. 举个例子, 比如coins=[1,2,3], amount=11, 那么 11除以3, 得3余2, 那么我们的i从3开始遍历, 这里有一步非常有用的剪枝操作, 没有这一步, 还是会TLE, 而加上了这一步, 直接击败百分之九十九以上, 可以说是天壤之别. 那就是判断若 cur + i &gt;= res - 1 成立, 直接break, 不调用递归. 这里解释一下, cur + i 自不必说, 是当前硬币个数cur 加上新加的i个硬币, 我们都是知道cur+i如果大于等于res的话, 那么res是不会被更新的, 那么为啥这里是大于等于res-1呢？因为能运行到这一步, 说明之前是无法整除的, 那么余数一定存在, 所以再次调用递归函数的target不为0, 那么如果整除的话, cur至少会加上1, 所以又跟res相等了, 还是不会使得res变得更小. 324. Wiggle Sort IIDescription: “驼峰” 排序Given an unsorted array nums, reorder it such that nums[0] &lt; nums[1] &gt; nums[2] &lt; nums[3]…. Example 1:12Input: nums = [1, 5, 1, 1, 6, 4]Output: One possible answer is [1, 4, 1, 5, 1, 6]. Example 2:12Input: nums = [1, 3, 2, 2, 3, 1]Output: One possible answer is [2, 3, 1, 3, 1, 2]. Note:You may assume all input has valid answer. Follow Up:Can you do it in O(n) time and/or in-place with O(1) extra space? 解法一: 排序时间复杂度: $O(nlogn + n)$, 排序的时间复杂度为 $O(nlogn)$, 构造 “驼峰” 数组的复杂度为 $O(n)$空间复杂度: $O(n)$, 额外数组需要占用 $O(n)$ 空间 该问题的解法可能有多个, 我们只需要找到其中一个即可, 核心思路是将一个数组分成两半, 其中前一半的元素都小于后一半的元素, 然后我们只需要依次从两个数组中取值组成新数组, 就可以满足 “驼峰” 排序.首先, 对数组中的元素排序, 这样, 任意的相邻元素, 都满足 nums[i] &lt;= nums[i+1], 我们将数组分成两半, 这样, 前半段的元素都小于等于后半段的元素, 注意, 题目中已经指明数组是合法的有效数组, 所以一定可以组成驼峰, 因此, 我们先取前半段的最后一个元素, 再取后半段的最后一个元素, 这两个元素一定满足绝对小于关系(否则无法形成 “驼峰”), 然后我们再取倒数第二个, 依次类推, 直至取完. 注意, 我们不能从前往后取, 因为不能保证前半段的第二个元素绝对小于后半段的第一个元素, 例如[4,5,5,6], 从前往后取就会变成[4,5,5,6], 不符合驼峰, 从后往前取为[5,6,4,5], 符合驼峰. 1234567891011121314class Solution &#123;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int low = 0, high = nums.size()-1; std::sort(nums.begin(), nums.end()); int mid = (nums.size()+1)/2; // 令mid指向中间的位置 vector&lt;int&gt; tmp; for(int i=mid-1, j=nums.size()-1; i&gt;=0 ; i--, j--)&#123; // 从后往前选择元素, 分别放到tmp中 tmp.push_back(nums[i]); if(j&gt;=mid) tmp.push_back(nums[j]); &#125; nums = tmp; &#125;&#125;; 解法二: partition时间复杂度: $O(n+n)= O(n)$, 查找中位数需要 $O(n)$, 填充数组需要 $O(n)$.空间复杂度: $O(n)$, 填充时使用了额外的数组空间来辅助. 如果当数组中的元素不含有重复时, 此题很容易就用基于 partition 的方法解决, 因为, 我们可以找到将数组分成两个具有绝对小于关系的数组, 然后依次用两个数组填充即可, 但是, 此题的元素是可重复的, 所以必须考虑重复元素的影响.首先我们利用 nth_element() 找到中位数, 虽然 nth_element() 的时间复杂度已经不是 $O(n)$, 但是这里我们为了简化代码, 仍然使用 nth_element() 来查找中位数 mid(后面也会更多稍复杂一点的 partition 算法, 面试时建议使用 nth_element, 注意要向面试官说明复杂度问题), 之后, 对于其他的任意一个数组元素, 都有三种不同的情况: 大于 mid, 将大于 mid 的元素放在数组开始的奇数位上面; 小于 mid, 将小于 mid 的元素放在数组的偶数位上面; 等于 mid, 用所有等于 mid 的元素填充剩下的位置. 由于题目指明输入的数组一定是有效的, 因此当我们进行了上面遍历后, 数组一定会变成 “驼峰” 数组, 因为当和 mid 相等的元素处于 “驼峰” 底部时, 它一定位于偶数位(奇数位都是大于 mid 的元素), 同理, 当 mid 处于 “驼峰” 顶部时, 它一定位于奇数位, 因为偶数位都被小于 mid 的元素填充. 故最终的数组是 “驼峰” 数组. nth_element()(该函数在 C++17 后不是 $O(n)$, 而是 $O(nlogn)$, 但是在 C++11 中仍然是 $O(n)$):12345678910111213141516171819202122class Solution &#123;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); std::nth_element(nums.begin(), nums.begin()+n/2, nums.end()); int mid = nums[n/2]; // 找到中位数 vector&lt;int&gt; res(n, mid); // 先将所有元素置为中位数 int even_i = (n-1)/2*2; // 令 even_i 指向数组的最后一个偶数位 int odd_i = 1; for(int i=0; i&lt;n; i++)&#123; if(nums[i] &gt; mid)&#123; // 将大于中位数的放到前面的奇数位上 res[odd_i] = nums[i]; odd_i += 2; &#125;else if(nums[i] &lt; mid)&#123; //将小于中位数的放到后面的偶数位上 res[even_i] = nums[i]; even_i -= 2; &#125; &#125; // 剩下的位置都是中位数 nums = res; &#125;&#125;; 自己利用partition实现 $O(n)$ 的中位数查找: 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;private: int partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P &lt;= nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P &gt;= nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int low = 0, high = n-1; int target = n/2; while(1)&#123; int m = partition(nums, low, high); if(m &lt; target) low = m + 1; else if(m &gt; target) high = m - 1; else break; &#125; int mid = nums[target]; // 找到中位数 vector&lt;int&gt; res(n, mid); // 先将所有元素置为中位数 int even_i = (n-1)/2*2; // 令 even_i 指向数组的最后一个偶数位 int odd_i = 1; // 指向第一个奇数位 for(int i=0; i&lt;n; i++)&#123; if(nums[i] &gt; mid)&#123; // 将大于中位数的放到前面的奇数位上 res[odd_i] = nums[i]; odd_i += 2; &#125;else if(nums[i] &lt; mid)&#123; //将小于中位数的放到后面的偶数位上 res[even_i] = nums[i]; even_i -= 2; &#125; &#125; // 剩下的位置都是中位数 nums = res; &#125;&#125;; Follow up: three-way partition时间复杂度: $O(n+n) = O(n)$, 找中位数时的复杂度为 $O(n)$, 调整数组的复杂度为 $O(n)$.空间复杂度: $O(1)$, 无需占用额外空间 解法二的时间复杂度满足要求, 问题在于我们如何能够在 $O(1)$ 的空间复杂度限制下, 完成数组的填充工作, 很自然的我们可以想到利用 swap 来实现, 具体流程如下所示: 先令 even_i 指向数组的最后一个偶数位(从0位开始, 0算作偶数位), 令 odd_i 指向第一个奇数位(下标为1). 我们从最后一个偶数位元素(用下标 i 指示)开始进行判断; 如果 nums[i]&lt;mid, 则将 nums[i] 与 nums[even_i] 交换, 交换后, even_i 不可再被访问, 令 even_i -= 2, 同时注意, 由于刚开始的时候 i 与 even_i 是相等的, 故也要令 i -= 2, 当 i&lt;0 以后, 要令 i 指向最后一个奇数位. 如果 nums[i]&gt;mid, 则将 nums[i] 与 nums[odd_i] 交换, 同时令 odd_i += 2, 注意, 此时, i 指向的数字是交换后的原来 odd_i 指向的数字, 因此, 我们需要对该数字进行判断, 故不能改变 i 的值. 如果和 mid 相等, 则无需进行交换填充, 令其保存原值即可, 判断下一个元素, 令 i -=2, 同时还要判断 i 是否小于 0, 若小于, 则需令 i 指向最后的奇数位. nth_element():12345678910111213141516171819202122232425262728class Solution &#123;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); std::nth_element(nums.begin(), nums.begin()+n/2, nums.end()); int mid = nums[n/2]; // 找到中位数 // O(1) 空间复杂度填充数组 int even_i = (n-1)/2*2; int odd_i = 1; int i = even_i; // 令i指向最后一个偶数位 int count = n; while(count--)&#123; //每次都会判断一个元素 if(nums[i] &lt; mid)&#123; std::swap(nums[i], nums[even_i]); even_i -= 2; i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125;else if(nums[i] &gt; mid)&#123; std::swap(nums[i], nums[odd_i]); odd_i += 2; // 奇数位增加 &#125;else&#123; // 保持原值不变, 判断下一个值 i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125; &#125; &#125;&#125;; partition: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123;private: int partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P &lt;= nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P &gt;= nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int low = 0, high = n-1; int target = n/2; while(1)&#123; int m = partition(nums, low, high); if(m &lt; target) low = m + 1; else if(m &gt; target) high = m - 1; else break; &#125; int mid = nums[target]; // 找到中位数 // O(1) 空间复杂度填充数组 int even_i = (n-1)/2*2; int odd_i = 1; int i = even_i; // 令i指向最后一个偶数位 int count = n; while(count--)&#123; //每次都会判断一个元素 if(nums[i] &lt; mid)&#123; std::swap(nums[i], nums[even_i]); even_i -= 2; i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125;else if(nums[i] &gt; mid)&#123; std::swap(nums[i], nums[odd_i]); odd_i += 2; // 奇数位增加 &#125;else&#123; // 保持原值不变, 判断下一个值 i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125; &#125; &#125;&#125;; 326. Power of ThreeDescription: 三的幂次Given an integer, write a function to determine if it is a power of three. Example 1:12Input: 27Output: true Example 2:12Input: 0Output: false Example 3:12Input: 9Output: true Example 4:12Input: 45Output: false 解法一: 自下而上(超时)时间复杂度: $O(logn)$, 计算3的幂次, 总共需要计算 $log_3n$ 次空间复杂度: $O(1)$ 该方法从 3 开始, 逐渐计算 3 的幂次, 但是由于对于任何数都要计算 $log3n$ 次, 故当数很大时会超时 12345678910class Solution &#123;public: bool isPowerOfThree(int n) &#123; int pow = 1; while(pow &lt; n)&#123; pow = pow*3; &#125; return pow==n ? true : false; &#125;&#125;; 解法二: 自上而下时间复杂度: $O(logn)$, 利用除法判断是否能整除 3, 当不能整除时, 可以提前退出, 起到剪枝效果, 最多需要计算 $log_3n$ 次空间复杂度: $O(1)$ 解法一采用的自下而上的乘法方法对于任何的数字都需要进行 $log_3n$ 次乘法才能判断是否为 3 的幂次, 这显然是不需要的, 我们只需要利用除法, 不断判断是否能被 3 整除即可, 一旦发现不能整除, 则肯定不是 3 的幂次, 可提前退出, 代码如下: 12345678910class Solution &#123;public: bool isPowerOfThree(int n) &#123; if(n&lt;1) return false; while (n%3 == 0)&#123; n /= 3; &#125; return n==1; &#125;&#125;; 解法三: 进制转换(不使用循环或迭代)十进制的 pow 形式为: 10, 100, 1000 (分别代表十, 一百, 一千)二进制的 pow 形式为: 10, 100, 1000 (分别代表二, 四, 八)因此我们可以推出三进制的形式为: 10, 100, 1000 (分别代表三, 九, 二十七) 故此, 我们可以将十进制先转换成三进制, 然后判断三进制形式是否首位为一, 其他位均为零, 如果满足, 则说明当前的数字是三的幂次. 该方法不需要循环和迭代(实际上在转换的过程仍然使用了循环和迭代). 12 328. Odd Even Linked ListDescription: 奇偶链表Given a singly linked list, group all odd nodes together followed by the even nodes. Please note here we are talking about the node number and not the value in the nodes. You should try to do it in place. The program should run in O(1) space complexity and O(nodes) time complexity. Example 1:12Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULLOutput: 1-&gt;3-&gt;5-&gt;2-&gt;4-&gt;NULL Example 2:12Input: 2-&gt;1-&gt;3-&gt;5-&gt;6-&gt;4-&gt;7-&gt;NULLOutput: 2-&gt;3-&gt;6-&gt;7-&gt;1-&gt;5-&gt;4-&gt;NULL Note:The relative order inside both the even and odd groups should remain as it was in the input.The first node is considered odd, the second node even and so on … 解法一: 一次遍历时间复杂度: $O(n)$, 遍历每个节点一次空间复杂度: $O(1)$, 未使用任何额外空间 我们利用两个变量分别来维护奇数链表和偶数链表, 最后令奇数链表的最后一个节点的 next 指针指向偶数链表的头结点, 代码如下: 123456789101112131415161718192021222324252627282930313233343536/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* oddEvenList(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return head; ListNode *odd_head = head; // 奇数链表头 ListNode *even_head = head-&gt;next; // 偶数链表头 ListNode *odd_node = odd_head; // 奇数链表节点 ListNode *even_node = even_head; // 偶数链表节点 ListNode *node = head-&gt;next-&gt;next; // 令当前节点指向第三个节点 int i = 3; // 记录节点编号(从1开始) while(node!=nullptr)&#123; if(i&amp;1 == 1)&#123; // 奇数链表 odd_node-&gt;next = node; odd_node = odd_node-&gt;next; node = node-&gt;next; &#125;else&#123; // 偶数链表 even_node-&gt;next = node; even_node = even_node-&gt;next; node = node-&gt;next; &#125; i++; &#125; odd_node-&gt;next = even_head; even_node-&gt;next = nullptr; // 少了这句话会超时, 原因是even_node会指向前面的某个节点, 形成环, 使得程序判断时无法终止 return odd_head; &#125;&#125;; 更简洁的写法:1234567891011121314public class Solution &#123; public ListNode oddEvenList(ListNode head) &#123; if (head == null) return null; ListNode odd = head, even = head.next, evenHead = even; while (even != null &amp;&amp; even.next != null) &#123; odd.next = even.next; odd = odd.next; even.next = odd.next; even = even.next; &#125; odd.next = evenHead; return head; &#125;&#125; 329. Longest Increasing Path in a MatrixDescription: 寻找矩阵中的最长递增序列Given an integer matrix, find the length of the longest increasing path. From each cell, you can either move to four directions: left, right, up or down. You may NOT move diagonally or move outside of the boundary (i.e. wrap-around is not allowed). Example 1:12345678Input: nums =[ [9,9,4], [6,6,8], [2,1,1]]Output: 4Explanation: The longest increasing path is [1, 2, 6, 9]. Example 2:12345678Input: nums =[ [3,4,5], [3,2,6], [2,2,1]]Output: 4Explanation: The longest increasing path is [3, 4, 5, 6]. Moving diagonally is not allowed. 解法一: DP + dfs时间复杂度: $O(mn)$, 每个节点都会遍历一次, 当遍历一次后, 下次再访问时可以直接通过 dp 数组得知答案.空间复杂度: $O(mn+mn=mn)$, $n$ 行 $m$ 列的 DP 数组所占用的空间大小, 另外还有递归所占用的空间($mn?$) 申请和矩阵相同大小的 DP 数组, 令 dp[i][j] 代表从 (i,j) 位置为起点的绝对递增数列的长度, 每遍历一个位置后, 下一次再访问该位置时就无需重复计算, 可以直接通过 dp 数组获取到相应长度. 在查找当前节点的最大长度时, 我们利用 dfs 算法, 依次从四个方向进行查找, 最终取最大值作为本位置的最长递增序列长度 123456789101112131415161718192021222324252627282930class Solution &#123;private: int dirs[4][2] = &#123;&#123;0, -1&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;1, 0&#125;&#125;; int dfs(vector&lt;vector&lt;int&gt;&gt; &amp;matrix, vector&lt;vector&lt;int&gt;&gt; &amp;dp, int i, int j, int &amp;n, int &amp;m)&#123; if(dp[i][j]!=0) return dp[i][j]; dp[i][j] = 1; //长度至少为1 for(auto d : dirs)&#123; int x = i+d[0], y = j+d[1]; if(x&gt;=0 &amp;&amp; x&lt;n &amp;&amp; y&gt;=0 &amp;&amp; y&lt;m &amp;&amp; matrix[x][y] &gt; matrix[i][j])&#123; // 绝对递增, 因此不能有 = int len = 1+dfs(matrix, dp, x, y, n, m); dp[i][j] = std::max(dp[i][j], len); &#125; &#125; return dp[i][j]; &#125;public: int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m = matrix[0].size(); vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(m, 0)); int res=1; for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; res = std::max(res, dfs(matrix, dp, i, j, n, m)); &#125; &#125; return res; &#125;&#125;; 解法二: DP + BFSTODO: http://www.cnblogs.com/grandyang/p/5148030.html 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; if (matrix.empty() || matrix[0].empty()) return 0; int m = matrix.size(), n = matrix[0].size(), res = 1; vector&lt;vector&lt;int&gt;&gt; dirs&#123;&#123;0,-1&#125;,&#123;-1,0&#125;,&#123;0,1&#125;,&#123;1,0&#125;&#125;; vector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, 0)); for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j ) &#123; if (dp[i][j] &gt; 0) continue; queue&lt;pair&lt;int, int&gt;&gt; q&#123;&#123;&#123;i, j&#125;&#125;&#125;; int cnt = 1; while (!q.empty()) &#123; ++cnt; int len = q.size(); for (int k = 0; k &lt; len; ++k) &#123; auto t = q.front(); q.pop(); for (auto dir : dirs) &#123; int x = t.first + dir[0], y = t.second + dir[1]; if (x &lt; 0 || x &gt;= m || y &lt; 0 || y &gt;= n || matrix[x][y] &lt;= matrix[t.first][t.second] || cnt &lt;= dp[x][y]) continue; dp[x][y] = cnt; res = max(res, cnt); q.push(&#123;x, y&#125;); &#125; &#125; &#125; &#125; &#125; return res; &#125;&#125;; 334. Increasing Triplet SubsequenceDescription: 递增的三元子序列Given an unsorted array return whether an increasing subsequence of length 3 exists or not in the array. Formally the function should: Return true if there exists i, j, ksuch that arr[i] &lt; arr[j] &lt; arr[k] given 0 ≤ i &lt; j &lt; k ≤ n-1 else return false.Note: Your algorithm should run in O(n) time complexity and O(1) space complexity. Example 1:12Input: [1,2,3,4,5]Output: true Example 2:12Input: [5,4,3,2,1]Output: false 解法一: 用辅助变量指向 min 和 mid时间复杂度: $O(n)$, 每个元素之遍历一次空间复杂度: $O(1)$, 无需额外空间 我们利用两个变量 min 和 mid 分别指向三元子序列中的最小元素和中间元素, 最开始时, 二者赋初值为 INT_MAX, 然后遍历数组, 对于数组中的每一个数 num, 进行如下判断: 是否小于等于 min, 若满足, 则令 min=num; 若不满足(1), 则说明 num &gt; min, 判断 num 是否小于等于 mid, 若满足, 责令 mid=num;(此时 mid 一定大于 min, 且下标也大于 min 下标) 若不满足(1)(2), 则说明 num 不仅大于 min, 而且大于 mid, 同时 num 的下标也大于前两者, 由此, 我们找到了一个满足条件的递增三元组子序列, 可直接返回 true. 否则, 重复以上步骤直至遍历完数组 如果遍历完整个数组后, 仍然找不到符合条件的序列, 则说明不存在这样的序列, 返回 false. 12345678910111213141516class Solution &#123;public: bool increasingTriplet(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() &lt; 3) return false; int min=INT_MAX, mid=INT_MAX; for(auto num : nums)&#123; if(num &lt;= min) // 等于号不能少, 否则会跳到最后的else中, 直接返回true min = num; else if(num &lt;= mid) // 如输入为 11111111 时, 若没有等于号, 则会跳到else中返回true mid = num; else return true; //当前数字比min和mid都大, 所以找到了一个三元组 &#125; return false; &#125;&#125;; 337. 打家劫舍 III-中等题目链接: https://leetcode-cn.com/problems/house-robber-iii/ 二叉树型的偷家 解法: 树形动态规划动态方程: 某个树的最大收益 = max（包含根节点的最大收益，以及不包含根节点的最大收益）； 不包含根节点的最大收益 = 左子树的最大收益 + 右子树最大收益 包含根节点的最大收益 = 不包含左子节点的左子树最大收益 + 根节点 + 不包含右子节点的最大收益 maxSum = max（maxSum，当前树的最大收益） 复杂度分析:时间复杂度：O（n）。只遍历一遍所有节点空间复杂度：O（n）。递归栈的调用，如果树极度不平衡，空间复杂度为O（n）；如果树平衡，为O（log N）。 C++ 实现:12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123; std::vector&lt;int&gt; traverse(TreeNode* root) &#123; int rob = 0, not_rob = 0; if (root == nullptr) return std::vector&lt;int&gt; &#123;rob, not_rob&#125;; auto left = traverse(root-&gt;left); auto right = traverse(root-&gt;right); rob = left[1] + right[1] + root-&gt;val; not_rob = std::max(left[0], left[1]) + std::max(right[0], right[1]); return std::vector&lt;int&gt; &#123;rob, not_rob&#125;; &#125;public: int rob(TreeNode* root) &#123; auto res = traverse(root); return std::max(res[0], res[1]); &#125;&#125;; Python 实现:1234567891011121314151617# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def rob(self, root: TreeNode) -&gt; int: def helper(root): if root == None: return 0, 0; l_rob, l_not_rob = helper(root.left) r_rob, r_not_rob = helper(root.right) rob = l_not_rob + r_not_rob + root.val not_rob = max(l_rob, l_not_rob) + max(r_rob, r_not_rob) return rob, not_rob return max(helper(root)) 341. Flatten Nested List IteratorDescription: 将嵌套的多维列表展开成一维Given a nested list of integers, implement an iterator to flatten it. Each element is either an integer, or a list — whose elements may also be integers or other lists. Example 1:123Input: [[1,1],2,[1,1]]Output: [1,1,2,1,1]Explanation: By calling next repeatedly until hasNext returns false, the order of elements returned by next should be: [1,1,2,1,1]. Example 2:123Input: [1,[4,[6]]]Output: [1,4,6]Explanation: By calling next repeatedly until hasNext returns false, the order of elements returned by next should be: [1,4,6]. 解法一: 栈PS: 这道题可以在初始化时将列表全部展开并存储, 这样 hasNext() 就可以达到 $O(1)$ 的时间复杂度, 但是, 这是很不好的! 因为实际实现迭代器时, 我们往往只在需要的时候才会对元素进行展开, 这样可以获得最大的平均效率 时间复杂度: $O(n)$, 每个节点至多遍历一次, 其中, next() 复杂度为 $O(1)$, 初始化和 hasNext() 的复杂度均为 $O(n)$空间复杂度: $O(n)$, 栈所需空间 先将数组中的所有元素从后往前的放进栈中, 这样栈顶元素即为数组中的第一个元素, 然后对栈顶元素进行判断, 如果 isInteger() 为真, 则直接返回 true, 否则, 就获取栈顶对应的 vector&lt;NestedInteger&gt; 数组, 并将栈顶 pop(), 然后将数组从后往前再放到栈中, 重复以上操作直至栈为空, 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * // This is the interface that allows for creating nested lists. * // You should not implement it, or speculate about its implementation * class NestedInteger &#123; * public: * // Return true if this NestedInteger holds a single integer, rather than a nested list. * bool isInteger() const; * * // Return the single integer that this NestedInteger holds, if it holds a single integer * // The result is undefined if this NestedInteger holds a nested list * int getInteger() const; * * // Return the nested list that this NestedInteger holds, if it holds a nested list * // The result is undefined if this NestedInteger holds a single integer * const vector&lt;NestedInteger&gt; &amp;getList() const; * &#125;; */class NestedIterator &#123;private: stack&lt;NestedInteger&gt; s;public: NestedIterator(vector&lt;NestedInteger&gt; &amp;nestedList) &#123; for(int i=nestedList.size()-1; i&gt;=0; i--)&#123; s.push(nestedList[i]); &#125; &#125; int next() &#123; auto res = s.top(); s.pop(); return res.getInteger(); &#125; bool hasNext() &#123; while(!s.empty())&#123; NestedInteger top = s.top(); if(top.isInteger()) return true; else&#123; s.pop(); vector&lt;NestedInteger&gt; list = top.getList(); for(int i=list.size()-1; i&gt;=0; i--)&#123; s.push(list[i]); &#125; &#125; &#125; return false; &#125;&#125;;/** * Your NestedIterator object will be instantiated and called as such: * NestedIterator i(nestedList); * while (i.hasNext()) cout &lt;&lt; i.next(); */ 解法二: deque时间复杂度: $O(n)$, 每个节点至多遍历一次, 其中, next() 复杂度为 $O(1)$, 初始化和 hasNext() 的复杂度均为 $O(n)$空间复杂度: $O(n)$, 双端队列所需空间 同样的思路, 也可以用双端队列解决.(栈有的功能双端队列也有) 344. Reverse StringDescription: 反转字符串Write a function that takes a string as input and returns the string reversed. Example 1:12Input: &quot;hello&quot;Output: &quot;olleh&quot; Example 2:12Input: &quot;A man, a plan, a canal: Panama&quot;Output: &quot;amanaP :lanac a ,nalp a ,nam A&quot; 解法一: 使用 reverse 函数时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567class Solution &#123;public: string reverseString(string s) &#123; std::reverse(s.begin(), s.end()); return s; &#125;&#125;; 解法二: 基于 swap时间复杂度: $O(n)$空间复杂度: $O(1)$ 12345678910class Solution &#123;public: string reverseString(string s) &#123; int len = s.size(); for(int i=0; i&lt;len/2; i++)&#123; std::swap(s[i], s[len-1-i]); &#125; return s; &#125;&#125;; 347. Top K Frequent ElementsDescription: 寻找频率最高的 k 个数字Given a non-empty array of integers, return the k most frequent elements. Example 1:12Input: nums = [1,1,1,2,2,3], k = 2Output: [1,2] Example 2:12Input: nums = [1], k = 1Output: [1] Note:You may assume k is always valid, 1 ≤ k ≤ number of unique elements.Your algorithm’s time complexity must be better than O(n log n), where n is the array’s size. 解法一: 哈希+大顶堆时间复杂度: $O(n+nlogn)=O(nlogn)$, 遍历复杂度为 $O(n)$, 堆排序复杂度为 $O(nlogn)$空间复杂度: $O(n+n) = O(n)$, unordered_map 和 priority_queue 各占 $O(n)$ 大小的空间 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; hash; priority_queue&lt;pair&lt;int, int&gt;&gt; q; vector&lt;int&gt; res; for(auto num : nums) hash[num]++; //对于不存在的关键字, 其值默认为0 for(auto it:hash) q.push(&#123;it.second, it.first&#125;); // 注意, sceond在前作为排序依据 for(int i=0 ; i&lt;k; i++)&#123; res.push_back(q.top().second); q.pop(); // 注意, 因为插入的时候将first插在了第二位, 因此, 获取时应该用second获取数字 &#125; return res; &#125;&#125;; 解法二: 哈希+小顶堆时间复杂度: $O(n+nlogk)=O(nlogk)$, 遍历复杂度为 $O(n)$, 堆排序时, 用小顶堆, 只保存最大的 k 个元素即可.空间复杂度: $O(n+n) = O(n)$, unordered_map 和 priority_queue 各占 $O(n)$ 大小的空间 整体思路和解法一相同, 只不过我们需要得到最大的 $k$ 个元素即可, 因此无需维护 $n$ 大小的大顶堆. 相反, 我们选择维护 $k$ 大小的小顶堆, 对于任意一个新来的元素, 如果它大于堆顶, 则将堆顶退出, 然后将新来元素加入堆中. 因为小顶堆的堆顶是最小的元素, 因此堆中用于 $k-1$ 个比堆顶大的元素, 故这 $k$ 个元素就是最大的 $k$ 个元素, 最终我们只需要将堆中数据依次取出, 然后执行一次 reverse() 即可. 12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; hash; // 注意这里小顶堆的定义, 其元素是 pair 类型 priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int,int&gt;&gt;, std::greater&lt;pair&lt;int,int&gt;&gt;&gt; q; // 小顶堆 vector&lt;int&gt; res; for(auto num : nums) hash[num]++; //对于不存在的关键字, 其值默认为0 for(auto it : hash)&#123; // 注意, 必须是遍历哈希表, 而不能遍历原数组, 因为原数组存在重复数字 if(q.size() &lt; k) q.push(&#123;it.second, it.first&#125;); else if(q.top().first &lt; it.second)&#123; q.pop(); q.push(&#123;it.second, it.first&#125;); &#125; &#125; for(int i=0 ; i&lt;k; i++)&#123; res.push_back(q.top().second); q.pop(); &#125; std::reverse(res.begin(), res.end()); //因为结果是从小顶堆中得到的, 所以需要逆置一下, 也可以不逆置 return res; &#125;&#125;; 解法三: 哈希+桶时间复杂度: $O(n+n+k)=O(n)$, 构建哈希表, 构建桶, 从桶找到 $k$ 个最大数字的复杂度分别为: $O(n)$, $O(n)$, 和 $O(k)$.空间复杂度: $O(n+n) = O(n)$, 哈希表和桶各占 $O(n)$ 当我们拥有关于元素频率的哈希表以后, 我们可以利用此表构建桶结构, 桶的 “关键字” 为元素频率, 之后, 我们可以用 $O(n)$ 的复杂度对桶进行遍历, 当找到 $k$ 个最大元素时, 跳出遍历循环, 代码如下: 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; hash; // 哈希 for(auto &amp;num : nums) hash[num]++; vector&lt;vector&lt;int&gt;&gt; buckets(nums.size()+1); // 根据数组的大小申请桶的空间, 多申请一个是为了方便下标对齐 for(auto h : hash) buckets[h.second].push_back(h.first); // 用频率来做桶的索引, 并且对应数字放入桶中 vector&lt;int&gt; res; for(int i=buckets.size()-1; i&gt;=0; i--)&#123; // 最后往前遍历, 寻找频率最高的k个元素 vector&lt;int&gt; bucket = buckets[i]; for(auto &amp; num : bucket)&#123; res.push_back(num); if(res.size() &gt;= k) return res; // 找到k个元素, 直接返回并退出 &#125; &#125; &#125;&#125;; 350. Intersection of Two Arrays IIDescription: 求两数组的交集Given two arrays, write a function to compute their intersection. Example 1:12Input: nums1 = [1,2,2,1], nums2 = [2,2]Output: [2,2] Example 2:12Input: nums1 = [4,9,5], nums2 = [9,4,9,8,4]Output: [4,9] Note:Each element in the result should appear as many times as it shows in both arrays.The result can be in any order. Follow up: What if the given array is already sorted? How would you optimize your algorithm? What if nums1’s size is small compared to nums2’s size? Which algorithm is better? What if elements of nums2 are stored on disk, and the memory is limited such that you cannot load all elements into the memory at once? 解法一: 哈希时间复杂度: $O(n1+n2)$, 构建哈希表和查询哈希表, 需要将两数组的元素都遍历一次空间复杂度: $O(n1)$, 用 nums1 构建哈希表, 然后用 nums2 进行查询.(也可以多做一步判断, 选择用数组长度较小数组来构建哈希表, 减少空间复杂度) 用一个数组构建哈希表, 哈希表的键为元素值, 哈希表的值为元素的出现次数, 然后用另一个数组的元素对哈希表进行查询, 如果能找到, 则将该元素加入结果数组 res, 并将哈希表对应键的值减一, 如果减到零, 则删除该键. 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; unordered_map&lt;int, int&gt; hash; // 构建哈希 for(auto &amp;num : nums1) hash[num]++; vector&lt;int&gt; res; for(auto &amp;num : nums2)&#123; if(hash.find(num) != hash.end())&#123; res.push_back(num); hash[num]--; if(hash[num]==0) hash.erase(num); // 当键对应值为0时, 将该键擦除 &#125; &#125; return res; &#125;&#125;; 解法二: 排序时间复杂度: $O(n1logn1 + n2logn2 + n1 + n2) = max(n1, n2)\times log(max(n1, n2))$空间复杂度: $O(1)$ 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; std::sort(nums1.begin(), nums1.end()); std::sort(nums2.begin(), nums2.end()); int i1=0, i2=0; // 设置两个指示变量 vector&lt;int&gt; res; while(i1&lt;nums1.size() &amp;&amp; i2&lt;nums2.size())&#123; if(nums1[i1] == nums2[i2])&#123; res.push_back(nums1[i1]); i1++; i2++; &#125;else if(nums1[i1] &lt; nums2[i2]) i1++; else i2++; &#125; return res; &#125;&#125;; Follow up当给定数组已经有序时可以设置两个指示变量, 分别指向两个数组, 然后按照指向元素的大小关系进行判断并递进, 这样, 时间复杂度为 $O(n1+n2)$, 空间复杂度为 $O(1)$, 代码可见解法二. 当 nums1 远远小于 nums2 时正如前面所说, 选用元素数量较少的数组来构建哈希表, 可以降低空间复杂度 如果 nums2 存放在磁盘上, 同时内存不足以加载整个 nums2 数组将 nums2 分片, 逐个求交集, 最后再合并 371. Sum of Two IntegersDescription: 不用加减乘除做加法Calculate the sum of two integers a and b, but you are not allowed to use the operator + and -. Example 1:12Input: a = 1, b = 2Output: 3 Example 2:12Input: a = -2, b = 3Output: 1 解法一: 位操作(递归)对于两个数相加, 例如 759+674, 在计算机中我们可以按照如下步骤求解: 不考虑进位, 相加得到 323; 只考虑进位, 进位为 1110; 将上面两个数字相加, 得到 1433, 即为最终结果 因此, 我们可以用 异或 求得不考虑进位的加, 用 与操作 来得到当前数字的进位, 由于进位与数字相加后, 有可能产生新的进位, 所以我们还要假设将新的进位加上, 直到进位位为0, 此时可以此时返回当前的和, 代码如下所示 123456789class Solution &#123;public: int getSum(int a, int b) &#123; if(b==0) return a ; // 如果进位为0, 则可直接返回 int sum = a ^ b; // 计算不带进位的加法 int carry = (a &amp; b) &lt;&lt; 1; // 计算进位 return getSum(sum, carry); // 结合并返回 &#125;&#125;; 上面的代码可以简化成一行: 123456class Solution &#123;public: int getSum(int a, int b) &#123; return b==0 ? a : getSum(a^b, (a&amp;b)&lt;&lt;1); &#125; &#125;; 解法二: 位操作(迭代)思路和解法一相同, 只不过写成了迭代的形式 1234567891011class Solution &#123;public: int getSum(int a, int b) &#123; while(b!=0)&#123; int tmp = a ^ b; // 不考虑进位的加 b = (a&amp;b) &lt;&lt; 1; // 进位 a = tmp; &#125; return a; &#125; &#125;; 378. Kth Smallest Element in a Sorted MatrixDescription: 找到半有序数组中的第 k 小的元素Given a n x n matrix where each of the rows and columns are sorted in ascending order, find the kth smallest element in the matrix. Note that it is the kth smallest element in the sorted order, not the kth distinct element. Example:12345678matrix = [ [ 1, 5, 9], [10, 11, 13], [12, 13, 15]],k = 8,return 13. Note:You may assume k is always valid, 1 ≤ k ≤ n2. 解法一: 堆基于堆的 baseline 解法:最简单的堆解法就是不使用矩阵的有序性质, 直接当成无序数组来做, 我们申请一个 $k$ 大小的大顶堆, 然后遍历矩阵中的所有元素, 如果某元素小于堆顶就将堆顶弹出, 并压入该元素, 最终, 大顶堆的堆顶就是整个矩阵中第 $k$ 小的元素. 该解法的时间复杂度为 $O(nmlogk)$, 空间复杂度为 $O(k)$, 由于没有使用到有序矩阵的性质, 故不做讨论. 更优的基于堆的解法(超屌的解法!): 时间复杂度: $O(klogn)$, $k$ 代表 kth, $n$ 代表矩阵的行数空间复杂度: $O(n)$, 堆的大小, $n$ 代表矩阵的行数 我们需要利用矩阵行列分别有序的性质, 首先, 具体思路如下: 利用将矩阵中每一行的首元素(也就是第一列元素, 同理, 这里也可以用第一行元素)构造一个最小堆(这一步的复杂度小于 $O(nlogn)$), 堆中的元素是一个 pair, 其中 first 为元素的值, second 又是一个 pair, 存储着值的行列坐标 (i, j) 将最小堆中的一个元素弹出(弹出的是当前堆最小的元素), 然后再将弹出元素的同一行的下一个元素(通过元素坐标获取)压入堆, 压入后, 堆会自动排序, 使得最小的元素位于堆顶. 重复步骤(2) k-1 次以后. 我们已经弹出了整个矩阵的最小的 k-1 个元素, 那么现在堆顶中的元素就是第 k 小的元素, 将其返回即可 1234567891011121314151617181920212223242526272829class Solution &#123;public: struct cmp&#123; bool operator()(pair&lt;int, pair&lt;int,int&gt;&gt; &amp;a, pair&lt;int, pair&lt;int,int&gt;&gt; &amp;b)&#123; return a.first &gt; b.first; // 小顶堆 &#125; &#125;; int kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m=matrix[0].size(); priority_queue&lt; pair&lt;int, pair&lt;int, int&gt;&gt;, vector&lt;pair&lt;int, pair&lt;int, int&gt;&gt;&gt;, cmp&gt; min_heap; for(int i=0; i&lt;n; i++)&#123; // 用矩阵每一行的首元素构建堆, 堆的元素组成为&lt;(val, (i,j))&gt; min_heap.push(make_pair(matrix[i][0], make_pair(i, 0))); &#125; int res; while(k--)&#123; int val = min_heap.top().first; int i = min_heap.top().second.first; int j = min_heap.top().second.second; min_heap.pop(); // 弹出堆 res = val; if(j+1&lt;m) // 将同行的下一个元素放入堆 min_heap.push(make_pair(matrix[i][j+1], make_pair(i, j+1))); &#125; return res; &#125;&#125;; 解法二: 二分查找时间复杂度: $O(nlogm\times logD$, $n$ 为矩阵的行数, $m$ 为矩阵的列数, $D$ 为矩阵中最大元素与最小元素之间的差值.空间复杂度: $O(1)$, 没有利用额外空间 算法利用了每一行中, 元素都是有序的这个性质(但是没有用到列有序的性质), 步骤如下: 获取矩阵中元素的最小值 low 和最大值 high 令 mid = (high+low)/2, 然后我们利用 upper_bound() 函数来查找矩阵中第一个大于 mid 的元素(耗时 $O(logn)$), 接着计算这个元素之前的元素数量. 对矩阵的每一行重复这个步骤, 并将所有的元素数量累加起来 如果累加元素数 count &lt; k, 说明, mid 的值较小, 我们令 low=mid+1, 否则, 说明 count&gt;=k, 我们令 high=mid, 注意, 这里的赋值关系最好不要改动, 并且要知道为什么令 high=mid, 而不是 mid-1. 重复上述过程直至 low=high, 此时, low 或 high 的值就是矩阵中第 k 小的值 123456789101112131415161718192021222324252627class Solution &#123;public: int kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m = matrix[0].size(); int low = matrix[0][0]; int high = matrix[n-1][m-1]; //题目中是方阵, 这里故意写成nm的矩阵, 以适应更普通的情况 while(low &lt; high)&#123; int mid = (low+high) / 2; int count = 0; for(int i=0; i&lt;n; i++)&#123; // 找到第一个大于 mid 的数, 然后计算这之前的元素个数 int row_count = std::upper_bound(matrix[i].begin(), matrix[i].end(), mid) - matrix[i].begin(); count += row_count; &#125; if(count &lt; k)&#123; // 注意, 这里不能令小于号来包括等于号时的情况, 因为 (low+high)/2 是偏向左边的, 这样会造成死循环 low = mid + 1; &#125;else&#123; // 当 count&gt;=k 时, 说明 mid之前就能满足 k 个元素, 故令 high=mid; 注意, 这里不要尝试令low=mid high = mid; &#125; // 这里的二分查找不同于普通的数组, 因为 mid 有可能不是数组中的值, 所以即使count=k时, 也不能直接返回mid &#125; return low; // 最终, 当 low=high时, 即为第k小的元素. 因为当, high指向第k小的元素时, 它就不可能再减小, 而只能是low一点点靠近high, 直至相等 &#125;&#125;; 解法三: 二分查找时间复杂度: $O((n+m)logD)$, $n$ 为矩阵行数, $m$ 为矩阵列数, $D$ 为矩阵中元素的最大差值空间复杂度: $O(1)$ 解法二中并没有完全使用到矩阵所有的性质, 考虑到矩阵在列上也是有序的, 我们可以进一步优化算法. 我们应该还记得在剑指offer的第一题中, 考察了这种行列有序数组的元素查找算法, 我们可以在 $O(n+m)$ 的时间里找到指定的元素, 因此, 我们可以利用该算法替换解法二中对每一行执行二分查找的算法, 故而时间复杂度就变成了 $O((n+m)logD)$, 其中, $n$ 为矩阵行数, $m$ 为矩阵列数, $D$ 为矩阵中元素的最大差值, 代码如下. 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m = matrix[0].size(); int low = matrix[0][0], high = matrix[n-1][m-1]; while(low &lt; high)&#123; int mid = (low+high) / 2; int count = search(matrix, mid); // 查找小于等于mid的元素数量 if(count &lt; k) low = mid + 1; else high = mid; &#125; return low; &#125; int search(vector&lt;vector&lt;int&gt;&gt; &amp;matrix, int target)&#123; int n = matrix.size(), m = matrix[0].size(); int i = n-1, j=0; // 从左下角开始 int count=0; // 记录小于等于 target 的元素数量 while(i&gt;=0 &amp;&amp; j&lt;m)&#123; if(matrix[i][j] &lt;= target)&#123; j++; count += i+1; &#125;else&#123; i--; &#125; &#125; return count; &#125;&#125;; 380. Insert Delete GetRandom O(1)Description: 常数时间复杂度的插入,删除,和随机获取Design a data structure that supports all following operations in average O(1) time. insert(val): Inserts an item val to the set if not already present. remove(val): Removes an item val from the set if present. getRandom: Returns a random element from current set of elements. Each element must have the same probability of being returned. Example:1234567891011121314151617181920212223// Init an empty set.RandomizedSet randomSet = new RandomizedSet();// Inserts 1 to the set. Returns true as 1 was inserted successfully.randomSet.insert(1);// Returns false as 2 does not exist in the set.randomSet.remove(2);// Inserts 2 to the set, returns true. Set now contains [1,2].randomSet.insert(2);// getRandom should return either 1 or 2 randomly.randomSet.getRandom();// Removes 1 from the set, returns true. Set now contains [2].randomSet.remove(1);// 2 was already in the set, so return false.randomSet.insert(2);// Since 2 is the only number in the set, getRandom always return 2.randomSet.getRandom(); 解法一: 哈希表+数组时间复杂度: $O(1)$, 符合题意空间复杂度: $O(n)$, 数组和哈希表的大小各为 $O(n)$. 解题思路: 插入: 用数组的 push_back() 存储新来的元素, 同时存入哈希表, key 为元素值, val 为元素在数组中的下标; 删除: 先用哈希表获取元素的下标, 然后将数组中的该元素和数组的最后一个元素交换, 接着用 pop_back() 删除该元素, 然后用 erase() 从哈希表中删除该元素, 最后在哈希表中更新被交换元素的下标; 获取随机元素: 利用 C++ 的内置随机函数 rand() 来获取随机数. 但是注意, rand() 对生成的随机数质量无法保证, 在 C++11 中, 已经建议使用随机数生成设施来替换 rand(). 另外注意: 如果想要使用 srand() 来播种, 那么不能将该语句放在 getRandom() 函数中, 因为重复播种会使得每次生成的随机数都一样, 正确的做法是将其放在构造函数中, 只进行一次播种. 123456789101112131415161718192021222324252627282930313233343536373839404142434445class RandomizedSet &#123;private: vector&lt;int&gt; vec; unordered_map&lt;int, int&gt; hash;public: /** Initialize your data structure here. */ RandomizedSet() &#123; srand(time(0)); &#125; /** Inserts a value to the set. Returns true if the set did not already contain the specified element. */ bool insert(int val) &#123; if(hash.find(val) != hash.end()) return false; vec.push_back(val); hash[val] = vec.size()-1; return true; &#125; /** Removes a value from the set. Returns true if the set contained the specified element. */ bool remove(int val) &#123; if(hash.find(val) == hash.end()) return false; int i = hash[val]; int j = vec.size() - 1; swap(vec[i], vec[j]); vec.pop_back(); // 将元素和最后一位元素交换, 然后在删除, 满足 O(1) 复杂度 hash[vec[i]] = i; hash.erase(val); // 在哈希表中删除指定键值 return true; &#125; /** Get a random element from the set. */ int getRandom() &#123; // srand(time(0)); // 不能放在这里, 要放只能放在构造函数中 return vec[rand()%vec.size()]; // rand 无法保证生成的随机数质量, C++11推荐用随机数生成设施来替换该函数 &#125;&#125;;/** * Your RandomizedSet object will be instantiated and called as such: * RandomizedSet obj = new RandomizedSet(); * bool param_1 = obj.insert(val); * bool param_2 = obj.remove(val); * int param_3 = obj.getRandom(); */ 384. Shuffle an ArrayDescription: 打乱数组Shuffle a set of numbers without duplicates. Example:123456789101112// Init an array with set 1, 2, and 3.int[] nums = &#123;1,2,3&#125;;Solution solution = new Solution(nums);// Shuffle the array [1,2,3] and return its result. Any permutation of [1,2,3] must equally likely to be returned.solution.shuffle();// Resets the array back to its original configuration [1,2,3].solution.reset();// Returns the random shuffling of array [1,2,3].solution.shuffle(); 解法一: 随机交换时间复杂度: $O(n)$, 打乱需要 $O(n)$, reset 为 $O(1)$空间复杂度: $O(n)$ shuffle: 打乱时, 遍历数组的下标, 然后随机生成一个下标, 令二者指向的元素交换. 更多分析请看Knuth shuffle算法 reset: 直接返回缓存的原始数组 123456789101112131415161718192021222324252627282930class Solution &#123;private: vector&lt;int&gt; v;public: Solution(vector&lt;int&gt; nums): v(nums)&#123; std::srand(std::time(0)); &#125; /** Resets the array to its original configuration and return it. */ vector&lt;int&gt; reset() &#123; return v; &#125; /** Returns a random shuffling of the array. */ vector&lt;int&gt; shuffle() &#123; vector&lt;int&gt; sv(v); for(int i=0; i&lt;sv.size(); i++)&#123; int j = i + rand() % (sv.size()-i); //这里生成的 j 只可能在 i 之后 swap(sv[i], sv[j]); &#125; return sv; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(nums); * vector&lt;int&gt; param_1 = obj.reset(); * vector&lt;int&gt; param_2 = obj.shuffle();**/ 387. First Unique Character in a StringDescription: 寻找字符串中的首个不重复字符Given a string, find the first non-repeating character in it and return it’s index. If it doesn’t exist, return -1. Examples:12345s = &quot;leetcode&quot;return 0.s = &quot;loveleetcode&quot;,return 2. Note: You may assume the string contain only lowercase letters. 解法一: 哈希表时间复杂度: $O(n+n)=O(n)$, 第一个 $n$ 用于建立哈希表, 第二个 $n$ 用于查询首个出现次数为 1 的字符, $n$ 为字符串的长度空间复杂度: $O(26)$, 哈希表的大小为字符集的大小 26 (如果是 unicode 字符, 就为 256). 遍历两边字符串, 第一遍构建哈希表, 第二遍按照字符串序列查询, 遇到值 1 的字符出现时, 就将其下标返回 12345678910111213class Solution &#123;public: int firstUniqChar(string s) &#123; unordered_map&lt;char, int&gt; hash; for(auto c : s)&#123; hash[c]++; &#125; for(int i=0; i&lt;s.size(); i++)&#123; if(hash[s[i]]==1) return i; &#125; return -1; &#125;&#125;; 394. 字符串解码题目链接: https://leetcode-cn.com/problems/decode-string/ 解法一: 遍历逐次的遍历字符串, 每次解码一层, 知道所有的数字都被消除为止 12345678910111213141516171819202122232425262728293031323334class Solution: def decodeString(self, s: str) -&gt; str: while True: length = len(s) i = 0 flag = False tmp_s = '' while i &lt; length: if s[i] &lt;= '9' and s[i] &gt;= '0': flag = True # whether have num dup_num = '' while s[i] &lt;= '9' and s[i] &gt;='0': dup_num += s[i] i += 1 dup_num = int(dup_num) i += 1 # skip '[' dup_str = '' pre_num = 0 while s[i] != ']' or pre_num &gt; 0: # get duplicate str in [...] if s[i] == '[': pre_num += 1 elif s[i] == ']': pre_num -= 1 dup_str += s[i] i += 1 for _ in range(dup_num): tmp_s += dup_str else: tmp_s += s[i] i += 1 if flag: # flag = True, have num, continue loop s = tmp_s else: # have no num, compelete decode return s 解法二: 栈涉及到括号匹配类的问题, 一般用栈解决起来比较方便 Python 实现:12345678910111213141516171819202122class Solution: def decodeString(self, s: str) -&gt; str: stack = [] res = '' for c in s: if c != ']': # 不是右括号就一直进栈 stack.append(c) else: string = '' # 先收集要加倍的字符串 while not stack[-1].isdigit(): string = stack.pop() + string times = '' # 再收集加倍倍数 while stack and stack[-1].isdigit(): times = stack.pop() + times if times: # 如果有倍数则加倍 string = string[1:] * int(times) if stack: # 还有没处理完的上级，把处理好的字符串入栈等待处理 #stack += list(string) stack.append(string) else: # 前面的字符串处理完毕了，直接把字符串加入答案 res += string return res + ''.join(stack) # 最后可能有没有右括号收尾的字符串 C++ 实现:1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: string decodeString(string str) &#123; std::stack&lt;std::string&gt; s; std::string res = ""; for (auto c : str) &#123; if (c != ']') &#123; std::string tmp_s = "x"; tmp_s[0] = c; s.push(tmp_s); &#125; else &#123; std::string dup_str = ""; while (!s.empty() and s.top() &lt; "0" or s.top() &gt; "9") &#123; dup_str = s.top() + dup_str; s.pop(); &#125; if (dup_str != "") dup_str = dup_str.substr(1); std::string times = ""; while (!s.empty() and s.top() &lt;= "9" and s.top() &gt;= "0") &#123; times = s.top() + times; s.pop(); &#125; std::string times_str = ""; for (int i = 0; !times.empty() and i &lt; std::stoi(times); i++) &#123; times_str += dup_str; &#125; if (s.empty()) &#123; res += times_str; &#125; else &#123; s.push(times_str); &#125; &#125; &#125; std::string rear_s = ""; while (!s.empty()) &#123; rear_s = s.top() + rear_s; s.pop(); &#125; return res + rear_s; &#125;&#125;; 395. Longest Substring with At Least K Repeating CharactersDescriptionFind the length of the longest substring T of a given string (consists of lowercase letters only) such that every character in T appears no less than k times. Example 1:1234567Input:s = &quot;aaabb&quot;, k = 3Output:3The longest substring is &quot;aaa&quot;, as &apos;a&apos; is repeated 3 times. Example 2:1234567Input:s = &quot;ababbc&quot;, k = 2Output:5The longest substring is &quot;ababb&quot;, as &apos;a&apos; is repeated 2 times and &apos;b&apos; is repeated 3 times. 解法一: 哈希表+位标志时间复杂度: 平均情况下为 $O(n)$, 最坏情况(待查找子串不存在)下为 $O(n^2)$空间复杂度: $O(26 + 1)$, 26 为哈希表的大小, 1 为 mask 的大小. 对于字母集, 可以利用哈希表来实现 $O(n)$ 复杂度的字符数量统计, 我们设置一个变量 mask, 该变量每一个比特位上的值有两种含义: 当某比特位为 1 时, 代表该比特位对应的字母在当前字符子串中的数量小于 k, 反之, 则该比特位为 0. 那么, 只要当 mask=0, 就说明此时的子串符合题目的要求, 我们计算当前子串的长度, 并更新最长长度值, 由于子串必须是连续的, 所以下一个子串的开始字符一定不会在当前子串的结束字符之前, 因为如果这样的话, 就一定会在当前子串的结束字符处终止, 故判断下一个子串时, 我们可以从当前子串结束字符的下一位开始判断. 代码如下: 123456789101112131415161718192021222324252627282930class Solution &#123;public: int longestSubstring(string s, int k) &#123; int n = s.size(); int res = 0; for(int i=0; i+k &lt;= n; )&#123; // i 代表其实字符的位置 int max_end = i; // 注意要把这三行放在第一个for循环内部, 每次都要初始化一次 unsigned int mask = 0; int hash[26] = &#123;0&#125;; for(int j=i; j&lt;n; j++)&#123; // j 代表终止字符的位置, 从 i 开始 int t = s[j] - 'a'; hash[t]++; if(hash[t] &lt; k) mask |= (1&lt;&lt;t); // set t bit to 1 else mask &amp;= (~(1&lt;&lt;t)); //这里外边的括号可以省, 但是位操作最好显式加括号 if(mask == 0)&#123; // 如果mask=0, 说明所有的字符要么没有出现, 要么数量&gt;=k. int length = j-i+1; res = std::max(res, length); max_end = j; &#125; &#125; i = max_end + 1; // 下一个最长的子串的开始一定不会在 i 与 max_end 之间, // 因为如果在这之间, 那么就一定会在 max_end 处终止 &#125; return res; &#125;&#125;; 解法二: 分而治之, 递归时间复杂度: $O(n)$, 最坏情况下为 $O(n)$, 因为递归调用的深度最多为 26, 而每一层的复杂度约为 $O(n)$. (这种说法是网上的说法, 但是这里我个人觉得最坏情况是 $O(n^2), 只不过有的递归调用很快退出, 是的程序运行时间很短)空间复杂度: $O(26+log_{26}n)$, 哈希表空间为, 递归占用空间为 $O(log_{26}n)$. 对于任意的字符串, 我们都执行下面的算法步骤: 根据当前的字符串, 构建相应的哈希表, 表内数据为没一个字符的出现次数, 所以哈希表的大小为 26(或 256); 如果哈希表内所有字符的出现次数都满足条件(出现 0 次出现 k 次以上), 那么当前字符串满足条件, 可直接输出长度 如果字符串中存在不满足条件的字符, 那么就以这些字符 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; int helper(string &amp;s, int l, int r, int k)&#123; int hash[256]=&#123;0&#125;; for(int i=l; i&lt;=r; i++)&#123; // 构建 l,r 范围内的字符数哈希表 hash[s[i]]++; &#125; bool flag = true; for(int i=l; i&lt;=r; i++)&#123; // 如果当前 l, r范围内的字符满足要求, 则直接返回 if(hash[s[i]] &amp;&amp; hash[s[i]] &lt; k)&#123; flag = false; break; &#125; &#125; if(flag) return (r-l+1); int res=0; int i = l; for(int j=l; j&lt;=r; j++)&#123; //以所有不满足条件的字符为分界线, 递归获取前半段和后半段的最长子串长度 if(hash[s[j]] &amp;&amp; hash[s[j]] &lt; k)&#123; res = std::max(res, helper(s, i, j-1, k)); i = j+1; // 这里虽然对于多个相同的不满足条件的字符会进行多次调用 // 但是由于传入的子串很短, 所以会很快接结束调用, 故可忽略不计此次调用 &#125; &#125; return std::max(res, helper(s, i, r, k));// i, r 为最后一段 &#125;public: int longestSubstring(string s, int k) &#123; int l = 0, r = s.size()-1; return helper(s, l, r, k); &#125;&#125;; 解法三: 更简洁的递归时间复杂度: $O(n)$, 最差情况下为 $O(kn)$, 详细见下面的分析空间复杂度: $O(n)$, 哈希+递归 真正的 $O(n)$ 复杂度的实现: 和上面的思路一致, 也是利用不满足条件的字符作为分隔(因为只有符合条件的字符组成的字符串从 有可能 具有正确的长度), 但是不同于上面程序的是, 此次我们只对满足条件的子串进行递归, 故而那些重复的不满足条件的字符不会被重复用于递归(上面的代码就是重复调用了, 因为是在发现 &lt;k 时就进行调用), 下面的代码更加精炼易懂, 我们首先会跳过所有不满足条件的字符, 然后从满足条件的字符开始, 找到连续的满足条件的子串的最后一个字符, 然后对这个子串进行递归调用, 也就是说, 我们最多会进行不超过 k 次递归调用, 因为最坏的情况是 26 个字符中, 只有一个字符不满足条件, 而这个字符最多将字符串分割成 k 段, 如果分割成 k+1 段, 那么就必须用 k 个字符, 此时与假设矛盾. 123456789101112131415161718192021222324252627class Solution &#123; int helper(string &amp;s, int l, int r, int k)&#123; int hash[26] = &#123;0&#125;; for(int i=l; i&lt;=r; i++) hash[s[i]-'a']++; // 构建哈希 int res=0; for(int i=l; i&lt;=r; )&#123; while(i&lt;=r &amp;&amp; hash[s[i]-'a']&lt;k) i++; // 跳过不符合的字符, 注意也要跳过未出现的字符, 所以=0也要跳过 if(i&gt;r) break; // 如果所有字符都不符合, 则直接break int j = i; while(j&lt;=r &amp;&amp; hash[s[j]-'a']&gt;=k) j++; // 找到当前子串中符合条件的最后一个连续字符 j--; // 此时 j 指向的是符合条件字符的下一个位置, 因此, 我们要令 j-- //if(j&gt;r) j=r; // j如果超限, 说明所有字符都符合, 则令 j 指向尾部字符即可 if(i==l &amp;&amp; j==r) return r-l+1; // 当前范围所有字符满足条件, 直接返回长度 res = std::max(res, helper(s, i, j, k)); // 对符合条件的子串进行调用, 最多会进行不超过 k 次调用 i = j+1; // 开始下一个子串的查询 &#125; return res; &#125;public: int longestSubstring(string s, int k) &#123; int l = 0, r = s.size()-1; return helper(s, l, r, k); &#125;&#125;; 上面的边界控制比较麻烦, 下面我们用超尾的方式来进行边界控制, 会使程序更加简洁, 如下所示: 1234567891011121314151617181920212223242526class Solution &#123; int helper(string &amp;s, int begin, int end, int k)&#123; int hash[26] = &#123;0&#125;; for(int i=begin; i&lt;end; i++) hash[s[i]-'a']++; // 构建哈希 int res=0; for(int i=begin; i&lt;end; )&#123; while(i&lt;end &amp;&amp; hash[s[i]-'a']&lt;k) i++; // 跳过不符合的字符, 注意也要跳过未出现的字符, 所以=0也要跳过 if(i==end) break; // 如果所有字符都不符合, 则直接break int j = i; while(j&lt;end &amp;&amp; hash[s[j]-'a']&gt;=k) j++; // 找到当前子串中符合条件的最后一个连续字符 //当使用超尾时, 无需对j特殊处理 if(i==begin &amp;&amp; j==end) return end-begin; // 当前范围所有字符满足条件, 直接返回长度 res = std::max(res, helper(s, i, j, k)); // 对符合条件的子串进行调用, 最多会进行不超过 k 次调用 i = j+1; // 开始下一个子串的查询 &#125; return res; &#125;public: int longestSubstring(string s, int k) &#123; int begin = 0, end = s.size(); return helper(s, begin, end, k); &#125;&#125;; 399. 除法求值题目链接: https://leetcode-cn.com/problems/evaluate-division/ 解法一: 构建有向图先构造图，使用dict实现，其天然的hash可以在in判断时做到O(1)复杂度。 对每个equation如”a/b=v”构造a到b的带权v的有向边和b到a的带权1/v的有向边， 之后对每个query，只需要进行dfs并将路径上的边权重叠乘就是结果了，如果路径不可达则结果为-1。 Python 实现:123456789101112131415161718192021222324252627282930313233class Solution: def calcEquation(self, equations: List[List[str]], values: List[float], queries: List[List[str]]) -&gt; List[float]: graph = dict() # construct a directed graph for (x, y), v in zip(equations, values): if x in graph: graph[x][y] = v else: graph[x] = &#123;y: v&#125; if y in graph: graph[y][x] = 1 / v else: graph[y] = &#123;x: 1/v&#125; def dfs(start, end, graph, visited): if start not in graph or end not in graph: # 如果开始节点或者结束节点不在图中, 则返回 -1 return -1.0 elif start == end: # 开始节点就是结束节点, 则可认为权重为 1 return 1.0 else: for node in graph[start].keys(): # 遍历当前节点的所有下一个节点 if node == end: return graph[start][end] elif node not in visited: # 未被访问 visited[node] = 1 # 加入访问字典 v = dfs(node, end, graph, visited) if v != -1: # 如果能从 node 抵达 end, 则返回该node return graph[start][node] * v return -1.0 # 没有找到路径 返回 -1 res = [] for query in queries: visited = &#123;(query[0]): 1&#125; # 注意要先将开始节点加入到已访问字典中 res.append(dfs(query[0], query[1], graph, visited)) return res C++ 实现:12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; double dfs(string start, string end, unordered_map&lt;string, unordered_map&lt;string, double&gt;&gt; graph, unordered_set&lt;string&gt; visited) &#123; if (graph.find(start) == graph.end() or graph.find(end) == graph.end()) &#123; return -1.0; &#125; else if (start == end) &#123; return 1.0; &#125; else &#123; for (auto const&amp; node : graph[start]) &#123; if (node.first == end) &#123; return node.second; break; &#125; else if (visited.find(node.first) == visited.end()) &#123; visited.insert(node.first); auto v = dfs(node.first, end, graph, visited); if (v != -1) &#123; return node.second * v; &#125; &#125; &#125; &#125; return -1.0; &#125;public: vector&lt;double&gt; calcEquation(vector&lt;vector&lt;string&gt;&gt;&amp; equations, vector&lt;double&gt;&amp; values, vector&lt;vector&lt;string&gt;&gt;&amp; queries) &#123; // 构建有向图 unordered_map&lt;string, unordered_map&lt;string, double&gt;&gt; graph; int n = values.size(); for (int i = 0; i &lt; n; i++) &#123; auto node1 = equations[i][0]; auto node2 = equations[i][1]; auto weight = values[i]; graph[node1][node2] = weight; graph[node2][node1] = 1.0 / weight; &#125; std::vector&lt;double&gt; res; for (auto const &amp;query : queries) &#123; std::unordered_set&lt;string&gt; visited&#123;query[0]&#125;; // 已访问节点 res.emplace_back(dfs(query[0], query[1], graph, visited)); &#125; return res; &#125;&#125;; 解法二: 并查集406. 根据身高重建队列题目链接: https://leetcode-cn.com/problems/queue-reconstruction-by-height/ 解法一: 排序根据题目要求, 排序，然后插入。 假设候选队列为 A，已经站好队的队列为 B. 从 A 里挑身高最高的人 x 出来，插入到 B. 因为 B 中每个人的身高都比 x 要高，因此 x 插入的位置，就是看 x 前面应该有多少人就行了。比如 x 前面有 5 个人，那 x 就插入到队列 B 的第 5 个位置。 C++ 实现:12345678910111213141516171819202122232425262728bool my_sort2(std::vector&lt;int&gt; vec1, std::vector&lt;int&gt; vec2) &#123; // 自定义函数必须写在最外面, 否则无法通过 if (vec1[0] == vec2[0]) &#123; return vec1[1] &lt; vec2[1]; &#125; else return vec1[0] &gt; vec2[0];&#125;class Solution &#123;public: struct &#123; bool operator() (std::vector&lt;int&gt; vec1, std::vector&lt;int&gt; vec2) &#123; if (vec1[0] == vec2[0]) &#123; return vec1[1] &lt; vec2[1]; &#125; else return vec1[0] &gt; vec2[0]; &#125; &#125; my_sort; // 匿名结构体变量 vector&lt;vector&lt;int&gt;&gt; reconstructQueue(vector&lt;vector&lt;int&gt;&gt;&amp; people) &#123; std::sort(people.begin(), people.end(), my_sort); // 排序, 按照 h 降序, k 升序 //std::sort(people.begin(), people.end(), my_sort2); //与上面一行等价 std::vector&lt;std::vector&lt;int&gt;&gt; res; for (auto vec : people) &#123; res.insert(res.begin()+vec[1], vec); // 按照 k 进行插入 &#125; return res; &#125;&#125;; Python 实现:1234567class Solution: def reconstructQueue(self, people: List[List[int]]) -&gt; List[List[int]]: people.sort(key = lambda x: [-x[0], x[1]]) res = [] for p in people: res.insert(p[1], p) return res 412. Fizz BuzzDescription: 输出指定字符串Write a program that outputs the string representation of numbers from 1 to n. But for multiples of three it should output “Fizz” instead of the number and for the multiples of five output “Buzz”. For numbers which are multiples of both three and five output “FizzBuzz”. Example:1234567891011121314151617181920n = 15,Return:[ &quot;1&quot;, &quot;2&quot;, &quot;Fizz&quot;, &quot;4&quot;, &quot;Buzz&quot;, &quot;Fizz&quot;, &quot;7&quot;, &quot;8&quot;, &quot;Fizz&quot;, &quot;Buzz&quot;, &quot;11&quot;, &quot;Fizz&quot;, &quot;13&quot;, &quot;14&quot;, &quot;FizzBuzz&quot;] 解法一: 条件判断直接输出时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617class Solution &#123;public: vector&lt;string&gt; fizzBuzz(int n) &#123; vector&lt;string&gt; res; for(int i=1; i&lt;=n; i++)&#123; if(i%15==0) res.push_back("FizzBuzz"); else if(i%5==0) res.push_back("Buzz"); else if(i%3==0) res.push_back("Fizz"); else res.push_back(std::to_string(i)); &#125; return res; &#125;&#125;; 416. 分割等和子集题目链接: https://leetcode-cn.com/problems/partition-equal-subset-sum/ 解法: 动态规划先求得需要划分的子集的元素和target, 构建长度为len(target)的dp数组, 进行两层循环, 第一层循环nums, 第二层循环dp, dp[j]表示在当前num之前, 是否可以选取一部分数字, 其和为j. Python 实现:123456789101112131415class Solution: def canPartition(self, nums: List[int]) -&gt; bool: s = sum(nums) if (s % 2 == 1): return False target = s // 2 dp = [False] * (target+1) dp [0] = True # base case for num in nums: for j in range(target, 0, -1): if j &gt;= num: dp[j] = dp[j] or dp[j-num] else: break return dp[-1] C++ 实现:1234567891011121314151617181920class Solution &#123;public: bool canPartition(vector&lt;int&gt;&amp; nums) &#123; int s = 0; for (auto num : nums) s += num; if (s % 2 == 1) return false; int target = s / 2; std::vector&lt;bool&gt; dp(target+1, false); dp[0] = true; for (auto num : nums) &#123; for (int j = target; j &gt; 0; j--) &#123; if (j &gt;= num) dp[j] = dp[j] or dp[j-num]; else break; &#125; &#125; return dp[target]; &#125;&#125;; 438. 找到字符串中所有字母异位词题目链接: https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/ 解法一: 滑动窗口将目标字符串的值加起来, 组成target, 只有窗口内部的元素和等于该target, 说明就是字母异位词. 维持窗口大小不变, 同步移动窗口, 继续进行判断. 时间复杂度为 $O(n)$, 因为每个字母至多判断一次. C++ 实现:12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;int&gt; findAnagrams(string s, string p) &#123; std::unordered_map&lt;char, int&gt; hash; int target = 0; for (auto c : p) &#123; target += int(c); hash[c]++; &#125; int start = 0; int end = 0; int sum = 0; while (end &lt; p.size() and end &lt; s.size()) &#123; // 先判断到窗口大小处, 注意, s 有可能长度小于 p, 因此也要做判断 if (hash.find(s[end]) != hash.end()) &#123; sum += int(s[end]); &#125; end++; &#125; std::vector&lt;int&gt; res; if (sum == target) res.emplace_back(start); // 第一个窗口内元素符合要求, 加入结果 while (end &lt; s.size()) &#123; // 移动窗口, 并判断窗口内元素是否符合要求 if (hash.find(s[end]) != hash.end()) &#123; sum += int(s[end]); &#125; if (hash.find(s[start]) != hash.end()) &#123; sum -= int(s[start]); &#125; end++; start++; if (sum == target) res.emplace_back(start); &#125; return res; &#125;&#125;; Python 实现: 注意在 Python 中如果想要获取一个字符的 ASCII 编码, 则需要使用ord(), 直接使用int强制类型转换, 无法得到 ASCII 编码, 因为在 Python 中, int(&#39;5&#39;) = 51234567891011121314151617181920212223class Solution: def findAnagrams(self, s: str, p: str) -&gt; List[int]: d = &#123;c:1 for c in p&#125; target = 0 for c in p: target += ord(c) start = 0 end = 0 res = [] cur_sum = 0 while (end &lt; len(p) and end &lt; len(s)): if s[end] in d: cur_sum += ord(s[end]) end += 1 if (target == cur_sum): res.append(start) while (end &lt; len(s)): if s[end] in d: cur_sum += ord(s[end]) if s[start] in d: cur_sum -= ord(s[start]) end += 1 start += 1 if (target == cur_sum): res.append(start) return res 442. 数组中重复的数据题目链接: https://leetcode-cn.com/problems/find-all-duplicates-in-an-array/ 解法一: 用当前的值作为索引对于任意一个数字num, 我们可以用起作为索引, 然后在nums数组内部构建相应的哈希表, 数字第一次出现时, 将目标位置的值置为负数, 置成负数的好处是, 我们仍然可以用绝对值的方式无损失的获取的该值的原始值, 这会, 第二次如果遇到已经是负数的, 说明是之前已经出现过的, 于是可以直接将其加入到结果中, 这样, 只需进行一次遍历, 同时不使用额外的空间. Python 实现:12345678910class Solution: def findDuplicates(self, nums: List[int]) -&gt; List[int]: res = [] for num in nums: key = abs(num)-1 # 由于下面会修改 nums 里面的值, 因此这里需要用abs获取其绝对值 if nums[key] &gt; 0: # 如果 "哈希" 中不存在该值 nums[key] = -nums[key] # 向 "哈希" 中添加新的键 else: # 如果已经存在该值, 说明出现了两次 res.append(abs(num)) return res C++ 实现:123456789101112131415class Solution &#123;public: vector&lt;int&gt; findDuplicates(vector&lt;int&gt;&amp; nums) &#123; std::vector&lt;int&gt; res; for (auto num : nums) &#123; int key = std::abs(num)-1; if (nums[key] &gt; 0) &#123; nums[key] = -nums[key]; &#125; else &#123; res.emplace_back(std::abs(num)); &#125; &#125; return res; &#125;&#125;; 448. 找到所有数组中消失的数字题目链接: https://leetcode-cn.com/problems/find-all-numbers-disappeared-in-an-array/ 数字归位遍历第一遍把数字放到与它自身值对应的下标上, 如 3 放到 nums[2] 处, 遍历第二次, 如果值与下标不对应, 则说明该数字丢失. Python 实现:123456789101112131415class Solution: def findDisappearedNumbers(self, nums: List[int]) -&gt; List[int]: i = 0 res = [] while (i &lt; len(nums)): if nums[i] == i+1 or nums[nums[i]-1] == nums[i]: # 如果当前位置以及符合, 或者目标位置以及符合, 则不进行交换 i += 1 continue else: # 否则进行交换 target_i = nums[i] -1 # 交换时, 先求得目标位置, 然后再交换, 错误写法: nums[i], nums[nums[i]-1] = nums[nums[i]-1], nums[i] nums[i], nums[target_i] = nums[target_i], nums[i] #return [i for i, num in enumerate(nums, 1) if i != num] # 与下面三行等价 for i, num in enumerate(nums, 1): if i != num: res.append(i) return res C++ 实现:1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; findDisappearedNumbers(vector&lt;int&gt;&amp; nums) &#123; std::vector&lt;int&gt; res; int i = 0; while (i &lt; nums.size()) &#123; if (nums[i] == i+1 or nums[nums[i]-1] == nums[i]) &#123; i++; continue; &#125; else &#123; int target_i = nums[i]-1; std::swap(nums[i], nums[target_i]); &#125; &#125; for (int i = 0; i &lt; nums.size(); i++) &#123; if (nums[i] != i+1) res.emplace_back(i+1); &#125; return res; &#125;&#125;; 解法二: 置负数我们将当前值所对于的下标置为负数, 这样, 一次遍历过后, 数组中正数的地方就是缺少的数字. Python 实现:12345678class Solution: def findDisappearedNumbers(self, nums: List[int]) -&gt; List[int]: i = 0 res = [] for i in range(len(nums)): target_i = abs(nums[i])-1 nums[target_i] = -abs(nums[target_i]) return [i for i, num in enumerate(nums, 1) if num &gt; 0] C++ 实现:1234567891011121314class Solution &#123;public: vector&lt;int&gt; findDisappearedNumbers(vector&lt;int&gt;&amp; nums) &#123; std::vector&lt;int&gt; res; for (int i = 0; i &lt; nums.size(); i++) &#123; int target_i = std::abs(nums[i]) - 1; nums[target_i] = -std::abs(nums[target_i]); &#125; for (int i = 0; i &lt; nums.size(); i++) &#123; if (nums[i] &gt; 0) res.emplace_back(i+1); &#125; return res; &#125;&#125;; 扩展题型扩展: 数组中每个元素出现的可能次数是 n 次,求出数组中出现此次为偶数（奇数）次的元素（出现 0 次也算偶数次）。 上述的解法二可以扩展到解此题, 只需修改一行, 注意出现0次也算是出现偶数次. 12345678910111213141516171819class Solution(object): def findDisappearedNumbers(self, nums): """ :type nums: List[int] :rtype: List[int] """ # 将所有正数作为数组下标，置对应数组值为相反数。那么，仍为正数的位置即为出现偶数次(未出现是0次，也是偶数次)数字。 # 举个例子： # 原始数组：[1, 1, 1, 1, 2, 3, 4, 5] # 重置后为：[1, -1, -1, -1, -2, 3, 4, 5] # 结论：[1,3,5,6] 分别对应的index为[1,6,7,8]（消失的数字） for num in nums: index = abs(num) - 1 # 保持nums[index]为相反数,唯一和上面的解法不同点就是这里，好好体会 nums[index] = -nums[index] #偶数次 return [i + 1 for i, num in enumerate(nums) if num &gt; 0] #奇数次 return [i + 1 for i, num in enumerate(nums) if num &lt; 0] 454. 4Sum IIDescription: 4 数之和为零的可能组合数Given four lists A, B, C, D of integer values, compute how many tuples (i, j, k, l) there are such that A[i] + B[j] + C[k] + D[l] is zero. To make problem a bit easier, all A, B, C, D have same length of N where 0 ≤ N ≤ 500. All integers are in the range of -228 to 228 - 1 and the result is guaranteed to be at most 231 - 1. Example:12345678910111213Input:A = [ 1, 2]B = [-2,-1]C = [-1, 2]D = [ 0, 2]Output:2Explanation:The two tuples are:1. (0, 0, 0, 1) -&gt; A[0] + B[0] + C[0] + D[1] = 1 + (-2) + (-1) + 2 = 02. (1, 1, 0, 0) -&gt; A[1] + B[1] + C[0] + D[0] = 2 + (-1) + (-1) + 0 = 0 解法一: 先求两两之和时间复杂度: $O(n^2+n^2)=O(n^2)$, 前者为 A, B 两两和的复杂度, 后者为 C, D 两两和的复杂度.空间复杂度: $O(n^2)$, 哈希表占用的空间 先求 A 与 B 的两两之和, 并将和作为键存于哈希表中, 哈希表中的值为和的出现次数, 然后再求 C, D 的两两之和, 同时查询哈希表中是否存在 C, D 和的负数, 若存在, 则说明可以组成零. 代码如下: 12345678910111213141516171819class Solution &#123;public: int fourSumCount(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B, vector&lt;int&gt;&amp; C, vector&lt;int&gt;&amp; D) &#123; unordered_map &lt;int, int&gt; hash; for(auto a : A)&#123; for(auto b : B)&#123; hash[a+b]++; &#125; &#125; int res = 0; for(auto c : C)&#123; for(auto d : D)&#123; int target = -(c+d); res += hash[target]; &#125; &#125; return res; &#125;&#125;; 543. 二叉树的路径题目链接: https://leetcode-cn.com/problems/diameter-of-binary-tree/ 解法一: 递归, 后序遍历C++ 实现:123456789101112131415161718192021222324/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123; int traverseTree(TreeNode* root, int &amp;res) &#123; if (root == nullptr) return 0; int left_len = traverseTree(root-&gt;left, res); int right_len = traverseTree(root-&gt;right, res); res = std::max(res, left_len+right_len); return std::max(left_len, right_len) + 1; &#125;public: int diameterOfBinaryTree(TreeNode* root) &#123; int res = 0; traverseTree(root, res); return res; &#125;&#125;; Python 实现:123456789101112131415161718# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def diameterOfBinaryTree(self, root: TreeNode) -&gt; int: def traverseTree(root, res): if root == None: return 0 l = traverseTree(root.left, res) r = traverseTree(root.right, res) res[0] = max(res[0], l+r) return max(l, r) + 1 res = [0] # 这里使用列表是为了将 res 作为可变对象进行传递 traverseTree(root, res) return res[0] 解法二: 迭代, 后序遍历貌似不是很好写, 较好的办法是修改树节点的结构体, 使之能够保存左右子树的最深深度. 否则, 非递归后序遍历时, 无法知道当前节点的左右子树深度, 就无法直接获取路径. 560. 和为 K 的子数组题目链接: https://leetcode-cn.com/problems/subarray-sum-equals-k/ 解法一: 哈希表时间复杂度: $O(n)$空间复杂度: $O(1)$ 只需遍历一次数组, 遍历的时候, 计算从第 0 个元素到当前元素的累加和, 同时用哈希表保存出现过的累加和的次数, 然后利用 sum-k 得到 target, 即为 dp[j], 那么就有 dp[i] - dp[j] = sum[i, j], 所以可以直接将哈希表中 target 的出现次数加到最终的结果变量中, 代码实现如下: Python 实现:12345678910111213class Solution: def subarraySum(self, nums: List[int], k: int) -&gt; int: if len(nums) == 0: return 0 dp = 0 sum_dict = &#123;0: 1&#125; # 首先在字典中存放一个0, 这样可以保证 0~i 的数组被考虑到 res = 0 for i, num in enumerate(nums): dp = dp + num # 计算 [0~i] 的数组和 target = dp - k # 计算 dp[i] 需要减去多少才能变成 k, 也就是找到 dp[j], dp[i] - dp[j] = [j+1, i] if target in sum_dict: # 如果字典中有 dp[j], 那么就将 dp[j] 的个数加到最终的结果中 res += sum_dict[target] sum_dict[dp] = sum_dict.get(dp, 0) + 1 # 将 dp[i] 存入到字典中, 值为 dp[i] 的出现次数 return res C++ 实现1234567891011121314151617class Solution &#123;public: int subarraySum(vector&lt;int&gt;&amp; nums, int k) &#123; std::unordered_map&lt;int, int&gt; hash&#123;&#123;0, 1&#125;&#125;; int dp = 0; int res = 0; for (auto num : nums) &#123; dp += num; int target = dp - k; if (hash.find(target) != hash.end()) &#123; res += hash[target]; &#125; hash[dp] += 1; &#125; return res; &#125;&#125;; 621. 任务调度器题目链接: https://leetcode-cn.com/problems/task-scheduler/ 解法一: 以最多的任务作为依据首先, 找到出现频率最高的任务, 然后在完成该任务时穿插完成其他任务, 根据任务的冷却时间不同, 分为两种情况: 次数最多的任务 A 的冷却时间大于其他任务的循环时间, 那么最小时间就是任务 A 全部执行完毕的时间: $(A - 1)\times(n + 1) + count_max$ 任务 A 的冷却时间小于其他任务的循环时间, 那么这个时间连次数最多的任务 A 都没有等待时间了, 所以其他所有的任务都可以完美紧密执行, 而不需要进行等待, 因此总时间就是len(tasks) Python 实现: 123456789101112class Solution: def leastInterval(self, tasks: List[str], n: int) -&gt; int: task_dict = &#123;&#125; for task in tasks: task_dict[task] = task_dict.get(task, 0) + 1 time = 0 max_num = max(task_dict.values()) count = 0 for v in task_dict.values(): if v == max_num: count += 1 min_time = (max_num-1)*(n+1) + count return max(min_time, len(tasks)) C++ 实现: 123456789101112131415161718class Solution &#123;public: int leastInterval(vector&lt;char&gt;&amp; tasks, int n) &#123; std::unordered_map&lt;char, int&gt; hash; int max_num = 0; for (auto c : tasks) &#123; hash[c]++; max_num = std::max(hash[c], max_num); &#125; int count = 0; for (auto item : hash) &#123; if (item.second == max_num) &#123; count++; &#125; &#125; return std::max((max_num-1) * (n+1) + count, int(tasks.size())); &#125;&#125;; 647. 回文子串题目链接: https://leetcode-cn.com/problems/palindromic-substrings/ 数有多少个回文子串 解法一: 扩展中心法时间复杂度 $O(n^2)$, 题目字符串长度不超过 1000, 因此复杂度满足题目要求, 我们将字符首尾插入两个不同的字符, 然后在所有字符中间插入相同的字符, 这样就可以避免判断回文串的奇偶长度了, 具体看下面的代码实现 Python 实现:123456789class Solution: def countSubstrings(self, s: str) -&gt; int: ss = '#'.join(list('$' + s + '@')) # 前后字符不一样可以帮助判断是否已经到了边界, 用 # 连接字符可以省去奇偶判断 count = 0 for i in range(1, len(ss)-1): l = 1 while (ss[i+l] == ss[i-l]): l += 1 # 先求导回文串的长度+1 count += l // 2 # 取整除法, 获得包含的回文子串个数 return count C++ 实现:123456789101112131415161718class Solution &#123;public: int countSubstrings(string s) &#123; s = '$' + s; std::vector&lt;char&gt; ss(2*s.size()+1, '@'); for (int i = 0; i &lt; ss.size()-1; i+=2) &#123; ss[i] = s [i/2]; ss[i+1] = '#'; &#125; int count = 0; for (int i = 1; i &lt; ss.size()-1; i++) &#123; int l = 1; while (ss[i+l] == ss[i-l]) l++; count += l / 2; &#125; return count; &#125;&#125;; 解法二: Manacher 算法Manacher 算法的时间复杂度接近于 $O(n)$ 这道题实际上就是求最长回文串的变形, 不同之处仅在于当求出每一个回文串的长度之后, 需要将相应的回文子串的数量添加到最终的结果中, 其余地方相同. 关于 Manacher 算法的详细讲解可以查看第 005 题, 本题的代码实现如下所示: Python 实现:1234567891011121314151617181920class Solution: def countSubstrings(self, s: str) -&gt; int: ss = '#'.join(list('$' + s + '@')) # 前后字符不一样可以帮助判断是否已经到了边界, 用 # 连接字符可以省去奇偶判断 p_len = [0] * len(ss) # 记录每个字符的回文串长度 count = 0 # 记录回文子串的个数 P = 0 # 记录回文串最右边所能到达的边界 center = 0 # 记录最右边回文串对应的中心 for i in range(1, len(ss)-1): if i &lt; P: l = min(P-i, p_len[center-(i-center)]) # l 为 P-i, 及center对应i的长度的较小者 while (ss[i-l] == ss[i+l]): l+=1 else: # 如果 i &gt; P, 就只能老老实实的使用中心扩展法 l = 1 while (ss[i-l] == ss[i+l]): l += 1 if (P &lt; i+l-1): # 更新 P, center P = i+l-1 center = i p_len[i] = l-1 # 更新 len count += l // 2 return count C++ 实现:123456789101112131415161718192021222324252627282930class Solution &#123;public: int countSubstrings(string s) &#123; s = '$' + s; std::vector&lt;char&gt; ss(2*s.size()+1, '@'); std::vector&lt;int&gt; p_len(ss.size(), 0); int P = 0, center = 0, count = 0; for (int i = 0; i &lt; ss.size()-1; i+=2) &#123; ss[i] = s [i/2]; ss[i+1] = '#'; &#125; for (int i = 1; i &lt; ss.size()-1; i++) &#123; int l; if (i &lt; P) &#123; // i &lt; P, 可以利用之前的计算结果 l = std::min(P-i, p_len[center - (i-center)]); while (ss[i+l] == ss[i-l]) l++; &#125; else &#123; // 否则只能使用中心扩展法 l = 1; while (ss[i+l] == ss[i-l]) l++; &#125; if (P &lt; l-1) &#123; // 更新 P 和 center P = i+l-1; center = i; &#125; p_len[i] = l-1; // 更新 len count += l / 2; &#125; return count; &#125;&#125;; 714. 买卖股票的最佳时机含手续费题目链接: https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/ 解法: 通用 DP 解法需要注意的是每次买入时需要多花费一笔手续费, 其他地方与无限次的买卖股票完全一致. Python 实现:1234567class Solution: def maxProfit(self, prices: List[int], fee: int) -&gt; int: if len(prices) &lt;= 1: return 0 dp = [-prices[0]-fee, 0] # base case: hold+fee, not_hold for price in prices[1:]: dp = [max(dp[0], dp[1]-price-fee), max(dp[1], dp[0]+price)] # 不要忘了买入时的手续费 return dp[1] C++ 实现:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices, int fee) &#123; if (prices.size() &lt;= 1) return 0; std::pair&lt;int, int&gt; dp = &#123;-prices[0]-fee, 0&#125;; for (int i=1; i&lt;prices.size(); i++) &#123; int hold = std::max(dp.first, dp.second-prices[i]-fee); int not_hold = std::max(dp.second, dp.first+prices[i]); dp.first = hold; dp.second = not_hold; &#125; return dp.second; &#125;&#125;; 739. 每日温度题目链接: https://leetcode-cn.com/problems/daily-temperatures/ 解法一: 单调递增栈维护一个单调递增栈, 栈内元素越深, 值越大, 判断某一个的升温天数时, 逐个查看栈顶, 若栈顶小于当前温度, 则退栈, 直到栈为空, 若为空, 则说明后面的温度不会升高. C++ 解法:12345678910111213141516171819202122class Solution &#123;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; T) &#123; std::stack&lt;std::pair&lt;int, int&gt;&gt; stk; std::vector&lt;int&gt; res(T.size(), 0); for (int i = int(T.size())-1; i &gt;= 0; i--) &#123; while (!stk.empty()) &#123; if (T[i] &lt; stk.top().first) &#123; // 栈顶温度高于当天, 则直接计算相差的天数, 并把当天情况入栈 res[i] = stk.top().second - i; stk.push(&#123;T[i], i&#125;); break; &#125; else &#123; // 栈顶温度低于当天, 则退栈, 因为栈顶的元素不可能成为前面的解 stk.pop(); &#125; &#125; if (stk.empty()) &#123; // 如果栈本身为空或一直退栈导致栈空, 则应该将当天情况入栈 stk.push(&#123;T[i], i&#125;); &#125; &#125; return res; &#125;&#125;; Python 解法:123456789101112131415class Solution: def dailyTemperatures(self, T: List[int]) -&gt; List[int]: stack = [] res = [0] * len(T) for i in range(len(T)-1, -1, -1): while len(stack) &gt; 0: if T[i] &lt; stack[-1][0]: res[i] = stack[-1][1] - i stack.append([T[i], i]) break else: stack.pop() if len(stack) == 0: stack.append([T[i], i]) return res 解法二: 利用已经求得的部分结果加速循环实际上我们不需要额外的维护这个栈, 我们可以直接利用已经求得的部分结果来进行计算, 这样可以空间复杂度降低. 从后往前判断, 对于任意一天, 逐个遍历该天后的温度, 由于我们已经求得了该天后的温度提升数组res, 因此, 如果某天温度比该天低, 我们可以直接跳到某天温度的升高天数, 这样, 降低了循环次数, 使其少于 $O(n^2)$ C++ 实现12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; T) &#123; std::vector&lt;int&gt; res(T.size(), 0); for (int i = int(T.size())-1; i &gt;= 0; i--) &#123; for (int j = i+1; j &lt; T.size(); ) &#123; if (T[i] &lt; T[j]) &#123; // 如果温度高于当天, 则直接计算天数, 并退出该层循环 res[i] = j - i; break; &#125; else if (res[j] == 0) &#123; // 如果温度低于当天, 且后面没有比此温度更高的, 则不用判断, 直接置零 break; &#125; else&#123; // 否则, 直接跳过 res 求得的天数, 加速循环 j += res[j]; &#125; &#125; &#125; return res; &#125;&#125;; Python 实现:123456789101112131415class Solution: def dailyTemperatures(self, T: List[int]) -&gt; List[int]: res = [0] * len(T) for i in range(len(T)-1, -1, -1): j = i + 1 while (j &lt; len(T)): if T[i] &lt; T[j]: res[i] = j - i break elif res[j] == 0: res[i] = 0 break else: j += res[j] return res 股票问题通用解法 买卖股票的最佳时机 买卖股票的最佳时机 II 买卖股票的最佳时机 III 买卖股票的最佳时机 IV 最佳买卖股票时机含冷冻期 买卖股票的最佳时机含手续费 框架:12345def stock(): # 定义 base case dp[0] = ... for price in prices: #更新 dp 状态 核心思想依然是 DP, 只不过可以套用下面的状态转移方程(也可以看做是 DP 更新方程): 12345678910111213dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]) max( 选择 rest , 选择 sell )解释：今天我没有持有股票，有两种可能：要么是我昨天就没有持有，然后今天选择 rest，所以我今天还是没有持有；要么是我昨天持有股票，但是今天我 sell 了，所以我今天没有持有股票了。dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]) max( 选择 rest , 选择 buy )解释：今天我持有着股票，有两种可能：要么我昨天就持有着股票，然后今天选择 rest，所以我今天还持有着股票；要么我昨天本没有持有，但今天我选择 buy，所以今天我就持有股票了。 这个解释应该很清楚了，如果 buy，就要从利润中减去 prices[i]，如果 sell，就要给利润增加 prices[i]。今天的最大利润就是这两种可能选择中较大的那个。而且注意 k 的限制，我们在选择 buy 的时候，把 k 减小了 1，很好理解吧，当然你也可以在 sell 的时候减 1，一样的。这样就相当于控制了可以交易的最大次数, 如果可以交易无限次, 那么就可以不记录 k. 现在，我们已经完成了动态规划中最困难的一步：状态转移方程。如果之前的内容你都可以理解，那么你已经可以秒杀所有问题了，只要套这个框架就行了。不过还差最后一点点，就是定义 base case，即最简单的情况。12345678dp[-1][k][0] = 0解释：因为 i 是从 0 开始的，所以 i = -1 意味着还没有开始，这时候的利润当然是 0 。dp[-1][k][1] = -infinity解释：还没开始的时候，是不可能持有股票的，用负无穷表示这种不可能。dp[i][0][0] = 0解释：因为 k 是从 1 开始的，所以 k = 0 意味着根本不允许交易，这时候利润当然是 0 。dp[i][0][1] = -infinity解释：不允许交易的情况下，是不可能持有股票的，用负无穷表示这种不可能。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM深入解析]]></title>
    <url>%2Fz_post%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-SVM%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言起初让我最头疼的是拉格朗日对偶和SMO，后来逐渐明白拉格朗日对偶的重要作用是将w的计算提前并消除w，使得优化函数变为拉格朗日乘子的单一参数优化问题。而SMO里面迭代公式的推导也着实让我花费了不少时间。 对比这么复杂的推导过程，SVM的思想确实那么简单。它不再像logistic回归一样企图去拟合样本点（中间加了一层sigmoid函数变换），而是就在样本中去找分隔线，为了评判哪条分界线更好，引入了几何间隔最大化的目标。 之后所有的推导都是去解决目标函数的最优化上了。在解决最优化的过程中，发现了w可以由特征向量内积来表示，进而发现了核函数，仅需要调整核函数就可以将特征进行低维到高维的变换，在低维上进行计算，实质结果表现在高维上。由于并不是所有的样本都可分，为了保证SVM的通用性，进行了软间隔的处理，导致的结果就是将优化问题变得更加复杂，然而惊奇的是松弛变量没有出现在最后的目标函数中。最后的优化求解问题，也被拉格朗日对偶和SMO算法化解，使SVM趋向于完美。 简述 SVM 的基本概念和原理最简单的 SVM 从线性分类器导出, 根据最大化样本点分类间隔的目标, 我们可以得到线性可分问题的 SVM 目标函数. 然后可以利用拉格朗日乘子法得到其对偶问题, 并根据 KKT 条件和 SMO 算法就可以高效的求出超平面的解. 但是实际任务中, 原始样本空间内也许并不存在一个能正确划分两类样本的超平面. 因此, 我们需要利用核函数将样本从原始空间映射到一个更高为的特征空间, 使得样本在这个特征空间内线性可分. 核函数的选择对于支持向量机的性能至关重要. 但是现实任务中往往很难确定合适的核函数使得训练样本在特征空间内线性可分, 因此, 我们引入了 “软间隔” 的概念, 也就是松弛变量和惩罚因子, 其基本思想就是, 允许支持向量机在一些样本上出错, 并对违反约束条件的训练样本进行惩罚. 所以, 最终的优化目标就是在最大化间隔的同时, 使得不满足约束的样本尽可能地少. SVM 推导过程1 间隔与支持向量给定训练样本集(二分类问题): D = {(\vec x_1, y_1), (\vec x_2,y_2),..,(\vec x_m,y_m)}y_i \in \{-1, +1\}\vec x_i =(x^{(1)}_i;x^{(2)}_i;...;x^{(d)}_i )注意,这里用的是分号, 表示这是一个列向量. SVM做的事情就是试图把一根 “木棍” 放在最佳位置, 好让 “木棍” 的两边都有尽可能大的 “间隔”. 这个 “木棍” 就叫做 “划分超平面”, 可以用下面的线性方程来描述: \vec w^T\vec x + b = 0其中 $\vec w =(w^(1); w^(2);…; w^(d))$ 为 $d$ 维法向量(注意,这里用的是分号, 表示这是一个列向量), 决定了超平面的方向, $\vec x$ 为 “木棍” 上的点的坐标($d$ 维列向量), $b$ 为位移项, 决定了超平面与原点之间的距离. 根据点到 “直线” 的距离公式,我们可以得到样本空间中任意点 $\vec x$ 到超平面 $(\vec w,b)$ 的距离为: r = \frac{|\vec w^T\vec x+b|}{\|\vec w \|}$||\vec w || = \sqrt{w_1^2 + w_2^2 + … + w_d^2}$ 为向量长度(也即向量的L2范式) 首先假设 当前的超平面可以将所有的训练样本正确分类, 那么就有如下式子: \begin{cases} \vec w^T\vec x_i + b \geq 0, & y_i = +1 \\ \vec w^T\vec x_i + b < 0, & y_i = -1 \end{cases}上式可以统一写成如下的约束不等式: y_i (\vec w^T\vec x_i + b) \geq 0上面的式子其实是冗余的, 因为假设样本点不在超平面上, 所以不可能出现等于0的情况, 又因为超平面方程两边都乘一个不等于0的数,还是 同一个超平面, 因此为了简化问题的表述, 我们对 $\vec w$ 和 $b$ 加上如下约束(这里的1没有什么特别的含义, 可以是任意的常数, 因为这里的点 $\vec x_i$ 不是超平面上的点, 所以所得值不为0): \min_i|\vec w^T\vec x_i +b| = 1即离超平面最近的正, 负样本距离超平面的距离为: $\frac{1}{||\vec w||}$ , 我们将这些距离超平面最近的几个训练样本点为定义 “支持向量”, 那么, 两个异类支持向量到超平面的距离之和就为 $\gamma = \frac{2}{||\vec w||}$ , 我们将这称为”间隔”. 同时, 根据此约束, 我们可以消除超分类平面约束的冗余, 得到新的超分类平面约束如下: y_i(\vec w^T\vec x_i + b) \geq 1SVM的目的就是找到具有 “最大间隔” 的划分超平面, 也就是要找到满足约束 $y_i(\vec w^T\vec x_i + b) \geq 1$ 中的参数 $\vec w, b$ , 使得其具有最大的间隔 $\gamma$ , 也就是: \arg\max_{\vec w,b}\frac{2}{\|\vec w\|}s.t. y_i(\vec w^T \vec x_i +b) \geq 1, i=1,...,m显然, 为了最大化间隔 $\gamma$ , 我们仅需要最大化 $|\vec w|^{-1}$ , 这就等于最小化 $|\vec w|^2$, 于是上式等价为: \arg\min_{\vec w,b} \frac{1}{2}\|\vec w\|^2 = \arg\min_{\vec w,b} \frac{1}{2}\vec w^T\vec w \tag 1s.t. y_i(\vec w^T \vec x_i +b) \geq 1, i=1,...,m下图即为SVM示意图, 注意,图中的1可以被任意常数替换(只要前面乘上对应的系数即可, =0说明在超分类平面上, !=0说明在两侧) 以上就是线性可分时的SVM基本型(现实中大多数问题是线性不可分的, 所以线性可分的SVM没有太多实用价值) 2 对偶问题求解 $\vec w$ 和 $b$问题说明对偶问题(dual problem):在求出一个问题解的同时, 也给出了另一个问题的解 我们希望通过求解式(1)来得到具有最大间隔的划分超平面的模型参数,由于该式是一个凸二次规划问题(目标函数是变量的二次函数, 约束条件是变量的线性不等式). 因此,对该式使用拉格朗日乘子法得到其 “对偶问题”. 对于式(1)的 每个样本点 约束添加拉格朗日乘子 $\alpha_i \geq 0$, 则该问题的拉格朗日函数为: L(\vec w,b,\alpha) = \frac{1}{2}\|\vec w\|^2 +\sum_{i=1}^{m}\alpha_i (1-y_i(\vec w^T \vec x_i +b))\tag 2其中, $\vec \alpha = (\alpha_1, \alpha_2,…,\alpha_m)$ ,每一个 $\alpha_i$ 均为标量 .接着令 $L(\vec w,b,\vec \alpha)$ 对 $\vec w$ 和 $b$ 求偏导, 并令其为0, 可得: \frac{\partial L(\vec w,b,\vec \alpha)}{\partial \vec w} = \vec w - \sum_{i=1}^{m} \alpha_i y_i \vec x_i = 0 \tag 3\frac{\partial L(\vec w,b,\vec \alpha)}{\partial b} = -\sum_{i=1}^{m}\alpha_i y_i = 0 \tag 4将(3)和(4)代入(2)式中, 消去 $\vec w$ 和 $b$ ( 注意, 这里 $\sum_{i=1}^{m}\alpha_i y_i = 0$, 但是不代表 $\alpha_i y_i = 0$ ), 可得: L(\vec w, b, \vec \alpha) = \frac{1}{2}\bigg( \sum_{i=1}^{m}\alpha_i y_i \vec x_i \bigg)^2 + \sum_{i=1}^{m} \alpha_i - \sum_{i=1}^{m}\alpha_i y_i \Big( \sum_{j=1}^{m} \alpha_j y_j \vec x_j \Big)^T \vec x_i - \sum_{i=1}^{m} \alpha_i y_i b= \sum_{i=1}^{m}\alpha_i - \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_i y_j \alpha_i y_j \vec x_i^T \vec x_j这里 $\vec x_i,\vec x_j$ 位置可互换, 为了好看,我将 $\vec x_i$ 写在了前面. 到此, 我们就得到了式(2)的对偶问题: \arg\max_{\vec \alpha} \bigg( \sum_{i=1}^{m} \alpha_i - \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_i \alpha_j y_i y_j \vec x_i^T \vec x_j \bigg) \tag 5s.t. \sum_{i=1}^{m} \alpha_i y_i = 0, 其中 \alpha_i \geq 0为了满足原始问题(1) 和对偶问题(5)之间的充分必要条件, 上述推导过程还需要满足KKT(Karush-Kuhn-Tucker)条件(其中前两条已经在上述推导过程中满足) , 即要求: \begin{cases} \alpha_i \geq 0 ; \\ y_i f(\vec x_i) - 1 \geq 0 ; \\ \alpha_i (y_i f(\vec x_i) - 1 ) = 0. \end{cases}当我们解出上式得到 $\vec \alpha$ 后, 就可以通过求得 $\vec w$ 和 $b$ 的值, 进而可得到划分超平面对应的模型: f(\vec x) = \vec w^T \vec x +b = \sum_{i=1}^{m} \alpha_i y_i \vec x_i^T \vec x +b根据 KKT 条件我们可以轻易得出, 对任意的训练样本 $(\vec x_i , y_i)$ , 总有 $\alpha_i = 0$ 或 $y_i f(\vec x_i) = 1$ . 若 $\alpha_i = 0$ , 则该项对应的样本不会出现在求和项中 ; 若 $\alpha_i &gt; 0$ , 则必有 $y_i f(\vec x_i) = 1$ , 这说明该样本点出现在最大间隔边界上, 是一个支持向量. 这显示出支持向量机的一个重要性质: 训练完成后, 大部分的训练样本都不需要保留(这些样本对应的系数 $\alpha_i = 0$ ), 最终模型仅与支持向量有关. 使用SMO算法求对偶问题的解从(5)式可以看出, 这仍是一个二次规划问题, 可以使用通用的二次规划法来求解, 但是, 该问题的规模正比于训练样本数量, 在实际任务中使用通用解法会造成很大的开销, 因此, 需要使用更高效的算法—-SMO(Sequential Minimal Optimization, 序列最小算法) SMO的基本思路: 先固定 $\alpha_i$ 之外的所有参数, 然后求 $\alpha_i$ 上的极值. 但是这里由于 $\alpha_i$ 之间不是互相独立的, 需要满足约束 $\sum_{i=1}^{m} \alpha_i y_i = 0$ , 即一个分量改变, 其他的也要随之改变,因此每次在优化变量中选取两个分量 $\alpha_i$ 和 $\alpha_j$ ,并将其他参数固定, 然后在参数初始化后, 不断执行如下两个步骤直至收敛: 选取一对需要更新的变量 $\alpha_i$ 和 $\alpha_j$ 固定 $\alpha_i$ 和 $\alpha_j$ 以外的参数, 求解(5)式更新后的 $\alpha_i$ 和 $\alpha_j$ 具体的求解过程如下: 首先假设需要优化的参数是 $\alpha_i$ 和 $\alpha_j$ , 于是我们将剩下的分量 $\sum_{k=1,k \neq i,j}^{m} \alpha_k y_k$ 固定, 作为常数处理, 可得下式: \alpha_i y_i + \alpha_j y_j = -\sum_{k\neq i,j}^{m} \alpha_k y_k = C对上式两边同乘以 $y_j$ ,由于 $y_j \times y_j = 1$ 可得: \alpha_j = C y_j - \alpha_i y_i y_j = y_j(C - \alpha_i y_i)将上式代入(5)式, 消去变量 $\alpha_j$ , 得到一个关于 $\alpha_i$ 的单变量二次规划问题, 所有的常数项用 $C$ 表示, (5)式被转换成如下,: F(\alpha_i) = \alpha_i + \Big( y_j(C - \alpha_i y_i) \Big) - \frac{1}{2}\alpha_i \alpha_i y_iy_i\vec x^{(i)T}\vec x_i - \frac{1}{2}\Big( y_j(C - \alpha_i y_i) \Big)^2y_jy_j\vec x^{(j)T}\vec x_j- \alpha_i \Big( y_j(C - \alpha_i y_i) \Big) y_iy_j\vec x^{(i)T} \vec x_j- \alpha_iy_i\sum_{k=1,k\neq i,j}^{m}\alpha^{(k)}y^{(k)}\vec x^{(i)T} \vec x^{(k)} - \Big( y_j(C - \alpha_i y_i) \Big) y_j\sum_{k=1,k\neq i,j}^{m}\alpha^{(k)}y^{(k)}\vec x^{(j)T}\vec x^{(k)}= \alpha_i + \Big( y_j(C - \alpha_i y_i) \Big) - \frac{1}{2}(\alpha_i)^2\vec x^{(i)T}\vec x_i - \frac{1}{2} \big( C - \alpha_iy_i \big)^2 \vec x^{(j)T}\vec x_j - \alpha_i \Big( (C - \alpha_i y_i) \Big) y_i\vec x^{(i)T} \vec x_j - \alpha_iy_iv_i - \big(C- \alpha_iy_i \big)v_j + C= \alpha_i + \Big( y_j(C - \alpha_i y_i) \Big) - \frac{1}{2}(\alpha_i)^2K_{i,i} - \frac{1}{2} \big( C - \alpha_iy_i \big)^2 K_{j,j} - \alpha_i \Big( (C - \alpha_i y_i) \Big) y_iK_{i,j} - \alpha_iy_iv_i - \big(C- \alpha_iy_i \big)v_j + C上式为了简便, 将 $\vec x^{(i)T}\vec x_j$ 简记为 $K_{i,j}$ (后文会用K代表核函数, 这里姑且认为此时的核函数 $K$ 为恒等映射),将上式对 $\alpha_i$ 求导, 并令其等于0, 可得: \frac{\partial F(\alpha_i)}{\partial \alpha_i} = 1 - y_iy_j - \alpha_iK_{i,i} + y_i(C-\alpha_i y_i)K_{j,j} - \Big( C-\alpha_iy_i - \alpha_i y_i \Big)y_iK_{i,j} - y_iv_i + y_iv_j= 1-y_iy_j -\alpha_i \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + Cy_iK_{j,j} - Cy_iK_{i,j} - y_i\big(v_i -v_j \big) = 0下面对上式进行变形, 使得可以用 $\alpha_i^{old}$ 来更新 $\alpha_i^{new}$ . 因为SVM对数据点的预测值为: $f(\vec x) = \sum_{i=1}^{m}\alpha_i y_i K(\vec x_i,\vec x) + b$, 则 $v_i$ 以及 $v_j$ 的值可以表示成: v_i = \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} K_{i,k} = f(x_i) - \alpha_i y_i K_{i,i} - \alpha_j y_j K_{i,j} + bv_j = \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} K_{j,k} = f(x_j) - \alpha_j y_j K_{j,j} - \alpha_i y_i K_{j,i} + b将 $\alpha_j = y_j(C - \alpha_i y_i)$ 带到上式, 可得到 $v_i - v_j$ 的表达式为: v_i - v_j = f(x_i) - f(x_j) - \alpha_i y_i K_{i,i} + \Big( y_j(C - \alpha_i y_i) \Big) y_j K_{j,j} - \Big( y_j(C - \alpha_i y_i) \Big) y_jK_{i,j} + \alpha_iy_iK_{j,i}= f(x_i) - f(x_j) - \alpha_iy_iK_{i,i} + CK_{j,j} - \alpha_iy_iK_{j,j} - CK_{i,j} + 2\alpha_iy_iK_{i,j}= f(x_i) - f(x_j) - \alpha_iy_i \Big( K_{i,i} + K_{j,j} -2K_{i,j} \Big)+ CK_{j,j} - CK_{i,j}注意 $v_i - v_j$ 中 $\alpha_i$ 是更新前初始化的值, 我们将其记作 $\alpha_i^{old}$ ,以便与我们期望获得的更新后的分量 $\alpha_i^{new}$ 相区分 , 将 $v_i - v_j$ 的表达式代入 $\frac{\partial F(\alpha_i)}{\partial \alpha_i^{new}}$ 中 , 可得到: \frac{\partial F(\alpha_i^{new})}{\partial \alpha_i^{new}} = 1-y_iy_j -\alpha_i^{new} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + Cy_iK_{j,j} - Cy_iK_{i,j}- y_i\bigg (f(x_i) - f(x_j) - \alpha_i^{old}y_i \Big( K_{i,i} + K_{j,j} -2K_{i,j} \Big)+ CK_{j,j} - CK_{i,j} \bigg)= \big( y_i \big)^2 -y_iy_j - y_if(x_i) + y_if(x_j) - \alpha_i^{new} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + \alpha_i^{old} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big)= f(x_j) - y_j - \big( f(x_i) -y_i \big) - \alpha_i^{new} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + \alpha_i^{old} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big)我们记 $E_i$ 为SVM预测值与真实值的误差: $E_i = f(x_i) - y_i$ . 并令 $\eta = K_{i,i} + K_{j,j} - 2K_{i,j}$ , 则最终的一阶导数表达式可以简化为: \frac{\partial F(\alpha_i^{new})}{\partial \alpha_i^{new}} = -\eta \alpha_i^{new} + \eta \alpha_i^{old} + y_i\big(E_j - E_i \big) = 0由此, 我们可以根据当前的参数值, 直接得到更新后的参数值: \alpha_i^{new} = \alpha_i^{old} + \frac{y_i\big(E_j - E_i \big)}{\eta} => \alpha_i^{new, unclipped} \tag 6这里注意, (6)式的推导过程并未考虑下面的约束, 因此, 我们暂且将(6)式中的 $\alpha_i^{new}$ 记作 $\alpha_i^{new, unclipped}$, 然后考虑如下约束: \alpha_i y_i + \alpha_j y_j = -\sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} = C0 \leq \alpha_i , \alpha_j \leq C我们分别以 $\alpha_i, \alpha_j$ 为坐标轴, 于是上述约束可以看作是一个方形约束(Bosk constraint), 在二维平面中我们可以看到这是个限制在方形区域中的直线, 如下图所示, 直线在方形区域内滑动(对应不同的截距), 同时 $\alpha_i^{new}$ 的上下边界也在改变: 当 $y_i \neq y_j$ 时(如左图), 限制条件可以写成 $\alpha_i - \alpha_j = \xi$ ,根据 $\xi$ 的正负可以得到不同的上下界, 因此 $\alpha_i^{new}$ 的上下界可以统一表示成: 下界: $L = \max(0, \alpha_i^{old} - \alpha_j^{old})$ 上界: $H = \min(C, C + \alpha_i^{old} - \alpha_j^{old})$ 当 $y_i = y_j$ 时(如右图), 限制条件可以写成 $\alpha_i + \alpha_j = \xi$ , 于是 $\alpha_i^{new}$ 的上下界为: 下界: $L = \max(0,\alpha_i^{old} + \alpha_j^{old} - C)$ 上界: $H = \min(C, \alpha_i^{old} + \alpha_j^{old})$ 根据得到的上下界, 我们可以得到”修剪”后的 $\alpha_i^{new,clipped}$ : \alpha_i^{new,clipped} = \begin{cases} H & \alpha_i^{new,unclipped} > H \\ \alpha_i^{new,unclipped} & L \leq \alpha_i^{new,unclipped} \leq H \\ L & \alpha_i^{new,unclipped} < L \end{cases} \tag 7得到了 $\alpha_i^{new,clipped}$ 以后, 便可以根据 $\alpha_i^{old} y_i + \alpha_j^{old} y_j= \alpha_i^{new}y_i + \alpha_j^{new}y_j$ 得到 $\alpha_j^{new}$ : \alpha_j^{new,clipped} = \alpha_j^{old} + y_iy_j\big( \alpha_i^{old} - \alpha_i^{new,clipped} \big) \tag 8通过(7)(8)式, 我们便可以高效的计算出更新后的 $\alpha_i$ 和 $\alpha_j$ . 当更新了一对 $\alpha_i$ 和 $\alpha_j$ 之后, 我们需要计算偏移项 $b$ 注意到, 对于任意支持向量 $(\vec x^{(s)} , y^{(s)})$ , 都有 $y^{(s)} f(x^{(s)}) = 1$ , 即: y^{(s)} \Big( \sum_{i \in S} \alpha_i y_i \vec x^{(i)T} \vec x^{(s)} + b\Big) = 1式中 $S$ 为所有支持向量的下标集. 理论上, 可以选取任意支持向量来获得 $b$ , 但现实中我们采取更加鲁棒的做法: 使用所有支持向量求解的平均值(式中所有量均已知, $\vec \alpha$ 使用的是支持向量对应的系数): b = \frac{1}{|S|} \sum_{s\in S} \bigg( \frac{1}{y^{(s)}} - \sum_{i \in S} \alpha_i y_i\vec x^{(i)T} \vec x^{(s)} \bigg)还有另一种更新 $b$ 的方式是, 只使用当前更新的变量 $\alpha_i^{new}$ 和 $\alpha_j^{new}$ 来对 $b$ 进行更新,如此一来, 为了满足KKT条件, 就有以下几种情况: 如果 $\alpha_i^{new}$ 在界内(即此时 $0 &lt; \alpha_i^{new} &lt; C$ , 当前对应样本为支持向量), 则 $b = b_i^{new}$ 如果 $\alpha_j^{new}$ 在界内(即此时 $0 &lt; \alpha_j^{new} &lt; C$ , 当前对应样本为支持向量), 则 $b = b_j^{new}$ 如果 $\alpha_i^{new}$ 和 $\alpha_j^{new}$ 都在界上,且 $L \neq H$时, 则 $b_i^{new}$ 和 $b_j^{new}$ 之间的所有的值都符合KKT条件, SMO一般选择终点作为新的偏移量: $b_{new} = \frac{b_i^{new} + b_j^{new}}{2}$ 以上讨论中, $b_i^{new}$ 的推导过程为, 当 $\alpha_i^{new}$ 在界内时, 对应的样本为支持向量 (根据KKT条件得出) , 此时 $y_i(\vec w^T \vec x_i +b) = 1$ , 两边同时乘上 $y_i$ ,得到 $\sum_{k=1}^{m}\alpha^{(k)}y^{(k)}K_{k,i} + b = y_i$, 将该式展开, 得到: b_i^{new} = y_i - \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)}K_{k,i} - \alpha_i^{new}y_iK_{i,i} - \alpha_j^{new}y_jK_{j,i}其中前两项可以写成: y_i - \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)}K_{k,i} = -E_i + \alpha_i^{old}y_iK_{i,i} + \alpha_j^{old}y_jK_{j,i} + b_{old}于是有: b_i^{new} = -E_i - \big( \alpha_i^{new} - \alpha_i^{old} \big)y_i K_{i,i} - \big(\alpha_j^{new} - \alpha_j^{old} \big)y_jK_{j,i} + b_{old}同理有: b_j^{new} = -E_j - \big( \alpha_j^{new} - \alpha_j^{old} \big)y_j K_{j,j} - \big(\alpha_i^{new} - \alpha_i^{old} \big)y_jK_{i,j} + b_{old}如何恰当的选取需要更新的变量 $\alpha_i$ 和 $\alpha_j$采用启发式的规则来选取, 直觉上我们知道, 我们应该首先优化那些违反KKT条件最严重的样本, 因此我们首先首先遍历所有满足约束条件 $0 &lt; \alpha_i &lt; C$ 的样本点, 即位于间隔边界上的支持向量点(直觉上也能发现这些点最有可能分类错误), 检验它们是否满足KKT条件. 如果这些样本都满足KKT条件，则遍历整个训练样本集，判断它们是否满足KKT条件，直到找到一个违反KKT条件的变量 $\alpha_i$ (即使 $\alpha_i$ 位于边界上,也有可能违反KKT条件). 当找到了第一个分量 $\alpha_i$ 后, 接下来寻找第二个分类 $\alpha_j$, 而选取的标准是使得它有足够大的变化, 也就是说使选取的两变量所对应的样本之间的间隔最大, 一种直观的解释是, 这样的两个变量有很大的差别, 与对两个相似的变量进行更新相比(相似说明有可能属于同一类, 更新意义不大), 对它们进行更新会带给目标函数值更大的变化. 第二个乘子的迭代步长正比于 $|E_i - E_j|$ , 因此, 我们希望选择的乘子能够具有最大的 $|E_i - E_j|$. 即当 $E_i$ 为正时选择绝对值最大的赋值 $E_j$ , 反之, 选择正值最大的 $E_i$ 3 核函数在之前的讨论中,我们假设 训练样本 是线性可分的, 然而在现实任务中, 原始样本空间内也许并不存在一个能正确划分两类样本的超平面, 对于这样的问题, 可将一样本从原始空间映射到一个更高维的特征空间, 使得样本在这个特征空间内线性可分 . 需要知道, 如果原始空间是有限维, 即属性数有限, 那么一定存在一个高维特征空间使样本可分 令 $\phi(\vec x)$ 表示将 $\vec x$ 映射后的特征向量, 于是, 在特征空间中划分超平面所对应的模型可表示为: f(\vec x) = \vec w^T \phi(\vec x) + b类似式(1), 有: \arg\min_{\vec w,b} \frac{1}{2} \|w\|^2s.t. y_i\big( \vec w^T \phi (\vec x_i) + b \big), i=1,2,..,m其对偶问题为: \arg\max_{\vec \alpha} = \sum_{i=1}^{m}\alpha_i - \frac{1}{2}\sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_i \alpha_j y_i y_j \phi(\vec x_i)^T \phi(\vec x_j) \tag 9s.t. \sum_{i=1}^{m} \alpha_i y_i = 0, \alpha_i \geq 0 , i = 1,2,...,m求解上式涉及到计算 $\phi(\vec x_i)^T \phi(\vec x_j$ , 这是样本 $\vec x_i$ 与 $\vec x_j$ 映射到特征空间之后的内积, 由于特征空间维数可能很高, 甚至是无穷维, 因此直接计算 $\phi(\vec x_i)^T \phi(\vec x_j$ 是很困难的, 为了避开这个障碍, 可以设想这样一个函数: K \big(\vec x_i, \vec x_j \big) = \phi(\vec x_i)^T \phi(\vec x_j即 $x_i$ 与 $x_j$ 在特征空间的内积等于它们在原始样本空间中通过函数 $K(\cdot, \cdot)$ 计算的结果. (有可能是先内积再函数映射, 也有可能是求范式再函数映射). 于是(9)式可重写为: \arg\max_{\vec \alpha} \sum_{i=1}^{m}\alpha_i - \frac{1}{2}\sum_{i=1}^{m} \sum_{j=1}^{m}\alpha_i \alpha_j y_i y_j K\big(\vec x_i, \vec x_j \big)s.t. \sum_{i=1}^{m} \alpha_i y_i = 0\alpha_i \geq 0, i=1,2,...,m注意, 前面几个小节的推导过程也用了符号 $K$ , 但是就像前面所说的, 前几个小节的 $K$ 是为了方便书写而使用的, 你可以把它看作是一个恒等映射的核函数 当我们解出上式得到 $\vec \alpha$ 后, 就可以得到划分超平面对应的模型(式中 $\vec x$ 为样本点, $f(\vec x)$ 为该样本点的预测结果): f(\vec x) = \vec w ^T \vec x +b = \sum_{i=1}^{m} \alpha_i y_i K\big(\vec x, \vec x_j \big) +b核函数定理: 令 $\chi$ 为输入空间 $K(\cdot, \cdot)$ 是定义在 $\chi \times \chi$ 上的对称函数, 则 $K(\cdot, \cdot)$ 是核函数 当且仅当 对于任意数据 $D = \\{\vec x^{(1)}, \vec x^{(2)},…,\vec x ^{(m)} \\}$ , 核矩阵 $K$ 总是半正定的 从以上分析可知, 核函数的选择决定了特征空间的好坏, 因此, 一个合适的核函数,就成为了支持向量机的最大变数. 下面是几种常用的核函数: 名称 表达式 参数 线性核 高斯核 拉普拉斯核 Sigoid核 此外,还可以通过函数组合得到: 若 $K_1$ 和 $K_2$ 都是核函数 ,则对任意的正数 $\gamma_1, \gamma_2$ , 其线性组合 $\gamma_1 K_1 + \gamma_2 K_2$ 也是核函数 若 $K_1$ 和 $K_2$ 为核函数, 则函数的直积 $K_1 \otimes K_2 (\vec x , \vec z) = K_1(\vec x, \vec z) K_2(\vec x, \vec z)$ 若 $K_1$ 是核函数, 则对任意函数 $g(\vec x)$, $K(\vec x, \vec z) = g(\vec x) K_1(\vec x, \vec z) g(\vec z)$ 也是核函数 4 软间隔与正则化在实现任务中, 往往很难确定合适的核函数, 使得训练样本在特征空间中线性可分, 即便是找到了, 也无法断定是否是由于过拟合造成的 , 因此, 我们需要 允许支持向量机在一些样本上出错 , 以缓解上面的问题. 硬间隔(hard margin)与软间隔(soft margin)的区分: 硬间隔: 所有样本都必须分类正确 软间隔: 允许某些样本不满足约束(11)式(即,预测结果和真实结果符号相反,分类错误,或预测结果绝对值小于1,相当于越过了支持向量划定的边界) 我们要在最大化间隔的同时, 使得不满足约束的样本应尽可能的少, 于是, 优化目标可写为: \min_{\vec w,b} \frac{1}{2} \|w\|^2 + C\sum_{i=1}^{m} l_{0/1} \big( y_i (\vec w^T x_i+b) - 1\big) \tag {10}y_i (\vec w^T \vec x_i +b) \geq 1 \tag {11}其中, $C&gt;0$ 为惩罚因子, 是一个常数(注意与前几节推导SVM时的常数区分), $l_{0/1}$ 是 “0/1 损失函数”: l_{0/1} (z) = \begin{cases} 1, & \text{if } z < 0 ; \\ 0, & \text{otherwise}. \end{cases}当C无穷大时, (10)式就会迫使所有样本均满足约束, 也就是令所有训练样本都分类正确(容易产生过拟合), 当C取有限值时, 则允许有一些样本不满足约束(11)式. 但是, $l_{0/1}$ 非凸, 不连续, 数学性质不好, 因此, 通常使用其他函数来替代, 称为” 替代损失”, 下面为三种常用的替代损失: hinge损失: $l_{hinge}(z) = max(0,1-z)$ 指数损失(exponential loss): $l_{exp}(z) = exp(-z)$ 对率损失(logistic loss): $l_{log}(z) = log(1+ exp(-z))$ 假设采用hinge损失损失, 然后可以引入”松弛变量”(slack variables) $\xi_i \geq 0$ ,每一个样本都有一个对应的松弛变量, 用以表征该样本不满足约束(11)的程度 则可将(10)式重写为: \min_{\vec w, b, \xi_i} \frac{1}{2} \|\vec w\|^2 + C \sum_{i=1}^{m} \xi_i \tag {12}s.t. y_i (\vec w^T x_i + b) \geq 1- \xi_i\xi_i \geq , i=1,2,...,m.可以看出, 上式是与之前推导相似的二次规划问题, 只不过是约束条件变的宽松了(为了允许一些样本犯错), 因此,同样利用拉格朗日乘子法求解, 首先得到上式的拉格朗日函数: L(\vec w, b, \vec \alpha, \vec \xi, \vec \mu) = \frac{1}{2} \|w\|^2 + C \sum_{i=1}^{m} \xi_i + \sum_{i=1}^{m}\alpha_i\big(1- \xi_i - y_i(\vec w^T\vec x_i +b) \big) - \sum_{i=1}^{m} \mu_i \xi_i其中, $\alpha_i \geq 0, \mu_i \geq 0$ 是拉格朗日乘子, 令 $L(\vec w, b, \vec \alpha, \vec \xi, \vec \mu)$ 对 $\vec w, b, \vec \alpha, \vec \xi$ 求偏导, 并令其为0 , 可得: \vec w =\sum_{i=1}^{m} \alpha_i y_i \vec x_i0 = \sum_{i=1}^{m} \alpha_i y_iC = \alpha_i + \mu_i 得到(12)式对应的对偶问题如下: \max_{\alpha} \sum_{i=1}^{m} \alpha_i - \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_i \alpha_j y_i y_j K_{i,j}s.t. \sum_{i=1}^{m} \alpha_i y_i = 00 \leq \alpha_i \leq C , i=1,2,...,m可以看到, 此时, $\alpha_i$ 的约束条件变成了 $0 \leq \alpha_i \leq C$ , 上式的KKT条件要求为: \begin{cases} \alpha_i \geq 0, \mu_i \geq 0 \\ y_if(\vec x_i) -1 +\xi_i \geq 0, \\ \alpha_i \big( y_if(\vec x_i) - 1 + \xi_i \big) = 0, \\ \xi_i \geq 0, \mu_i \xi_i = 0 \end{cases}于是, 从KKT条件中我们可以看出, 对任意的训练样本 $(\vec x_i, y_i)$, 总有 $\alpha_i = 0$ 或 $y_i f(\vec x_i) = 1 - \xi_i$. 若 $\alpha_i = 0$, 则该样本不会对 $f(\vec x)$ 产生影响. 若 $\alpha_i &gt; 0$, 则必有 $y_i f(\vec x_i) = 1 - \xi_i$, 即该样本是支持向量 因为 $C = \alpha_i + \mu_i$ , 所以, 若 $\alpha_i &lt; C$ , 则有 $\mu_i &gt; 0$ , 进而有 $\xi_i = 0$, 即该样本在最大间隔边界上(是否也就是支持向量?) 若 $\alpha_i = C$ , 则有 $\mu_i = 0$, 此时若 $\xi_i \leq 1$, 则该样本落在最大间隔内部, 若 $\xi_i &gt; 1$, 则该样本被错误分类. 以上讨论, 我们可以看出, 最终的模型依然只与支持向量有关, 保持了稀疏性(hinge损失有一块平坦的零区域,这使得SVM的解具有稀疏性) 以上是对使用hinge损失时讨论的情况, 还可以将其替换成别的损失函数以得到其他学习模型, 这些模型的性质与所用的替代函数直接相关, 但它们具有一个共性: 优化目标中的第一项用来描述划分超平面的”间隔”大小, 另一项用来表示训练集上的误差, 可写为更一般的形式: \min_{f} \Omega(f) + C\sum_{i=1}^{m} l(f(\vec x_i) , y_i)其中, $\Omega(f)$ 称为”结构风险”(structural risk), 用于描述模型 $f$ 自身的性质; 第二项 $C\sum_{i=1}^{m} l(f(\vec x_i)$ 称为”经验风险”(empirical risk), 用于描述模型与训练数据的契合程度. $C$ 用于对二者进行折衷. 从预测误差的角度来看, 第二项相当于模型误差, 第一项相当于正则化项, 表述了模型本身的性质, 一方面, 这为引入领域知识和用户意图提供了途径, 另一方面, 该信息有助于消减假设空间, 降低过拟合风险 SVM 如何解决线性不可分问题 为什么SVM的分类结果仅依赖于支持向量?百机p53 如何选取核函数?最常用的是线性核与高斯核, 也就是 Linear 核与 RBF 核. 一般情况下 RBF 效果不会差于 Linear, 但是时间上 RBF 会耗费更多. Linear 核: 主要用于线性可分的情形. 参数少, 速度快, 对于一般数据, 分类效果已经很理想了. RBF 核: 主要用于线性不可分的情况. 参数多, 分类结果非常依赖于参数. 有很多人是通过训练数据的交叉验证来寻找合适的参数, 不过这个过程比较耗时. 个人体会是: 使用 libsvm, 默认参数, RBF 核比 Linear 核效果稍差. 通过进行大量参数的尝试, 一般能找到比 linear 核更好的效果. 至于到底该采用哪种核, 要根据具体问题和数据分析, 需要多尝试不同核以及不同参数. 如果特征提取的好, 包含的信息量足够大, 很多问题都是线性可分的. 当然, 如果有足够的时间去寻找合适的 RBF 核参数, 应该能取得更好的效果. 吴恩达的观点: 如果 Feature 的数量很大, 跟样本数量差不多, 这时候可以使用 LR 或者是 Linear Kernel 的 SVM. (因为核函数需要计算内积, 两两样本都得算, 所以样本过多的话时间消耗太大, 很明显高斯核比线性核复杂的多) 如果 Feature 的数量比较小, 样本数量一般, 不算大也不算小, 就选用 SVM + Gaussian Kernel 如果 Feature 的数量比较小, 而样本数量比较多, 就需要手工添加一些 feature, 使之变成第一种情况. 为什么说高斯核函数将原始特征空间映射成了无限维空间?https://blog.csdn.net/lin_limin/article/details/81135754 核函数中不同参数的影响https://blog.csdn.net/lin_limin/article/details/81135754 https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247484495&amp;idx=1&amp;sn=4f3a6ce21cdd1a048e402ed05c9ead91&amp;chksm=fdb699d8cac110ce53f4fc5e417e107f839059cb76d3cbf640c6f56620f90f8fb4e7f6ee02f9&amp;scene=21#wechat_redirect 既然深度学习技术性能表现已经全面超越 SVM, SVM 还有存在的必要吗?Reference[1] https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247483937&amp;idx=1&amp;sn=84a5acf12e96727b13fd7d456c414c12&amp;chksm=fdb69fb6cac116a02dc68d948958ee731a4ae2b6c3d81196822b665224d9dab21d0f2fccb329&amp;scene=21#wechat_redirect [2] 西瓜书 [3] http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html https://zhuanlan.zhihu.com/p/29212107]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>SVM</tag>
        <tag>核函数</tag>
        <tag>SMO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用PyTorch实现经典VGG网络]]></title>
    <url>%2Fz_post%2FPyTorch-VGG%2F</url>
    <content type="text"><![CDATA[首先, 来看一下原文中关于 VGG 网络的结构设置, 如下图所示: 可以看到, 上图中, 不同版本的 VGG 网络的整体结构差不多, 主要的不同体现在每一个卷积段内(共5个卷积段)卷积层的个数以及卷积层的参数, 下面我们以 VGG-19 为例, 给出 VGG 网络的 PyTorch 实现, 其他版本的 VGG 网络可以用同样方式进行定义. 123456789101112131415161718import torchimport torch.nn as nnclass VGGNet(nn.Module): def __init__(self, num_classes): super(VGGNet, self).__init__() self.num_classes = num_classes self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1) self.relu1_1 = nn.ReLU(inplace=True) self.conv1_2 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1) self.relu1_2 = nn.ReLU(inplace=True) self.max1 = nn.MaxPool2d(kernel_size=2, stride=2) self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1) self.relu2_1 = nn.ReLU(inplace=True) self.conv2_2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1) self.relu2_2 = nn.ReLU(inplace=True) self.max2 = nn.MaxPool2d(kernel_size=2, stride=2) #...TODO 如此定义19个层 上面的定义方式比较直观, 但是不够简洁, 由于 VGGNet 的结构设计比较有规律, 因此我们可以用下面的代码使模型定义变的更加整洁: 123456789101112131415161718192021222324252627282930313233343536373839# vgg16, 可以看到, 带有参数的刚好为16个net_arch16 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M5', "FC1", "FC2", "FC"]# vgg19, 基本和 vgg16 相同, 只不过在后3个卷积段中, 每个都多了一个卷积层net_arch19 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M5', "FC1", "FC2", "FC"]import torchimport torch.nn as nnclass VGGNet(nn.Module): def __init__(self, net_arch, num_classes): # net_arch 即为上面定义的列表: net_arch16 或 net_arch19 super(VGGNet, self).__init__() self.num_classes = num_classes layers = [] in_channels = 3 # 初始化通道数 for arch in net_arch: if arch == 'M': layers.append(nn.MaxPool2d(kernel_size=2, stride=2)) elif arch == 'M5': layers.append(nn.MaxPool2d(kernel_size=3, stride=1, padding=1)) elif arch == "FC1": layers.append(nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=6, dilation=6)) layers.append(nn.ReLU(inplace=True)) elif arch == "FC2": layers.append(nn.Conv2d(1024,1024, kernel_size=1)) layers.append(nn.ReLU(inplace=True)) elif arch == "FC": layers.append(nn.Conv2d(1024,self.num_classes, kernel_size=1)) else: layers.append(nn.Conv2d(in_channels=in_channels, out_channels=arch, kernel_size=3, padding=1) layers.append(nn.ReLU(inplace=True)) in_channels=arch self.vgg = nn.ModuleList(layers) def forward(self, input_data): x = input_data for layer in self.vgg: x = layer(x) out = x return out 通过此方式定以后, 模型的 forward 部分非常简洁, 也很易于理解.]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
        <tag>源码实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cpp-RTTI机制]]></title>
    <url>%2Fz_post%2FCpp-RTTI%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[RTTI概念RTTI (Run Time Type Identification) 即运行时类型识别, 程序能够使用基类类型的指针或引用来检查来检查这些指针或引用所指的对象的实际派生类型. RTTI机制的产生C++ 是一种静态类型语言, 其具体类型是在编译器就确定的, 不能在运行时更改. 然而由于面向对象程序设计中多态性的要求, C++中的指针或引用, 可能指向与它实际类型不符的其他类型(子类). 有时我们需要将一个多态指针转换为其实际指针对象的类型, 此时就需要知道运行时的类型信息. typeid 和 dynamic_cast 操作符RTTI提供了两个非常有用的操作符: typeid 和 dynamic_cast. typeid操作符: 返回指针和引用所指的实际类型 dynamic_cast操作符: 将基类类型的指针或引用安全的转换为其派生类类型的指针或引用 我们知道C++的多态性是有虚函数实现的, 对于多态性的对象, 无法在程序编译阶段确定对象的类型. 为了在运行时获得一个对象的类型, 可以使用typeid函数, 该函数返回一个对type_info类对象的引用, 要使用typeid时必须使用头文件&lt;typeinfo&gt;, 因为typeid是一个返回类型为type_info的引用, 因此, 首先看一下type_info类 type_info 类成员函数: name(): 返回类型的名称 raw_name(): 返回名字编码(Name Mangling)算法产生的新名称. hash_code(): 返回当前类型对应的hash值. hash值是一个可以用来标志当前类型的函数, 有点类型学生的学号, 公民的身份证号, 银行卡号等等. 不过hash值有赖于编译器的实现, 在不同的编译器下可能会有不同的整数, 但它们都能唯一的标识某个类型. 遗憾的是, C++标准只对type_info类做了很有限的规定, 不仅成员函数少, 功能弱, 而且各个平台的实现不一致. 例如最常用的name()函数, int类型和Base(类)类型在VC/VS下的输出结果分别是int和class Base, 而在GCC下的输出结果分别是i和4Base. C++标准规定, type_info类至少要有如下所示的4个public属性的成员函数, 其他的扩展函数编译器开发者可以自由发挥, 不做限制. const char *name() const: 返回一个能表示类型名称的字符串, 但是C++标准没有规定这个字符串是什么形式的, 因此出现了不同编译器返回的字符串形式不同的情况. bool before (const type_info &amp;rhs) const: 判断一个类型是否位于另一个类型前面, rhs参数是一个type_info对象的引用, 但是C++标准并没有规定类型的排列规则, 不同的编译器有不同的排列规则, 程序员也可以自定义. 要特别注意的是, 这个排列顺序和继承顺序是没有关系的, 基类并不一定位于派生类的前面. bool operator==(const type_info &amp;rhs) const: 重载运算符==, 判断两个类型是否相同, rhs参数是一个type_info对象的引用 bool operator!=(const type_info &amp;rhs) const: 重载运算符!=, 判断两个类型是否不同, rhs参数是一个type_info对象的引用]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 Numpy 实现一个简单的神经网络]]></title>
    <url>%2Fz_post%2FPython-%E7%94%A8Numpy%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[本示例来自于PyTorch的官网上的一个warm-up小示例, 觉得很有代表性, 所有这里单独记录一下.对于numpy来说, 它对计算图, 深度学习, 梯度等等概念几乎是不知道的, 但是, 如果我们了解简单神经网络的具体结构, 那么我们就可以很轻易的用numpy来实现这个简单网络, 对此, 我们通常需要自己来实现前向计算和反向计算的逻辑, 下面我们来实现一个具有两层隐藏层的简单网络: 12345678910111213141516171819202122232425262728293031323334353637import numpy as np# N 为batch size, D_in 为输入维度# H 为隐藏层的维度, D_out 为输出的维度N, D_in, H, D_out = 64, 1000, 100, 10# 创建随机的输入和输出数据x = np.random.randn(N, D_in) # N × D_in 的矩阵y = np.random.randn(N, D_out) # N × D_out 的矩阵# 对两个隐藏层w1,w2进行初始化w1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)# 设置学习率learning_rate = 1e-6for t in range(500): # 前向传播: 计算预测结果 y_pred h = x.dot(w1) # x维度为64 × 1000, w1维度为 1000 × 100, 计算完以后, h维度为 64 × 100 h_relu = np.maximum(h,0) y_pred = h_relu.dot(w2) # h_relu维度为 64×100, w2维度为100×10, y的维度为64×10 # 计算损失 loss = np.square(y_pred - y).sum() print(t, loss) # 反向传播根据loss更新w1和w2的值 grad_y_pred = 2.0*(y_pred - y) # 对y_pred求导 grad_w2 = h_relu.T.dot(grad_y_pred) # 对w2求导, 微分矩阵应该与w2的size相同 grad_h_relu = grad_y_pred.dot(w2.T) # 对h_relu求导 grad_h = grad_h_relu.copy() grad_h[h &lt; 0] = 0 # 经过relu, 将小于0的梯度归0 grad_w1 = x.T.dot(grad_h) # Update weights w1 = w1 - learning_rate * grad_w1 w2 = w2 - learning_rate * grad_w2 在执行上述代码以后, w1和w2的值会是的预测出来的pred_y与y之间的平方损失越来越小.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSSD-Deconvolutional Single Shot Detector]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DSSD-Arxiv2017%2F</url>
    <content type="text"><![CDATA[核心亮点(1) 利用反卷积模块向特征图谱中添加更多的上下文信息主要是对SSD的一点改进, SSD使用了不同阶段的卷积特征图谱进行目标检测, 而DSSD受到人体姿态识别任务的启发, 将这些不同阶段的卷积特征图谱通过反卷积模块连接起来, 然后再进行目标检测的预测任务. (2), 预测模块采用Residual模块这个不算是亮点, 不过也是改动之一, 基本来说就说原始的SSD是直接在特征图谱预测结果并计算损失的, 而DSSD在预测之前会先经过一个Residual模块做进一步的特征提取, 然后在进行预测. 论文细节摘要这篇文章最主要的贡献在于提出了一个可以将额外的上下文信息引入到现有大多数目标检测模型的方法. 为了达到这个目标, 本文首先将Resnet101 分类网络和SSD模型结合起来, 然后对SSD+Resnet101的模型进行了扩展, 添加了反卷积层, 以此引入了针对更大范围尺度的目标物上下文特征信息, 进而提高了准确率(特别是在小物体上面). 这种方法在进行高度阐述时, 很容易就能讲明白, 但是在真正实现时, 却很难成功. 因此本文精心的添加了一些具有已经学习好的特征信息的阶段, 特别是在反卷积时的前向计算的连接上, 最终使得上面的方法得以起效. DSSD 模型base network如图1上半部分所示, SSD模型是用一个经典网络做为基础网络, 然后后接几层额外的特征层构建的. 原始的SSD采用的是VGGnet, 但是大量的工作都是用ResNet获得了更好的效果, 因此, 本文也选用ResNet-101网络作为backbone. 并且将额外的卷积层(也换成Residual模块)接在 conv5_x block后面, 同时会分别从 conv3_x, conv5_x两个卷积段预测score和offsets. 个人觉得奇怪的一点是, 为什么单单把VGG换成ResNet并没有提高mAP?(VOC数据集, 前者77.5, 后者76.4) 而是在使用了其他辅助模块后才提高的 prediction module MS-CNN指出, 提升每个任务的子网络有助于提高准确率, 根据这个原则, 我们在每一个预测层都添加了一个residual block, 如图2(c)所示. 同时也对其他形式的predictin module进行了尝试(图2,a,b,c). Deconvolutional SSD为了增加更多高级别的上下文信息, 文章将prediction module 移动到了一系列的反卷积层之后, 并与原始SSD的额外卷积层形成了一种非对称的沙漏结构(hourglass network, 灵感来自于一篇人体姿态检测论文), 如图1所示. 每一个卷积层的特征图谱会和之前的层一起经过一个反卷积模块(该模块细节在后面介绍), 这就相当于在特征图谱中加入了更多的上下文信息. 这里的反卷积只有很浅的几层, 作者这样设计的原因一是不想增加过多的计算时间, 二是由于迁移学习方法可以帮助更好更快的模型收敛, 同时可以获得更高的精度, 因此无需设计过深的网络. 反卷积层很重要的一个点在于计算成本的增加, 除了反卷积操作本身的计算, 还体现在从之前层中添加信息时 Deconvolution Module为了帮助整合反卷积层和之前层的特征信息, 文章引入了一种反卷积模块, 如图3所示. 图3中左下角是从原始SSD中得到的特征图谱, 左上角是论文Learning to refine object segment中提出的反卷积层. 在当前模块中的每一个卷积层, 都使用了BN层, 在放大特征图谱时, 我们使用了学习到的反卷积层, 而不是双线性插值法. 在测试了多种conbination方法后(element-wise sum, element-wise product), 根据实验结果决定采用对应为相乘的结合方式(VOC数据集, 前者78.4, 后者78.6, 提升了0.2的mAP). Training除了一些参数设置的不同外, 训练策略基本遵循SSD. 实验 从COCO数据集的结果来看, DSSD在小物体方面并没有提升, 而在大物体方面获得了很大的提升, 推测原因主要是因为ResNet-101在大物体的特征提取能力上, 要远强于VGGNet.另外, 可以看出, 由于采用了更深的ResNet网络, 同时增加了反卷积过程, 使得FPS降低不少.(即使在测试阶段利用计算公式移除了BN层, 这个trick可以提升1.2~1.5倍的检测速度).]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则化方法深入解析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[L1 正则L1范数为: \|w\|_1 = |w_1| + |w_2| + ... + |w_n|L1正则项如下所示, 其中 $L_0$ 代表原始的不加正则项的损失函数, $L$ 代表加了正则项以后的损失函数, $m$ 则代表训练batch的样本大小 : L = L_0 + \lambda\|w\|_1 = L_0 + \lambda \sum_{w}|w|将上式对参数 $w$ 求导如下(由于正则项与 $b$ 无关, 因此参数 $b$ 的导数不变): \frac{\partial L}{\partial w} = \frac{\partial L_0}{\partial w} + \lambda sign(w)上式中 $sign(w)$ 表示 $w$ 的符号, 当 $w&gt;0$ 时, $sign(w)=1$ , 当 $w&lt;0$ 时, $sign(w)=-1$, 为了实现方便, 我们特意规定, 当 $w=0$ 时, $sign(w) = 0$ , 相当于去掉了正则项. 因此, 权重 $w$ 的更新表达式可如下表示: w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta \lambda sign(w)L2 正则(权重衰减/岭回归)L2范数为: \|w\|_1 = \sqrt {w_1^2 + w_2^2 + ... + w_n^2 }L2正则项如下所示, 其中 $L_0$ 代表原始的不加正则项的损失函数, $L$ 代表加了正则项以后的损失函数, 式中的系数 $\frac{1}{2}$ 主要是为了消去求导后产生的常数 $2$, 方便表示 (因为可以根据 $\lambda$ 的值来替代这些常数): L = L_0 + \lambda\|w\|^2_2 =L_0 + \lambda \sum_{w}w^2将上式对参数 $w$ 求导如下: \frac{\partial L}{\partial w} = \frac{\partial L_0}{\partial w} + 2\lambda w则, 权重 $w$ 的更新表达式可如下表示: w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta 2\lambda w由于, $\eta, \lambda, m$ 三个值都是正的, 因此, 加上 $L2$ 正则化以后, 权重整体减小了, 这也是”权重衰减”的由来. L1 正则和 L2 正则的特点是什么? 各有什么优势?二者共同的特点都是能够防止过拟合问题. L1 的优点: 能够获得更加稀疏的模型.L1 的缺点: 加入 L1 后会使得目标函数在原点不可导, 需要做特殊处理 L2 的有点: 在任意位置都可导, 优化求解过程比较方便, 而且更加稳定L2 的缺点: 无法获得真正的稀疏模型 在实际应用过程中, 大部分情况下都是 L2 正则的效果更好, 因此推荐优先使用 L2 正则 L1 和 L2 的区别 L1 相对于 L2 能够产生更加稀疏的模型 L2 相比于 L1 对于离异值更敏感(因为平方的原因, L2 对于大数的乘法比对小数的惩罚大) L1 和 L2 梯度下降速度不同: 前者梯度恒定, 并且接接近于 0 的时候会很快将参数更新成0, 后者在接近于0 时, 权重的更新速度放缓, 使得不那么容易更新为0 (这也解释了为什么 L1 具有稀疏性) 二者解空间性状不同 下图是 L1 和 L2 对向量中值的分布的先验假设, L1 是蓝色的线, L2 是红色的线, 可以看出, L1 的分布对于极端值更能容忍. L1正则化使模型参数稀疏的原理是什么?角度一: 函数图像 L1 在 0 处迅速下降到 0, L2 在 0 处会变得缓慢, 并不会直接更新为 0. 角度二: 函数叠加(梯度下降更新公式) w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta \lambda sign(w) \tag{L1}w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta 2\lambda \tag{L2}w从以上的更新表达式我们可以看出, 当 $w$ 为正时, L1正则化会将更新后的 $w$ 变的再小一点, 而当 $w$ 为负时, L1正则化会将其变的更大一点—-因此L1的正则化效果就是让 $w$ 尽可能的向 $0$ 靠近, 即最终的 $w$ 参数矩阵会变的更加稀疏 角度三: 贝叶斯先验, “百面机器学习”角度四: 解空间性状, “百面机器学习” 为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验?为什么权重矩阵稀疏可以防止过拟合?可以从两个方面来理解: 1）特征选择(Feature Selection)：稀疏性可以实现特征的自动选择, 可以在进行预测时减少无用信息的干扰 大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，$x_i$ 的大部分元素（也就是特征）都是和最终的输出 $y_i$ 没有关系或者不提供任何信息的，在最小化目标函数的时候考虑 $x_i$ 这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确 $y_i$ 的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为 0。 2）可解释性(Interpretability)：较稀疏的模型表示最终的预测结果只与个别关键特征有关, 这符合实际生活中的历史经验 另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型： $y=w_1 \times x_1+w_2 \times x_2+…+w_{1000} \times x_{1000}+b$ （当然了，为了让 $y$ 限定在 $[0,1]$ 的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的 $w$ 就只有很少的非零元素，例如只有 5 个非零的 $wi$ ，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果 1000 个 $w_i$ 都非 0，医生面对这 1000 种因素，累觉不爱. 为何权重参数 $w$ 减小就可以防止过拟合?直观解释: 更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合刚刚好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果 “数学一点”的解释: 过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大. 而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。 $L0$ 范式和 $L1$ 范式都能实现稀疏, 为什么不选择用 $L0$ 而要用 $L1$?L0范数是指向量中非零元素的个数 一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解 为什么说 L2 正则可以优化计算?防止过拟合: 最基本的好处是可以提高模型泛化能力, 防止过拟合 优化计算: 从优化或者数值计算的角度来说, L2正则化有利于提高模型训练速度, 加快计算 原因: https://www.cnblogs.com/callyblog/p/8094745.html 正则项前面的系数一般怎么设置?通常做法是一开始将正则项系数 $\lambda$ 设置为 0, 然后先确定出一个比较好的 learning rate, 接着固定该 learning rate, 给 $lambda$ 一个初始值, 如 1.0. 然后根据验证集上的准确率, 将 $\lambda$ 增大或者缩小 10 倍, 这里增减 10 倍是粗调节, 当确定了 $\lambda$ 合适的数量级以后, 再进一步的细调节. Reference知乎: l1正则与l2正则的特点是什么，各有什么优势知乎: 机器学习中常常提到的正则化到底是什么意思]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种损失函数深入解析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%90%84%E7%A7%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[常用损失函数及其形式 损失函数 形式 绝对值损失(L1损失) 平方损失(L2损失) 交叉熵损失 各个损失函数详细解析绝对值损失别名 $L_1$ 损失 平方损失:平方损失的别名是 $L_2$ 损失 平方损失函数是由线性模型引出的. 对于最简单的线性模型, 可以用房屋面积和房屋价格来举例子, 假设我们已经知道了一些面积和价格的数据: 将其描绘出来如下图所示: 那么, 如果新来了一个面积, 我们能否根据已有的数据来预测它的价格, 这就是线性回归问题. 我们利用一条直线来拟合这些数据, 从而可以得到预测的价格, 如下图所示: 将这种最简单的线性回归一般化, 使其成为具有多个变量的线性模型, 就可以用向量的形式来表达, 如下所示: h_\theta (x) = \theta ^Tx对于上面的公式, 我们就可以求出多个不同的 $\theta$, 来得到不同的模型, 但是我们需要知道到底哪些模型是好的, 哪些是不好的, 因此, 就需要引入了评价机制来判断当前的参数 $\theta$ 是好还是坏, 这就引出了平方误差损失函数, 如下所示: J(\theta) = \frac{1}{2} \sum_{i=1}^{m}{(h_\theta(x^{(i)}) - y^{(i)})^2}这个公式本身非常好理解, 就是希望我们当前模型的参数 $\theta$ 可以让模型的输出结果与真实结果无限逼近. 但是问题是: 为什么是平方形式? 对此,数学解释如下: 一句话说明: 平方损失函数就是对theta的极大似然估计 首先, 预测结果和真实结果之间肯定是有误差的, 我们假设这个误差是 $\epsilon ^{(i)}$ , 那么就有如下公式: y^{(i)} = \theta ^T x^{(i)} + \epsilon ^{(i)}而一般在实际使用中, 我们的训练数据是海量的, 根据中心极限定力, 我们可以假定误差满足均值为0, 方差为 $\sigma ^2$ 的正态分布, 即 $\epsilon^{(i)} \sim N(0, \sigma ^2)$ : p(\epsilon^{(i)}) = \frac{1}{\sqrt {2 \pi } \sigma }exp(-\frac{(\epsilon^{(i)})^2}{2 \sigma ^2}) 这也就是说: p(y^{(i)} | x^{(i)};\theta) = \frac{1}{\sqrt {2 \pi } \sigma }exp(-\frac{(y^{(i)} - \theta ^T x^{(i)})^2}{2 \sigma ^2}) $p(y^{(i)} | x^{(i)};\theta)$ 代表在给定的 $x^{(i)}$ 和参数 $\theta$ 下, $y^{(i)}$的分布概率, 这可以看做是在给定的 $\theta$ 一个关于 $y$ 和$x$ 的函数. 与之相对的,我们也可以将其视为是关于参数 $\theta$ 的函数,如下所示: L(\theta) = L(\theta ; X, \vec y) = p(\vec y | X; \theta)注意到, $\epsilon^{(i)} , y^{(i)} , x^{(i)}$ 都是独立同分布的, 因此, 根据极大似然定理, 我们希望下面的式子能够取得最大值(也就是在给定数据的情况下, 我们希望找到一组参数 $\theta$ , 来使这些数据出现的概率最大, 也就是概率积最大) L(\theta) = \prod_{i=1}^{m}{p(y^{(i)} | x{(i)} ; \theta)} = \prod_{i=1}^{m}{\frac{1}{\sqrt{2\pi} \sigma} exp\Big( -\frac{ (y^{(i)} - \theta ^T x^{(i)})^2}{2\sigma ^2} \Big)}为方便计算, 对上式取对数, 可得: l(\theta) = log L(\theta) = log\prod_{i=1}^{m}{\frac{1}{\sqrt{2\pi} \sigma} exp\Big( -\frac{ (y^{(i)} - \theta ^T x^{(i)})^2}{2\sigma ^2} \Big)}= \sum_{i=1}^{m} log \frac{1}{sqrt{2\pi} \sigma} exp\Big( -\frac{(y^{(i)} - \theta ^T x^{(i)})^2}{2\sigma ^2} \Big) = mlog\frac{1}{\sqrt{2\pi} \sigma} - \frac{1}{\sigma ^2}\times \frac{1}{2}\sum_{i=1}^{m}(y^{(i)} - \theta ^T x^{(i)})^2为了让上面的式子取值最大, 那我们就只需要令下面的式子取值最小即可: \frac{1}{2} \sum_{i=1}^{m} ( y^{(i)} - \theta ^T x^{(i)}) ^2上面的形式恰好就是我们的平方误差损失函数(通常还需要对上面的损失函数做归一化, 也就是乘上 $\frac{1}{m}$ ), 这也是平方误差损失函数的来源. (但实际上, 要知道, 基于概率假设来说, 不一定非要是平方项, 另外, 无需在意 $\sigma$ 的具体值是什么) softmax 交叉熵损失y_i = softmax(z_j) = \frac{e^{z_j}}{\sum_j e^{z_j}}E(t,y) = -\sum_j t_j log y_j上式中, $t$ 和 $y$ 分别表示神经网络的真实标签和预测输出, 第一个公式代表 softmax 激活函数. binary 交叉熵损失首先定义符号说明: $p^{(i)}$: 第i个样本类别为1的真实概率(如第i个样本真实类别为1, 则概率为1, 否则为0) $o^{(i)}$: 第i个样本预测类别为1的概率 $p_k^{(i)}$: 第i个样本类别为k的真实概率(如第i个样本真实类别为k, 则概率为1, 否则为0) $o_k^{(i)}$: 第i个样本预测类别为k的概率 面对二分类问题, 损失函数形式为: J(W,b) = -\Big[\frac{1}{m} \sum_{i=1}{m}\big(y^{(i)}logo^{(i)} + (1-y^{(i)})log(1-o^{(i)}) \big) \Big]面对多分类问题, 损失函数形式为: J(W,b) = -\Big[\frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{n} y_k^{(i)} log o_k^{(i)} \Big]交叉熵衡量了两个分布之间的差异性, 当概率相等时, 交叉熵最大, 则损失函数达到最小(因为加了负号) 损失函数之间的区别和联系为什么分类问题要使用交叉熵损失而不用平方损失?]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cpp-整型上下限INT_MAX和INT_MIN及其运算]]></title>
    <url>%2Fz_post%2FCpp-%E6%95%B4%E5%9E%8B%E4%B8%8A%E4%B8%8B%E9%99%90INT-MAX%E5%92%8CINT-MIN%E5%8F%8A%E5%85%B6%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[INT_MAX,INT_MIN数值大小因为int占4字节32位，根据二进制编码的规则，INT_MAX = 2^31-1，INT_MIN= -2^31.C/C++中，所有超过该限值的数，都会出现溢出，出现warning，但是并不会出现error。如果想表示的整数超过了该限值，可以使用长整型long long 占8字节64位。 关于INT_MAX INT_MIN的运算由于二进制编码按原码、补码和反码的规则进行运算，所有程序中对INT_MAX和INT_MIN的运算应当格外注意，在出现溢出的时候，不遵循数学规则。 INT_MAX + 1 = INT_MIN INT_MIN - 1 = INT_MAX abs(INT_MIN) = -INT_MIN = INT_MIN 另外要注意的是: INT_MAX + 1 &lt; INT_MAX， INT_MIN - 1 &gt; INT_MIN, abs(INT_MIN) &lt; 0. 虽然abs(INT_MIN) = -INT_MIN = INT_MIN, 但是可以利用unsigned int来获取最小负值的绝对值:1unsigned int un = abs(INT_MIN) // un = 2147483648]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度消失和梯度爆炸问题详解]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E9%97%AE%E9%A2%98%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1.为什么使用梯度下降来优化神经网络参数？反向传播（用于优化神网参数）：根据损失函数计算的误差通过反向传播的方式，指导深度网络参数的更新优化。 采取反向传播的原因：首先，深层网络由许多线性层和非线性层堆叠而来，每一层非线性层都可以视为是一个非线性函数$f(x)$(非线性来自于非线性激活函数），因此整个深度网络可以视为是一个复合的非线性多元函数。 我们最终的目的是希望这个非线性函数很好的完成输入到输出之间的映射，也就是找到让损失函数取得极小值。所以最终的问题就变成了一个寻找函数最小值的问题，在数学上，很自然的就会想到使用梯度下降来解决。 2.梯度消失、爆炸会带来哪些影响举个例子，对于一个含有三层隐藏层的简单神经网络来说，当梯度消失发生时，接近于输出层的隐藏层由于其梯度相对正常，所以权值更新时也就相对正常，但是当越靠近输入层时，由于梯度消失现象，会导致靠近输入层的隐藏层权值更新缓慢或者更新停滞。这就导致在训练时，只等价于后面几层的浅层网络的学习。 3.产生的原因以最简单的网络结构为例，加入有三个隐藏层，每层的神经元个数都是1，且对应的非线性函数为$y_i = \sigma(z_i)=\sigma(w_i x_i + b_i)$（其中 $\sigma$ 为某个激活函数）如下图： 现在假设我们需要更新参数 $b_1$ ，那么我们就要求出损失函数对参数 $b_1$ 的导数，根据链式法则，可以写成下面这样： 而对于激活函数，之前一直使用Sigmoid函数，其函数图像成一个S型，如下所示，它会将正无穷到负无穷的数映射到0~1之间： S(x) = \frac{1}{1+e^{-x}} = \frac{e^x}{e^x+1} 当我们对Sigmoid函数求导时，得到其结果如下： S(x) = S(x)(1-S(x))由此可以得到它Sigmoid函数图像，呈现一个驼峰状（很像高斯函数），从求导结果可以看出，Sigmoid导数的取值范围在0~0.25之间，而我们初始化的网络权值$|w|$通常都小于1，因此，当层数增多时，小于0的值不断相乘，最后就导致梯度消失的情况出现。同理，梯度爆炸的问题也就很明显了，就是当权值$|w|$过大时，导致 $|\sigma’(z)w| &gt; 1$，最后大于1的值不断相乘，就会产生梯度爆炸。 Sigmoid函数求导图像 4.解决办法梯度消失和梯度爆炸本质上是一样的，都是因为网络层数太深而引发的梯度反向传播中的连乘效应。 解决梯度消失、爆炸主要有以下几种方案： 4.1 换用Relu、LeakyRelu、Elu等激活函数ReLu：让激活函数的导数为1 LeakyReLu：包含了ReLu的几乎所有有点，同时解决了ReLu中0区间带来的影响 ELU：和LeakyReLu一样，都是为了解决0区间问题，相对于来，elu计算更耗时一些（为什么） 具体可以看关于各种激活函数的解析与讨论 4.2 BatchNormalizationBN本质上是解决传播过程中的梯度问题，具体待补充完善，查看BN 4.3 ResNet残差结构具体待补充完善，查看ResNet 4.4 LSTM结构LSTM不太容易发生梯度消失，主要原因在于LSTM内部复杂的“门（gates）”，具体看LSTM基本原理解析 4.4 预训练加finetunning此方法来自Hinton在06年发表的论文上，其基本思想是每次训练一层隐藏层节点，将上一层隐藏层的输出作为输入，而本层的输出作为下一层的输入，这就是逐层预训练。 训练完成后，再对整个网络进行“微调（fine-tunning）”。 此方法相当于是找全局最优，然后整合起来寻找全局最优，但是现在基本都是直接拿imagenet的预训练模型直接进行finetunning。 4.5 梯度剪切、正则这个方案主要是针对梯度爆炸提出的，其思想是设值一个剪切阈值，如果更新梯度时，梯度超过了这个阈值，那么就将其强制限制在这个范围之内。这样可以防止梯度爆炸。 另一种防止梯度爆炸的手段是采用权重正则化，正则化主要是通过对网络权重做正则来限制过拟合，但是根据正则项在损失函数中的形式： 可以看出，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种激活函数整理总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%90%84%E7%A7%8D%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[常用激活函数及其导数 激活函数 形式 导数形式 Sigmoid $f(x) =\frac{1}{1+e^{-x}}$ $f’(x) = f(x)(1-f(x))$ Tanh $f(x) = tanh(x)= \frac{e^x-e^{-x}}{e^x+e^{-x}}$ $f’(x) = 1-(f(z))^2$ ReLU $f(x)=max(0,x)=\begin{cases} 0 &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}$ $f’(x)=\begin{cases} 0 &amp; x\leq 0 \\ 1 &amp; x&gt;0 \end{cases}$ Leaky ReLU $f(x)=max(0.001 x,x)=\begin{cases} 0.001x &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}a$ $f(x)=max(0.001 x,x)=\begin{cases} 0.001 &amp; x \leq 0 \\ 1 &amp; x&gt;0 \end{cases}$ PReLU $f(x)=max(\alpha x,x)=\begin{cases} \alpha x &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}$ $f(x)=max(\alpha x,x)=\begin{cases} \alpha &amp; x \leq 0 \\ 1 &amp; x&gt;0 \end{cases}$ RReLU PReLU中的 $\alpha$ 随机取值 ELU $f(x) = \begin{cases} x &amp; x \geq 0 \\ \alpha(e^x - 1) &amp; x&lt;0 \end{cases}$ $f(x) = \begin{cases} 1 &amp; x \geq 0 \\ \alpha e^x &amp; x&lt;0 \end{cases}$ Maxout $f(x) = max(w_1^T x + b_1, w_2^T x + b_2)$ $f(x) = max(w_1, w_2)$ 常用激活函数及其导数的图像Sigmoid Tanh ReLU LeakyReLU PReLU RReLU ELU 为什么需要激活函数标准说法这是由激活函数的性质所决定来, 一般来说, 激活函数都具有以下性质: 非线性: 首先,线性函数可以高效可靠对数据进行拟合, 但是现实生活中往往存在一些非线性的问题(如XOR), 这个时候, 我们就需要借助激活函数的非线性来对数据的分布进行重新映射, 从而获得更强大的拟合能力. (这个是最主要的原因, 其他还有下面这些性质也使得我们选择激活函数作为网络常用层) 可微性: 这一点有助于我们使用梯度下降发来对网络进行优化 单调性: 激活函数的单调性在可以使单层网络保证网络是凸优化的 $f(x) \approx x:$ 当激活满足这个性质的时候, 如果参数初值是很小的值, 那么神经网络的训练将会很高效(参考ResNet训练残差模块的恒等映射); 如果不满足这个性质, 那么就需要用心的设值初始值( 这一条有待商榷 ) 如果不使用激活函数, 多层线性网络的叠加就会退化成单层网络,因为经过多层神经网络的加权计算，都可以展开成一次的加权计算 更形象的解释对于一些线性不可分的情况, 比如XOR, 没有办法直接画出一条直线来将数据区分开, 这个时候, 一般有两个选择. 如果已知数据分布规律, 那么可以对数据做线性变换, 将其投影到合适的坐标轴上, 然后在新的坐标轴上进行线性分类 而另一种更常用的办法, 就是使用激活函数, 以XOR问题为例, XOR问题本身不是线性可分的, https://www.zhihu.com/question/22334626 用ReLU解决XOR问题.首先, XOR问题如下所示: $x_1$ $x_2$ y 1 0 1 0 1 1 1 1 0 0 0 0 首先构造一个简单的神经网络来尝试解决XOR问题, 网络结构如下图所示: 先来看看不使用激活函数时的情况, 当不使用激活函数时, 整个网络的函数表达式如下所示: y = f(x_1, x_2; W, c, w ,b) = [w_1, w_2] \bigg( \bigg[\begin{matrix} W_{11} & W_{12} \\ W_{21} & W_{22} \end{matrix} \bigg] \Big[\begin{matrix} x_1 \\ x_2 \end{matrix} \Big]+ \Big[\begin{matrix} c_1 \\ c_2 \end{matrix} \Big] \bigg) + b = (w^TW^T)x + (w^Tc+b) = w'^Tx+b'可以看到, 多层无激活函数的网络叠加, 首先是会退化成单层网络, 而对于单层网络, 求解出来的参数 $w’$ 和 $b’$ 无法对非线性的数据进行分类. 再来看看进入ReLU以后, 是如何解决XOR问题的, 首先, 引入后的公式如下所示: y = f(x_1, x_2; W, c, w ,b) = [w_1, w_2] max \bigg(0 , \bigg[\begin{matrix} W_{11} & W_{12} \\ W_{21} & W_{22} \end{matrix} \bigg] \Big[\begin{matrix} x_1 \\ x_2 \end{matrix} \Big]+ \Big[\begin{matrix} c_1 \\ c_2 \end{matrix} \Big] \bigg) + b可以看到, 此时函数是无法化简, 因为此时引入了非线性的ReLU函数, 于是 ,就可以求得一个参数组合${w,W,c,b}$ 使得对于特定的输入$x_1, x_2$ ,能够得到正确的分类结果 $y$. 至于这个参数组合具体是什么, 这是需要通过梯度下降来不断学习的, 假如我们现在找到了一组参数如下(当然不一定是最优的), 来看看这组参数具体是如何解决XOR问题的: W=\bigg[ \begin{matrix} 1 & 1 \\ 1 & 1 \end{matrix} \bigg]c =\Big[ \begin{matrix} 0 \\ -1 \end{matrix} \Big]w =\Big[ \begin{matrix} 1 \\ -1 \end{matrix} \Big]b = 0然后, 分别将4种 $x_1, x_2$的值代入上式, 可以得到, y的值如下: $x_1$ $x_2$ 计算过程 y 1 0 $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 1 \\ 0 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$ 1 0 1 $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 0 \\ 1 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$ 1 1 1 $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 1 \\ 1 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$ 0 0 0 $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 0 \\ 0 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$ 0 关于各个激活函数的比较和适用场景神经元饱和问题: 当输入值很大或者很小时, 其梯度值接近于0, 此时, 不管从深层网络中传来何种梯度值, 它向浅层网络中传过去的, 都是趋近于0的数, 进而引发梯度消失问题 zero-centered: 如果数据分布不是zero-centered的话就会导致后一层的神经元接受的输入永远为正或者永远为负, 因为 $\frac{\partial f}{\partial w} = x$ , 所以如果x的符号固定,那么 $\frac{\partial f}{\partial w}$ 的符号也就固定了, 这样在训练时, weight的更新只会沿着一个方向更新, 但是我们希望的是类似于zig-zag形式的更新路径 (关于非0均值问题, 由于通常训练时是按batch训练的, 所以每个batch会得到不同的信号, 这在一定程度上可以缓解非0均值问题带来的影响, 这也是ReLU虽然不是非0 均值, 但是却称为主流激活函数的原因之一) 激活函数 优势 劣势 适用场景 Sigmoid 可以将数据值压缩到[0,1]区间内 1. 神经元饱和问题 2.sigmoid的输出值域不是zero-centered的 3. 指数计算在计算机中相对来说比较复杂 在logistic回归中有重要地位 Tanh 1. zero-centered: 可以将 $(-\infty, +\infty)$ 的数据压缩到 $[-1,1]$ 区间内 2.完全可微分的，反对称，对称中心在原点 1. 神经元饱和问题 2. 计算复杂 在分类任务中，双曲正切函数（Tanh）逐渐取代 Sigmoid 函数作为标准的激活函数 ReLU 1. 在 $(0,+\infty)$ ,梯度始终为1, 没有神经元饱和问题 2. 不论是函数形式本身,还是其导数, 计算起来都十分高效 3. 可以让训练过程更快收敛(实验结果表明比sigmoid收敛速度快6倍) 4. 从生物神经理论角度来看, 比sigmoid更加合理 1. 非zero-centered 2. 如果输入值为负值, ReLU由于导数为0, 权重无法更新, 其学习速度可能会变的很慢,很容易就会”死”掉(为了克服这个问题, 在实际中, 人们常常在初始化ReLU神经元时, 会倾向于给它附加一个正数偏好,如0.01) 在卷积神经网络中比较主流 LeakyReLU 1. 没有神经元饱和问题 2. 计算高效 3. 收敛迅速(继承了ReLU的优点) 4. 神经元不会”死”掉(因为在负值时, 输出不为0, 而是x的系数0.001) PReLU 1. 没有神经元饱和问题 2. 计算高效 3. 收敛迅速(继承了ReLU的优点) 4. 神经元不会”死”掉(因为在负值时, 输出不为0, 而是x的系数 $\alpha$ ) 5. 相对于Leaky ReLU需要通过先验知识人工赋值, PReLU通过迭代优化来自动找到一个较好的值, 更加科学合理, 同时省去人工调参的麻烦 ELU 1. 拥有ReLU所有的优点 2. 形式上更接近于zero-centered 3. 在面对负值输入时,更加健壮 1. 引入了指数计算, 使计算变的复杂 Maxout 1. 跳出了点乘的基本形式 2. 可以看作是ReLU和Leaky ReLU 的一般化形式 3. linear Regime(啥意思?)! 4. 在所有输入范围上都没有神经元饱和问题 5. 神经元永远不会”死”掉 6. 拟合能力非常强，它可以拟合任意的的凸函数。作者从数学的角度上也证明了这个结论，即只需2个maxout节点就可以拟合任意的凸函数了(相减)，前提是”隐含层”节点的个数可以任意多 1. 使得神经元个数和参数个数加倍, 导致优化困难 sigmoid 和softmax区别sigmoid是将一个正负无穷区间的值映射到(0,1)区间, 通常用作二分类问题,而softmax把一个k维的实值向量映射成一个$(b_1,b_2,…,b_k)$ ,其中$b_i$为一个0~1的常数, 且它们的和为1, 可以看作是属于每一类的概览,通常用作多分类问题. 在二分类问题中, sigmoid和softmax是差不多的, 都是求交叉熵损失函数, softmax可以看作是sigmoid的扩展, 当类别k为2时, 根据softmax回归参数冗余的特点, 可以将softmax函数推导成sigmoid函数 https://www.jianshu.com/p/22d9720dbf1a 什么情况下 ReLU 的神经元会死亡? 为什么? 如何解决?谈谈由异常输入导致的 ReLU 神经元死亡的问题: https://liam.page/2018/11/30/vanishing-gradient-of-ReLU-due-to-unusual-input/ 深度学习中，使用relu存在梯度过大导致神经元“死亡”，怎么理解？: https://www.zhihu.com/question/67151971 解决方法: 把 ReLU 换成 LReLU 或者 PReLU，保证让激活函数在输入小于零的情况下也有非零的输出。 采用较小的学习率 采用 momentum based 优化算法，动态调整学习率 激活函数的使用原则 优先使用ReLU, 同时要谨慎设置初值和学习率 ( 实际操作中，如果你的learning rate 很大，那么很有可能你网络中的40%的神经元都 “dead” 了。 当然，如果你设置了一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁 ) 尝试使用LeakyReLU/PReLU/Maxout/ELU等激活函数 可以试下tanh, 但是一般不会有太好的结果 不要使用sigmoid 其他更多激活函数https://www.jiqizhixin.com/articles/2017-10-10-3]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Batch-Normalization深入解析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Batch-Normalization%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[InceptionV2 在 V1 的基础上引入了 BN 层, 减少了 Internal Covariate Shift(内部神经元的数据分布差异), 使得每一层的输出都可以规范化到一个标准高斯分布上. 为什么要进行归一化在神经网络中, 数据分布对训练会产生影响. 当数据较大时, 有的激活函数比如 sigmoid 或者 tanh 的输出就会接近于 1, 此时的梯度就会接近于0, 处于激活函数的饱和阶段, 也就是说无论输入再怎么扩大, sigmoid 或者 tanh 激励函数输出值也还是接近1. 换句话说, 神经网络在初始阶段已经不对那些比较大的 x 特征范围敏感了. 因此我们需要用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 需要注意的是, 这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生.当没有进行normalizatin时,数据的分布是任意的,那么就会有大量的数据处在激活函数的敏感区域外, 对这样的数据分布进行激活后, 大部分的值都会变成1或-1, 造成激活后的数据分布不均衡, 而如果进行了Normallizatin, 那么相对来说数据的分布比较均衡.一句话总结就是: 通过Normalization让数据的分布始终处在激活函数敏感的区域 简述 BN 的原理在训练深度神经网络时, 每个隐藏层的参数变化会使得后一层的输入发生变化, 从而每一批训练数据的分布也随之改变, 导致网络在每次迭代中都需要拟合不同的数据分布, 增大了训练的复杂度以及过拟合的风险. 这使得我们需要非常谨慎的去设定学习率, 初始化权重等参数更新策略. 因此, 为了保证网络层中的每一批数据都处于相同的数据分布下, 我们需要在网络的每一层输入之前增加归一化处理, 具体来说, 就是对当前 batch 中的所有元素减去均值再除以标准差. 这样的归一化操作可以对原始数据添加额外的约束, 从而可以增强模型的泛化能力, 但同时, 由于简单归一化之后的数据分布被强制为 0 均值和 1 标准差, 因此可能会破坏原始数据本身的特征. 为了能够还原原始数据分布, BN 的第二个关键操作就是引入了用于变换重构的线性偏移参数 $\gamma$ 和 $\beta$, 它们分别对简单归一化后的数据执行 scale 和 shift 操作, 可以在一定程度还原数据本身的分布特别. 总体来说, BN 的作用可以简单概括为两步, 第一步是进行归一化, 用于统一不同网络层的数据分布; 第二步变换重构, 用于恢复原始数据的特征信息. \mu = \frac{1}{m}\sum_{i=1}^{m}{x_i}\sigma^2 = \frac{1}{m} \sum_{i=1}^{m}{(x_i - \mu)}\hat x_i = \frac{x_i - \mu}{\sqrt{\sigma^2}+\varepsilon}\hat y_i = \gamma \hat x_i + \betaBN 解决了什么问题BN 主要解决的是深层网络中不同网络数据分布不断发生变化的问题, 也就是 Internal Covariate Shift. 该问题是指在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift. ICS 带来了两个问题: 上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低 网络的训练过程容易陷入梯度饱和区,减缓网络收敛速度 使用 BN 有什么好处总的来说，BN通过将每一层网络的输入进行归一化, 保证输入分布的均值与方差固定在一定范围内, 减少了网络中的 Internal Covariate Shift问题, 加速了模型收敛; 并且 BN 可以使得网络对参数的设置如学习率, 初始权重等不那么敏感, 简化了调参过程, 使得网络学习更加稳定; 同时 BN 使得网络可以使用饱和性激活函数如 Sigmoid, tahh 等, 从而缓解了梯度消失问题; 最后 BN 在训练过程中由于使用的 mini-batch 的均值和方差每次都不同，因此引入了随机噪声，在一定程度上对模型起到了正则化的效果, 也就是说, BN 可以起到和 Dropout 类似的作用, 因此在使用 BN 时可以去掉 Dropout 层而不会降级模型精度. 原因如下: https://zhuanlan.zhihu.com/p/34879333(1) BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度BN通过规范化与线性变换使得每一层网络的输入数据的均值与方差都在一定范围内，使得后一层网络不必不断去适应底层网络中输入的变化，从而实现了网络中层与层之间的解耦，更加有利于优化的过程,提高整个神经网络的学习速度。 (2) BN使得模型对初始化方法和网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定在神经网络中，我们经常会谨慎地采用一些权重初始化方法（例如Xavier）或者合适的学习率来保证网络稳定训练。当学习率设置太高时，会使得参数更新步伐过大，容易出现震荡和不收敛… (3) BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题在不使用BN层的时候，由于网络的深度与复杂性，很容易使得底层网络变化累积到上层网络中，导致模型的训练很容易进入到激活函数的梯度饱和区；通过normalize操作可以让激活函数的输入数据落在梯度非饱和区，缓解梯度消失的问题；另外通过自适应学习 $\gamma$ 与 $\beta$ 又让数据保留更多的原始信息。 (4)BN具有一定的正则化效果在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，与Dropout通过关闭神经元给网络训练带来噪音类似，在一定程度上对模型起到了正则化的效果。原作者也证明了网络加入BN后，可以丢弃Dropout，模型也同样具有很好的泛化效果。 BN 层通常处于网络中的什么位置BN 通常应用于网络中的非线性激活层之前, 将卷积层的输出归一化, 使得激活层的输入在 [0, 1] 之间, 避免梯度消失的问题. BN 中 batch 的大小对网络性能有什么影响由于 BN 在计算均值和方差时是在当前的 batch 上进行计算的, 因此, 当 batch 较小时, 求出来的均值和方差就会有较大的随机性, 从而导致效果下降, 具体来说, 当 batch 的大小低于 16 时, 就不建议使用 BN, 当 batch 低于 8 时, 网络的性能就会有非常明显的下降. BN 中线性偏移的参数个数怎么计算的对于 BN 层来说, 如果它的输入 shape 均为为 $(N, C, H, W)$, 则其输出 shape 也为 $(N, C, H, W)$, 即保持输入输出 shape 不变. BN 中的线性偏移参数 $\gamma$ 和 $beta$ 的个数 与输入 shape 的通道数相同, 均为 $C$. PyTorch 中 $\gamma$ 和 $\beta$ 参数分别对应着weight和bias, 下面是 BN 的声明.1torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) BN 中使用的均值和方差是如何求得的在训练阶段, 就是利用当前 batch 中的均值和方差进行计算.在测试阶段, 采用的是网络中维护的滑动平均值进行计算的, 滑动平均值的维护方式是用当前的滑动平均值乘以一个 $decay$ 系数, 然后再加上 $(1 - decay)$ 倍的当前 batch 的统计值. $decay$ 决定了数值的更新速度, 通常 $decay$ 会设成一个非常接近于 1 的数, 比如, 0.99 或 0.999. shadow_variable = decay \times shadow_variable + (1 - decay) \times variable. 在多卡训练使用 BN 时, 需要注意什么问题需要注意多卡之间的通信同步问题目前大部分的框架, 包括 Caffe, PyTorch, TF 等, 对于 BatchNorm 的实现都只考虑了 single GPU, 也就是说 BN 使用的均值和标准差是单个 GPU 计算的, 这相当于缩小了 mini-batch size. 至于为什么这样实现: (1) 因为没有 sync 的需求, 因为对于大多数 vision 问题, 单 GPU 上的 mini-batch 已经够大了, 完全不会影响结果. (2) 影响训练速度, BN layer 通常是在网络结构里面广泛使用的, 这样每次都同步一下 GPUs, 十分影响训练速度. BN 的具体实现及其反向传播公式是如何计算的具体实现: 两个 Scale 层. 反向 https://www.jianshu.com/p/4270f5acc066https://zhuanlan.zhihu.com/p/27938792 在Caffe2实现中, BN层需要和Scale层配合使用, 其中, BN专门用于做归一化操作, 而后续的线性变换层, 会交给Scale层去做. 训练阶段:在训练时利用当前batch的mean和variance来进行BN处理, 同时使用滑动平均的方式不断的更新global 的mean和variance, 并将其存储起来. 测试阶段:在预测阶段, 直接使用模型存储好的均值和方差进行计算 使用 BN 时, 前一层的卷积网络需不需要偏置项, 为什么使用 BN 时的前一层卷积网络可以不加偏置项(降低模型参数量)当使用 BN 时, 无论加偏置还是不加偏置, 效果都是一样的, 公式证明如下: 当卷积层后跟batchnormalization层时为什么不要https://blog.csdn.net/u010698086/article/details/78046671 CChttps://zhuanlan.zhihu.com/p/36222443 另外, 在 BN 中的 $\beta$ 参数也可以起到一定的偏置作用. 使用BN时应注意的问题bn总结: https://www.cnblogs.com/makefile/p/batch-norm.html]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《牛客网算法进阶班》视频教程笔记]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B-%E7%89%9B%E5%AE%A2%E7%BD%91%E7%AE%97%E6%B3%95%E8%BF%9B%E9%98%B6%E7%8F%AD%2F</url>
    <content type="text"><![CDATA[第一章大部分机器一秒钟可接受的操作大约在 $10^8$. 题目一: 判断一个整数是否为回文数解法一: 先转成字符串再计算回文至少需要遍历两遍 解法二: 借助 helphelp 代表最高位的阶数, 于是 num/help 就可以得到第一位的数字, num%10 就可以得到最后一位的阶数, 然后对 num 进行除法和取余, 使得去掉两端, 同时 help/100, 继续下一次判断. 不用转换 1234567891011121314151617if (n &lt; 0) &#123; return false;&#125;int help = 1;while (n / help &gt;= 10) &#123; help = help * 10;&#125;while (n != 0) &#123; if (n / help != n % 10) &#123; return false; &#125; n = (n % help) / 10; help /= 100;&#125;return true; 题目二:题目三:题目四:题目五:题目六:]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>视频教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[训练过程中遇到的问题及解决方案]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题?(百面: 1.07.1)带来的问题: 过拟合处理方法 基于模型的方法: 采用降低过拟合风险的措施,包括简化模型(如将非线性简化成线性), 添加约束项以缩小假设空间(如L1和L2正则化), 集成学习, Dropout超参数等. 基于数据的方法, 主要通过数据扩充(Data Augmentation), 即根据一些先验知识, 在保持特定信息的前提下, 对原始数据进行适合变换以达到扩充数据集的效果. 在图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换： 观察角度：一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等 噪声扰动：椒盐噪声、高斯白噪声 颜色变换：在RGB颜色空间上进行主成分分析 其他：亮度、清晰度、对比度、锐度 其他扩充数据方法：特征提取, 在图像的特征空间内进行变换：数据扩充or上采样技术，如SMOTE（Synthetic Minority Over-sampling Technique)。 最后，迁移学习或者用GAN合成一些新样本也可帮助解决数据不足问题。 如何解决数据不均衡问题?https://www.cnblogs.com/zhaokui/p/5101301.html 训练不收敛的具体表现是什么? 可能的原因是什么? 如何解决?我们主要通过观察 loss 曲线来判断是否收敛, 根据不同的 loss 曲线, 有以下三种不收敛的情形: 从训练开始曲线就一直震荡或者发散 可能原因: (1) 学习率设置的过大; (2) 向网络中输入的数据是错误数据, 如标签对应错误, 读取图片时将宽高弄反, 图片本身质量极差等; 解决方法: 调节学习率; 检查数据读取代码 在训练过程中曲线突然发散 可能原因: (1) 学习率设置过大, 或者没有采用衰减策略; (2) 读取到了个别的脏数据, 如标签对应错误, 或者标签为空等 解决方法: 调整学习率及相应的衰减策略; 将 batch size 设为 1, shuffle 置为 false, 检查发散时对应的数据是否正确; 在训练过程中曲线突然震荡 可能原因: (1) 损失函数中的正则化系数设置有问题, 或者损失函数本身存在 Bug; (2) 数据存在问题 解决方法: 检查损失函数; 检查数据 训练过程中出现 Nan 值是什么原因? 如何解决?Nan 是 “Not a number” 的缩写, 出现 Nan 的可能情况一般来说有两种: 一种是梯度爆炸, 使得某一层计算出来的值超过了浮点数的表示范围 另一种是由于损失函数中 $log$ 项的值出现的负值或者 0 导致的, 因为 $logx$ 只在 $x$ 大于 0 的时候才有意义. 解决梯度爆炸的方法通常是对数据进行归一化(BN, GN 等), 减小学习率, 加入 gradient clipping, 更换参数初始化方法(待商榷). 对于 $log$ 项出现负值或者 0 的情况(Softmax 激活函数的取值范围是 [0,1], 因此有可能输出 0), 首先确保网络使用了正确的初始化方法(若参数全为 0, 则输出也为 0), 其次, 检查数据本身是否存在问题, 因为实际业务上的真实数据通常还有大量的脏数据, 有时候数据本身就还有 Nan 值, 因此, 在训练网络之前 先要确保数据是正确的. 可以设计一个简单的小网络, 然后将所有数据跑一遍, 再根据日志信息去除其中的脏数据. loss 的计算问题, 当我们采用先求取loss的和, 再做归一化除法时, 如果batch_size过大, 那么loss之和可能会超过数据类型的表示上限, 此时, 有两种解决方法, 一种是将数据类型的表示范围提高, 例如将float变成double, 但是这样也不保险, 较好的做法是在计算loss时, 避免添加操作, 或者预先估计loss的大小1234# 提升 loss 的表示范围, 修改自 ssd.pytorch 代码N = num_pos.data.sum().double()loss_l = loss_l.double()loss_c = loss_c.double() 如果以上方法都不能解决问题的话, 那应该就是网络结构本身或者损失函数可能存在 Bug, 需要进一步更细致的分析. 如将网络拆解开来, 减少层数, 对不同层进行测试等等. 过拟合是什么? 如何处理过拟合?过拟合定义: 当模型在训练数据上拟合的非常好, 但是在训练数据意外的测试集上却不能很好的拟合数据, 此时就说明这个模型出现的过拟合现象. 解决方法: 使用正则项(Regularization): L1, L2 正则 数据增广(Data Augmentation): 水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转等等, 也可利用GAN辅助生成(不常用) Dropout: Dropout是指在深度网络的训练中, 以一定的概率随机的”临时丢弃”一部分神经元节点. 具体来讲, Dropout作用于每份小批量训练数据, 由于其随机丢弃部分神经元的机制, 相当于每次迭代都在训练不同结构的神经网络, 可以被认为是一种实用的大规模深度神经网络的模型继承算法. 对于包含 $N$ 个神经元节点的网络, 在Dropout的作用下可以看作为 $2^N$ 个模型的集成, 这 $2^N$ 个模型可认为是原始网络的子网络, 它们共享部分权值, 并且拥有相同的网络层数, 而模型整个的参数数目不变, 大大简化了运算. 对于任意神经元来说, 每次训练中都与一组随机挑选的不同的神经元集合共同进行优化, 这个过程会减弱全体神经元之间的联合适应性, 减少过拟合的风险, 增强泛化能力. 工作原理和实现: 应用Dropout包括训练和预测两个阶段, 在训练阶段中, 每个神经元节点需要增加一个概率系数, 在前向传播时, 会以这个概率选择是否丢弃当前的神经元. 在测试阶段的前向传播计算时, 每个神经元的参数都会预先乘以概率系数p, 以恢复在训练中该神经元只有p的概率被用于整个神经网络的前向传播计算 Drop Connect: Drop Connect 是另一种减少算法过拟合的正则化策略，是 Dropout 的一般化。在 Drop Connect 的过程中需要将网络架构权重的一个随机选择子集设置为零，取代了在 Dropout 中对每个层随机选择激活函数的子集设置为零的做法。由于每个单元接收来自过去层单元的随机子集的输入，Drop Connect 和 Dropout 都可以获得有限的泛化性能 [22]。Drop Connect 和 Dropout 相似的地方在于它涉及在模型中引入稀疏性，不同之处在于它引入的是权重的稀疏性而不是层的输出向量的稀疏性。 早停: 早停法可以限制模型最小化代价函数所需的训练迭代次数。早停法通常用于防止训练中过度表达的模型泛化性能差。如果迭代次数太少，算法容易欠拟合（方差较小，偏差较大），而迭代次数太多，算法容易过拟合（方差较大，偏差较小）。早停法通过确定迭代次数解决这个问题，不需要对特定值进行手动设置。 Reference:https://www.cnblogs.com/callyblog/p/8094745.html 欠拟合是什么? 如何处理欠拟合?过拟合定义: 当模型在训练数据和测试数据上都无法很好的拟合数据时, 说明出现了欠拟合 解决方法: 首先看看是否是神经网络本身的拟合能力不足导致的, 具体方法是让神经网络在每次训练时, 只迭代 同样的数据, 甚至每一个 batch 里面也是完全相同一模一样的数据, 再来看看 loss 值和 accurancy 值的变化. 如果这时候 loss 开始下降, accurancy 也开始上升了, 并且在训练了一段时间后神经网络能够正确地计算出所训练样本的输出值, 那么这种情况属于神经网络拟合能力不足. 因为对于大量的数据样本, 神经网络由于自身能力的原因无法去拟合全部数据, 只能拟合大量样本的整体特征, 或者少数样本的具体特征. 对于拟合能力不足问题, 通常可以增加网络层数, 增加神经元个数, 增大卷积核通道数等方法. 如果不是拟合能力不足导致的欠拟合, 就需要尝试其他方法, 更改网络初始化方法(Xavier, MSRA), 更改优化器, 降低学习率 Dropout 的实现方式在训练阶段和测试阶段有什么不同? 如何保持训练和测试阶段的一致性?Dropout 的实现方式有两种: 直接 Dropout: 使用较少, AlexNet 使用的是这种Dropout. 该方法在训练阶段会按照保留概率来决定是否将神经元的激活值置为0. 同时, 为了保持训练阶段和测试阶段数值的一致性, 会在测试阶段对所有的计算结果乘以保留概率. Inverted Dropout: 这是目前常用的方法. 该方法在训练阶段会按照保留概率来决定是否将神经元的激活值置为0, 并且, 在训练阶段会令输出值都会乘以 $\frac{1}{\alpha_{dropout}}$, 这样一来, 在训练阶段可以随时更改 dropout 的参数值, 而对于测试阶段来说, 无需对神经元进行任何额外处理, 所有的神经元都相当于适配了训练过程中 dropout 对参数数值大小带来的影响. Dropout 为什么可以起到防止过拟合的作用? 如何选取 Batch Size 的值? 显存中通常会存储哪些东西?]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 源码解析-网络工具函数]]></title>
    <url>%2Fz_post%2FCaffe2-Detectron-%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[源码文件: detectron/utils/net.py detectron/utils/c2.py detectron/utils/vis.py: 结果可视化 utils/net.py这个文件经常会被使用到, 它主要的作用提供一些可以使 Caffe2 networks 更方便使用的辅助函数, 该文件解读如下(该文件中包含多个辅助函数, 按照函数在文件中的顺序从上到下逐个解读)]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
        <tag>Detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Group Normalization]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-GroupNormalization-ECCV2018%2F</url>
    <content type="text"><![CDATA[作者: Yuxin Wu and Kaiming He发表: ECCV 2018, Best Paper Honorable Mention 核心亮点针对BN对batch size的依赖问题, 提出了一种新的通用型归一化方法提出了一个用于替代BN的简单算法, 称之为GN(Group Normalization). GN将输入图谱的通道分成不同的组, 并且计算每一组的mean和variance, 然后将其进行归一化. GN的计算复杂度与batch size 的大小是相互独立的, 并且它的准确度在不同范围内的batch size下仍然是稳定的. 并且在整体表现和不同任务上的效果均强于其他类型的归一化方法(LN,IN等) 摘要BN是深度学习中的一项里程碑式的技术, 它可以让不同网络进行训练. 但是按照batch进行归一化的过程会引入一些问题: 当batch的size比较小时, 由于batch的统计期望十分不精确, 会使得BN的误差大幅度增加. 这一点限制了BN在训练大型模型时的使用(如目标检测, 分割等等, 由于GPU内存的限制往往batch的值很小). 因此, 本文提出了一个用于替代BN的简单算法, 称之为GN(Group Normalization). GN将输入图谱的通道分成不同的组, 并且计算每一组的mean和variance, 然后将其进行归一化. GN的计算复杂度与batch size 的大小是相互独立的, 并且它的准确度在不同范围内的batch size下仍然是稳定的. 在ResNet50中, 当batch size为2时, GN的错误率比BN要低10.6%, 当batch size为经典值时(32,64等), GN的表现也可以媲美BN, 同时, 也超越了其他归一化方法(Layer, Instance, Weight Normalization等). 不仅如此, GN还可以很自然的从预训练的模型中进行fine-tuning. GN在多个任务上都表现出了很好的效果, 可以用其替换掉BN. (只需数行代码即可实现GN). 介绍BN在多项任务中都起到了很好的实验效果, 但是BN的有效性必须建立在足够大的batch size之上(如32/GPU). 当batch size 比较小时, BN往往无法取得好的效果, 并且还会提升模型的误差, 如图1所示. 由于硬件GPU显存大小的设置, 在使用较大的模型训练分辨率较高的图片时, 往往不能设置很高的batch size. 因此, 本文提出了GN算法来作为BN的代替. 相关工作Normalization: BN在很多任务上都取得了很好的效果(BN通常会在每一层都执行), 但是, BN依赖于batch的平均值和方差, 这使得batch size的大小对BN的效果有较大的影响, 同时, 在测试阶段, 单个的图片是没有均值和方差的, 所以只能用整个数据集的均值和方差来代替, 通常会使用滑动平均来维护这两个变量, 也就是说, 在使用BN时, 如果数据集改变了, 则均值和方差就会有较大改变, 这就造成了训练阶段和测试阶段的不一致性, 由此也会带来一些问题.另一些Normalization方法, 尝试避开batch size, 如Layer Normalization(LN)和Instance Normalization等, 但他们通常是针对RNN/LSTM模型的, 并且在大多数的视觉任务上表现不如BN好, 还有Weight Normalization, 它不是对网络层的输入进行归一化, 而是对网络层的参数进行归一化, 同样, 在大多数的视觉任务上, 表现都不如BN. Addressing small batches: Ioffe在NIPS2017上提出Batch Renormalization(BR)尝试解决BN的小batch size问题. 它引入了两个额外的参数来限制BN的估计期望和方差, 减少它们在小batch size时的不稳定问题. 但是BR本质上还是依赖于batch的, 当batch较小时, 其性能也会相应下降(不过下降较少).也有的工作尝试避免使用小batch size. CVPR2018的一篇文章通过同步BN的方法, 使得模型可以在多GPU上计算平均值和方差, 但是, 这个方法并没有才本质上解决BN的问题, 相反的, 它的方法更像是一种工程和硬件上的解决方案, 希望以此来达到BN的要求. 不仅如此, 这种同步BN方案也使得模型在工业中的大规模分布式训练下无法利用异步的优化方法, 如ASGD. Group-wise computation: Group convolution计算在多个模型中都有提及. 但是本文的GP并不需要组卷积计算, 它是一个一般化的网络层(generic layer). Group Normalization特征图谱中的各个channels之前也并不是完全互相独立的. 公式典型的归一化公式形式(BN,LN,IN,GN)为: \hat x_i = \frac{x_i - \mu_i}{\sigma_i}上式中, $x$ 代表某一层的特征, $i$ 代表下标, 在2D图像中, $i=(i_N, i_C, i_H, i_W)$ , 是一个4D的向量. $\mu$ 和 $\sigma$ 分别为期望和标准差, 通过下式计算得到: \mu_i = \frac{\sum_{k\in S_i} x_k}{m}, \sigma_i = \sqrt{\frac{sum_{k\in S_i} (x_k-\mu_i)^2}{m} + \epsilon}大多数的Normalization方法的不同之处就在于集合 $S_i$ 的不同(如图2所示): BN: $S_i = \{k | k_C = i_C \}$, 代表BN是在求每一个channel的均值和方差. 也即 $C$ 不变, 求固定 $C$ 时 $(N,H,W)$ 的均值和方差 LN: $S_i = \{k | k_N = i_N \}$, 代表 $N$ 不变, 求固定 $N$ 以后 $(C,H,W)$ 的均值和方差(可以看出, 此时的均值和方差已经不受batch size的影响) IN: $S_i = \{k | k_N = i_N, k_C = i_C\}$, 代表 $N$ 和 $C$ 都固定时 , $(H,W)$ 的均值和方差. 也就是说是对单个特征中, 单个通道上的均值和方差. 上面所有的Normalization方法(BN,LN,IN)都使用了线性偏移来补偿可能引起的数据分布表征丢失问题($\gamma$ 和 $\beta$ 都通过 $i_C$ 作为下标, 也就是对于每个通道都有不同的 $\gamma$ 和 $beta$): y_i = \gamma x_i + \betaGroup Norm: 在Group Norm中, $\mu$, $\sigma$ 以及集合 $S_i$ 的定义如下: S_i = \{ k | k_N = i_N, \lfloor \frac{k_C}{C/G} \rfloor = \lfloor \frac{i_C}{C/G} \rfloor \}上式中, $G$ 是group的数量, 是一个超参数(默认为32), $C/G$ 是每一个group中的channels的数量, $\lfloor \frac{k_C}{C/G} \rfloor = \lfloor \frac{i_C}{C/G} \rfloor \}$ 意味着下标 $i$ 和 $k$ 在同一个group内. GN计算的 $\mu$ 和 $\sigma$ 是处于同一个group的所有通道上的 $(H,W)$ 的均值和方差, 具体的计算方式如图2最右侧所示, 在该图实例中, G=2, 并且每一个group具有3个channels. GN同样会在每一个channel中使用参数 $\gamma$ 和 $\beta$ 对数据执行线性偏移. 具体来说, 处于同一个 group 当中的所有像素都会被都一个 $\mu$ 和 $\simga$ 归一化, GN 会在每个通道上都学习参数 $\gamma$ 和 $\beta$. (注意是通道, 不是 Group) Relation to Prior Work: 很明显, LN和IN实际上可以看做是GN的一种特例情况(如图2). 当 $G=1$ 时, GN就变成LN, 当 $G=C$ 时, GP就变成了IN. 实现就和GN的思想一样, GN实现起来也十分简单, 下图是GN基于python和tensorflow的实现代码, 从代码中可以看到, $\gamma$ 和 $\beta$ 的shape为 [1,C,1,1], 也就是说, $\gamma$ 和 $\beta$ 在同一个group中的不同channel来说, 值是不一样的. 实验 简述 GN 的原理BN 在很多任务上都取得了很好的效果(BN通常会在每一层都执行), 但是, BN 依赖于 batch 的平均值和方差, 这使得 batch size 的大小对BN的效果有较大的影响, 同时, 在测试阶段, 单个的图片无法提供良好的均值和方差进行归一化, 所以只能用整个数据集的均值和方差来代替, 通常会使用滑动平均来维护这两个变量, 也就是说, 在使用 BN 时, 如果数据集改变了, 则均值和方差就会有较大改变, 这就造成了训练阶段和测试阶段的不一致性, 由此也会带来一些问题. 因此, GN 为了解决 BN 对 batch 大小的依赖问题, 转而从另一个角度来进行归一化, GN 更像是介于 LN 和 IN 中间的一种归一化方法, 它会将通道分成不同的组, 同时在固定下标 N 的同时, 求取当前组内的均值和方差来进行归一化. 通过实验分析和论证, GN 可以取得不错的效果, 避免了对 batch 的依赖问题. 为什么 GN 效果好GN 是从 LN 和 IN 中变化来的, 组的划分实际上可以看做是一种对数据分布的假设, 以 LN 为例, 它实际上假设了每张图片所有通道的特征都是同分布的, 而 GN 则是假设每个组的分布不同, 条件没有那么苛刻, 因此 GN 的表现力和包容性会更强, 而 IN 只依赖与独立的某一维, 没有探究不同通道之间特征的关联性. 相对于 BN 来说, 当 batch 的大小足够时, BN 的性能表现依然很不错, 因此, GN 充当的角色更像是当 batch 较小, 无法使用 BN 时的一种替代措施. 传统角度来讲，在深度学习没有火起来之前，提取特征通常是使用SIFT，HOG和GIST特征，这些特征有一个共性，都具有按group表示的特性，每一个group由相同种类直方图的构建而成，这些特征通常是对在每个直方图（histogram）或每个方向（orientation）上进行组归一化（group-wise norm）而得到。而更高维的特征比如VLAD和Fisher Vectors(FV)也可以看作是group-wise feature，此处的group可以被认为是每个聚类（cluster）下的子向量sub-vector。从深度学习上来讲，完全可以认为卷积提取的特征是一种非结构化的特征或者向量，拿网络的第一层卷积为例，卷积层中的的卷积核filter1和此卷积核的其他经过transform过的版本filter2（transform可以是horizontal flipping等），在同一张图像上学习到的特征应该是具有相同的分布，那么，具有相同的特征可以被分到同一个group中，按照个人理解，每一层有很多的卷积核，这些核学习到的特征并不完全是独立的，某些特征具有相同的分布，因此可以被group。导致分组（group）的因素有很多，比如频率、形状、亮度和纹理等，HOG特征根据orientation分组，而对神经网络来讲，其提取特征的机制更加复杂，也更加难以描述，变得不那么直观。另在神经科学领域，一种被广泛接受的计算模型是对cell的响应做归一化，此现象存在于浅层视觉皮层和整个视觉系统。作者基于此，尝试使用了组归一化（Group Normalization）的方式进行模型训练, 结果意外发现训练效果非常不错, 显著优于BN、LN、IN等。 简述 BN, LN, IN, GN 的区别这些 Norm 方法的不同之处就在于计算均值和方差时使用的像素集合不同(如图2所示), 假设输入的 tensor 的 shape 为 $(N, C, H, W)$: BN 是固定 $C$ 不变, 求固定 $C$ 时所有 $(N,H,W)$ 像素点的均值和方差, 这个均值和方差会用来归一化所有处于当前通道 $C$ 上的像素. LN 是固定 $N$ 不变, 求固定 $N$ 时所有 $(C,H,W)$ 像素点的均值和方差, 这个均值和方差会用来归一化所有处于当前 $N$ 上的像素. 可以看出, 这里 LN 在求取均值和方差时, 由于固定了 $N$, 所以与 batch 的大小无关. IN 是同时固定 $N$ 和 $C$ 不变, 求固定 $N$ 和 $C$ 时所示 $(H,W)$ 像素点的均值和方差. GN 是介于 LN 和 IN 中的一种 Norm 方法, 它首先也是固定 $N$ 不变, 然后会将 $C$ 分成若干个 Group, 然后分别求取每个 Group 的均值和方差, 并对 Group 中的像素进行归一化 注意, 无论是哪种 Norm 方法, 它们使用的线性偏移的参数个数都等于通道 $C$ 的大小. GN 中线性偏移的参数个数怎么计算的对于 GN 层来说, 如果它的输入 shape 均为为 $(N, C, H, W)$, 则其输出 shape 也为 $(N, C, H, W)$, 即保持输入输出 shape 不变. GN 中的线性偏移参数 $\gamma$ 和 $beta$ 的个数 与输入 shape 的通道数相同, 均为 $C$. GN 除了需要确定输入层的通道数以外, 还需要确定 Goup 的数量. 下面给 PyTorch 中 GN 的声明.1torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True) GN, 在进行归一化时, 使用的mean和var是按照组进行划分的, 但是, 在进行偏移时的gamma和beta参数, 仍然是与 channel 数量保持一致的 其他预训练很重要, 尤其是当你的数据集很小时,它可以有效的防止过拟合, 提高泛化能力]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R-FCN (NIPS, 2016)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-R-FCN-NIPS2016%2F</url>
    <content type="text"><![CDATA[文章: R-FCN: Object Detection via Region-based Fully Convolutional Networks 核心亮点 全卷积网络怎分类任务上表现较好, 但是在目标检测任务往往精度不行, 这是因为在一般情况下, 分类任务具有平移不变性, 而检测任务却要求对目标的平移做出正确响应. 在Faster RCNN类的方法中RoI pooling之前都是卷积, 具有平移不变性, 但是一旦经过RoI pooling 之后, 后面的网络结果就不再具备平移不变性了. 因此, 本文了position sensitive score map来将目标位置的信息融合进RoI 对于Faster RCNN等基于感兴趣区域的检测方法来说, 实际上是分成了几个subnetwork, 第一个用来在整张图上做比较耗时的conv, 这些操作与region无关, 是计算共享的. 第二个subnetwork是用来产生候选区域(如RPN), 第三个subnetwork是用来分类或者进一步对box进行回归的, 这个subnetwork和region是有关系的, 衔接在这个subnetwork和前两个subnework中间的就是RoI pooling. 本文与FasterRCNN相比(前91层共享, RoI pooling之后, 后10层不共享)不同, 将ResNet所有的101层都放在的前面共享的subnetwork中, 最后用来进行prediction的卷积只有1层, 大大减少了计算量. 最终, 从实验结果来看, 本文提出的用于目标检测任务的全卷积网络在精度上仍然不如标准的Faster RCNN, 但是在test time上要好于FasterRCNN (因为有大部分层都变成参数共享的了). 论文细节摘要本文提出了一个用于精确高效进行物体检测的基于区域的全卷积网络. 在Fast/Faster RCNN中, 使用了计算成本很大的子网络来提取候选区域, 与之相比, 本文的基于区域的检测器是全卷积的, 因此几乎所有的计算都可以共享. 为了达到这个目标, 本文提出了一个位置敏感的score maps来解决图像分类问题中的平移不变性和物体检测中的平移可变性之间的鸿沟. 因此, 本文的方法可以很自然的使用全卷积图像分类网络, 比如ResNet. 本文的方法在检测阶段的速度大约为FasterRCNN的2.5~20倍. 介绍最近的图像分类网络如 ResNet 和 GoogleNets 都是通过全卷积网络设计的.(只有最后一层是全连接的, 并且该层会在进行目标检测任务时被去掉). 我们讨论了之前提到的不自然的设计是由于图像分类的平移不变性和目标检测的平移可变性之间的鸿沟造成的. 一方面, 在图像级别上的分类任务倾向于平移不变性, 因此, 深度卷积网络的结构会尽可能是使得结果的检测具有一定的平移不变性. 另一方面, 物体检测任务需要坐标表示, 这是一种平移可变性的表现. 为了解决这个问题, ResNet的检测方法是插入了一个RoI pooling 层—该层可以用来打破神经网络原有的平移不变性, RoI后续的卷积层在对不同区域进行评价时, 实际上已经不再具有平移不变性(出现在天空位置时, 行人的预测概率较低). 但是, 这种RoI的设计模型牺牲了训练和测试的高效性, 因为它引入了大量额外的快计算. 在这篇文章中, 我们构建了一个用于物体检测任务的基于区域的全卷积网络的框架模型. 我们的网络模型由共享的全卷积网络组成. 为了与FCN的平移可变性相协调, 我们构建了一个位置敏感型的score maps. 每一个score maps都根据相对空间位置将位置信息进行了编码. 在FCN之上, 我们添加了一个位置敏感的RoI pooling layer 用于指导从score maps中获取的信息, 并且在其后没有再使用带权重的层(全连接or全卷积). Our approachOverview: 和RCNN一样, 本文使用了 two-stage 的物体检测策略, 包括:1) 区域推荐, 2)区域分类. 本文通过RPN网络来提取候选框(RPN网络本身也是一个全卷积网络). 和Faster RCNN一样, 我们令RPN和R-FCN网络的权重参数共享. 下面的图2显示了这个系统的整体视图 (位于上方的RPN网络和位于下方的R-FCN网络使用的卷积图谱都是来自同一段卷积网络, 因此参数共享): 当给定感兴趣区域(proposals regions)后, R-FCN网络会用于对RoIs分类. 在R-FCN中, 所有的可学习的参数都是卷及参数, 并且都是在同一张图片上计算得到的. 最后一层卷积层对于每一类都会输出 $k^2$ 个位置敏感的socre maps, 因此总共有对于具有 $C$ 个物体类别来说, 输出层具有 $k^2(C+1)$ 个通道. $k^2$ 主要是根据用于描述相关位置的 $k\times k$ 的空间网格来决定. 比如, 当 $k \times k = 3\times 3$ 时, 对于每一个物体类别都会有9个score maps 根据下列情况进行编码: {top-left, top-center, top-right, … , bottom-right}. R-FCN最后会有一个位置敏感的RoI pooling层, 这一层会将最后一层卷积层的输出全部整合, 并为每个RoI生成对应的score. 和之前的工作不同, 本文的位置敏感型的RoI层会执行selective pooling, 并且每一个$k\times k$ bin 都会整个仅一个score map. 下面的图展示了示例: Backbone architecture: R-FCN的网络主体是基于ResNet-101的, 我们将平均池化层和fc层移除, 只使用前面的卷积网络来计算特征图谱. 由于卷积段输出的维度为2048, 因此我们使用 $1\times 1$ 的卷积层来进行降维, 使其维度变成1024. 然后我们使用通道数为 $k^2(C+1)$ 的卷积层来生成score maps. Position-sensitive score maps &amp; Position-sentitive RoI pooling. 为了具体的对每个RoI的位置信息进行编码, 我们将每一个RoI划分成 $k\times k$ 大小的普通网格, 然后, 最后一层卷积层对每一个类别都会生成 $k^2$ score maps, 在第 $(i,j)$ 个bin中 $(0 \leq i,j \leq k-1)$. 我们定义位置敏感的RoI pooling计算操作如下所示: r_c(i,j | \theta) = \sum_{(x,y)\in bin(i,j)} z_{i,j,c}(x+x_0, y+y_0 | \theta)/n]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Soft-NMS(ICCV, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SoftNMS-ICCV2017%2F</url>
    <content type="text"><![CDATA[作者: Navaneeth Bodla, Bharat Singh, Rama Chellappa, Larry S.Davis发表: ICCV2017机构: Center For Automation Research 核心亮点提出了一种NMS的变体, 通过利用该变体, 基本上可以提升任何模型的检测准确率作者们提出了一种新式的NMS算法, 并且利用该算法, 可以普遍提高当前现有模型的召回率(尤其是面对重叠程度大的物体), 同时, 由于可以不增加复杂度的情况下直接用该算法替换传统NMS算法, 因此, 在替换SoftNMS时, 无需更改模型的任何参数, 也无需重新训练模型, 就可以达到提升召回率的作用. (对mAP的提升大约为1%左右) 论文细节传统NMS: 先将score倒序排列, 然后取socres值最大的box并将其置于final box列表中, 计算所有剩余box与该box的重叠度, 大于某一阈值的就将其删除, 然后迭代的使用此方法, 直到final box数量达到要求或者没有多的box了.(在FasterRCNN中, 生成候选框时会使用一次NMS, 预测还会分别对每一个类别都使用一次NMS) 传统NMS存在的问题: 由上面的描述可知, 如果两个物体本身的重叠度过大, 那么其中一个物体的框就会被删除(score被置为0), 从而导致漏解. Soft-NMS: 在将具有最大score的box置于 picked box 之后, 计算所有剩余 box 与该 box 的重叠度, 对于那些重叠度大于一定阈值的 box, 我们并不将其删除, 而仅仅只是根据重叠程度来降低那些 box 的 socre, 这样一来, 这些 box 仍旧处于 box 列表中, 只是 socre 的值变低了. 具体来说, 如果 box 的重叠程度高, 那么 score 的值就会变得很低, 如果重叠程度小, 那么 box 的 score 值就只会降低一点, Soft-NMS 算法伪代码如下图所示: 设 $s_i$ 为第 $i$ 个 box 的 score, 则在应用 SoftNMS 时各个 box score 的计算公式如下: s_i = \begin{cases} s_i, & iou(M, b_i) < N_t \\ s_i(1-iou(M, b_i)), & iou(M, b_i) \geq N_t \end{cases}上式过于简单直接, 为了函数的连续性, 文章改用了高斯惩罚系数(与上面的线性截断惩罚不同的是, 高斯惩罚会对其他所有的 box 作用): s_i = s_i e^{\frac{iou(M, b_i)^2}{\sigma}} \forall b_i\notin D]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NMS 算法源码实现]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-NMS-Implementation%2F</url>
    <content type="text"><![CDATA[【链接】非极大值抑制算法(NMS)及python实现https://blog.csdn.net/Blateyang/article/details/79113030 【链接】NMS-非极大值抑制-Python实现https://blog.csdn.net/u011436429/article/details/80107042 简述 NMS 的原理非极大值抑制(Non-Maximum Suppression, NMS), 顾名思义就是抑制那些不是极大值的元素, 可以理解为局部最大值搜索. 对于目标检测来说, 非极大值抑制的含义就是对于重叠度较高的一部分同类候选框来说, 去掉那些置信度较低的框, 只保留置信度最大的那一个进行后面的流程, 这里的重叠度高低与否是通过 NMS 阈值来判断的. 计算两个边框 IoU 的公式如下所示: x1 = \max (box1_{x1}, box2_{x1}), y1 = \max (box1_{y1}, box2_{y1})x2 = \min (box1_{x2}, box2_{x2}), y2 = \min (box1_{y2}, box2_{y2})intersection = (x2 - x1 + 1) \times (y2 - y1 + 1)IoU = \frac{intersection}{area1+area2-intersection} NMS 算法源码实现算法逻辑:输入: $n$ 行 $4$ 列的候选框数组, 以及对应的 $n$ 行 $1$ 列的置信度数组.输出: $m$ 行 $4$ 列的候选框数组, 以及对应的 $m$ 行 $1$ 列的置信度数组, $m$ 对应的是去重后的候选框数量算法流程: 计算 $n$ 个候选框的面积大小 对置信度进行排序, 获取排序后的下标序号, 即采用argsort 将当前置信度最大的框加入返回值列表中 获取当前置信度最大的候选框与其他任意候选框的相交面积 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除. 对剩余的框重复以上过程 Python 实现:123456789101112131415161718192021222324252627282930313233343536373839404142import cv2import numpy as npdef nms(bounding_boxes, confidence_score, threshold): if len(bounding_boxes) == 0: return [], [] bboxes = np.array(bounding_boxes) score = np.array(confidence_score) # 计算 n 个候选框的面积大小 x1 = bboxes[:, 0] y1 = bboxes[:, 1] x2 = bboxes[:, 2] y2 = bboxes[:, 3] areas =(x2 - x1 + 1) * (y2 - y1 + 1) # 对置信度进行排序, 获取排序后的下标序号, argsort 默认从小到大排序 order = np.argsort(score) picked_boxes = [] # 返回值 picked_score = [] # 返回值 while order.size &gt; 0: # 将当前置信度最大的框加入返回值列表中 index = order[-1] picked_boxes.append(bounding_boxes[index]) picked_score.append(confidence_score[index]) # 获取当前置信度最大的候选框与其他任意候选框的相交面积 x11 = np.maximum(x1[index], x1[order[:-1]]) y11 = np.maximum(y1[index], y1[order[:-1]]) x22 = np.minimum(x2[index], x2[order[:-1]]) y22 = np.minimum(y2[index], y2[order[:-1]]) w = np.maximum(0.0, x22 - x11 + 1) h = np.maximum(0.0, y22 - y11 + 1) intersection = w * h # 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除 ratio = intersection / (areas[index] + areas[order[:-1]] - intersection) left = np.where(ratio &lt; threshold) order = order[left] return picked_boxes, picked_score C++ 实现 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;struct Bbox &#123; int x1; int y1; int x2; int y2; float score; Bbox(int x1_, int y1_, int x2_, int y2_, float s): x1(x1_), y1(y1_), x2(x2_), y2(y2_), score(s) &#123;&#125;;&#125;;float iou(Bbox box1, Bbox box2) &#123; float area1 = (box1.x2 - box1.x1 + 1) * (box1.y2 - box1.y1 + 1); float area2 = (box2.x2 - box2.x1 + 1) * (box2.y2 - box2.y1 + 1); int x11 = std::max(box1.x1, box2.x1); int y11 = std::max(box1.y1, box2.y1); int x22 = std::min(box1.x2, box2.x2); int y22 = std::min(box1.y2, box2.y2); float intersection = (x22 - x11 + 1) * (y22 - y11 + 1); return intersection / (area1 + area2 - intersection);&#125;std::vector&lt;Bbox&gt; nms(std::vector&lt;Bbox&gt; &amp;vecBbox, float threshold) &#123; auto cmpScore = [](Bbox box1, Bbox box2) &#123; return box1.score &lt; box2.score; // 升序排列, 令score最大的box在vector末端 &#125;; std::sort(vecBbox.begin(), vecBbox.end(), cmpScore); std::vector&lt;Bbox&gt; pickedBbox; while (vecBbox.size() &gt; 0) &#123; pickedBbox.emplace_back(vecBbox.back()); vecBbox.pop_back(); for (size_t i = 0; i &lt; vecBbox.size(); i++) &#123; if (iou(pickedBbox.back(), vecBbox[i]) &gt;= threshold) &#123; vecBbox.erase(vecBbox.begin() + i); &#125; &#125; &#125; return pickedBbox;&#125; CUDA 实现: 简述 Soft-NMS 的原理在 Soft-NMS 中, 对于那些重叠度大于一定阈值的 box, 我们并不将其删除, 而仅仅只是根据重叠程度来降低那些 box 的 socre, 这样一来, 这些 box 仍旧处于 box 列表中, 只是 socre 的值变低了. 具体来说, 如果 box 的重叠程度高, 那么 score 的值就会变得很低, 如果重叠程度小, 那么 box 的 score 值就只会降低一点, Soft-NMS 算法伪代码如下图所示: Soft-NMS 算法源码实现算法逻辑:输入: bboxes: 坐标矩阵, 每个边框表示为 [x1, y1, x2, y2] scores: 每个 box 对应的分数, 在 Soft-NMS 中, scores 会发生变化(对外部变量也有影响) iou_thresh: 交并比的最低阈值 sigma2: 使用 gaussian 函数的方差, sigma2 代表 $\sigma^2$ score_thresh: 最终分数的最低阈值 method: 使用的惩罚方法, 1 代表线性惩罚, 2 代表高斯惩罚, 其他情况代表默认的 NMS 返回值: 最终留下的 boxes 的 index, 同时, scores 值也已经被改变.算法流程: 在 bboxes 之后添加对于的下标[0, 1, 2…], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标 计算每个 box 自身的面积 对于每一个下标 $i$, 找出 i 后面的最大 score 及其下标, 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大. 计算 IoU 根据用户选定的方法更新 scores 的值 以上过程循环 $N$ 次后($N$ 为总边框的数量), 将最终得分大于最低阈值的下标返回, 根据下标获取最终存留的 Boxes, 注意, 此时, 外部 scores 的值已经完成更新, 无需借助下标来获取. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import numpy as npdef soft_nms(bboxes, scores, iou_thresh=0.3, sigma2=0.5, score_thresh=0.001, method=2): # 在 bboxes 之后添加对于的下标[0, 1, 2...], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标 N = bboxes.shape[0] # 总的 box 的数量 indexes = np.array([np.arange(N)]) # 下标: 0, 1, 2, ..., n-1 bboxes = np.concatenate((bboxes, indexes.T), axis=1) # concatenate 之后, bboxes 的操作不会对外部变量产生影响 # 计算每个 box 的面积 x1 = bboxes[:, 0] y1 = bboxes[:, 1] x2 = bboxes[:, 2] y2 = bboxes[:, 3] areas = (x2 - x1 + 1) * (y2 - y1 + 1) for i in range(N): # 找出 i 后面的最大 score 及其下标 pos = i + 1 if i != N-1: maxscore = np.max(scores[pos:], axis=0) maxpos = np.argmax(scores[pos:], axis=0) else: maxscore = scores[-1] maxpos = 0 # 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大 if scores[i] &lt; maxscore: bboxes[[i, maxpos + i + 1]] = bboxes[[maxpos + i + 1, i]] scores[[i, maxpos + i + 1]] = scores[[maxpos + i + 1, i]] areas[[i, maxpos + i + 1]] = areas[[maxpos + i + 1, i]] # IoU calculate xx1 = np.maximum(bboxes[i, 0], bboxes[pos:, 0]) yy1 = np.maximum(bboxes[i, 1], bboxes[pos:, 1]) xx2 = np.minimum(bboxes[i, 2], bboxes[pos:, 2]) yy2 = np.minimum(bboxes[i, 3], bboxes[pos:, 3]) w = np.maximum(0.0, xx2 - xx1 + 1) h = np.maximum(0.0, yy2 - yy1 + 1) intersection = w * h iou = intersection / (areas[i] + areas[pos:] - intersection) # Three methods: 1.linear 2.gaussian 3.original NMS if method == 1: # linear weight = np.ones(iou.shape) weight[iou &gt; iou_thresh] = weight[iou &gt; iou_thresh] - iou[iou &gt; iou_thresh] elif method == 2: # gaussian weight = np.exp(-(iou * iou) / sigma2) else: # original NMS weight = np.ones(iou.shape) weight[iou &gt; iou_thresh] = 0 scores[pos:] = weight * scores[pos:] # select the boxes and keep the corresponding indexes inds = bboxes[:, 4][scores &gt; score_thresh] keep = inds.astype(int) return keep# boxes and scoresboxes = np.array([[200, 200, 400, 400], [220, 220, 420, 420], [240, 200, 440, 400], [200, 240, 400, 440], [1, 1, 2, 2]], dtype=np.float32)boxscores = np.array([0.9, 0.8, 0.7, 0.6, 0.5], dtype=np.float32)index = soft_nms(boxes, boxscores, method=2)print(index) # 按照 scores 的排序指明了对应的 box 的下标print(boxes[index])print(boxscores) # 注意, scores 不需要用 index 获取, scores 已经是更新过的排序 scores Soft-NMS 论文解读 介绍一下其他的 NMS 算法Face++ 论文: SofterNMS-Arxiv2018 完整实现Python 实现:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import cv2import numpy as npdef nms(bounding_boxes, confidence_score, threshold): if len(bounding_boxes) == 0: return [], [] bboxes = np.array(bounding_boxes) x1 = bboxes[:, 0] y1 = bboxes[:, 1] x2 = bboxes[:, 2] y2 = bboxes[:, 3] score = np.array(confidence_score) picked_boxes = [] picked_score = [] areas =(x2 - x1 + 1) * (y2 - y1 + 1) order = np.argsort(score) while order.size &gt; 0: index = order[-1] picked_boxes.append(bounding_boxes[index]) picked_score.append(confidence_score[index]) x11 = np.maximum(x1[index], x1[order[:-1]]) y11 = np.maximum(y1[index], y1[order[:-1]]) x22 = np.minimum(x2[index], x2[order[:-1]]) y22 = np.minimum(y2[index], y2[order[:-1]]) w = np.maximum(0.0, x22 - x11 + 1) h = np.maximum(0.0, y22 - y11 + 1) intersection = w * h ratio = intersection / (areas[index] + areas[order[:-1]] - intersection) left = np.where(ratio &lt; threshold) order = order[left] return picked_boxes, picked_scoredef main(): img_path = "/home/zerozone/Pictures/testimg/face.jpg" bounding_boxes = [(187, 82, 337, 317), (150, 67, 305, 282), (246, 121, 368, 304)] confidence_score = [0.9, 0.75, 0.8] image = cv2.imread(img_path) orig = image.copy() font = cv2.FONT_HERSHEY_SIMPLEX font_scale = 0.7 thickness = 2 threshold = 0.5 # Draw bboxes and score for (x1, y1, x2, y2), confidence in zip(bounding_boxes, confidence_score): (w, h), baseline = cv2.getTextSize( str(confidence), font, font_scale, thickness) cv2.rectangle(orig, (x1, y1 - (2 * baseline + 5)), (x1 + w, y1), (0, 255, 255), -1) cv2.rectangle(orig, (x1, y1), (x2, y2), (0, 255, 255), 2) cv2.putText(orig, str(confidence), (x1, y1), font, font_scale, (0, 0, 0, thickness)) # Draw bboxes and score after NMS picked_boxes, picked_score = nms(bounding_boxes, confidence_score, threshold) for (x1, y1, x2, y2), confidence in zip(picked_boxes, picked_score): (w, h), baseline = cv2.getTextSize( str(confidence), font, font_scale, thickness) cv2.rectangle(image, (x1, y1 - (2 * baseline + 5)), (x1 + w, y1), (0, 255, 255), -1) cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 255), 2) cv2.putText(image, str(confidence), (x1, y1), font, font_scale, (0, 0, 0, thickness)) cv2.imshow("origin", orig) cv2.imshow("NMS", image) cv2.waitKey(0)if __name__ == "__main__": main() C++ 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;struct Bbox &#123; int x1; int y1; int x2; int y2; float score; Bbox(int x1_, int y1_, int x2_, int y2_, float s): x1(x1_), y1(y1_), x2(x2_), y2(y2_), score(s) &#123;&#125;;&#125;;float iou(Bbox box1, Bbox box2) &#123; float area1 = (box1.x2 - box1.x1 + 1) * (box1.y2 - box1.y1 + 1); float area2 = (box2.x2 - box2.x1 + 1) * (box2.y2 - box2.y1 + 1); int x11 = std::max(box1.x1, box2.x1); int y11 = std::max(box1.y1, box2.y1); int x22 = std::min(box1.x2, box2.x2); int y22 = std::min(box1.y2, box2.y2); float intersection = (x22 - x11 + 1) * (y22 - y11 + 1); return intersection / (area1 + area2 - intersection);&#125;std::vector&lt;Bbox&gt; nms(std::vector&lt;Bbox&gt; &amp;vecBbox, float threshold) &#123; auto cmpScore = [](Bbox box1, Bbox box2) &#123; return box1.score &lt; box2.score; // 升序排列, 令score最大的box在vector末端 &#125;; std::sort(vecBbox.begin(), vecBbox.end(), cmpScore); std::vector&lt;Bbox&gt; pickedBbox; while (vecBbox.size() &gt; 0) &#123; pickedBbox.emplace_back(vecBbox.back()); vecBbox.pop_back(); for (size_t i = 0; i &lt; vecBbox.size(); i++) &#123; if (iou(pickedBbox.back(), vecBbox[i]) &gt;= threshold) &#123; vecBbox.erase(vecBbox.begin() + i); &#125; &#125; &#125; return pickedBbox;&#125;int main() &#123; std::vector&lt;Bbox&gt; vecBbox; vecBbox.emplace_back(Bbox(187, 82, 337, 317, 0.9)); vecBbox.emplace_back(Bbox(150, 67, 305, 282, 0.75)); vecBbox.emplace_back(Bbox(246, 121, 368, 304, 0.8)); auto pickedBbox = nms(vecBbox, 0.5); for (auto box : pickedBbox) &#123; std::cout &lt;&lt; box.x1 &lt;&lt; ", " &lt;&lt; box.y1 &lt;&lt; ", " &lt;&lt; box.x2 &lt;&lt; ", " &lt;&lt; box.y2 &lt;&lt; ", " &lt;&lt; box.score &lt;&lt; std::endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>源码实现</tag>
        <tag>Python</tag>
        <tag>计算机视觉</tag>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉-目标检测训练策略]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[NMSMulti-ScaleTraining Testing #]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】计算机视觉知识点总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。 使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。 使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。 总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维, 聚类 深度学习: 优化方法, 初始化方法, 损失函数, 激活函数, 正则化, 归一化, 感受野, 全连接层, 卷积层, 反卷积层, 池化层, 训练问题 网络结构: AlexNet, VGGNet, InceptionV1, InceptionV2, InceptionV3, InceptionV4, Xception, ResNet, ResNeXt, DenseNet, SqueezeNet, MobileNet, MobileNetV2, ShuffleNet, ShuffleNetV2, SENet, 目标检测: NMS 图像处理: 图像放缩 数学基础: 概率分布, 矩阵乘法优化 常见问题: 目前的 SOTA 目标检测模型 SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别 常用的训练 Trick 有哪些数据增广方法? 怎么实现的? PyTorch 和 TensorFlow 的区别 目标检测领域还有哪些可以继续改进或者优化的地方 机器学习篇各种机器学习算法的应用场景分别是什么(比如朴素贝叶斯、决策树、K 近邻、SVM、逻辑回归最大熵模型)https://www.zhihu.com/question/26726794/answer/151282052 基本概念 PR 曲线 ROC 曲线 逻辑回归逻辑回归与线性回归 逻辑回归和线性回归的定义 逻辑回归和线性回归的联系和区别 对于一个二分类问题, 如果数据集中存在一些离异值, 在不清洗数据的情况下, 选择逻辑回归还是 SVM? 为什么? 逻辑回归与 SVM 的区别是什么? 哪个是参数模型? 分别适合在什么情况下使用? 支持向量机SVM深入解析 简述 SVM 的基本概念和原理 SVM 推导过程 SVM 如何解决线性不可分问题 为什么SVM的分类结果仅依赖于支持向量? 如何选取核函数 为什么说高斯核函数将原始特征空间映射成了无限维空间? 核函数中不同参数的影响 既然深度学习技术性能表现以及全面超越 SVM, SVM 还有存在的必要吗? 决策树 降维 聚类 简单介绍常用的聚类方法 深度学习篇 优化方法梯度下降: SGD, Momentum, Nesterov, Adagrad, Adadelta, RMSprop, Adam, Adamax牛顿法:拟牛顿法:共轭梯度法: 简述各种优化方法的概念及其优缺点 简述 Adam 中使用的指数加权滑动平均法 各种优化方法的源码实现 各个优化算法的形式, 优点和缺点 Adam 无法收敛?: https://www.jiqizhixin.com/articles/2017-12-06 SGD 的参数设置 https://www.cnblogs.com/happylion/p/4172632.html https://www.cnblogs.com/shixiangwan/p/7532830.html https://www.cnblogs.com/hlongch/p/5734105.html https://www.baidu.com/link?url=8EyCqGYnldJzHuqBBGagV9juEA_nhCYvRElM2Tw0lBdewSmc0qshAy_AHAEegO-wT3vLsrcY1xSDdyLOmL09Ltm_UICAFX_C02QdkkSCcWW&amp;wd=&amp;eqid=ce9adcb10004685c000000035b5d4fb6 各种优化方法整理总结 https://mp.weixin.qq.com/s/lh4jTYJroq6AKb2fYsP-GQ 初始化方法constant, uniform, gaussian, xavier, msra(kaiming), bilinear 各个初始化方法的形式, 神经网络训练时是否可以将全部参数初始化为 0? 深度学习-各种初始化方法深入分析 损失函数绝对值损失(L1), 平方损失(L2), Binary 交叉熵, Softmax 交叉熵 深度学习-各种损失函数深入解析 写出多层感知机的平方误差和交叉熵误差损失函数 推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式 激活函数Sigmoid, Tanh, ReLU, Leaky ReLU, PReLU, RReLU, ELU, Maxout 写出常用的激活函数的公式及其导数形式 简单画出常用激活函数的图像 为什么需要激活函数? 各个激活函数的优缺点和适用场景 Sigmoid 激活函数和 Softmax 激活函数的区别 什么情况下 ReLU 的神经元会死亡? 为什么? 如何解决? 激活函数的使用原则 深度学习-各种激活函数深入解析 正则化L1, L2 深度学习-正则化方法深入解析 L1 正则和 L2 正则的特点是什么? 各有什么优势? L1 和 L2 的区别有哪些? L1正则化使模型参数稀疏的原理是什么? 为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验? 为什么权重矩阵稀疏可以防止过拟合? 为何权重参数 $w$ 减小就可以防止过拟合? L0 范式和 L1 范式都能实现稀疏, 为什么不选择用 L0 而要用 L1? 为什么说 L2 范式可以优化计算? 正则项前面的系数一般怎么设置? 归一化 Batch Normalization 为什么要进行归一化 简述 BN 的原理 BN 解决了什么问题 使用 BN 有什么好处 BN 层通常处于网络中的什么位置 BN 中 batch 的大小对网络性能有什么影响 BN 中线性偏移的参数个数怎么计算的 BN 中的使用的均值和方差是如何求得的 在多卡训练使用 BN 时, 需要注意什么问题 使用 BN 时, 前一层的卷积网络需不需要偏置项, 为什么 Group Normalization 简述 GN 的原理 为什么 GN 效果好 简述 BN, LN, IN, GN 的区别 GN 中线性偏移的参数个数怎么计算的 Layer Normalization Instance Normalization Switchable Normalization 感受野 感受野的作用 理论感受野和有效感受野的区别? https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw 目标检测中的 anchor 的设置和感受野的大小之间有什么关系? https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw 全连接层 全连接层的作用是什么? https://www.zhihu.com/question/41037974 为什么要将全连接层转化为卷积层? https://www.cnblogs.com/liuzhan709/p/9356960.html 请推导全连接层的反向传播算法. https://zhuanlan.zhihu.com/p/39195266 卷积层卷积层的作用? 简述 1x1 卷积层的作用 卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用 卷积层底层是如何实现的 简述矩阵乘法的优化方法 卷积操作通常由 GEMM 实现, 但是需要在内存进行名为 im2col 的初始重新排序, 以便将其映射到 GEMM 当中. 卷积核的大小如何确定?卷积核的大小决定了该卷积核在上一层特征图谱上的感受野大小，在确定卷积核的大小时有以下原则（并非通用性原则，实际设计时需要结合具体情况决定）：在网络的起始层，选用较大的卷积核（7×7），这样可以使得卷积核“看到”更多的原图特征；在网络中中间层，可以用两个3×3大小的卷积层来代替一个5×5大小的卷积层，这样做可以在保持感受野大小不变的情况下降低参数个数，减少模型复杂度；通常使用奇数大小的卷积核，原因有二，一是可以更加方便的进行padding，二是奇数核相对于偶数核，具有天然的中心点，并且对边沿、对线条更加敏感，可以更有效的提取边沿信息 反卷积层反卷积与上采样. 反卷积和双线性插值的区别, 各自的优势 池化层池化层的作用? 平均池化和最大池化有什么异同? 为什么用全局平均池化替换全连接层? 讲一下pooling的作用， 为什么max pooling要更常用？哪些情况下，average pooling比max pooling更合适？ 个人理解: 最大池化层会保留核内的最大响应值, 也可以理解成是最显著的特征, 然后利用这些最显著的特征去预测, 从直觉上来说会取得较好的效果, 就像是人眼一样, 我们往往只通过一些很明显的特征就可以判断出一个物体的种类, 最大池化多多少少也有这一层含义.而 mean pooling 是平均核内的所有特征, 这样做有一点不好的地方就是, 显著的响应值会被周围的不显著响应值所影响, 因此, 最终可能会得到一个不高不低的值. 举一个例子, 比如两处不同的位置进行 mean pooling, 一处的最大值是100, 然后经过mean pooling 之后, 它的输出值变成了 20, 而另一处的最大值是50, 然后经过mean pooling 之后它的输出值也是20, 这样, 对于不同的特征, 我们却得到了重复的结果, 这实际上是一种信息冗余, 也可以认为是一种特征丢失, 因此, 在使用中, maxpooling 更常用. 什么时候mean pooling 更好用? 通常在整个网络的最后, 我们会使用 gap 来整合整体的特征, 此时, 因为特征图谱已经是经过高度提取抽象后的, 所以, 我们不能只关注那些最大的值, 图谱上的每一个值所对应的特征我们都需要综合考虑, 因此, 我们通常会用 gap 来得到固定长度的特征向量, 进行最大的分类预测. 池化层的作用:降低优化难度和参数个数：池化层可以降低特征图谱的维度，从而降低网络整体的复杂度，不仅可以加速计算，也能起到一定的防止过拟合的作用增大感受野：当没有pooling时，一个3×3，步长为1的卷积，那么输出的一个像素的感受野就是33的区域，再加一个stride=1的33卷积，则感受野为5*5。当使用pooling后，很明显感受野迅速增大，这就是pooling的一大用处。感受野的增加对于模型的能力的提升是必要的，正所谓“一叶障目则不见泰山也”平移不变性：pooling层只会关注核内的值，而不会关注该值的位置，因此，当目标位置发生移动时，pooling层也可以得到相同的结果，所以pooling层在一定程度上可以增加CNN网络的平移不变性 训练问题训练过程中遇到的问题及解决方案 在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题? 如何解决数据不均衡问题? 训练不收敛的具体表现是什么? 可能的原因是什么? 如何解决? 训练过程中出现 Nan 值是什么原因? 如何解决? 过拟合是什么? 如何处理过拟合? 欠拟合是什么? 如何处理欠拟合? Dropout 的实现方式在训练阶段和测试阶段有什么不同? 如何保持训练和测试阶段的一致性? Dropout 为什么可以起到防止过拟合的作用? 如何选取 Batch Size 的值? 显存中通常会存储哪些东西? 网络结构篇 模型 层数 特点 参数量 Top-1 Acc Top-5 Acc AlexNet 8 6000w+ VGGNet 19 1亿3000w+ 71.1 89.8 InceptionV1 (GoogLeNet) 22 69.8 89.6 InceptionV2 22 73.9 91.8 InceptionV3 22 2000w+ 78.0 93.9 InceptionV4 22 80.2 95.2 ResNet 152 200w 76.8 93.2 InceptionResNet 80.4 95.3 ResNeXt AlexNet AlexNet 的网络结构相对来说比较简单, 它包括 5 层卷积层, 3 层最大池化层, 以及 3 层全连接层. 池化层被分别放置在 conv1, conv2, 和 conv5 的后面. 虽然 AlexNet 结构简单, 但是由于全连接层的存在, 使得 AlexNet 的参数量较大, 大约有 6000w 个参数. VGGNet VGGNet 的网络结构延续了 AlexNet 的设计思想. 将卷积层分成 5 段, 每一段之间通过池化层分隔开, 后面同样跟了 3 层全连接层, 同时他用多个小卷积核替换了 AlexNet 中的大卷积核, 可以在减少参数量的同时提高感受野的范围, 并且通过统建更深层的网络, 使得提取到的特征图谱的表征能力更强. VGGNet 比较常用的结构有 VGG16 和 VGG19. 二者的区别在于前者每个卷积段的卷积层数量是(2, 2, 3, 3, 3), 后者每个卷积段中的卷积层数量是(2, 2, 4, 4, 4). InceptionV1GoogLeNet 模型的核心思想是 卷积神经网络中的最优局部稀疏结构可以被现有的组件逼近和覆盖, 因此, 只要找到这个局部最优结构, 并在网络结构中重复使用它, 就可以进一步提升神经网络的拟合能力. 于是, InceptionV1 跳出了传统卷积神经网络的简单堆叠结构, 首次提出了 Inception 模块. Inception 模块综合了 1x1, 3x3, 5x5 这三种不同尺度的卷积核进行特征提取, 同时, 考虑到池化层的重要作用, 还综合了 3x3 大小的最大池化层. 并且, 还在 3x3 和 5x5 的卷积层之前, 以及池化层之后, 使用了 1x1 的卷积层来降低特征维度, 从而减少计算量. 以 Inception 模块为基本单元就可以构建出 IncetionV1 模型, 构建时仍然遵循了 5 个卷积段的段落形式, 段之间通过最大池化层分隔, 具体来说, 前两段使用的是传统的卷积层, 其中第一段是单层的 7x7 大小的卷积层, 第二段是两层较小尺寸的卷积层(1x1, 3x3), 后三段卷积段都是由 Inception 模块组成, 每一段使用的 Inception 模块数量分别为 2, 5, 2. 最后的分类层由全局平均池化层, 全连接层, Softmax 激活层组成. 另外, 由于网络结构较深, 因此, 为了防止梯度消失, InceptionV1 分别在 4a 和 4d 的 Inception 模块上添加了辅助侧枝分类器, 该分类器由一层平均池化层, 一层 1x1 卷积层, 两层全连接层和 Softmax 激活层组成. 简述一下 GoogLeNet 采用多个卷积核的原因 Inception 中为什么使用 1×1 卷积层 Inception 中为什么使用全局平均池化层 为什么使用侧枝 GoogLeNet 在哪些地方使用了全连接层 InceptionV3简述 InceptionV2 相比于 GoogLeNet 有什么区别InceptionV2 改进的主要有两点. 一方面加入了 BN 层, 减少了 Internal Covariate Shift 问题(内部网络层的数据分布发生变化), 另一方面参考了 VGGNet 用两个 $3\times 3$ 的卷积核替代了原来 Inception 模块中的 $5\times 5$ 卷积核, 可以在降低参数量的同时加速计算. 简述 InceptionV3 相比于 GoogLeNet 有什么区别InceptionV3 最重要的改进是分解(Factorization), 这样做的好处是既可以加速计算(多余的算力可以用来加深网络), 有可以将一个卷积层拆分成多个卷积层, 进一步加深网络深度, 增加神经网络的非线性拟合能力, 还有值得注意的地方是网络输入从 $224\times 224$ 变成了 $299\times 299$, 更加精细设计了 $35\times 35$, $17\times 17$, $8\times 8$ 特征图谱上的 Inception 模块.具体来说, 首先将第一个卷积段的 $7\times 7$ 大小的卷积核分解成了 3 个 $3\times 3$ 大小的卷积核. 在第二个卷积段也由 3 个 $3\times 3$ 大小的卷积核组成. 第三个卷积段使用了 3 个 Inception 模块, 同时将模块中的 $5\times 5$ 卷积分解成了两个 $3\times 3$ 大小的卷积. 在第四个卷积段中, 使用了 5 个分解程度更高的 Inception 模块, 具体来说, 是将 $n\times n$ 大小的卷积核分解成 $1\times n$ 和 $n\times 1$ 大小的卷积核, 在论文中, 对于 $17\times 17$ 大小的特征图谱, 使用了 $n = 7$ 的卷积分解形式. 在第五个卷积段中, 面对 $8\times 8$ 大小的特征图谱, 使用了两个设计更加精细的 Inception 模块. 它将 $3\times 3$ 大小的卷积层分解成 $1\times 3$ 和 $3\times 1$ 的卷积层, 这两个卷积层不是之前的串联关系, 而是并联关系. Inception 模块的设计和使用原则是什么 InceptionV4 and Inception ResNetInception 系列的缺点: 模块过于复杂, 人工设计的痕迹太重了. 简述 InceptionV4 做了哪些改进InceptionV4 使用了更复杂的结构重新设计了 Inception 模型中的每一个模块. 包括 Stem 模块, 三种不同的 Inception 模块以及两种不同的 Reduction 模块. 每一个模块的具体参数设置均不太一样, 但是整体来说都遵循的卷积分解和空间聚合的思想. 简述 Inception-Resnet-v1 做了哪些改进Inception ResNet v1 网络主要被用来与 Inception v3 模型性能进行比较, 因此它所用的 Inception 子网络的计算相对常规模块有所减少, 这是为了保证使得它的整体计算和内存消耗与 Inception v3 近似, 如此才能保证公平性. 具体来说, Inception ResNet v1 网络主要讲 ResNet 中的残差思想用到了 Inception 模块当中, 对于每一种不太的 Inception 模块, 都添加了一个短接连接来发挥残差模型的优势. 简述 Inception-ResNet-v2 做了哪些改进Inception ResNet v2 主要被设计来探索残差模块用于 Inception 网络时所尽可能带来的性能提升. 因此它是论文给出的最终性能最高的网络设计方案, 它和 Inception ResNet v1 的不同主要有两点, 第一是使用了 InceptionV4 中的更复杂的 Stem 结构, 第二是对于每一个 Inception 模块, 其空间聚合的维度都有所提升. 其模型结构如下所示: Xception ResNet 简述 ResNet 的原理 ResNet 中可以使用哪些短接方式 如何理解所谓的残差 $F(x)$ 比原始目标 $H(x)$ 更容易优化 为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5 ResNet 到底解决了一个什么问题 ResNet 残差模块中激活层应该如何放置 ResNeXt ResNeXt 在 ResNet 上做了哪些改进 DenseNet 简述 DenseNet 的原理 SqueezeNet 简述 SqueezeNet 的原理 MobileNet 简述 MobileNet 的原理 MobileNetV2 MobileNetV2 做了哪些改进 ShuffleNet 简述 ShuffleNet 的原理 简述 ShuffleNet 和 MobileNet 的区别 ShuffleNetV2 ShuffleNetV2 做了哪些改进 SENet 简述 SENet 的原理 目标检测篇 NMS简述 NMS 的原理非极大值抑制(Non-Maximum Suppression, NMS), 顾名思义就是抑制那些不是极大值的元素, 可以理解为局部最大值搜索. 对于目标检测来说, 非极大值抑制的含义就是对于重叠度较高的一部分同类候选框来说, 去掉那些置信度较低的框, 只保留置信度最大的那一个进行后面的流程, 这里的重叠度高低与否是通过 NMS 阈值来判断的. 计算两个边框 IoU 的公式如下所示: x1 = \max (box1_{x1}, box2_{x1}), y1 = \max (box1_{y1}, box2_{y1})x2 = \min (box1_{x2}, box2_{x2}), y2 = \min (box1_{y2}, box2_{y2})intersection = (x2 - x1 + 1) \times (y2 - y1 + 1)IoU = \frac{intersection}{area1+area2-intersection} NMS 算法源码实现算法逻辑:输入: $n$ 行 $4$ 列的候选框数组, 以及对应的 $n$ 行 $1$ 列的置信度数组.输出: $m$ 行 $4$ 列的候选框数组, 以及对应的 $m$ 行 $1$ 列的置信度数组, $m$ 对应的是去重后的候选框数量算法流程: 计算 $n$ 个候选框的面积大小 对置信度进行排序, 获取排序后的下标序号, 即采用argsort 将当前置信度最大的框加入返回值列表中 获取当前置信度最大的候选框与其他任意候选框的相交面积 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除. 对剩余的框重复以上过程 Python 实现:123456789101112131415161718192021222324252627282930313233343536373839404142import cv2import numpy as npdef nms(bounding_boxes, confidence_score, threshold): if len(bounding_boxes) == 0: return [], [] bboxes = np.array(bounding_boxes) score = np.array(confidence_score) # 计算 n 个候选框的面积大小 x1 = bboxes[:, 0] y1 = bboxes[:, 1] x2 = bboxes[:, 2] y2 = bboxes[:, 3] areas =(x2 - x1 + 1) * (y2 - y1 + 1) # 对置信度进行排序, 获取排序后的下标序号, argsort 默认从小到大排序 order = np.argsort(score) picked_boxes = [] # 返回值 picked_score = [] # 返回值 while order.size &gt; 0: # 将当前置信度最大的框加入返回值列表中 index = order[-1] picked_boxes.append(bounding_boxes[index]) picked_score.append(confidence_score[index]) # 获取当前置信度最大的候选框与其他任意候选框的相交面积 x11 = np.maximum(x1[index], x1[order[:-1]]) y11 = np.maximum(y1[index], y1[order[:-1]]) x22 = np.minimum(x2[index], x2[order[:-1]]) y22 = np.minimum(y2[index], y2[order[:-1]]) w = np.maximum(0.0, x22 - x11 + 1) h = np.maximum(0.0, y22 - y11 + 1) intersection = w * h # 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除 ratio = intersection / (areas[index] + areas[order[:-1]] - intersection) left = np.where(ratio &lt; threshold) order = order[left] return picked_boxes, picked_score C++ 实现 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;struct Bbox &#123; int x1; int y1; int x2; int y2; float score; Bbox(int x1_, int y1_, int x2_, int y2_, float s): x1(x1_), y1(y1_), x2(x2_), y2(y2_), score(s) &#123;&#125;;&#125;;float iou(Bbox box1, Bbox box2) &#123; float area1 = (box1.x2 - box1.x1 + 1) * (box1.y2 - box1.y1 + 1); float area2 = (box2.x2 - box2.x1 + 1) * (box2.y2 - box2.y1 + 1); int x11 = std::max(box1.x1, box2.x1); int y11 = std::max(box1.y1, box2.y1); int x22 = std::min(box1.x2, box2.x2); int y22 = std::min(box1.y2, box2.y2); float intersection = (x22 - x11 + 1) * (y22 - y11 + 1); return intersection / (area1 + area2 - intersection);&#125;std::vector&lt;Bbox&gt; nms(std::vector&lt;Bbox&gt; &amp;vecBbox, float threshold) &#123; auto cmpScore = [](Bbox box1, Bbox box2) &#123; return box1.score &lt; box2.score; // 升序排列, 令score最大的box在vector末端 &#125;; std::sort(vecBbox.begin(), vecBbox.end(), cmpScore); std::vector&lt;Bbox&gt; pickedBbox; while (vecBbox.size() &gt; 0) &#123; pickedBbox.emplace_back(vecBbox.back()); vecBbox.pop_back(); for (size_t i = 0; i &lt; vecBbox.size(); i++) &#123; if (iou(pickedBbox.back(), vecBbox[i]) &gt;= threshold) &#123; vecBbox.erase(vecBbox.begin() + i); &#125; &#125; &#125; return pickedBbox;&#125; CUDA 实现: 简述 Soft-NMS 的原理在 Soft-NMS 中, 对于那些重叠度大于一定阈值的 box, 我们并不将其删除, 而仅仅只是根据重叠程度来降低那些 box 的 socre, 这样一来, 这些 box 仍旧处于 box 列表中, 只是 socre 的值变低了. 具体来说, 如果 box 的重叠程度高, 那么 score 的值就会变得很低, 如果重叠程度小, 那么 box 的 score 值就只会降低一点, Soft-NMS 算法伪代码如下图所示: Soft-NMS 算法源码实现算法逻辑:输入: bboxes: 坐标矩阵, 每个边框表示为 [x1, y1, x2, y2] scores: 每个 box 对应的分数, 在 Soft-NMS 中, scores 会发生变化(对外部变量也有影响) iou_thresh: 交并比的最低阈值 sigma2: 使用 gaussian 函数的方差, sigma2 代表 $\sigma^2$ score_thresh: 最终分数的最低阈值 method: 使用的惩罚方法, 1 代表线性惩罚, 2 代表高斯惩罚, 其他情况代表默认的 NMS 返回值: 最终留下的 boxes 的 index, 同时, scores 值也已经被改变.算法流程: 在 bboxes 之后添加对于的下标[0, 1, 2…], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标 计算每个 box 自身的面积 对于每一个下标 $i$, 找出 i 后面的最大 score 及其下标, 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大. 计算 IoU 根据用户选定的方法更新 scores 的值 以上过程循环 $N$ 次后($N$ 为总边框的数量), 将最终得分大于最低阈值的下标返回, 根据下标获取最终存留的 Boxes, 注意, 此时, 外部 scores 的值已经完成更新, 无需借助下标来获取. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import numpy as npdef soft_nms(bboxes, scores, iou_thresh=0.3, sigma2=0.5, score_thresh=0.001, method=2): # 在 bboxes 之后添加对于的下标[0, 1, 2...], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标 N = bboxes.shape[0] # 总的 box 的数量 indexes = np.array([np.arange(N)]) # 下标: 0, 1, 2, ..., n-1 bboxes = np.concatenate((bboxes, indexes.T), axis=1) # concatenate 之后, bboxes 的操作不会对外部变量产生影响 # 计算每个 box 的面积 x1 = bboxes[:, 0] y1 = bboxes[:, 1] x2 = bboxes[:, 2] y2 = bboxes[:, 3] areas = (x2 - x1 + 1) * (y2 - y1 + 1) for i in range(N): # 找出 i 后面的最大 score 及其下标 pos = i + 1 if i != N-1: maxscore = np.max(scores[pos:], axis=0) maxpos = np.argmax(scores[pos:], axis=0) else: maxscore = scores[-1] maxpos = 0 # 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大 if scores[i] &lt; maxscore: bboxes[[i, maxpos + i + 1]] = bboxes[[maxpos + i + 1, i]] scores[[i, maxpos + i + 1]] = scores[[maxpos + i + 1, i]] areas[[i, maxpos + i + 1]] = areas[[maxpos + i + 1, i]] # IoU calculate xx1 = np.maximum(bboxes[i, 0], bboxes[pos:, 0]) yy1 = np.maximum(bboxes[i, 1], bboxes[pos:, 1]) xx2 = np.minimum(bboxes[i, 2], bboxes[pos:, 2]) yy2 = np.minimum(bboxes[i, 3], bboxes[pos:, 3]) w = np.maximum(0.0, xx2 - xx1 + 1) h = np.maximum(0.0, yy2 - yy1 + 1) intersection = w * h iou = intersection / (areas[i] + areas[pos:] - intersection) # Three methods: 1.linear 2.gaussian 3.original NMS if method == 1: # linear weight = np.ones(iou.shape) weight[iou &gt; iou_thresh] = weight[iou &gt; iou_thresh] - iou[iou &gt; iou_thresh] elif method == 2: # gaussian weight = np.exp(-(iou * iou) / sigma2) else: # original NMS weight = np.ones(iou.shape) weight[iou &gt; iou_thresh] = 0 scores[pos:] = weight * scores[pos:] # select the boxes and keep the corresponding indexes inds = bboxes[:, 4][scores &gt; score_thresh] keep = inds.astype(int) return keep# boxes and scoresboxes = np.array([[200, 200, 400, 400], [220, 220, 420, 420], [240, 200, 440, 400], [200, 240, 400, 440], [1, 1, 2, 2]], dtype=np.float32)boxscores = np.array([0.9, 0.8, 0.7, 0.6, 0.5], dtype=np.float32)index = soft_nms(boxes, boxscores, method=2)print(index) # 按照 scores 的排序指明了对应的 box 的下标print(boxes[index])print(boxscores) # 注意, scores 不需要用 index 获取, scores 已经是更新过的排序 scores 介绍一下其他的 NMS 算法 简述 NMS 的原理 NMS 算法源码实现 简述 Soft-NMS 的原理 Soft-NMS 算法源码实现 介绍一下其他的 NMS 算法 R-CNN Selective Search AlexNet SVM Bounding Box Regression t_x = (G_x - P_x) / P_w, t_y = (G_y - P_y) / P_ht_w = log(G_w / P_w), t_h = log(G_h / P_h) Fast R-CNNR-CNN 缺点: 训练过程是分阶段的(Training is a multi-stage pipeline) Training is expensive in space and time 目标检测速度太慢(Object detection is slow) SPPNet 缺点: 训练过程是分阶段的(Training is a multi-stage pipeline) 无法 Fine-Tuning 金字塔池化层之前的卷积层 Fast R-CNN 贡献: 更高的检测准确率(mAP) 整个训练过程更加统一(利用多目标损失函数) 训练时可以对所有网络层参数进行更新(相比于SPPNet) 无需在硬盘上额外存储 feature.(相比于 R-CNN, 因为共享卷积计算结果, 使得feature的体积大大降低) 要点: Multi-task loss: 下式中, $L_{cls}(p,u) = - log p_u$, 即对于真实类别 $u$ 的 log 损失.L(p, u, t_u, v) = L_{cls}(p,u) + \lambda [u \geq 1] L_{loc}(t^u, v) \tag 1L_{loc}(t^u, v) = \sum_{i\in {x,y,w,h}} smooth_{L_1}(t_i^u - v_i) \tag 2smooth_{L_1}(x) = \begin{cases} 0.5x^2 && |x|]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 算法题(记录总结)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-record%2F</url>
    <content type="text"><![CDATA[解题细节: LeetCode-Easy LeetCode-Medium LeetCode-Hard 熟练程度: 优: 看到题目立马想到正确的解题思路, 并且可以一次AC 良: 看到题目后有相对正确的解题思路, 但是在编码实现时经过多次调试才完全正确 中: 看到题目后想到的是次优的解题思路, 在参考标准答案后可以一次AC最优和次优. 差: 需要重点关注的题目 题号 题目 熟练程度 题号 题目 熟练程度 001 Two Sum 002 Add Two Numbers 004 Longest Substring Without Repeating Characters 005 006 007 008 009 010 011 013 014 015 017 019 020 021 022 023 026 028 029 033 034 036 038 041 042 044 046 Permutations 差(重) 048 049 050 Pow(x, n) 差 053 Maximum Subarray 良 054 Spiral Matrix 良 055 Jump Game 良 056 Merge Intervals 良 062 Unique Paths 良 066 Plus One 良 069 Sqrt(x) 良 070 Climbing Stairs 优 073 Set Matrix Zeroes 中 075 Sort Colors 差 076 Minimum Window Substring 差 078 Subsets 差 079 Word Search 良 084 Largest Rectangle in Histogram 差 088 Merge Sorted Array 良 091 Decode Ways 中 145 Binary Tree Postorder Traversal 差 094 Binary Tree Inorder Traversal 良 098 Validate Binary Search Tree 差 101 Symmetric Tree 中 102 Binary Tree Level Order Traversal 良 103 Binary Tree Zigzag Level Order Traversal 良 104 Maximum Depth of Binary Tree 良 105 Construct Binary Tree from Preorder and Inorder Traversal 中 108 Convert Sorted Array to Binary Search Tree 中 116 Popolating Next Right Pointers in Each Node 中 118 Pascal’s Triangle 良 121 Best Time to Buy and Sell Stock II 优 122 Best Time to Buy and Sell Stock II 优 124 Binary Tree Maximum Path Sum 良 125 Valid Palindrome 良 127 Word Ladder 差 128 Longest Consecutive Sequence 差 130 Surrounded Regions 优 131 Palindrome Partitioning 差 134 Gas Statioin 136 Single Number 优 138 Copy List with Random Pointer 139 Word Break 差 140 Word Break II 差 141 Linked List Cycle 良 146 LRU Cache 差 148 Sort List 差 149 Max Points on a Line 差 150 Evaluate Reverse Polish Notation 中 152 Maximum Product Subarray 差 155 Min Stack 优 160 Intersection of Two Linked Lists 良 162 Find Peak Element 差 163 166 Fraction to Recurring Decimal 差 169 Majority Element 优 171 Excel Sheet Column Number 优 172 Factorial Trailing Zeroes 差 179 Largest Number 良 189 Rotate Array 良 190 Reverse Bits 中 191 Number of 1 Bits 中 198 House Robber 差 200 Number of Islands 中 202 Happy Number 差 204 Count Primes 差 206 Reverse Linked List 中 207 Course Schedule 中 208 Implement Trie(Prefix Tree) 差 210 Course Schedule II 差 212 Word Search II 差 215 Kth Largest Element in an Array 中(重) 217 Contains Duplicate 良 218 The Skyline Problem 差 227 Basic Calculator II 差 230 Kth Smallest Element in a BST 良 234 Palindrome Linked List 中 236 Lowest Common Ancestor of a Binary Tree 差 237 Delete Node in a Linked List 优 238 Product of Array Except Self 差 239 Sliding Window Maximum 差 240 Search a 2D Matrix II 优 242 Valid Anagram 良 251 253 268 Missing Number 中(重) 269 277 279 Perfect Squares 中 283 Move Zeroes 中 285 287 Find the Duplicate Number 中 289 Game of Life 差 295 Find Median from Data Stream 中 297 Serialize and Deserialize Binary Tree 差 300 Longest Increasing Subsequence 差 308 315 Count of Smaller Numbers After Self 很差 322 Coin Change 很差 324 Wiggle Sort II 很差 326 Power of Three 差 328 Odd Even Linked List 中 329 Longest Increasing Path in a Matrix 差 334 Increasing Triplet Subsequence 差 340 341 Flatten Nested List Iterator 差 344 Reverse String 优 347 Top K Frequent Elements 中 350 Intersection of Two Arrays II 差 371 Sum of Two Integers 差 378 Kth Smallest Element in a Sorted Matrix 差 380 Insert Delete GetRandom $O(1)$ 差 384 Shuffle an Array 差 387 First Unique Character in a String 优 395 Longest Substring with At Least K Repeating Characters 差 412 Fizz Buzz 优 454 4Sum II 优]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OHEM (CVPR, 2016)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-OHEM-CVPR2016%2F</url>
    <content type="text"><![CDATA[文章: Training Region-based Object Detectors with Online Hard Example Mining作者: Abhinav Shrivastava, Abhinav Gupta, Ross Girshick 核心亮点提出了一种在线的难样例挖掘算法:作者根据每个RoIs的loss的大小来决定哪些是难样例, 哪些试试简单样例, 通过这种方法, 可以更高效的训练网络, 并且可以使得网络获得更小的训练loss. 同时, OHEM还具有以下两个优点: 消除FastRCNN系列模型中的一些不必要这参数 , 这些参数大多都是为了解决难样例问题服务的, 在使用OHEM以后, 不仅无需在对这些超参数进行调优, 同时还能获得更好的性能表现. OHEM算法可以与其他多种提升模型精度的trick相结合, 对于大多数模型(RCNN系列), 在使用了OHEM以后, 都能够获得精度上的提高, 可以看做是一种普适性的提升精度的方法. 注: 在实现OHEM上, 作者为了提升速度和效率, 特意设计了两个RoI网络, 以减少无用的计算. 论文细节摘要目前, 基于区域选择的CNN目标检测方法已经取得了很大的成功, 但是他们的训练过程仍然包含着许多启发法[注]和超参数(调优过程成本很高). 本文提出了一种针对区域选择目标检测方法的一种十分简单但非常有效的 在线的难样例挖掘(OHEM)算法. 我们的动机来源于数据集中存在的海量的简单样本, 而只有一小部分困难样本. 如果能够自动的选择这些困难样本用于训练, 那么就会使得训练过程更加高效和有效. OHEM 是一种简单且直观的算法, 它可以消除多个启发过程和超参数. 更重要的是, 它可以稳定的提升检测模型的算法性能, 当数据集越来越大, 越来越复杂时, 它的提升效果就越大. [注] 启发法: 启发式方法(试探法)是一种帮你寻找答案的技术, 但它给出的答案是具有偶然性的(subject to chance), 因为启发式方法仅仅告诉你该如何去找, 而没有告诉你要找什么, 它并不会告诉你该如何直接从A点到B点, 他甚至可能连A点和B点在哪里都不知道. 启发式算法的难点是建立符合实际问题的一些列启发式规则, 启发式算法的有点在于它比盲目型的搜索法要高效, 一个经过仔细设计的启发函数, 往往在很快的时间内就可以得到一个搜索问题的最优解. 介绍基于区域的CNN目标检测法使用的数据集中带物体标签的区域和背景区域之前的样本比例存在着巨大失衡. 在DPM中, 这种比例达到了1:100000. 一些算法(如Selective Search)对此进行了处理但失衡比例仍然很大(1:70). bootstrapping(现在多称为 hard negative mining)问题至少已经存在了20年. 并且Bootstrapping技术已经在目标检测领域内流行了十几年(尤其是在训练针对目标检测的SVMs时). 很多现代的基于深度学习的目标检测方法都是用了基于难样例挖掘的SVMs来帮助训练检测模型(RCNN, SPPnet). 但是奇怪的是后来的一些模型(FastRCNN, FasterRCNN等) 都没有使用bootstrapping技术. 一个潜在的原因可能是在深度神经网络中, 存在一些技术上的困难, 是的bootstrapping使用效果不佳. 传统的bootstrapping需要先用一个固定的模型来找到新的样本已准备训练数据, 然后再用一个固定的样本将检测模型激活并训练. 而在训练深度神经网络时, 其需要成千上万的大量样本用于训练, 因此, 我们需要一个 纯粹在线 的难样例选择算法. 在本文中, 我们提出了一个新型的bootstrapping技术称为 online hard example mining(OHEM), 并将其应用到基于深度学习的当前最先进的目标检测模型上. 该算法实际上是对SGD做了一些小改动, 使得训练样本可以从一个非均匀分布都采样得到, 该分布是一个基于当前样本loss的非静态分布. 该方法利用了目标检测问题特殊的结构优势, 那就是每一个SGD的mini-batch中仅仅包含一张或两张图片, 但是会有上千个候选样本. 这样候选样本会被继续按照特定的分布(倾向于那些不同的, 可以造成很高loss的样本)进行采样, 由于采样后的样本只是一小部分样本子集, 因此梯度下降优化算法仍然高效. 将OHEM算法用于标准的Fast RCNN算法以后, 显示除了三点好处: 移除了一些在基于区域推荐的CNN目标检测算法中的启发方法和超参数 稳定且大幅度的提升了mAP 当training set变的更大更复杂时, OHEM的有效性会提升 不仅如此, 从OHEM中获得的性能提升是对最近目标检测领域其他提升性能方法的一种补充, 如multiscale testing和迭代式bounding box回归. 在使用OHEM的同时结合这些tricks, 可以更进一步的提升mAP. 相关工作绝大多数目标检测模型都使用了结合bootstrapping算法的SVMs来作为检测的scoring function.但是有一些特例, FastRCNN和FasterRCNN等没有使用结合bootstrapping的SVMs, 而是完全根据SGD进行训练, 这些模型通过引入一些在线的难样例挖掘算法来解决这个问题(送入minibatch的前后景比例1:3). 下面简单介绍一下 Hard example mining和CNN目标检测以及他们之间的关系 Hard example mining: 目前常用的有两大算法.第一种是用于优化SVMs的: 训练算法会维护一个工作样本集, 并且该样本集会依据特定的规则不断在训练SVMshe更新样本集之间迭代. 这些规则会将简单样本(很容易分类正确)从样本集中移除, 同时会添加困难样本到样本集中.第二种方法用于非SVMs模型, 如浅层神经网络和boosted决策树: 该算法会从正样例和一部分随机负样例组成的数据集开始训练, 在该数据集上训练至收敛以后, 会继续在一个更大的, 包含更多负样例的数据集上进行训练. 这个过程通常只会进行一次迭代, 并且没有任何的收敛性证明. ConvNet-bases detection: 近年来CNN在目标检测领域迅速, 尤其是基于深度学习的目标检测方法(SPPNet, MRVNN Fast RCNN). Hard example selection in deep learning: 目前已经有很多专门针对目标检测算法hard example mining方法. 这些算法的基本思路与我们相同, 但是我们的算法更关注基于区域推荐的目标检测算法的 在线难样例挖掘. Overview of Fast RCNN在Fast RCNN中, 每一个minibatch包含N=2张图片, 每一张图片会采样B/N=128/2=64个候选框. RoI sampling过程使用了多个启发式规则, 如下所示: Foreground RoIs: 每一个RoI都会根据与真实框的IOU大小来分成前景框和后景框 Background RoIs: 在[bg_lo,0.5) 区间的被认为是后景, bg_lo(FastRCNN为0.1)用来充当难样例挖掘的角色, 但是这样会忽视一些不频繁但是很重要的后景区域, OHEM移除了bg_lo阈值. Balancing fg-bg RoIs: 为了处理难样例问题, FastRCNN采取的策略是将minibatch中前后景的比例设置为 1:3 (25%为前景). 这是一个十分重要的启发式规则阈值, 在实验中, 将他移除或者改变都会引起mAP分数的大幅度下降(3 points). 但是利用OHEM, 就可以在不损失mAP的情况下, 移除这个超参数. Our approach本文提出的OHEM算法可以简化复杂的FastRCNN系列模型的训练及调参过程, 同时可以获得更好的训练结果(lower training loss)和更高的测试性能(higher mAP) Online hard example mining在RCNN中使用SVMs,大致有两个阶段, 阶段 a) 首先会筛选并处理指定数目(10or100)个图片, 然后在在这些图片进进行训练直到收敛. 重复这两个阶段直到SVMs找到所有的支持向量为止. RCNN所采用的这个优化策略效率是很低的, 因为在对图片进行筛选和处理的时候, 没有任何模型会进行更新. OHEM算法流程如下: 对于处于第t次SGD迭代的输入图片来说, 首先计算器卷积特征图谱. 然后令RoI网络使用这个特征图谱和 所有 的RoIs (不是minibatch子集, 而是所有), 进行前向传播(仅包含RoI pooling层和几层fc层). 由此计算出的loss代表了当前网络在每一个RoI上的表现好坏. Hard examples的选择方法是将每个RoI的loss进行排序, 然后选择loss最大的 B/N 个样本作为hard examples. 直观上可以看出, 这些样本对于当前网络来说, 是最难正确分类的样本. 同时, 由于RoI pooling层本身计算量不高, 且各个RoI之间的计算可以共享(//TODO,怎么共享??), 因此, 额外的计算成本相对来说并不高. 此外, 参与反向计算过程的样本集合很很小的一个集合, 因此, 相比以前的方法并不会带来更多的计算成本.但是, 这里有一个小警告: 如果两个RoI之间的overlap较大, 那么很有可能这两个RoI的loss直接会有一定关联程度. 也就是说, 这些重叠度较高的RoIs可以映射到特征图谱上的同一块区域中, 又因为分辨率之间的差异性, 就可能导致loss的重复计算. 为了解决这种冗余计算和关联区域, 我们使用NMS算法来降低重复性. 具体来说, 给定RoIs列表和它们对应的losses, NMS迭代的选择那些具有最高loss的RoI, 然后移除所有与高RoI重叠度较高(IOU&gt;0.7)的其他RoI(这些RoI的loss更低).可以看出, 上面的过程并不需要fg-bg比例这个超参数, 如果任何一类被忽视了, 那么这个类对应的loss就会一直升高, 知道这个类被采样的概率变大为止. 对于有些图片来说, 前景区域是简单样例, 此时网络就会只采用背景区域进行训练, 反之, 也有的图片会认为背景区域(草地, 天空)是简单样例. Implementatin details实现OHEM算法的方法有很多, 它们之间有着不同的权衡和考量. 一个明显的方法是修改loss层, 使其完成难样例的选取工作. loss层可以计算所有RoIs的loss, 然后将它们进行排序,并且根据loss的值进行难样例的选择, 同时将所有非难样例的RoIs的loss设置为0 (表示梯度下降时不会考虑这些样例). 这种方式很直接, 但是却不够高效, 因为RoI网络仍然需要申请空间来存储这些RoIs, 并且还要对所有的RoIs进行反向传播计算(非难样例的loss虽然为0, 但也要参与计算流程).为了克服上面的效率问题, 本文提出了一种结构如图2所示. 我们的实现包含两个RoI网络的副本, 其中一个是 只读 的. 这意味着我们的只读RoI网络只需要申请前向传播计算的内存, 而不用像经典RoI网络一样, 需要同时申请前向计算和反向传播时的内存. 对于一次SGD迭代来说, 给定卷积特征图谱, 只读RoI网络会对所有的RoIs执行前向计算并计算loss( $R$ , 图2中的绿色箭头所示). 然后难样例采样模块会按照之前说的采样策略来选择难样例, 然后会将这些难样例输入到一个常规的RoI网络中( $R_{hard-sel}$ 图2中的红色箭头所示). 于是, 这个网络仅仅只会对难样例同时进行前向计算和反向传播计算. 在实际中, 我们使用所有图片的所有RoI作为 $R$, 因此对于只读RoI网络最后的minibatch的size为 $|R|$. (//TODO 嘛意思?)在实验中, N=2(意味着 $|R|\approx 4000$ ), B = 128. 实验与分析OHEM vs. heuristic sampling如下表所示, 没有使用 bg_lo 超参数的OHEM在FasrRCNN上的mAP提高了4.8个点 Robust gradient estimates因为N=2, 所以选出来的框之间很有很大的关联性, 这会不会使得梯度不稳定从而难以收敛. 实验结果表明, OHEM同样对这种情况具有鲁棒性, 即使将N设置为1, mAP也不会降低多少(仅降低了0.2%). (当然, 在硬件条件允许的情况下, 选取越大的N, 效果一般越好) Why just hard examples, when u can use call?如果使用所有的RoI loss参与权重更新(而不仅仅是hard examples)会怎么样呢? 在这种情况下, 那些简单样本将会拥有较小的loss, 从而不会对梯度的更新贡献太大, 整个训练过程会自动的专注于难样例的训练.(这种全训练的结果会使得相对于标准FastRCNN的mAP提升一点, 因为标准的FastRCNN并没有针对难样例, 而是随机选的minibatch), 但是这种全训练很是的训练时间大幅提高. Better optimization利用OHEM可以获得更低的 mean loss per RoI (取自各种方法的第20K次迭代) Computational cost不论是耗时上还是内存占用上, 都变多了, 但总体来说, 是可以接受的 PASXAL VOC and MS COCO results在训练阶段和测试阶段使用multi-scale和multi-stage bbox regression 可以大幅度提高mAP multi-scale: $s\in \{ 480, 576, 688, 864, 900 \}$ for training, $s\in \{480, 576,688,864,1000\}$ for testing. 这些scales和caps的选择主要受制于GPU的显存大小.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PASCAL VOC数据集]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%95%B0%E6%8D%AE%E9%9B%86-VOC%2F</url>
    <content type="text"><![CDATA[评价标准VOC 数据集介绍]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>数据处理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的智能指针]]></title>
    <url>%2Fz_post%2FCpp-%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[C++ 提供了四个智能指针模板类, 分别是: auto_ptr, unique_ptr, shared_ptr和weak_ptr. (auto_ptr是 C++98 提供的解决方案, C++11 已经将其摒弃, 并提供了另外三种解决方案). 这三个智能指针模板都定义了类似指针的对象, 可以将new获得(直接或间接)的地址赋给这种对象. 当智能指针过期时, 其析构函数将使用delete来释放内存. (要创建智能指针对象, 需要包含头文件&lt;memory&gt;) 三种智能指针的区别? auto_ptr: 当进行赋值时, 会将旧指针的所有权转让, 使得 对于特定的对象, 只能有一个智能指针可以拥有它. unique_ptr: 当进行赋值时, 会将旧指针的所有权转让, 使得 对于特定的对象, 只能有一个智能指针可以拥有它. unique_ptr 相比于 auto_ptr 会执行更加严格的所有权转让策略 shared_ptr: 通过引用计数(reference counting), 跟踪引用特定特定对象的智能指针数. 当发生赋值操作时, 计数增1, 当指针过期时, 计数减1. 仅当最后一个指针过期时, 才调用 delete. unique_ptr 和 auto_ptr 的区别? 所有权转让机制不同: auto_ptr 允许通过直接赋值进行转让, 但是这样会留下危险的 悬挂指针, 容易使得程序在运行阶段崩溃. unique_ptr 仅仅允许将临时右值进行赋值, 否则会在编译阶段发生错误, 这样更加安全(编译阶段错误比潜在的程序崩溃更安全). 相比于 auto_ptr 和 share_ptr, unique_ptr 可以使用new[]分配的内存作为参数: std::unique_ptr&lt;double[]&gt; pda(new double(5)); 如何选择合适的只能指针?如果程序要使用多个指向同一个对象的指针, 应选择shared_ptr, 这样的情况包括: 对于智能指针数组, 用辅助指针来标识最大值或最小值的情况 很多 STL 算法都支持复制和赋值操作, 这些操作可用于 shared_ptr, 但不能用于 unique_ptr 和 auto_ptr. 如果程序不需要多个指向同一个对象的指针, 则可以使用unique_ptr, 如果函数使用new分配内存, 并返回指向该内存的指针, 将其返回类型声明为unique_ptr是不错的选择, 这样, 所有权将转让给接受返回值的unique_ptr.]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNetV2]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-MobileNetV2%2F</url>
    <content type="text"><![CDATA[文章: MobileNetV2: Inverted Residuals and Linear Bottlenecks作者: Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen备注: Google 摘要本文中我们介绍了一个新的网络结构, MobileNetV2, 提高了移动模型在多个任务和基准以及不同模型大小的最好性能. 我们还介绍了将这些 Mobile 模型应用的目标检测上的有效方法, 并给出了一个新的框架, SSDLite. 此外, 我们还演示了如何通过一个简化形式的 DeepLabv3 (我们称之为 Mobile DeepLabv3)来构建移动语义分割模型.我们的模型基于逆置残差结构(Inverted Residual Structure), 该结构中的 shortcut 连接位于 bottleneck 的网络层之间. 中间的 expansion layer 使用了轻量级的 Depthwise Conv 来过滤特征, 将结果传给非线性激活层. 此外, 我们发现在 narrow layers 中去除非线性层对于保持表征能力来说是非常重要的. 我们证明了这样做可以提供性能, 同时给出了这种设计的 Intuition.最后, 我们的方法还可以让输入输出和 expressiveness of the transformation 解耦, 这为进一步的分析提供了一个方便的框架. 我们在 ImageNet 分类数据集, COCO 目标检测数据集, VOC 实例分割数据集上测试了模型的性能. 同时还评估了精度, 乘法加法操作次数, 实际延迟和参数数量之间的 trade-offs. Introduction本文的主要贡献是一个新型的 layer module: the inverted residual with linear bottleneck. 该模块采用低维压缩表征作为输入, 首先将其扩展至高维, 然后用轻量级的 Depthwise Conv 进行滤波. 特征随后会被一个 linear convolution 投影回低维表征.这些模块可以利用现有的任何框架中的标准操作实现, 并且可以取得 sota 的效果. 此外, 本文提出的卷积模块特征适合用移动设计, 因为它允许通过 “never fully materializing large intermediate tensors” 来显著减少 Inference 过程中所需的内存占用. 这减少了许多嵌入式硬件设计对主存访问的需求, 这些设计提供了非常快的软件控制的高速缓存. Related WorkNetwork Pruning Connectivity Learning ShuffleNet Architectural Search: genetic algorithms, reinforcement learning Preliminaries, discussion and intuitionDepthwise Separable ConvolutionsDepthwise Separable Convolutions 在 MobileNet 和 Xception 中是非常关键的一个模块, 这里我们也同样在网络中使用. 其基本思想就是将原始的标准卷积操作分解良两个独立的卷积层. 第一个卷积层称为 Depthwise Conv, 它对 每个输入通道分别应用一个独立的卷积滤波器来进行轻量级的滤波. 第二个卷积层称为 Pointwise Conv(1x1 Conv), 它负责通过计算输入通道的线性组合来建立新的特征图谱. 当标准卷积层的输入图谱为 $h_i\times w_i\times d_i$, 卷积核为 $R^{k\times k\times d_i\times d_j}$, 输出图谱为 $h_i\times w_i\times d_j$ 时, 则该卷积的计算成本为: $h_i \cdot w_i \cdot d_i \cdot d_j\cdot k\cdot k$. Depthwise Separable Conv 是对标准卷积层的一种替代. 从经验上看, 它们的效果几乎和标准卷积一样好, 只不过成本更低, 如下所示(Depthwise 和 Pointwise 的计算成本之和): h_i \cdot w_i \cdot d_i (k^2 + d_j)可以看出, 与标准卷积层相比, 深度可分离卷积有效的减少了几乎 $k^2$ 被的计算量. 在 MobileNetV2 中, 我们队 $k=3$ 的卷积层使用深度可分离卷积, 因此计算成本可以降低 8~9 倍, 同时精度只降低一点. Linear Bottlenecks对于具有 $n$ 层网络层的深度神经网络来说, 每一个网络层 $L_i$ 都具有 $h_i\times w_i\times d_i$ 维度的 activation tensor. 在本节中, 我们将讨论这些 activation tensors 的基本性质, 并将这些 tensors 看做是具有 $d_i$ 维度的 $h_i\times w_i$ 大小的像素容器. 非正式的说, 对于实际图像的输入集, 我们称网络层的 activations (对于任意的网络层 $L_i$) 集合组成了一个 “manifold of interest”. 长期以来, 人们一直认为神经网络中的 manifolds of interest 可以嵌入到低维的子空间中. 换句话说, 当我们深层的卷积层中所有单独的 $d$ 通道的 像素 时, 这些值中编码的信息实际上存在于一些 manifold 中, 而这些 manifold 又可以嵌入到低维的子空间中. (注意, manifold 的维度不同于通过线性变换嵌入的子空间维度) 粗略来看, such a fact 可以通过简单的减少一个层的维度来捕获和利用, 从而减少操作空间的维度. MobileNetV1 成功的利用了这一点, 通过 width multiplier 超参数可以有效的在计算成本和精度之间进行权衡, 并且该方法已经被纳入其他网络的有效模型设计中. 根据这种 Intuition, width multiplier 方法允许降低 activation space 的维度, 直到 manifold of interest 覆盖整个空间. 但是, 当我们回忆起深度卷积神经网络的在每个坐标点上的转换都是非线性的使用, 例如 ReLU, 这种 Intuition 就不成立了. 例如, ReLU 在一维空间中时, 会产生一条射线, 但是在 $R^n$ 维空间中时, 通常会产生一条具有 $n$ 个连接的分段线性曲线.It is easy to see that in general if a result of a layer transformation ReLU($Bx$) has a non-zero volume $S$, the points mapped to interior $S$ are obtained via a linear transformation $B$ of the input, thus indicating that the part of the input space corresponding to the full dimensional output, is limited to a linear transformation. 换句话说, 深度网络只有在输出域(output domain)的非零部分(non-zero volume part)才具有线性分类器的能力.另一方面, 当 ReLU collapses the channel 时, 它不可避免的会丢失该通道中的信息. 然而, 如果我们有很多个通道, 并且在 activation manifold 中有一个结构, 那么信息可能仍然保存在其他通道中. 在补充材料中, 我们证明了如果 input manifold 可以嵌入到激活空间的一个显著的低维子空间中, 那么在将所需的复杂度引入到表征函数集合中时, ReLU 变换可以保留一定的信息.综上所示, 我们强调了两个特性, 它们表明了 manifold of the interest 在高维 activation space 中嵌入到低维子空间的要求: 如果 manifold of interest 在 ReLU 变换后保持非零体积, 则对应线性变换. ReLU 能够保存 input manifold 的完整信息, 但前提是 input manifold 位于属于空间的低维子空间当中. 这两个性质为我们优化现有的神经结构提供了经验性的提示: 假设 manifold of interest 是低维的, 那么我们可以通过在卷积块中插入 linear bottleneck 来捕获它. 实验证据表明, 使用线性层是至关重要的, 因为它可以防止非线性层破坏太多的信息. 在第 6 节, 我们会展示在 bottlenecks 中使用非线性层实际上会损害最终的精度, 进一步验证了我们的假设.在本文的其余部分, 我们将使用 bottleneck , 并且我们将 bottleneck 的输入大小和内部大小的比值称为膨胀比(expansion ratio). Inverted residualsBottleneck Blocks 和 Residual Blocks 类似, 其中每个块包含一个输入, 然后是若干 bottlenecks, 然后是 expansion. 有一种 Intuition 认为 Bottleneck 包含了所有的必要信息, 而 expansion layer 仅仅作为伴随张量非线性变换的实现细节, 受到该观点的启发, 我们直接在 Bottlenecks 之间使用 shortcut. 图3提供了不同设计的示意图. 插入 shortcut 的动机和传统的残差连接类似: 我们想要提高梯度跨多层传播的能力. 在第5节中显示了 Inverted 的设计大大提高了内存效率, 并且在本文的实验中效果更好一些. Running time and parameter count for bottleneck convolution 基本的实现结构如表1所示. 在表3中, 我们比较了 MobileNetV1, MobileNetV2, ShuffleNet 所需的分辨率大小. Information flow interpretation我们的网络结构的一个有趣的特性是, 它在 building blocks(bottleneck layers) 的 input/output domains 和层转换之间提供了一种自然的间隔(natural separation). 层转换是一个将输入转换为输出的非线性函数, 前者可以看做是网络在每一层的容量(capacity), 而后者可以看做是表征能力(expressiveness). 这与传统的卷积块形成了鲜明的对比, 传统的卷积是 regular and separable 的, 它的 expressiveness 和 capacity 是纠缠在一起的, 是输出图谱通道数的函数. 特别地, 在我们的例子中, 当内层网络的深度为 0 时, 多亏了 shortcut 的存在, 使得底层卷积变成了一个 indentity function. 当膨胀比(expansion ratio)小于 1 时, 这就是一个经典的残差卷积块. 但是, for our purposes, 我们展示了大于 1 的膨胀比是最有用的.这一解释使得我们能够不考虑 capacity 而独立的研究网络的表征能力, 我们认为, 对这种 separation 的进一步探索有助于更好的理解网络的特性. Model Architecture接下来我们将详细描述我们的网络结构. 正如前一节所讨论的, 基本的 building block 是 bottleneck depth-separable convolution with residuals. 该模块的详细结构如表 1 所示. MobileNetV2 的网络结构如表2 所示, 第一层是一个 filters 数量为 32 的卷积层, 后面 19 个 residual bottleneck 层. 由于 ReLU6 在面对低精度计算时具有更高的鲁棒性, 因此我们选它作为非线性激活函数. 我们的卷积核大小通常为 3x3, 并在训练中使用 dropout 和 BN. 除了第一层以外, 我们在整个网络中都使用了恒定的膨胀率. 在我们的实验中, 我们发现在膨胀率在 5~10 之间时具有几乎相同的性能曲线, 并且在较小的网络中小膨胀率性能更好, 在较大的网络中大膨胀率性能较好.在我们主要的实验中, 均使用大小为 6 的膨胀因子. 例如, 对于一个输入通道数为 64, 输出通道数为 128 的 bottleneck 模块来说, 中间的 expansion layer 的通道数为 $64\times 6 = 384$. Trade-off hyper parameters 和 MobileNetV1 中一样, 我们将输入图像的分辨率和宽度乘子作为可调节的超参数, 根据所需的精度和性能要求权衡我们的体系结构, 以此适应不同的性能. 我们的 primary network(width multiplier 1, 224x224) 的计算成本为 3 亿次 multiply-adds, 并且具有 3.4 million 的参数. 我们探索了从 resolution 才 96 到 224, width multipliers 从 0.35 到 1.4 的性能表现. 网络的计算成本在 7~585 M MAdds, 模型大小在 1.7~6.9M 个参数.MobileNetV2 在实现上与 MobileNetV1 的一个小的差异是, 对于小于 1 的乘数, 我们将 width multiplier 应用于除最后一个卷积层之外的所有层. 这对小模型的性能有所提升. Implementation NotesMemory efficient inferenceInverted Residual Bottleneck 可以实现时具有内存高效的好处, 这对于移动应用来说非常重要. 计算过程会优先使需要在内存中的张量总数最小化来进行安排. 在通常情况下, 深度学习框架(TF, Caffe)会搜索所有可能的计算顺序 $\Sigma (G)$, 并从中选择总计算量最小的一个. M(G) = \min_{\pi\in\Sigma(G)} \max_{i\in 1..n} \Biggl[ \sum_{A\in R(i, \pi, G) |A|} \Biggr] + size(\pi_i)上式中, $R(i, \pi, G)$ 是连接到任意 $\pi_i, …, \pi_n$ 节点的中间张量列表, $|A|$ 代表了张量 $A$ 的大小, $size(i)$ 代表在操作 $i$ 起见内部存储所需要的内存总量. 对于只有平凡并行结构的图(如残差连接), 只有一个 non-trivial 的计算顺序, 因此可以简化计算图 $G$ 推理所需的总量和内存边界. M(G) = \max_{op\in G} \Biggl[ \sum_{A\in op_{inp}} |A| + \sum_{B\in op_{out}} |B| + |op| \Biggr]重申一下, 内存量就是所有操作中输入和输出的最大总大小. 在下面, 我们表明, 如果我们把一个 bottleneck residual block 作为一个单独的操作(将 inner convolution 作为一次性张量), 总的内存量大小将会由 bottleneck tensors 的大小决定, 而不是由 bottleneck 内部的 tensor 大小决定(much larger). Bottleneck Residual Block 图3(b) 中的操作可以看做三个子操作: Linear transformation, Non-linear per-channel transformation, Linear transformation.在我们的网络中, 我们非线性激活层为: ReLU6+dwise+ReLU6. Balablabla…(关于具体实现时的计算成本) ExperimentsImageNet ClassificationTraining setup: TensorFlow, RMSPropOptimizer(decay = 0.9, momentum = 0.9), BN (after every layer), weight decay = 0.00004, initial lr = 0.045, lr decay = 0.98 per epoch, 16 GPU asynchronous(异步) workers, batch size = 96. Results: 如表4, 图5所示. Object DetectionSSDLite: 用深度可分离卷积替换标准卷积, 大幅降低 Params 和 MAdds, 如表5所示. 关于 mAP, 参数量, 乘法加法次数的测试和比较如表6所示. Semantic SegmentationDeepLabv3, 结果如表7所示. Ablation studyInverted residual connections: shortcut connecting bottleneck perform better than shortcuts connecting the expanded layers, 如图6(b)所示 Importance of linear bottlenecks 线性 bottleneck 模型严格来说没有非线性模型强大, 因为激活总是可以在线性状态下运行, 并对 bias 和 scale 进行适当的改变. 但是我们的实验结果如图6所示, 线性 bottleneck 提高了性能, 为非线性破坏低维空间中的信息提供了补救措施(providing support). MobileNetV2 做了哪些改进]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FPN (CVPR, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FPN-CVPR2017%2F</url>
    <content type="text"><![CDATA[文章: Feature Pyramid Networks for Object Detectin作者: Tsung-Yi Lin, Piotr Dollar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie 核心亮点提出了多尺度的特征金字塔结构将最后一层特征图谱进行不断进行上采样, 并与每一个金字塔阶级的特征图谱进行加法合并操作, 得到新的表征能力更强的不同金字塔层次的特征图谱, 然后将RoI按照尺寸分别映射到这些特征图谱上, 再在每个特征图谱上进行类别和位置预测. 可以直观感受到, 这种多尺度的特征图谱在面对不同尺寸的物体时, 具有更好的鲁棒性, 尤其是在面对小型物体时. 同时, 这种特征金字塔结构是一种通用的特征提取结构, 可以应用到不同的网络框架中, 显著提高(5~8%)模型的召回率(因为提出了更多不同尺度, 不同特征信息的anchor box), 并且可以广泛提高(2~3%)模型的mAP. 背景介绍在面对不同尺度的物体检测问题时, 特征金字塔结构是一个非常基本的组成部分, 但是最近的检测模型都舍弃了这一结构(Fast RCNN, Faster RCNN, YOLOv2等), 其一部分原因是因为这个结构对计算和内存的要求较高. 本文在控制资源消耗的情况下, 建立了一个跨所有层的特征金字塔结构, 我们将其称为 Feature Pyramid Network(FPN), 将 FPN 应用在基本的 Faster R-CNN 网络中, 取得了当下的STOA性能. 传统的特征金字塔结构对于计算资源和内存资源的依赖较为严重, 同时深度卷积网络在不同阶段的卷积层, 虽然较好的传递了特征, 但是因为每一层的输出通道数不同, 会导致层与层之间形成一种潜在的语义鸿沟. 较高的分辨率往往具有更多的低级信息(在深层会被过滤掉), 但是多余的信息也会对降低泛化能力, 较低的分辨率则具有权重更高的重要信息, 但是这样也会使得小目标物体难以检测. SSD与FPN中多尺度特征图谱融合的区别SSD算是首批结合多尺度特征金字塔的检测系统, 但是SSD为了避免用到过多的低级特征(高层卷积图谱上的特征), 放弃使用以及计算好的特征特普, 而是从网络的最后一层卷积层开始, 添加新的卷积层, 并在这些新添加的卷积层上进行特征金字塔融合. 这样做一个很直观的结果就是, 它会错过很多高分辨率特征图谱上的特征信息, 而这些特征信息在面对小物体检测时是十分有用的.(这也是SSD对小物体检测较为敏感的原因之一). 介绍 在不同尺寸(different scales)上对物体进行识别是计算机视觉领域中一个具有挑战性的基本问题(fundamental challenge). 在图片金字塔(image pyramids)上建立特征金字塔(feature pyramids)的方法(我们称之为 featurized image pyramids)是一个标准的解决方案, 如图1(a)所示. 这些金字塔结构具有尺寸不变性(scale-invariant), 因为当物体的scale发生变化时, 我们可以通过在pyramid的levels之间移动(shifting)来适应. Intuitively, 这个特性可以通过让模型同时在位置和pyramid levels上进行扫描(scanning), 从而可以在很大的尺度范围内检测物体.这种方法(featurized image pyramids)在人工设计图片特征的时代十分受用. 而随着深度卷积网络的兴起, 我们可以从一张单一的特征图谱上获取到大量的抽象特征, 抽了提取特征之外, ConvNets在尺寸变化上也表现出了很强的鲁棒性, 这使得我们可以利用一张图片就能获得足够的信息来做出预测, 如图(b)所示. 但是即使拥有这种鲁棒性, 我们仍然需要 pyramid 结构来获取更加准确的结果. 几乎所有的模型在 ImageNet 和 COCO 的目标检测比赛上都使用了在 featurized image pyramids 上进行 multi-scale testing 的方法. 在不同 level 的 image pyramid 上进行预测的一个主要好处是, 它可以产生一个多尺度的特征表示(multi-scale), 其中所有层在语义上都是强的, 包括高分辨率层.但是, 在 image pyramids 的每一层上提取特征具有很明显的缺点, 那就是会使得 Inference time 显著提升. 更进一步的, 会使得在 image pyramid 上训练端到端的深层网络变的不可行, 也因此, 我们仅仅在测试阶段才会使用 image pyramids, 这会在训练和测试阶段之间产生不一致问题. 基于以上原因, Fast 和 Faster R-CNN 选择在默认设置下不使用 featurized image pyramid(尽管它有助于提高精度)s然而, image pyramids 并不是唯一的计算多尺度特征表示(multi-scale feature representation)的方法. 一个深层的 ConvNet 会一层层的计算出一个特征层级(feature hierarchy), 同时配合 subsampling 层, 使得 feature hierarchy 具有了固有的多尺度金字塔结构(inherent multi-scale, pyramidal shape). SSD 是首个在这些特征图谱上使用特征金字塔的模型, 它看起来就像是 featurized image pyramid(实际上不是), 如图(c)所示. 理想情况下, SSD 的特征金字塔是从多个卷积层输出的特征图谱得到的, 因此它的计算成本几乎为零. 但是为了避免使用到那些表征能力不强的低阶特征图谱(浅层), SSD 只使用了深层的特征图谱(conv4_3), 同时在 backbone 网络的后面又添加了几层卷积层来提取高表征能力的特征图谱. 但是这样就是的 SSD 错过了那些低阶特征的信息(高分辨率的特征图谱), 这些低阶特征中往往包含了高阶特征(低分辨率特征图谱)不具有的信息, 如小物体的特征信息, 这也是为什么 SSD 对小物体不敏感的原因之一.本文的目标时可以自然的利用 ConvNet’s feature hierarchy 的金字塔结构的同时创建一个在所有尺度(all scales)上都具有强语义信息的特征金字塔. 为了达到这个目标, 我们通过 top-down pathway(top指的就是深层的小卷积图谱) 和 lateral connections 建立了一个可以结合低阶特征(high-resolution, semantically weak features)和高阶特征(low-resolution, semantically strong features)的特征金字塔结构, 如图1(d)所示. 由图易知, 这个特征金字塔在所有尺度的特征图谱上都具有很强的语义特征, 同时可以从一张单一尺寸的图片出发, 利用很低的计算成本建立起来. 换句话说就是, 我们可以在不牺牲模型特征表达能力, 速度, 以及内存消耗的情况下, 创建一个网络模型内部的特征金字塔结构, 从而可以替换掉 featurized image pyramids.和本文的特征金字塔比较相似的结构是利用 top-down 和 skip-connection 建立的网络, 如图2(top)所示, 该网络的主要目前是产生一个 单一的 具有很强表征能力和适度大小(fine resolution)的特征图谱, 然后在这张特征图谱上进行预测. 与此相反的是, 我们的方法是利用特征图谱的结构, 将其作为一个特征金字塔, 然后在金字塔的每一层中都进行独立的预测(predictions are independently made on each level). 如图2(down)所示. 通过对比实验和消融实验, 我们发现 FPN 可以大幅的题目 bounding box proposals 的召回率, 也可以提升检测和分割任务的性能, 并且很容易应用到现有的模型当中.除此以外, 我们的 pyramid 结构可以被端到端(with all scales)的训练, 并且在 train/test 阶段可以保证一致性. 相关工作Hand-engineered features and early neural networks: SIFT, HOG, shallow networks Deep ConvNet object detectors: OverFeat, R-CNN, SPPnet, Fast R-CNN, Faster R-CNN Methods using multiple layers: FCN, HyperNet, ParseNet, ION, SSD, MS-CNN Feature Pyramid Networks我们的目标是利用 ConvNet 的金字塔式的特征层级, 这种特征层级拥有从低到高的不同级别的语义信息(浅层的语义信息少, 深层的多), 同时建立一个具有具有整体高级语义信息的特征金字塔. 本文我们主要关注 FPN 的建立, 以及在 RPN(sliding window proposers) 中和 Fast R-CNN 中的使用, 同时会在第6节给出在实例分割proposals上的扩展. 输入: 任意尺寸的单张图片(不进行尺度缩放)输出: 以全卷积的方式, 输出多层次的按比例大小的对应特征图谱映射上面的过程独立于骨干卷积体系结构(backbone convolution architectures), 本文的网络我们使用 ResNets. 构建 FPN 的步骤依次为 bottom-up pathway, top-down pathway 和 lateral connections, 介绍如下: 自底向上的路径(bottom-up pathway):该步骤是根据 backbone 卷积网络的前馈计算过程进行的. 在前向计算中, 卷积网络会以两倍的缩放系数计算出不同尺寸的 feature maps, 最终形成我们所说的 feature hierarchy. 通常情况下, 会有很多的网络层输出的特征图谱具有相同的尺寸, 我们称这些网络层都处于同一个网络阶段(same network stage). 对于我们的特征金字塔来说, 我们在每一个”network stage”上都定义一个金字塔级别. 然后选择每个阶段的最后一层作为特征图的参考集合(因为每一个 stage 的最深层理应具有最强的特征表示), 我们会丰富(enrich)这个特征图谱来创建金字塔.具体来说, 对于 ResNets, 我们使用了每一个阶段的最后一个残差结构的激活层输出的特征, 将这些残差模块conv2, conv3, conv4, conv5 的输出表示为 $\{C_2, C_3, C_4, C_5\}$, 并且注意到他们相对于输入图像具有 $\{4,8,16,32\}$ 像素的步长(原始图片与特征图谱宽或高的比例). 由于 conv1 的特征图谱占用内存较多, 因此我们没有将它包括在金字塔中. 自顶向下的路径以及横向连接(Top-down pathway and lateral connections):自顶向下的路径是通过在较粗糙, 但是语义信息较强的高层特征图(深层)上进行上采样来产生(hallucinates)更高分辨率的图谱. 然后将这些上采样之后的 features 与自底向上(自浅而深)的 features 通过横向连接(lateral connections)的方式拼接在一起.(横向连接的feature map的size是一样大的). 每一次横向连接都会将两个 pathway 上的具有相同大小的 feature maps 融合在一起.那些 bottom-up frature maps 具有较为低级的语义信息(低级是指抽象程度低), 但是这些图谱的特征激活信息(重要特征才会被激活)的位置精度更高, 因为它们经过的下采样次数更少.下面的图3显示了构建 top-down feature map 的模块. 对于一个分辨率较粗糙的特征图谱, 首先将其上采样至2倍(为了简单起见, 直接使用最近邻上采样法), 然后将上采样后的特征图谱与对应的自底向上的图谱进行按元素相加合并(element-wise addition, 由于二者通道数不同, 因此合并前自底向上的图谱会将经过1×1卷积降低通道数). 这个过程会一直迭代进行, 直到最浅的卷积图谱也被合并为止. 为了开始迭代, 在最开始的时候, 我们直接用 $1\tiems 1$ 的卷积层作用在 $C_5% 上, 来产生分辨率最粗糙的特征图谱. 最后, 我们会用3×3的卷积层作用在每一个合并后的特征图谱上, 以此来得到最终的特征图谱, 这是为了消除上采样的混叠效应(aliasing effect of unsampling??). 我们将这些最后得到的特征图谱记为 $\{P_2, P_3, P_4, P_5\}$, 他们与$\{C_2, C_3, C_4, C_5\}$ 相对应并且具有相同的大小. 由于金字塔的每一层都使用了共享的分类器和回归器(就像传统的 featurized image pyramid 一样), 因此我们固定了每一层特征图谱的深度 $d$(numbers of channels), 本文中, 我们令 $d=256$, 也就是说所有额外添加的卷积层的输出通道数都是 256. 在这些额外添加的卷积层中, 我们没有使用非线性结构, 我们通过实验发现, 这会对最终的结果有轻微的影响.Simplicity 是本文设计的核心, 同时我们也发现我们的模型对于很多设计选择都具有很强的鲁棒性. 我们实验了更多复杂的模块(eg using multilayer residual blocks as connections)并且也发现了略微更好的结果. 同时也存在其他更好的连接设计, 但本文的主要目的是探讨FPN的有效性, 因此没要尝试过多的连接组合. 应用FPN是一种用于在卷积网络内部建立特征金字塔的一般化的解决方. 在下文中, 我们在 RPN 中使用我们的方法来进行 bounding box proposal generation, 同时在 Fast R-CNN 中使用 FPN 来进行 object detion. 为了证明我们方法的简单性和有效性, 我们仅仅对原始的系统做很小的改变. Feature Pyramid Networks for RPNRPN 是一个滑动窗口式的物体检测器(类别不可知, class-agnostic). 在原始的 RPN 设计中, 一个小的子网络会在密集的 $3\times 3$ 大小的滑动窗口上进行 evaluate, 这是在一个 单一尺寸的卷积特征图谱 进行的二分类和边框回归操作. 这个过程是通过一个 $3\times 3$ 的卷积层, 后接两个并行的 $1\times 1$ 的卷积层, 这两个卷积层分别进行分类和回归任务, 我们将其称为 network head(这三个网络层统称为 network head).我们通过将原本的 单一尺寸的特征图谱 替换成 FPN 的金字塔特征图谱 来在 FPN 中应用 RPN. 我们在特征金字塔的每一层都添加与 RPN 相同的 head 结构( $3\times 3$ conv and two sibling $1\times 1$ convs). 由于 head 会密集地在金字塔中的所有层级的所有 locations 上滑动(sliding), 因此就 没有必要在每一个层级上使用多尺度的 anchors 了. 相对应的, 我们会给每一个 level 赋予单一的尺寸. 具体来说, 对于特征图谱 $\{P_2, P_3, P_4, P_5, P_6\}$ (这里的 $P_6$ 仅仅为了覆盖更大的尺寸 $512^2$, 它是通过在 $P_5$ 上进行 stride 为 2 的降采样得到的, 在 Fast R-CNN 中并没有使用 $P_6$) 来说, 其每一个特征图谱对应的 anchors 的大小分别为 ${32^2, 64^2, 128^2, 256^2, 512^2}$, 每一层anchors的宽高比例为{1:2, 1:1, 2:1}, 因此, 总共具有15个 anchors (对于每一个 location 而言有15个 anchors, 对比 Faster R-CNN, 每一个 location 具有默认具有 3×3=9 个 anchors)训练时的标签赋值策略和FasterRCNN是一样的, 都会根据 IoU 的大小为每一个 anchors 贴上正负样本的浅标签, 或者不贴.注意, heads 的参数在所有的特征金字塔层级中都是共享的, 我也测试了不共享的情况, 结果显示二者差不多. 共享参数的良好性能表现说明了我们的特征金字塔在所有的层级上都共享着差不多的语义信息. 这个特性带来的好处和使用 featurized image pyamid 差不多, 因为我们可以使用一个通用的 head classifier 在任意图片尺寸中进行预测.按照上述的策略, 我们可以很自然的在 RPN 中使用 FPN 网络, 更具体的细节会在实验部分给出. Feature Pyramid Networks for Fast RCNNFastRCNN 通常只作用在单一尺寸的特征图谱上, 将FPN用于FastRCNN时, 我们需要在不同的金字塔层次上赋予不同尺度的 RoI 大小(因为 RoI pooling 是根据特征图谱和原图的尺寸关系决定的).我们将特征金字塔看做是从图片金字塔产生的特征图谱, 因此我们可以采用和 Fast R-CNN 相同的分配策略来完成 RoI pooling, 具体来说, 我们将宽度为 $w$ ,高度为 $h$ 的 RoI (这里的宽和高是针对原始图片而言的)通过如下公式分配到特征金字塔的 $P_k$ 等级上: k = \lfloor k_0 + log_2(\frac{\sqrt{wh}}{224})这里 224 是标准的ImageNet预训练的大小, 而 $K_0$ 是则大小为 $w\times h = 224^2$ 的RoI应该映射到的目标级别. 类似于基于 ResNet 的 Faster RCNN 使用 $C_4$ 作为单尺度特征映射, 我们将 $k_0$ 设置为4 (也就是说, 与图片一样大的RoI会映射到 $P_4$ 的特征图谱上). 上式表明, 如果RoI的尺度变的更小(如224的0.5倍), 那么该RoI就应该映射到分辨率更高的金字塔图谱上(如 $k=3$ ).(也就是说不同大小的RoI会映射到不同金字塔层级的特征图谱上, 总的来说, 越小的RoI, 会映射到更浅层的特征图谱上, 因为太深的图谱可能已经将小物体信息过滤掉了) 文章将预测器(分类和坐标回归)应用到所有金字塔层级的RoI上面. 需要注意, 预测器(heads)在所有层级上的权重都是共享的. . 在ResNet中, 会在conv4的特征图谱上在加上一个conv5, 但是本章已经将conv5用于构建特征金字塔. 所以和ResNet不同, 文章很直接的利用RoI pooling来获取 $7\times 7$ 的特征 (注意不是基于滑动窗口的检测器, 这一点和YOLO差不多), 并且会使用2层1024维的 fc 隐藏层(后接 ReLU), 然后才会送入最终的预测器层当中(分类和位置回归). 注意到, 和标准的 conv5 head 相比, 我们的 2-fc MLP head 具有更少的权重参数, 运行速度也更快 实验用COCO 80ktrain和35k val进行实验. 所有的网络均在ImageNet1k上预训练. Region Proposal with RPN 实验细节:表1中的所有模型都是以端到端的方式训练的, 输入图片的尺寸被resize, 其最短边长为800像素. 8块GPU同步训练, 每个GPU的minibatch为两张图片, 每张图片的anchors为256. weight decay为0.0001, momentum为0.9. learning rate 开始的30k图片是0.02, 之后是0.002. 训练时包含了那些处于image之外的anchor boxes(Faster选择忽略). 消融实验Comparisons with baselines: 为了公平比较, 我们使用了两种 baseline 方法, 一个采用 C4 特征图谱, 一个采用 C5 特征图谱, 并且他们的 scales 都是 $\{ 32^2, 64^2, 128^2, 256^2, 512^2\}$, 表1(b)相对于表1(a)并没有提高, 说明单一的更高层级的特征图谱不足以输出更好的结果, 因此当层级更高时, 虽然表征能力更强, 但同时特征图谱也变的更加粗糙. 而使用 FPN 则可以大大提高目标的准确率和召回率(AR), 如表1(c)所示. 尤其是在面对小物体和中等物体等多尺度物体时, 会显著提高AR指标. top-down 表1(d)显示了不带 top-down pathway 的 FPN 实验结果, 与表1(b)相比, 可以看出, 带有 top-down pathway 的特征图谱加强可以使得特征图谱具有很强的语义特征信息和更好的分辨率.(原始的特征图谱之间的语义鸿沟更大, 层与层之间的联系比较简单粗糙) lateral connections: 虽然top-down方式的特征图谱具有很强的语义特征信息和更好的分辨率效果, 但是由于经过不断的降采样和上采样过程, 该特征图谱的位置信息可能会变得不够精确. lateral connections 同时结合具有精确位置信息的特征图谱和具有强语义信息的图谱, 进而达到更好的效果. 当没有 lateral connections 时(也就是不使用 down-top 的特征图谱), 效果明显下降, 如表1(e)所示. Pyramid结构的重要性: 如果我们只在特征图谱 $P_2$ 上进行检测, 这就像是Faster RCNN的单尺度方法一样, 所有的anchors都在最后一层图谱上, 这种变体比Faster RCNN好但是比FPN差, 如表1(f)所示. 直观上来说, 在所有特征层上进行检测, 对不同尺度的物体的鲁棒性要更好. 同时我们也注意到, 由于 $P_2$ 的分辨率较高, 因此它会产生更多的 anchors, 但是最终的精度并没有提供太过, 这说明生成大量的 anchors 并不足以提升模型的精度. 利用Fast/Faster RCNN进行目标检测接下来我们在基于区域的检测器上来使用验证 FPN 的有效性, 我们利用AP(Average Precision)指标对FPN进行验证. 实验细节:图片被缩放到最短边长为 800 pixels; 在 8 个 GPU 上利用同步 SGD 来训练模型, 每一个 GPU 上的 mini-batch 中包含 2 张图片, 每张图片有 512 个 RoIs. weight decay 为 0.0001, momentum 为 0.9; lr 在前 60k mini-batches 为 0.02, 在后 20k 为 0.002, 在训练时每张图片会产生 2000 个 RoIs, 在测试时会产生 1000 个 RoIs. 在 COCO 数据集上训练带有 FPN 的 Fast R-CNN 需要 10 个小时. Fast R-CNN Faster R-CNN(on consistent proposals) Comparing with COCO Competition Winners 在Faster RCNN上使用FPN, mAP提高了 2%, 其中小物体的mAP提高了2.1%.(固定的候选区域集合) 在面对consistent proposals时(因为RPN和Fast RCNN要共享权重,所以会不断迭代训练), FPN比Faster RCNN的AP高 2.3 点, 比AP@0.5高 3.8 点. FasterRCNN中RPN和FastRCNN的权重共享大约可以提升mAP值0.5左右(0.2~0.7), 同时, 权重共享也可以降低预测时间(0.148 vs 0.172, ResNet50, M40 GPU因为不用计算两个不同的权重参数, RPN与Fast RCNN用的是一个权重参数). FPN没有使用很多流行的提升精度的方法, 如迭代回归, 难样例挖掘, 上下文建模, 数据增强等等. 但是FPN仍然在目标检测, 实例分割, 关键点检测等多项任务上刷新了最高分. 如果使用这些trick, 理论上会获得更高的精度. FPN是一种通用的特征提取方法, 他同样也适用于实例分割任务, 并且可以取得很好的效果. Extensions: Segmentation Proposals]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学题]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E6%95%B0%E5%AD%A6%E9%A2%98%2F</url>
    <content type="text"><![CDATA[概率论矩阵论线性变换的矩阵为什么强调在这组基下矩阵的奇异值和特征值有什么相似之处和区别之处?奇异值分解把线性变换清晰地分解为旋转, 缩放, 投影这三种基本线性变换. 首先, 矩阵是对线性变换的表示, 确定了定义域空间与目标空间的两组基, 就可以很自然的得到该线性变换的矩阵表示 高数一阶矩和二阶矩是什么?期望, 方差 有一个很大的二维数组, 数组里面大部分都是nan值, 有一小部分不是nan值, 求这些不是nan值之间的欧式距离, 并存到另一个数组中.# 正态函数的随机性是怎么实现的均匀分布随机函数是怎么实现的如何用均匀分布来实现正态分布的随机函数技巧题a,b~U[0,1]，互相独立求Max(a,b) 期望 #]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面试-面经汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E9%9D%A2%E7%BB%8F%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[优秀面经https://www.cnblogs.com/huanyi0723/p/8470866.html https://www.nowcoder.com/discuss/78195 http://www.zheyibu.com/article/5626.html https://www.jianshu.com/p/6671232cec79 https://www.zhihu.com/question/62482926 https://zhuanlan.zhihu.com/p/42705310 在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug， 你如何调试这个bug。解决Bug，第一步就是重现，第二步定位以及Reduce，第三步再来解。所以，不管百万次还是十万次，首先要重现出来，然后找出重现出来的计算机状态。计算机不会欺骗人，每一个问题出来肯定是有原因的，唯一要做的就是如何把这个计算机状态信息还原出来，你可以使用log跟踪等，怎么纪录还原都是工程师的选择。而若能把相关的状态信息拿到，剩下的就是定位是哪里的问题，而这时候最好的就是模拟和Reduce，把问题缩小，排除其它信息干扰。模拟与Reduce成功以后，再想办法解决，然后再来估计解决问题的难度与成本问题等，有些BUG我们是知道，但是解决太麻烦了，影响也不大，就放着。 作者：蓝色链接：https://www.zhihu.com/question/43416744/answer/95944740来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 另一方面，从管理上应该要考虑 bug 的严重性与成本／时间的问题。如果最终能找出问题，需要研究怎样防范相似的 bug。 这个bug很难重现，这个时候你要怎么处理或者重现呢。有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。需要先限定编译器和环节，比如，virtual table 在 Linux 下 GCC 4.9 的实现就是放在read only 段 .rodata，怎么可能被修改？好，就算可以被修改，我第一反应就是上GDB与Valgrind，被破坏的原因很多，你不让我调，我怎么跟你继续说下去，不如直接给我代码，我调给你看？ 那你首先准备一个这样的代码？ 作者：蓝色链接：https://www.zhihu.com/question/43416744/answer/95944740来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 模型压缩cuda作者：oncecoder链接：https://www.nowcoder.com/discuss/23418来源：牛客网 面试官：看你简历上写熟悉CUDA，你能具体讲讲吗。 我：写过图片的resize,padding,卷积，提取hog特征等的gpu代码（kernel函数），效果还不错。 面试官问：具体说说怎么做到提升速度的。 我：把处理安排到gpu的每个thread上。 面试官：那看来你就相当于简单的利用了gpu的多核的特性？ 我一听感觉面试官不是很满意，于是扯了扯：还用了share_memory,const_memory等来提升速度，用了原子操作等来保证安全性。 面试官：你能讲讲使用shared memory为什么快吗？ 我：在某些应用场景下会快，一来和使用场景有关，讲了下哪些场景用这个会好一些，二来可能是硬件方面的原因吧，硬件原理方面的我也不清楚。 然后面试官从内存的金字塔结构，以及gpu的一些特性给我展开讲了很多，这个面试官感觉是gpu方面的行家，人非常好，感觉给我做了个讲座。。。 然后面试官问：你知道warp这个概念吗？ 我说知道，就是gpu底层同时执行的指令数量，现在一般是32.所以在写内核函数的时候，thread的数目最好是32的倍数。其他的不太清楚。 面试官好像点了点头，又给我balabala做了一次讲座。。。。 面试官问：假如要申请一大片空间，一次性申请这么大的，和分多次申请很多小的，但总数一样，哪个快，为什么。 我：在做项目的时候遇到过这种情况，前者会快很多，然后说了原因（答得不太标准，就不误导大家了） 面试官：其实cpu和gpu在这方面是一样的， 都会维护一个表什么的，记不太清楚了。 面试官：怎么看gpu使用情况。我：nvidia-smi(我用的是nvidia的卡) face++ 面经作者：一一后链接：https://www.nowcoder.com/discuss/119900来源：牛客网 一面（30分钟+ 撸项目（很细节，第一个项目每一步都要问为什么不用某个其他的方法） 讲讲adaboost和random frost的相同之处和不同，各自应用范围，实际应用选择 对SVM的理解，简单推导SVM，为什么要用对偶问题（二次规划+核化）具体讲一下为什么要核化，核化的过程 讲一下DL中目标检测的大类和特点（one stage、two stage）为什么two stage比one stage慢，为什么one stage比two stage精度高？one stage在哪些具体方面检测精度不高（ROI+default box的深层理解） 讲讲梯度消失问题及其应对方案（BN、Relu、初始化） 讲讲BN的细节（过程，公式，作用）为什么BN可以加快优化算法的速度 有什么问题 总结：问得很深入，基本都要非常理解才行，提到某个细节之后可能会深入问这个细节更细节的东西，千万别在回答的时候给自己挖坑。 二面：（40分钟+ 自我介绍；链表的倒数第k个结点（双指针） 应用场景题 抛一个不均匀的硬币，设计策略能得到1/2的概率（抛两次）如果要求得到1/3和2/3呢？设计策略（抛四次，我想着抛6次，小哥哥提醒了） 给出一个0到n的随机数生成器，设计策略，让不得到x的条件下，得到其他数的均匀分布（只能生成一次）（hash映射，但是我找不到合适的映射函数，小哥哥提醒了）扩展：不得到两个数呢？m个数呢？（一样） 房子500万，每年涨10%，程序员工资100万，不涨，问多少年能全款买房（几秒钟估算了一下，永远买不起…）（总觉得小哥哥在暗示我什么） 堆介绍，插入元素时调整的时间复杂度（变成二叉树，递归定义）堆排序、其他排序方法介绍和特点（按时间复杂度分了三种去介绍），最常用哪种 有什么问题（小哥哥建议多看些ML的实际场景（我其实想问智商怎么提升…） 总结：二面考基本功，数学算法和ML的熟练运用能力。 三面（院长大佬面）（挂） 自我介绍 用到深度学习的项目（大部分时间聊项目） 深度学习的前沿知识（最新的网络结构、精度最高的目标检测模型等） 有什么问题（大佬很委婉地劝我说他们主要收深度学习方向的…） 作者：jucic 链接：https://www.nowcoder.com/discuss/108078 来源：牛客网 CV岗： 一面： 用C++将一个类改造成线程安全的类 凸优化了解吗 SLAM里面闭环检测是什么怎么做 用深度学习做SLAM了解吗 兼职offer上一原题 交叉熵是什么 二面: 链表反转 快排 三面（院长面） 一直在聊项目 算法细节部分被怼的很厉害 某个函数只能随机产生0或1，利用这个实现一个函数能等概率的返回1-n之间的数，手撕实现代码 一个文件有一亿条整数数据，算一下占用多大磁盘，里面有几十个重复的数据，怎么找出来，内存占用不要超过本身的文件大小 a) 概率是抽样的题目居多，计算正确，错误或者抽中没抽中的概率，与腾讯考察的要求差不多，但稍难其中一题，第一题，问试卷中的10道题，每到5个选项，如果瞎猜，每道题的数学期望是多少，如果每道题猜错的概率是92%，那么每道题的数学期望是多少？b) 计算甲乙两地距离的问题，甲乙分别从AB两地相向而行，甲乙速度比是常数，第一次相遇在距离甲地80KM处，分别到达对方起点后，再返回来相向而行，第二次相遇在距离甲地40KM处，计算甲乙两地相距多远的问题c) 研究基础，问到了RANSAC抽样的问题，将它与概率结合，抽取两个样本，抽取10次，问抽样概率d) ICCV会议2013与2015年分别是在哪里开的e) 选做题：写HOG的伪代码；关于图像模糊问题；问常见的跟踪方法有哪些，简述他们的优缺点，举一个近五年CVPR中流行的跟踪方法，写出它的思想 作者：牛客网链接：https://zhuanlan.zhihu.com/p/29695077来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 中国平安 - 实习生(上海/北京) 1.卷积正向和反向传播 2.Caffe源码 3.斐波那契 memcpy 4.pooling反向 5.项目介绍 6.override overload 纯虚函数等 阿里巴巴 - 2017.3.23 - 实习生 - idst - 非内推 1.linux 修改环境变量 2.sql语句 3.gbdt xgboost区别 4.kaggle项目 30min 5.融合方法，改进 阿里巴巴 - 2017.3.28 - 实习生 - 淘宝搜索 - 内推一面 1.项目介绍(30分钟)—项目过程，融合方法，训练方法，augmentation等 2.batch normalization 3.有没有了解其他机器学习算法 4.介绍一个熟悉的算法(决策树) 5.在线写线性回归 6.对深度学习框架有没有了解，还是只是停留在使用的层面 7.有没有什么想问的 阿里巴巴 - 2017.3.31 - 实习生 - 淘宝搜索 - 内推二面 1.项目介绍 2.kd-tree 3.开放问题 100w商品 50个推荐窗口，怎么安排推荐 腾讯 - 2017.4.10 - 实习生非内推 - 优图实验室 - 一面 1.项目介绍 2.计算卷积核参数数量 3.如何处理深度学习overfitting 4.如何在测试中，加速1000倍(不改变网络结构) 5.pooling层的作用，以及为什么会选择maxpooling 6.有没有从头开始训练一个模型 vgg16 resnet googlenet收敛问题 今日头条 - 2017.4.11 - 日常实习生非内推 - 一面 1.项目介绍 2.如何训练深度学习网络 3.如何处理样本分布不均衡的问题 4.手写代码-反转链表 5.手写代码-前序遍历 今日头条 - 2017.4.11 - 日常实习生非内推 - 二面 1.项目介绍（为什么不尝试xgboost以外的模型） 2.xgboost gbdt区别 3.深度学习训练方法 4.改进方法 5.caffe框架结构 6.手写代码-旋转数组找出最大数字 今日头条 - 2017.4.13 - 日常实习生非内推 - 三面 1.前两面反应较好，聊天 2.对前两个面试官有什么看法 3.有什么问题 #腾讯挺坑的，一面过了，二面面试官打电话确认了面试时间，收到了确认邮件，然后鸽了 腾讯游戏 - 校招内推 - 一面 1.实习介绍 2.介绍svm，为什么要求对偶 3.介绍一个熟悉的算法 4.全局变量 局部变量存储位置不同，静态变量初始化，生存周期 5.python多线程的实现，死锁 6.优化算法 sgd 牛顿法。为什么牛顿法快？及其缺点？ 网易 - 内推校招 - 人工智能事业部 - 一面 1.实习介绍 2.kaggle 深度学习项目介绍 3.几个框架对比 4.模型融合策略和方法 网易 - 内推校招 - 人工智能事业部 - 二面 1.项目介绍，讲你最好的项目 2.实习介绍 3.svm手推 4.kaggle融合的策略和方法 #前3面反映较好，加面 网易 - 内推校招 - 人工智能事业部 - special 加面 1.最好的项目介绍 2.batch normalization算法 3.实习经历 4.cnn现在发展以及不足 5.说对游戏ai感兴趣 - alphago的技术点，强化学习等 华为 - 内推校招 - 1,2,3面 #略 #Nvidia Deeplearning software 面试官很客气，提前定好这次面试时长40分钟 Nvidia - 内推校招 - 一面 1.项目介绍 30min 2.编程题2道 3.过拟合欠拟合 以及其背后本质，偏差方差角度如何理解 #Sensetime 商汤科技 每面30min #号称最难进公司之一？ Sensetime - 2017.9.11 - 校招内推 - 计算机视觉&amp;深度学习 - 一面 1.kaggle比赛 问的比较详细 包括 data augmentation， KNN的trick， 模型融合等 2.实习经历 3.有什么问题 Sensetime - 2017.9.11 - 校招内推 - 计算机视觉&amp;深度学习 - 二面 1.kaggle比赛 2.头条实习 3.python set-list转化 4.caffe框架结构，learning rate设置 5.第K大的数 6.sgd adam区别 7.resnet vgg区别 8.python 变量拷贝规则 9.有什么要问的 Sensetime - 2017.9.11 - 内推校招 计算机视觉&amp;深度学习 - 三面 1.头条实习 比较详细以及为什么头条推荐这么厉害 #面试官是在做dl+推荐，所以比较关心头条所做的东西 2.熟悉什么框架 3.喜欢什么方向，cv还是推荐等，以及个人认为他们的前景 4.学术型硕士还是工程型硕士？ 5.有什么问题 阿里巴巴 - 2017.9.13 - 校招 - 初面 1.头条实习 ——- 特征维度，为什么时延很低，在头条做了哪些，头条的算法 2.深度学习和传统机器学习 3.深度学习最近的发展和技术突破点 4.GBDT是什么 — 加法模型 5.为什么现在推荐可以使用GBDT的内部结点当做LR的特征 — 特征选择和子集评价，还是stack模型融合？ 6.RF GBDT区别 — 方差偏差理论，bagging&amp;boost区别 7.GBDT xgboost区别 —泰勒二阶，并行化，正则项 8.手写MergeSort 9.熟悉什么语言 10.用什么框架 11.深度学习正则化 12.GBDT分布式如何实现 #没有了解过，然后简单说了自己的想法，面试官给我讲了许多这方面 阿里巴巴 - 2017.9.15 - 校招 - 终面 1.头条实习 ——- 模型介绍 2.GBDT xgboost区别 3.kaggle比赛 4.一个整数数组中，寻找3个数乘积最大 5.GBDT与bagging等方法区别 6.linux常用指令 sort grep等 阿里巴巴 - 2017.9.15 - 校招 - 加面 #压力面？ 1.头条实习ffm替换skip gram模型，为什么？效果如何？为什么会有提速效果？线上如何部署等 2.头条所做？训练两个大模型，效果如何？ 3.kaggle比赛 4.vgg16 resnet googlenet区别 5.手写代码-旋转数组找出最小数字 #其余记不清了 大疆 - 2017.9.17 - 校招 - 初面 1.头条实习 2.kaggle项目 待看http://www.cnblogs.com/mrxsc/articles/6266584.html https://zhuanlan.zhihu.com/p/29633019 【链接】依图面试经历（三轮面试，已得offer）https://zhuanlan.zhihu.com/p/27842581 https://www.nowcoder.com/discuss/73739 https://zhuanlan.zhihu.com/p/38067051 【链接】依图科技暑期实习生面试经验https://blog.csdn.net/wslf123/article/details/79924413 字节跳动提前批作者：DASEason链接：https://www.nowcoder.com/discuss/206226?type=2来源：牛客网 一面二面是现场面，三面和交叉面是视频面一面和二面连在一起，三面大约5天之后，交叉面大约三面的两天后，offer call在交叉面的一天后 本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）一面（两道编程题）：面试官应该是未来同事，上来在白板上先描述了第一道题。A题题意：给定n个结点，m条有向边（n&lt;=100）。每个结点代表一个抖音用户，每条边A-&gt;B代表A关注了B。关注具有传递性，即若A关注了B且B关注了C，那么等同于A关注了C。 然后定义“抖音红人”的概念：若一个用户被其它n-1个用户关注，那么他是抖音红人。现给定这样一个关注网络，返回所有的“抖音红人”列表。A题题解：DP+dfs（记忆化搜索）。对于某个用户A，若要求关注A的的用户个数，则需要累加所有指向A的用户的被关注数。然后递归地（dfs）求所有指向A的用户Bi，也要累加所有指向Bi的用户的被关注数。。 有两个关键点：1.需要用记忆化搜索保存中间过程，对于已求过的结点，不能重复递归计算；2.累加不是单纯的加和，而是要对每个结点维护一个集合set，累加的操作其实是求并集操作，防止同一用户被累加多次。本人解题情况：一开始写的猛如虎，然后忘记考虑集合求并集的操作了，后来面试官比较好提醒了我一下，后来把代码改对了。 然后面试官接着描述了B题，题意比较简单：描述KMeans算法，并用Tensorflow写代码实现。题解：这题没啥好说了，把能说的关于Kmeans的细节都和面试官说了，代码也写的还OK（不用写feed_dict那些繁琐的过程，只要写建图的部分就好）。 注意代码需要高度并行化，例如计算相似度这些操作需要用张量运算，保证高度并行化。 两题写完之后，面试官问我有啥想问的，然后就让我等一会儿。过5分钟二面开始。 二面（个人经历、项目、竞赛、论文）二面面试官应该是我将来的mentor，很和蔼。一开始就让我介绍我的经历，然后我就从本科到研究生的经历都说了一遍，沟通过程也很愉快。 中间主要花时间和面试官讲解了曾经的ACM经历（挫折，成就，意义）、介绍 Github 1.5k star 的项目（项目做了啥，为什么受到这么多关注，创新点）、介绍一年多的实习项目（开发过程，技术细节，沟通协作）、讲解自己的一篇AAAI paper（模型架构，contribution，实验）。最后二面面试官挺满意的，面试愉快地结束了。 三面（个人经历、项目、竞赛、论文）三面面试官是AILab王雨轩总监。王老师人在美国，所以是早上7点的视频面。。三面是我个人感觉最难一面，由于不能保证我回答的准确性，这里只写王老师问了啥。 讲讲你的个人经历 你介绍一下你的Paper 我看你还做过CV的项目和安卓游戏的项目，也简单介绍一下吧4.（开始虐了）先写道题吧。用Tensorflow写一个KNN算法 KNN算法是否可微 我看你用了tf.argmax()，argmax的导数是啥（其实是不可导，因为我之前回答了KNN是可微的，所以他想看看我会回答什么）7.（王老师看我被虐的有点惨，笑着说换道题吧）用C++写个简单的矩阵乘法吧 矩阵乘法怎么优化？（当时我回答的是将复杂度优化到O(n^log7)的Strassen算法，而且算法名字不会读。。 有可能王老师还希望听到我回答关于多线程的优化方法） 两个上三角矩阵相乘如何优化？（完全懵逼，答不出来）王老师还问了一些其它细节问题，暂时想不起来了。 当时三面面完感觉自己要凉了。。 交叉面（个人经历、项目、NLP算法细节、职业规划）当接到HR交叉面的通知时，我是不敢相信的（而且HR居然说前三面的面试官对我的评分都很不错，难以置信。。）当我知道面试官是李航老师的时候，我更是不敢相信的（当时心里太激动，心想能和李航老师交流，挂了也值了-。-）抱着久久不能平复的心情，坐在显示器前等待了一个多小时，终于等到李航老师上线了。 能和偶像当面对话，难掩心中的激动，但是担心给李航老师留下不好的印象，于是还是克制住了自己激动的情绪。。我这里也主要只写李航老师问了啥吧，我的回答就不写了。 介绍一下你做过的项目 介绍一下你的paper Word2vec，fasttext，ELMo，GPT，BERT的区别 介绍一下BERT的模型架构，多少层，怎么预训练，怎么feature based/fine-tune 什么是self-attention，什么情况下要用，K、Q、V分别是啥 你为什么选择我们公司 你将来的职业发展规划李航老师人也特别的好，基本没有怎么为难我（而且没考我《统计学习方法》）。最后李航老师问你有什么想问我的。于是我面试结束前才屁颠屁颠地表达了我压抑已久的对李航老师的仰慕，然后臭不要脸地加了李航老师的微信（这波不亏！） 最终本人于一天后收到offer call。简单总结一下个人认为面试成功的几个关键因素： 刷题还是很必须的。要做到快速出题，实在不会的题也得写个次优解，千万不要挂机。 多掌握面试的主导权。引导面试官听你擅长的东西。 面试气氛也很重要。 至少你要保持笑容，尽量不要愁眉苦脸，让面试官觉得以后和你合作会很愉快。 知识的积累。这个平时就要做到，就不多说了。 面试前的复习重点是自己的简历。 因为面试官重点会考察你对自己做过的项目的理解程度，看你是不是划水的。 放松心态。 不要因为一个题出不来就方了，其实很多题大家都做不出来。保持心态回答后续的问题，不要中途就认为自己凉了。很多面试其实是所谓的“压力面”，面试官并不指望你能回答所有问题，有的时候更想看看你在面对这种难题时是如何思考和应对的。 暂时先写这么多吧，祝大家都拿到自己心仪的offer！]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SSD-Single Shot MultiBox Detector]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SSD-ECCV2016%2F</url>
    <content type="text"><![CDATA[文章: SSD: Single Shot MultiBox Detector作者: Wei Liu, Dragomir Anguelov, Dumitru Erhan 核心亮点(1) 在不同层的feature map上使用网格法获取候选区域: 某种程度上SSD可以看做是YOLOv1和FasterRCNN的结合, 在不同layer的输出的不同尺度的feature map上划格子, 在格子上利用anchor思想. 因此, . (YOLOv2也使用了Anchor的思想) (2) 使用了数据增广, 难样例挖掘, atrous算法等trick大幅度提升精度和速度这个其实算不上亮点, 只不过作者确实使用这些技术提升性能不少 (3) 相对于那些需要object proposals的两阶段模型, SSD方法全完取消了 proposals generation, pixel resampling 或者 feature resampling 这些阶段 论文细节背景介绍目前, 虽然Faster RCNN取得了很好的检测精度, 但是对于普通设备来说, Faster RCNN过于庞大, 计算时间太久, 不足以达到实时监测. YOLO虽然速度很快, 但是精度太低了, 达不到基本要求. SSD的出现正是为了解决这些问题, 确定在不丢失过度精度的前提下, 提升检测的速度. Single Shot Detector(SSD) 根据上图, 简单说一下SSD的关键要素 输入: 图像以及每个物体对应的ground truth boxes 多特征图谱的anchor思想: 在不同尺度的特征图谱上(如上图的4×4和8×8), 对每个位置上设置多个具有不同大小和长宽比的boxes, 称之为 default boxes. 输出: 对于每一个default box, 都会输出4个相对位移用于边框回归, 同时会输出所有类别的预测概率 匹配: 在预测阶段, 需要将这些 defaults boxes 与 gt boxes 匹配. 在上图中, 最终有两个框(蓝色)与猫所在框匹配, 有一个框(红色)与狗所在框匹配. 这三个框被标记为正样本, 其余剩下的框都被标记为负样本. (可见负样本数量远远大于正样本数量) 损失函数: 边框回归损失(Smooth L1) 和 类别置信度损失(softmax 交叉熵损失) 的权重和. ModelSSD 会产生固定数量的bounding box, 以及每个bounding box的各个类别的预测概率, 最后会使用NMS算法生成罪最终的检测结果. 多尺度feature map: 在卷积网络的不同卷积层后面添加convolutional feature layers, 并且在每一层中都会进行检测任务. Convolutional predictors for detection: 每一个添加的特征层(或者在基础网络里的特征层), 都可以使用一系列的卷积核产生固定大小的predictions, 如图2所示. 对于一个大小为 $m\times n$, 具有 $p$ 通道的特征层, 使用的卷积核就是 $3\times 3\times p$ , 之后会产生相对于 default box 的预测坐标, 已经每一类的预测置信度. 对于特征图上 $m\times n$个位置, 在对每个位置使用卷积核之后, 都会产生一个输出值. (YOLO架构则是用一个全连接层来代替这里的卷积层) Default boxes and aspect ratios: 每一个feature map的cell都会与一系列 default bounding box 相关联. 对于每一个cell来说, 模型会预测与之关联的 default bounding box 相对于该cell的偏移量, 同时会预测这些boxes对应的每一类的出现概率. 具体来说, 对于一个位置上的 $k$ 个boxes中的每一个box, 都会计算出这个box的4个相对位移值 $c$ 个类别的score. 因此, 对于一个feature map来说, 总共需要 $(c+4)\times k$ 个卷积核, 最终该对于大小为 $m\times n$ 的 feature map来说, 其输出结果数量为: $(c+4)\times k\times m\times n$. 空洞卷积(Dilation Conv) 采用VGG16做基础模型，首先VGG16是在ILSVRC CLS-LOC数据集预训练。然后借鉴了DeepLab-LargeFOV，分别将VGG16的全连接层fc6和fc7转换成 $3 \times 3$卷积层 conv6和 $1 \times 1$ 卷积层conv7，同时将池化层 pool5 由原来的 stride=2 的 $2\times 2$ 变成 stride=1 的(猜想是不想reduce特征图大小)，为了配合这种变化，采用了一种 Atrous Algorithm，其实就是conv6采用扩展卷积或带孔卷积（Dilation Conv），其在不增加参数与模型复杂度的条件下指数级扩大卷积的视野，其使用扩张率(dilation rate)参数，来表示扩张的大小，如下图所示，(a)是普通的 $3 \times 3$ 卷积，其视野就是 $3\times 3$ ，(b)是扩张率为 1，此时视野变成 $7\times 7$ ，(c)扩张率为3时，视野扩大为 $15 \times 15$ ，但是视野的特征更稀疏了。Conv6采用 $3\times 3$ 大小但dilation rate=6的扩展卷积。 https://wx4.sinaimg.cn/mw690/d7b90c85ly1g178tkhu8kj20lc07lgq1.jpg TrainingSSD与二阶段检测方法在训练时的区别: SSD训练图像中的GT信息需要赋予到那些固定输出的boxes上面(也就是说不仅要使用bounding box的坐标, 还有把类别标签也与每一个box绑定, 这种方法在YOLO, FasterRCNN(只分前后景), MultiBOx中都有用到). Matching strategy: 只要预测框与gt box之间的 jaccard overlap(就是交并比) 大于一个阈值(0.5), 就认为是配对成功, 反之, 认为是背景. Training objective: SSD的损失函数源自于MultiBox的损失函数, 但是SSD对其进行拓展, 使其可以处理多个目标类别. 用 $x_{ij}^p={1,0}$ 表示第 $i$ 个default box 与类别 $p$ 的第 $j$ 个gt box匹配, 否则若不匹配的话, 则 $x_{ij}^p = 0$. 根据上面的策略, 一定会有 $\sum_i x_{ij}^p &gt;1 $ 的情况出现, 意味着对于第 $j$ 个gt box, 很有可能有多个default box与之匹配. 总的目标函数是由Localization loss(loc) 和 confidence loss(conf) 的加权求和得到的: L(x,c,l,g) = \frac{1}{N} (L_{conf}(x,c) + \alpha L_{loc}(x,l,g))式中: $N$是与ground truth box 相匹配的 default boxes个数(如果N为0, 则将该项loss设为0) localization loss(loc) 是 Fast RCNN 中的Smooth L1 loss, 用于对bounding box进行回归, 与Faster RCNN一样, 我们会将真实的gt box坐标值转换成相对于default box( $d$ )中心 $(cx,cy)$ 的偏移量和缩放度, 预测的时候也是对偏移量和缩放度进行预测: L_{loc}(x,l,g) = \sum_{i\in Pos}^N \sum_{m\in\{cx,cy,w,h\}} x_{ij}^k smooth_{L_1}(l_i^m - \hat g_j^m) confidence loss(conf) 是 Softmax 交叉熵loss L_{conf}(x,c) = -\sum_{i\in Pos}^N x_{ij}^p log(\hat c_i^p) - \sum_{i\in Neg} log(\hat c_i^0), 其中, \hat c_i^p = \frac{exp(c_i^p)}{\sum_p exp(c_i^p)} 权重项 \alpha, 默认设置为1. Choosing scales and aspect ratios for default boxes: 大部分CNN网络在越深的层, feature map的尺寸会越来越小, 这样做不仅仅是为了减少计算与内存的需求, 还有个好处就是, feature map往往具有一定程度的平移和尺度不变性.为了处理不同尺度的物体, OverFeat和SPPNet都是通过在feature map上进行不同尺度的pooling, 然后再将这些pooling综合进行获取固定长度的特征向量输出. SSD采用的策略是使用同一个网络中不同层的feature map, 这些feature map也是不同尺度的, 同时也具有共享参数的好处. 本文使用了 8×8 和 4×4 大小的feature map. 假如feature maps数量为 $m$, 那么每一个feature map中的default box的尺寸大小计算如下: s_k = s_{min} + \frac{s_{max} - s_{min}}{m-1}(k-1), k\in [1,m]上式中, $s_{min} = 0.2 , s_{max} = 0.9$. 对于原文中的设置 $m=6 (4, 6, 6, 6, 4, 4)$, 因此就有 $s = \{0.2, 0.34, 0.48, 0.62, 0.76, 0.9\}$然后, 几个不同的aspect ratio, 用 $a_r$ 表示: $a_r = {1,2,3,1/2,1/3}$, 则每一个default boxes 的width 和height就可以得到( $w_k^a h_k^a=a_r$ ): w_k^a = s_k \sqrt{a_r}h_k^a = \frac{s_k}{\sqrt {a_r}}对于宽高比为1的 default box, 我们额外添加了一个 scale 为 $s_k’ = \sqrt{s_k s_{k+1}}$ 的 box, 因此 feature map 上的每一个像素点都对应着6个 default boxes (per feature map localtion).每一个default box的中心, 设置为: $(\frac{i+0.5}{|f_k|}, \frac{j+0.5}{f_k})$, 其中, $|f_k|$ 是第 $k$ 个feature map的大小 $i,j$ 对应了 feature map 上所有可能的像素点.在实际使用中, 可以自己根据数据集的特点来安排不同的 default boxes 参数组合 这种多尺度的feature maps策略, 可以适应不同大小的物体的检测, 如下图, 对于体积较小的猫来说, 它会与 8×8 feature map 的default box匹配, 而对于体积较大的狗来说, 它会与 4×4 feature map 的default box 匹配, 而其余的都会被看做是负样本. Hard negative mining: 在一系列的matching之后, 大多数default boxes都会被认为是负样本. 这会导致正负样本不均衡问题. 对于, SSD会将所有的负样本按照scores loss的高低进行排序(损失高的优先级在前), 然后每次只选择顶端的负样本进行训练, 负样本与正样本之间的比例为 3:1. Data augmentation: 为了增强对物体多尺度和形状的鲁棒性, 对于每一张训练数据, 会随机使用下列数据增广技术: 使用整张图片 采样一个patch (这里的patch我认为就是裁剪子区域的感觉), 使其与物体之间的最小交并比为0.1, 0.3, 0.5, 0.7, 0.9 随机采样一个patch 采样的patch与原始图像大小的比例为[0.1, 1], aspect ratio在 0.5 到 2 之间. 当gt box的中心出现在采样的patch中时, 我们保留重叠部分. 在这些采样步骤之后, 每一个采样的patch被resize到固定的大小, 并且以0.5的概率被水平翻转. 实验 hole filling algorithm??//TODO SSD模型对于bounding box的size非常敏感, 也就是说, SSD对于小物体目标较为敏感, 在检测小物体目标上表明交差, 主要也是因为对于小目标而言, 经过多层卷积之后, 剩余信息过少导致的. 数据增广对于结果的提升非常明显 多feature map对结果的提升是有很大帮助的 使用较多的default boxes, 效果较好(但也不能太多) atrous: atrous是精度有一定提高, 同时对速度有很大提高(约20%) Inference time: SSD会产生大量的bounding boxes, 使用NMS算法只留下top200 (这一步SSD300在VOC20类的每张图像上, 需耗时2.2msec) 上图看起来SSD300比YOLO还要快, 但实际上YOLO的网络层数是24层, 而SSD的层数是12层, 这样比起来有点不太公平( 但是层数多居然精度没SSD高, 这也值得吐槽, 但是个人觉得这是因为YOLOv1的设计比较粗糙, 很多trick没有使用导致的, 所以看看YOLOv2, 和YOLOv3的版本, 结果还是挺不错的) SSD 中如何计算 default box 的大小假如feature maps数量为 $m$, 那么每一个feature map中的default box的尺寸大小计算如下: s_k = s_{min} + \frac{s_{max} - s_{min}}{m-1}(k-1), k\in [1,m]上式中, $s_{min} = 0.2 , s_{max} = 0.9$. 对于原文中的设置 $m=6 (4, 6, 6, 6, 4, 4)$, 因此就有 $s = \{0.2, 0.34, 0.48, 0.62, 0.76, 0.9\}$然后, 几个不同的aspect ratio, 用 $a_r$ 表示: $a_r = {1,2,3,1/2,1/3}$, 则每一个default boxes 的width 和height就可以得到( $w_k^a h_k^a=a_r$ ): w_k^a = s_k \sqrt{a_r}h_k^a = \frac{s_k}{\sqrt {a_r}}对于宽高比为1的 default box, 我们额外添加了一个 scale 为 $s_k’ = \sqrt{s_k s_{k+1}}$ 的 box, 因此 feature map 上的每一个像素点都对应着6个 default boxes (per feature map localtion). SSD 使用了哪些数据增广方法?水平翻转, 随机裁剪+颜色扭曲(random crop &amp; color distortion), 随机采集区域块(randomly sample a patch, 目标是为了获取小目标训练样本) 为什么SSD不直接使用浅层的特征图谱, 而非要额外增加卷积层, 这样不是增加模型的复杂度了吗?FPN: 理想情况下, SSD 的特征金字塔是从多个卷积层输出的特征图谱得到的, 因此它的计算成本几乎为零. 但是为了避免使用到那些表征能力不强的低阶特征图谱(浅层), SSD 只使用了深层的特征图谱(conv4_3), 同时在 backbone 网络的后面又添加了几层卷积层来提取高表征能力的特征图谱. 但是这样就是的 SSD 错过了那些低阶特征的信息, 这些低阶特征中往往包含了高阶特征不具有的信息, 如小物体的特征信息, 这也是为什么 SSD 对小物体不敏感的原因之一.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SNIPER]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SNIPER%2F</url>
    <content type="text"><![CDATA[文章:作者:备注:]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FaFS (CVPR, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FaFS-CVPR2017%2F</url>
    <content type="text"><![CDATA[文章: Fully-adaptive feature sharing in multi-task networks with applications in person attribute classification作者: Yongxi Lu, Abhishek Kumar, Shuangfei Zhai备注: https://blog.csdn.net/cv_family_z/article/details/78224184 Paper Reading Note URL: http://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Fully-Adaptive_Feature_Sharing_CVPR_2017_paper.pdf TL;DR在进行多任务学习时, 手动设计网络结构是一个繁琐, 低效的过程, 本篇文章提出了一种可以构建紧凑的多任务深度学习体系结构的方法. 主要思想是首先从一个较 “薄” 的网络开始, 然后在训练过程中以贪心的方式动态地扩展这个网络, 通过不断的迭代, 最终会创建出一种类似于树的深层体系结构，类似的任务处在相同的分支上. 作者在行人的多属性识别任务上验证了这种方法的有效性. Algorithm首先从一个教 “薄” 的网络开始, 令 thin-w 代表 “瘦身后” 的模型，$w$ 是瘦身因子，瘦身版的模型与原始VGG-16对比为图1所示: 最小化目标函数如下面的公式2所示: 接着我们使用贪心算法 SOMP 找到近似解 $w^* (l)$, 如算法2所示: 网络分割成两个或多个子网络或分支，对于行人属性，每个子网络的预测是sigmoid单元，生成归一化的属性置信度得分。论文仅在结合点加宽网络，扩展后新增加的矩阵参数与扩展器参数矩阵大小相同，网络在扩展点有多个输出, 具体的过程如图2所示. 在进行任务之间的聚合时, 直观上可以知道, 对于相似度较小的两个任务, 我们应该提前将它们分割, 因为它们之间需要共享的特征较少, 也就是说, 对于相同的特征, 其中一个任务可以较好的识别, 但是另一个任务就无法识别了, 任务之间的关系描述为公式6所示: 两个分支的密切关系为公式 7 和 8 所示: Experiment DetailCelebA人脸属性分类和DeepFashion衣物属性分类如表1所示 不同方法之间的 acc, speed, 和 compactness 的比较如表2所示 当将任务组更改为将更多的不同任务分到同一组时，准确度会降低, 如图3所示 表4探究了不同分组所带来的影响: Thoughts多任务学习对于行人属性可以提点, 同样的, 对于车辆属性也应该具有类似的效果, 关键在于如何设计合理的多任务学习模型和损失函数, 文中虽然给出了一种基于贪心的自动构建方法, 但是这种方法是否能够方便的扩展到其他模型上, 这一点还有待论证.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>多任务学习</tag>
        <tag>行人属性识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShuffleNetV2 (ECCV, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-ShuffleNetV2-ECCV2018%2F</url>
    <content type="text"><![CDATA[文章: ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design作者: Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, Jian Sun备注: Megvii 摘要目前，神经网络体系结构设计主要以计算复杂度的 间接度量 为指导，即, FLOPs。然而，速度等直接指标也取决于其他因素，如内存访问成本和平台特性。因此，这项工作建议评估目标平台上的直接度量，而不仅仅是考虑 FLOPs。在一系列控制实验的基础上，提出了一些实用的网络设计准则。并依照这些准则, 提出了一种新的体系结构，称为ShuffleNet V2。综合消融实验证明，本文提出的模型在速度和精度上是最先进的。 Introduction近年来的模型: VGG, GooLeNet, ResNet, DenseNet, ResNeXt, SE-Net除了精度外，计算复杂度也是一个重要的考虑因素。现实世界中的任务通常旨在在有限的计算预算下获得最佳的精度，这是由目标平台(例如，硬件)和应用场景(例如，自动驾驶需要较低的延迟)给出的。这激发了一系列致力于轻量级架构设计和更好的速度精度权衡的工作，包括Xception[12]、MobileNet[13]、MobileNet V2[14]、ShuffleNet[15]和CondenseNet[16]等。在这些模型中，分组卷积(Group Conv)和深度卷积(Depth-wise Conv)是至关重要的。为了度量计算复杂性，一个广泛使用的度量是浮点运算的数量，即 FLOPs。然而，FLOPs是一个间接指标。这是一个近似，但通常不等于本文真正关心的直接度量，比如速度或延迟。这种差异在以前的工作中已经注意到了[17,18,14,19]。例如，MobileNet v2 比 NASNET-A 快得多，但它们却有类似的 FLOPs。这种现象在图1(c)(d)中得到了进一步的体现，图1(c)(d)显示了具有类似故障的网络具有不同的速度。因此，仅用 FLOPs 作为计算复杂度的度量是不够的，可能会导致次优设计。 间接(FLOPs)和直接(speed)指标之间的差异可以归结为两个主要原因。第一，几个对速度有很大影响的重要因素没有被FLOPs考虑在内。其中一个因素就是内存访问成本(MAC)。在某些操作(如组卷积)中，这样的开销占运行时的很大一部分。它可能成为计算能力强的设备(如gpu)的瓶颈。在网络体系结构设计中不应简单地忽略这一成本。另一个是并行度。在相同的失败情况下，并行度高的模型比并行度低的模型快得多。第二, 同样的FLOPs操作根据平台的不同，可能会有不同的运行时间。例如，张量分解在早期的工作中被广泛使用[20,21,22]来加速矩阵的乘法。然而，最近的[19]研究发现，在GPU上[22]中的分解甚至更慢，尽管它减少了75%的FLOPs。本文调查了这个问题，发现这是因为最新的CUDNN[23]库是专门针对3×3 conv优化的，本文不能想当然的认为3×3 conv比1×1 conv慢9倍。根据这些观察结果，本文建议在进行有效的网络架构设计时应考虑两个原则。首先，应该使用直接度量(例如，速度)，而不是间接度量(例如，FLOPs)。其次，应该在目标平台上评估这些指标。在这项工作中，本文遵循这两个原则，并提出了一个更有效的网络工作架构。在第2节中，本文首先分析了两种具有代表性的最先进网络的运行时性能[15,14]。在此基础上，本文提出了四种有效的网络设计准则，这些准则不仅仅是考虑 FLOPs。虽然这些指南是独立于平台的，但本文依然进行了一系列受控的实验，在两个不同的平台(GPU和ARM)上用专用的代码优化来验证它们，以确保本文的结论是最先进的。在第三节中，本文根据准则设计了一个新的网络结构。因为它的灵感来自ShuffleNet[15]，所以它被称为ShuffleNet V2。通过第4节的综合验证实验，在这两个平台上都比以前的网络更快、更准确。图1(a)(b)给出了比较情况的概览。例如，在计算复杂度预算为40M FLOPs的情况下，ShuffleNet v2的准确率分别比ShuffleNet v1和MobileNet v2高3.5%和3.7%。 Practical Guidelines for Efficient Network Design本文的研究是在两个广泛采用的硬件与行业级优化的CNN库。本文注意到本文的CNN库比大多数开源库更有效。因此，本文保证本文的观察和结论是可靠的，对工业实践具有重要意义。 GPU. A single NVIDIA GeForce GTX 1080Ti is used. The convolution li- brary is CUDNN 7.0 [23]. We also activate the benchmarking function of CUDNN to select the fastest algorithms for different convolutions respectively. ARM. A Qualcomm Snapdragon 810. We use a highly-optimized Neon-based implementation. A single thread is used for evaluation. 其他设置包括:打开全优化选项(例如张量融合，用于减少小操作的开销)。输入图像大小为224×224。每个网络被随机初始化并会评价100次, 使用平均运行时间作为最终结果.为了开始本文的实验，本文分析了两种最先进的网络ShuffleNet v1[15]和MobileNet v2[14]的运行时性能。它们在图像分类任务中既高效又准确。它们都广泛应用于手机等低端设备。虽然本文只分析了这两个网络，但本文注意到它们代表了当前的趋势。它们的核心是分组卷积和深度卷积，这也是其他先进网络的关键组件，如ResNeXt[7]、Xception[12]、MobileNet[13]和CondenseNet[16]. 根据不同的操作分解整个运行时间，结果如图2所示。本文注意到 FLOPs 只占有卷积部分。虽然这部分花费的时间最多，但是其他操作包括数据I/O、data shuffle 和 element-wise 操作(add张量、ReLU等)也需要相当长的时间。因此，只使用 FLOPs 对实际运行时进行估计不够准确。 基于这一观察，本文从几个不同的方面对运行时间(或速度)进行了详细的分析，并为高效的网络架构设计得出了几个实用的指导原则。 G1) 通道宽度相等，内存访问成本(MAC)最小现代网络通常采用深度可分卷积[12,13,15,14]，其中点态卷积(即 1×1 卷积)占了[15]复杂度的绝大部分。本文研究了1×1卷积的核形状, 发现其由两个参数指定: 输入通道 $c_1$ 和输出通道 $c_2$ 的数量。设 $h$ 和 $w$ 为 feature map 的空间大小，1×1 卷积的 FLOPs 为 $B = hwc_1c_2$为了简单起见，本文假设计算设备中的缓存足够大，可以存储整个特征图谱和参数。因此，内存访问成本(MAC)或内存访问操作的数量是 $MAC = hw(c_1+c_2)+c_1c_2$。注意，这两项分别对应于输入/输出特性映射和卷积核权重的内存访问。从均值不等式，本文得到: MAC \geq 2\sqrt{hwB} + \frac{B}{hw}因此，MAC有一个由FLOPs给出的下界。当输入通道和输出通道数目相等时，到达下界。上面结论只是理论性的。实际上，许多设备上的缓存不够大。此外，现代计算库通常采用复杂的阻塞策略来充分利用缓存机制[24]。因此，实际MAC可能会偏离理论MAC。为了验证上述结论，本文进行了如下实验。通过重复叠加10个 building block 来构建基准网络。每个 block 包含两个卷积层。第一个包含c1输入通道和c2输出通道，and the second otherwise.(啥意思?)表1通过改变 $c_1:c2$ 的比例来测试运行速度，同时固定 FLOPs 不变。很明显，当 $c_1:c_2$ 接近 1:1 时，MAC变得更小，网络评估速度更快。 G2) 过多的 Group Conv 会增加 MACGroup Conv 是现代网络结构的核心[7,15,25,26,27,28]。它通过将所有通道之间的密集卷积变的更稀疏(仅在通道组内)来降低计算复杂度(FLOPs)。一方面，它允许在给定 FLOPs 的情况下使用更多的通道，增加了网络容量(从而提高了准确性)。然而，另一方面, 通道数量的增加导致更多的 MAC。形式上，1×1 Group Conv 的 MAC 和 FLOPs 之间的关系为 MAC = hw(c_1 + c_2) + \frac{c_1 c_2}{g} = hwc_1 + \frac{Bg}{c_1} + \frac{B}{hw}其中 $g$ 为组数，$B = hwc_1c_2 / g$ 为 FLOPs。可以看出，给定固定的输入形状 $c_1\times h\times w$，计算量 B 和 MAC 都随着 $g$ 的增大而增大。 为了验证 Group Conv 在实际应用中的影响，本文通过叠加 10个 pointwise group 卷积层，建立了一个基准网络。表2显示了在固定 FLOPs 不变时使用不同 group numbers 的运行速度. 很明显，使用较大的分组数量会显著降低运行速度。例如，在GPU上使用8组比使用1组(标准密集卷积)慢两倍多，在ARM上慢30%。这主要是由于MAC的增加。本文注意到，本文的实现经过了特别的优化，比一组一组地计算卷积要快得多。 因此，本文建议根据目标平台和具体任务谨慎的选择分组数量。使用较大的组号是不明智的，因为这可能会导致产生更多的通道，这样一来精度提高的好处很容易被快速增长的计算成本所抵消。 G3) 网络碎片化降低了并行度在 GoogLeNet 系列[29,30,3,31]和自动生成的体系结构[9,11,10]中，每个网络块都广泛采用“多路径”结构。使用许多小的操作符(这里称为“片段操作符”)，而不是一些大的操作符。例如，在NASNET-A[9]中，碎片操作符的数量(即一个 building block 中单个卷积或池化操作的数量)为13。相反，在像 ResNet 这样的常规结构中，这个数字是2或3。虽然这种碎片化的结构已被证明有利于提高精度，但它可能会降低效率，因为它对GPU等具有强大并行计算能力的设备不友好。它还引入了额外的开销，比如 kernel launching 和信息同步(synchronization) 为了量化网络碎片化对效率的影响，本文评估了不同碎片化程度的网络块的结构。具体来说，每个构建块由1到4个1×1的卷积组成，这些卷积按顺序或并行排列。块结构如附录图1所示。每个网络块都会重复堆叠10次。 表3的结果显示，分段在GPU上显著降低了速度，如4段结构比1段慢3倍。在ARM上，减速相对较小。 G4) Element-wise 操作是不可忽略的如图2所示，在轻量模型[15,14]中，element-wise 操作占用了相当多的时间，尤其是在GPU上。这里的元素操作符包括ReLU、Add Tensor、Add Bias等。它们的 FLOPs 较小，但 MAC 相对较高。特别地，本文还考虑了深度卷积(depthwise convolution)[12,13,14,15]作为一个 element-wise 运算符的情况，因为它也具有较高的MAC/FLOPs比。 为了验证本文的想法，本文在ResNet[4]中实验了 “bottleneck” 单元(1×1 conv + 3×3 conv + 1×1 conv, ReLU + Shortcut)。同时分别移除了 ReLU 和 Shortcut 操作。表4展示了不同变体的运行时间。可以看出, 在去除 ReLU 和 Shortcut 后，GPU 和 ARM 均获得了20%左右的加速。 结论和讨论基于上述指导思想和实证研究，本文认为有效的网络架构应该遵循以下几点: 使用 “均衡” 的卷积(信道宽度相等); 在使用分组卷积(Group Conv)时, 需要注意带来的成本; 降低网络的破碎程度, 即不要过多的使用多路径的 block; 减少 element-wise 操作这些特性的选择依赖于具体的平台(例如内存操作和代码优化)，它们不仅仅依赖于 FLOPs。因此, 在实际的网络设计中, 应该同时考虑这些因素. 轻量级神经网络体系结构的最新进展[15,13,14,9,11,10,12]大多基于 FLOPs 度量，没有考虑上述特性。例如，ShuffleNet v1[15]严重依赖于组卷积(违反G2)和类似瓶颈的构建块(违反G1)。MobileNet v2[14]使用了一个违反G1的反向瓶颈结构。它使用深度卷积, 同时在一个很 “厚” 的特征图谱上使用 ReLU, 这违反了G4。自动生成的结构[9,11,10]高度碎片化，违反G3。 ShuffleNet V2: an Efficient ArchitectureReview of ShuffleNet v1根据 ShuffleNetV1，轻量级网络的主要挑战是，在给定的计算成本(FLOPs)下，只能负担得起有限数量的特征信道(feature channel)。为了在不显著增加 FLOPs 的情况下增加信道数量，ShuffleNetV1采用了两种技术: Point-wise Group Conv 和 bottleneck 结构。然后引入 “通道洗牌” 操作，使不同的通道组之间能够进行信息通信，从而提高准确性。构建块如图3(a)(b)所示。 正如第2节所讨论的，Point-wise Group Conv 和 bottleneck 结构都增加了MAC(违反G1和G2)。这一成本是不可忽视的，特别是对轻量的模型。此外，使用太多分组违反了G3。Shortcut Connect 中的 element-wise add 操作也是不可取的(G4)。因此，为了达到高的模型容量和效率，关键问题是如何保持一个大的数量和同样宽的通道，既不进行密集卷积，也不使用过多的分组. Channel Split and ShuffleNet V2为了实现上述目的，本文引入了一个简单的操作符 Channel Split。如图3(c)所示。在每个单元的开始，将 $c$ 特征通道的输入分为两个分支，分别为 $c - c’$ 和 $c’$ 通道。根据 G3 原则，其中一个分支保持不变(相当于 Shortcut)。另一个分支由三个具有相同输入和输出通道的卷积组成，以满足G1。与 ShuffleNetV1 不同的是，这两个1×1卷积不再是 Group-wise 的, 其中部分原因是遵循G2，另一部分原因是 Channel Split 操作已经天然的生成了两个组。 经过 Shuffling 之后，下一个单元开始。注意，ShuffleNet v1中的 Add 操作不再存在。像ReLU和深度卷积这样的元素操作只会存在于一个分支中。此外，连续的三个元素操作(“Concat”, “通道洗牌” 和 “通道分割”)被合并为单个的 element-wise 操作。根据 G4 可知, 这种做法是有益的。 对于空间向下采样(spatial down sampling)，本文对该单元进行了稍微修改，如图3(d)所示, 本文移除了 Channel Split 操作符。因此，输出通道的数量刚好增加了一倍(符合 down sampling 的特点) 本文提出的 building block (c)(d) 以及生成的网络称为 ShuffleNet V2。基于以上分析，本文得出结论，这种架构设计是高效的，因为它遵循所有的准则(G1~G4)。 将这些 building-block 反复堆叠，进而构建整个网络。为了简单起见，本文设置 $c’ = c/2$。总体网络结构与ShuffleNet v1[15]相似，如表5所示。只有一个区别:在全局平均池之前添加一个传统的1×1卷积层来混合特性，而在ShuffleNet v1中没有。与[15]类似，将每个块中的信道数进行缩放，生成不同复杂度的网络，标记为0.5×、1×等。 Analysis of Network AccuracyShuffleNet v2不仅高效，而且准确。有两个主要原因: 首先，每个 building-block 的高效特性使得可以使用更多的特性通道和更大的网络容量 其次，在每个块中，有一半 feature channels (当 $c’ = c/2$ 时)直接穿过当前的 block 并加入下一个块。这可以看作是一种特征重用(feature reuse)，这种思想来自于DenseNet[6]和CondenseNet [16] 在DenseNet[6]中，为了分析特征重用模式，绘制了层间权重的l1-norm，如图4(a)所示。很明显，相邻层之间的连接比其他层之间的连接更强。这意味着所有层之间的紧密连接可能会引入冗余。最近的CondenseNet[16]也支持这一观点.在ShuffleNet V2中，很容易证明 $i-th$和 $(i+j)-th$ 构建块之间的“直接连接”通道的数量为 $r^jc$，其中 $r = (1 -c’)/c$。换句话说，特性重用量随着两个块之间的距离呈指数衰减。在距离较远的块之间，特性重用变得非常弱。图4(b)绘制了与图(a)类似的可视化，其中r = 0.5。注意(b)中的模式类似于(a)。因此，ShuffleNet V2的结构通过设计实现了这种类型的特性重用模式。它具有与DenseNet[6]中类似的功能重用的优点，但如前所述，它的效率要高得多。 这在实验中得到验证，见表8。 Experiment本文的消融实验是在ImageNet 2012分类数据集上进行的[32,33]。按照通常的做法[15,13,14]，相比之下，所有网络都有四个级别的计算复杂度，即大约40、140、300和500+ MFLOPs。这种复杂性在移动场景中非常典型。其他超参数和协议与ShuffleNet v1[15]完全相同。本文与以下网络架构进行了比较: ShuffleNet V1 MobileNet V2 Xception Densenet表8总结了所有结果。本文从不同的角度分析这些结果。 准确性与 FLOPs很明显，本文提出的的 ShuffleNet v2 模型在很大程度上优于其他所有网络，特别是在较小的计算预算下。此外，本文注意到 MobileNet v2 在 40 MFLOPs 级别上的表现很糟糕，其图像大小为224×224。这可能是由于 channels 太少造成的。相反，本文的模型没有这个缺点，因为本文的高效设计允许使用更多的通道。此外，虽然本文的模型和DenseNet[6]都重用了特性，但是本文的模型要有效得多，如第3节所讨论的。表8还将本文的模型与其他最先进的网络进行了比较，包括 CondenseNet[16]、IGCV2[27]和IGCV3[28]。本文的模型在不同的复杂度级别上表现得更好。 Inference Speed vs. FLOPs/Accuracy对于四种精度较好的架构ShuffleNet v2、MobileNet v2、ShuffleNet v1和Xception，本文将它们的实际速度(Actual Speed)与FLOPs进行比较，如图1(c)(d)所示。附录表1提供了关于不同分辨率的更多结果。 ShuffleNet v2显然比其他三个网络更快，尤其是在GPU上。例如，500MFLOPs ShuffleNet v2比MobileNet v2快58%，比ShuffleNet v1快63%，比Xception快25%。在ARM上，ShuffleNet v1、Xception和ShuffleNet v2的速度相当;然而，MobileNet v2要慢得多，尤其是在较小的失败。本文认为这是因为MobileNet v2有更高的MAC(参见第2节中的G1和G4)，这在移动设备上非常重要。 与MobileNet v1[13]、IGCV2[27]和IGCV3[28]相比，本文有两个观察结果。首先，虽然MobileNet v1的精度不高，但是它在GPU上的速度比所有的同类产品都要快，包括ShuffleNet v2。本文认为这是因为它的结构满足大多数建议的准则(例如，对于G3, MobileNet v1的片段甚至比ShuffleNet v2更少)。其次，IGCV2和IGCV3速度较慢。这是由于使用了太多的卷积组(4或8在[27,28])。这两项意见都符合本文提出的准则。 最近，自动模型搜索[9,10,11,35,36,37]已经成为CNN结构设计的一个很有前途的趋势。表8的底部部分评估了一些自动生成的模型。本文发现它们的速度相对较慢。本文认为这主要是因为使用了太多的片段(参见G3)。尽管如此，这一研究方向仍然很有前景。例如，如果模型搜索算法与本文提出的准则相结合，并在目标平台上评估直接度量(速度)，可能会得到更好的模型。 最后，图1(a)(b)总结了精度与速度(直接度量)之间的关系。本文得出结论，ShuffeNet v2在GPU和ARM上都是最好的。 与其他方法的兼容性ShuffeNet v2可以与其他技术相结合，进一步提高性能。当使用 Squeeze-and-excitation(SE)模块[8]时，ShuffleNet v2的分类精度提高了0.5%，并且保证不会有大的速度损失。block 结构如下面的附录图2(b)所示。结果见表8(底部部分)。 对大型模型的泛化。虽然我们的消融主要用于轻重量的情况下，ShuffleNet v2可以用于大型模型(e.g, FLOPs≥2G)。表6比较了50层ShuffleNet v2(详见附录)与ShuffleNet v1[15]和ResNet-50[4]的对应版本。ShuffleNet v2仍然在2.3GFLOPs上优于ShuffleNet v1，并且以40%的更少的FLOPs超过ResNet-50。 对于非常深的ShuffleNet v2(例如超过100层)，为了使训练更快地收敛，我们通过添加一个残差路径(详见附录)来稍微修改基本的ShuffleNet v2单元。表6给出了一个包含164层的ShuffleNet v2模型，其中包含SE[8]组件(详见附录图2)。与以前的最先进的型号[8]相比，它在更少的 FLOPs 下获得了更高的精度。 目标检测为了评估目标检测的泛化能力，我们还测试了COCO目标检测[38]任务。我们使用最先进的轻型检测: Light-Head RCNN[34] 作为我们的框架，并遵循相同的 training 和 testing 策略。只替换骨干网络。模型在ImageNet上进行预处理，然后对检测任务进行细化。除了minival set中的5000张图片外，我们使用COCO中的train+val set进行训练，并使用minival set进行测试。精度指标为COCO标准mmAP，即在box IoU阈值0.5到0.95之间的平均 mAPs。 将ShuffleNet v2与其他三个轻量级模型:Xception[12,34]、ShuffleNet v1[15]和MobileNet v2[14]在四个复杂级别上进行比较。表7中的结果显示ShuffleNet v2的性能最好。 将检测结果(表7)与分类结果(表8)进行比较，有趣的是，在分类时，准确率等级为ShuffleNet v2≥MobileNet v2 &gt; ShuffeNet v1 &gt; Xception，而在检测时，准确率等级变为ShuffleNet v2 &gt; Xception≥ShuffleNet v1≥MobileNet v2。这说明，Xception在检测任务上表现良好。这可能是由于Xception构建块的感受野大于其他构建块(7 vs. 3)。受此启发，我们还通过在每个构建块的第一个点卷积之前引入额外的3×3深度卷积，来扩大ShuffleNet v2的接受域。这个变体表示为ShuffleNet v2*。在只增加少数额外的 FLOPs 情况，它可以进一步提高准确性。 我们还在GPU上测试运行时。为了公平比较，批处理大小被设置为4，以确保GPU的充分利用。由于数据复制(分辨率高达800×1200)等检测专用操作(如PSRoI池[34])的开销，不同模型之间的速度差距小于分类。尽管如此，ShuffleNet v2的性能仍然优于其他软件，例如，它比ShuffleNet v1快40%左右，比MobileNet v2快16%。 此外，变体ShuffleNet v2具有最好的精度，仍然比其他方法更快。这引发了一个实际的问题:*如何增加接受域的大小?这对于高分辨率图像[39]中的目标检测至关重要。 我们以后会研究这个话题。 Conclusion我们提出了网络架构设计应考虑速度等直接指标，而不是FLOPs等间接指标。同时还提出了实用的指导方针和一个新的架构，ShuffleNet v2。综合实验验证了该模型的有效性。我们希望这项工作能够启发未来的网络架构设计工作，使其更具有平台意识和实用性.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉-模型结构小结]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[https://ethereon.github.io/netscope/quickstart.html]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《STL源码剖析》]]></title>
    <url>%2Fz_post%2FCpp-Book-STL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[第一章 STL概论与版本简介STL 的提出是为了提高代码的复用性, 提升编程效率. STL 提供六大组件, 彼此可以组合套用: 容器(containers): 各种数据结构, 如 vector, list, deque, set, map 等 class template; 算法(algorithms): 各种常用算法如 sort, search, copy, erase 等 function template; 迭代器(iterators): 扮演容器与算法之间的胶合剂, 从实现角度看, 迭代器是一种将 operator*, operator-&gt;, operator++, operator-- 等指针相关操作予以重载的 class template; 仿函数(functors): 行为类似函数, 可作为算法的某种策略. 配接器(adapters): 一种用来修饰容器(containers), 仿函数(functors), 或者迭代器(iterators)接口的东西. 例如, STL 提供的 queue 和 stack, 虽然看似容器, 其实只能算是一种容器配接器, 因为它们的底层完全借助 deque 完成. 改变 functor 接口者, 称为 function adapter, 改变 container 接口者, 称为 container adapter, 改变 iterator 接口者, 称为 iterator adapter. 配置器(allocators): 负责空间配置与管理, 从实现角度来看, 配置是是一个实现了动态空间配置, 空间管理, 空间释放的 class template. 以上六者的关系为: Container 通过 Allocator 取得数据存储空间, Algorithm 通过 Iterator 存取 Container 内容, Functor 可以协助 Algorithm 完成不同的策略变化, Adapter 可以修饰或套接 Functor. 4.8 priority_queue4.8.1 priority_queue 概述priority_queue 首先是一个队列, 因此它允许在底端加入元素, 并从顶端取出元素, 除此之外别无其他存取元素的途径. priority_queue带有权值观念, 其内部的元素并非依照插入顺序排序, 而是按照元素的权值进行排列, 权值较高者, 排在最前面. 缺省情况下 priority_queue 利用一个 max-heap 完成, 也即 top() 元素表示的是队列中值最大的元素. 4.8.2 priority_queue 定义完整列表priority_queue 的实现在缺省情况下是以 vector 为底部容器, 再加上 heap 相关处理规则, 所以其实现非常简单, 也因此, 我们通常并不认为 priority_queue 并非是一种新的容器, 而只是把它归类为 container adapter(容器配接器). 1// priority_queue 内部完整实现 4.8.3 priority_queue 没有迭代器由于 priority_queue 只有顶端元素 (权值最高者) 才有机会被外界使用, 因此, priority_queue 不提供遍历功能, 也不提供迭代器. 4.8.4 priority_queue 测试实例1//TODO]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习框架底层实现原理-caffe2源码探究]]></title>
    <url>%2Fz_post%2FCaffe2-caffe2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>Caffe2</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MultiBox-CVPR2014]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-MultiBox-CVPR2014%2F</url>
    <content type="text"><![CDATA[文章: Scalable Object Detection using Deep Neural Networks作者: Dumitru Erhan, Christian Szegedy, Alexander Toshev, and Dragomir Anguelov 核心亮点(1) 回归问题:将物体检测问题定义为输出多个bounding box的回归问题. 同时每个bounding box会输出关于是否包含目标物体的置信度, 使得模型更加紧凑和高效 (2) 损失函数:将训练bounding box检测器作为整个网络训练过程的一部分, 也就是说在损失函数中包含了关于bounding box的损失项. 通过联合训练, 不仅利用了神经网络强大的特征表示能力, 而且将检测器的训练集成到了网络中 (3) 无类别监督训练作者将本文的目标边框检测器在无监督的样本下训练, 由于本方法主要完成的功能就是画框, 并不会输出框中包含的物体类别, 因此训练的时候无需知道样本的类别信息. 这也使得该方法的计算复杂度与类别信息几乎无关, 可以轻易的推广到未知的类别当中. (当然也可以进行相关类别的训练, 对每个类别都训练一个检测器, 模型的总参数会随着类别数线性增加) 关键技术 作者将bounding box的检测过程集成到了神经网络中, 使其转变成了一个回归问题, 通过BP算法优化下面的损失函数即可获得预测的框, 相比于SS算法, 计算复杂度更低. $x_{ij}=1$ 当且仅当第 $i$ 个预测框与第 $j$ 个真实框匹配. $l_i$ 和 $g_j$ 分别是预测框和真实框的归一化后的坐标, $c_i$ 代表置信度: F_{match}(x,l) = \frac{1}{2} \sum_{i,j} x_{ij} \|l_i - g_j\|_2^2F_{conf}(x,c) = -\sum{i,j} x_{i,j} log(c_i) - \sum_i (1 - \sum_j x_{ij}) log(1-c_i)F(x,l,c) = \alpha F_{match}(x,l) + F_{conf}(x,c)x^* = \arg \min_x F(x,l,c)\text{subject to } x_{ij} \in \{0, 1\}, \sum_i x_{ij}=1利用BP算法分别对 $l_i$ 和 $c_i$ 求导, 以便更新相关参数使其损失函数值更低. \frac{\partial F}{\partial l_i} = \sum_j (l_i - g_j) x^*_{ij}\frac{\partial F}{\partial c_i} = \frac{\sum_j x^*_{ij} c_i}{c_i(1-c_i)}论文细节背景介绍在(2014年)之前的工作中, 对于目标检测任务都是对整个图片进行检测, 无法检测出同一张图片中的多个目标物. 于是, 本文就提出了一种目标检测模型, 可以在一张图片中预测多个bounding boxes, 并且每个box都对应了包含某个类别物体的置信度. 作者使用了一个单一的DNN网络, 来生成候选区域框, 并且每个区域框都会带有一个置信度, 代表这框内包含物体的可能性大小. Model: 模型最后一层的神经元的输出值代表着每个框的坐标和对应的置信度. Bounding Box: 将左上角和右下角的坐标分别作为四个神经元的输出值. 这些坐标都是经过归一化的. Confidence: 每个Box对应的置信度会单独作为一个神经元节点输出. 在预测阶段, 可以利用该模型输出 $K$ 个bounding box预测结果, 同时可以利用NMS算法得到置信度更高的Box集合, 然后将这些集合送到分类器中进行分类. 训练目标: 假设对于一个训练样本, 具有 $M$ 个已经标注好的GT bounding box. 然后, 检测器会生成 $K$ 个预测的bounding box, $K$ 的值一般远远大于 $M$. 因此, 我们仅仅需要优化 $K$ 中与 $M$ 个GT匹配度最高的一个子集合. 优化的时候, 我们尽可能的提高这些子集合内部的预测框的置信度, 同时降低其他那些不在子集合里面的框的置信度. 对此, 形式化描述为下面的函数: F_{match}(x,l) = \frac{1}{2} \sum_{i,j} x_{ij} \|l_i - g_j\|_2^2上式中, $x_{ij}=1$ 当且仅当第 $i$ 个预测框与第 $j$ 个真实框匹配. $l_i$ 和 $g_j$ 分别是预测框和真实框的归一化后的坐标. 此外, 我们还希望对预测框的置信度进行优化, 将匹配框的置信度最大化, 这个过程转换成最小化下面的式子: F_{conf}(x,c) = -\sum{i,j} x_{i,j} log(c_i) - \sum_i (1 - \sum_j x_{ij}) log(1-c_i)从上式可以看到, $\sum_j x_{ij} = 1$ 当且仅当预测框 $i$ 可以匹配到某个真实框. 在这种情况下, $c_i$ 将王越来越大的方向优化. 上面这个式子正式交叉熵. 结合上面的两个公式, 最终的损失函数如下所示, 其中 $\alpha$ 用于调节两部分的权重: F(x,l,c) = \alpha F_{match}(x,l) + F_{conf}(x,c)优化: 对于每一个训练样本, 都希望按照如下最优化问题求得 $x^*$ (也就是最优化预测框与真实框的匹配方案) : x^* = \arg \min_x F(x,l,c)\text{subject to } x_{ij} \in \{0, 1\}, \sum_i x_{ij}=1由于标记物体的数量非常少, 所以上面公式的计算复杂度并不高. 对于上面的公式, 可以利用BP算法分别对 $l_i$ 和 $c_i$ 求导, 以便更新相关参数使其损失函数值更低. Training Details: 使用了三个小改动, 进一步提升了精度的速度]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协变(covariance)与逆变(contravariance)]]></title>
    <url>%2Fz_post%2FCpp-%E5%8D%8F%E5%8F%98%E4%B8%8E%E9%80%86%E5%8F%98%2F</url>
    <content type="text"></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SPPNet (ECCV, 2014)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SPPNet-ECCV2014%2F</url>
    <content type="text"><![CDATA[文章: Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition作者: Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun 核心亮点(1) 提出了一种新的池化方法—-空间金字塔池化SPP: 可以接受任意尺寸的输入图片,并生成固定长度的表征向量 可以进行多尺度的联合训练, 提升模型精度 这种池化方法是比较general的, 可以提升不同模型架构的性能(分类任务) (2) 将SPP用于目标检测, 并且提出了先求卷积特征图谱, 后取区域的的策略: 大大提升了模型训练和预测的速度(在预测阶段, 比RCNN快24~102倍, 同时取得了更好的精度). 注1: 在特征图谱上使用检测方法不是首次提出, 而SPP的贡献可以结合了deep CNN结构强大的特征提取能力和SPP的灵活性, 使得精度和速度同时提高注2: 相比于RCNN, SPPNet使用了EdgeBoxes( $0.2s/img$ )的方法来进行候选区域推荐, 而不是Selective Search( $1\sim 2s/img$ )注3: SPPNet在ILSVRC2014的目标检测任务上取得第二名, 在图片分类任务上取得第三名 论文细节背景介绍指明固定图片输入尺寸的缺点: 需要剪裁或wrap图片, 无法包含整个图片信息, 导致信息丢失或引起形变 破除尺寸限制的做法: 在最后一个卷积层之后, 添加SPP层, SPP层可以将不同尺寸的feature map池化成固定长度的特征向量., 之后, 仍然与普通网络一样, 后街全连接层或者其他分类器 SPP本文的核心就在于SPPNet, 其主要用法是在卷积神经网络的最后一层卷积特征图谱上, 通过多尺度的网格划分, 接受任意尺寸的特征图谱输入, 同时输出固定长度的特征向量, 以此来实现网络模型接受任意尺寸图片输入的目的. SPPNet实现原理如下图所示: 首先, 设定好固定的网格划分方法, 以便得到spatial bins, 如上图, 有三种不同spatial bins, 网格划分力度分别为 4×4, 2×2 和 1×1, 因此, spatial bins的数量为:$4\times 4+2\times 2+ 1\times 1 = 21 = M$, 图中的256代表最后一层卷积层的filter的数量, 也就是特征图谱的depth = $k$. 因此, SPP层的输出为 $kM$ 维的一维向量. 注意: 这里最粗粒度的spatial bins 是对整张特征图谱上进行pooling, 这实际上是为了获得一些全局信息.(之前也很很多work集成了这种全局pooling方法, 貌似有助于提升精度, 同时由于是全局信息, 所以相当general, 可以一定程度上起到降低过拟合的作用) SPP可以看做是Bag-of-Words(BoW)模型的一种扩展 SPP用于deep CNNs时, 具有一些瞩目的性质: 相比于sliding window pooling的方式, SPP可以生成固定尺寸的特征向量 SPP使用了多尺寸的spatial bins, 而sliding window只是用了单一的window size. 这使得SPP对于物体的形变更加鲁棒 由于输入尺寸的灵活性, SPP可以在不同尺度下提取图片特征(可以在训练时接受多尺寸土木, 降低过拟合风险) SPP使用了MutiBoxes来进行候选区域推荐. Deep Networks With Spatial Pyramid Pooling卷积层和特征图谱卷积层可以接受任意尺寸的图片, 并且可以在特征图谱上得到相应的响应. 根据BoW的思想, 在 deep convolutional features 上也可以使用(与Bow)相似的pooling方式使得输出固定长度的特征向量 Training the Network虽然上面的work可以接受任意尺度的图片输入, 但在实际训练中, GPU相关组件如caffe或者cuda-convnet还是倾向于接受固定尺寸的输入. 因此作者介绍了他们的training solution, 以便在使用GPU高计算能力的同时, 保留SPP的pooling特点. Single-size training假设最后一层卷积层的特征图谱的size为 $a\times a$. pyramid level为 $n\times n$ bins. 那么实现该pyramid pooling的方式可以看做是 $win=\lceil a / n\rceil , stride = \lfloor a/n \rfloor$ 的sliding window pooling. 对于不同级别的pyramid, 使用同样的方法, 最终将所有的bins的输出连接起来组成一个一维向量. 上面用一句话总结: 在实际实现中, 使用sliding window pooling的方式来实现spp的, 对于单一尺寸的输入, 可以提前计算好需要的windows size, 编码时直接常量定义相关pooling即可. Multi-size training对于不同的尺寸输入, 分别计算不同的windows, 然后定义相关的pooling. (需要重新定义网络的pooling参数) 为了减少训练不同size网络的间接成本, 作者会先训练一个网络, 在一个epoch完成后, 会转向训练另一个网络(两个网络共享参数, 注意pooling是没有参数的) 也就是说, 对于两个网络, spp的参数设置是根据图片的尺寸来调节的, 因为要得到固定长度的特征向量, 所以如果图片尺寸较大, 那么最后一层卷积层的特征图谱也就较大, 那么久需要比较大的sliding windows size 来实现spp. 作者为了能一次性训练不同尺寸图片, 采用了这种迭代训练的方式(反正 pooling层是没有参数的 , 只不过是定义时需要指定window size). 进行多尺度训练的目的: 为了协同不同尺度下的图片特征提取, 同时利用已有的优化技术. 注意: 以上策略仅仅在training阶段使用. SPP-Net For Image ClassificationExperiments on ImageNet 2012 Classifization训练策略: images resize 使得图片的短边长度为256, 然后对其进行224×224 crop(四角+中心). 图像增强: horizontal flipping, color altering. dropout: 用于2层全连接层 lr: 0.01, 两次衰减10分之1 Baseling Network ArchitecturesZF-5, Convnet*-5, Overfeat-5/7 Multi-level Pooling Improves Accuracy需要注意的是, 模型精度的不是因为更多参数(pooling没有参数), 但是因为考虑了这种spatial结构, 从而使得模型的精度提升. Multi-size Training Improves Accuracy顾名思义, 作者使用了多尺度的训练, 同样提升了精度 Full-image Representations Improve Accuracy作者将Full-Image和crop(224×224, center)的策略进行了实验比较, 发现未经裁剪的Full-Image的精度更高, 说明维持原始图片的完整输入是很有必要的. 作者发现, 即使使用了很多视角下的crop结果进行投票, 额外的增加两个full-image(with flipping) 仍然可以提升模型 0.2%的精度 Multi-view Testing on Feature Maps受到目标检测算法的启发, 作者发现整合在feature maps上面进行不同视角的预测, 会使得模型精度有所提高. 实验结果证明, 在features maps上面进行10-view投票相比于直接在原始图上面进行10-view投票, 精度提高了0.1% (top-5 error) 作者使用了是不同image size, 结合了不同的view(18种, center+四角+四边中心+filp,), 总共有96种view(18*5 + 6(图片size只有224的时候)). 将top-5 error 从10.95% 降到 9.36%, 再结合two full image view, 降到了9.14%. Overfeat 也是从feature map中获取不同views的, 但它不能处理多尺度的图片 Experiments on VOC 2007 ClassificationExperiments on Caltech101SPP-Net For Object DetectionRCNN: 先从原始图像中选出大约2000个框, 然后将这些图像区域缩放到227×227大小, 然后对每个区域进行卷积分类, 使用了SVM分类器. 特征提取存在大量重复计算, 占用了绝大部分的时间 改进: 从feature maps提取对应框,只进行一次卷积计算: 之前的DPM在HOG特征图谱上选框, SS在SIFT特征图谱上选框, Overfeat在深度卷积特征图谱上选框, 但是Overfeat必须固定图片尺寸. 相比之前的这些方法, SPP具有在深度卷积特征图谱上的灵活性, 可以接受任意尺寸的输入, Detection Algorithm使用 “fast” mode的SS来生成2000个候选区域框, 然后将image 进行resize ,使其 min(w,h) = s. 接着对整张图片计算卷积特征图谱. 然后在特征图谱上选框, 接着对这些框进行spp, 最后使用svm进行分类. 使用了strandard hard negative mining来训练svm. Detection ResultsComplexity and Running Time改用了MultiBox算法, 处理每张图片只需要0.2左右, 原来的SS算法大约需要1~2s才可以. Model Combination for Detection在ImageNet上训练另一个模型, 使用相同的网络结构, 但是随机初始化状态不同. 如此得到两个模型, 他们的性能表现差不多. 首先分别用这两个模型给所有的测试样例的候选框进行打分, 然后利用NMS消除这些候选框(包含两个模型的预测结果)中的重复框, 这样一来, 就会保留下置信度更高的框. mAP从 59.1%, 59.2% 提升到了 60.9% ILSVRC 2014 DetectionConclusionAppendix AMean SubtractionImplementatioin of Pooling BinsMapping a Window to Featrue Maps]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python面试总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-Python%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[https://github.com/L1nwatch/interview_collect/tree/master/Python%20%E8%AF%AD%E8%A8%80%E7%89%B9%E6%80%A7 Python有哪些特点和优点 可解释 动态特性 面向对象 简明简单 python中, 对于基本类型, 每次的=赋值都会生成新的地址:1234567a = 1print(id(a))# 4490543616a = 2print(id(a))# 4490543648 深拷贝和浅拷贝的区别深拷贝是完全的拷贝, 当对一个对象的深拷贝做出改变时, 不会影响原对象的状态, 使用b = copy.deepcopy(a) 来完成深拷贝 浅拷贝是将一个对象的引用拷贝到另一个对象上, 如果在拷贝中进行改动, 则会影响到原对象的状态, 使用b = copy.copy(a) 完成浅拷贝 python中对象的赋值操作都是进行对象引用的传递(也就是浅拷贝的形态) 对于非容器类型(如数字, 字符串, 和其他原子类型的对象), 没有拷贝一说(除非使用=运算符, 否则经过拷贝的对象中的非容器类型, 与原对象的元素都是相对独立的,不会互相影响) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import copyorigin = ["will", 28, ["python", "C++"]]op_equal = origincp_shallow = copy.copy(origin)cp_deep = copy.deepcopy(origin)print("origin:")print(id(origin))print(origin)print([id(item) for item in origin])print()origin[0] = "new_will"origin[1] = 30origin[2].append("Caffe2")print("changed origin:")print(id(origin))print(origin)print([id(item) for item in origin])print()print("op_equal:")print(id(op_equal))print(op_equal)print([id(item) for item in op_equal])print()print("cp_shallow:")print(id(cp_shallow))print(cp_shallow)print([id(item) for item in cp_shallow])print()print("cp_deep")print(id(cp_deep))print(cp_deep)print([id(item) for item in cp_deep])print()origin:4339513864['will', 28, ['python', 'C++']][4334051088, 4330878304, 4339513928]changed origin:4339513864['new_will', 30, ['python', 'C++', 'Caffe2']][4339502384, 4330878368, 4339513928]# str和int在修改时会被赋予新的地址空间, 同时替换对应的旧元素op_equal:4339513864['new_will', 30, ['python', 'C++', 'Caffe2']][4339502384, 4330878368, 4339513928]# =赋值, 会将所有元素及对象的地址传递, 不会生成新的变量及对象, 与原对象完全关联cp_shallow:4339513736['will', 28, ['python', 'C++', 'Caffe2']][4334051088, 4330878304, 4339513928]#浅拷贝会生成一个新对象, 但是, 对于对象内的元素, 浅拷贝只会使用原始元素的引用# 对于非容器类型, 没有拷贝深浅之分, 因为原对象改变后, 其会指向一个新的地址, 而浅拷贝的地址不受影响, 所以二者是独立的# 但如果是可变类型, 则不会生成新的地址, 这会的话原对象的改变会对浅拷贝对象造成影响cp_deep4339513672['will', 28, ['python', 'C++']][4334051088, 4330878304, 4339513608]# 深拷贝, 与原对象完全独立, 没有任何关系 列表和元组之间的区别是:二者的区别主要是列表是可变的, 而元组是不可变的 Python 三元运算子1[on true] if [expression] else [on false] Python的继承单继承: 一个类继承自单个基类多继承: 一个类继承自多个基类多级继承: 一个类继承自单个继承, 后者则继承自另一个基类分层继承: 多个类继承自单个基类混合继承: 两种或多种类型继承的混合 Python中是如何管理内存的?Python有一个四有堆空间来保存所有的对象和数据结构, 作为开发者, 无法对其进行访问, 是由解释器在管理它, 但是有了核心API之后, 可以访问一些工具, Python内存管理器控制内存分配.]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe2 手册]]></title>
    <url>%2Fz_post%2FCaffe2-%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[corefrom caffe2.python import core : OperatorsCaffe2中的Operators有点像函数, 从C++的角度来说, 它们都是从一个通用接口派生而来的, 并且通过类型注册(什么意思?), 因此我们可以在runtime下调用不同的operators. 关于operators的接口定义在 caffe2/proto/caffe2.proto 中. 通常情况下, 它会接受一大批输入, 同时会返回一大批输出. 记住, 当我们说在 Caffe2 Python 中创建一个operator时, 还没有任何东西开始运行. 这仅仅是创建了一个protocal buffer(协议缓冲区), 用于指定具体的operator, 在稍后的一段时间内, 它将会被送入到C++后台去执行.(protobuf仅仅是一个针对结构化数据的json-like的序列化工具). Relu下面的代码创建了一个operator:123456789101112op = core.CreateOperator( "Relu", # 我希望运行的operator的类型 ["X"], # 一个列表, 里面存放的是输入的blobs的名字 ["Y"] # 仍然是一个列表, 里面存放的是输出的blobs的名字)print(type(op)) # &lt;class 'caffe2.proto.caffe2_pb2.OperatorDef'&gt;print(op)# input: "X"# output: "Y"# name: ""# type: "Relu" 接下来, 尝试使用operator, 首先将输入blobs添加到workspace中, 然后使用最简单的运行operator的方法, 即调用workspace.RunOperatorOnce(operator):12workspace.FeedBlob("X", np.random.randn(2,3).astype(np.float32))workspace.RunOperatorOnce(op) # 指定需要运行的operator变量 执行了RunOperatorOnce以后, workspace中会多出一个名字为name=&quot;Y&quot;的blobs, 用FetchBlobs()获取该blobs以后, 可以看到Y的值实际上就是对X执行Relu函数以后的结果(对应位置大于0的元素保留, 其他位置归0). 注意, 只有在执行了RunOperatorOnce以后, 名字为Y的blobs才会存在于workspace中, 此时使用FetchBlobs()才能够获取到对应值, 否则, Y是不存在的 CreateOperatoroperators同时也可以接受一些可选参数, 这些参数可以通过键值的方式来指定:12345678op = core.CreateOperator( "GaussianFill", [], # 填充时不需要输入任何数据 ["Z"], # 指定输出的名字 shape=[100,100], # 指定shape, 这里是一个100×100的二维列表 mean=1.0, # 指定平均值 std=1.0 # 指定标准差) NetsNets本质上就是计算图. 一个Net由多个operators组成, 当我们谈到Nets的时候, 我们同时也会谈到 BlobReference, 这是一个对象, 通过它我们可以轻易的将各种operators连接起来. 在创建网络时, 暗示着protocal buffer除了name以外其余都是空的123my_net = core.Net("my_first_net") # 重复调用时, 会不断创建net, 每次都会在后面加上一个后缀以区别不同的net, 如my_first_net, my_first_net_1, my_first_net_2等等print(my_net.Proto()) # name: "my_first_net"print(type(my_net)) # &lt;class 'caffe2.python.core.Net'&gt; 接下来, 向net中创建一些blobs1X = my_net.GaussianFill([], ["X"], mean=0.0, shape=[2,3], std=1.0, run_once=0) 此时, my_net中就创建了一个operator, 其类型为”GaussianFill”. 在这里, 对象X的类型为: &lt;class &#39;caffe2.python.core.BlobReference&#39;&gt;, 它会记录两个值, 一个是blob的名字, 另一个记录该对象是从哪个net中来的(_from_net). 上面没有使用core, 而是直接利用my_net进行operator的创建, 同样也可以使用core中的CreateOperator来创建operator, 并将其添加到对应的net中, 如下所示:12op = core.CreateOperator("op_name", ... )net.Proto().op.append(op) 继续创建W和b:12W = net.GaussianFill([], ["W"], mean=0.0, std=1.0, shape=[5,3], run_once=0)b = net.ConstantFill([], ["b"], shape=[5,], value=1.0, run_once=0) 下面利用了一个简单的语法糖, 由于BlobReference对象知道自己是从哪个net中来的, 因此, 可以直接利用BlobReference对象来创建operators, 下面显示了如何创建FC operator:1Y = X.FC([W,b], ["Y"]) 如果利用net创建则是下面的形式:1Y = my_net.FC([X,W,b], ["Y"]) 此时, 如果利用my_net.Proto()来查看net信息的话, 由于参数变多, 难以观察, 因此 Caffe2 提供了一个精简的minimal graph视图来帮助观察net:1234from caffe2.python import net_drawerfrom IPython import displaygraph = net_drawer.GetPydotGraph(net, rankdir="LR")display.Image(graph.create_pgn(), width=800) 通过上面的代码, 我们创建一个Net, 但是还没有任何东西被运行, 当我们运行network的时候, 会发生下面两件事情: 一个C++的net对象会从protobuf中实例化 实例化的网络的Run()函数会被调用 再做其他事情之前, 我们需要先用ResetWorkspace()清空早前的workspace, 然后有两种方式可以用来run net, 首先看看第一种:123456workspace.ResetWorkspace()print(workspace.Blobs()) # [] 可以看到, 列表为空, 因为X,Y,W,b均是operatorsworkspace.RunNetOnce(net) # 只执行一次, 无需调用CreateNetprint(workspace.Blobs()) # ['W','X','Y','b'], 在执行了RunNetOnce以后, workspace内被添加了有关operators的blobs.for name in workspace.Blobs(): print(name, workspace.FetchBlobs(name)) 下面是第二种创建并执行net的方式, 首先, 清空workspace里面的blobs, 然后创建net对象, 最后, 执行net1234567workspace.ResetWorkspace()print(workspace.Blobs()) #[] 之前的blobs又被清空了workspace.CreateNet(net) # 先创建networkspace.RunNet(net.Proto().name) # 执行net, 传入net.Proto().name参数print(workspace.Blobs()) # ['W','X','Y','b']for name in workspace.Blobs(): print(name, workspace.FetchBlob(name)) RunNetOnce 和 RunNet 之间有一点小区别, 最重要的区别就是计算开销的不同. 因为RunNetOnce包含了序列化protobuf, 同时还要将其在Python和C中传递, 并对network进行初始化, 因此它需要更长的执行时间. net.FC()1model.net.FC() net.Softmax()net.SoftmaxWithLoss()参数:logits: Unscaled log probabilitieslabels:weight_tensor: 返回值:softmax: Tensor with softmax cross entropy loss (也可以认为是概率)loss: Average loss 示例:1model.net.SoftmaxWithLoss() net.LabelCrossEntropy()示例:1xent = model.LabelCrossEntropy([softmax, label], 'xent') net.AveragedLoss(xent, “loss”)示例:1loss = model.AveragedLoss(xent, "loss") net.Cast()示例:1data = model.net.Cast(data_uint8, "data", to=core.DataType.FLOAT) net.Scale()示例:12# 将 data 从 [0, 255] 放缩到 [0,1]data = model.Scale(data, data, scale=float(1./256)) net.StopGradient()示例:12# 避免计算数据的梯度data = model.StopGradient(data, data) net.Checkpoint()workspacefrom caffe2.python import workspace 12import cv2 # NOQA(Must import before importing caffe2 due to bug in cv2)from caffe2.python import workspace GlobalInit()123workspace.GlobalInit( ['caffe2', '--caffe2_log_level=0', '--caffe2_gpu_memory_tracking=1']) 初始化caffe2的全局环境, 如果希望看到更加详细的初始化信息, 可以将--caffe2_log_level设置为1. 当初始化成功时, 返回 True, 否则, 返回 False. caffe2的工作空间由你创建的blobs组成, 并且将其存储在内存当中. 将blob当做是numpy中的一个N维数组, 可以从Basics.ipynb中看出, blob实际上是一个指针, 它指向可以存储任意类型的一个C++对象, 但是最常存储的类型仍然是 Tensor 类型. Blobs()workspace.Blobs()方法可以打印出workspace中的所有存在的blobs (只会显示出blobs的名称). HasBlob()workspace.HasBlob(&quot;blob_name&quot;)用于查询workspace中是否存在名为blob_name的blob, 返回一个布尔值 workspace.FeedBlob()用于向workspace中添加blobs1234X = np.random.randn(2,3).astype(np.float32)print("Generated X from numpy:\n&#123;&#125;".format(X))workspace.FeedBlob("X", X) # 若添加成功, 则返回True, 否则, 返回False# 如果调用该函数时, 名字已经在workspace中存在, 则后添加的值会覆盖之前添加的值 workspace.FetchBlob(&quot;X&quot;)用来获取对应名字的blob的值, 如果获取的名字不在workspace中, 那么就会抛出错误, 我们可以用利用try except语句来输出错误信息:1234try: workspace.FetchBlob("not_exists_name")except RuntimeError as err: print(err) # Can't find blob:... workspace.ResetWorkspace()说明:重置工作空间, 如果root_folder为空, 则会保持当前的目录设置. 参数:root_folder(str): 路径 返回:无 定义: 备注:返回 workspace.SwitchWorkspace()同时, 你可以拥有多个不同的workspaces, 每一个workspace都有不同的名字, 你可以调用workspace.SwitchWorkspace(&quot;name&quot;)来在这些不同的名字之间交换. 不同workspace中的blobs是相互独立的, 你可以使用workspace.CurrentWorkspace来查询当前所有的workspace:123456# Switch the workspace. The second argument "True" means creating# the workspace if it is not existsworkpsace.SwitchWorkspace("new_workspace_name", True) # 如果名为"new_workspace_name"的workspace存在, 则切换当前workspace到该workspace, 如果不存在, 那么就创建它.print("Current workspace:&#123;&#125;".format(workspace.CurrentWorkspace())) # 默认的workspace的名称为: defaultprint("Current blobs in the workspace:&#123;&#125;".format(workspace.Blobs())) 利用workspace.ResetWorkspace()可以清空当前workspace中的所有东西, 谨慎使用1workspace.ResetWorkspace() ModelHelper源码: model_helper.py 12from caffe2.python import model_helpermodel = model_helper.ModelHelper(...) param_init()XavierFill()12m = model_helper.ModelHelper(name="my model")weight = m.param_init_net.XavierFill([], "fc_w", shape=[10, 100]) ConstantFill()1bias = m.param_init_net.ConstantFill([], "fc_b", shape=[10, ]) netnet.Accuracy()net.FC()1fc_1 = m.net.FC(["data", "fc_w", "fc_b"], "fc1") # "data", "fc_w", "fc_b" 都是workspace中的blobs net.Sigmoid()1pred = m.net.Sigmoid(fc_1, "pred") net.SoftmaxWithLoss()1softmax, loss = m.net.SoftmaxWithLoss([pred, "label"], ["softmax", "loss"]) brew源码: brew.py, caffe2/python/helpers/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from caffe2.python.helpers.algebra import *from caffe2.python.helpers.arg_scope import *from caffe2.python.helpers.array_helpers import *from caffe2.python.helpers.control_ops import *from caffe2.python.helpers.conv import *from caffe2.python.helpers.db_input import *from caffe2.python.helpers.dropout import *from caffe2.python.helpers.elementwise_linear import *from caffe2.python.helpers.fc import *from caffe2.python.helpers.nonlinearity import *from caffe2.python.helpers.normalization import *from caffe2.python.helpers.pooling import *from caffe2.python.helpers.tools import *from caffe2.python.helpers.train import * class HelperWrapper(object): _registry = &#123; 'arg_scope': arg_scope, 'fc': fc, 'packed_fc': packed_fc, 'fc_decomp': fc_decomp, 'fc_sparse': fc_sparse, 'fc_prune': fc_prune, 'dropout': dropout, 'max_pool': max_pool, 'average_pool': average_pool, 'max_pool_with_index' : max_pool_with_index, 'lrn': lrn, 'softmax': softmax, 'instance_norm': instance_norm, 'spatial_bn': spatial_bn, 'relu': relu, 'prelu': prelu, 'tanh': tanh, 'concat': concat, 'depth_concat': depth_concat, 'sum': sum, 'transpose': transpose, 'iter': iter, 'accuracy': accuracy, 'conv': conv, 'conv_nd': conv_nd, 'conv_transpose': conv_transpose, 'group_conv': group_conv, 'group_conv_deprecated': group_conv_deprecated, 'image_input': image_input, 'video_input': video_input, 'add_weight_decay': add_weight_decay, 'elementwise_linear': elementwise_linear, 'layer_norm': layer_norm, 'batch_mat_mul' : batch_mat_mul, 'cond' : cond, 'loop' : loop, 'db_input' : db_input, &#125; # ... 示例: 123456from caffe2.python import brewdef AddLeNetModel(model, data): conv1 = brew.conv(model, data, 'conv1', 1, 20, 5) pool1 = brew.max_pool(model, conv1, 'pool1', kernel=2, stride=2) # ... brew.conv()参数:model:blobs_in:blobs_out:dim_in:dim_out:kernel:stride:pad: 返回值:blobs_out 的引用 示例:1234conv1 = brew.conv( model, data, 'conv1', dim_in=image_channels, dim_out=32, kernel=5, stride=1, pad=2) brew.max_pool()参数:model:blobs_in:blobs_out:kernel:stride: 返回值:blobs_out 的引用 池化层:1pool1 = brew.max_pool(model, conv1, "pool1", kernel=2, stride=2) brew.average_pool()示例:1pool2 = brew.average_pool(model, relu2, "pool2", kernel=3, stride=2) brew.relu()示例:1relu1 = brew.relu(model, pool1, "relu1") brew.accuracy()参数:model: 模型对象blob_in: 输入的blobblob_out: 输出的blob**kwargs:kwargs[&#39;device_option&#39;]:kwargs[&#39;top_k&#39;]:kwargs[&#39;accuracy&#39;]: 返回值:model.net.Accuracy(...,blob_out,...) 源码: caffe2/python/helpers/train.py123456789101112# brew.py# rows 55class HelperWrapper(object): _registry = &#123; 'accuracy': accuracy &#125;# caffe2/python/helpers/train.py# rows 37def accuracy(model, blob_in, blob_out, **kwargs): # ... model.net.Accuracy(...) 示例:1234# blobs_in 为 [softmax, label]# blobs_out 为 "accuracy"def AddAccuracy(model, softmax, label): accuracy = brew.accuracy(model, [softmax, label], "accuracy") brew.fc()参数:modelblob_inblob_outdim_indim_outweight_init=Nonebias_init=NoneWeightInitializer=NoneBiasInitializer=Noneenable_tensor_core=Falsefloat16_compute=False**kwargs 返回值:_: blob_out 的引用 源码: caffe2/python/helpers/fc.py12345678910111213141516171819202122# brew.py# rows 34from caffe2.python.helpers.fc import *class HelperWrapper(object): _registry=&#123; 'fc':fc &#125;# caffe2/python/helpers/fc.py# rows 57def fc(model, *args, **kwargs): return _FC_or_packed_FC(model, model.net.FC, *args, **kwargs)# rows 13def _FC_or_packed_FC( model, op_call, blob_in, blob_out, dim_in, dim_out, weight_init=None, bias_init=None, WeightInitializer=None, BiasInitializer=None, enable_tensor_core=False, float16_compute=False, **kwargs): # ... return op_call([blob_in, weight, bias], blob_out, **kwargs) brew.softmax()参数:modelblob_inblob_out=Noneuse_cudnn=False**kwargs:kwargs[&#39;engine&#39;]: &#39;CUDNN&#39; 返回值: 源码: caffe2/python/helpers/normalization.py 12345678910111213141516# brew.py# rows 44_registry=&#123; 'softmax':softmax&#125;# caffe2/python/helpers/normalization.py# rows 37def softmax(model, blob_in, blob_out=None, use_cudnn=False, **kwargs): if use_cudnn: kwargs['engine'] = 'CUDNN' if blob_out is not None: return model.net.Softmax(blob_in, blob_out, **kwargs) else: return model.net.Softmax(blob_in, **kwargs) brew.db_input()数据集输入层处理函数 参数:model(ModelHelper):blobs_out:batch_size(int): eg: 64db(str): 数据文件夹的路径, eg: /home/zerozone/caffe2_notebooks/tutorial_data/cifar10/training_lmdbdb_type(str): eg: &#39;lmdb&#39; 返回值: 源码: caffe2/python/helpers/db_input.py12345678910def db_input(model, blobs_out, batch_size, db, db_type): dbreader_name = "dbreader_" + db dbreader = model.param_init_net.CreateDB( [], dbreader_name, db=db, db_type=db_type, ) return model.net.TensorProtosDBInput( dbreader, blobs_out, batch_size=batch_size) 示例:1234567data_uint8, label = brew.db_input( model, # ModelHelper 实例 blobs_out=["data_uint8", "label"], batch_size=batch_size, db=db, db_type=db_type,) optimizer1from caffe2.python import optimizer 源码: caffe2/python/optimizer.py optimizer.build_sgd()参数:model:base_learning_rate(float):max_gradient_norm=None:allow_lr_injection=False:**kwargs:kwargs[&#39;policy&#39;](str): eg &quot;fixed&quot;kwargs[&#39;momentum&#39;](float): eg 0.9kwargs[&#39;weight_decay&#39;](float): eg 0.004 返回值:优化器实例 源码: 1234567891011# caffe2/python/optimizer.py# rows 1410def build_sgd( model, base_learning_rate, max_gradient_norm=None, allow_lr_injection=False, **kwargs): sgd_optimizer = SgdOptimizer(base_learning_rate, **kwargs) return _build(...) CNNModelHelper源码: cnn.py 123from caffe2.python import cnnm = cnn.CNNModelHelper(name="my cnn helper") CNNModelHelper.FC()1234# cnn.py# rows 133def FC(self, *args, **kwargs): return brew.fc(self, *args, **kwargs) CNNModelHelper.Softmax()1234# cnn.py# rows 158def Softmax(self, *args, **kwargs): return brew.softmax(self, *args, use_cudnn=self.use_cudnn, **kwargs) caffe2_pb21from caffe2.proto import caffe2_pb2 源码: caffe2.proto caffe2_pb2.NetDef()示例:12345678# 这里的 init_net_proto 也可以替换成 predict_net_proto# 相应的应该将 .param_init_net 替换成 .netinit_net_proto = caffe2_pb2.NetDef()with open(init_net_path, "rb") as f: init_net_proto.ParseFromString(f.read())test_model.param_init_net = test_model.param_init_net.AppendNet( core.Net(init_net_proto)) caffe2_pb2.TensorProtos()定义:12345// caffe2/proto/caffe2.proto// rows 134message TensorProtos&#123; repeated TensorProto protos = 1;&#125; 备注:123tensor_protos = caffe2_pb2.TensorProtos()img_tensor = tensor_protos.protos.add() caffe2_pb2.TensorProto()TensorProto.dims定义:123// caffe2/proto/caffe2.proto// rows 44repeated int64 dims = 1; 备注:12345print(type(img_tensor.dims))# &lt;class 'google.protobuf.pyext._message.RepeatedScalarContainer'&gt;img_tensor.dims.extend((32,32,3))print(img_tensor.dims) # [32, 32,3] TensorProto.data_type定义:12345678910111213141516171819202122// caffe2/proto/caffe2.proto// rows 47 enum DataType &#123; UNDEFINED = 0; // Basic types FLOAT = 1; // float INT32 = 2; // int BYTE = 3; // byte, when deserialized, is going to be restored as uint8 STRING = 4; // string // Less-commonly used data types BOOL = 5; // bool UINT8 = 6; // uint8_t INT8 = 7; // int8_t UINT16 = 8; // uint16_t INT16 = 9; // int16_t INT64 = 10; // int64_t FLOAT16 = 12; // at::Half DOUBLE = 13; // double &#125; optional DataType data_type = 2 [default = FLOAT]; 备注:12345print(type(img_tensor.data_type))# &lt;class 'int'&gt;img_tensor.data_type = 1 # 默认值为2print(img_tensor.data_type)# 1 TensorProto.float_data定义:123// caffe2/proto/caffe2.proto// rows 85repeated float float_data = 3 [packed = true]; 备注:1img_tensor.float_data.extend(flatten_img) # flatten_img 是 3072 长的一维向量(32×32×3) TensorProto.int32_data定义:123// caffe2/proto/caffe2.proto// rows 89repeated int32 int32_data = 4 [packed = true]; 备注:1label_tensor.int32_data.append(5) Caffe2 模型结果可视化下面的网站可以对 .Prototxt 格式的文件或者代码可视化显示 http://ethereon.github.io/netscope/quickstart.html http://ethereon.github.io/netscope/#/editor mobile_exportermobile_exporter.Export()]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>Caffe2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OverFeat (ICLR, 2014)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-OverFeat-ICLR2014%2F</url>
    <content type="text"><![CDATA[文章: OverFeat: Integrated Recognition, Localization and Detectin using Convolutional Networks 作者: 核心亮点Multi-Scale Classification:在分类任务上, 虽然训练时采用和AlexNet相同的multi crop方法, 但是在预测阶段没有使用AlexNet的crop投票策略, 而是提出了Multi-Scale Classification方法, 一句话概括就是 对整个图片以不同的尺寸, 并且对每一个location进行模型预测 利用了全卷积的思想代替全连接, 降低了滑动窗口的计算代价 可以用同一个模型完成分类, 定位, 检测任务:同一个模型, 只需要用回归层替换分类层, 即可完成目标定位任务, 同时利用了贪心策略来融合最终的定位结果 论文细节背景介绍提出了一种新的深度学习方法, 通过预测物体的边界来对目标物体进行定位. 本文的模型是ILSVRC2013的冠军 从表现最好的模型中开源了特征提取器, 并取名为OverFeat 作者为了避免大量的时间消耗, 没有在背景样例中训练, 但同时声称效果也不错?(持怀疑态度) 物体画框的时候, 因为画到了物体的一部分, 而没有画到整个物体, 更别说将框画到物体的正中心了. 因此, 希望可以对框进行预测回归, 使之画出来的框更加准确 与Krizhevsky等人之前的图像分类的paper做了个简单的比较 2. 视觉任务本文研究了三种计算机视觉任务, 分别为: 分类, 定位和检测 3. 分类本文的分类体系架构与Krizhevsky在12年使用的体系结构类似, 但是对模型中的一些细节进行了更多的探索 3.1 模型设计和训练训练数据集: ImageNet 2012 (1.2 million 张图片, 共1000类) 输入尺寸: 训练阶段先将所有的图片downsample, 使其最小尺寸为256, 然后从每张图片(包括反转图片)中裁剪出5张子图(加上反转共10张), 尺寸为221*221, 这与AlexNet的策略相同, 但是在预测阶段, 使用了不同Multi-Scale Classificatioin方法, 具体见下文. mini-batch: 128 模型权重初始化: 随机初始化 $(\mu, \sigma) = (0, 1\times 10^{-2})$ momentmu项为: 0.6 L2 权重衰减系数: $1\times 10^{-5}$ 学习率: $5\times 10^{-2}$, 每经过(30,50,60,70,80)epochs时, 衰减1/2. Dropout: 0.5(用于6,7层的全连接) 模型结果细节图: 3.2 Feature Extractor根据本文的方法, 开源了一个名为”OverFeat”的Feature Extractor, 有两个版本, 分别是精度优先和速度优先. 模型结构以及他们之间的比较都在上面两张图中显示. 3.3 Multi-Scale Classificaion在测试阶段, 之前的Alex-Net中, 使用了multi-view投票来提升性能(一张图片crop出10个子图, 分别为四角和中心,以及他们的反转图片). 但是这个方法有一些问题: 忽视了图片中的很多区域, 并且计算存在冗余重复, 同时, 生成子图的操作都是在同一尺度上进行的, 这有时候不是最佳的尺度选择策略. 与此相反, 本文提出对整个图片以不同的尺寸, 并且对每一个location进行模型预测 , 虽然这种滑动窗口的方法在计算上是不可取的, 但是, 结合下面的3.5节中的策略, 可以缓解计算复杂问题. 上面方法的好处: 可以对同一张图片生成更多不同角度下的预测结果, 并将结果用于投票, 使得最终结果更鲁棒. 但是存在问题: 上面提到的subsampling方法的比例为 2×3×2×3, 也就是36. 这样一来, 模型在只能依赖36个像素点来生成分类向量. 这样粗粒度的分布使得模型的性能表现低于10-view方法. 主要原因是因为网络窗口没有和图片中的物体边界对齐. 于是本文提出了一种方法来克服这个问题, 对最后一个subsampling在不同的offset上进行pooling, 这样做可以缓解这一层的loss of resolution问题, 生成的总的subsampling比例为12, 而不是36. //TODO 这一段啥意思?, 36怎么来的, 12怎么来 下来解释具体是如何进行resolution augmentation的, 本文对于同一张图片, 使用了6种不同的尺寸, 如下图所示(C为类别): 具体过程如下: 对于一个给定的scale的图片, 我们从第5层, 还未pooling的特征图谱开始 对于每一个未经过pooling的特征图谱, 进行 3×3 的pooling操作(非重叠池化), 重复 3×3 次($\Delta x, \Delta y)$ 以不同的offset {0,1,2}). 这样可以得到 3×3 个pooling后的特征图谱. 分类器(6,7,8层)具有一个 5×5 的固定的输入大小, 同时对于每一个location的土整图谱都会生成 C 维的输出向量 根据不同的offset, 可以得到不同的结果 下面的图以一维向量为例讲解了offset pooling的原理, 可以类推到3维结构中 上面的操作可以看做是以一个像素为单位, 在特征图谱上进行了位移操作, 进而得到了不同角度下的图谱结果用于分类, 与之前的crop方法相比, 这个方法没有对图片进行裁剪, 但同时又达到了获取同一张图片不同视角结果的目的. 这样做最大的优点在于: 对于一张图片, 可以宏观的将网络分成两个部分, 分别是特征提取层和分类层, 在特征提取部分, 同一张图片只会进行一次前向计算, 在这计算角度来说, 大大提高了计算效率, 减少了荣冗余计算. 这种极致的pooling策略(exhaustive pooling scheme) 确保了我们可以在分类器和特征图的对象之间获得准确的边界对齐. 3.4 结果实验结果如下表所示: 分类错误率在18个队伍中的排名为第5 (主要本篇文章的两点也不在分类, 还是在目标检测上) 3.5 convNets和滑动窗口效率 首先, 要知道全卷积与全连接层之间的关系, 利用全卷积层代替全连接层以后, 可以接受不同图片尺寸的输入, 同时, 在计算时, 由于卷积操作本身的计算共享特性, 可以使得计算过程更加高效, 以此来缓解滑动窗口方法带来的计算问题. // TODO 这块还是不是很懂 4. 定位 Localization用回归网络代替分类网络, 同时训练网络使其在每一个空间location和scale下预测目标物体的bounding boxes. 然后将回归预测结果与每个位置的分类结果结合在一起. 4.1 生成预测由于可以共享特征提取层的计算结果, 因此只需要重新计算最终的回归层即可. 因为每个位置的分类结果为所有的类别都赋予了一个置信度, 因此, 我们可以将这个置信度作为bounding box的置信度使用. 4.2 回归训练 Regressor Training回归网络将第5层的池化后的特征图谱作为输入. 后面接入两个全连接层, 隐藏神经元个数分别为4096和1024. 最终的输出层具有4个神经元, 用于指定bounding box的坐标. 和分类网络一样, 也是用了基于offset的pooling策略. 该网络的结构如下图所示 训练时, 固定前5层的特征提取层, 然后使用每个样本的真实边界与预测边界之间的L2损失(平方损失)来训练回归网络. 最后的这个回归层根据与特定类相关的, 每一个类都会有一个回归层(也就是说有1000个不同的回归层版本). 当输入图片与目标物体的IOU小于50%时, 则不会进行训练 同时使用了多尺度的输入进行训练(与第三节相同), 以便更好的进行不同尺度下的预测. 4.3 联合预测通过对回归得到的bounding boxes使用贪心融合策略, 来得到单个目标物的预测结果. 具体算法过程如下: 1.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ string 完整笔记]]></title>
    <url>%2Fz_post%2FCpp-string%2F</url>
    <content type="text"><![CDATA[在 C++ 中, 用于处理字符串的类 string 虽然有用很多和 STL 相似的性质和用法, 但是一般来说, 我们不认为它是 STL 的一份子, 因为实际上, string 并不是模板, 它其实是某个模板的实例, 即 basic_string&lt;char&gt;. 因此, 这里我们单独讨论关于 string 类的一系列方法和属性, 但是需要知道, string 类在很多地方都与模板的函数或者属性很相似. 成员函数元素访问at() 返回char类型的字符 [] 返回char类型的字符 操作push_back: 将字符添加到字符串结尾 pop_back: 移除末尾字符 类型转换单个字符 char 转换到 string单个字符无法直接转换成 string:可以通过以下两种方式间接转换: 字符数组 12char c = 'c'char s1[2] = &#123;c, '\0'&#125; 新建 string 对象 123char c = 'c';std::string str = "a";str[0] = c; string 转换到其他类型12345678910#include &lt;string&gt;// 别忘了加 std::stod()stof()stoi()stol()stold()stoll()stoul()stoull char 转换到其他类型12345// 这些函数不在 stirng 头文件中, 是 C 自身有的函数, 不需要加 std::atof()atoi()atol()atoll() 其他类型转换到 string123#include &lt;string&gt;std::to_string()std::to_wstring() 最简单的将int转换成string的方法方法一：C风格的itoa123int a = 10;char* intStr = itoa(a);string str = string(intStr); 方法二：1234int a = 10;stringstream ss;ss &lt;&lt; a;string str = ss.str(); 方法三：C++风格的std::to_string1234#include &lt;string&gt;std::string s = std::to_string(42);auto s = std::to_string(42); 字符串流典型应用: 二叉树的序列化和反序列化 stringstream控制流的输入输出操作 istringstream控制流的输入 ostringstream控制流的输出 不确定数目的整数输入持续输入, 自动忽略输入中的空白符(空格, 回车, 制表符), 下面的程序当遇到 99 时终止输入12std::vector&lt;int&gt; vec;for (int a; std::cin &gt;&gt; a and a != 99; vec.emplace_back(a)); 仅仅输入一行, 自动忽略输入中的空白符, 注意, 如果输入中存在其他字符, 例如分号, 逗号等, 那么 istringstream 的输出会在其他字符之前停止12345678#include &lt;string&gt;#include &lt;sstream&gt;std::vector&lt;double&gt; vec;string line;std::getline(std::cin, line);std::istringstream iss(line);for (double v; iss &gt; v; vec.emplace_back(v));]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MicroSoft COCO数据集]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E6%95%B0%E6%8D%AE%E9%9B%86-COCO%2F</url>
    <content type="text"><![CDATA[安装错误no such file or directory: &#39;pycocotools/_mask.c&#39;解决办法: pip install cython 评价标准COCO数据集介绍COCO数据集具有5种标签类型, 分别为: 目标检测, 关键点检测, 物体分割, 多边形分割 以及 图像描述. 这些标注数据使用JSON格式存储. 所有文件除了标签项以外都共享同样的数据结构, 如下所示: 标签结构各有不同, 如下所示: Object Detection每一个目标实例的标签都具有一系列条目, 包括该目标的类别id以及分割掩膜(segmentation mask). 分割掩膜的格式取决于实例表示的是一个单一的目标(iscrowd=0, 使用polygons标注)还是一群目标(iscrowd=1, 使用RLE标注). 注意, 一个单一的物体(iscrowd=0)在被遮挡的情况下, 可能会需要多个多边形来表示. Crowd标签用来标注一大群目标(如一群人). 另外, 每一个物体都会提供一个闭合的bounding box( box的坐标系从图左上角开始,0-indexed). 最后, 标注结构的类别条目存储着从cat id 到类别的映射以及超类别的名字. 关键点检测Stuff SegmentationStuff Segmentation的格式和object detection的格式几乎一模一样, 但是stuff segmentation无需iscrowd条目, 因为该条默认置为0. 为了方便访问, coco提供了json和png两种标注格式. 在 json 格式中, 每一个出现在图片中的类别都会单独用一个RLE标签条目编码(也就是说同类的会被放到同一个RLE编码里面). category_id 则代表当前的物体类别的id. Panoptic Segmentation 数据集信息标注格式COCO-API 使用方法及源码解析利用 json 文件实例化 COCO API 对象 参数 -annotation_file=None (str): location of annotation file 12345678910from pycocotools.coco import COCOdataDir = '/home/zhaozheng/coco'dataType = 'val2017'annFile = '&#123;&#125;/annotations/instances_&#123;&#125;.json'.format(dataDir, dataType)coco = COCO(annFile)# 若实例化成功, 则会返回:# loading annotations into memory...# Done (t=0.81s)# creating index...# index created! coco.createIndex()COCO 的构造函数会调用该函数来建立数据索引, 用户通常不会直接调用该函数 参数: 无返回: 无 调用后会输出:1234loading annotations into memory...Done (t=0.74s)creating index...index created! coco.info()参数: 无返回: 无 调用后会打印数据集标签的相关信息123456description: COCO 2017 Dataseturl: http://cocodataset.orgversion: 1.0year: 2017contributor: COCO Consortiumdate_created: 2017/09/01 coco.getAnnIds() 参数: imgIds=[](int array) : 返回指定 imgs id 的 annotations id 列表 catIds=[](int array) : 返回指定类别 id 的所有 annotations id 列表 areaRng=[](float array, 二元组, 指定面积区间大小) : 返回area项标签处于指定区间的 annotations id 列表 iscrowd=None(boolean): 返回: 返回满足条件的 annotations 的 id, 如果三个列表参数均为空, 则直接返回所有的 id. 注意上面三个参数的筛选过程是逐步进行的, 前者筛选后的结果会作为后者筛选的输入, 若三项同时为空, 则会返回所有的类别编号 coco.getCatIds() 参数(当传入单个字符串时, 会自动转换成只包含一个字符串元素的列表): catNms=[] (str array) : 返回列表中指定的类别名称的类别编号 supNms=[] (str array) : 返回列表中指定的子类别名称的类别编号 catIds=[] (int array) : 返回指定类别编号对应的类别编号 返回 ids (int array) : 类别编号, 注意上面三个参数的筛选过程是逐步进行的, 前者筛选后的结果会作为后者筛选的输入, 若三项同时为空, 则会返回所有的类别编号 coco.getImgIds() 参数: imgIds=[](int array) : 返回指定 img ids 的 img ids catIds=[](int array) : 返回具有指定类别 ids 的 img ids 返回: 符合条件的图片的 id, 若参数均为空, 则返回所有的图片 id coco.loadAnns() 参数: ids=[](int array) : 加载指定 ann ids 的 ann 返回: 一个元素均为字典类型的列表, 其中字典的键根据任务的不同可能包含: segmentation: area: iscrowd: 布尔值, 表示是否是群体目标(不好检测及分割) image_id: 代表当前框属于哪一张图片 bbox: 代表 bbox 的坐标, 分别为 [x,y,width,height] category_id: 代表当前的类别编号 id: 当前框的 id, 也就是输入参数 ann ids 的值注意, 参数为空时会返回一个空列表 coco.loadCats()加载类别信息 参数: ids=[](int array): 类别编号 cat ids 返回: 一个元素均为字典类型的列表, 字典的键包含: supercategory: 分别代表大类别(如交通工具) id: 类别编号 cat ids name: 以及类别的名称(如飞机). 注意, 参数为空时会返回一个空列表 coco.loadImgs()加载图片信息 参数: ids=[](int array): 图片编号 img ids 返回: 一个元素均为字典类型的列表, 字典的键包含: license file_name: 图片的本地文件名 coco_url: 可以在线访问的图片地址 height: 图片的高 width: 图片的宽 data_captured flickr_url, id coco.showAnns()先标签的信息显示出来(前面的 load 函数只是加载) 参数没有默认值, 调用函数时必须指定 参数: anns(array of object), 传入的需要是 loadAnns() 函数返回的 anns 对象列表 返回: 无 该函数需要先用import matplotlib.pyplot as plt创建相应的画布并加载图片才能看到最终的可视化效果, 具体见如下代码所示 12345678910111213141516import matplotlib.pyplot as plt# get all images containing given categories, select one at randomcatIds = coco.getCatIds(catNms=['person','dog','skateboard']);imgIds = coco.getImgIds(catIds=catIds );imgIds = coco.getImgIds(imgIds = [324158])img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]I = io.imread(img['coco_url'])plt.axis('off')plt.imshow(I)plt.show()# load and display instance annotationsplt.imshow(I); plt.axis('off')annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)anns = coco.loadAnns(annIds)coco.showAnns(anns) coco.loadRes()(待尝试)加载算法结果, 同时创建API以便访问它们, Load algorithm results and create API for accessing them. 参数: resFile(sre): 文件名称或者 result file, 无默认值, 必须指定 返回: result pai object coco.download()从Mscoco.org.server上下载COCO数据集 coco.loadNumpyAnnotations()从 numpy 数组中转换算法的结果, 其结果是一个 Nx7 大小的数组 参数: data(numpy.ndarray), Nx7, {imageId, x1, y1, w, h, score, class} 返回: annotations(python nested list) coco.annToRLE只能接受一个 ann 对象, 不能是多个 ann 组成的列表 参数: ann, 将 polygons 或者 uncompressed RLE 类型的数据转换成 RLE 返回: rle 类型的数据 coco.annToMask只能接受一个 ann 对象, 不能是多个 ann 组成的列表 参数: ann, 将 polygons, uncompressed RLE 或者 RLE 类型的数据转换成二值掩膜 返回: 二值掩膜 encode()将 binary masks 编码成 RLE 形式 参数: bimask 返回: RLE 类型的数据 decode()将 RLE 形式解码成 binary masks 参数: rleObjs, rle 类型的输入 返回: 解码后的二值掩膜 area() 参数: rleObjs, rle 类型的输入 返回: 分割区域的面积 toBbox()源码解析最常用的是 pycocotools/coco.py 文件中的COCO类, 其内部实现如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# pycocotools/coco.py# 首先, 是一大串的注释# COCO API提供了一系列的辅助函数来帮助载入,解析以及可视化COCO数据集的annotations# 该文件定义了如下API 函数:# COCO - COCO api 类, 用于载入coco的annotation 文件, 同时负责准备对应数据结构来存储# decodeMask - 通过rle编码规范, 来对二值mask M进行解码# encodeMask - 使用rle编码规范来对二值mak M进行编码# getAnnIds - 获得满足给定过滤条件的ann ids(标注)# getCatIds - 获得满足给定过滤条件的cat ids(类别)# getImgIds - 获得满足给定过滤条件的img ids(图片)# loadAnns - 根据指定的ids加载anns# loadCats - 根据指定的ids加载cats# loadImgs - 根据指定的ids加载imgs# annToMask - 将annotation里面的segmentation信息转换成二值mask# showAnns - 可视化指定的annotations# loadRes - 加载算法结果同时创建API以便访问它们# download - 从Mscoco.org.server上下载COCO数据集# 接下来, 具体看一下COCO类的实现class COCO: def __init__(self, annotation_file=None): # 构造函数 # 参数annotation_file: 指定了annotation文件的位置 # dataset, anns, cats, imgs均为字典类型数据 self.dataset, self.anns, self.cats, self.imgs = dict(), dict(), dict(), dict() # imgToAnns, catToImgs均为defaultdict数据类型(带有默认值的字典) self.imgToAnns, self.catToImgs = defaultdict(list), defaultdict(list) if not annotation_file == None: #... # 以只读方式加载json标注文件 dataset = json.load(open(annotation_file, 'r')) assert type(dataset)==dict # 确保读出来的是字典类型 #... # 正式将读取的字典数据赋给该类的成员变量 self.dataset = dataset # 创建索引 self.createIndex() def createIndex(self): # 创建索引 # 三个都是字典数据类型 anns,cats,imgs=&#123;&#125;,&#123;&#125;,&#123;&#125; # 两个defaultdict数据类型 imgToAnns, catToImgs = defaultdict(list), defaultdict(list) if 'annotations' in self.dataset: for ann in self.dataset['annotations']: xml 数据转成 COCO 数据对于 COCO 数据格式, 我们需要利用 json 模块来构建, 不同的任务需要的标签各不相同, 对于目标检测任务来说, 我们需要如下标签信息: info: 数据集相关信息, 主要是数据集的相关信息, 训练时不会用到 images: 图片相关信息, id, 宽, 高, 文件名(最重要的四个)等 annotations: 标签相关信息, 目标检测任务需要 bbox, 对应的类别编号, 以及所属图片编号 license: 训练时不会用到, 随便填 通用模板如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109import sysimport globtry: import xml.etree.cElementTree as ETexcept ImportError: import xml.etree.ElementTree as ETimport osfrom PIL import Imageimport jsonimport numpy as np# 输入: 多个 xml 文件, 每个 xml 文件对应了一张图片的标签# 输出: 一个 json 文件, 文件中的数据格式符合 COCO 的格式要求# 首先, 将需要转换的所有 xml 文件路径名获取到xml_dir = 'path/to/xmls'xmls = glob.glob(os.path.join(xml_dir, '*.xml'))# 然后, 对于 COCO 数据集的每一项, 分别定义不同的函数来获取, 这种方式易于实现, 且简单直观def xml_get_img_name(xml_path): tree = ET.ElementTree(xml_path) # 打开一个 xml 文件, 并解析成树结构 root = tree.getroot() return root.find('filename').text # 返回找到的文件名(图片名)def xml_get_bboxes(xml_path): tree = ET.ElementTree(xml_path) # 打开一个 xml 文件, 并解析成树结构 root = tree.getroot() objects = root.findall('object') bboxes = [] # 因为一张图片中有多个 bbox, 因此, 我们要返回一个列表 for obj in objects: obj_name = obj.find('name').text bbox = obj.find('bndbox') x1 = int(bbox.find('xmin').text) y1 = int(bbox.find('ymin').text) x2 = int(bbox.find('xmax').text) y2 = int(bbox.find('ymax').text) bboxes.append([x1, y1, x2, y2, int(obj_name)]) return bboxesjson_dict = &#123;&#125; # 创建最外层的 json 字典# 建立 info 部分json_dict['info'] = &#123;&#125; # 这里是字典, 一个 json 文件只有一个 info 信息json_dict['info']['contributor'] = 'zhaozheng'json_dict['info']['year'] = 'zhaozheng'json_dict['info']['description'] = 'zhaozheng'json_dict['info']['url'] = 'zhaozheng'json_dict['info']['date_created'] = 'zhaozheng'# 还可以自行完善其他信息, info 部分不影响训练# 建立 licenses 部分json_dict['licenses'] = [] # 注意, 这里是列表, 这是由 COCO 的数据格式决定的, 说明一个json文件可以有多个 licensetmp_dict = &#123;&#125; # 申请临时的字典, 构建单个 licensetmp_dict['id'] = 1tmp_dict['name'] = 'xxxx License'json_dict['licenses'].append(tmp_dict) # 这里只添加一个 license, 可以根据实际情况进行添加# 建立 images 部分json_dict['images'] = [] # 注意, 是列表, 列表的长度代表了数据集中图片的数量for i in range(len(xmls)): # 注意, xml 文件与图片一一对应, 这里我们顺序访问, 并用 i 作为每一张 img 的 id, 后面会利用这个 i 给每一个 box 填充 img_id tmp_dict = &#123;&#125; # 创建单个 img 的临时字典 tmp_dict['id'] = i tmp_dict['file_name'] = xml_get_img_name(xml[i]) img_path = os.path.join(xml_dir, tmp_dict['file_name']) img = cv2.imread(img_path)# 默认 xml 与 jpg 的一一对应文件在同一个目录下 tmp_dict['height'] = img.shape[0] tmp_dict['width'] = img.shape[1] tmp_dict['flickr_url'] = '' # coco 格式要求, 训练时不会用到, 填空即可 tmp_dict['coco_url'] = '' # 同理 tmp_dict['date_captured'] = '' # 同理 tmp_dict['license'] = 1 # 这里赋予的是 license 的id, 我们上面定义了 id 为 1 的license json_dict['images'].append(tmp_dict) # images 中的一项已经填充完毕, 将其添加到列表中# 建立 categories 部分, 对于目标检测任务来说, 除了 annotations 之外还有 categories 关键字json_dict['categories'] = [] # 同理, 多个类别, 每个类别构成一个字典, 字典中包含该类别信息, 列表的长度代表字典的个数, 也就是类别的个数cats = ['cat', 'dog', 'fish']for i in range(len(cats)): tmp_dict = &#123;&#125; tmp_dict['id'] = i tmp_dict['name'] = cats[i] tmp_dict['supercategory'] = 'animal' json_dict['categories'].append(tmp_dict)# 建立 annotations 部分json_dict['annotations'] = []id = 0 # bbox 的 idfor i in range(len(xmls)): # 为了方便知道当前 bbox 对应的 img id, 我们从每个 xml 文件进行遍历 # 获取当前图片中的所有 bbox bboxes = xml_get_bboxes(xmls[i]) for bbox in bboxes: # bbox = [x1, y1, x2, y2, bbox] tmp_dict = &#123;&#125; tmp_dict['id'] = id id += 1 tmp_dict['image_id'] = i tmp_dict['category_id'] = bbox[4] x = bbox[0] + bbox[2] // 2 y = bbox[1] + bbox[3] // 2 width = bbox[2] - bbox[0] height = bbox[3] - bbox[1] tmp_dict['bbox'] = [x, y, width, height] tmp_dict['segmentation'] = [] tmp_dict['area'] = w * h tmp_dict['iscrowd'] = 0 json_dict['annotations'].append(tmp_dict)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>数据处理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法题杂记]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E9%A2%98%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[交换两个数的特殊方法加法注意: 有可能导致溢出 123a = a + b; //但是加法可能会最终导致溢出b = a - b;a = a - b; 异或123a = a^b;b = a^b;a = a^b; 上面的实习原理是利用异或的自身特性: 12a ^ a = 0a ^ 0 = a 注意: 用异或交换两个整数存在一个陷阱 当交换两个相同的数字时, 由于异或自身的特性, 会使得这两个数字都变成0, 解决方法是加上一个判断条件: 12345if(a!=b)&#123; a = a^b; b = a^b; a = a^b;&#125; 不开根号求平方根牛顿迭代法假设要对 $a$ 进行开根, 那么就需要找到一个值 $x$, 满足 $x^2 = a$, 我们令 $f(x) = x^2 - a$ , 则只需找到使 $f(x)=0$ 的值 $x$ 即为开根后的值, 也就是说要求 $f(x)$ 与x轴的交点, 在x轴上任选一点 $(x_0, f(x_0))$, 求该点在函数 $f(x)$ 上面的切线方程如下: f(x) - f(x_0) = f'(x_0)(x - x_0)也就是: f(x) - (x_0^2 - a) = 2x_0(x - x_0)我们求该直线与x轴的交点, 即 $f(x)=0$ , 求得 $x$ 的值为: x = x_0 - \frac{x_0^2 -a}{2x_0}如果上面求得的 $x$ 不是 $f(x)$ 与 x 轴的交点, 那么久继续这个过程, 直到结果满足我们需要的精度 123456789int main()&#123; double a = 24;//欲求24的开根 double x = 1.0; while(abs(x*x-a)&gt;0.0001)&#123; x = x- (x*x-a)/(2*x+1e-9); &#125; cout&lt;&lt;x; return 0&#125; 二分法1234567891011int main()&#123; double a = 24;//欲求24的开根 double high = a; double low = 0; while(high-low&gt;0.0001)&#123; double mid = (high+low)/2; if(mid*mid &gt; t) high = mid; if(mid*mid &lt; t) low = mid; &#125; return low;&#125; 有两个数组, 数组很大, 其中一个数组存储着n个人的名字, 另一个数组存储着这n个人的身高?问题一: 现在需要找出m个身高最高的人的名字, 要求时间和空间复杂度最低问题二: 哪些排序算法时间复杂度是 $O(1)$ 的, 哪些不是问题三: 哪些排序算法是稳定的, 哪些是不稳定的 稳定: 冒泡, 插入排序, 归并(合并), 基数排序 不稳定: 选择, 快排, 希尔排序, 堆排序 问题四: 现在需要设计一个算法, 每次从这n个人当中挑出一个人, 要求最终跳出的所有人当中, 身高高的人站的比例大函数轮盘赌算法求下面函数的返回值:12345678int func(x)&#123; int countx=0; while(x)&#123; countx++; x=x&amp;(x-1); &#125; return countx;&#125; 假定x=9999, 答案:8思路: 将x转化为2进制, 看含有1的个数 在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug， 你如何调试这个bug。n个数里面求最大的m个数, (堆)建立size为m的最小堆, 堆顶为最小的值, 堆内的数据都比堆顶小, 所以这m个数字即为n个数里面最大的m个数. 求两个不相交的连续子数组的最大和题目：有一个整数数组n，a和b是n里两个互不相交的子数组。返回sum(a)+sum(b)的最大值。 分析：1234567891011121314151617181920212223242526272829303132333435363738394041int SumOfTwoSubarray(const vector&lt;int&gt; &amp;n)&#123; if (n.size() &lt; 2) &#123; throw exception(); &#125; vector&lt;int&gt; left(n.size()), right(n.size()); int sum = n[0], maxnum = n[0]; left[0] = n[0]; right.back() = n.back(); for (uint32_t i = 1; i &lt; n.size()-1; ++i) &#123; if (sum &gt; 0) sum += n[i]; else sum = n[i]; if (sum &gt; maxnum) &#123; maxnum = sum; &#125; left[i] = maxnum; &#125; sum = n.back(); maxnum = n.back(); for (uint32_t i = n.size()-2; i &gt;=1; --i) &#123; if (sum &gt; 0) sum += n[i]; else sum = n[i]; if (sum &gt; maxnum) &#123; maxnum = sum; &#125; right[i] = maxnum; &#125; int res = 0x80000000; for (uint32_t i = 0; i &lt; n.size() - 1; ++i) res = max(res, left[i] + right[i + 1]); return res;&#125; 新建两个数组left和right，left[i]表示n[0:i]的连续子数组的最大和，right[i]表示n[i:length-1]的连续子数组的最大和。left[i]+right[i+1]的最大值就是答案。 https://blog.csdn.net/bupt8846/article/details/48115931 随机数算法的实现实现均匀分布的随机采样实际正态分布的随机采样]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面试-其他知识点总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E5%85%B6%E4%BB%96%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Linuxtar 指令 /etc/ld.so.conf httpd.conf 查看内存的指令1free 查看进程cpu/mem占用htop 待解决问题360 2019 C++ 开发工程师 套卷基数排序 利用动态规划计算以下矩阵连乘：A1(2025)、A2(255)、A3(515)、A4(1510)、A5(1020)、A6(2025)正确答案 : A您的答案 : DA(A1A2)(((A3A4)A5)A6)B(A1A2A3)((A4A5)A6)C(((A1((A2A3)A4))A5)A6)D(A1A2)((A3(A4A5))A6) 待排序元素规模较小时，宜选取哪种排序算法效率最高（ 冒泡排序 ） 对关键码集合K={22，11，38，68，43，6，10，48},用筛选法创建最小堆时，从关键码（ 68 ）开始调整 HANDLE hMutexSuicide=::OpenMutex (SYNCHRONIZE,FALSE,g_szMutexName);其中FALSE的作用是（ 不需要向下传递 ） shell中要输出a+b的结果（假设a和b已经被赋值），如何得到: echo $((a+b)) 友元函数下列运算符重载函数中，属于友元函数的是（ ） 正确答案 : BCD您的答案 : CABase operator+(Base); BBase operator—(Base); CBase operator&amp;&amp;(Base, Base); DBase operator++(Base,int); 数组加一是加整个数据的长度. 执行如下代码后输出结果为（ 2, 5 ） int main() { int a[5] = {1, 2, 3, 4, 5}; int *ptr = (int*)(&amp;a + 1); printf(&quot;%d, %d&quot;, *(a + 1), *(ptr - 1)); return; } 下面程序的输出结果是（ 0, 因为 &lt;&lt; 的优先级高于 ?: ） include using namespace std; void max(int i, int j) { cout &lt;&lt; (i&gt;j) ? i : j; } int main() { int m = 016, n = 18; max(m, n); return 0; }]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[各种初始化方法整理总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%90%84%E7%A7%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[初始化方法概览 初始化方法 服从分布 说明 均匀分布 … 将权值与偏置进行均匀分布的初始化 高斯分布 … 初始化为服从 $N(\mu, \sigma ^2)$ 的高斯分布 Xavier $W \sim U\Big[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}},\frac{\sqrt{6}}{\sqrt{n_j + n_{j+1}}} \Big]$, 服从均值为 0, 方差为 $\frac{2}{n_i + n_{i+1}}$ 的均匀分布 公式中, $n_i$ 为本层输入的神经元个数, $n_{i+1}$ 为本层输出的神经元个数, 适合于线性激活函数(原文公式推导的假设) MSRA(Kaiming) 基于均值为0, 方差为 $\sqrt{\frac{2}{(1+a^2)\times fan_{in}}}$ 的高斯分布 它特别适合 ReLU 激活函数(非线性) 双线性初始化 … 常用在反卷积网络里的权值初始化 初始化方法详细说明Xavier(‘zeiviə’)核心理念是: 优秀的初始化方法应该使得各层的激活值和状态梯度在传播过程中的方差保持一致 再继续推导之前, 需要先提出以下假设: 首先,输入数据来说,其均值和方差应满足: $E(x)=0, Var(x)=1$ (通过BN,较容易满足) 权重矩阵 $W$ 和 网络输入 $x$ 互相独立 每层输入的每个特征方差一样 激活函数对称: 这主要是为了满足均值为0的假设 激活函数是线性的, 也就是说其导数为1 初始时, 状态值落在激活函数的线性区域, 即此时导数为1 现在假设有一个 $n$ 维的输入向量 $\vec X$ 和一个单层的线性神经网络, 它的权重向量是 $\vec W$, 网络的输出是 $Y$, 则有: Y = W_1 X_1 + W_2 X_2 + ... + W_n X_n对于每个 $W_i X_i$, 它对应的方差为: Var(W_i X_i) = E(X_i)^2 Var(W_i) + E(W_i)^2 Var(X_i) + Var(X_i) Var(W_i)当输入的 $X$ 均值为 0 时(通过 BN, 较容易满足), 输出的方差就是: Var(W_i X_i) = Var(W_i)Var(X_i)进一步假设 $W_i$ 和 $X_i$ 是独立同分布的, 就可以得到: Var(Y) = n\times Var(W_i) Var(X_i)也就是说输出的方差跟输入的方差只是相差了一个倍数 $nVar(W_i)$, 因此, 为了保证前向传播和反向传播时每一层的方差一致, 则有下面的公式成立: \forall i, n_i Var[W^i] = 1同时考虑反向传播时输入输出刚好相反, 于是就有: \forall i, n_{i+1} Var[W^i] =1权衡上面两个公式, 最终给出的权重方差为: \forall, Var[W^i] = \frac {2}{n_i + n_{i+1}}再由概率统计中均匀分布方差的性质反推,可以得到Xavier最终的初始化分布如下: W \sim U\Big[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}},\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}} \Big]Xavier在Caffe中的具体实现: 123456789101112131415161718192021222324template &lt;typename Dtype&gt;class XavierFiller : public Filler&lt;Dtype&gt; &#123; public: explicit XavierFiller(const FillerParameter&amp; param) : Filler&lt;Dtype&gt;(param) &#123;&#125; virtual void Fill(Blob&lt;Dtype&gt;* blob) &#123; CHECK(blob-&gt;count()); int fan_in = blob-&gt;count() / blob-&gt;num(); int fan_out = blob-&gt;count() / blob-&gt;channels(); Dtype n = fan_in; // default to fan_in if (this-&gt;filler_param_.variance_norm() == FillerParameter_VarianceNorm_AVERAGE) &#123; n = (fan_in + fan_out) / Dtype(2); &#125; else if (this-&gt;filler_param_.variance_norm() == FillerParameter_VarianceNorm_FAN_OUT) &#123; n = fan_out; &#125; Dtype scale = sqrt(Dtype(3) / n); caffe_rng_uniform&lt;Dtype&gt;(blob-&gt;count(), -scale, scale, blob-&gt;mutable_cpu_data()); CHECK_EQ(this-&gt;filler_param_.sparse(), -1) &lt;&lt; "Sparsity not supported by this Filler."; &#125;&#125;; 可以看出, Caffe的Xavier实现有三种选择: (1) FAN_IN, 方差只考虑输入个数: Var[W^i] = \frac{1}{n_i}(2) FAN_OUT, 方差只考虑输出个数: Var[W^i] = \frac{1}{n_{i+1}}(3) AVERAGE, 方差同时考虑输入和输出个数: Var[W^i] = \frac{2}{n_i + n_{i+1}}MSRAkaiming 初始化给出的公式解释时, ReLU 函数把输出的一半负值都置零了, 为了保持输入输出的方差一致, 显然需要把原来正数输出 初始化方法讨论为什么不能全0初始化首先, 在神经网络中, 每一层中的任意神经元都是同构的, 它们拥有相同的输入, 如果再将参数全部初始化为同样的值(如0), 那么输出也就是相同的, 反过来它们的梯度也都是相同的. 那么无论是前向传播还是反向传播的取值都是完全相同的, 那么每一个神经元都是基于input做相同的事情, 这样一来, 不同的神经元根本无法学到不同的特征, 这样就失去网络学习特征的意义了]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集成学习方法]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[个体与集成集成学习(ensemble learning): 通过构建并结合多个学习器来完成学习任务 同质集成(homogeneous): 集成中只包含同种类型的个体学习器( 神网+神网, 决策树+决策树), 其中的个体学习器称为”基学习器”, 算法为”基学习算法”. 异质集成(heterogenous): 集成中包含不同类型的个体学习器( 神网+决策树 ), 其中的个体学习器称 “组件学习器”或”个体学习器” 要获得好的集成效果, 每个个体学习器应 “好而不同”, 即个体学习器要有一定的准确性, 同时还要有一定的差异性(否则多个学习器会退化成单一学习器,因为每个学习器都差不多) 事实上, 个体学习器的”准确性”和”差异性”本身就存在冲突, 一般的, 当准确性很高之后, 要增加多样性就需要牺牲准确性. 根据个体学习器的生成方式, 目前的集成学习方法大致可分为两大类: 个体学习器间存在依赖关系, 必须串行生成的序列化方法, eg: Boosting 个体学习器间不存在依赖关系, 可同时生成的并行化方法, eg: Bagging 和 随机森林(Random Forest) Boosting工作机制: 先从初始训练集训练出一个基学习器, 再根据基学习器的表现对训练样本进行调整, 使得先前基学习器做错的训练样本在后续受到更多关注, 然后基于调整后的样本分布来训练下一个基学习器, 如此重复进行, 直至基学习器数目达到事先指定的值T, 最终将这T个基学习器进行加权结合 Boosting族有很多种算法, 最著名的代表是 AdaBoost]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-常用指令助记]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E5%8A%A9%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1.查看磁盘空间 df -hl 查看磁盘剩余空间 df -h 查看每个根路径的分区大小 2.查看文件/文件夹大小 查看指定文件/文件夹大小：du -hs &lt;文件名或文件夹名&gt; 查看当前文件夹下所有文件大小（包括子文件夹）：du -sh 3.查看文件数量 统计当前目录下文件的个数（不包括目录） ls -l | grep “^-“ | wc -l作者：spectre7来源：CSDN原文：https://blog.csdn.net/weixin_41278720/article/details/83591027版权声明：本文为博主原创文章，转载请附上博文链接！ wget: curl1curl -O [url] zip1zip [参数] xxx.zip [folder | file] -a 将文件转成ASCII模式-F 尝试修复损坏的压缩文件-h 显示帮助界面-m 将文件压缩之后，删除源文件 -n 特定字符串 不压缩具有特定字尾字符串的文件-o 将压缩文件内的所有文件的最新变动时间设为压缩时候的时间-q 安静模式，在压缩的时候不显示指令的执行过程-r 将指定的目录下的所有子目录以及文件一起处理-S 包含系统文件和隐含文件（S是大写）-t 日期 把压缩文件的最后修改日期设为指定的日期，日期格式为mmddyyyy tarcatgrepls统计文件个数更换国内镜像源清华源:1https://mirrors.tuna.tsinghua.edu.cn/ 中科大源: 1http://mirrors.ustc.edu.cn/help/homebrew-bottles.html 阿里源:123456789```# apt# pip# brew中科大 cd “$(brew —repo)”git remote set-url origin https://mirrors.ustc.edu.cn/brew.git1234# npmhttps://npm.taobao.org/ npm config set registry http://registry.npm.taobao.org1234# docker从Registry中拉取镜像 sudo docker pull registry.cn-hangzhou.aliyuncs.com/zerozone/non-target-baseline-local:[镜像版本号]sudo docker pull registry.cn-hangzhou.aliyuncs.com/zerozone/non-target-baseline-local:[镜像版本号]12将镜像推送到Registry $ sudo docker login —username=ksws840662044 registry.cn-hangzhou.aliyuncs.com$ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/zerozone/non-target-baseline-local:[镜像版本号]$ sudo docker push registry.cn-hangzhou.aliyuncs.com/zerozone/non-target-baseline-local:[镜像版本号]12把容器打包成镜像 docker commit -m “” -a “” [CONTAINER ID] [给新的镜像命名]12查看镜像 docker images12将指定的imageid的镜像重命名 $ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/zerozone/non-target-baseline-local:[镜像版本号]12推送 sudo docker push registry.cn-hangzhou.aliyuncs.com/zerozone/non-target-baseline-local:1.0.2123从本地push到镜像 sudo docker login —username=${uname} registry.cn-shanghai.aliyuncs.comcd ${code_path} # where there is a Dockerfile for build this docker imagedocker build -t ${docker_image_path}:${tag_version} .docker push ${docker_image_path}:${tag_version}12查看容器: docker ps -a12启动容器 CONTAINER ID = a364c4f5ab8asudo nvidia-docker start a364c4f5ab8asudo nvidia-docker attach a364c4f5ab8a123容器和本地之间的文件拷贝:将主机`/www/runoob`目录拷贝到容器 96f7f14e99ab(Container ID) 中 `/www` 目录下 docker cp /www/runoob 96f7f14e99ab:/www/1反之: docker cp 96f7f14e99ab:/www/ /www/runoob123456789101112131415161718192021222324# 命令行光标移动快捷键ctrl+a/e: 跳至行首/尾ctrl+f/b: 左/右移一个字符alt+f/b: 左/右一个单词ctrl+h/d: 左/右删除ctrl+u/k: 删除剩余(u不好使? 会删除所有), 带有剪切功能ctrl+y: 复制ctrl + p/n: 上一条/下一条历史记录alt + p/n: 上一条/下一条最相近的历史记录# tmux```pytmux attach-sessiontmux at -t session-nametmux list-sessionstmux lstmux attach-session -c 2 重命名窗口:ctrl+b+,重命名session:ctrl+b+$]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔试及面试记录]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AC%94%E8%AF%95%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[笔试常见坑数字相乘后超出 int 范围, 能用 long long 就用 long longpython 的 sys.stdin.readline()split() 读入的都是字符串, 因此在进行比较时需要注意字符串的比较和数字类型的比较的区别. python 的 append 方法是对列表直接操作, 不会返回任何结果(返回 None) python 的for i in range语法的每一次迭代都是基于 range 的, 不会被内部改变, 如下所示, 下面三段程序的输出是一模一样的.12345678910111213141516 for i in range(10): if i % 2 == 0: i += 1 continue print(i)for i in range(10): if i % 2 == 0: continue print(i)for i in range(10): if i % 2 == 0: i = 3 continue print(i) 商汤科技实习一面你有计算过感受野的大小吗你有没有计算过网络结构的感受野大小, 做目标检测的时候根据网络的参数算感受野大小? 可以举个例子吗?你有没有发理论上计算出来的感受野大小和实际网络的效果是有差别的, 偏大还是偏小? 为什么?CNN 具有平移不变性, 这句话是对的吗如果 CNN 中具有全连接层, 你觉得还具有平移不变性吗检测文章还看了哪些比较新的工作?讲一下 MaskRCNN你觉得那些竞赛哪一个比较难网络结构改动最大的是哪一些, 自己重新搭建了一个网络结构?有没有自己去重新构建一个网络结构, 或者说一些组合? resnet , inception, 各种组合, 有尝试过吗(这里可以答 seblock 等等) 给定一个整数数组, 求最大的连续子序列和 C++ 用过智能指针吗 商汤科技实习二面FLOPs的计算nxn 的矩阵乘法的 FLOPs卷积的 FLOPs 的计算模型在inference时除了 FLOPs 还有哪些影响速度的因素? BN 在 Inference 阶段可以放到其他操作理做吗? Conv + BN 可以吗Conv + relu + BN 可以吗Depthwise + BN 可以吗Depthwise + relu + BN 可以吗 CNN 具有平移不变性吗? anchor 是越多越好吗? 除了速度降低外, anchor 多了还会有其他什么缺点吗? anchor 的作用是什么? anchor free 方法有什么优势或者好处? yolo 的anchor free 方法有什么优势? 虚函数的作用虚函数的实现c++11 的特点什么时候用智能指针, 什么时候不用? 智能指针有什么缺点?vector 的内存扩增机制, 成倍增长相对于线性增长有什么优势? 1.5倍和2.0倍有什么区别?struct 为什么要字节对齐? 为什么是4字节? 为什么是8字节?map 和 unorderd_map 的区别? map 的排序依据是什么? 物体检测还有什么可以继续完善的地方? 如果让你去做, 你会怎么改进? 03.07 360 提前批笔试数星星时间限制：C/C++语言 1000MS；其他语言 3000MS内存限制：C/C++语言 65536KB；其他语言 589824KB题目描述：给出一个m*n的只由01组成的矩阵，我们称包含：123 1111 1 这样的形状为星星（矩阵的四角为0、1均可），现在要从这个矩阵中选出一个矩形区域，要求这个矩形区域中至少有k个星星，问有多少个这样的矩形区域。（矩形区域即选取连续的若干行和连续的若干列所构成的交集区域） 输入输入第一行包含三个整数n,m,k(1&lt;=n,m&lt;=500,1&lt;=k&lt;=m*n), n和m分别表示矩阵的行数和列数。接下来有n行，每行包含一个长度为m的仅含01的字符串，描述这个矩阵。 输出输出仅包含一个正整数，表示符合要求的矩形区域的数量。 样例输入12343 5 2111001111001100 样例输出12 //有选择1到4列和1到5列两种矩形区域的选择方式。 座位安排时间限制：C/C++语言 1000MS；其他语言 3000MS内存限制：C/C++语言 65536KB；其他语言 589824KB题目描述：假设班主任需要为N名学生安排座位，现在有M张桌子，每张桌子可以供一名学生单独使用，也可以供两名学生共同使用，共用一张桌子的两名学生便称为同桌。班主任为所有学生评估出淘气值，第i名学生的淘气值为Ai，如果同桌两人淘气值之和过高，便容易产生矛盾。那么班主任该如何安排座位，使得淘气值之和最大的两名同桌，其淘气值之和尽可能小？ 输入第一行包含两个整数N和M，1≤M＜N≤105且N≤M×2。第二行包含N个整数A1到AN，0≤Ai≤109。(数字间均以空格隔开)输出.输出淘气值之和最大的两名同桌，其淘气值之和可能的最小值。 样例输入125 34 1 8 2 6 样例输出127// 安排第1名与第4名学生共用一张桌子，两人淘气值之和为6；第2名与第5名学生共用一张桌子，两人淘气值之和为7；第3名学生单独用一张桌子。 03.13 阿里一面 简单自我介绍 目标检测现在比较流行的一些检测方法有哪些? 对于yolo, rcnn等模型, 有没有具体的实操过? yolo 和 rcnn 的区别? yolo 和 rcnn 在初期对于图片的采样上面有什么差异? 在使用 yolo 的过程中, 还有哪些可以优化的点? 或者说 yolo 不具备的能力? yolo 的 anchor box 是怎么产生的? 通过什么方式生成出来的? anchor box 怎么能够得到一个更好的初始化的结果? 有哪些调整的手段可以去控制或干预? 比如产生多少 anchor box? anchor box 的长和宽的数据怎么得到? (基于 kmean 的聚类的过程来学习出这些 anchor box) 有没有针对 yolo 解决过一些具体的实际问题? 检测什么样的一个目标? 怎么去检测来达到最终的一个效果? 平时有没有做过一些和算法相关的实际的项目? 视频有了解过吗? 设想以下场景, 在淘宝上搜索某个商品, 搜出来的图片通常有很多文字, logo, 边框等, 我们认为这些图片对用户体验不好, 我们希望能够搜索出那些 背景不杂乱的图片, 如何做? 问题简化一些就是: 怎么判断目标的背景不杂乱? 有没有了解过一些图片的客观质量评估的一些算法? 在图像的传统的特征上面有没有做过一些研究? 对于传统的机器学习的方法有学习过吗? 能解释一下分类和回归的定义吗? 在做分类时, 当数据集里面有些许异常值时, 对于逻辑回归模型和 SVM 模型, 哪一种受到的干扰会少一些? 正则化平时有用过吗? L1 正则和 L2 正则分别解决什么问题? 猴子搬玉米的问题如果解决? 3.15 海康 目标检测现在的 sota 3.18 360darnet模型压缩, 速度, 怎么优化小目标样本检测feature map 的计算归并排序实现 3.19 360 一面 找一个你觉得你自己做不还不错的目标检测项目, 介绍一下 做不同的比赛不会对网络模型或者loss进行一些改进吗? 模型融合是怎么做的? 两个框架的模型放在一起会不会增加一些误检? Focal Loss 的原理 ResNet 的原理 BN 的原理 sigmoid 为什么会引入梯度消失 介绍一下 deepglint 的工作 杂记虚函数、指针和引用的区别、Linux进程间通信、Linux怎么看内存占用、sql运行太占资源怎么解决、TCP握手、python IS和==的区别、深拷贝浅拷贝、冒泡排序. 昨天内推，今天电面，计算机视觉算法岗。 全程50分钟，无传统算法题。 根据记忆，大概有如下一些问题。 1.介绍一下前一段实习 简单介绍了一下目标检测的实习经历 2.目标检测two-stage模型 RCNN—&gt;SPPNet—&gt;Fast RCNN—&gt;Faster RCNN—&gt;RFCN—&gt;DCN—&gt;DCNv2 其中重点问了selective search和RPN，另外每个的创新点需要讲一下。 3.目标检测one-stage模型 YOLO系列、SSD、RefineDet 4.resnet和densenet及其不同 5.Inception系列的演化 6.BN的原理和实现细节，其中均值和标准差的计算，以及训练和测试时分别怎么用 7.Focal loss 8.小目标检测用什么方法 9.mobilenet 10.项目和比赛的某些细节作者：spectre7来源：CSDN原文：https://blog.csdn.net/weixin_41278720/article/details/87817164版权声明：本文为博主原创文章，转载请附上博文链接！ 格灵深瞳作者：txfs链接：https://www.nowcoder.com/discuss/167238来源：牛客网 充分认识到自己多辣鸡了。分享一下面经并欢迎回复解答。 batchnorm的几个参数，能不能整合到前面的conv里，训练时和测试时的区别感受野计算33，s=1与55，s=2的核在无限大（即不用考虑padding）的feature map上卷积计算的计算量之比解释一下sgd的momentum算法题：非常大的两个数组，一个是人的id（unique，无序），一个是浮点型身高值。一一对应。要求返回top m身高及对应的id。约束条件：1. 这m个身高和id的顺序必须是数组原状态的顺序。2. 空间复杂度O（1），时间不作要求。softmax和cross entropy loss排序的空间复杂度如何生成随机数]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《玩转算法面试LeetCode》视频教程笔记]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B-%E7%8E%A9%E8%BD%AC%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[讲师: liuyubobobo 第一章 算法面试到底是什么鬼1-1在面对一个算法题时, 面试官有时候看重的并不是你能否在有限的时间内解出来, 更看重的是你 是否有一个合理的思考路径, 要把算法面试的过程看做是和面试官一起探讨一个问题的解决方案, 对于问题的细节和应用环境, 可以和面试官沟通(不要提问太多, 可以自己提出假设, 自己解答), 在沟通的过程中, 一步一步深入到问题的细节, 并完善自己的假设. 这种沟通是非常重要的, 它暗示了你的思考问题的方式. 举例来说: 如果我们被要求对一组数据进行排序: 直接用快排?(这不是一个好的答案)提问: 这组数据有着什么样的特征?例如: 有没有可能包含有大量的重复元素?(如果是的, 那么三路快排是更好的选择, 在很多语言的标准库中, 实现排序的基本算法就是三路快排)又例如: 是否大部分数据距离它的正确位置很近? 是否近乎有序? 如快递订单排序. (如果是的话, 则插入排序更好)又例如: 是否数据的取值范围有限? 比如对学生成绩排序. (如果是, 那么计数排序更好)又例如: 是否需要稳定排序? (若是, 则归并更好)又例如: 数据的存储状况(数据结构)是怎么样的? 如果使用的是链表, 则不能进行随机存取, 就无法使用快排, 而应该使用归并排序.又例如, 如果数据量很大, 内存放不下, 那么久必须使用外部排序算法 其他主要注意的地方: 对问题的独到见解, 优化, 代码规范, 容错率. 对于算法面试, 人难亦难, 因此不要轻言放弃, 关键在于你所表达出的解决问题的思路. 甚至可以通过表达解题思路的方向, 得出结论: 这个问题的解决方案, 应该在哪个领域, 我可以通过查阅或者进一步学习解决问题. 1-2注意算法面试只是技术面试的一部分, 其中一个优秀不代表另一个也优秀 重点考察项目经历和项目中遇到的问题, 从这些可以看出你对于技术的态度是怎么样的 如: 你遇到过的印象最深刻的bug是什么? 你有说如何处理这个bug的? 这个问题没有参考答案, 因人而异, 却很容易看出一个人的真实水平是怎样的, 也可以看出你在技术领域的深度, 因此, 建议对这类问题有所准备. 近年来喜欢考察的点: 系统设计(scalability), 即系统在面对大规模设计时遇到的一些常见问题, 关于这些问题也有一些常见的思路和解决思路, 建议提前准备.(这些问题不属于算法面试的内容, 因此本课程不会过多介绍, 建议自己查阅相关资料进行整理) 不能只准备算法的面试, 也要根据自己所申请职位的不同, 对专业领域的知识熟练掌握, 这很重要 项目很重要, 最好能好好准备, 并且对于简历上出现的项目一定要非常熟悉 不是 “项目” 的项目: 一本优秀书籍的代码整理, 个人技术博客等. 通过过去了解你的行为方式: 遇到的最大挑战? 犯过哪些致命的错误? 遭遇的失败? 最享受的工作内容? 遇到冲突的处理方式? 做的最与众不同的事? 对于以上问题, 最后提前准备, 并且最好与自己的实际项目或者应聘的岗位相挂钩, 回答不要太过笼统, 最好能举出具体的事例(可信度更高), 能反映出你的一些个人素质和性格(对公司有利的). 准备好合适的问题问面试官. 这些问题可以反映出你关心的是什么. 如 整个小组的大概运行模式是怎么样的? 整个项目的后序规划是怎么样的? 贵公司中某个产品的某个问题是如何解决的? 贵公司为什么会选择某些技术或标准? 具体的考量是怎么样的? 我对某个技术很感兴趣, 在贵公司的小组中我会有怎么样的机会深入这种技术? 1-3准备算法面试不需要啃完一本《算法导论》 对于学习, 我们不能要求一步到位, 很多书, 很多知识, 我们都是要阅读, 理解很多遍, 慢慢的熟练, 直到内化到自己的血液中. 学习切记完美主义 高级数据结构和算法被提及的概率较低(但是对于某些特殊岗位, 这些算法也有可能是必考题). 如: 红黑树, 计算几何, B-Tree, 数论, 斐波那契堆, FFT(傅里叶变换) 远远不需要达到ACM竞赛的水平 算法面试的准备范围: 不要轻视基础算法和数据结构, 而只关注 “有意思” 的题目. 基础算法大致有: 各种排序算法 基础数据结构和算法的实现: 如堆, 二叉树, 图, … 基础数据结构的使用: 如链表, 栈, 队列, 哈希表, 图, Trie, 并查, … 基础算法: 深度优先, 广度优先, 二分查找, 递归 基本算法思想: 递归, 分治, 回溯搜索, 贪心, 动态规划 在进行实际时, 一味的刷题, 过度的在意正确与否, 而不去考虑题目背后的算法思想, 往往效率很低.(好像自己做了很多题, 但实际上收货并不大 ) 1-4 解法算法面试问题的整体思路注意题目中的条件:有一些题目的条件本身就是暗示, 如: 有序数组 设计指定复杂度的算法, 如 $O(nlogn)$, 那么就要考虑分治或者排序 无需考虑额外空间, 那么就要考虑申请额外的空间 数据规模大概是10000, 对于此, 那么 $O(n^2)$ 是可以接受的 当没有思路的时候: 自己给自己几个简单的测试用例, 试验一下 不要忽视暴力解法, 暴力解法通常是思考的起点 优化算法: 常见的算法思路, 常见的数据结构 空间和时间的交换(哈希) 对数据进行预处理(排序) 在复杂度的瓶颈处寻找答案 在实际编写时, 要注意对极端条件的判断: 数组为空? 字符串为空? 数量为0? 指针为 nullptr? 变量名, 模块化, 复用性, 这些可以给面试官留下好印象 对于基本问题, 如实现堆, 二叉树等, 要做到可以白板变成. 第二章 面试中的复杂度分析2-1 大 O 记法大 O 记法: $n$ 表示数据规模, $O(f(n))$ 表示运行算法所需要执行的指令数, 和 $f(n)$ 成正比. $O(n^2)$ 不一定比 $O(n)$ 快, 如: $10000\times n$ 和 $10\times n^2$ 在学术界, 严格的讲, $O(f(n))$ 表示算法执行的上界. 但是在业界, 我们就用其表示算法执行的下界. (如归并排序, 在数据量不同时, 有时是 $O(nlogn)$, 有时是 $O(n^2)$, 但是, 在面试时, 我们就说是 $O(nlogn)$ 就可以) 虽然算法复杂度是用例相关的, 但是在面试中, 我们更在意的是平均的时间复杂度. 不会扣得特别细.(心里有数即可) 2-2 数据规模的概念对 $10^5$ 的数据进行选择排序, 结果计算机假死? (这很正常, $O(n^2)$ 算法需要 $10^10$ 次操作, 这大概需要几十秒, 而这会使得程序内存超限.) 如果要想在 1s 之内解决问题: $O(n^2)$ 的算法可以处理大约 $10^4$ 级别的数据. $O(n)$ 的算法可以处理大约 $10^8$ 级别的数据.(例如, 如果面试官说数据规模为一千万, 那么不用想, 我们的算法复杂度必须为 $O(n)$) $O(nlogn)$ 的算法可以处理大约 $10^7$ 级别的数据.(以上是对简单的操作而言, 如果单次的操作较复杂, 那么可以对上面的级别再低估一点, 如缩小10倍一般就没问题了) 空间复杂度: 需要注意的是递归空间的占用, 递归了多少次, 其占用的空间复杂度就大致为多少. 2-3 常见的复杂度分析注意循环语句的坏境. 注意下面双重循环的复杂度, 并不是 $O(n^2)$. 因为外层循环不是 $O(n)$, 而是 $O(logn)$.12345void hello(int n)&#123; for(int sz = 1; sz &lt; n; sz += sz) for(int i = 1; i &lt; n; i++) cout&lt;&lt;"hello"&lt;&lt;endl;&#125; 2-4 复杂度试验自以为写出了一个 $O(nlogn)$ 的算法, 但实际上是 $O(n^2)$ 的算法. (复杂度前面的常数有可能差距很大) 实验, 观察趋势. 每次将数据规模提高两倍, 看时间的变化. 第三章 数组中的问题其实最常见第四章 查找表相关问题第五章 在链表中穿针引线第六章 栈, 队列, 优先队列第七章 二叉树和递归第八章 递归和回溯法第九章 动态规划基础第十章 贪心算法]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>视频教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode算法题(Hard)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-3%2F</url>
    <content type="text"><![CDATA[004. Median of Two Sorted ArraysDescription: 寻找两个有序数组的中位数There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1:1234nums1 = [1, 3]nums2 = [2]The median is 2.0 Example 2:1234nums1 = [1, 2]nums2 = [3, 4]The median is (2 + 3)/2 = 2.5 解法一: 根据中位数的特性题目要求需要时间复杂度为 $O(log (m+n))$.空间复杂度: $O(1)$, 未使用额外空间 首先我们思考中位数的作用: 中位数可以将一个数组分成两个长度相同的部分, 并且一部分中的数字总比另一部分中的小. 那么对于两个数组的情况, 我们需要做的就是找到一个数字, 可以使这两个数组分别分成两部分, 这两部分长度相等(当个数为奇数时, 前一部分多一个元素), 同时前一部分的元素小于等于后一部分的元素. 首先,我们将数组 A 分成两部分, 由于 A 有 m 个数字, 所以它可以有 m 种不同的分法, 我们以下标 i 对应的数字为界限, 将A分成两部分, 前一部分的长度为 i (从0到 i-1 ), 后一部分的长度为 m-i (从 i 到 m-1): A[1,2,...,i-1] | A[i, i+1, ..., m-1]. 同理,数组 B 也可以做如下分割: B[1,2,...,j-1] | B[j, j+1, ..., n-1]. 这里需要注意一个细节, 我们需要确保 A[i] 这个数字可以将两个数组等长的分割, 那么 A 数组的长度 必须小于等于 B 数组的长度. 因为如果 A 数组的长度大于 B 数组的长度, 那么就会出现一种情况: A[i] 前的数字个数已经大于两数组总个数的一半, 此时无论如何也做不到等长分割, 因此, 我们需要先对数组长度判断, 令 A 数组代表的是较短的数组, 利用 swap() 方法可以在 $O(1)$ 时间复杂度内完成. 当两个数组 A 和 B 都被分到了两部分以后, 将它们合起来, 第一部分的数字为 A[1,2,...,i-1] 和 B[1,2,...,j-1], 第二部分的数字为 A[i, i+1, ..., m-1] 和 B[j, j+1, ..., n-1], 我们并不关系两部分内部的顺序, 我们只关心一件事, 那就是: 第一部分和第二部分的长度相等, 并且第一部分的数字都比第二部分小, 于是, i 和 j和取值就必须满足下列关系: i+j = m-i + n-j 或 m-i + n-j + 1 (加1的原因是因为有可能数组总长为奇数, 我们令前一部分比后一部分多1个元素) i=0 或 A[i-1] &lt;= B[j] (前者说明 A 中元素全部被分配到后半段, 即前半段元素均由 B 中元素组成) i=m 或 B[j-1] &lt;= A[i] (前者说明 A 中元素全部在前半段, 即后半段元素均由 B 中元素组成) 由于上式 i+j = m-i + n-j 或 m-i + n-j + 1 , 因此有 j = (m+n+1)/2 - i ; (向下取整). 故而可以只对 i 进行判断 i 是否越界, 只要 i 满足条件, j就不会等于0或n(前提条件是 A 数组长度小于等于 B 数组长度) 根据上面的分析, 解题过程如下: 根据两数组的长度, 将短的一方设为A数组 (j要对应较长的那个数组, 否则的话j有可能小于0 ), 令start=0, end=A.size 令 i=(start+end)/2 计算j = (m+n+1)/2 - i 判断当前 i 和 j 是否满足条件,有三种情况(对这三种情况不断重复, 直到i,j位置刚刚好): i &gt; 0 并且 A[i-1] &gt; B[j], 说明 i 的位置过大, 令 end = i-1. i &lt; m 并且 B[j-1] &gt; A[i], 说明 i 的位置过小, 令 start = i+1; 其他情况(i==0 或 A[i-1] &lt;= B[j] 并且 i==m 或 B[j-1] &lt;= A[i]), 说明 i 和 j的位置刚刚好. 当i,j位置刚好时, 根据数组整体长度的奇偶, 返回正确的中位数: 奇数: 返回前半段的最大元素 偶数: 返回前半段最大元素和后半段最小元素的平均值 非递归写法123456789101112131415161718192021222324252627282930313233class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &gt; nums2.size()) nums1.swap(nums2); int m = nums1.size(); int n = nums2.size(); int start = 0, end=m; while(start&lt;=end)&#123; //当 start = end 时, 此时 i=start=end, 不能忽略 int i = (start+end) / 2; int j = (n+m+1)/2 - i; if(i&gt;0 &amp;&amp; nums1[i-1] &gt; nums2[j]) //注意, i=0时说明位置恰好 end = i-1; //i太大 else if(i&lt;end &amp;&amp; nums2[j-1] &gt; nums1[i]) start = i+1; // i太小 else&#123; int leftmax;// 取左边最大的 if(i==0) leftmax=nums2[j-1]; else if(j==0) leftmax=nums1[i-1]; else leftmax = max(nums1[i-1], nums2[j-1]) ; if( (n+m)%2 == 1) return leftmax; int rightmin; // 取右边最小的 if(i==m) rightmin = nums2[j]; else if(j==n) rightmin = nums1[i]; else rightmin = min(nums1[i] ,nums2[j]); return (leftmax+rightmin) / 2.0; &#125; &#125; // return 0.0; //因为, 两数组不会同时为空, 所以这句话主要用于调试 &#125;&#125;; 递归写法写法一:123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &lt;= nums2.size()) return helper(nums1, 0 , nums1.size(),nums2); else return helper(nums2, 0 , nums2.size(),nums1); &#125; double helper(vector&lt;int&gt;&amp; nums1, int start1, int end1, vector&lt;int&gt;&amp; nums2)&#123; int i = (start1+end1)/2; int j = (nums1.size()+nums2.size()+1)/2 - i; // if(start1 &gt; end1) return 0.0; 因为数组一定是有效的, 因此不会出现这种情况 if( (i==0 || nums1[i-1]&lt;=nums2[j]) &amp;&amp; (i==nums1.size() || nums2[j-1]&lt;=nums1[i]))&#123; // 如果找到i int res11, res12; int res21, res22; // 首先将左边部分的两个数组分别赋值, 如果i或j为0, 说明对应数组在左边 //只有0个元素 , 将其赋值为INT_MIN(因为要取max(res11, res21)) if(i==0) res11= INT_MIN; else res11=nums1[i-1]; if(j==0) res21= INT_MIN; else res21=nums2[j-1]; //同理, 对右边进行处理, 取min(res12, res22) if(i==nums1.size()) res12= INT_MAX; else res12=nums1[i]; if(j==nums2.size()) res22= INT_MAX; else res22=nums2[j]; // 根据数组奇偶个数返回结果 if((nums1.size() + nums2.size())%2 == 1 )&#123; return max(res11, res21); &#125; else&#123; return ( max(res11,res21)+min(res12,res22) ) / 2.0; &#125; &#125;else if(nums1[i-1] &gt; nums2[j])&#123; return helper(nums1, start1, i-1, nums2); &#125;else&#123; return helper(nums1, i+1, end1, nums2); &#125; &#125;&#125;; 写法二: 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &gt; nums2.size()) return helper(nums2, nums1, 0, nums2.size()); else return helper(nums1, nums2, 0, nums1.size()); &#125; double helper(vector&lt;int&gt; &amp;nums1, vector&lt;int&gt; &amp;nums2, int start, int end)&#123; //if (start&gt;end) return 0.0; 因为数组一定是有效的, 因此不会出现这种情况 int m = nums1.size(); int n = nums2.size(); int i = (start+end)/2; int j = (m+n+1)/2 - i; if(i&gt;0 &amp;&amp; nums1[i-1] &gt; nums2[j]) return helper(nums1, nums2, start, i-1); else if(i&lt;m &amp;&amp; nums2[j-1] &gt; nums1[i]) return helper(nums1, nums2, i+1, end); else&#123; int leftmax; if(i==0) leftmax = nums2[j-1]; else if(j==0) leftmax = nums1[i-1]; else leftmax = max(nums1[i-1], nums2[j-1]); if((m+n)&amp;1 == 1) return leftmax; int rightmin; if(i==m) rightmin = nums2[j]; else if(j==n) rightmin = nums1[i]; else rightmin = min(nums1[i], nums2[j]); return (leftmax+rightmin)/2.0; &#125; &#125;&#125;; 010 Regular Expression MatchingDescription: 正则表达式匹配Given an input string (s) and a pattern (p), implement regular expression matching with support for ‘.’ and ‘*’. ‘.’ Matches any single character.‘*’ Matches zero or more of the preceding element.The matching should cover the entire input string (not partial). Note:s could be empty and contains only lowercase letters a-z.p could be empty and contains only lowercase letters a-z, and characters like . or *. Example 1:12345Input:s = &quot;aa&quot;p = &quot;a&quot;Output: falseExplanation: &quot;a&quot; does not match the entire string &quot;aa&quot;. Example 2:12345Input:s = &quot;aa&quot;p = &quot;a*&quot;Output: trueExplanation: &apos;*&apos; means zero or more of the precedeng element, &apos;a&apos;. Therefore, by repeating &apos;a&apos; once, it becomes &quot;aa&quot;. Example 3:12345Input:s = &quot;ab&quot;p = &quot;.*&quot;Output: trueExplanation: &quot;.*&quot; means &quot;zero or more (*) of any character (.)&quot;. Example 4:12345Input:s = &quot;aab&quot;p = &quot;c*a*b&quot;Output: trueExplanation: c can be repeated 0 times, a can be repeated 1 time. Therefore it matches &quot;aab&quot;. Example 5:1234Input:s = &quot;mississippi&quot;p = &quot;mis*is*p*.&quot;Output: false 解法一: 递归实现( 速度很慢, 只超过0.97%的提交)采用递归法, 首先判断当前字符串 p 是否已经走到尽头, 如果是, 则看 s 是否走到尽头, 返回 true 或者 false.然后在第一个字符的匹配情况, 并记录之.然后看是否存在 ‘‘, 并根据情况进行递归调用.若不存在 ‘‘, 则按正常匹配处理. 1234567891011121314151617181920212223class Solution &#123; bool helper(string &amp;s, int i, string &amp;p, int j) &#123; int n = s.size(), m = p.size(); if (j == m) return (i == n); bool firstMatch = (i != n and (s[i] == p[j] or p[j] == '.')); if (j &lt; m - 1 and p[j+1] == '*') &#123; //只有长度大于 2 的时候，才考虑 * //两种情况 //pattern 直接跳过两个字符。表示 * 前边的字符出现 0 次 //pattern 不变，例如 text = aa ，pattern = a* return helper(s, i, p, j+2) or (firstMatch and helper(s, i+1, p, j)); &#125; else &#123; // return firstMatch and helper(s, i+1, p, j+1); &#125; &#125;public: bool isMatch(string s, string p) &#123; return helper(s, 0, p, 0); &#125;&#125;; 解法二: 动态规划This problem has a typical solution using Dynamic Programming. We define the state P[i][j] to be true if s[0..i) matches p[0..j) and false otherwise. Then the state equations are: P[i][j] = P[i - 1][j - 1], if p[j - 1] != ‘*’ &amp;&amp; (s[i - 1] == p[j - 1] || p[j - 1] == ‘.’); P[i][j] = P[i][j - 2], if p[j - 1] == ‘*’ and the pattern repeats for 0 times; P[i][j] = P[i - 1][j] &amp;&amp; (s[i - 1] == p[j - 2] || p[j - 2] == ‘.’), if p[j - 1] == ‘*’ and the pattern repeats for at least 1 times. Putting these together, we will have the following code. 12345678910111213141516class Solution &#123;public: bool isMatch(string s, string p) &#123; bool dp[s.size()+1][p.size()+1]&#123;0&#125;; //!! 这里注意一定要初始化, 否则在下面的循环中, dp[2][0] 是循环不到的, 但是dp[2][2]会访问dp[2][0]的值, 如果不进行初始化, 就会发生 RuntimeError !!! dp[0][0]=true; for(int i =0; i&lt;s.size()+1; i++)&#123; for(int j = 1;j&lt;p.size()+1;j++)&#123; if(p[j-1] == '*') // 注意这里是j-1 dp[i][j] = ( j &gt; 1 &amp;&amp; dp[i][j-2] )|| ( i&gt;0 &amp;&amp; (s[i-1] == p[j-2] || p[j-2] == '.') &amp;&amp; dp[i-1][j]); // 注意这里是j-2, i-1, 一定要知道这些是为什 else dp[i][j] = i&gt;0 &amp;&amp; dp[i-1][j-1] &amp;&amp; (s[i-1] == p[j-1] || p[j-1] == '.'); &#125; &#125; return dp[s.size()][p.size()]; &#125;&#125;; 023. Merge k Sorted ListsDescription: 合并 k 个有序链表Merge k sorted linked lists and return it as one sorted list. Analyze and describe its complexity. Example:1234567Input:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 解法一: 基于比较的合并时间复杂度: $O(k \times N)$ k为需要合并和链表个数, 在比较时需要遍历k个链表的头结点, 以便找出最小的. 每插入一个节点, 就要重新遍历一次, 故需要遍历 $N$ 次, $N$ 为所有链表的节点总数.空间复杂度: $O(1)$ 将该问题看做是两个有序链表的合并问题, 只不过每次选择最小的节点时, 需要从vector.size()个节点中选择, 同时还要注意及时移除vector中已经走到头的空链表, 并判断size当前的大小, 当vector中的size大小为1时, 说明其余链表都已经合并完成, 此时退出循环, 直接将该链表接入即可. 另外要注意vector为空, 以及vector中全是nullptr链表的特殊情况. 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.size() == 0) return nullptr; //处理[]的情况 ListNode* dummy = new ListNode(0); ListNode* cur_node = dummy; while(lists.size() &gt; 1)&#123; int min_node_index = 0; for(int i = 0; i&lt;lists.size() ;i++)&#123; if(lists[i] == nullptr) &#123; lists.erase(lists.begin()+i); i--; //移除第i个元素后, 下一个元素会自动成为第i个元素,因此, 将当前i-- continue; // continue后, i会++, 最终i指向了下一个元素 &#125; if(lists[min_node_index]-&gt;val &gt; lists[i]-&gt;val)&#123; min_node_index = i; &#125; &#125; if(lists.size() == 0) return nullptr; //主要是应对 [[], []] 的情况, 本身vector的size大于0, 但是经过erase以后size就变成0了, 此时应返回nullptr cur_node-&gt;next = lists[min_node_index]; cur_node = cur_node-&gt;next; lists[min_node_index] = lists[min_node_index]-&gt;next; if(lists[min_node_index] == nullptr) lists.erase(lists.begin()+min_node_index); &#125; cur_node-&gt;next = lists[0]; return dummy-&gt;next; &#125;&#125;; 解法二: 用小顶堆对解法一的比较操作进行优化时间复杂度: $O(logk \times N)$, N 代表所有链表的节点总数.空间复杂度: $O(k)$ 由于要构造堆, 所以需要额外空间 由于我们只需要找到k个节点里面数值最小的那一个, 因此可以利用Priority Queue (实际上就是大顶堆和小顶堆)对上面的比较操作进行优化, 使得比较操作的复杂度从 $k$ 降到 $logk$. 由于每个节点都会进入小顶堆一次, 所有总共需要执行 $N$ 次入堆操作, 故最终的复杂度的 $logk\times N$. 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: // 用函数对象进行比较 struct cmp&#123; bool operator()(ListNode *node1, ListNode *node2)&#123; return node1-&gt;val &gt; node2-&gt;val; &#125; &#125;;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; priority_queue&lt;ListNode *, vector&lt;ListNode *&gt;, cmp&gt; min_heap; // 用 lambda 表达式进行比较 // auto cmp = [](ListNode* node1, ListNode* node2) &#123; // return node1-&gt;val &gt; node2-&gt;val; // 小顶堆 // &#125;; //priority_queue&lt;ListNode *, vector&lt;ListNode *&gt;, decltype(cmp)&gt; min_heap(cmp); for(auto node_head : lists) if(node_head!=nullptr) min_heap.push(node_head); if(min_heap.empty()) return nullptr; ListNode *dummy = new ListNode(0); ListNode *cur = dummy; while(!min_heap.empty())&#123; ListNode *tmp = min_heap.top(); min_heap.pop(); cur-&gt;next = tmp; cur = cur-&gt;next; if(tmp-&gt;next != nullptr) min_heap.push(tmp-&gt;next); &#125; return dummy-&gt;next; &#125;&#125;; 解法三: 转化成双列表合并问题时间复杂度: $O(k \times N)$空间复杂度: $O(1)$ 双列表合并问题的时间复杂度为 $O(m+n)$ , 可以将多链表合并问题看做是k次双列表合并. 解法四: 对解法三进行优化时间复杂度: $O(logk \times N)$空间复杂度: $O(1)$ 对列表合并时, 每次都是两两合并(不是解法三中的逐一合并), 这样, 只需要经过 $logk$ 次两两合并就可完成所有合并过程. 迭代实现:12345678910111213141516171819202122232425262728293031323334class Solution &#123;private: ListNode* mergeTwoLists(ListNode *l1, ListNode *l2)&#123; ListNode *dummy = new ListNode(0); ListNode *cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur = cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l1==nullptr) cur-&gt;next = l2; else cur-&gt;next = l1; return dummy-&gt;next; &#125;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.empty()) return nullptr; int len = lists.size(); int interval = 1; while(interval &lt; len)&#123; for(int i=0; i+interval&lt;len; i+= 2*interval)&#123;//i应满足: 0,2,4... / 0,4,.. / 0 lists[i] = mergeTwoLists(lists[i], lists[i+interval]);//i+interval必须&lt;len, 否则溢出 &#125; interval *= 2; //区间大小翻倍 &#125; return lists[0]; &#125;&#125;; 递归实现: 递归实现需要额外的 $O(logk)$ 的栈空间(调用递归的次数)12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: ListNode* mergeTwoLists(ListNode *l1, ListNode *l2)&#123; ListNode *dummy = new ListNode(0); ListNode *cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur = cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l1==nullptr) cur-&gt;next = l2; else cur-&gt;next = l1; return dummy-&gt;next; &#125; ListNode* partition(vector&lt;ListNode*&gt;&amp; lists, int start, int end)&#123; if(start==end)&#123; return lists[start]; &#125;else if(start &lt; end)&#123; int mid = (start+end)/2; ListNode* l1 = partition(lists, start, mid); ListNode* l2 = partition(lists, mid+1, end); return mergeTwoLists(l1, l2); &#125;else return nullptr; &#125;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.empty()) return nullptr; return partition(lists, 0, lists.size()-1); &#125;&#125;; 将双链表合并也写成递归形式:123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: ListNode* mergeTwoLists(ListNode *l1, ListNode *l2)&#123; if(l1==nullptr) return l2; else if(l2==nullptr) return l1; else if(l1-&gt;val &lt; l2-&gt;val)&#123; l1-&gt;next = mergeTwoLists(l1-&gt;next, l2); return l1; &#125;else&#123; l2-&gt;next = mergeTwoLists(l1, l2-&gt;next); return l2; &#125; &#125; ListNode* partition(vector&lt;ListNode*&gt;&amp; lists, int start, int end)&#123; if(start==end)&#123; return lists[start]; &#125;else if(start &lt; end)&#123; int mid = (start+end)/2; ListNode* l1 = partition(lists, start, mid); ListNode* l2 = partition(lists, mid+1, end); return mergeTwoLists(l1, l2); &#125;else return nullptr; &#125;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; if(lists.empty()) return nullptr; return partition(lists, 0, lists.size()-1); &#125;&#125;; 041. First Missing Positive寻找数组中缺失的最小的正数 DescriptionGiven an unsorted integer array, find the smallest missing positive integer. Example 1: Input: [1,2,0]Output: 3Example 2: Input: [3,4,-1,1]Output: 2Example 3: Input: [7,8,9,11,12]Output: 1Note: Your algorithm should run in O(n) time and uses constant extra space. 解法一: 下标与正数对应时间复杂度: $O(n)$空间复杂度: $O(1)$ (但是对改变了原始的数组, 这是一个小缺陷) 将下标与正数相应对, 例如对于正数5, 我们就将放置在nums[4]上, 这样一来, 再次遍历数组的时候, 当遇到第一个与下标不对应的数字时, 该下标对应的正数(i+1)就是缺少的正数. 放置正数到正确位置上时, 需要注意几点: swap之后需要继续将原来位置上(nums[4])的数放置到正确的位置上, 这里需要一个while循环 在检查数组时, 如果所有数组内所有数字都处在正确位置上, 那么就应该返回nums.size+1 (包括了数组为空的情况: 返回0+1=1) 写法一: for+while 123456789101112131415class Solution &#123;public: int firstMissingPositive(vector&lt;int&gt;&amp; nums) &#123; for(int i = 0; i &lt; nums.size(); i++)&#123; // 注意这些条件: 前两个是为了令交换下标合法, 后一个是防止相同的数交换, 造成死循环 while(nums[i] &gt; 0 &amp;&amp; nums[i]&lt;nums.size() &amp;&amp; nums[i] != nums[nums[i]-1]) std::swap(nums[i], nums[nums[i]-1]); &#125; for(int i =0; i&lt;nums.size(); i++)&#123; if(nums[i] != i + 1) return i+1; &#125; return nums.size()+1; &#125;&#125;; 写法二: while1234567891011121314151617class Solution &#123;public: int firstMissingPositive(vector&lt;int&gt;&amp; nums) &#123; int i = 0; while(i&lt;nums.size())&#123; if(nums[i] &gt; 0 &amp;&amp;nums[i]&lt;nums.size() &amp;&amp; nums[i] != nums[nums[i]-1]) std::swap(nums[i], nums[nums[i]-1]); // 如果进行了swap, 就不要i++ else i++; &#125; for(int i =0; i&lt;nums.size(); i++)&#123; if(nums[i] != i + 1) return i+1; &#125; return nums.size()+1; &#125;&#125;; 解法二: 哈希时间复杂度: $O(n)$ (3次for循环, 毫无争议的 $O(n)$ )空间复杂度: $O(1)$ (但是对改变了原始的数组, 这是一个小缺陷) 注意: 虽然这里的时间复杂度是毫无争议的 $O(n)$ , 但是不一定会上面的速度快, 因为上面只有两次循环, 内第一次内部的循环次数一般情况下都不会很大. 从哈希的角度理解: 可以将数组下标看成是hash的key for any array whose length is l, the first missing positive must be in range [1,…,l+1], so we only have to care about those elements in this range and remove the rest. we can use the array index as the hash to restore the frequency of each number within the range [1,…,l+1] 123456789101112131415161718192021222324class Solution &#123;public: int firstMissingPositive(vector&lt;int&gt;&amp; nums) &#123; // 丢失的最小正数只可能在 [1,2,...,nums.size()+1] 之间 // 这里的pushback是必须的, 因为下面会将不符合要求的元素都置为0, //因此nums[0]需要与0对应, 以代表所有的非法元素, //这点与上面基于swap的方法不同, 上面的swap是让nums[0] 与 1 对应. nums.push_back(0); int length = nums.size(); for(int i =0 ; i&lt;length; i++)&#123; if(nums[i] &lt; 0 || nums[i] &gt;= length) nums[i] = 0; // 将所有不符合丢失正数的数移除, 这一步必须单独用一个for循环做 &#125; for(int i = 0; i&lt;length; i++)&#123; nums[nums[i]%length] += length; &#125; for(int i = 1 ; i&lt;length; i++)&#123; if(nums[i]/length == 0) return i; &#125; return length; &#125;&#125;; 042 Trapping Rain Water数组中每个值代表柱状体的高度, 每个柱状体的宽度都为1, 根据数组内的值组成的高低不同的块, 能够存储多少个bin (1×1)的水 DescriptionGiven n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. Thanks Marcos for contributing this image! Example: Input: [0,1,0,2,1,0,1,3,2,1,2,1]Output: 6 解法一: 左右指针时间复杂度: $O(n)$空间复杂度: $O(1)$ 分别用两个变量left和right指向左边和右边的柱子, 并再用两个变量maxleft和maxright维护左边最高的柱子和右边最高的柱子, 统计的时候, 先固定left和right当中柱子高度较高的那一个, 然后统计较低柱子上存储的水量. 利用, 如果当前left的高度小于right的高度, 则我们计算left上面能够存储的水量, 有两种情况, 当left柱子的高度大于等于maxleft时, 则left柱子上没法存储水, 因为谁会从左边全部流失(右边比左边高, 所以不会从右边流失). 如果left的高度小于maxleft时, 由于水无法从左边流失, 也不能从右边流失, 因此当前柱子上就会存储水, 存储的水量为maxleft-height[left] (不考虑maxright, 因为maxright大于maxleft). 注意: 此题中的柱子是有 宽度 的, 这一点很重要, 如果柱子的宽度为0 , 那么就是另一种情况了. 1234567891011121314151617181920class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; int len = height.size(); int left = 0, right = len-1; int res = 0, maxleft = 0, maxright = 0; while(left &lt;= right)&#123; if(height[left] &lt;= height[right])&#123; //固定较大的一个柱子 if(height[left] &gt; maxleft) maxleft = height[left];// 如果当前柱子的高度大于左边max柱子的高度, 那么该柱子所处位置一定存不下水 else res = res + maxleft - height[left]; // 反之, 该柱子位置上可以存储的水的量为 坐标max高度减去当前的高度 left++; &#125;else&#123; if(height[right] &gt; maxright) maxright = height[right]; else res = res + maxright - height[right]; right--; &#125; &#125; return res; &#125;&#125;; 更简洁的写法:123456789101112131415161718192021class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; if (height.empty()) return 0; int left = 0, right = height.size() -1; int maxLH = height[left], maxRH = height[right]; int res = 0; while (left &lt; right) &#123; maxLH = std::max(maxLH, height[left]); maxRH = std::max(maxRH, height[right]); if (height[left] &lt; height[right]) &#123; res += maxLH - height[left]; left++; &#125; else &#123; res += maxRH - height[right]; right--; &#125; &#125; return res; &#125;&#125;; 044. Wildcard MatchingDescription: 通配符匹配Given an input string (s) and a pattern (p), implement wildcard pattern matching with support for ‘?’ and ‘*’. ‘?’ Matches any single character.‘*’ Matches any sequence of characters (including the empty sequence).The matching should cover the entire input string (not partial). Note: s could be empty and contains only lowercase letters a-z.p could be empty and contains only lowercase letters a-z, and characters like ? or *.Example 1: Input:s = “aa”p = “a”Output: falseExplanation: “a” does not match the entire string “aa”.Example 2: Input:s = “aa”p = ““Output: trueExplanation: ‘‘ matches any sequence.Example 3: Input:s = “cb”p = “?a”Output: falseExplanation: ‘?’ matches ‘c’, but the second letter is ‘a’, which does not match ‘b’.Example 4: Input:s = “adceb”p = “ab”Output: trueExplanation: The first ‘‘ matches the empty sequence, while the second ‘‘ matches the substring “dce”.Example 5: Input:s = “acdcb”p = “a*c?b”Output: false 解法一: 迭代时间复杂度: $O(m+n)$空间复杂度: $O(1)$ 对于每次循环迭代, i和j其中至少有一个前进一步, 所以时间复杂度为 $O(m+n)$. 1234567891011121314151617181920212223242526272829class Solution &#123;public: bool isMatch(string s, string p) &#123; int n = s.size(); int m = p.size(); int i = 0, j = 0; int star_index = -1, match = -1; while (i &lt; n) &#123; if (j &lt; m and (s[i] == p[j] or p[j] == '?')) &#123; // 单个字符匹配, i, j继续匹配下一个 i++; j++; &#125; else if (j &lt; m and p[j] == '*') &#123; star_index = j; // 如果当前字符为 *, 则有可能如0或若干个字符匹配, 首先假设至于0个字符匹配 match = i; // 只与0个字符匹配时, 记录当前i的值, 然后将j++, i不变 j++; &#125; else if (star_index != -1) &#123; // 如果前面两个条件都不满足, 说明之间的匹配方法不正确, 此时重新从前一个 * 开始匹配 match++; // 令 * 与之前标记的未匹配的i进行匹配, 然后将标记往后移一位 i = match; // 令 i 和 j 都等于下一个字符, 继续匹配过程 j = star_index+1; &#125; else &#123; return false; &#125; &#125; for (int jj = j ; jj &lt; m; jj++) &#123; // 当 i==n 退出循环时, j 有可能还未达到m, 因为有可能是 ***** 的形式 if (p[jj] != '*') return false; &#125; return true; &#125;&#125;; 解法二: DP时间复杂度: $O(nm)$, $n$ 为s的长度, $m$ 为p的长度空间复杂度: $O(n)$ 12345678910111213141516171819class Solution &#123;public: bool isMatch(string s, string p) &#123; int pLen = p.size(), sLen = s.size(), i, j, k, cur, prev; if(!pLen) return sLen == 0; bool matched[2][sLen+1]; fill_n(&amp;matched[0][0], 2*(sLen+1), false); matched[0][0] = true; for(i=1; i&lt;=pLen; ++i) &#123; cur = i%2, prev= 1-cur; matched[cur][0]= matched[prev][0] &amp;&amp; p[i-1]=='*'; if(p[i-1]=='*') for(j=1; j&lt;=sLen; ++j) matched[cur][j] = matched[cur][j-1] || matched[prev][j]; else for(j=1; j&lt;=sLen; ++j) matched[cur][j] = matched[prev][j-1] &amp;&amp; (p[i-1]=='?' || p[i-1]==s[j-1]) ; &#125; return matched[cur][sLen]; &#125;&#125;; 解法三: DP时间复杂度: $O(nm)$, $n$ 为s的长度, $m$ 为p的长度空间复杂度: $O(nm)$ 采用和第 10 题相同的思路, 令dp[i][j]代表s[0, i)和p[0,j)是否匹配, 该解法的空间复杂度比解法二高. 123456789101112131415161718192021class Solution &#123;public: bool isMatch(string s, string p) &#123; int n = s.size(); int m = p.size(); bool dp[n+1][m+1]; std::fill_n(&amp;dp[0][0], (n+1)*(m+1), false); // 用 fill_n 初始化 dp[0][0] = true; for (int i = 0; i &lt; n+1; i++) &#123; for (int j = 1; j &lt; m+1; j++) &#123; if (p[j-1] == '*') &#123; dp[i][j] = (i &gt; 0 and dp[i-1][j]) or (dp[i][j-1]); &#125; else &#123; dp[i][j] = i &gt; 0 and dp[i-1][j-1] and (s[i-1] == p[j-1] or p[j-1] == '?'); &#125; &#125; &#125; return dp[n][m]; &#125;&#125;; 076. Minimum Window Substring求包含子串字符的最小窗口 DescriptionGiven a string S and a string T, find the minimum window in S which will contain all the characters in T in complexity O(n). Example: Input: S = “ADOBECODEBANC”, T = “ABC”Output: “BANC”Note: If there is no such window in S that covers all characters in T, return the empty string “”.If there is such window, you are guaranteed that there will always be only one unique minimum window in S. 解法: 两个变量记录当前窗口大小时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617181920class Solution &#123;public: string minWindow(string s, string t) &#123; vector&lt;int&gt; hmap(256,0); for(auto c:t) hmap[int(c)]++; int count = t.size(), begin=0, end=0, head=0, cur_window=INT_MAX; while(end&lt;s.size())&#123; // 这里可以直接写成 if(hmap[int(s[end++])]-- &gt; 0) count--; 但是可读性很差, 不建议这样写. if(hmap[int(s[end])] &gt; 0) count--; hmap[int(s[end])]--; end++; while(count==0)&#123; //end 超尾 if( (end-begin) &lt; cur_window) cur_window = end - (head=begin); // 同样, 可以直接写成 if(hmap[int(s[begin++])]++ &gt; 0) count++; 但是可读性很差 if(hmap[int(s[begin])] == 0) count++; hmap[int(s[begin])]++; begin++; &#125; &#125; return cur_window==INT_MAX ? "" : s.substr(head, cur_window); &#125;&#125;; 子串相关题目的模板解法https://leetcode.com/problems/minimum-window-substring/discuss/26808/Here-is-a-10-line-template-that-can-solve-most-&#39;substring&#39;-problems 对于大多数的子串相关的问题, 通常可以描述为给定一个字符串, 要求找到满足某些限制条件的子串, 这类都可以用下面的基于哈希表和两个辅助指示变量的模板来求解: 123456789101112131415161718192021int findSubstring(string s)&#123; vector&lt;int&gt; hmap(128,0); int count; // 用于检查子串是否合法 int begin=0, end=0; // 两个指示变量, 分别指向子串的头和尾(end会在++后退出循环, 因此最后end会变成超尾) int len_sub; // 子串的长度 for()&#123; &#125;//对hasp map进行初始化 while(end&lt;s.size())&#123; //if(hmap[s[end++]]-- ? ) &#123; &#125; //修改count //上面的语句可读性很差, 最后拆开来写, 后面也同理, 拆开写 if(hmap[int(s[end])] ? ) &#123; &#125; //修改count hmap[int(s[end])]--; //注意顺序 end++; while( count? )&#123; // 检查count是否满足条件 // update len_sub if(hmap[int(s[begin])] ?) &#123; &#125; //修改count hmap[int(s[begin])]++; begin++; &#125; &#125;&#125; 例如, 对于问题 Longest Substring At Two Distinct Characters 的模板解法如下: 对于问题 Longest Substring Without Repeating Characters 的模板解法如下:12345678910int lengthOfLongestSubstring(string s)&#123; vector&lt;int&gt; map(256,0); int begin=0,end=0,len_sub=0,count=0; while(end&lt;s.size())&#123; if(map[int(s[end])] &gt; 0) count++; map[int(s[end])]++; end++; while(count&gt;0) if(map[int(s[begin])] &gt; 1) count; &#125;&#125; 084. Largest Rectangle in Histogram求最大面积的矩形 DescriptionGiven n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Example:Input: [2,1,5,6,2,3]Output: 10 解法一: 穷举时间复杂度: $O(n^2)$, 超时空间复杂度: $O(1)$ 列出以每一个i上的值为矩形高度的矩形面积, 然后取得最大值12345678910111213141516171819class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; int max_area = 0; for(int i =0; i&lt;heights.size(); i++)&#123; int low = i; while(low&gt;=0 &amp;&amp; heights[low] &gt;=heights[i]) low--; low++; int high = i; while(high&lt;heights.size() &amp;&amp; heights[high] &gt;= heights[i]) high++; high--; int cur_area = heights[i]* (high-low+1); if(max_area&lt;cur_area) max_area = cur_area; &#125; return max_area; &#125;&#125;; 解法二: 解法一的改进-空间换时间时间复杂度: $O(n)$, 前面省略常数项(因为不好确定常数项的值)空间复杂度: $O(2n)$ 从解法一中我们可以看出, 核心的要点就在于求取每一个i对应的矩形的左端和右端, 如下图所示: 那么, 如果我们可以在 $O(1)$ 的时间内获取到左端和右端的值, 则时间复杂度就可以降低到 $O(n)$, 因此, 首先想到的是用数组将每个i对应的左端和右端的值保存起来. 于是, 我们需要先求取这两个数组(左端,右端)的值, 在对左端和右端求值时, 我们要确保时间复杂度不能超过 $O(n)$, 因此, 我们不能每次都重新从i出发分别向左向右遍历(如解法一那样), 反之, 我们可以利用左端和右端中已经求好的值, 对于左端来说, 我们可以利用左端数组跳跃式的向左前进, 对于右端来说, 我们可以利用右端数组跳跃式的向右前进(这里不太好用语言描述, 具体请看程序代码). 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; int *left = new int[heights.size()]; int *right = new int[heights.size()]; left[0]=-1; for(int i=1; i&lt;heights.size(); i++)&#123; int p = i-1; while(p&gt;=0 &amp;&amp; heights[p] &gt;= heights[i]) p = left[p]; left[i] = p; &#125; right[heights.size()-1] = heights.size(); for(int i=heights.size()-2; i&gt;=0; i--)&#123; int p = i+1; while(p&lt;heights.size() &amp;&amp; heights[p] &gt;= heights[i]) p = right[p]; right[i] = p; &#125; int max_area = 0; for(int i =0; i&lt;heights.size(); i++)&#123; int low = left[i]; int high = right[i]; int cur_area = heights[i]*(high-low-1); if(max_area&lt;cur_area) max_area = cur_area; &#125; return max_area; &#125;&#125;; 解法三: 最优-栈时间复杂度: $O(n)$, 无常数项空间复杂度: $O(n)$, 无常数项 上面的解法二, 虽然时间复杂度为 $O(n)$, 但实际上其时间复杂度是略微高于 $O(n)$, 因为在求取左端右端时, 每次跳跃的次数是大于等于1, 而不是仅为1次的.(只不过大O记法不考虑常数项). 而对于空间复杂度来说, 实际上是 $O(2n)$. 下面我们从另外一个角度出发: 不再以当前i对应的高度为最低, 向左右两边探索, 改为以当前i对应的高度为最低, 仅仅向左边探索, 实现算法如下: 首先, 构造一个空栈 从heights数组的第一个bar开始, 遍历所有的bar值(0~n-1), 并执行以下逻辑: 如果当前栈为空, 或者当前数组bar值大于等于栈顶bar值, 则将bar值下标入栈 否则, 将栈顶出栈, 并以栈顶下标对应的bar值作为最低的高度, 求该高度对应的面积, 因为当前数组bar值小于栈顶下标对应的bar值, 因此可以将当前bar值下标作为right_index, 又因为栈顶bar值下标的前一个元素, 要么小于栈顶, 要么等于栈顶, 不论哪种情况, 都可以将其下标作为left_index(因为栈顶退出对, 次栈顶就会成为新的栈顶, 所以可以包括bar值相等的情况), 得到了高度, right_index, left_index, 即可计算当前栈顶对应的面积, 并与max_area判断, 更新max_area的值 最后, 如果遍历完以后栈顶不为空(说明后面有几个连续的bar值相等, 或者bar只呈递增排序), 则依次强制弹出栈顶计算面积, 并更新max_area. 复杂度分析: 由于入栈出栈的元素仅为heights数组元素, 可以栈的size就是heights数组的大小, 即空间复杂度为 $O(n)$, 时间复杂度从代码中可看出约为 $O(n)$. 1234567891011121314151617181920212223242526272829class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; std::stack&lt;int&gt; s; int max_area = 0; int cur_area = 0; int height_index=0; int i=0; while(i&lt;heights.size())&#123; if(s.empty() || heights[i] &gt;= heights[s.top()]) s.push(i++); else&#123; height_index = s.top(); s.pop(); cur_area = heights[height_index] * ( s.empty()? i : i-s.top()-1 ); // 注意, 如果栈为空, 则说明当前i对应的bar值是前i个bar值中最小的, 所以宽为i, 否则宽为i-s.top()-1 if(cur_area &gt; max_area) max_area = cur_area; &#125; &#125; while(!s.empty())&#123; height_index = s.top(); s.pop(); cur_area = heights[height_index] * ( s.empty()? i : i-s.top()-1 ); // 注意, 如果栈为空, 则说明当前i对应的bar值是前i个bar值中最小的, 所以宽为i, 否则宽为i-s.top()-1 if(cur_area &gt; max_area) max_area = cur_area; &#125; return max_area; &#125;&#125;; 124. Binary Tree Maximum Path Sum求二叉树中, 以任意节点为起始的路径和(这里是将二叉树看成无向图来计算路径的)的最大值, 例如对于下面的二叉树, 具有最大值的为:2-&gt;1-&gt;3 = 6123 1 / \2 3 Description: 求最长路径加权和Given a non-empty binary tree, find the maximum path sum. For this problem, a path is defined as any sequence of nodes from some starting node to any node in the tree along the parent-child connections. The path must contain at least one node and does not need to go through the root. Example 1:12345Input: [1,2,3] 1 / \ 2 3Output: 6 Example 2:1234567Input: [-10,9,20,null,null,15,7] -10 / \ 9 20 / \ 15 7Output: 42 解法一: 递归这道题的难点在于能否解读出题目的求值过程实际上是一个后序遍历的过程. 对于本题来说, 我们需要求得每个节点所在的路径的最大值, 以下面的例子来说:12345 4 / \ 11 13 / \7 2 我们需要求的最大和的路径为: 7-&gt;11-&gt;4-&gt;13. 而根据二叉树的遍历性质, 我们假设现在已经遍历到节点7, 此时, 左右子树均为空, 所以左右子树的最大和为0, 那么此时节点7所在的路径的最大和为: 左子树+右子树+当前节点值 = 7. 然后, 回溯到了节点11, 此时同理, 节点11所在的路径的最大和为: 左子树+右子树+当前节点值 = 11.(忽略节点2的遍历过程). 接下来对于节点4, 同理也应为: 左子树+右子树+当前节点值. 右子树返回的值很容易看出是13, 但是左子树应该返回多少呢? 由于我们希望求得当前的最大和, 因此, 左子树就应该返回它的最大和, 但是, 不能统计两条路径, 而应该选择以左节点为根节点的左右子树的较大者, 因此, 应该返回的是: max(左节点左子树, 左节点右子树)+左节点的值, 因此, 返回的是: 7+11 = 18. 于是, 节点4对应的最大和就为: 18+13+4. 可以看到, 这实际上就是一个后序遍历的过程. 12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int maxPathSum(TreeNode* root) &#123; int res=INT_MIN; helper(root, res); return res; &#125; int helper(TreeNode* cur_node, int &amp;res)&#123; if(cur_node==nullptr) return 0; int left = std::max(helper(cur_node-&gt;left, res), 0); int right = std::max(helper(cur_node-&gt;right, res), 0); res = std::max(res, left+right+cur_node-&gt;val); return std::max(left, right)+cur_node-&gt;val; &#125;&#125;; 解法二: 迭代后序遍历的迭代实现 128. Longest Consecutive Sequence返回无序数组中, 可以组成的最长的连续子串的长度 DescriptionGiven an unsorted array of integers, find the length of the longest consecutive elements sequence. Your algorithm should run in O(n) complexity. Example: Input: [100, 4, 200, 1, 3, 2]Output: 4Explanation: The longest consecutive elements sequence is [1, 2, 3, 4]. Therefore its length is 4. 解法一: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 先排序, 然后在从头往后遍历, 并用一个变量维护当前的最长连续序列的长度. 解法二: 利用哈希表时间复杂度: $O(n)$空间复杂度: $O(n)$ 利用 unordered_set 将所有的数字存储起来, 然后遍历每一个数字 num, 查看这个数字是否为所在连续序列的开头(即查看 num-1 是否存在). 若 num 就是所在连续序列的开头, 则查看当前序列的长度, 并更新最大长度. 故而时间复杂度为 $O(n+n) = O(n)$. 同时, 因为使用了 unordered_set, 所以空间复杂度为 $O(n)$.123456789101112131415161718class Solution &#123;public: int longestConsecutive(vector&lt;int&gt;&amp; nums) &#123; unordered_set&lt;int&gt; sets(nums.begin(), nums.end()); int longest = 0; for(auto num : sets)&#123; if(sets.find(num-1) == sets.end())&#123; int cur_len = 1; while(sets.find(num+1) !=sets.end())&#123; num++; cur_len++; &#125; if(longest &lt; cur_len) longest = cur_len; &#125; &#125; return longest; &#125;&#125;; 解法三: 另一种哈希表用法时间复杂度: $O(n)$空间复杂度: $O(n)$ 主题思想与解法二相同, 不过是从另一角度来使用 unordered_map, 首先, 依然利用 unordered_map 将 nums 存储起来, 然后遍历 nums, 对于 nums 中的每一个 num, 查看其是否存在于 unordered_map 中, 如果存在, 则分别向左向右查找当前数字 num 所在序列的最左端和最右端的数字, 同时, 将在 unordered_map 中遍历过的数字都移除(因为每个数字只可能唯一的属于一个连续序列). 之后, 利用最左端和最右端来更新最长连续序列的长度. 这样, 遍历的时间复杂度也为 $O(n+n) = O(n)$ 12345678910111213141516171819class Solution &#123;public: int longestConsecutive(vector&lt;int&gt;&amp; nums) &#123; unordered_set&lt;int&gt; sets(nums.begin(), nums.end()); int longest = 0; for(auto num : nums)&#123; if(sets.find(num)!=sets.end())&#123; sets.erase(num); int pre = num-1, next = num+1; while(sets.find(pre)!=sets.end()) sets.erase(pre--); while(sets.find(next)!=sets.end()) sets.erase(next++); if(longest &lt; next-pre) longest = next-pre-1; &#125; &#125; return longest; &#125;&#125;; 140. Word Break IIDescriptionGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, add spaces in s to construct a sentence where each word is a valid dictionary word. Return all such possible sentences. Note: The same word in the dictionary may be reused multiple times in the segmentation.You may assume the dictionary does not contain duplicate words.Example 1: Input:s = “catsanddog”wordDict = [“cat”, “cats”, “and”, “sand”, “dog”]Output:[ “cats and dog”, “cat sand dog”]Example 2: Input:s = “pineapplepenapple”wordDict = [“apple”, “pen”, “applepen”, “pine”, “pineapple”]Output:[ “pine apple pen apple”, “pineapple pen apple”, “pine applepen apple”]Explanation: Note that you are allowed to reuse a dictionary word.Example 3: Input:s = “catsandog”wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]Output:[] 解法一: DP直接使用回溯法, 有大量重复计算, 导致时间超时, 无法通过 OJ, 因此考虑 DP 思想. 将中间的计算结果缓存起来, 再次遇到的时候无需重复计算, 只需直接使用即可.利用一个哈希表将每个字符串与该字符串能拆分出的句子联系起来, 其中, key 为字符串, value 为字符串拆分后的句子. 假设我们已经求出一个字符串的解为 res, 并将其存入到哈希表中, 此时, 如果在该字符串的前面再加上一个单词(单词表的中任意一个), 那么新的解就应该为: word+&quot; &quot;+res[i]. 代码实现如下. 注意, 这里我们要对 wordDict 进行遍历来查找可以拆分的情况, 如果是对字符串 s 查找可拆分情况, 那么哈希表中的键将会大幅增加, 例如对于&quot;aaaaaaaaaaa&quot;这种情况. 12345678910111213141516171819202122class Solution &#123;public: vector&lt;string&gt; wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_map&lt;string, vector&lt;string&gt;&gt; hash_dict; return DP_helper(s, wordDict, hash_dict); &#125; vector&lt;string&gt; DP_helper(string s, vector&lt;string&gt; &amp;wordDict, unordered_map&lt;string, vector&lt;string&gt;&gt; &amp;hash_dict)&#123; if(hash_dict.find(s)!=hash_dict.end()) return hash_dict[s]; if(s=="") return &#123;""&#125;; //这里必须返回具有一个元素("")的vector, 否则下面的push_back语句不会执行 vector&lt;string&gt; res; for(auto word : wordDict)&#123; if(s.substr(0, word.size()) != word) continue; vector&lt;string&gt; res_word = DP_helper(s.substr(word.size()), wordDict, hash_dict); //s.substr(word.size()) 代表截取剩余的字符, 所以有可能出现空字符的情况 for(auto str : res_word)&#123; // 如果返回的是空的vector, 则不会执行该语句, 因此, 不能返回空vector, 当遇到空字符串时, 因该返回 &#123;""&#125;, 即只有一个元素的vector, 该元素为"". res.push_back(word + (str==""? "":" ") + str); //这里根据 str的值来决定是否加空格, 如果str为空, 说明是word是最后一个字符, 则其后不应该添加空格 &#125; &#125; hash_dict[s] = res; return res; &#125;&#125;; 内存超限的写法: 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;string&gt; wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_map&lt;string, vector&lt;string&gt;&gt; hash; for (int i = 0; i &lt; s.size(); i++) &#123; vector&lt;string&gt; res; for (auto const&amp; word : wordDict) &#123; int lenW = word.size(); if (i+1 &gt;= lenW and s.substr(i-lenW+1, lenW) == word) &#123; if (i+1 == lenW) &#123; res.push_back(word); &#125; else &#123; string tmp_s = s.substr(0, i-lenW+1); if (hash.find(tmp_s) != hash.end()) &#123; auto tmp_words = hash[tmp_s]; for (auto str : tmp_words) &#123; res.push_back(str + " " + word); &#125; &#125; &#125; &#125; &#125; hash[s.substr(0, i+1)] = res; &#125; if (hash.find(s) != hash.end()) return hash[s]; return &#123;""&#125;; &#125;&#125;; 149. Max Points on a LineDescription 最大的共线点个数Given n points on a 2D plane, find the maximum number of points that lie on the same straight line. Example 1: Input: [[1,1],[2,2],[3,3]]Output: 3Explanation:^|| o| o| o+——————-&gt;0 1 2 3 4Example 2: Input: [[1,1],[3,2],[5,3],[4,1],[2,3],[1,4]]Output: 4Explanation:^|| o| o o| o| o o+—————————-&gt;0 1 2 3 4 5 6 解法一: 哈希表时间复杂度: $O(n^2)$, 求取任意两点间的斜率空间复杂度: $O(n)$, 哈希表, 存储斜率 由于要求共线点个数, 就必须获取任意两点间的斜率, 因此, 时间复杂度最少为 $O(n^2)$. 算法流程如下: 对于每一个点来说, 构造一个哈希表, 表中的键为斜率, 表中的值为对应斜率的点的个数, 这里注意, 当我们求完第i个点与第j个点之间的斜率之后, 就不用再求第j个点与第i个点之间的斜率情况了(即令int j = i+1, 而不是int j = 0) 对于重点的情况, 需要单独设置一个变量来记录, 之后将该重复次数加入到该点所在的每条直线上(因为重点也算是共线) 对于斜率不存在的情况, 可以考虑利用INT_MAX来作为键值 精度: 在求取斜率时, 会进行除法, 而在计算机内部, 除法在精度上始终会有一定误差, 会造成斜率相同的两对点在计算成浮点数以后斜率不同, 因此, 要 避免使用除法, 解决办法是利用 最大公约数, 求取y2-y1与x2-x1之间的最大公约数, 然后对进行约分, 用约分后的值作为键来存储, 就不会造成精度上的损失, 但是, 此时需要用pair作为键, 故不能用unordered_map(C++没有为pair类型提供对应的哈希函数), 而只能用map(键只有重载了&lt;和&gt;就可以使用map, 搜索的时间复杂度为 $O(logn)$), 另一种可选做法是利用string类型, 将两个int数值转换成string后再拼接, 此时就可以使用unordered_map了(搜索的时间复杂度为 $O(1)$, 但是int和string的类型转换也需要消耗时间). 当采用公约数以后, 因为没有了除法, 因此可以不用特殊处理斜率不存在的情况, 代码更加简洁. 12345678910111213141516171819202122232425262728293031323334353637383940C/** * Definition for a point. * struct Point &#123; * int x; * int y; * Point() : x(0), y(0) &#123;&#125; * Point(int a, int b) : x(a), y(b) &#123;&#125; * &#125;; */class Solution &#123;public: int maxPoints(vector&lt;Point&gt;&amp; points) &#123; int res=0; for(int i=0; i&lt;points.size(); i++)&#123; int duplicate = 1; map&lt;pair&lt;int,int&gt;, int&gt; lines_hash; //这里用map的原因是因为unordered_map的键的类型只能是基本类型, 不能是pair for(int j=i+1; j&lt;points.size(); j++)&#123; if(points[i].x==points[j].x &amp;&amp; points[i].y==points[j].y)&#123; duplicate++; &#125;else&#123; int a = points[j].y-points[i].y; int b = points[j].x-points[i].x; int d = gcd(a, b); lines_hash[&#123;a/d, b/d&#125;]++; &#125; &#125; res = max(res, duplicate); // 如果points里面只有一个点, 则哈希表中不会有键值, 因此需要先处理只有一个点的情况 for(auto line : lines_hash)&#123; res = max(res, duplicate+line.second); &#125; &#125; return res; &#125; int gcd(int a, int b)&#123; // 求a与b的最大公约数 return (b==0) ? a : gcd(b, a%b); &#125;&#125;; 用 string 做键, 使用哈希表而不是map: 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int gcd(int a, int b) &#123; return b == 0 ? a : gcd(b, a%b); &#125; int maxPoints(vector&lt;Point&gt;&amp; points) &#123; int n = points.size(); int res = 0; for (int i = 0; i &lt; n; i++) &#123; std::unordered_map&lt;std::string, int&gt; line_hash; int duplicate = 1; for (int j = i + 1; j &lt; n; j++) &#123; if (points[i].x == points[j].x and points[i].y == points[j].y) &#123; duplicate++; continue; &#125; int a = points[j].y - points[i].y; int b = points[j].x - points[i].x; int d = gcd(a, b); std::string slope = std::to_string(a/d) + std::to_string(b/d); line_hash[slope]++; &#125; res = std::max(res, duplicate); for (auto it : line_hash) &#123; res = std::max(res, duplicate + it.second); &#125; &#125; return res; &#125;&#125;; 212. Word Search IIDescription: 返回字符矩阵中含有的所有单词Given a 2D board and a list of words from the dictionary, find all words in the board. Each word must be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once in a word. Example: Input:words = [“oath”,”pea”,”eat”,”rain”] and board =[ [‘o’,’a’,’a’,’n’], [‘e’,’t’,’a’,’e’], [‘i’,’h’,’k’,’r’], [‘i’,’f’,’l’,’v’]] Output: [“eat”,”oath”] 解法一: 穷举时间复杂度: $O(w mn 4^k)$, 暴力求解, $mn$ 为字符矩阵的宽和高, 也即 cell 数量, 对于 dfs 中的每个 cell, 有4个扩展方向, 一共需要扩展 $k$ 次($k$ 为单词的长度). 总共有 $w$ 个单词, 因此复杂度为$O(w mn 4^k)$空间复杂度: $O(mn)$ , 和79题相同, 回溯时, 用#来记录已经遍历过的点, 无需申请额外空间来记录. 但是递归程序需要占用 $O(mn)$ 的空间复杂度. 该题和79题类似, 只不过给定的是一个单词列表, 而不是一个单词, 因此, 可以对这个单词列表循环调用79题的解. 不过时间复杂度过高, 无法通过 OJ. 解法二: 字典树时间复杂度: $O(mn 4^k)$, 暴力求解, $mn$ 为字符矩阵的 cell 数量, 对于 dfs 中的每个 cell, 有4个扩展方向, 一共需要扩展 $k$ 次($k$ 为单词的长度).空间复杂度: $O(mn)$ , 和79题相同, 回溯时, 用#来记录已经遍历过的点, 无需申请额外空间来记录. 但是递归程序需要占用 $O(mn)$ 的空间复杂度. 另外, 还有构建字典树所需的空间复杂度, 这部分复杂度与具体的字符串数组有关, 当字符串公共部分较多时, 复杂度较低, 反之, 复杂度较高, 最差情况下为 $O(wk)$, 即无公共前缀 相对于第79题来说, 本题增加的复杂度主要体现在需要同时查看 $w$ 个单词的字符, 查询这些单词字符的复杂度约为 $O(wk)$, 其中, $k$ 为单词的最大长度, 那么, 我们能否将这里的复杂度降低成 $k$ 呢? 如果降低成 $k$ 的话, 就相当是在查找一个单词, 那么整体的复杂度就和79题相同, 变成了 $O(mn 4^k)$.实际上, 字典树正是这种数据结构! 在由 $w$ 个字符串构成的字典树中查询某个字符串或者字符子串的复杂度为 $k$. 因此, 我们可以借助字典树来降低整体的时间复杂度. 代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class TrieNode&#123;public: TrieNode *child[26]; string str; TrieNode():str("")&#123; for(auto &amp;node : child) node=nullptr; &#125;&#125;;class Trie&#123;public: TrieNode *root; Trie():root(new TrieNode())&#123;&#125;; void insert(string s)&#123; TrieNode *p = root; for(auto c : s)&#123; int i = c - 'a'; if(p-&gt;child[i] == nullptr) p-&gt;child[i] = new TrieNode(); p = p-&gt;child[i]; &#125; p-&gt;str = s; &#125;&#125;;class Solution &#123;public: vector&lt;string&gt; findWords(vector&lt;vector&lt;char&gt;&gt;&amp; board, vector&lt;string&gt;&amp; words) &#123; vector&lt;string&gt; res; if(words.size()==0 || board.size()==0 || board[0].size()==0) return res; vector&lt;vector&lt;bool&gt;&gt; visit(board.size(), vector&lt;bool&gt;(board[0].size(), false)); Trie T; for(auto word : words) T.insert(word); for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[i].size(); j++)&#123; if(T.root-&gt;child[board[i][j] - 'a'] != nullptr)&#123; search(board, T.root-&gt;child[board[i][j]-'a'], i, j, visit, res); &#125; &#125; &#125; return res; &#125; void search(vector&lt;vector&lt;char&gt;&gt; &amp;board, TrieNode *node, int i, int j, vector&lt;vector&lt;bool&gt;&gt; &amp;visit, vector&lt;string&gt; &amp;res)&#123; if(!node-&gt;str.empty())&#123; res.push_back(node-&gt;str); node-&gt;str.clear(); // 重新置为空 node-&gt;str = ""; 防止重复push_back &#125; int direct[4][2] = &#123; &#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125; &#125;; visit[i][j] = true; // 将当前位置设置为已访问, 因为题目要求同一个位置只能在一个字符串中被访问一次 for(auto d : direct)&#123; int new_i = i + d[0]; int new_j = j + d[1]; if(new_i&gt;=0 &amp;&amp; new_j&gt;=0 &amp;&amp; new_i&lt;board.size() &amp;&amp; new_j&lt;board[0].size() &amp;&amp; visit[new_i][new_j]==false &amp;&amp; node-&gt;child[board[new_i][new_j] - 'a'] != nullptr)&#123; search(board, node-&gt;child[board[new_i][new_j] - 'a'], new_i, new_j, visit, res); &#125; &#125; visit[i][j] = false; &#125;&#125;; 218. The Skyline ProblemDescription: 天际线问题A city’s skyline is the outer contour of the silhouette formed by all the buildings in that city when viewed from a distance. Now suppose you are given the locations and height of all the buildings as shown on a cityscape photo (Figure A), write a program to output the skyline formed by these buildings collectively (Figure B). The geometric information of each building is represented by a triplet of integers [Li, Ri, Hi], where Li and Ri are the x coordinates of the left and right edge of the ith building, respectively, and Hi is its height. It is guaranteed that 0 ≤ Li, Ri ≤ INT_MAX, 0 &lt; Hi ≤ INT_MAX, and Ri - Li &gt; 0. You may assume all buildings are perfect rectangles grounded on an absolutely flat surface at height 0. For instance, the dimensions of all buildings in Figure A are recorded as: [ [2 9 10], [3 7 15], [5 12 12], [15 20 10], [19 24 8] ] . The output is a list of “key points” (red dots in Figure B) in the format of [ [x1,y1], [x2, y2], [x3, y3], … ] that uniquely defines a skyline. A key point is the left endpoint of a horizontal line segment. Note that the last key point, where the rightmost building ends, is merely used to mark the termination of the skyline, and always has zero height. Also, the ground in between any two adjacent buildings should be considered part of the skyline contour. For instance, the skyline in Figure B should be represented as:[ [2 10], [3 15], [7 12], [12 0], [15 10], [20 8], [24, 0] ]. 解法一: multiset时间复杂度: $O(nlogn)$, 拆分三元组到二元组为 $O(n)$, 排序为 $O(nlogn)$, 更新轮廓节点为 $O(nlogn)$ (插入高度为 $O(log)$, 总共有 $O(n)$ 组高度).空间复杂度: $O(n)$, 存储高度的二元组 vector, 以及维护当前建筑物高度顺序的 multiset. 首先我们将表示建筑物的所有三元组(Li, Ri, Hi)进行拆分, 将其分成(Li, -Hi), (Ri, Hi)的两个二元组, 将这些二元组存放在一个数组 vector 中, 然后按照 x 轴的下标进行排序, 注意如果当一个建筑物的右侧和另一个建筑物的左侧重叠时, 我们为了不丢失当前建筑物的高度, 必须先考虑将另一个建筑物的左侧添加进 multiset 里, 然后获取最高高度. 接着在下一次循环时, 再将重合的右侧边界对应的建筑物剔除, 因此我们需要令二元组中的左侧为负, 使其在排序时可以排到前面.得到有序的建筑物二元组序列以后, 我们遍历该序列, 如果遇到了某个建筑物的左侧边界, 则将该边界对应建筑物的高度加入到 multiset 中, 如果遇到了某个建筑物的右侧边界, 则将对应建筑物的高度剔除. 假设我们已经得到了前 i 个坐标的建筑物组成的轮廓坐标点, 现在来到第 i+1 个坐标, 只有可能对应下面几种情况: i+1 坐标上新来的建筑物(遇到该建筑物左侧就行)完全被之前的建筑物覆盖, 此时不更新 res 轮廓. 说明添加了该建筑物后, 并不改变当前建筑群的最高高度. i+1 坐标上新来的建筑物比当前建筑群最高的高度还要高, 则需要记录当前的点. i+1 坐标上没有新来建筑物, 但是有一个建筑物遇到了右侧边界, 此时建筑群的高度会变成第二高建筑物的高度, 同样需要记录当前的坐标点. i+1 坐标上既没有新来建筑物, 也没有遇到建筑物右侧, 此时无需记录任何值, 可继续探测 i+2 坐标. 123456789101112131415161718192021222324252627282930class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; getSkyline(vector&lt;vector&lt;int&gt;&gt;&amp; buildings) &#123; vector&lt;pair&lt;int, int&gt;&gt; heights, res; // height 用于存放建筑物的高度, res存放结果 multiset&lt;int&gt; m; // 用 multiset 数据结构来维护当前x坐标之前的建筑物高度 for(auto &amp;b : buildings)&#123; //用负高度代表当前的边是左侧的边. 因为后面有排序, 所以必须令左侧为负, 而不能令右侧为负. //因为当x坐标相同时, 当前的building的右侧还不能剔除, //否则, 有可能"低估" 轮廓高度所以要将左侧的排在前面 heights.push_back(&#123;b[0], -b[2]&#125;); heights.push_back(&#123;b[1], b[2]&#125;); &#125; std::sort(heights.begin(), heights.end()); // 按照x坐标排序, 当x一样时, 按照高度排序 int pre = 0; // pre代表之前的最高建筑物的高度, 初始为0 int cur; // cur 代表当前的最高建筑物的高度, 会在for循环中赋值. m.insert(0); // 开始的时候, m中的最高高度为0 for(auto &amp;h : heights)&#123; if(h.second &lt; 0) m.insert(-h.second); // 如果是左侧边, 则加入当前建筑物高度集合, 并自动排序 else m.erase(m.find(h.second)); // 如果遇到了右侧边, 则将对应的建筑物从当前建筑物集合内剔除 // 注意, 这里在使用erase时, 是先找到key值匹配的某一个元素的迭代器(多个存在多个匹配), 然后再删除 // 如果直接使用 erase(key) 的话, 则会将满足key值的所有元素都擦除, 这样会导致程序出错. cur = *m.rbegin(); // 获取当前的最大高度 if(cur != pre)&#123; // 说明此时要么新加入了更高的高度, 要么被用于最高高度的建筑物被剔除, 需要更新轮廓点 res.push_back(&#123;h.first, cur&#125;); //新更新的轮廓点的x坐标即为当前h的x坐标. pre = cur; // 更新pre &#125; &#125; return res; &#125;&#125;; 解法二: priority_queue(堆)在解法一中, 用了 multiset, 之所以不用 priority_queue 的原因是因为, C++ 的 priority_queue 容器并没有提供erase或者find之类的方法, 因此, 在删除指定高度时, 比较麻烦. 而 multiset 不仅完成堆的功能(最后一个元素就是最大的), 同时还支持在对数复杂度时间内删除指定的高度. 因此, 如果想要使用 priority_queue 的话, 就需要调整算法的逻辑, 下面是使用 priority_queue 的解法: 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; getSkyline(vector&lt;vector&lt;int&gt;&gt;&amp; buildings) &#123; std::vector&lt;std::pair&lt;int, int&gt;&gt; res; int cur = 0, cur_X, cur_H = -1, len = buildings.size(); std::priority_queue&lt;std::pair&lt;int, int&gt;&gt; liveBlg; while (cur &lt; len or !liveBlg.empty()) &#123; cur_X = liveBlg.empty() ? buildings[cur][0] : liveBlg.top().second; if (cur &gt;= len or buildings[cur][0] &gt; cur_X) &#123; while (!liveBlg.empty() &amp;&amp; (liveBlg.top().second &lt;= cur_X)) &#123; liveBlg.pop(); &#125; &#125; else &#123; cur_X = buildings[cur][0]; while (cur &lt; len &amp;&amp; buildings[cur][0] == cur_X) &#123; liveBlg.push(&#123;buildings[cur][2], buildings[cur][1]&#125;); cur++; &#125; &#125; cur_H = liveBlg.empty() ? 0 : liveBlg.top().first; if (res.empty() or (res.back().second != cur_H)) &#123; res.push_back(&#123;cur_X, cur_H&#125;); &#125; &#125; return res; &#125;&#125;; 239. Sliding Window MaximumDescription: 滑动窗口的最大值Given an array nums, there is a sliding window of size k which is moving from the very left of the array to the very right. You can only see the k numbers in the window. Each time the sliding window moves right by one position. Return the max sliding window. Example:123456789101112Input: nums = [1,3,-1,-3,5,3,6,7], and k = 3Output: [3,3,5,5,6,7]Explanation:Window position Max--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 Note:You may assume k is always valid, 1 ≤ k ≤ input array’s size for non-empty array. Follow up:Could you solve it in linear time? 解法一: 双端队列时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(k)$, 双端队列的 size 为 $k$. 使用双端队列deque, 从下标0开始, 一直到n-1, 每次进行如下步骤: 当前元素是否比队列中最后一个元素大, 如果大, 说明队列元素以后也不可能再成为较大值, 直接pop, 如此循环, 直到队列为空或者遇到比当前值大的元素 判断队列中队首的元素是否过期(若队空则直接下一步, 无需判断), 若过期, 则pop, 否则, 不管( 只看队首, 队内的元素是否过期不影响算法, 因为就算过期后面也会将其淘汰) 将当前元素的下标存到队尾 将新的队首元素存到结果向量max_res中 注意: 队列里面存的是下标, 而不是元素本身的值, 后面在提到队列的元素值时, 均是指队列中存储的下标对应的元素值. 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; if(nums.size()==0 || k ==0) return vector&lt;int&gt;&#123;&#125;; int n = nums.size(); deque&lt;int&gt; dq; vector&lt;int&gt; res; for(int i=0; i&lt;n; i++)&#123; if(dq.empty()) dq.push_back(i); else&#123; if(dq.front() &lt; i-k+1) dq.pop_front(); //过期元素, 出队列 while(!dq.empty() &amp;&amp; nums[dq.back()] &lt;= nums[i]) dq.pop_back(); // 将队列中小于当前元素的都出队列(因为它们不可能成为max) dq.push_back(i); // 将当前元素入队列. &#125; if(i &gt;= k-1) res.push_back(nums[dq.front()]); &#125; return res; &#125;&#125;; 295. Find Median from Data StreamDescription: 返回数据流的中位数Median is the middle value in an ordered integer list. If the size of the list is even, there is no middle value. So the median is the mean of the two middle value. For example,[2,3,4], the median is 3[2,3], the median is (2 + 3) / 2 = 2.5 Design a data structure that supports the following two operations: void addNum(int num) - Add a integer number from the data stream to the data structure. double findMedian() - Return the median of all elements so far. Example:12345addNum(1)addNum(2)findMedian() -&gt; 1.5addNum(3)findMedian() -&gt; 2 Follow up: If all integer numbers from the stream are between 0 and 100, how would you optimize it? If 99% of all integer numbers from the stream are between 0 and 100, how would you optimize it? 解法一: 传统排序时间复杂度: $O(nlogn)$, 添加数字时不排序, 返回中位数时排序空间复杂度: $O(n)$, 排序需要额外空间 添加数字时, 直接添加, 时间复杂度为 $O(1)$, 每次需要输出中位数时, 都对数组内当前所有元素排序, 时间复杂度为 $O(nlogn)$, 该方法超时. 解法二: 插入排序时间复杂度: $O(n)$, 二分搜索位置需要 $O(logn)$, 插入需要 $O(n)$.空间复杂度: $O(n)$ 每次新来一个数字时, 都执行插入排序, 先利用二分搜索(因为当前数组已经有序)找到应该插入的位置, 时间复杂度为 $O(logn)$, 然后将数字插入到该位置, 插入的时间复杂度是 $O(n)$, 由于已经排序好, 因此返回中位数的时间复杂度是 $O(1). 该解法 同样超时. 解法三: 大顶堆+小顶堆时间复杂度: $O(5\times logn) = O(logn)$空间复杂度: $O(n)$, 大顶堆和小顶堆的大小之和为 $n$. 元素首先加入大顶堆($O(logn)$), 得到前面数字的最大值, 然后将该最大值弹出($O(logn)$)并加入到小顶堆当中($O(logn)$), 以维护当前小顶堆的元素合法(例如, 新的大顶堆堆顶的元素大于当前小顶堆堆顶元素, 这就不合法了), 然后, 看看当前大顶堆和小顶堆的元素个数是否符合要求, 如果不符合的话, 就小顶堆的堆顶弹出($O(logn)$)并加入大顶堆($O(logn)$). 由此可知, 添加元素的时间复杂度为: $O(5\times logn)$. 返回中位数时可以直接获取堆顶, 而无需更改堆结构, 故而为 $O(1)$. 所以, 最终的时间复杂度就为 $O(5\times logn) = O(logn)$ 1234567891011121314151617181920212223242526272829303132class MedianFinder &#123;private: priority_queue&lt;int&gt; max_heap; // 大顶堆, 维护前 (n+1)/2 个元素 priority_queue&lt;int, vector&lt;int&gt;, std::greater&lt;int&gt;&gt; min_heap; //小顶堆, 维护后n/2个元素public: /** initialize your data structure here. */ MedianFinder() &#123; &#125; void addNum(int num) &#123; max_heap.push(num); // 先将当前元素添加到大顶堆中, 找到前半段最大元素 min_heap.push(max_heap.top()); max_heap.pop(); // 调节最小堆, 这一步是必须的, 是为了同时确保大顶堆和小顶堆的元素正确 // 数字会随着元素size的变化而不断在大顶堆和小顶堆之间切换 if(max_heap.size() &lt; min_heap.size())&#123; //调节后, 平衡大顶堆和小顶堆的size max_heap.push(min_heap.top()); min_heap.pop(); &#125; &#125; double findMedian() &#123; return (max_heap.size() + min_heap.size())%2==1 ? double(max_heap.top()) : (max_heap.top() + min_heap.top())*0.5; &#125;&#125;;/** * Your MedianFinder object will be instantiated and called as such: * MedianFinder obj = new MedianFinder(); * obj.addNum(num); * double param_2 = obj.findMedian(); */ 解法四: multiset+指示器时间复杂度: $O(logn+1) = O(logn)$空间复杂度: $O(n)$, multiset 容器需要 $n$ 大小的空间. 用两个迭代指示器分别指向当前数组内的中位数(元素数目为奇数时, 二者指向同一点), 那么当新来一个元素时, 这个元素只可能有三种插入情况: 插在两指示器的前面 插在两指示器的后面 插在两指示器的中间(只在未插入前元素数目为偶数时才可以) 由于迭代指示器是随着元素移动而移动的(这点和下标就有区别了), 因此, 我们可以通过对指示器操作来使其指向新的中位数, 对应三种情况分别为: 前面元素变多, 说明指示器应该后挪(最多一位) 后面元素变多, 说明指示器应该前挪(最多一位) 插在中间, 说明当前插入的元素正是中位数, 令指示器指向即可. 当然, 上面只是核心思想, 具体的挪动算法还要分元素数目的奇偶性来分情况讨论, 代码如下所示: 1234567891011121314151617181920212223242526272829303132333435363738class MedianFinder &#123;private: std::multiset&lt;int&gt; data; std::multiset&lt;int&gt;::iterator low_mid, high_mid; // 迭代指示器会随着容器的变动而变动, 这个性质是该解法可行的重要因素之一public: /** initialize your data structure here. */ MedianFinder():low_mid(data.end()), high_mid(data.end()) &#123; &#125; void addNum(int num) &#123; const size_t n = data.size(); data.insert(num); if(n == 0)&#123; low_mid = data.begin(); high_mid = data.begin(); &#125;else if(n &amp; 1==1)&#123; // 插入之前元素数量为奇数, low_mid=high_mid if(num &lt; *low_mid) // 会插入到 low_mid/high_mid 之前, 因此, 前半段元素增加 low_mid--; else // 如果 &gt;=, 则会插入到low_mid/high_mid 之后 high_mid++; &#125;else&#123; // 插入之前元素数量为偶数, low_mid+1 = high_mid if(num &gt;= *low_mid &amp;&amp; num &lt; *high_mid)&#123; //插入的元素刚好在中间, 注意前面要用 &gt;=, 后面用 &lt;, 因为相等时, 会插在后面 low_mid++; high_mid--; // 两个指针都想中间靠拢. &#125;else if(num &lt; *low_mid)&#123; // 插入元素会插在前面, 则前面元素数量增加 high_mid--; // 令high_mid=low_mid; &#125;else&#123; // 插在了后面 low_mid++; // 令low_mid=high_mid; &#125; &#125; &#125; double findMedian() &#123; return (*low_mid + *high_mid) * 0.5; &#125;&#125;; 上面的指示器实际上可以简化成一个(因为两个指示器只能互相挨着或者重叠), 因此, 我们可以只维护一个指示器, 简化代码如下(但是不太好理解): 12345678910111213141516171819202122232425262728class MedianFinder &#123; multiset&lt;int&gt; data; multiset&lt;int&gt;::iterator mid;public: MedianFinder() : mid(data.end()) &#123; &#125; void addNum(int num) &#123; const int n = data.size(); data.insert(num); if (!n) // first element inserted mid = data.begin(); else if (num &lt; *mid) // median is decreased mid = (n &amp; 1 ? mid : prev(mid)); else // median is increased mid = (n &amp; 1 ? next(mid) : mid); &#125; double findMedian() &#123; return data.size() &amp; 1 == 1 ? (*mid) : (*mid + *next(mid)) * 0.5 ; &#125;&#125;; Follow Up If all integer numbers from the stream are between 0 and 100, how would you optimize it? 用bucket? If 99% of all integer numbers from the stream are between 0 and 100, how would you optimize it? 297. Serialize and Deserialize Binary TreeDescription: 序列化和反序列化二叉树Serialization is the process of converting a data structure or object into a sequence of bits so that it can be stored in a file or memory buffer, or transmitted across a network connection link to be reconstructed later in the same or another computer environment. Design an algorithm to serialize and deserialize a binary tree. There is no restriction on how your serialization/deserialization algorithm should work. You just need to ensure that a binary tree can be serialized to a string and this string can be deserialized to the original tree structure. Example:123456789You may serialize the following tree: 1 / \ 2 3 / \ 4 5as &quot;[1,2,3,null,null,4,5]&quot; Clarification: The above format is the same as how LeetCode serializes a binary tree. You do not necessarily need to follow this format, so please be creative and come up with different approaches yourself. Note: Do not use class member/global/static variables to store states. Your serialize and deserialize algorithms should be stateless. 解法一: DFS时间复杂度: $O(n)$, 在序列化和反序列化递归中, 各遍历每个节点一次空间复杂度: $O(n\times v + n) = O(n)$, 其中, $n$ 为节点个数, $v$ 为节点上的值所占空间大小, 最后的一个 $n$ 代表递归调用所占的空间大小. 使用 ostringstream 和 istringstream 来缓存字符串, 中间用空格分隔, 利用流操作 &lt;&lt; 和 &gt;&gt; 可以方便的对字符串进行存入和读取, 而无需额外进行分词操作. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Codec &#123;private: void serialize(TreeNode *root, ostringstream &amp;out)&#123; // 函数重载 if(root==nullptr) out &lt;&lt; "# "; else&#123; out &lt;&lt; root-&gt;val &lt;&lt; " "; serialize(root-&gt;left, out); serialize(root-&gt;right, out); &#125; &#125; TreeNode *deserialize(istringstream &amp;in)&#123; string cur_val; in &gt;&gt; cur_val; if(cur_val=="#") return nullptr; else&#123; TreeNode *node = new TreeNode(std::stoi(cur_val)); node-&gt;left = deserialize(in); node-&gt;right = deserialize(in); return node; &#125; &#125;public: // Encodes a tree to a single string. string serialize(TreeNode* root) &#123; ostringstream out; serialize(root, out); return out.str(); &#125; // Decodes your encoded data to tree. TreeNode* deserialize(string data) &#123; istringstream in(data); return deserialize(in); &#125;&#125;;// Your Codec object will be instantiated and called as such:// Codec codec;// codec.deserialize(codec.serialize(root)); 解法二: BFS时间复杂度: $O(n)$, 在序列化和反序列化中, 每个节点都遍历一次空间复杂度: BFS 的会按照层次遍历的顺序将树的节点序列化, 序列化的代码比较好写, 只需对普通的层次遍历稍加改动即可. 反序列化的代码有一点麻烦, 需要控制树节点的左右子节点的值, 具体如下. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Codec &#123;public: // Encodes a tree to a single string. string serialize(TreeNode* root) &#123; ostringstream out; if(root==nullptr) return ""; queue&lt;TreeNode*&gt; q; q.push(root); while(!q.empty())&#123; TreeNode *node = q.front(); q.pop(); if(node!=nullptr)&#123; out &lt;&lt; node-&gt;val &lt;&lt; " "; q.push(node-&gt;left); q.push(node-&gt;right); &#125;else out &lt;&lt; "# "; &#125; return out.str(); &#125; // Decodes your encoded data to tree. TreeNode* deserialize(string data) &#123; if(data.empty()) return nullptr; istringstream in(data); queue&lt;TreeNode *&gt; q; string val; in &gt;&gt; val; TreeNode *res = new TreeNode(std::stoi(val)); TreeNode *cur = res; q.push(cur); while(!q.empty())&#123; TreeNode *node = q.front(); q.pop(); if(!(in&gt;&gt;val)) break; if(val!="#")&#123; cur = new TreeNode(std::stoi(val)); node-&gt;left = cur; q.push(cur); &#125; if(!(in&gt;&gt;val)) break; if(val!="#")&#123; cur = new TreeNode(std::stoi(val)); node-&gt;right = cur; q.push(cur); &#125; &#125; return res; &#125;&#125;; 315. Count of Smaller Numbers After SelfDescription: 统计右边比当前数字小的个数You are given an integer array nums and you have to return a new counts array. The counts array has the property where counts[i] is the number of smaller elements to the right of nums[i]. Example:1234567Input: [5,2,6,1]Output: [2,1,1,0]Explanation:To the right of 5 there are 2 smaller elements (2 and 1).To the right of 2 there is only 1 smaller element (1).To the right of 6 there is 1 smaller element (1).To the right of 1 there is 0 smaller element. 解法一: multiset时间复杂度: $O(n\times(logn+n+logn)=O(n^2)$空间复杂度: $O(n+n) = O(n)$ 先介绍一下利用 multiset 的解法, multiset 的底层实现使用了红黑树, 所以在插入和查找的时候复杂度都为 $O(logn)$, 但是求 distance 时, 由于 multiset 的迭代器不是随机访问的, 因此复杂度为 $O(n)$, 故而最后的时间复杂度为 $O(n^2)$. 该方法在 OJ 上超时, 此处仅用于记录. 1234567891011121314151617 class Solution &#123;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; multiset&lt;int&gt; nums_set; int n = nums.size(); vector&lt;int&gt; res(nums.size(), 0); for(int i=n-1; i&gt;=0; i--)&#123; auto itlow = nums_set.lower_bound(nums[i]); res[i] = std::distance(nums_set.begin(), itlow); // multiset 求distance的复杂度为线性, 因此, 总复杂度为 O(n^2) nums_set.insert(nums[i]); &#125; return res; &#125;&#125;; 解法二: 有序数组时间复杂度: $O(n\times (logn+n) = O(n^2)$, 在有序数组中找指定位置需要 $O(logn)$, 将当前元素插入到数组的指定位置需要 $O(n)$, 这个过程需要进行 $n$ 次.空间复杂度: $O(n+n) = O(n)$, 一个有序数组, 一个结果数组, 大小都为 $n$. 我们从后往前遍历, 将遍历过的数字维护成一个有序数组, 然后对于任意一个新来的数字, 我们可以在有序数组中查询小于该数字的元素个数, 查询的时间复杂度为 $O(logn)$, 然后我们需要将该数字也插入到有序数组中并保持有序, 插入操作需要的时间复杂度为 $O(n)$, 总共有 $n$ 个数字, 因此需要执行 $n$ 次, 故时间复杂度约为 $O(n^2)$, (虽然是 $O(n^2)$, 但是仍然没超时, 考虑是因为只有一个 $logn$, 而解法一具有两个 $logn$.) 代码如下: 123456789101112131415class Solution &#123;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; order_nums; vector&lt;int&gt; res(n, 0); for(int i=n-1; i&gt;=0; i--)&#123; //计算第一个不小于nums[i]的数字之前的数字个数 int d = std::lower_bound(order_nums.begin(), order_nums.end(), nums[i]) - order_nums.begin(); res[i] = d; //将数字个数填进结果数字 order_nums.insert(order_nums.begin()+d, nums[i]); // 当 nums[i] 插入到合适位置, 保持order_nums有序 &#125; return res; &#125;&#125;; 解法三: 二叉搜索树(BST)时间复杂度: $O(nlogn)$, 内部只有一个 $logn$ 复杂度的插入操作, 没有其他操作, 但是由于不是平衡的, 所以在最坏情况下的复杂度为 $O(n^2)$, 最好情况即为平衡树, 复杂度为 $O(nlogn)$.空间复杂度: $O(n+n)$, res 数组和二叉树结构各占 $n$ 大小的空间. 如果采用递归实现插入, 则可能额外需要 $n$ 大小的递归空间. 在解法一中, 通过 multiset 红黑树的结构使得插入时的复杂度为 $logn$, 但是最终需要进行的操作过多, 导致时间超时, 为此, 我们可以自己实现一个二叉搜索树, 从后往前的遍历数组, 并且在插入元素的时候就统计出小于当前元素的节点的个数(为此我们需要在树的结构中额外添加一个变量 smaller, 只是小于当前节点的元素个数), 故而只需要一次 $logn$, 且没有其他多于操作, 代码如下: 12345678910111213141516171819202122232425262728293031323334class Solution &#123; struct TreeNode&#123; int val; int smaller; TreeNode *left; TreeNode *right; TreeNode(int v, int s):val(v), smaller(s), left(nullptr), right(nullptr)&#123;&#125;; &#125;; int insert(TreeNode *&amp;root, int val)&#123; // 注意, 这要insert函数中, root的值要影响函数外的指针, 所以要用引用&amp; if(root==nullptr)&#123; root = new TreeNode(val, 0); return 0; // &#125; if(val &lt; root-&gt;val)&#123; root-&gt;smaller++; // 如果新来的数比当前root的的值还小, 则smaller增1 return insert(root-&gt;left, val); // 递归插入到左子树中 &#125;else&#123; // 递归插入到右子树中, 返回的小于元素的数量为: 根左侧的数量+右子树的数量+根(0:1) return root-&gt;smaller + insert(root-&gt;right, val) + (root-&gt;val==val ? 0 : 1); // 这里要千万注意三目运算符的优先级, 一定要用括号整个括起来才行!!! &#125; &#125;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; res(n, 0); TreeNode *root = nullptr; for(int i=n-1; i&gt;=0; i--)&#123; // 如果题目问的是左侧, 则i从0开始 res[i] = insert(root, nums[i]); &#125; return res; &#125;&#125;; 解法四: 归并排序时间复杂度: $O(nlogn)$空间复杂度: $O(n+n) = O(n)$ 由于解法三构造的二叉树并不是一个平衡的二叉树, 导致在树的极端情况下, 时间复杂度为 $O(n^2)$, 而要手动实现二叉树的平衡逻辑, 又有些复杂, 不适合解此题. 所以, 我们可以考虑此题的另一种解法, 即利用归并排序来解决. 【链接】Loading…https://leetcode.com/problems/count-of-smaller-numbers-after-self/discuss/76607/C%2B%2B-O(nlogn)-Time-O(n)-Space-MergeSort-Solution-with-Detail-Explanation 329. Longest Increasing Path in a MatrixDescription: 寻找矩阵中的最长递增序列Given an integer matrix, find the length of the longest increasing path. From each cell, you can either move to four directions: left, right, up or down. You may NOT move diagonally or move outside of the boundary (i.e. wrap-around is not allowed). Example 1:12345678Input: nums =[ [9,9,4], [6,6,8], [2,1,1]]Output: 4Explanation: The longest increasing path is [1, 2, 6, 9]. Example 2:12345678Input: nums =[ [3,4,5], [3,2,6], [2,2,1]]Output: 4Explanation: The longest increasing path is [3, 4, 5, 6]. Moving diagonally is not allowed. 解法一: DP + dfs时间复杂度: $O(mn)$, 每个节点都会遍历一次, 当遍历一次后, 下次再访问时可以直接通过 dp 数组得知答案.空间复杂度: $O(mn+mn=mn)$, $n$ 行 $m$ 列的 DP 数组所占用的空间大小, 另外还有递归所占用的空间($mn?$) 申请和矩阵相同大小的 DP 数组, 令 dp[i][j] 代表从 (i,j) 位置为起点的绝对递增数列的长度, 每遍历一个位置后, 下一次再访问该位置时就无需重复计算, 可以直接通过 dp 数组获取到相应长度. 在查找当前节点的最大长度时, 我们利用 dfs 算法, 依次从四个方向进行查找, 最终取最大值作为本位置的最长递增序列长度 123456789101112131415161718192021222324252627282930class Solution &#123;private: int dirs[4][2] = &#123;&#123;0, -1&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;1, 0&#125;&#125;; int dfs(vector&lt;vector&lt;int&gt;&gt; &amp;matrix, vector&lt;vector&lt;int&gt;&gt; &amp;dp, int i, int j, int &amp;n, int &amp;m)&#123; if(dp[i][j]!=0) return dp[i][j]; dp[i][j] = 1; //长度至少为1 for(auto d : dirs)&#123; int x = i+d[0], y = j+d[1]; if(x&gt;=0 &amp;&amp; x&lt;n &amp;&amp; y&gt;=0 &amp;&amp; y&lt;m &amp;&amp; matrix[x][y] &gt; matrix[i][j])&#123; // 绝对递增, 因此不能有 = int len = 1+dfs(matrix, dp, x, y, n, m); dp[i][j] = std::max(dp[i][j], len); &#125; &#125; return dp[i][j]; &#125;public: int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m = matrix[0].size(); vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(m, 0)); int res=1; for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; res = std::max(res, dfs(matrix, dp, i, j, n, m)); &#125; &#125; return res; &#125;&#125;; 解法二: DP + BFSTODO: http://www.cnblogs.com/grandyang/p/5148030.html 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; if (matrix.empty() || matrix[0].empty()) return 0; int m = matrix.size(), n = matrix[0].size(), res = 1; vector&lt;vector&lt;int&gt;&gt; dirs&#123;&#123;0,-1&#125;,&#123;-1,0&#125;,&#123;0,1&#125;,&#123;1,0&#125;&#125;; vector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, 0)); for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j ) &#123; if (dp[i][j] &gt; 0) continue; queue&lt;pair&lt;int, int&gt;&gt; q&#123;&#123;&#123;i, j&#125;&#125;&#125;; int cnt = 1; while (!q.empty()) &#123; ++cnt; int len = q.size(); for (int k = 0; k &lt; len; ++k) &#123; auto t = q.front(); q.pop(); for (auto dir : dirs) &#123; int x = t.first + dir[0], y = t.second + dir[1]; if (x &lt; 0 || x &gt;= m || y &lt; 0 || y &gt;= n || matrix[x][y] &lt;= matrix[t.first][t.second] || cnt &lt;= dp[x][y]) continue; dp[x][y] = cnt; res = max(res, cnt); q.push(&#123;x, y&#125;); &#125; &#125; &#125; &#125; &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智力题]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E6%99%BA%E5%8A%9B%E9%A2%98%2F</url>
    <content type="text"><![CDATA[智力题:如果一个女生说，她集齐了十二个星座的前男友，我们应该如何估计她前男友的数量？https://www.zhihu.com/question/38331955]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>智力题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种优化方法整理总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%90%84%E7%A7%8D%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简述各种优化方法的概念及其优缺点\theta_t = \theta_{t-1} + \Delta \theta_t 名称 公式 优化方法简述 优点 缺点 SGD $g_t = \nabla_{\theta_{t-1}} f(\theta_{t-1})$ $\Delta \theta_t = - \eta \times g_t$ 每一次都计算mini-batch的梯度, 然后对参数进行更新. 公式中的 $\eta$ 是学习率, $g_t$ 是当前 batch 的梯度 收敛速度快 (1) 因为要兼顾整个神经网络中所有参数的训练效果, 因此对学习率的选择比较敏感. (2) SGD 容易收敛到局部最优, 并且在某些情况下容易被困在鞍点, 需要使用合适的初始化和步长; (3) 参数的更新仅仅依赖于当前 batch 中的数据, 当数据波动大时, 更新往往不够稳定 Momentum $g_t = \nabla_{\theta_{t-1}} f(\theta_{t-1})$ $m_t = \mu \times m_{t-1} + g_t$ $\Delta \theta_t = -\eta \times m_t$ 公式中的 $\mu$ 为动量因子, 通常取值 0.9 或 0.99, 借助于物理学里面动量的概念, 通过动量的积累来在相关方向上加速 SGD 优化速度, 抑制震荡, 同时有助于跳出局部最优, 进而加快收敛 (1) 下降初期, 下降方向一致, 有助于加速下降; (2) 下降中后期, 在局部最小值附近, 有助于跳出局部最优; (3) 在梯度改变方向时, 能够降低更新幅度, 减小震荡 暂无 Nesterov $g_t=\nabla_{\theta_{t-1}} f(\theta_{t-1} - \eta \times \mu \times m_{t-1})$ $m_t = \mu \times m_{t-1} + g_t$ $\Delta \theta_t = -\eta \times m_t$ 可以看出, Nesterov 与 Momentum 公式的区别在于, 前者不是在当前的位置上求梯度, 而是根据本来计划要走的那一步提前前进一步以后, 再在新的位置上求梯度, 然后对这个新求得的梯度进行 Momentum 梯度下降计算 (1) 站在下一步的位置看看, 再进行更新, 使得梯度更新方向更具前瞻性 (1) 增加了计算量 Adagrad $n_t = n_{t-1} + g^2_t$ $\Delta \theta_t = -\frac{\eta}{\sqrt{n_t + \epsilon}} \times g_t$ Adagrad相当于在学习率前面乘了一个约束项 $\frac{1}{\sqrt {n_t + \epsilon}}$, 该约束项会随着算法的不断迭代而越来越大, 那么对应学习率就会越来越小, 也就是说 Adagrad 算法在开始时是大步前进的, 而在后面则会减小步伐, 缓慢收敛 (1) 在整个更新期间学习率不是固定的, 会随着训练过程变化; (2) 适合面对稀疏梯度 (1) 仍然依赖于一个人工设置的全局学习率; (2) 中后期, 分母上的梯度放平累加和会越来越大, 使得更新提早停滞, 训练提前结束 AdaDelta $Eg^2_t = \rho\times Eg^2_{t-1} + (1-\rho)\times g^2_t$ $\Delta \theta_t = -\frac{\eta}{\sqrt{Eg^2_t + \epsilon}} g_t$ $= -\frac{\eta}{RMS[g]_t} g_t$ $= -\frac{RMS[\Delta\theta]_{t-1}}{RMS[g]_t} g_t$ Adadelta是对Adagrad的扩展, 和 Adagrad 相比, 其改进是将分母约束项换成了过去的梯度平方的衰减平均值, 相当于梯度的均方根(root mean squared, RMS), 此外, 如果将学习率也换成 $RMS[\Delta \theta]$ 的话, 甚至可以不用设置学习率了 (1) 对 Adagrad 的扩展, 约束项不容易产生太大值而使得更新提早结束; (2) 无需人工设置学习率 (1) 训练后期会反复在局部最小值附近抖动(why?) RMSprop $Eg^2_t = \rho\times Eg^2_{t-1} + (1-\rho)\times g^2_t$ $\Delta \theta_t = -\frac{\eta}{\sqrt{Eg^2_t + \epsilon}} g_t$ RMSprop可以算作是Adadelta的一个特例, 可以看出 RMSprop 仍然需要设置全局学习率 (1) Adadelta 的特例, 也是对学习率添加约束, 适合处理非平稳目标, 对 RNN 效果较好 (1) 依然需要依赖于全局学习率 Adam $m_t = \mu \times m_{t-1} + (1-\mu) \times g_t$ $n_t = \nu \times n_{t-1} + (1 - \nu) \times g^2_t$ $\hat m_t = \frac{m_t}{1-\mu_t}$ $\hat n_t = \frac{n_t}{1- \nu_t}$ $\Delta \theta_t = -\frac{\hat m_t}{\sqrt{\hat n_t} + \epsilon} \times \eta$ Adam本质上是带有动量项的 RMSprop, 它利用 修正后的 梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率. 公式中, $m_t, n_t$ 分别是对梯度的一阶矩估计和二阶矩估计, 可以看做是对期望 $E g_t$, $E g^2_t$ 的估计, $\hat m_t$, $\hat n_t$ 是对 $m_t$, $n_t$ 的校正, 这样可以近似为对期望的无偏估计 (1) 经过偏置校正后, 每一次迭代学习率都有一个确定的范围, 使得参数更新比较平稳; (2) 结合了 Adagrad 善于处理稀疏梯度和 RMSprop 善于处理非平稳目标的有点; (3) 对内存需求较小; (4) 适用于大多非凸优化, 适用于大数据集和高维空间 Adamax $n_t = max(\nu \times, abs(g_t))$ $\Delta x = -\frac{\hat m_t}{n_t + \epsilon}\times\eta$ Adamax 是 Adam 的一种变体, 此方法对学习率的上限提供了一个更简单的范围, 可以看出, 学习率的边界范围更加简单 Nadam … … 简述 Adam 中使用的指数加权滑动平均法加权滑动平均法, 就是对观察值分别属于不同的权重, 按不同的权重来求最终的滑动平均值. 而指数加权滑动平均法就是指各个观察值的加权系数随着时间呈指数递减, 越靠近当前时刻的观察值权重越大. 公式如下: v_t = \beta v_{t-1} + (1 - \beta) \theta_t上式中, $\theta_t$ 代表当前时刻的观察值, 系数 $\beta$ 代表加权下降的速率, 其值越小下降的越快, $v_t$ 代表当前时刻的指数加权滑动平均值. PS: 在数学中一般会以 $\frac{1}{e}$ 来作为一个临界值, 小于该值的加权系数对应的值不作考虑. 因此, 当 $\beta = 0.9$ 时, $0.9^{10}$ 约等于 $\frac{1}{e}$, 认为此时是约 10 个数值的加权平均. 偏差修正: 当初始化 $v_0 = 0$ 时, 由于初始化的值太小, 导致初期的滑动平均值偏小, 随着时间的增长, 初期的值影响减小, 滑动平均值才逐渐正常. 为了让初期的滑动平均值也相对正常, 我们利用下面的式子进行修正: v_t = \frac{\beta v_{t-1} + (1 - \beta)\theta_t}{1 - \beta^t} 各种优化方法的源码实现深入解析各个损失函数的优缺点SGD缺点: Momentum特点: 下降初期时, 由于动量因子的存在使得可以加速网络的训练速度 当遇到鞍点时, 梯度虽然为零, 但是动量不为零, 可以轻松的跳出鞍点 当梯度改变方向时, 动量可以抑制震荡, 加速网络收敛. 缺点: 需要人工设置学习率 Nesterov特点:Nesterov 相比于 Momentum 来说, 提前走了一步, 因此, 它能够让算法提前看到前方的地形梯度, 如果前面的梯度比当前位置的梯度大, 那么就可以把步子迈的比原来大一些, 反之, 可以把步子迈的比原来小一些. 这个大一些, 小一些, 都是相对于原来不看前方梯度, 只看当前位置梯度的情况来说的.另一个角度, 二阶导信息: https://zhuanlan.zhihu.com/p/22810533 缺点: 需要人工设置学习率 Adagrad特点:可以根据梯度的大小动态的改变学习率的大小. 缺点: 由公式可以看出, 扔依赖于人工设置一个全局的学习率 约束项的初值设置的不合理的话, 会影响梯度的调节幅度. Adadelta特点: 可以动态改变学习率的大小 无需设置全局的学习率 RMSprop实际上是 Adadelta 的变体, 从公式可以看出, 仍然需要设置全局学习率 Adam(Adaptive Moment Estimation)特点: 结合了 Adagrad 善于处理稀疏梯度和 RMSprop 善于处理非平稳目标的有点 对内存需要较小 为不同的参数计算不同的自适应学习率 也适用于大多非凸优化, 适用与大数据集和高维空间 损失平面等高线: 鞍点处的比较: 损失函数选择经验 对于稀疏数据, 尽量使用学习率可自适应的优化方法, 因为自适应的优化方法对不同的参数会赋予不同的更新步长 // TODO 以下四点未确认正确性 SGD通常训练时间更长, 但是在好的初始化和学习率调度方案的情况下, 结果更可靠 如果在意更快的收敛, 并且需要训练较深较复杂的网络时, 推荐使用学习率自适应的优化方法 Adadelta, RMSprop, Adam是比较相近的算法, 在相似情况下表现差不多 在想使用带动量的RMSprop, 或者Adam的地方, 大多可以使用Nadam取得更好的效果 区别与联系超参数learning rate: 学习率决定了权值更新的速度, 设置的太大会使结果超过最优值, 太小会使下降速度过慢, 仅靠认为干预调整参数需要不断修改学习率, 十分不合理. weight decay: 就是正则项, L1或L2正则项 momentum: learning rate decay: 每经过一段迭代次数以后, 就会减小learning rate的大小.]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 面试总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-Cpp%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[一. 基础篇基础问题 C++ 在 C 的基础上加了什么 define 宏定义 C++ 的编译和链接过程 结构体和联合体有什么区别 封装, 继承, 多态, 重载, 重写/覆盖概念解析 简单介绍一下 C++ 的继承机制 子类不能从父类继承的函数 重载, 隐藏和重写/覆盖的区别 友元类和友元函数 嵌套类 范围解析运算符 避免文件被多次编译 float 与 0 比较时需要注意什么 什么情况下会发生运行时错误 Runtime Error 数组和指向数组名的指针有什么区别 初始化列表 initialization list C++ 是不是类型安全的 函数参数的入栈顺序 todo: 结构体和共用体的 size 是如何计算的 类的 size 是如何计算的 友元类和友元函数 能访问私有成员 破坏封装性 友元关系不可传递 友元关系的单向性 友元声明的形式及数量不受限制 C++ 中的友元 virtual 关键字C++ 中的 virtual 关键字 简单介绍一下虚函数表与虚函数指针 单继承时的虚函数表和多继承时的虚函数表有什么区别 为什么虚函数表指针的类型为void * 为什么虚函数表前要加const 虚函数中的默认参数 静态函数可以被声明为虚函数吗 构造函数可以为虚函数吗 析构函数可以为虚函数吗 虚函数可以为私有函数吗 虚函数可以被内联吗 纯虚函数与抽象类的基本概念 为什么不要重写非虚函数 override 关键字从C++11起，引入了新的关键字override，主要用于紧随成员函数声明或定义内成员函数的声明器之后使用。在成员函数声明或定义中，override确保该函数为虚并覆写（overrride）来自基类的虚函数。override是在成员函数声明器后使用时才拥有特殊含义的标识符，其他情况下不是保留的关键字。 123456789101112struct A&#123; virtual void foo(); void bar();&#125;;struct B : A&#123; void foo() const override; // 错误： B::foo 不覆写 A::foo（签名不匹配） void foo() override; // OK ： B::foo 覆写 A::foo void bar() override; // 错误： A::bar 非虚&#125;; final 关键字指定派生类不能覆写虚函数，或类不能被继承。在虚函数声明或定义中使用时，final确保函数为虚且不可被派生类覆写，否则程序生成编译时错误。在类定义中使用时，final指定此类不可出现于另一类的定义的 base-specifier-list 中（换言之，不能从它派生出其他类），否则程序生成编译时错误。final是在用于成员函数声明或类头部时有特殊含义的标识符，其他语境中它非保留关键字，可用于命名对象或函数。 123456789101112131415161718struct Base&#123; virtual void foo();&#125;;struct A : Base&#123; void foo() final; // A::foo 被覆写且是最终覆写 void bar() final; // 错误：非虚函数不能被覆写或是 final&#125;;struct B final : A // struct B 为 final&#123; void foo() override; // 错误： foo 不能被覆写，因为它在 A 中是 final&#125;;struct C : B // 错误： B 为 final&#123;&#125;; explicit 关键字当类的构造函数只有 一个参数 时, C++ 默认会对其调用执行隐式的类型转换. 这时候, 可以使用explicit关键字修饰构造函数, 防止函数参数的隐式转换. (多个参数不涉及隐式转换问题)explicit关键字只能用于类内部的单参数构造函数的声明上, 而不能用于其他函数Effective C++建议, 除非有一个好的理由允许构造函数被用于隐式类型转换, 否则应该将其声明为explicit.还有一个例外情况, 就是如果构造函数除了第一个参数以外, 剩余参数都具有默认值, 那么此时, explicit也有效 extern 关键字C++ 中的 extern 关键字 extern 关键字的主要作用是什么? 如何令 const 对象可以在多个文件中共享 一个源文件定义了char a[6], 在另一个文件使用extern char *a进行声明, 可以吗? 在 C++ 程序中调用被 C 编译器编译后的函数, 为什么要加 extern “C” 当函数提供方单方面修改函数原型时, 使用方却没有修改, 这时候编译会怎么样? 链接时会怎么样? 如何解决? extern 和 static 可以同时修饰一个变量吗? const 关键字C++ 中的const关键字 修饰普通类型的变量: 变量会变成常量, 其值不能再被更改 修饰指针变量: 常量指针, 指向常量的指针, 指向常量的常量指针. 修饰函数参数: 值传递(无需const, 因为自带保护作用), 指针/引用传递(可防止数据被意外篡改) 修饰函数返回值: 内置类型(加不加const区别不大), 自定义类型, 指针/引用. 修饰类成员函数 static 关键字C++ 中的static关键字 static 关键字的作用是什么 都有哪些存储持续性类型和链接性类型 全局变量的链接性是怎么样的? 全局常量呢? 函数存储持续性和是否受static关键字影响? static关键字修饰函数时, 其什么作用? 静态成员数据和静态成员函数有哪些特点? 可以用 const static 来修饰成员数据和成员函数吗? 静态局部变量保存在全局数据区, 而不是保存在栈中, 每次的值保持到下一次调用, 知道下次赋新值 类的静态成员在类实例化之前就存在了, 并分配了内存, 而函数的静态局部变量会在执行函数时才分配内存. const全局常量的链接性为内部, 因此可以放在头文件中而不会重定义 引用 什么是引用? 声明和使用引用时要注意哪些问题? 引用和指针的关系与区别? 将引用作为函数参数有哪些特点? 将引用作为函数返回值类型的优势和注意事项? 在什么时候需要使用常引用? 什么是右值引用? this指针函数指针和函数对象(仿函数)Cpp-函数指针和函数对象 构造函数C++ 中的构造函数和析构函数 子类析构时要调用父类的析构函数吗? 内联函数 虚函数可以是内联函数吗 对于常见的主流编译器, 写不写 inline 有什么影响 内存分配和动态内存C++ 中的内存分配和动态内存 描述 C++ 的内存分配方式以及它们之间的区别? 自由存储区和堆的区别 new 和 malloc 的区别 new 运算符, operator new, new 表达式 delete 和 delete []的区别 如何限制一个类对象只在栈(堆)上分配空间? C++ 浮点数控制输出的小数位数:1std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(3) &lt;&lt; 3.1415 &lt;&lt; endl; math 设计模式 都有哪些设计模式? 具体的实现方法是什么? 二. 字符串及模板篇字符串basic_string 模板类stringstream 字符串流更详细的总结可见:C++ string 完整笔记 模板详细总结请见: C++ 标准模板库STL完整笔记 容器顺序式容器:array ,vector ,list ,deque关联式容器:map, unordered_map, multimap, unordered_multimap, set, unordered_set, multiset, unordered_multiset容器适配器:queue, priority_queue 标准库中各个容器的数据结构是什么? vector 的容量增长机制是怎样的? 内存分配机制是怎样的? 为什么vector::push_back()的复杂度是分摊之后的 $O(1)$? 设计一道可以使用low_bound/upper_bound轻松解决的算法题 实现一下set_intersection()/set_union()/merge() 迭代器在什么情况下会失效? 标准库的线程安全性 list 的insert()/erase()与 vector 相比哪个快? 算法排序 算法 功能 复杂度 sort 默认将区间升序排序 $O(nlogn)$ is_sorted 默认检查区间元素是否按照升序排列 $O(n)$ is_sorted_until 返回满足范围 [first, it) 已排序的最后的迭代器it. $O(n)$ partial_sort 将区间内较小的k个元素排序, 对数复杂度 $O(klogk)$ partial_sort_copy 先将区间内的元素复制, 然后再进行部分排序, 部分排序的数量根据目标范围决定 $O(nlog(\min(n, n_{copy})))$ stable_sort 稳定排序, 将区间内的元素排序, 同时保持相等的元素之间的顺序不变 $O(nlogn^2)$, 若额外内存可用, 则为 $O(nlogn)$ nth_element 对给定的区间部分排序, 使得第n个元素位于排序后的正确位置上, 并且前半段的元素小于等于后半段元素 $O(n)$, 基于 Partition 算法实现 调用示例:12345678910111213141516vector&lt;int&gt; vec = &#123;2,5,8,5,3,2,3,6,8&#125;;std::sort(vec.begin(), vec.end(), [](int a, int b)&#123;return a &gt;= b;&#125;);std::is_sort(vec.begin(), vec.end(), [](int a, int b)&#123;return a &gt;= b;&#125;);auto it = std::is_sort_until(vec.begin(), vec.begin()+3, vec.end(), [](int a, int b)&#123;return a &gt;= b;&#125;);if (it = vec.end()) std::cout &lt;&lt; *it &lt;&lt; std::endl;std::partial_sort(vec.begin(), vec.begin()+3, vec.end(), [](int a, int b)&#123;return a &gt;= b;&#125;);std::partial_sort_copy(vec.begin(), vec.end(), copy.begin(), copy.end(), std::greater&lt;int&gt;()); // 注意这里的greater带有(), 说明是函数, 而不是类型std::stable_sort(vec.begin(), vec.end(), [](int a, int b)&#123;return a &gt;= b;&#125;);std::nth_element(vec.begin(), vec.begin() + vec.size() / 2, vec.end() std::greater&lt;int&gt;()); 查找/搜索 算法 功能 复杂度 返回值 binary_search 检查等价于 value 的元素是在 [first, last) 中, 要求范围内元素必须有序 $O(logn)$ bool equal_range 返回 [first, last) 中等价于 value 的元素范围, 要求范围内元素必须有序 $O(logn)$ 由 lower_bound 和 upper_bound 组成的 pair 对 lower_bound 返回 [first, last) 中 首个不小于(大于等于) value 的元素迭代器, 要求范围内元素必须有序 $O(logn)$ 对应元素的迭代器, 或者 last(没找到) upper_bound 返回 [first, last) 中 首个大于 value 的元素迭代器, 要求范围内元素必须有序 $O(logn)$ 对应元素的迭代器, 或者 last(没找到) search 搜索指定序列, 或者搜索 Searcher 构造函数中指定的模式 $O(N_1\times N_2)$ 返回找到的首个子序列的起始迭代器, 或者 last(没找到) search_n 在 [first, last) 中搜索 count 个值为 value 的序列 $O(n)$ 返回找到的序列的起始迭代器, 或者 last(没找到) find 返回 [first, last) 中满足特定判别标准的 首个 元素 $O(n)$ 返回首个满足条件的迭代器, 或者 last(没找到) find_if 同上 - find_if_not 同上 - - find_end 在范围 [first, last) 中搜索序列 [s_first, s_last] 的最后一次出现 $O(n_s\times (n - n_s +1))$ 返回找到序列的开始迭代器, 或者 last(没找到) find_first_of adjacent_find count count_if all_of any_of none_of mismatch for_each for_each_n 最值 算法 功能 复杂度 返回值 max max_element min min_element minmax minmax_element clamp: 在一堆边界值间夹住一个值 划分 算法 功能 复杂度 返回值 partition is_partitioned partition_copy stable_partition partition_point 排列 算法 功能 复杂度 返回值 is_permutation next_permutation prev_permutation 比较 算法 功能 复杂度 返回值 equal lexicographical_compare compare_3way lexicographical_compare_3way | | | | 集合以下算法均要求范围内的元素已经有序| 算法 | 功能 | 复杂度 | 返回值 || :—: | :—: | :—: | :—: || merge | | | || inplace_merge | | | || includes | | | || set_difference | | | || set_intersection | | | || set_symmetric_difference | | | || set_union | | | | 堆 算法 功能 复杂度 返回值 is_heap is_heap_until make_heap push_heap pop_heap sort_heap 其他123456// generate: 根据函数结果将其值赋给范围内的每个元素std::srand(0);std::generate(vec.begin(), vec.end(), []()&#123;return std::rand() % 100;&#125;);// generate_n: 根据函数结果将其值赋给范围起始的前n个元素 三. 高级篇lambda 表达式C++中的lambda表达式 C++中的协变与逆变https://www.jianshu.com/p/db76a8b08694 智能指针C++ 中的智能指针 栈内存与文字常量区Linux 多进程, 多线程并发]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode算法题(Medium)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-2%2F</url>
    <content type="text"><![CDATA[002. Add Two NumbersDescription: 链表数之和You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example: Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 解法一: 顺序相加, 注意进位从链表的第一个节点开始, 将两个节点的值和进位位想加, 如果大于10, 则当前结果节点的值对10取余, 同时将进位位置1, 如果小于10, 则直接赋值给当前结果节点, 同时将进位位置0. 特别注意 l1 和 l2 的长度问题, 当二者节点遇到 nullptr 时, 将较长的剩余部分重新赋给l1, 并继续判断 最后, 需要注意是否有进位位, 如果有, 则要申请一个新节点, 并将其置为1 时间复杂度: $O(\max(m,n))$空间复杂度: $O(1)$ (这种做法会破坏原有链的结构) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; int carry = 0; ListNode* head = new ListNode(0); //创建指向最终结果的头指针 if(l1!=nullptr) head-&gt;next = l1; // 虽然题目指明为非空链表, 但是最好还是做一下判断 else head-&gt;next = l2; ListNode* pre=head; // pre用于保存l1的上一个指针 while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; l1-&gt;val = l1-&gt;val + l2-&gt;val + carry; if(l1-&gt;val &gt; 9)&#123; l1-&gt;val %= 10; carry = 1; &#125;else&#123; carry = 0; &#125; pre = l1; l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; if(l2!=nullptr)&#123; // 此时说明l2比l1长, 用l1的上一个指针指向当前l2剩余的部分, l1 = pre; l1-&gt;next = l2; l1 = l1-&gt;next; &#125; while(l1!=nullptr)&#123; // 此时l1为剩余(l1或l2) 的部分, 只需要考虑是否有进位即可 l1-&gt;val = l1-&gt;val + carry; if(l1-&gt;val &gt; 9)&#123; l1-&gt;val %= 10; carry = 1; &#125;else&#123; carry = 0; // 如果没有进位, 一定要将此处置0, 否则会引起错误 break; &#125; pre = l1; l1 = l1-&gt;next; &#125; if(carry == 1)&#123; // 对应 999 + 001 的特殊情况, 此时进位会不断传递, 最终数字位数加1, 最高位为1 ListNode* newnode = new ListNode(1); l1 = pre; l1-&gt;next = newnode; &#125; return head-&gt;next; &#125;&#125;; 解法二: 顺序相加, 维持原链表时间复杂度: $O(\max(m,n))$空间复杂度: $O(\max(m,n))$ (这种做法需要额外申请空间, 但不会破坏原有链的结构) 该解法思路与解法一一致, 只不过每次都申请一个新的节点, 确保不会改变原有链表的结构. 1234567891011121314151617181920212223242526class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode *dummy = new ListNode(0); ListNode *pre = dummy; int carry = 0; while(l1!=nullptr || l2!=nullptr)&#123; ListNode *cur = new ListNode(0); int a = l1==nullptr ? 0 : l1-&gt;val; int b = l2==nullptr ? 0 : l2-&gt;val; cur-&gt;val = a + b + carry; carry = cur-&gt;val / 10; cur-&gt;val = cur-&gt;val % 10; pre-&gt;next = cur; pre = cur; if(l1!=nullptr) l1 = l1-&gt;next; if(l2!=nullptr) l2 = l2-&gt;next; &#125; if(carry &gt; 0)&#123; pre-&gt;next = new ListNode(carry); &#125; return dummy-&gt;next; &#125;&#125;; 扩展问题What if the the digits in the linked list are stored in non-reversed order? For example: $(3 \to 4 \to 2) + (4 \to 6 \to 5) = 8 \to 0 \to 7 (3→4→2)+(4→6→5)=8→0→7$ 思路: 先将链表转置 , 再用上面的方法求解 转置时间复杂度: $O(n)$转置空间复杂度: $O(1)$ 003. Longest Substring Without Repeating CharactersDescription: 寻找无重复字符的最长子串Given a string, find the length of the longest substring without repeating characters. Example 1:123Input: &quot;abcabcbb&quot;Output: 3Explanation: The answer is &quot;abc&quot;, with the length of 3. Example 2:123Input: &quot;bbbbb&quot;Output: 1Explanation: The answer is &quot;b&quot;, with the length of 1. Example 3:123Input: &quot;pwwkew&quot;Output: 3Explanation: The answer is &quot;wke&quot;, with the length of 3. Note that the answer must be a substring, “pwke” is a subsequence and not a substring. 解法一:暴力时间复杂度: $O(n^3)$ 对于每一个字符, 子串的添加以及查重过程时间复杂度为 $O(n^2)$ , 总共n个字符, 所以为 $O(n^3)$空间复杂度: $O(min(n,m))$ 需要将当前子串存在起来以便查询是否相等, n为字符串length, m为字符集size 解法二: 前后两个指示变量时间复杂度: $O(2n) = O(n)$空间复杂度: $O(min(n,m))$ 思路: 首先构造一个哈希表, 用来存储当前子串中出现的字符, 这样, 新来的字符可以直接查询哈希表来判断字符是否存在, 构建哈希表空间复杂度为 O(min(n,m)) ( $m$ 为字符集合的大小,一般为26(字母), 128(ASCII), 256(ASCII), $n$ 为字符串的长度) 然后, 使用两个指示变量, 分别指向当前未重复子串的首字符, 和超尾字符, 进行如下几个判断: 如果超尾字符与当前子串中的字符不重复, 那么将超尾字符加入到当前子串中,并将length加1 如果超尾字符与当前子串中的字符重复, 利用哈希表查的重复字符的所在位置, 将当前子串的首字符直接跳向该重复字符的下一个位置( 这样可以保证只遍历一遍 ), 并将包括重复字符在内的之前所有字符都从哈希表中删除(之前的字符不再可能组成更长的子串了), 同时将超尾字符加入, length赋予新值: 超尾位置-重复位置-1; 判断首字符与超尾字符是否相等, 如果相等, 将超尾字符加1, 并将length置为1 看当前length是否比maxlength大, 并重复以上过程,直到超尾字符超出size 12345678910111213141516171819class Solution &#123;public: int lengthOfLongestSubstring(string s)&#123; int hash[256]=&#123;0&#125;; int max_len = 0; for(int l=0, r=0; r&lt;s.size(); )&#123; if(hash[s[r]] == 0)&#123; hash[s[r]] = 1; max_len = std::max(max_len, r-l+1); r++; &#125;else&#123; hash[s[l]] = 0; l++; &#125; &#125; return max_len; &#125;&#125;; 解法三: 只需一次遍历时间复杂度: $O(n)$, 只需一次遍历空间复杂度: $O(min(m,n)$, 与解法二相同 当我们在 [i,j) 之间发现了一个重复的下标为 j&#39; 的字符时, 我们不用一点点的增加 i 的值, 而是可以直接将 i 的值跳到 j&#39;+1 处. 故, 我们可以只利用一次遍历就找到最长的不重复子串. 123456789101112131415161718class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; unordered_map&lt;char, int&gt; s_hash; int max_length = 0; for(int i = 0 ,j=0 ; j&lt; s.size() ; j++)&#123; if(s_hash.count(s[j]))&#123; // 这里未删除 i 之前的, 所以即使这里的哈希可以查到, 也不一定就是重复. i = max(i,s_hash[s[j]]+1); //如果遇到重复的, 就将当前的i指向重复的下一个 // (这里用max的原因是, 没有删除当前i到重复字符之间的其他字符, 这些字符 // 后续还可能被检测到, 所以这里只取max的, 也就是i不会倒退) //s_hash.erase(s[j]); // 该语句是多余的 &#125; s_hash[s[j]] = j; max_length = max_length &gt; (j-i+1) ? max_length : (j-i+1); &#125; return max_length; &#125;&#125;; 用数组做哈希表:12345678910111213141516class Solution &#123;public: int lengthOfLongestSubstring(string s)&#123; int hash[256];// 哈希表中存在的值代表下标 for(auto &amp;item : hash) item = -1; // 赋初值 int max_len = 0; for(int i=0, j=0; j &lt; s.size(); j++)&#123; if(hash[s[j]] != -1)&#123; // 当哈希表中值不为-1时, 说明存在重复 i = std::max(hash[s[j]] + 1, i); // 注意这里必须保证 i 不会倒退, 因此要使用 max &#125; max_len = std::max(max_len, j-i+1); hash[s[j]] = j; &#125; return max_len; &#125;&#125;; 005. Longest Palindromic SubstringDescription: 最大回文子串Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. Example 1: Input: “babad”Output: “bab”Note: “aba” is also a valid answer.Example 2: Input: “cbbd”Output: “bb” 解法一：最长公共子串时间复杂度: $O(n^2)$空间复杂度: $O(n)$ 先将字符串 s 利用 reverse 逆置成 s&#39;, 然后查找 s 和 s&#39; 的最长公共子串, 即为最长的回文子串. 解法二： 穷举时间复杂度: $O(n^3)$空间复杂度: $O(1)$ 对于字符串中的每一个字符, 共有 $\frac{n(n-1)}{2}$ 种包含该字符的子串, 所以如果对所有可能的子串判断, 需要 $O(n^3)$ 的时间复杂度 解法三： 动态规划时间复杂度: $O(n^2)$空间复杂度: $O(n^2)$ 我们令 DP 数组为一个 $n\times n$ 的矩阵, $dp(i,j)$ 代表从 s[i] 开始, 到 s[j] 结束的子串是否为回文串, 如果是, 则为 true. 那么, $dp(i,j)$ 为真的条件就是必须满足 $dp(i+1, j-1)=true$ 并且 $s[i]=s[j]$. dp 数组的初始值为: $dp(i,i)=true$, $dp(i,i+1)= s[i]==s[i+1]$. 由于需要遍历 dp 矩阵中每一个位置的值, 因此时间复杂度为 $O(n^2)$, 空间复杂度很明显为 $O(n^2)$. 解法三： 扩展中心法时间复杂度: $O(n^2)$空间复杂度: $O(1)$ 或者 $O(n)$ 以每一个字符为中心, 向两边扩展, 将当前能够扩展的长度 len 和最大扩展长度 max_len 作比较, 记录较大者, 同时记录较大者的所对应的中心字符的下标 max_index. 最后, 根据最大扩展的长度max_len 和中心字符的下标 max_index 计算最大回文子串的开始位置和总长度 此处注意, 回文子串有奇偶两种情况, 可采用以下举措之一解决: 分别检查奇数和偶数的情况, 这样多检查一次(虽然多检查一次, 但和下面的检查总次数差不多, 因为下面虽然只检查一次, 但次数较多) 向字符内插入特殊符号 ‘#’, 这样不管偶数奇数, 都可以当做奇数处理, 缺点是占用了额外的 $O(n)$ 空间. 注意: 既然已经使用了空间复杂度为 $O(n)$ 的方法, 实际上更应该将其该写成马拉车算法 12345678910111213141516171819202122232425262728293031// 空间复杂度 $O(1)$class Solution &#123;public: string longestPalindrome(string s) &#123; int max_len = 0; int start = 0; for(int i=0; i &lt; s.size(); i++)&#123; int len1=0,len2=0; int left=i, right = i; //通过left和right , 是的对奇偶的分别处理更方便 while( left &gt;=0 &amp;&amp; right&lt;s.size() &amp;&amp; s[left] == s[right])&#123; left--; right++; &#125; len1 = right-left-1; // 注意, 这里一定是-1, 而不是+1 left=i; right=i+1; while( left&gt;=0 &amp;&amp; right&lt;s.size() &amp;&amp; s[left] == s[right])&#123; left--; right++; &#125; len2 = right-left-1; int len = max(len1, len2); if(len&gt;max_len)&#123; max_len = len; start = i- (len-1)/2; &#125; &#125; return s.substr(start, max_len); &#125;&#125;; 另一种写法: 1234567891011121314151617181920212223242526272829303132333435363738// 空间复杂度 $O(1)$class Solution &#123;public: string longestPalindrome(string s) &#123; int max_i = 0; int max_len = 0; for(int i = 0; i&lt;s.size(); i++)&#123; int left, right; left = i, right = i; while(s[left] == s[right])&#123; // 奇数情况 left--; right++; if(left &lt; 0 || right == s.size())&#123; break; &#125; &#125; if(max_len &lt; right-left-1)&#123; max_len = right-left-1; max_i = i; &#125; left = i, right = i+1; // 下面要对 right 判断, 防止越界 while(right !=s.size() &amp;&amp; s[left] == s[right])&#123;// 偶数 left--; right++; if(left &lt; 0 || right == s.size())&#123; break; &#125; &#125; if(max_len &lt; right-left-1)&#123; max_len = right-left-1; max_i = i+1;//偶数时令max_i指向偏右的下标 &#125; &#125; return s.substr(max_i-max_len/2, max_len); &#125;&#125;; 1234567891011121314151617181920212223242526272829303132// 空间复杂度 $O(n)$class Solution &#123;public: string longestPalindrome(string s) &#123; char* cs = new char[s.size() * 2+1]; cs[0]='#'; for(int i=0; i&lt;s.size() ; i++)&#123; //插入 '#' cs[i*2+1] = s[i]; cs[i*2+2] = '#'; &#125; int max_len=0; int max_index = 0; for(int i =0; i&lt;s.size()*2+1 ; i++)&#123; int len=0; //记录当前扩展长度len for(int j=1; i-j&gt;=0 &amp;&amp; i+j&lt;s.size()*2+1 ;j++)&#123; if(cs[i-j] == cs[i+j])&#123; //两边字符若相等, 则len长度增1 len++; &#125;else break; &#125; if(len &gt; max_len)&#123; max_len = len; max_index = i; &#125; &#125; int start = (max_index - max_len)/2; //根据maxlen和index 计算回文子串开始坐标 int len = max_len; delete cs; return s.substr(start, len); &#125;&#125;; 解法五: 马拉车(Manacher) 算法时间复杂度: $O(n)$空间复杂度: $O(n)$ There is even an O(n), O(n) algorithm called Manacher’s algorithm, explained here in detail. However, it is a non-trivial algorithm, and no one expects you to come up with this algorithm in a 45 minutes coding session. But, please go ahead and understand it, I promise it will be a lot of fun. 马拉车算法的核心思想还是从中心扩展发出发, 不过他必须使用 ‘#’ 字符先对原始字符串插入, 如下所示: 接下来, 在每一次 for 循环当中, 都需要保存这么几个值(命名是个人习惯, 可以用其他名字代替): P: P 为最大右边界下标值, 对应的是所有已检测的回文子串中, 右边界下标最大的那个 P_center: 该值是P对应的回文子串的中心下标 max_len: 对应当前最大回文子串的半径(aba的半径为1, a的半径为0) max_index: 对应当前最大回文子串的中心下标 然后, 还需要构建一个和插入’#’后的字符串长度相关的数组 p_len, 里面存放着对应位置的回文串半径, 用以后续的计算, 这一步是关键, 有了这个数组 ,才能实现利用之前计算结果 接下来, 遍历 “新字符串”(即插入’#’之后的字符串) 的每一个字符, 设当前下标为 i, 则有如下情况, 分别处理: P&gt;i, 说明 i 在 P 的范围内, 可以利用前面的计算结果 P&lt;=i, 说明 i 不在 P 的范围内, 无法利用前面的计算结果, 只能逐个判断 对上面两种情况具体分析如下: 第一种情况: P&gt;i 找到i相对于 P_center 的对称位置, 设为j, 那么如果Len[j]&lt;P-i, 如下图所示: 则以i为中心的回文串的长度至少和以j为中心的回文串一样 , 即Len [i]&gt;=Len[j] , 因此可以直接从Len[j]+1开始判断回文 如果Len[j]&gt;=P-i, 如下图所示: 由对称性, 说明以i为中心的回文串可能会延伸到P之外, 而大于P的部分我们还没有进行匹配, 所以要从P+1位置开始一个一个进行匹配, 直到发生失配 第二种情况: P&lt;=i 如果i比P还要大, 说明对于中点为i的回文串还一点都没有匹配, 这个时候, 就只能老老实实地一个一个匹配了 在这一次循环完成之前, 更新上面提及的四个变量 循环结束后, 根据 max_index 和 max_len 的值返回最长回文子串 时间复杂度分析: 对于每一个字符, 由于如果直接比较过, 那么就可以利用之前比较的结果直接判断, 所以每个字符都只进行了一次比较, 故而时间复杂度为 $O(n)$ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123;public: string longestPalindrome(string s) &#123; int cs_size = s.size()*2+1; char* cs = new char[cs_size]; cs[0] = '#'; for(int i = 0;i&lt;s.size(); i++)&#123; cs[i*2 + 1] = s[i]; cs[i*2 + 2] = '#'; &#125; int P = 0; int P_center = 0; int max_index = 0; int max_len = 0; int* p_len = new int[cs_size]; for(int i =0; i&lt;cs_size; i ++)&#123; if( i &lt; P)&#123; // 如果i&lt;P, 说明可以复用前面的计算结果 int j = P_center*2 - i; // j对i关于P_center的对称点 if(P-i &gt; p_len[j])&#123; // 如果i与P之间的距离比 j 的回文串长度还大, //说明可以直接从p_len[j] + 1开始比较, 之前的子串一定是回文串 int k = p_len[j] + 1; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125;else&#123; // 如果距离没有p_len[j] + 1大, 则从超出P的部分开始比较 int k = P - i; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125; &#125;else&#123; //如果i不在P范围内, 则必须从1开始逐个比较, 无法利用之前的计算结果 int k = 1; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125; if(p_len[i] &gt; max_len)&#123; max_len = p_len[i]; max_index = i; &#125; if(i+p_len[i] &gt; P)&#123; P = i+p_len[i]; P_center = i; &#125; &#125; delete cs; delete p_len; int start = (max_index - max_len)/2; int len = max_len; return s.substr(start, len); &#125;&#125;; 008. String to Integer (atoi)Description: 将字符串转换成整数解法一: 考虑多种情况此题时间复杂度为 $O(n)$ , 重点考察是否考虑的全面, 主要有以下几种情况, 缺一不可: +123 dd // 返回123 +123d // 返回123 d-123 // 返回0 -123+ //返回-123 -123+4 // 返回-123 323123423423423 // 返回INT_MAX -1231238923894234 // 返回INT_MIN 1234-5 // 返回1234 123456789101112131415161718192021222324252627282930class Solution &#123;public: int myAtoi(string str) &#123; int sign =1; bool is_first = true; //记录当前非数字字符是否是第一个非空格字符, 如果是, 返回0 bool has_sign = false; // 记录正负号的出现次数, 出现多于1次的, 返回0 long res = 0; //记录当前的int值, 要出现int范围, 返回对应的INT for(int i =0 ; i&lt;str.size(); i++)&#123; if(str[i] == ' ' &amp;&amp; is_first) continue; // 空格, 且没有出现任何非空格字符(如出现了, 则空格也会跟着变成循环停止的标志) else if( !has_sign &amp;&amp; (str[i] == '+' || str[i] == '-') )&#123; // 判断符号 has_sign = true; is_first = false; sign = str[i]=='+' ? 1:-1; &#125;else if(str[i] &lt;= '9' &amp;&amp; str[i] &gt;= '0')&#123; has_sign = true; is_first = false; res = res*10 + int(str[i] - '0') * sign; // 数字累加, 注意这里使用了sign, 因此无需在后面判断正负, 直接加就可以 if (res &gt; INT_MAX) return INT_MAX; // 超限 else if(res &lt; INT_MIN) return INT_MIN; &#125;else if(is_first)&#123; //首字符为非法字符, 返回0 return 0; &#125;else&#123; break; &#125; &#125; return int(res); &#125;&#125;; 011. Container With Most WaterDescriptionGiven n non-negative integers a1, a2, …, an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. The below vertical lines are represented by array [1,8,6,2,5,4,8,3,7]. In this case, the max area of water (blue section) the container can contain is 49. 解法一: 暴力时间复杂度: $O(n^2)$ 用max_area标记当前最大容器的取值, 然后两个for循环遍历所有容器的可能取值 1234567891011121314class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int max_area = 0; for(int i=0; i&lt;height.size(); i++)&#123; for(int j = i+1; j &lt; height.size(); j++)&#123; if(max_area &lt; min( height[i],height[j] ) * (j-i))&#123; max_area = min( height[i],height[j] ) * (j-i); &#125; &#125; &#125; return max_area; &#125;&#125;; 解法二: 用两个指针时间复杂度: $O(n)$空间复杂度: $O(1)$ 分别用两个指针指向数组的第一个元素和最后一个元素, 并计算当前的area, 然后移动指针元素值较小的一方, 移动过程中更新max_area的值 原理: 首先假设容器可以具有最大长度的宽, 也就是分别指向首尾元素, 这时候 , 我们想查看是否还有比当前最大容积更大的容器, 那么, 我们必须维持较高的垂直边不动, 而将较低的垂直边移动, 因为只有这样, 我们才 有可能 (注意不是一定)获得比当前容积更大的容器, 这个时候虽然宽变小了, 但是高度却可能增加(因为新增的边有可能大于当前较低边的高). 如果移动较高的边, 那么新增的边由于受到当前较低边的作用, 只有可能减小容器的面积 123456789101112131415161718class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int low = 0, high = height.size()-1; int max_area = 0; while(low&lt;high)&#123; int area = min( height[low], height[high] ) * (high-low); if(max_area &lt; area)&#123; max_area = area; &#125; if(height[low] &lt; height[high]) low++; else high--; &#125; return max_area; &#125;&#125;; 015. 3SumDescription: 三数和为零Given an array nums of n integers, are there elements a, b, c in nums such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. Note:The solution set must not contain duplicate triplets. Example:1234567Given array nums = [-1, 0, 1, 2, -1, -4],A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 解法一: 固定一个数, 剩余两个数用双指针法求时间复杂度: $O(n^2+nlogn)=O(n^2)$空间复杂度: $O(1)$, 无需额外空间 解题步骤: 对整个数组排序, $O(nlogn)$; 固定下标 i, 令下标j=i+1, 令 k=nums.size()-1. 如果 nums[i] 为正数, 说明不可能组成和为零的三元组, 直接返回当前结果; 为了消除重复, 对于相同的相邻元素, 我们只选其中的一个参与组合. 注意: 这里的重复是指三元组的值的重复, 而不是下标重复, 也就是说, 对于下标不同但值相同的元素, 也算作重复. 重复(2)(3)(4)过程直到循环终止. 排序的必要性: 这里我们排序的主要目的是为了消除重复, 如果题目允许重复, 那么可以不进行排序, 而采用基于哈希表的 TwoSum 来求解. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Solution &#123;public: int partition(vector&lt;int&gt;&amp; nums, int low, int high)&#123; if(nums[low] != nums[(low+high)/2])&#123; // 注意这里用异或交换的陷阱 nums[low] = nums[low] + nums[(low+high)/2]; nums[(low+high)/2] = nums[low] - nums[(low+high)/2]; nums[low] = nums[low] - nums[(low+high)/2]; &#125; // 主要是将中将的数字和首位交换, 个人觉得可有可无, 因为时间复杂度是一样的 int P = nums[low]; while(low &lt; high)&#123; while(low&lt;high &amp;&amp; P&lt;=nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P&gt;=nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125; void quickSort(vector&lt;int&gt;&amp; nums, int low, int high)&#123; int mid = partition(nums, low, high); if(low&lt;mid ) quickSort(nums, low, mid-1); if(mid&lt;high) quickSort(nums, mid+1, high); &#125; vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(nums.size()&lt;3) return res; quickSort(nums, 0, nums.size()-1); for(int i =0; i&lt;nums.size(); i++)&#123; if(nums[i]&gt; 0) break; //剪枝, 如果当前数字为正, 那么后面就不可能再有符合条件的三元组, 可以提前退出 if(i&gt;0 &amp;&amp; nums[i] == nums[i-1] ) continue; //去除重复, 遇到除第一个外相同的三元组最小的数字, 则跳过 int low = i+1, high = nums.size()-1; while(low &lt; high)&#123; if(low&gt;i+1 &amp;&amp; nums[low] == nums[low-1])&#123; // 仍然是去除重复, low++; continue; &#125; int sum = nums[low] + nums[i] + nums[high]; if(sum&gt;0) high--; else if(sum&lt;0) low++; else&#123; vector&lt;int&gt; tmp&#123;nums[low], nums[i], nums[high]&#125;; res.push_back(tmp); low++; // 这一点千万别漏了, 要继续判断, 因为以当前数字开始的三元组可能不止一个 &#125; &#125; &#125; return res; &#125;&#125;; 更好的写法:12345678910111213141516171819202122232425vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; result; if(nums.size()&lt;=2)return result; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size() - 2; i++) &#123; int a = nums[i]; if(a &gt; 0) break; if (i &gt; 0 &amp;&amp; a == nums[i - 1]) continue;// 这里不能用nums[i]==nums[i+1], 因为会丢掉类似于 -1,-1,2 的解. for (long j = i + 1, k = nums.size() - 1; j &lt; k;) &#123; int b = nums[j]; int c = nums[k]; int value = a + b + c; if (value == 0) &#123; result.push_back(vector&lt;int&gt;(&#123;a, b, c&#125;)); while (j &lt; k &amp;&amp; b == nums[++j]); // 主要是这里的写法很优雅, 其他地方和上面差不多 while (j &lt; k &amp;&amp;c == nums[--k]); &#125; else if (value &gt; 0) &#123; k--; &#125; else &#123; j++; &#125; &#125; &#125; return result; &#125; 解法二: python写法123456789101112131415161718192021class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: nums.sort() target = 0 res = [] for p1 in range (len(nums) - 2): if (nums[p1] &gt; 0): return res if (p1 &gt; 0 and nums[p1] == nums[p1-1]): continue p2 = p1 + 1 p3 = len(nums) -1 while (p2 &lt; p3): if (p2-1 != p1 and nums[p2] == nums[p2-1]): p2 += 1 continue tmp = nums[p1] + nums[p2] + nums[p3] if (tmp &gt; 0): p3 -= 1 elif (tmp &lt; 0): p2 += 1 else: res.append([nums[p1], nums[p2], nums[p3]]) p2 += 1 return res 017. Letter Combinations of a Phone NumberDescription: 九键字母组合Given a string containing digits from 2-9 inclusive, return all possible letter combinations that the number could represent.A mapping of digit to letters (just like on the telephone buttons) is given below. Note that 1 does not map to any letters. Example:12Input: &quot;23&quot;Output: [&quot;ad&quot;, &quot;ae&quot;, &quot;af&quot;, &quot;bd&quot;, &quot;be&quot;, &quot;bf&quot;, &quot;cd&quot;, &quot;ce&quot;, &quot;cf&quot;]. Note:Although the above answer is in lexicographical order, your answer could be in any order you want. C++解法一: 递归时间复杂度: $O(n4^n)$, $n$ 为数字的长度*空间复杂度: $O(4^n)$ 1234567891011121314151617181920212223242526class Solution &#123;public: void back_tracking(vector&lt;string&gt;&amp; res, const vector&lt;string&gt;&amp; digit_letters, string&amp; tmp,string digits, int index)&#123; if(index == digits.size())&#123; res.push_back(tmp); &#125; else &#123; for(int i=0; i&lt;digit_letters[digits[index]-'0'].size(); i++)&#123; tmp.push_back(digit_letters[digits[index]-'0'][i]); back_tracking(res, digit_letters, tmp, digits, index+1); tmp.pop_back();// 移除当前末尾元素, 以便可以加下一个 &#125; &#125; &#125; vector&lt;string&gt; letterCombinations(string digits) &#123; vector&lt;string&gt; res; if(digits.size() &lt;=0) return res; //res.push_back(""); //在递归解法中, 不需要改语句. const vector&lt;string&gt; digit_letters&#123;"","","abc","def","ghi","jkl", "mno","pqrs","tuv","wxyz"&#125;; string tmp=""; back_tracking(res, digit_letters, tmp, digits, 0); return res; &#125;&#125;; 解法二: 非递归时间复杂度: $O(n4^n)$, $n$ 为数字数组的长度*空间复杂度: $O(4^n)$ 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;string&gt; letterCombinations(string digits) &#123; vector&lt;string&gt; res; if(digits.size() &lt;=0) return res; res.push_back(""); //对res向量初始化,以便开始, 如果不初始化, 则size为0,后面的循环无法进行 const vector&lt;string&gt; digit_letters&#123;"","","abc","def","ghi","jkl", "mno","pqrs","tuv","wxyz"&#125;; for(int i =0 ;i&lt;digits.size(); i++)&#123; int num = digits[i] - '0'; if(digit_letters[num] == "") continue; vector&lt;string&gt; tmp; // 申请一个临时vector, 用于存放加上当前数字字符的string集合 for(int k = 0; k &lt; digit_letters[num].size(); k++)&#123; for(int l =0; l &lt; res.size(); l++)&#123; tmp.push_back(res[l]+digit_letters[num][k]); &#125; &#125; res.swap(tmp); // 将res于tmp交换, swap仅仅是改变指针, 比'='更快, 因为'='包含了复制 &#125; return res; &#125;&#125;; Python解法一: 利用reduce实现123456789101112131415class Solution: def letterCombinations(self, digits): """ :type digits: str :rtype: List[str] """ if digits=="": return [] digit_letters = &#123;'0':"", '1':"", '2':"abc", '3':"def", '4':"ghi", '5':"jkl", '6':"mno", '7':"pqrs", '8':"tuv", '9':"wxyz"&#125; from functools import reduce # 在python3中, reduce()函数已经从全局命名空间移除, 现在存在于functools模块中,使用时需要导入 return reduce(lambda res,digit:[x+y for x in res for y in digit_letters[digit]], digits, [""]) 018. 四数之和解法:转换成两数之和 123456789101112131415161718192021222324252627class Solution: def fourSum(self, nums: List[int], target: int) -&gt; List[List[int]]: def twoSum(nums, target, k, res, tmp_res): if(len(nums) &lt; k or nums[0] * k &gt; target or nums[-1] * k &lt; target): return if (k == 2): i = 0 j = len(nums) - 1 while (i &lt; j): if (i &gt; 0 and nums[i-1] == nums[i]): i += 1 continue tmp = nums[i] + nums[j] if (tmp &lt; target): i += 1 elif (tmp &gt; target): j -= 1 else: res.append(tmp_res + [nums[i], nums[j]]) i += 1 else: for i in range(len(nums)): if (i &gt; 0 and nums[i-1] == nums[i]): #i += 1 这里不论加不加 i 效果都一样, 为什么? continue twoSum(nums[i+1:], target-nums[i], k-1, res, tmp_res+[nums[i]]) res = [] twoSum(sorted(nums), target, 4, res, []) return res 019. Remove Nth Node From End of ListDescription: 移除链表的倒数第 N 个字符Given a linked list, remove the n-th node from the end of list and return its head. Example:123Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5. Note:Given n will always be valid. Follow up:Could you do this in one pass? 解法一: 遍历两次第一次遍历求出链表长度, 第二次遍历在对应位置删除节点 解法二: 双指针, 只遍历一次时间复杂度: $O(n)$ 且只遍历一次 空间复杂度: $O(1)$ 维护两个指针, 两指针之间的距离刚好相差n, 当第二个指针到达链表尾部时, 第一个指针刚好指向倒数第n个节点, 直接删除该节点即可. 12345678910111213141516171819202122232425/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; ListNode* first = head; ListNode* second = head; while (n--) &#123; first = first-&gt;next; &#125; if (first == nullptr) return head-&gt;next; // 链表长度为n, 删除倒数第n个节点 while (first-&gt;next != nullptr) &#123; second = second-&gt;next; first = first-&gt;next; &#125; second-&gt;next = second-&gt;next-&gt;next; return head; &#125;&#125;; 下面是有一种写法, 新申请了一个节点空间, 用于指向head节点, 可以使代码看起来更容易理解, 对边界条件的判断也更加方便 123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; if(head == nullptr || n &lt;= 0) return head; //链表为空, 或者n&lt;=0时, 直接返回head ListNode* dummy = new ListNode(0); dummy-&gt;next = head; ListNode* first = dummy; ListNode* second = dummy; for(int i = 0; i &lt; n ; i++)&#123; second = second-&gt;next; if(second == nullptr) return dummy-&gt;next;// n超出了链表的长度 &#125; while(second-&gt;next!=nullptr)&#123; first = first-&gt;next; second = second-&gt;next; &#125; first-&gt;next = first-&gt;next-&gt;next; return dummy-&gt;next; &#125;&#125;; 022. Generate ParenthesesDescription解法一: 暴力先求出所有可能性, 然后验证每一种可能性是否正确 解法二: 回溯有关递归的时间空间复杂度分析起来都不太容易, 这里只上答案(//TODO 具体怎么来没搞懂) 时间复杂度: $O(\frac{4^n}{\sqrt n})$空间复杂度: $O(\frac{4^n}{\sqrt n})$ 以及 $O(n)$ 的空间来存储组合序列 考虑合法括号组合的规律: 必须首先出现左括号, 然后才能出现右括号, 如果当前的string里面的右括号数量大于左括号数量, 那么就一定会出现)(这种不匹配的情况. 核心思路: 从头开始构建组合, 每次接入一个字符, 接入的字符只有两种可能性, 即左括号或者右括号, 而一旦接入的字符使得当前字符中右括号数量大于左括号, 就会变得不合法组合,其它均为合法. 根据此性质, 进行如下递归: 维护两个变量left_rest, right_rest分别代表 剩余 可以添加的括号的 数量. 采用递归算法, 每次添加一个 ‘(‘ 或者一个 ‘)’, 添加时需要考虑下面几种情况: 为了保证当前string内左括号数量多于右括号数量, left_rest一定要小于right_rest 如果left_rest = right_rest = 0, 则说明此时没有可以添加的括号了. 1234567891011121314151617class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; vector&lt;string&gt; res; helper(res, "", n, n); return res; &#125; void helper(vector&lt;string&gt; &amp;res, string out, int left_rest, int right_rest)&#123; //注意这里的 out 不能生命成引用形式 //if(left_rest &gt; right_rest) return; if(left_rest == 0 &amp;&amp; right_rest ==0) res.push_back(out); else&#123; if(left_rest&gt;0) helper(res, out+'(', left_rest-1, right_rest); if(right_rest&gt;0 &amp;&amp; right_rest &gt; left_rest) helper(res, out+')', left_rest, right_rest-1); &#125; &#125;&#125;; 解法三: Closure Number时间复杂度: $O(\frac{4^n}{\sqrt n})$, 同解法4空间复杂度: $O(\frac{4^n}{\sqrt n})$, 同解法4 该方法可以看做是一种插入法, 选定一组括号 (), 由此便消耗了一组括号的数量, 此时还剩下 n-1 组括号, 我们将这 n-1 组括号插入到选定的括号中, 即 (left)right, 其中, left 和 right 都是有效的括号组合, 它们的括号组数加起来刚好为 n-1, 因此, left 的括号组数的情况共有 n 种情况: [0, …, n-1], 对应的 right 的组数有 n-1-left 组. 具体代码实现如下所示: 123456789101112131415class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; vector&lt;string&gt; res; if(n==0)&#123; res.push_back(""); &#125;else&#123; for(int c=0; c&lt;n; c++) for(string left : generateParenthesis(c)) for(string right : generateParenthesis(n-1-c)) res.push_back("("+left+")"+right); &#125; return res; &#125;&#125;; 解法四: 用栈来模拟递归首先是最厚的括号包裹状态, 即一开始左边是连续的左括号, 右边是连续的右括号, 然后执行以下逻辑： 右括号不能比左括号多; 弹出右括号, 直到遇到第一个左括号, 如果左括号改成右括号仍然合法, 则把它改成右括号; 否则, 左括号继续弹出; 改完之后一个劲加左括号, 直到所有可以用的左括号都加完为止; 然后再一个劲的加右括号, 直到加完位置; 循环一直执行到不能弹出括号为止, 即直到栈为空. 这里刚好凸显了一件事情, 那就是要注意尽可能不要将自增或自减操作写在 while() 条件句里面, 否则会造成一些很难发现的错误, 下面代码中的注释会说明 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; int left = n; int right = n; vector&lt;string&gt; res; string s; // 注意, 将left写在while里面的问题时, 当left为0时才会结束while // 但是此时会使得 left 变成 -1, 因此, 需要再left++, 或者讲left--写在 while 里面 while (left--) &#123; s += '('; &#125; left++; while (right--) &#123; s += ')'; &#125; right++; res.push_back(s); while (!s.empty()) &#123; if (s.back() == ')') &#123; s.pop_back(); right++; &#125; else if (left+1 &lt; right) &#123; left++; right--; s.back() = ')'; while (left--) s.push_back('('); left++; while (right--) s.push_back(')'); right++; res.push_back(s); &#125; else &#123; s.pop_back(); left++; &#125; &#125; return res; &#125;&#125;; 029. Divide Two IntegersDescription: 实现除法Given two integers dividend and divisor, divide two integers without using multiplication, division and mod operator.Return the quotient after dividing dividend by divisor.The integer division should truncate toward zero. Example 1:12Input: dividend = 10, divisor = 3Output: 3 Example 2:12Input: dividend = 7, divisor = -3Output: -2 Note:Both dividend and divisor will be 32-bit signed integers.The divisor will never be 0.Assume we are dealing with an environment which could only store integers within the 32-bit signed integer range: $[−2^{31}, 2^{31 − 1}]$. For the purpose of this problem, assume that your function returns 2^{31 − 1} when the division result overflows. 解法一: 循环加法时间复杂度: $O(dividend)$ 这种方法很容易时间超限: 当被除数很大(INT_MAX), 除数很小(1), 则需要循环INT_MAX次才能完成计算. 解法二: 左移法时间复杂度: $O(log(dividend))$, dividend 为被除数的大小. 对除数进行左移, 相当于每次乘以2, 直到左移后大于被除数, 用被除数减去左移后的数字, 记录左移对应除数的倍数, 然后再次将从除数开始左移, 直到被除数小于除数. 以上是除法的基本实现思路, 但是在具体实现时, 还需要特别考虑下面的情况 当被除数为 INT_MIN, 除数为 -1 时, 此时的返回值为 INT_MAX+1. (根据题目要求, 溢出时刻直接返回 INT_MAX) 当除数为 0 时, 也应该看做是溢出情况. 处理上面情况最方便的方法使用 long 长整型, 而不是 unsigned int 无符号类型. 因为 unsigned int 类型在进行乘以 2 的操作时, 很容易也溢出, 最终造成程序的死循环, 为了防止溢出, 最好使用 long, 具体请看代码. 123456789101112131415161718192021class Solution &#123;public: int divide(int dividend, int divisor) &#123; if(divisor==0 || (dividend==INT_MIN&amp;&amp;divisor==-1)) return INT_MAX; int res=0; int sign = ((dividend&lt;0) ^ (divisor&lt;0)) ? -1:1;// 用异或来获取符号 long did = labs(dividend); // long与int在有些环境中字节中一样, 此时最好用long long long dis = labs(divisor); while(did &gt;= dis)&#123; long temp = dis, multiple = 1; while( did &gt;= temp&lt;&lt;1 )&#123; temp = temp&lt;&lt;1; multiple = multiple&lt;&lt;1; &#125; did -= temp; res+= multiple; &#125; return res*sign; &#125;&#125;; 扩展: 这道题如果不允许使用 long 或者long long 怎么解?031. Next PermutationDescription: 实现 next_permutation 函数逻辑Implement next permutation, which rearranges numbers into the lexicographically next greater permutation of numbers.If such arrangement is not possible, it must rearrange it as the lowest possible order (ie, sorted in ascending order).The replacement must be in-place and use only constant extra memory.Here are some examples. Inputs are in the left-hand column and its corresponding outputs are in the right-hand column.1231,2,3 → 1,3,23,2,1 → 1,2,31,1,5 → 1,5,1 解法一: next_permutation 实现时间复杂度: $O(n)$空间复杂度: $O(1)$ STL中的 next_permutation 函数和 prev_permutation 两个函数提供了对于一个特定排列P, 求出其后一个排列P+1和前一个排列P-1的功能. next_permutation 的实现方法如下: 先 从后往前 找第一个小于后一个数的元素 nums[i]: nums[i]&lt;nums[i+1] 再 从后往前 找第一个大于 nums[i] 的数 nums[j]: nums[j]&gt;nums[i] 交换 nums[i] 和 nums[j] 将 i 之后的元素逆置(reverse) 12345678910111213class Solution &#123;public: void nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); &#125;&#125;; 033. Search in Rotated Sorted ArrayDescription: 在循环有序数组中查找元素Suppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand. (i.e., [0,1,2,4,5,6,7] might become [4,5,6,7,0,1,2]). You are given a target value to search. If found in the array return its index, otherwise return -1. You may assume no duplicate exists in the array. Your algorithm’s runtime complexity must be in the order of $O(log n)$. Example 1:12Input: nums = [4,5,6,7,0,1,2], target = 0Output: 4 Example 2:12Input: nums = [4,5,6,7,0,1,2], target = 3Output: -1 解法一: 二分查找时间复杂度: $O(logn)$空间复杂度: $O(1)$ 对于数组[4,5,6,7,0,1,2], 可以将其看成是两段: [4,5,6,7] 和 [0,1,2], 可以看出, 前一段中的任意一个数字都大于后一段中的数字, 于是, 令low=0, high=size()-1, 进行二分查找, 其中 mid 对应的数字要么落在前半段(nums[low] &lt;= nums[mid]), 要么落在后半段. 如果落在的前半段, 则看 target 的值是否在 low与mid之间. 是则 high = mid-1, 否则 low = mid+1 反之, 如果落在后半段, 则看 target 的值是否在 mid 与 high 之间, 是则 low=mid+1 , 否则high = mid-1 1234567891011121314151617181920212223242526class Solution &#123;public: int search(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size()-1; //数组前半段的数字永远大于后半段的数字 while(low&lt;=high)&#123; //当low==high时, mid=low=high, 如果不等于target, 则之后会退出循环 int mid = (low+high)/2; if(target == nums[mid]) return mid; if(nums[low] &lt;= nums[mid])&#123; //说明当前mid落在数组的前半段(), 这里等于号必须带, 否则会漏解 //判断target是否在low与mid之间, 这里low需要带等于号, //因为target有可能=nums[low], mid无需带等于号 if(target &gt;= nums[low] &amp;&amp; target &lt; nums[mid]) high = mid-1; else low = mid+1; &#125;else&#123; // 只有当nums[low]完全小于nums[mid]时, mid才落在后半段 if(target &gt; nums[mid] &amp;&amp; target &lt;= nums[high]) low = mid+1; else high = mid-1; &#125; &#125; return -1; &#125;&#125;; 解法二: 二分查找时间复杂度: $O(logn)$空间复杂度: $O(1)$ 该方法同样是二分查找, 只不过与上面有一点不同, 对于数组nums=[4,5,6,7,0,1,2]来说, 如果 target &lt; nums[0], 说明 target 位于数组的后半段, 那么可以将数组看做是nums=[INT_MIN,INT_MIN,INT_MIN,INT_MIN,0,1,2] , 这样一来, 就变成了最常规的有序数组, 反之, 如果 target 位于数组的前半段, 那么可以将数组看做是nums=[4,5,6,7,INT_MAX,INT_MAX,INT_MAX]. 注意, 这里并不会改变数组内部的值, 我们只是利用一个临时变量num来代替当前的nums[mid]的值, 然后利用 num 与 target 比较进行二分查找. 1234567891011121314151617181920212223class Solution &#123;public: int search(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size()-1; while(low&lt;=high)&#123; int mid = (low+high)/2; int num; if(target &lt; nums[0])&#123; //target在后半段, 所以将前半段都看做INT_MIN if(nums[mid] &lt; nums[0]) num = nums[mid]; // nums[mid]在后半段 else num = INT_MIN; // nums[mid]在前半段, &#125;else&#123; //target在前半段, 所以将后半段都看作是INT_MAX if(nums[mid] &lt; nums[0]) num = INT_MAX; // nums[mid]在后半段 else num = nums[mid]; // nums[mid]在前半段 &#125; if(num == target) return mid; else if(target &lt; num) high = mid-1; else low = mid+1; &#125; return -1; &#125;&#125;; 更精简的写法:12345678910111213141516171819class Solution &#123;public: int search(vector&lt;int&gt;&amp; nums, int target) &#123; int n = nums.size(); int low=0, high=n-1; while(low&lt;=high)&#123; int mid = (low+high)/2; int num; if(target&lt;nums[0]) num = nums[mid]&lt;nums[0] ? nums[mid] : INT_MIN; else num = nums[mid]&lt;nums[0] ? INT_MAX : nums[mid]; if(target &gt; num) low = mid+1; else if(target &lt; num) high = mid-1; else return mid; &#125; return -1; &#125;&#125;; 034. Find First and Last Position of Element in Sorted ArrayDescription: 在有序数组中查找目标的开始位置和结束位置Given an array of integers nums sorted in ascending order, find the starting and ending position of a given target value. Your algorithm’s runtime complexity must be in the order of O(log n). If the target is not found in the array, return [-1, -1]. Example 1:12Input: nums = [5,7,7,8,8,10], target = 8Output: [3,4] Example 2:12Input: nums = [5,7,7,8,8,10], target = 6Output: [-1,-1] 解法一: 二分查找时间复杂度: $O(logn)$空间复杂度: $O(1)$ 先用常规的二分查找找到target, 然后分别用二分查找找到最左边的target和最右边的target下标. 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size() - 1; vector&lt;int&gt; res&#123;-1,-1&#125;; int mid=-1; while(low &lt;= high)&#123; //正常的二分查找, 先找到target mid = (low+high)/2; if(nums[mid] == target) break; else if(nums[mid] &lt; target) low = mid+1; else high = mid-1; &#125; if(mid==-1 || nums[mid] != target) return res; // 数组为空或者数组内没有target //以mid为中心, 分别查找下标最小的target和下标最大的target int llow=low, lhigh=mid; // 左边的二分查找low,high初始化 int rlow=mid, rhigh=high; // 右边的二分查找low,high初始化 while(llow&lt;=lhigh)&#123; int mid = (llow+lhigh)/2; if(nums[mid] == target)&#123; if(mid==llow || nums[mid-1] != target)&#123; //关键: 只有当等于target并且左边没有元素或者左边元素不等于target时, 当前mid才是最左边的target res[0] = mid; break; &#125;else lhigh = mid-1; &#125;else if(nums[mid] &lt; target) llow = mid+1; else lhigh = mid-1; &#125; while(rlow&lt;=rhigh)&#123; int mid = (rlow+rhigh)/2; if(nums[mid] == target)&#123; if(mid==rhigh || nums[mid+1] != target)&#123; //同理, 找最右边的target res[1] = mid; break; &#125;else rlow = mid+1; &#125;else if(nums[mid] &lt; target) rlow = mid+1; else rhigh = mid-1; &#125; return res; &#125;&#125;; 解法二: 二分查找同样是二分查找, 更加精炼, 先找到最左边的target, 然后以最左边为low, 开始找最右边的target, 需要注意的是不能在nums[mid] == target时就退出循环. 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; int low = 0; int high = nums.size()-1; vector&lt;int&gt; res&#123;-1, -1&#125;; while(low &lt; high)&#123; //找起始位置, 注意这里不能是 &lt;=, 而必须是=, 否则会死循环 int mid = (low+high)/2; //偏向左边, 很重要, 否则会死循环 if(nums[mid] &lt; target) low = mid+1; else high = mid; //注意, 这里不是mid-1, 因为现在是在找最左边的target, 故不能在=target时退出, 因此也不能直接令high=mid-1, 否则会丢失mid=target的情况 &#125; if(nums.size()==0 || nums[low] != target) return res; res[0]=low; high = nums.size()-1;// low 已经指向起始位置, 这里只需重置high while(low &lt; high)&#123; // 找终止位置 int mid = (low+high+1)/2; //使mid偏向右边, 这很重要 if(nums[mid] &gt; target) high = mid-1; else low = mid; &#125; res[1]=high; return res; &#125;&#125;; 解法三: STL 函数时间复杂度: $O(logn)$空间复杂度: $O(1)$ 直接利用 STL 的 lower_bound() 和 upper_bound() 函数分别找到其实位置和终止位置即可, 在使用这两个函数时, 需要注意以下几点: lower_bound() 函数返回首个 不小于 target 的迭代器, 如果数组中所有元素 都小于 target, 则会返回超尾迭代器. upper_bound() 函数返回首个 大于 target 的迭代器, 如果数组中所有元素 都小于等于 target, 则会返回超尾迭代器. 注意 upper_bound() 返回的迭代器是首个 大于 目标值的迭代器, 因此需要将其减一才是我们要找的 target 的终止位置. 12345678910class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; if(nums.empty()) return vector&lt;int&gt;&#123;-1,-1&#125;; auto lower = std::lower_bound(nums.begin(), nums.end(), target); if(lower==nums.end() || *lower != target) return vector&lt;int&gt;&#123;-1,-1&#125;; auto upper = std::upper_bound(nums.begin(), nums.end(), target); return vector&lt;int&gt;&#123;lower-nums.begin(), upper-nums.begin()-1&#125;; &#125;&#125;; 036. Valid SudokuDescription: 验证一个矩阵是否是数独数据Determine if a 9x9 Sudoku board is valid. Only the filled cells need to be validated according to the following rules: Each row must contain the digits 1-9 without repetition.Each column must contain the digits 1-9 without repetition.Each of the 9 3x3 sub-boxes of the grid must contain the digits 1-9 without repetition. 解法一: 利用flag数组存储判断矩阵时间复杂度: $O(9^2)$空间复杂度: $O(3\times 9^2)$ 虽然要申请三个二维数组, 但都是常数级. 用三个 9×9 大小的矩阵, 分别储存每一行上, 每一列上, 每一个子块上1-9数字是否出现.12345678910111213141516171819class Solution &#123;public: bool isValidSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; // 下面三个矩阵分别存储了 行上1-9是否出现, 列上1-9是否出现, sub-box上1-9是否出现的bool值 // 如果row_flag[1][3] 为真, 则说明第1行(从第0行算起)上已经具有数字4(数字比下标大1)了 bool row_flag[9][9] &#123;0&#125;, col_flag[9][9] &#123;0&#125;, sub_flag[9][9] &#123;0&#125;; for(int i = 0 ; i&lt;board.size(); i++)&#123; for(int j = 0; j&lt;board[i].size(); j++)&#123; if(board[i][j] == '.') continue; // 如果为 '.' 则可以直接跳过此次判断 int num = board[i][j] - '0' - 1; //这里-1主要是为了能够直接将num作为下标使用 int k = i/3*3 + j/3; if(row_flag[i][num] || col_flag[j][num] || sub_flag[k][num]) return false; row_flag[i][num]=col_flag[j][num]=sub_flag[k][num]=true; &#125; &#125; return true; &#125;&#125;; 解法二: 位操作时间复杂度: $O(n^2)=O(9^2)$空间复杂度: $O(3\times 9)$ 这是目前看到的最好的方法, 核心思想就是用一个 short 类型变量的某一位来作为 flag, 这样, 我们可以进一步节省空间的使用, 将空间复杂度从 $O(n^2)$ 降低到 $O(n)$. 12345678910111213141516171819class Solution &#123;public: bool isValidSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; vector&lt;short&gt; row(9,0); vector&lt;short&gt; col(9,0); vector&lt;short&gt; block(9,0); for(int i=0; i&lt;9; i++)&#123; for(int j=0; j&lt;9; j++)&#123; int idx = 1 &lt;&lt; (board[i][j]-'0'); if(row[i]&amp;idx || col[j]&amp;idx || block[i/3*3+j/3]&amp;idx) return false; row[i] |= idx;//将对应位置为1, 标记已经出现过 col[j] |= idx; block[i/3*3+j/3] |= idx; &#125; &#125; return true; &#125;&#125;; 046. Permutations全排列, 注意是distict的数字, 故而不需要进行重复检查 Description: 不含重复数字的全排列Given a collection of distinct integers, return all possible permutations. Example: Input: [1,2,3]Output:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 解法一: 递归时间复杂度: $O(A^n_n)$ , 每一种情况都是 $O(1)$ , 共有 $O(A^n_n)$ 种情况. (对吗?) 用一个变量pos指向nums的第一个位置, 然后将pos与后面所有位置上的数字交换(包括自己), 最终会得到n种可能性, 这n种可能性就是出现在第一位置上的所有可能字符的情况集合, 然后将第一位固定, 并将pos指向下一位, 此时问题转换成了n-1个字符的全排列, 按照这种想法一致递归下去, 就可以找到所有位置上的所有组合情况(用pos==nums.size()判断) 123456789101112131415161718192021class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(nums.size()==0) return res; permute_helper(res, 0, nums); return res; &#125; void permute_helper(vector&lt;vector&lt;int&gt; &gt; &amp;res, int pos, vector&lt;int&gt; &amp;nums)&#123; if(pos == nums.size()) res.push_back(nums); // 当pos走到最后时, 说明一种情况诞生, 将其添加到res中 else&#123; for(int i = pos; i&lt;nums.size(); i++)&#123; std::swap(nums[pos], nums[i]); permute_helper(res, pos+1, nums); std::swap(nums[pos], nums[i]); // 能够去掉这句话的前提是对res内的字符串进行重复检查, 具体可看牛客分析 //在面对含有重复字符的情况时, 最好加上这句话 &#125; &#125; &#125;&#125;; 解法二: 迭代时间复杂度: $O(n^3)$空间复杂度: $O(A_n^n)$ 全排列的size 对于n个数的全排列问题, 可以想象成已经获得了n-1个数的全排列, 然后将第n个数插入到n-1个数的n个空位上( 如将3插入到12的空位上分别为: 312,132,123). 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; permute(vector&lt;int&gt; &amp;num) &#123; vector&lt;vector&lt;int&gt;&gt; res(1,vector&lt;int&gt;()); for(int i=0; i&lt;num.size(); i++)&#123; vector&lt;vector&lt;int&gt;&gt; tmp_res(std::move(res)); // move之后, res内部会自动被清空, 而且move的效率较高 for(int j=0; j&lt;tmp_res.size(); j++)&#123; for(int k=0; k&lt;=tmp_res[0].size(); k++)&#123; // 注意这里是&lt;=, 因为还要往尾部插 vector&lt;int&gt; tmp(tmp_res[j]); tmp.insert(tmp.begin()+k, num[i]); res.push_back(tmp); &#125; &#125; &#125; return res; &#125;&#125;; 解法三: 利用C++的内置函数 next_permutation关于 next_permutation() 的详细解析请看这里 STL中的 next_permutation 函数和 prev_permutation 两个函数提供了对于一个特定排列P, 求出其后一个排列P+1和前一个排列P-1的功能. 1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(next_permutation(nums.begin(), nums.end())); return res; &#125;&#125;; 这道题利用 prev_permutation 也可以解决, 但是这里就多了一步 reverse 的操作, 这里贴出来只是帮助理解 STL 函数的内部实现, 对于 Permutation2 题也是同理:1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end(), greater&lt;int&gt;()); // 倒序排序 do&#123; res.push_back(nums); &#125;while(prev_permutation(nums.begin(), nums.end()));//使用 prev return res; &#125;&#125;; 解法四: 自己实现 next_permutation用迭代器作为参数:1234567891011121314151617181920212223class Solution &#123; template &lt;typename T&gt; bool nextPermutation(T first, T last) &#123; auto i = last - 2; auto j = last - 1; while (i &gt;= first &amp;&amp; *i &gt;= *(i+1)) i--; if (i &gt;= first) &#123; while (j &gt;= first &amp;&amp; *i &gt;= *j) j--; std::iter_swap(i, j); std::reverse(i+1, last); &#125; return i&gt;=first ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); std::vector&lt;std::vector&lt;int&gt;&gt; res; do &#123; res.push_back(nums); &#125; while (nextPermutation(nums.begin(), nums.end())); return res; &#125;&#125;; 用数组作为参数:1234567891011121314151617181920212223class Solution &#123;private: bool nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(nextPermutation(nums)); return res; &#125;&#125;; prev_permutation 实现:1234567891011121314151617181920212223class Solution &#123;private: bool prevPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&lt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&lt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end(), greater&lt;int&gt;()); do&#123; res.push_back(nums); &#125;while(prevPermutation(nums)); return res; &#125;&#125;; next_permutation python 实现:12345678910111213141516171819class Solution: def nextPermutation(self, nums: List[int]) -&gt; None: n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &gt;= nums[i+1]): i -= 1 # 找到i if (i &gt;= 0): while (j &gt; i and nums[i] &gt;= nums[j]): j -= 1 # 找到 j nums[i], nums[j] = nums[j], nums[i] # 交换, 并将 i 之后的进行逆置 nums[i+1:] = nums[i+1:][::-1] return True if i != -1 else False def permute(self, nums: List[int]) -&gt; List[List[int]]: nums.sort() res = [] res.append(nums.copy()) # 注意这里一定要用copy, 否则后续的更改会影响前面的nums的值 while(self.nextPermutation(nums)): res.append(nums.copy()) return res prev_permutation python 实现12345678910111213141516171819class Solution: def prevPermutation(self, nums: List[int]) -&gt; None: n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &lt;= nums[i+1]): i -= 1 # 找到i if (i &gt;= 0): while (j &gt; i and nums[i] &lt;= nums[j]): j -= 1 # 找到 j nums[i], nums[j] = nums[j], nums[i] # 交换, 并将 i 之后的进行逆置 nums[i+1:] = nums[i+1:][::-1] return True if i != -1 else False def permute(self, nums: List[int]) -&gt; List[List[int]]: nums.sort(reverse=True) res = [] res.append(nums.copy()) # 注意这里一定要用copy, 否则后续的更改会影响前面的nums的值 while(self.prevPermutation(nums)): res.append(nums.copy()) return res 047. Permutations IIDescription: 带有重复元素的全排列解法一: 递归+set时间复杂度:空间复杂度: set 插入元素的时间复杂度为 $O(logn)$, $n$ 为当前 set 的大小. 1234567891011121314151617181920class Solution &#123;private: void helper(set&lt;vector&lt;int&gt;&gt; &amp;res, int pos, vector&lt;int&gt; &amp;nums)&#123; int len = nums.size(); if(pos==len) res.insert(nums); for(int i=pos; i&lt;len; i++)&#123; if(i!=pos &amp;&amp; nums[i]==nums[pos]) continue; swap(nums[pos], nums[i]); helper(res, pos+1, nums); swap(nums[pos], nums[i]); &#125; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; set&lt; vector&lt;int&gt;&gt; res; helper(res, 0, nums); return vector&lt;vector&lt;int&gt;&gt;(res.begin(), res.end()); &#125;&#125;; 解法二: STL 的 next_permutation 函数关于 next_permutation() 的详细解析请看这里 1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(next_permutation(nums.begin(), nums.end())); return res; &#125;&#125;; 使用 prev_permutation() 也可解决, 不过需要记得要倒序排序.1234567891011class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end(), greater&lt;int&gt;()); // 倒序排序 do&#123; res.push_back(nums); &#125;while(prev_permutation(nums.begin(), nums.end())); // prev return res; &#125;&#125;; 解法三: 自己实现 next_permutation()python 实现:12345678910111213141516171819class Solution: def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]: def nextPermutation(nums): n = len(nums) i = n - 2 j = n - 1 while (i &gt;= 0 and nums[i] &gt;= nums[i+1]): i -=1 if (i&gt;=0): while (j &gt; i and nums[i] &gt;= nums[j]): j -=1 nums[i], nums[j] = nums[j], nums[i] nums[i+1:] = nums[i+1:][::-1] return True if i != -1 else False nums.sort() res = [] res.append(nums.copy()) while (nextPermutation(nums)): res.append(nums.copy()) return res 用迭代器做参数:123456789101112131415161718192021222324class Solution &#123; template &lt;typename T&gt; bool nextPermutation(T first, T last) &#123; auto i = last - 2; auto j = last - 1; while (i &gt;= first &amp;&amp; *i &gt;= *(i+1)) i--; if (i &gt;= first) &#123; while (j &gt;= first &amp;&amp; *i &gt;= *j) j--; std::iter_swap(i, j); std::reverse(i+1, last); &#125; return i&gt;=first ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); std::vector&lt;std::vector&lt;int&gt;&gt; res; do &#123; res.push_back(nums); &#125; while(nextPermutation(nums.begin(), nums.end())); return res; &#125;&#125;; 用数组做参数: 1234567891011121314151617181920212223class Solution &#123;private: bool nextPermutation(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int i = n-2, j = n-1; while(i&gt;=0 &amp;&amp; nums[i]&gt;=nums[i+1]) i--; if(i&gt;=0)&#123; while(j&gt;=0 &amp;&amp; nums[i]&gt;=nums[j]) j--; swap(nums[i], nums[j]); &#125; reverse(nums.begin()+i+1, nums.end()); return i&gt;=0 ? true : false; &#125;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); do&#123; res.push_back(nums); &#125;while(nextPermutation(nums)); return res; &#125;&#125;; 048. Rotate ImageDescription: 图片旋转 90 度You are given an n x n 2D matrix representing an image. Rotate the image by 90 degrees (clockwise). Note: You have to rotate the image in-place, which means you have to modify the input 2D matrix directly. DO NOT allocate another 2D matrix and do the rotation. Example 1: Given input matrix =[ [1,2,3], [4,5,6], [7,8,9]], rotate the input matrix in-place such that it becomes:[ [7,4,1], [8,5,2], [9,6,3]]Example 2: Given input matrix =[ [ 5, 1, 9,11], [ 2, 4, 8,10], [13, 3, 6, 7], [15,14,12,16]], rotate the input matrix in-place such that it becomes:[ [15,13, 2, 5], [14, 3, 4, 1], [12, 6, 8, 9], [16, 7,10,11]] 解法一: 逆置+转置时间复杂度: $O(n^2)$, 因为转置的复杂度为 $O(n^2)$ 将图像矩阵看做是线性代数中的行列式, 首先将所有的行逆置(行与行交换), 然后对整个矩阵转置. 原理: 利用线性代数行列式的运算法则可证明(数学归纳法) clockwise rotatefirst reverse up to down, then swap the symmetry1231 2 3 7 8 9 7 4 14 5 6 =&gt; 4 5 6 =&gt; 8 5 27 8 9 1 2 3 9 6 3 12345678910class Solution &#123;public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; std::reverse(matrix.begin(), matrix.end()); //逆置 for(int i = 0; i&lt;matrix.size(); i++)&#123; for(int j=i+1; j&lt;matrix[i].size();j++) // 转置, 注意j=i+1 std::swap(matrix[i][j], matrix[j][i]); &#125; &#125;&#125;; 解法二: 转置+列逆置先求转置, 再对列逆置(列与列交换): 1234567891011class Solution &#123;public: void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; for(int i = 0; i&lt;matrix.size(); i++)&#123; for(int j=i+1; j&lt;matrix[i].size();j++) std::swap(matrix[i][j], matrix[j][i]); &#125; for(auto &amp;vec_i : matrix) std::reverse(vec_i.begin(), vec_i.end()); &#125;&#125;; 补充: 逆时针旋转90度先使用列逆置(列与列交换), 然后对矩阵使用转置 1231 2 3 3 2 1 3 6 94 5 6 =&gt; 6 5 4 =&gt; 2 5 87 8 9 9 8 7 1 4 7 1234567void anti_rotate(vector&lt;vector&lt;int&gt; &gt; &amp;matrix) &#123; for (auto vi : matrix) reverse(vi.begin(), vi.end()); for (int i = 0; i &lt; matrix.size(); ++i) &#123; for (int j = i + 1; j &lt; matrix[i].size(); ++j) swap(matrix[i][j], matrix[j][i]); &#125;&#125; 补充: 图片旋转 180 度(上下翻转)将所有的行逆置1231 2 3 7 8 94 5 6 =&gt; 4 5 67 8 9 1 2 3 1reverse(matrix.begin(), matrix.end()) 补充: 图片左右翻转将所有的列逆置1231 2 3 3 2 14 5 6 =&gt; 6 5 47 8 9 9 8 7 1for (auto vi : matrix) reverse(vi.begin(), vi.end()); 049. Group AnagramsDescription: 找出同字母的异序词, 并按字母分组输出Given an array of strings, group anagrams together. Example: Input: [“eat”, “tea”, “tan”, “ate”, “nat”, “bat”],Output:[ [“ate”,”eat”,”tea”], [“nat”,”tan”], [“bat”]]Note: All inputs will be in lowercase.The order of your output does not matter. 解法一: 哈希表+sort用哈希表来存, 键为有序的字符序列, 值为string数组, 里面存着各个与有序字符序列包含字符相同的其他序列 时间复杂度: $O(nmlogm)$ , 其中, n为输入字符串数组的长度, m为每个字符串的长度, 对于n个字符串, 要进行n次哈希表的插入, 同时每次插入时, 需要对字符串进行排序, 排序复杂度为 $O(mlogm)$. 空间复杂度: $O(mn)$ 123456789101112131415class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; std::unordered_map&lt;string,vector&lt;string&gt;&gt; res_map; for(auto str: strs)&#123; string str_value = str; std::sort(str.begin(), str.end()); res_map[str].push_back(str_value); //key 为字母有序string, value为含有这些字母的序列 &#125; vector&lt;vector&lt;string&gt;&gt; res_vec; for(auto str : res_map) res_vec.push_back(str.second); //将map中的所有的string转移到vec返回结果中 return res_vec; &#125;&#125;; 解法二: 哈希表(不使用sort)时间复杂度: $O(nm)$ , 其中, n为string个数, m为每个string的字母数.空间复杂度: $O(nm)$ 由于上面的解法二需要使用排序, 故而时间上不够优化, 因此, 这里我们可以设计新的键来代替sort, 基本思想是对26个字母, 分别赋予一个素数值, 然后, 计算键的时候, 将对应字母的素数 相乘 即可, 这样一来, 每一种字符串的key都是唯一的( 因为最终的乘积可以唯一的表示成素数相乘的序列 ). 12345678910111213141516171819202122// 该解法是错误的class Solution &#123;public: int primer[26] = &#123;2, 3, 5, 7, 11 ,13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101&#125;; int get_sum_id(string str)&#123; int sum = 1; for(auto c : str)&#123; sum * = primer[(int)(c-'a')]; &#125; return sum; &#125; vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; std::unordered_map&lt;int,vector&lt;string&gt;&gt; res_map; for(auto str: strs)&#123; res_map[get_sum_id(str)].push_back(str); //key 为字母有序string, value为含有这些字母的序列 &#125; vector&lt;vector&lt;string&gt;&gt; res_vec; for(auto str : res_map) res_vec.push_back(str.second); //将map中的所有的string转移到vec返回结果中 return res_vec; &#125;&#125;; 解法三: 另一种生成 key 的解法(不用sort)应该将字符count作为键, 所谓字符count就是统计每个字符出现的次数, 然后根据该信息就可以生成唯一的一个字符串, 例如, 对于 “abbb”, 来说, ‘a’ 出现了一次, ‘b’ 出现了三次, 因此, 其字符count就应该为: (1,3,0,…0), 总共有 26 个元素, 为了将其转换成字符串, 需要用一个特殊符号来做分隔符, 因此可以生成如下的字符串: &quot;#1#3#0#0...#0&quot;(这也是通常的内置 hash 的键的实现方法之一).该解法的时间复杂度为 $O(mn)$, 其中, $n$ 为遍历字符串数组的时间, $m$ 为获取 key 的时间, 无需进行排序. 123456789101112131415161718192021222324class Solution &#123;private: string get_key(string str)&#123; int str_count[26]&#123;0&#125;; for(auto c : str) str_count[c-'a']++; string str_key; for(auto i : str_count) str_key += "#" + to_string(i); return str_key; &#125;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; unordered_map&lt;string, vector&lt;string&gt;&gt; res_hash; for(auto str : strs)&#123; string s = get_key(str); res_hash[s].push_back(str); &#125; vector&lt;vector&lt;string&gt;&gt; res; for(auto s : res_hash) res.push_back(s.second); return res; &#125;&#125;; 050. Pow(x, n)实现幂乘操作 DescriptinImplement pow(x, n), which calculates x raised to the power n (x^n). Example 1: Input: 2.00000, 10Output: 1024.00000Example 2: Input: 2.10000, 3Output: 9.26100Example 3: Input: 2.00000, -2Output: 0.25000Explanation: 2-2 = 1/22 = 1/4 = 0.25Note: -100.0 &lt; x &lt; 100.0n is a 32-bit signed integer, within the range $[−2^{31}, 2^{31} − 1]$ 解法一: 递归时间复杂度: $O(logn)$空间复杂度: $O(1)$ 当n为偶数时: $x^n = x^{n/2} \times x^{n/2}$当n为奇数时: $x^n = x\times x^{n/2} \times x^{n/2}$ 这里需要注意一点: abs(INT_MIN) 的值仍然是负值, 因为 int 只有 32 位, abs(INT_MIN) 时, 仍然是 32 位, 因此不会变成正值, 解决方法是先把该值赋给 long 型变量, 然后对 long 型变量调用 abs() 函数, 另一种解决方法是利用 unsigned int:12345678int min = INT_MIN; // -2147483648long min_abs1 = abs(min); // 2147483648, 这里 min_abs1 的值仍然是 INT_MIN, 因为调用 abs 的时候, 仍然是32位long min_abs2 = min;min_abs2 = abs(min_abs2); // 2147483648, 这里是对64位调用 abs, 所以成功转化成正数// 解决方法二是利用 unsigned intunsigned int abs_min = abs(min) //2147483648 12345678910class Solution &#123;public: double myPow(double x, int n) &#123; if(n==0) return 1.0; unsigned int un = abs(n); //注意这里必须是 unsigned类型, 就算是long , 也必须带unsigned, 主要是因为abs(INT_MIN)仍为负数INT_MIN! if(n &lt; 0) x = 1/x; return (un%2==0) ? myPow(x*x, un/2) : x*myPow(x*x, un/2); &#125;&#125;; 解法二: 非递归时间复杂度: $O(logn)$空间复杂度: $O(1)$ n 要么为偶数, 要么为奇数, 我们每一次都将 n 的值减半, 并且将 x 与自身相乘, 每次当 n 为奇数时, 我们都将 res 与 x 相乘, 最终, res 的值就是我们要求的幂乘. 举例来说,对于 x=2, n=10 , 每次将x和自身相乘, 同时将 n 减半, n 和 x 的值分别为:12n: 10, 5, 2, 1, 0x: 2, 4, 16, 256, 65536 可以看到, 我们将 n 为奇数时的 x 相乘, 就是最终的幂乘: $4\times 256 = 2^{10} = 1024$. 当 n 为奇数时也是同理, 如下所示: 12n: 11, 5, 2, 1, 0x: 2, 4, 16, 256, 65536 最终幂乘: $2\times 4\times \times 256 = 2^{11} = 2048$ 123456789101112131415class Solution &#123;public: double myPow(double x, int n) &#123; if(n&lt;0) x = 1/x; long ln = n; ln = abs(ln); double res=1; while(ln&gt;0)&#123; if(ln%2==1) res *= x; x = x*x; ln = ln/2; &#125; return res; &#125;&#125;; 054. Spiral Matrix以顺时针螺旋顺序返回矩阵元素, 顺时针打印矩阵 DescriptionGiven a matrix of m x n elements (m rows, n columns), return all elements of the matrix in spiral order. Example 1: Input:[ [ 1, 2, 3 ], [ 4, 5, 6 ], [ 7, 8, 9 ]]Output: [1,2,3,6,9,8,7,4,5]Example 2: Input:[ [1, 2, 3, 4], [5, 6, 7, 8], [9,10,11,12]]Output: [1,2,3,4,8,12,11,10,9,5,6,7] 解法: 按层次输出(由外而内)时间复杂度: $O(n)$空间复杂度: $O(n)$ 输出形式如下(按层次编码, 以4×6的矩阵为例), 需要注意边界控制条件: \begin{matrix} 1_{top}&1_{top}&1_{top}&1_{top}&1_{top}&1_{top} \\ 1_{left}&2_{top}&2_{top}&2_{top}&2_{top}&1_{right} \\ 1_{left}&2_{bottom}&2_{bottom}&2_{bottom}&2_{bottom}&1_{right} \\ 1_{bottom}&1_{bottom}&1_{bottom}&1_{bottom}&1_{bottom}&1_{bottom} \end{matrix}12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; res; if(matrix.size()==0 || matrix[0].size() ==0) return res; int row_layer = (matrix.size()+1)/2; int col_layer = (matrix[0].size()+1)/2; int layer = min( row_layer, col_layer); // 计算总共的层数 int cur_layer =0; // 用于记录当前所处哪一层 int len_row = matrix.size(); int len_col = matrix[0].size(); //分别为行和列的size while(cur_layer &lt; layer)&#123; //top 输出上边 for(int j =cur_layer; j&lt;len_col-cur_layer; j++) res.push_back(matrix[cur_layer][j]); //right 输出右边 for(int i = cur_layer+1; i&lt;len_row-1-cur_layer; i++) res.push_back(matrix[i][len_col - 1 - cur_layer]); //bottom 输出下边, 这里注意为了防止重复输出, 需要确保上边和下边的行数不同,即: // cur_layer!=len_row-1-cur_layer for(int j= len_col - 1 -cur_layer; cur_layer!=len_row-1-cur_layer &amp;&amp; j &gt;=cur_layer ;j--) res.push_back(matrix[len_row - 1 -cur_layer][j]); //left 输出左边, 同样, 要确保左边和右边的列数不同, 即: cur_layer!=len_col-1-cur_layer for(int i = len_row-2-cur_layer; cur_layer!=len_col-1-cur_layer &amp;&amp; i&gt;cur_layer; i--) res.push_back(matrix[i][cur_layer]); cur_layer++; &#125; return res; &#125;&#125;; 另一种写法:12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; std::vector&lt;int&gt; res; if (matrix.empty() or matrix[0].empty()) return res; int n = matrix.size(); int m = matrix[0].size(); int rowUp = -1; // 记录上边界 int rowDown = n; // 下边界 int colLeft = -1; // 左边界 int colRight = m; // 右边界 while (rowUp &lt; rowDown and colLeft &lt; colRight) &#123; rowUp++; rowDown--; if (rowUp &gt; rowDown) break; // 如果越界, 则直接退出 colLeft++; colRight--; if (colLeft &gt; colRight) break; // 越界则退出 for (int j = colLeft; j &lt;= colRight; j++) &#123; res.emplace_back(matrix[rowUp][j]); &#125; for (int i = rowUp+1; i &lt;= rowDown-1; i++) &#123; res.emplace_back(matrix[i][colRight]); &#125; for (int j = colRight; rowUp != rowDown and j &gt;= colLeft; j--) &#123; res.emplace_back(matrix[rowDown][j]); &#125; for (int i = rowDown-1; colLeft != colRight and i &gt;= rowUp+1; i--) &#123; res.emplace_back(matrix[i][colLeft]); &#125; &#125; return res; &#125;&#125;; 055. Jump Game数组的数字为最大的跳跃步数, 根据数组判断是否能跳到最后一位上 DescriptionGiven an array of non-negative integers, you are initially positioned at the first index of the array. Each element in the array represents your maximum jump length at that position. Determine if you are able to reach the last index. Example 1: Input: [2,3,1,1,4]Output: trueExplanation: Jump 1 step from index 0 to 1, then 3 steps to the last index.Example 2: Input: [3,2,1,0,4]Output: falseExplanation: You will always arrive at index 3 no matter what. Its maximum jump length is 0, which makes it impossible to reach the last index. 解法一: 回溯时间复杂度: $O(2^n)$ 总共有 $2^n$ 种跳法来跳到最后一个位置上(对于任意一个位置, 有经过和不经过两个种可能性)空间复杂度: $O(n)$ 试遍所有的可能性, 正常来说会超时, 并且也肯定不是最佳答案 123456789101112131415161718class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; return helper(nums, 0); &#125; bool helper(vector&lt;int&gt; &amp;nums, int position)&#123; int final_position = nums.size()-1; if(position == final_position) return true; int furthest = std::min(position+nums[position], final_position); for(int i = position+1; i&lt;=furthest; i++)&#123; //这里有个小小的优化, 就是令i从最大步长开始, i--, 这种优化虽然最坏情况时一样的 //但在实际使用中, 会比从position+1开始要快一点(但是依然超时) if(helper(nums, i)) return true; &#125; return false; &#125;&#125;; 解法二: top-down 动态规划(递归)时间复杂度: $O(n^2)$ , 对于每个点来说, 都是要找到下一个good_position, 则需要进行 $(O)$ 的查找, 又因为总共有 $O(n)$个元素, 所以复杂度为 $O(n^2)$.空间复杂度: $O(2n)$, 递归需要 $O(n)$ , memo需要 $O(n)$. 设计一个数组, 用来记录当前下标对应位置是否可又达到终点, 如果能, 则该位置为good position, 如果不能, 则为bad position, 刚开始的时候都是unknown position(除了最后一个位置为good). 123456789101112131415161718192021222324class Solution &#123;public: enum class Status&#123;GOOD, BAD, UNKNOWN&#125;; bool canJump(vector&lt;int&gt;&amp; nums) &#123; vector&lt;Status&gt; memo; for(int i=0; i&lt;nums.size()-1; i++) memo.push_back(Status::UNKNOWN); memo.push_back(Status::GOOD); return helper(nums, memo, 0); &#125; bool helper(vector&lt;int&gt; &amp;nums, vector&lt;Status&gt; &amp;memo, int position)&#123; int final_position = nums.size()-1; if(memo[position] != Status::UNKNOWN) return memo[position]==Status::GOOD ? true : false; int furthest = std::min(position+nums[position], final_position); for(int i = furthest; i&gt;position; i--)&#123; if(helper(nums, memo, i))&#123; memo[position] = Status::GOOD; //注意是position, 不是i return true; &#125; &#125; memo[position] = Status::BAD; return false; &#125;&#125;; 解法三: down-top 动态规划(非递归)时间复杂度: $O(n^2)$ , 对于每个点来说, 都是要找到下一个good_position, 则需要进行 $(O)$ 的查找, 又因为总共有 $O(n)$个元素, 所以复杂度为 $O(n^2)$.空间复杂度: $O(n)$, 无需递归 , 只需要memo, $O(n)$. 动态规划的非递归版本. 1234567891011121314151617181920212223class Solution &#123;public: enum class Status&#123;GOOD, BAD, UNKNOWN&#125;; bool canJump(vector&lt;int&gt;&amp; nums) &#123; //if(nums.size() ==0) return false; vector&lt;Status&gt; memo; for(int i=0; i&lt;nums.size()-1; i++) memo.push_back(Status::UNKNOWN); memo.push_back(Status::GOOD); int final_position = nums.size()-1; for(int i=nums.size()-2; i&gt;=0; i--)&#123; int furthest = std::min(i+nums[i], final_position); //for(int j = i+1; j&lt;=furthest; j++)&#123; for(int j = furthest; j&gt;i;j--)&#123; if(memo[j] == Status::GOOD)&#123; // 只要有一个GOOD, 当前i位置就为GOOD, 而无需考虑BAD的情况 memo[i] = memo[j]; break; &#125; &#125; &#125; return memo[0] == Status::GOOD ? true : false; &#125;&#125;; 解法四: 贪心时间复杂度: $O(n)$空间复杂度: $O(1)$ 由上面的down-top递归可以看出, 当前下标位置的点是否为good点, 实际上只取决于当前点是否能够达到右边坐标中(从右往左走)最左边的good(可以看上面的break语句), 如果能够达到, 则当前点一定为good点, 因此, 我们只需要用一个变量left_most_good来维护当前点右边的最左good点下标即可, 无需任何其他空间和操作.(速度极快) 123456789101112class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; int left_most_good = nums.size()-1; for(int i = nums.size()-2; i&gt;=0; i--)&#123; if(i+nums[i] &gt;= left_most_good)&#123; left_most_good = i; &#125; &#125; return left_most_good==0; &#125;&#125;; 另一种贪心的形式: 记录当前能够达到的最大位置 123456789class Solution &#123;public: bool canJump(vector&lt;int&gt;&amp; nums) &#123; int i =0; for(int reach=0; i&lt;nums.size() &amp;&amp; i&lt;=reach; i++ ) reach = max(i+nums[i], reach); return i==nums.size(); // 或者用 reach &gt;= nums.size()-1 判断 &#125;&#125;; 056. Merge Intervals融合区间 DescriptionGiven a collection of intervals, merge all overlapping intervals. Example 1: Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6].Example 2: Input: [[1,4],[4,5]]Output: [[1,5]]Explanation: Intervals [1,4] and [4,5] are considerred overlapping. 解法一: sort+O(n)时间复杂度: $O(nlogn)$, 主要是排序空间复杂度: $O(n)$ 最简单的实现方法, 先按照interval.start用sort排序, 排好序以后, 能够融合的interval都会聚到一起, 这个时候, 因为start是呈递增的, 只需要看end的大小关系就可以. 最简单的实现方法就是sort之后, 通过额外申请空间来存储融合后的interval, 最后返回 1234567891011121314class Solution &#123;public: vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; if(intervals.size()==0) return vector&lt;Interval&gt;&#123;&#125;; vector&lt;Interval&gt; res; std::sort(intervals.begin(), intervals.end(), [](Interval a, Interval b)&#123;return a.start &lt; b.start;&#125;); res.push_back(intervals[0]); for(auto iv : intervals)&#123; if(res.back().end &lt; iv.start) res.push_back(iv); else res.back().end = std::max(res.back().end, iv.end); &#125; return res; &#125;&#125;; 解法二: sort+O(1)时间复杂度: $O(nlogn)$ , 主要是排序空间复杂度: $O(1)$ 上面的方法在逻辑上不够好, 因为既然已经申请了额外的内存来存储放回结果, 说明我们不希望改变原vector内部的数据, 但是sort之后, 数据顺序已经被破坏了, 既然已经破坏了, 那最好就是直接使用原地融合的办法, 来减少内存的开销1234567891011121314151617181920class Solution &#123;public: vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; if(intervals.size()==0) return vector&lt;Interval&gt;&#123;&#125;; //vector&lt;Interval&gt; res; 既然决定使用sort, 就说明已经改变了intervals, 此时不应该在额外申请空间, 而应该进行原地融合. std::sort(intervals.begin(), intervals.end(), [](Interval a, Interval b)&#123;return a.start &lt; b.start;&#125;); auto cur_iv = intervals.begin(); auto next_iv = intervals.begin()+1; for(; next_iv!=intervals.end(); next_iv++)&#123; if( (*cur_iv).end &lt; (*next_iv).start )&#123; cur_iv++; (*cur_iv) = (*next_iv); &#125;else&#123; (*cur_iv).end = std::max( (*cur_iv).end, (*next_iv).end ); &#125; &#125; intervals.erase(cur_iv+1, intervals.end()); return intervals; &#125;&#125;; 解法三: 不使用sort有时, 我们要求不能改变原向量intervals的内容, 此时, 就不能使用sort (除非牺牲大量空间留副本,但单肯定不推荐). //TODO, 未细看, 但时间复杂度应该会高于 O(nlogn)https://leetcode.com/problems/merge-intervals/discuss/153979/Elegant-c++-solutions.-One-without-modifying-intervals-and-one-inplace123456789101112131415161718192021222324252627Without modifying intervalsSince we can't sort interval, we want to instead ensure our destination vector is sorted. A insertion sort is required then. Insertion should be done as follows;Find first destination interval that ends after the incoming interval starts. Called itIf no such interval is found or the incoming interval end is less than found intervals start then we can just insert and be done.Otherwise there must be an overlap, but it could be more than one. Do another search, this time for the first interval whose start is greater than incoming interval end. Called lastEverything from [it, last) can be merged together with incoming interval into a single interval vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; std::vector&lt;Interval&gt; ret; for (auto&amp; interval : intervals) &#123; auto it = std::lower_bound(ret.begin(), ret.end(), interval.start, [](const Interval&amp; l, int r) &#123; return l.end &lt; r; &#125;); if (it == ret.end() || interval.end &lt; it-&gt;start) // No overlap, insert as is ret.insert(it, interval); else &#123; // There is an overlap, there might be more, so find the upper bound too it-&gt;start = std::min(it-&gt;start, interval.start); auto last = std::upper_bound(it, ret.end(), interval.end, [](int l, const Interval&amp; r) &#123; return l &lt; r.start; &#125;); it-&gt;end = std::max((last - 1)-&gt;end, interval.end); ret.erase(it + 1, last); &#125; &#125; return ret; &#125; 062. Unique PathsDescriptionA robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below). The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below). How many possible unique paths are there? 解法一: DP时间复杂度: $O(mn)$空间复杂度: $O(mn)$ 这是一道经典的DP问题, 当机器人处于某一点时, 它只能从上面或者左边到达该点, 因此很容易得出path[i][j] = path[i-1][j] + path[i][j-1];, 其中 path[i][j]指到达 $(i,j)$ 点的可能路径数量. 123456789101112class Solution &#123;public: int uniquePaths(int m, int n) &#123; vector&lt;vector&lt;int&gt;&gt; path(m, vector&lt;int&gt;(n,1)); for(int i = 1 ;i&lt;m; i++)&#123; for(int j=1 ; j&lt;n; j++)&#123; path[i][j] = path[i-1][j] + path[i][j-1]; &#125; &#125; return path[m-1][n-1]; &#125;&#125;; 解法二: 优化的DP时间复杂度: $O(mn)$空间复杂度: $O(n)$ 通过分析知道, 当前点的可能路径数量只与上面点和左边点的值有关, 在上面的方法中, 我们用一个 $m\times n$ 的数组来存储当前点上面和左边的值, 实际上, 我们只需要用一行数组就可以完成这个功能, 首先, 求出第一行的所有点的值, 这里只会用每个点左边的值, 然后, 对于第二行的第一个点来说, 它只会用到上面的值, 也就是第一行的第一个值, 因此可以通过行数组直接得到, 然后, 对于第二行的第二个值, 它可以从第二行的第一个值, 以及第二行的第二个值得到, 这些值都是已知的, 所以可以直接求的, 由于在求得以后, 我们就再也不需要第一行的第二个值了, 所以我们可以用这个存储空间来存储第二行的第二个值, 如此递归执行, 我们只需要 $O(n)$ 的空间即可. 123456789101112class Solution &#123;public: int uniquePaths(int m, int n) &#123; vector&lt;int&gt; path(n,1); for(int i = 1; i&lt;m; i++)&#123; for(int j = 1; j&lt;n; j++)&#123; path[j] = path[j] + path[j-1]; &#125; &#125; return path[n-1]; &#125;&#125;; 解法三: 排列组合(最优)时间复杂度: $O(n)$空间复杂度: $O(1)$ 实际上, 仔细分析该问题, 可以把该问题看成是一个典型的排列组合问题. 首先, 将机器人向右走记为 1, 将机器人向下走记为 0. 题目问有多少种不同的走法, 实际上就是在问1/0序列的不同排列有多少种, 并且, 1/0 的长度必须为 $(m -1 + n - 1)$. 因此, 这个问题可以看做是从 $(m-1+n-1)$ 个空槽位上选择 $(m-1)$ 个槽位, 将其置为1, 并将剩余的 $n-1$ 个槽位置为0, 故而就是组合问题: $C_{m-1+n-1}^{m-1}$ . 又因为 $C_{m-1+n-1}^{m-1} = C_{m-1+n-1}^{n-1}$ , 所以为了防止溢出, 我们可以选择小的进行计算 注意, 在排列如何时, 因为涉及到出发, 所以一定要注意计算法则的先后顺序, 具体请看代码 1234567891011class Solution &#123;public: int uniquePaths(int m, int n) &#123; long res = 1; //需要注意的是, 由于下面的计算操作是会有先乘一个数, 再初以一个数的操作, 因此很有可能乘完后超过int上限, 所以需要声明为long整型 for(int i = 1; i&lt; std::min(m,n); i++)&#123; res = res * (m-1+n-1 - i+1) / i; // 这里如果写成 res *= (m-1+n-1+i+1) / i, 则会报错, 因为这样会先计算除法, 这样有可能会出现浮点数, 但是排列组合是不会出现浮点数的, 切记! &#125; return res; &#125;&#125;; 073. Set Matrix ZeroesDescriptionGiven a m x n matrix, if an element is 0, set its entire row and column to 0. Do it in-place. Example 1: Input:[ [1,1,1], [1,0,1], [1,1,1]]Output:[ [1,0,1], [0,0,0], [1,0,1]]Example 2: Input:[ [0,1,2,0], [3,4,5,2], [1,3,1,5]]Output:[ [0,0,0,0], [0,4,5,0], [0,3,1,0]]Follow up: A straight forward solution using O(mn) space is probably a bad idea.A simple improvement uses O(m + n) space, but still not the best solution.Could you devise a constant space solution? 解法一: 穷举时间复杂度: $O(nm)$空间复杂度: $O(nm)$ 记录所有出现0的位置, 然后根据这些位置坐标将对应的行和列上的值置为0. 12345678910111213141516171819202122232425class Solution &#123;public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; rows; vector&lt;int&gt; cols; for(int i=0; i&lt;matrix.size(); i++)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; if(matrix[i][j] == 0)&#123; rows.push_back(i); cols.push_back(j); &#125; &#125; &#125; for(auto i:rows)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; matrix[i][j] = 0; &#125; &#125; for(auto j:cols)&#123; for(int i=0; i&lt;matrix.size(); i++)&#123; matrix[i][j] = 0; &#125; &#125; &#125;&#125;; 解法二: 穷举(减少空间复杂度)时间复杂度: $O(nm)$空间复杂度: $O(n+m)$ 上面在记录位置坐标时没有进行重复检查, 实际上, 对于已经记录过的行或列, 可以不用再记录, 此时, 空间复杂度可以降为 $O(m+n)$. 1234567891011121314151617181920212223242526class Solution &#123;public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; vector&lt;int&gt; rows; vector&lt;int&gt; cols; for(int i=0; i&lt;matrix.size(); i++)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; if(matrix[i][j] == 0)&#123; // 记录行或列坐标之前先进行重复检查 if(std::count(rows.begin(), rows.end(), i)==0) rows.push_back(i); if(std::count(cols.begin(), cols.end(), j)==0) cols.push_back(j); &#125; &#125; &#125; for(auto i:rows)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; matrix[i][j] = 0; &#125; &#125; for(auto j:cols)&#123; for(int i=0; i&lt;matrix.size(); i++)&#123; matrix[i][j] = 0; &#125; &#125; &#125;&#125;; 解法三: 穷举(无空间复杂度)时间复杂度: $O(nm\times (m+n))$空间复杂度: $O(1)$ 遍历矩阵时, 如果遇到 $(i,j)$ 上的值为0, 那么就将对应的行和列上的所有非0值全部置为一个矩阵范围外的值NAN(解答里面用的是-100000, 实际上这种解法存在问题, 因为理论上矩阵中的元素可以是表示范围内的任何值 ). 之后将所有的NAN值置为0, 就可以完成置0任务, 并且没有使用额外的空间. 由于每次找到一个0时, 都要遍历这个位置上的行和列, 因此时间复杂度较高 解法四: 用第一行和第一列记录时间复杂度: $O(nm)$空间复杂度: $O(1)$ 用第一行和第一列的值记录是否应该将对应的行和列置为0, 此时由于第一行和第一列被用作了标记数组, 因此第一行和第一列的0不能用来判断是否应该置为全0, 所以需要额外设置两个变量记录.1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; bool is_row=false, is_col = false; // 用第一行和第一列的值来做标记, 因此需要额外的记录第一行和第一列本身是有应该全0 for(int i=0; i&lt;matrix.size(); i++)&#123; for(int j=0; j&lt;matrix[0].size(); j++)&#123; if(matrix[i][j] == 0)&#123; if(i==0) is_row=true; if(j==0) is_col=true; matrix[i][0] = 0; matrix[0][j] = 0; &#125; &#125; &#125; for(int i=1; i&lt;matrix.size(); i++)&#123; if(matrix[i][0]!=0) continue; for(int j=0; j&lt;matrix[0].size(); j++)&#123; matrix[i][j] = 0; &#125; &#125; for(int j=1; j&lt;matrix[0].size(); j++)&#123; if(matrix[0][j]!=0) continue; for(int i=0; i&lt;matrix.size(); i++)&#123; matrix[i][j] = 0; &#125; &#125; if(is_row)&#123; //需要特别判断第一行和第一列是否应该置为0 for(int j=0; j &lt;matrix[0].size();j++) matrix[0][j]=0; &#125; if(is_col)&#123; for(int i=0; i&lt; matrix.size(); i++) matrix[i][0]=0; &#125; &#125;&#125;; 075. Sort Colors对0,1,2 (颜色: RGB) 进行排序 DescriptionHere, we will use the integers 0, 1, and 2 to represent the color red, white, and blue respectively. Note: You are not suppose to use the library’s sort function for this problem. Example: Input: [2,0,2,1,1,0]Output: [0,0,1,1,2,2]Follow up: A rather straight forward solution is a two-pass algorithm using counting sort.First, iterate the array counting number of 0’s, 1’s, and 2’s, then overwrite array with total number of 0’s, then 1’s and followed by 2’s.Could you come up with a one-pass algorithm using only constant space? 解法一: 两次遍历时间复杂度: $O(n)$空间复杂度: $O(1)$ 第一次遍历统计0,1,2的个数, 第二次遍历根据0,1,2的个数覆盖数组原有值 解法二: 一次遍历时间复杂度: 大于 $O(n)$空间复杂度: $O(1)$ 设置mid, low, high三个指示变量, 如果mid==0, 则将其与low交换, 如果mid==2, 则将其与high交换, 直到mid&gt;high为止. 12345678910111213141516class Solution &#123;public: void sortColors(vector&lt;int&gt;&amp; nums) &#123; int low=0, mid=0, high=nums.size()-1; while(mid&lt;=high)&#123; if(nums[mid]==2) std::swap(nums[mid], nums[high--]); else if(nums[mid]==0) std::swap(nums[mid++], nums[low++]); //这里 mid 可以直接++ 的原因是因为mid已经将0和2的情况进行处理, // 所以现在 low 指向的值只可能是 1, 因此交换后无需再对nums[mid]判断, 直接++即可 else mid++; &#125; &#125;&#125;; 077. CombinationsDescription: 输出所有的组合Given two integers n and k, return all possible combinations of k numbers out of 1 … n. Example:12345678910Input: n = 4, k = 2Output:[ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 解法一: 回溯时间复杂度:空间复杂度: 标准的回溯(深度游戏遍历)解法 123456789101112131415161718192021class Solution &#123;private: void dfs_helper(vector&lt;vector&lt;int&gt;&gt; &amp;res, vector&lt;int&gt; &amp;out, int n, int k, int level)&#123; int count = out.size(); if(count==k)&#123; res.push_back(out); &#125; for(int i=level; i&lt;n; i++)&#123; out.push_back(i+1); dfs_helper(res, out, n, k, i+1); out.pop_back(); &#125; &#125;public: vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; out; dfs_helper(res, out, n, k, 0); return res; &#125;&#125;; 解法二: 迭代TODO: 未看懂 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; out(k, 0); int i = 0; while (i &gt;= 0) &#123; out[i]++; if (out[i] &gt; n) i--; else if (i == k - 1) res.push_back(out); else &#123; i++; out[i] = out[i - 1]; &#125; &#125; return res; &#125;&#125;; 078. Subsets返回给定数字序列的子集, 序列中每个元素都不同(这是一个很重要的条件!!) DescriptionGiven a set of distinct integers, nums, return all possible subsets (the power set). Note: The solution set must not contain duplicate subsets. Example: Input: nums = [1,2,3]Output:[ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], []] 解法一: 迭代直接求出子集时间复杂度: $O(2^n)$ , 对于任意一个元素, 有包含和不包含两种情况空间复杂度: $O(2^n)$ 由于序列中的每个元素都不同, 因此, 对于任意一个元素, 只需要将其添加都前面序列所组成的子集的每一个子序列的末尾即可, 无需考虑是否包含重复元素的情况. 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res &#123;vector&lt;int&gt;&#123;&#125;&#125;; for(auto n : nums)&#123; int len = res.size(); for(int i=0; i&lt;len; i++)&#123; vector&lt;int&gt; sub_item = res[i]; // c++中, =为复制赋值, move函数为移动赋值 sub_item.push_back(n); res.push_back(sub_item); &#125; &#125; return res; &#125;&#125;; 解法二: 回溯https://leetcode.com/problems/subsets/discuss/27281/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partitioning)回溯法可以解决一系列相关问题, 先看Subsets的求解 123456789101112131415161718class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; sub_item; back_track(res, sub_item, 0, nums); return res; &#125; void back_track(vector&lt;vector&lt;int&gt;&gt; &amp;res, vector&lt;int&gt; sub_item, int start, vector&lt;int&gt; &amp;nums)&#123; res.push_back(sub_item); for(int i=start; i&lt;nums.size(); i++)&#123; sub_item.push_back(nums[i]); back_track(res, sub_item, i+1, nums); sub_item.pop_back(); &#125; &#125;&#125;; 其他问题: Subsets II (contains duplicates) : https://leetcode.com/problems/subsets-ii/悠悠 11:05:53Permutations : https://leetcode.com/problems/permutations/悠悠 11:06:01Permutations II (contains duplicates) : https://leetcode.com/problems/permutations-ii/悠悠 11:06:09Combination Sum : https://leetcode.com/problems/combination-sum/悠悠 11:06:16Combination Sum II (can’t reuse same element) : https://leetcode.com/problems/combination-sum-ii/悠悠 11:06:23Palindrome Partitioning : https://leetcode.com/problems/palindrome-partitioning/ 解法三: bit控制时间复杂度: $O(n\times 2^n)$ , 最慢的方法.空间复杂度: $O(2^n)$因为对于任意一个数只有两种可能性, 出现在子序列中, 或者不出现在子序列中, 因此对于长度为 n 的(无相同元素的)序列来说, 共有 $2^n$ 个子序列, 我们先为这些子序列申请空间, 然后根据位操作(刚好有0,1两种情况)来决定对应位置上的字符出现还是不出现. 在实现时, 观察到, 第一个元素每隔两个子序列出现一次, 第二个元素每隔四个子序列出现两次, 第三个元素每隔八个子序列出现四次… 依次类推, 我们可以根据当前元素的位置来决定当前元素是否出现(间隔的前一半出现, 后一半不出现) 123456789101112131415class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; int len_subsets = std::pow(2,nums.size()); vector&lt;vector&lt;int&gt;&gt; res(len_subsets, vector&lt;int&gt;&#123;&#125;); for(int i =0; i&lt;nums.size(); i++)&#123; for(int j=0; j&lt;len_subsets; j++)&#123; if(j&gt;&gt;i &amp; 1 == 1)&#123; res[j].push_back(nums[i]); &#125; &#125; &#125; return res; &#125;&#125;; 079. Word Search判断指定单词是否存在于字符矩阵中(可以通过上下左右邻接字符相连的才算是一个单词) Description: 判断指定单词是否存在于字符矩阵中Given a 2D board and a word, find if the word exists in the grid. The word can be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once. Example: board =[ [‘A’,’B’,’C’,’E’], [‘S’,’F’,’C’,’S’], [‘A’,’D’,’E’,’E’]] Given word = “ABCCED”, return true.Given word = “SEE”, return true.Given word = “ABCB”, return false. 解法一: dfs+回溯时间复杂度: $O(mn 4^k)$, 暴力求解, $mn$ 为字符矩阵的宽和高, 也即 cell 数量, 对于 dfs 中的每个 cell, 有4个扩展方向, 一共需要扩展 $k$ 次($k$ 为单词的长度).空间复杂度: $O(mn)$ , 回溯时, 用#来记录已经遍历过的点, 无需申请额外空间来记录. 但是递归程序需要占用 $O(mn)$ 的空间复杂度. 123456789101112131415161718192021222324252627class Solution &#123;public: bool exist(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word) &#123; if(board.size()==0 || board[0].size()==0) return false; for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[0].size(); j++)&#123; if(dfs(board, word, 0, i, j)) return true; &#125; &#125; return false; &#125; bool dfs(vector&lt;vector&lt;char&gt;&gt; &amp;board, string word, int start, int x, int y)&#123; char cur_c = board[x][y]; if(cur_c != word[start]) return false; if(start == word.size()-1) return true; board[x][y]='#'; bool res=false, b_down=false, b_left=false, b_right=false; if(x&gt;0) res = dfs(board, word, start+1, x-1, y); if(!res &amp;&amp; x&lt;board.size()-1) res = dfs(board, word, start+1, x+1, y); if(!res &amp;&amp; y&gt;0) res = dfs(board, word, start+1, x, y-1); if(!res &amp;&amp; y&lt;board[0].size()-1) res = dfs(board, word, start+1, x, y+1); board[x][y]=cur_c; return res; &#125;&#125;; 另一种写法:123456789101112131415161718192021222324252627282930313233343536class Solution &#123;private: bool dfs(vector&lt;vector&lt;char&gt;&gt; &amp;board, string &amp;word, int i, int j, int pos)&#123; if(board[i][j] != word[pos]) return false; if(pos == word.size()-1) return true; // 注意是size-1 int direct[4][2] = &#123;&#123;0,-1&#125;,&#123;0,1&#125;,&#123;-1,0&#125;,&#123;1,0&#125;&#125;; int m = board.size(); int n = board[0].size(); char c = board[i][j]; board[i][j] = '#'; // 标记成已访问 for(auto d : direct)&#123; int x=i+d[0]; int y=j+d[1]; if(x&gt;=0 &amp;&amp; x&lt;m &amp;&amp; y&gt;=0 &amp;&amp; y&lt;n &amp;&amp; board[x][y]!='#')&#123; if(dfs(board, word, x, y, pos+1)) return true; &#125; &#125; board[i][j] = c; // 退出前重置访问状态 return false; &#125;public: bool exist(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word) &#123; if(board.empty() || board[0].empty()) return false; if(word.empty()) return true; int m = board.size(); int n = board[0].size(); for(int i=0; i&lt;m; i++)&#123; for(int j=0; j&lt;n; j++)&#123; if(dfs(board, word, i, j, 0)) return true; &#125; &#125; return false; &#125;&#125;; 090. Subsets IIDescription: 含重复元素的数组的子集Given a collection of integers that might contain duplicates, nums, return all possible subsets (the power set). Note: The solution set must not contain duplicate subsets. Example:12345678910Input: [1,2,2]Output:[ [2], [1], [1,2,2], [2,2], [1,2], []] 解法一: 迭代时间复杂度: $O(2^n)$, 时间复杂度为子集的个数时间复杂度: $O(n)$, 空间复杂度为最长子集的长度 先排序, 然后对于一个元素, 如果这个元素与前一个元素相等, 那么在插入的时候, 就不能从第一个子集插入, 因为这样会重复, 因此要从不会造成重复的元素开始插入, 具体可看代码. 1234567891011121314151617181920class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); vector&lt;vector&lt;int&gt;&gt; res &#123;vector&lt;int&gt; &#123;&#125;&#125;; int pre_start = 0; for (int i = 0; i &lt; nums.size(); i++) &#123; int j = (i&gt;0 and nums[i]==nums[i-1]) ? pre_start : 0; // 从不会重复的元素开始 或者 从头开始 int len = res.size(); for ( ; j &lt; len; j++) &#123; auto sub_item = res[j]; sub_item.emplace_back(nums[i]); res.emplace_back(sub_item); &#125; pre_start = len; // 更新该值 &#125; return res; &#125;&#125;; 解法二: 回溯时间复杂度: $O(2^n)$, 时间复杂度为子集的个数时间复杂度: $O(n)$, 空间复杂度为递归的深度 先排序, 然后同样, 如果遇到相等元素, 则跳过, 以避免重复 123456789101112131415161718192021class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; sub_item; back_trace(res, sub_item, 0, nums); return res; &#125; void back_trace(vector&lt;vector&lt;int&gt;&gt;&amp; res, vector&lt;int&gt;&amp; sub_item, int start, vector&lt;int&gt;&amp; nums) &#123; res.push_back(sub_item); for (int i = start; i &lt; nums.size(); i++) &#123; if (i &gt; start and nums[i] == nums[i-1]) continue; sub_item.emplace_back(nums[i]); back_trace(res, sub_item, i+1, nums); sub_item.pop_back(); &#125; &#125;&#125;; 091. Decode WaysDescriptionA message containing letters from A-Z is being encoded to numbers using the following mapping: ‘A’ -&gt; 1‘B’ -&gt; 2…‘Z’ -&gt; 26Given a non-empty string containing only digits, determine the total number of ways to decode it. Example 1: Input: “12”Output: 2Explanation: It could be decoded as “AB” (1 2) or “L” (12).Example 2: Input: “226”Output: 3Explanation: It could be decoded as “BZ” (2 26), “VF” (22 6), or “BBF” (2 2 6). 解法一(最优): DP constant space时间复杂度: $O(n)$空间复杂度: $O(1)$ 存在问题: 下面的程序在面对测例:230001或230时, 输出的不是0. 但是仍然能通过OJ, 但实际上下面的解法在面对上面的样例时会返回错误答案, 因为没有对 0 进行特殊处理. 1234567891011121314151617class Solution &#123;public: int numDecodings(string s) &#123; if(s.size()==0 || s.front()=="0") return 0; // 注意, 不能用s.front() == "0" int f1=1, f2=1; for(int i=1; i&lt;s.size(); i++)&#123; if(s[i]=='0') f1=0; //注意, 不能用s[i] == "0" if(s[i-1]=='1' || (s[i-1]=='2' &amp;&amp; s[i]&lt;='6'))&#123; f1 = f1+f2; // 令f1为前i-1字符的可能组合+前i-2字符的可能组合 f2 = f1-f2; // 令f2为前i-1字符的可能组合, 也就是对于下一个i来说的前i-2的可能组合 &#125; else f2 = f1; // 如果当前字符不能与前一个字符组合, 则当前字符f1不变, 而f2有变为下一个i的前i-2的可能组合, 即让新f2等于旧的f1 &#125; return f1; &#125;&#125;; 修复了上述的问题, 现在遇到 0 时会进行额外的判断, 0 不能单独编码, 必须与前面的字符组合, 如果无法组合, 则应该返回0, 如 230001, 就应该返回 0, 代码如下:123456789101112131415161718192021222324252627class Solution &#123;public: int numDecodings(string s) &#123; int n = s.size(); if(n==0 || s[0] == '0') return 0; //if(n==1) return 1; vector&lt;int&gt; dp(n, 0); dp[0] = 1; int i = 1; while(i&lt;n)&#123; if(s[i]=='0')&#123; if(s[i-1] =='2' || s[i-1] == '1') // 0 不能单独编码, 必须与前面的数字组合, 因此这里是 dp[i-2] dp[i] = i&gt;1 ? dp[i-2] : 1; else // 如果 0 前面的值大于 2, 则无法组成编码, 应返回 0 return 0; &#125; else if(s[i-1]=='1' ||(s[i-1]=='2' &amp;&amp; s[i] &lt;= '6'))&#123; int prev_two = i&gt;1 ? dp[i-2] : 1; dp[i] = dp[i-1] + prev_two; &#125;else&#123; dp[i] = dp[i-1]; &#125; i++; &#125; return dp[n-1]; &#125;&#125;; 上面的代码使用了 DP 数组, 空间复杂度为 $O(n)$, 实际上我们并不需要这么多空间, 只需要常数空间就可以完成数组, 即只需要当前 dp 值的前两个 dp 值即可. 代码如下:123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: int numDecodings(string s) &#123; int n = s.size(); if(n==0 || s[0] == '0') return 0; //if(n==1) return 1; vector&lt;int&gt; dp(n, 0); int f1 = 1; // 代表当前dp值之前一位的dp值 int f2 = 1; // 代表当前dp值之前两位的dp值 dp[0] = 1; int i = 1; while(i&lt;n)&#123; if(s[i]=='0')&#123; if(s[i-1] =='2' || s[i-1] == '1')&#123; // 0 不能单独编码, 必须与前面的数字组合, 因此这里是 dp[i-2] int tmp = f1; f1 = f2; // 令当前dp值为f2 (当前的dp值会成为下一个f1值) f2 = tmp; &#125; else // 如果 0 前面的值大于 2, 则无法组成编码, 应返回 0 return 0; &#125; else if(s[i-1]=='1' ||(s[i-1]=='2' &amp;&amp; s[i] &lt;= '6'))&#123; f1 = f1 + f2; f2 = f1 - f2; // 上面两个式子相当于: // int tmp = f1; f1 = f1+f2; f2 = tmp; //int prev_two = i&gt;1 ? dp[i-2] : 1; //dp[i] = dp[i-1] + prev_two; &#125;else&#123; f2 = f1; // 当前dp值不变, 所以只需要更新 f2 即可 &#125; i++; &#125; return f1; &#125;&#125;; 另一种写法, 更好理解:123456789101112131415161718192021222324252627class Solution &#123;public: int numDecodings(string s) &#123; if (s.empty() || s[0] == '0') return 0; int dp1 = 1; // 记录当前字符前一位的可能组合数 int dp2 = 1; // 记录当前字符前两位的可能组合数 long res = 1; // 记录当前字符的可能组合数 for (int i = 1; i &lt; s.size(); i++) &#123; if (s[i] == '0') &#123; if (s[i-1] == '1' or s[i-1] == '2') &#123; // d res = dp2; &#125; else &#123; return 0; &#125;d &#125; else if (s[i-1] == '1' or (s[i-1] == '2' and s[i] &lt; '7' and s[i] &gt; '0')) &#123; res = dp1 + dp2; &#125; else &#123; res = dp1; &#125; dp2 = dp1; dp1 = res; &#125; return res; &#125;&#125;; 解法二: 递归时间复杂度: $O(n^2)$ 1234567891011121314151617class Solution &#123;public: int numDecodings(string s) &#123; if(s.size()==0) return 0; return recurve(0,s); &#125; int recurve(int pos, string &amp;s)&#123; if(pos==s.size()) return 1; if(s[pos]=='0') return 0; int tmp_res = recurve(pos+1, s); if(pos&lt;s.size()-1 &amp;&amp; (s[pos]=='1' || (s[pos]=='2'&amp;&amp;s[pos+1]&lt;='6'))) tmp_res += recurve(pos+2, s); return tmp_res; &#125;&#125;; 094. Binary Tree Inorder Traversal中序遍历二叉树 DescriptionGiven a binary tree, return the inorder traversal of its nodes’ values. Example:12345678Input: [1,null,2,3] 1 \ 2 / 3Output: [1,3,2] Follow up: Recursive solution is trivial, could you do it iteratively? 解法一: 递归1234567891011121314151617181920212223/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root==nullptr) return res; inorder(root, res); return res; &#125; void inorder(TreeNode* root, vector&lt;int&gt; &amp;res)&#123; if(root-&gt;left!=nullptr) inorder(root-&gt;left, res); res.push_back(root-&gt;val); if(root-&gt;right!=nullptr) inorder(root-&gt;right, res); &#125;&#125;; 解法二: 非递归标准的中序非递归遍历算法 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(root==nullptr) return res; std::stack&lt;TreeNode*&gt; s_tree; while(!s_tree.empty() || root!=nullptr)&#123; while(root!=nullptr)&#123; s_tree.push(root); root= root-&gt;left; &#125; if(!s_tree.empty())&#123; root = s_tree.top(); s_tree.pop(); res.push_back(root-&gt;val); root = root-&gt;right; &#125; &#125; return res; &#125;&#125;; 098. Validate Binary Search TreeDescriptionGiven a binary tree, determine if it is a valid binary search tree (BST). Assume a BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node’s key.The right subtree of a node contains only nodes with keys greater than the node’s key.Both the left and right subtrees must also be binary search trees.Example 1: Input: 2 / \ 1 3Output: trueExample 2: 5 / \ 1 4 / \ 3 6Output: falseExplanation: The input is: [5,1,4,null,null,3,6]. The root node’s value is 5 but its right child’s value is 4. 解法一: 递归用一个指针来指向当前节点在顺序上的前一个节点, 判断是否为BST 123456789101112131415class Solution &#123;public: bool isValidBST(TreeNode* root) &#123; TreeNode* pre_node = nullptr; return isBST(root, pre_node); &#125; bool isBST(TreeNode* root, TreeNode * &amp;pre_node)&#123; // 注意!!! 要维持递归时的pred_node, 因此必须使用 * &amp;, 否则每次的pre_node = root;实际上只是改变了pred_node的副本 if(root==nullptr) return true; if(isBST(root-&gt;left, pre_node) == false) return false; if(pre_node!=nullptr &amp;&amp; pre_node-&gt;val &gt;= root-&gt;val) return false; pre_node = root; if(isBST(root-&gt;right, pre_node)==false) return false; return true; &#125;&#125;; 下面的代码是典型错误解法: 因为, 我们不知只要考虑左子树节点值要小于当前节点值, 还要满足的另外一个条件是左子树本身也是一个二叉搜索树, 下面的代码没有进行该判断. 1234567891011121314151617181920212223242526/*Input[10,5,15,null,null,6,20]OutputtrueExpectedfalse*/class Solution &#123;public: bool isValidBST(TreeNode* root) &#123; if(root==nullptr) return true; bool b=true; if(root-&gt;left!=nullptr)&#123; if(root-&gt;left-&gt;val &gt;= root-&gt;val) return false; b = isValidBST(root-&gt;left); &#125; if(b==false) return b; if(root-&gt;right!=nullptr)&#123; if(root-&gt;right-&gt;val &lt;= root-&gt;val) return false; b = isValidBST(root-&gt;right); &#125; return b; &#125;&#125;; 解法二: 迭代(中序)中序遍历二叉搜索树时, 返回的是一个有序的数组, 因此, 我们可以在遍历时, 一旦发现不有序, 就返回 false, 需要注意一点的是, 本题中二叉搜索树中的节点值是唯一的. 12345678910111213141516171819202122class Solution &#123;public: bool isValidBST(TreeNode* root) &#123; TreeNode* prev = nullptr; stack&lt;TreeNode*&gt; s; while(root!=nullptr || !s.empty())&#123; while(root!=nullptr)&#123; s.push(root); root = root-&gt;left; &#125; if(!s.empty())&#123; root = s.top(); s.pop(); if(prev!=nullptr &amp;&amp; prev-&gt;val &gt;= root-&gt;val) return false; prev = root; root = root-&gt;right; &#125; &#125; return true; &#125;&#125;; 102. Binary Tree Level Order Traversal按层次输出二叉树节点的值(每层的值要分开) Description解法一: 层次遍历时间复杂度: $O(n)$ , 每个节点遍历一次空间复杂度: $O(n)$ , 存储了n个节点的值 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(root == nullptr) return res; std::queue&lt;TreeNode*&gt; q; TreeNode * cur_node; q.push(root); while(!q.empty())&#123; int len = q.size(); vector&lt;int&gt; layer; for(int i=0; i&lt;len; i++)&#123; cur_node = q.front(); q.pop(); layer.push_back(cur_node-&gt;val); if(cur_node-&gt;left != nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right != nullptr) q.push(cur_node-&gt;right); &#125; res.push_back(layer); &#125; return res; &#125;&#125;; 103. Binary Tree Zigzag Level Order Traversal按之字形打印二叉树 DescriptionGiven a binary tree, return the zigzag level order traversal of its nodes’ values. (ie, from left to right, then right to left for the next level and alternate between). For example:Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7return its zigzag level order traversal as:[ [3], [20,9], [15,7]] 解法一：利用reverse时间复杂度为 $O(n^2)$ 空间复杂度为 $O(n)$ 然后每次访问节点时, 都判断当前节点的层数, 如果为奇数层, 则将该层直接push back到结果向量中, 如果为偶数, 则将该层数据进行reverse后再push back到结果向量中. 通过while里面内置for循环, 来保证每次for循环都会将一整层的节点放进队列中, 无需额外的数组来存储depth信息1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(pRoot == NULL) return res; queue&lt;TreeNode*&gt; que; que.push(pRoot); bool even = false; while(!que.empty())&#123; vector&lt;int&gt; vec; //将vec声明在内部, 省去每次的clear操作, clear操作需要对vector进行遍历, 并将每个元素置为null？ const int size = que.size(); //当前存的节点数目就是这一层所有的节点, 之前层的到已经被取出, 并且这一层的子节点还没有开始入队列 for(int i=0; i&lt;size; ++i)&#123; //将该层所有节点的子节点入队列, 同时当到达该层最后一个节点时终止 TreeNode* tmp = que.front(); que.pop(); vec.push_back(tmp-&gt;val); if(tmp-&gt;left != NULL) que.push(tmp-&gt;left); if(tmp-&gt;right != NULL) que.push(tmp-&gt;right); &#125; if(even) //根据奇偶标识判断是否需要reverse std::reverse(vec.begin(), vec.end()); res.push_back(vec); even = !even; &#125; return res; &#125;&#125;; 解法二: 最优(不用reverse)时间复杂度: $O(n)$空间复杂度: $O(n)$ 在解法二中, 复杂度高的原因是因每次遇到偶数层的时候都要进行 reverse, 实际上, 当我们知道了该层的节点个数以后, 我们可以直接开辟一个指定大小的 vector, 然后根据下标随机访问来填入该层的节点值, 这样一来就不用进行 reverse, 并且空间复杂度与解法二相同 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; zigzagLevelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(root == nullptr) return res; std::queue&lt;TreeNode*&gt; q; q.push(root); bool is_odd = true; TreeNode* cur_node; while(!q.empty())&#123; int layer_len = q.size(); vector&lt;int&gt; cur_layer(layer_len); for(int i=0; i&lt;layer_len; i++)&#123; cur_node = q.front(); q.pop(); if(is_odd==true) cur_layer[i] = cur_node-&gt;val; else cur_layer[layer_len-1-i ] = cur_node-&gt;val; if(cur_node-&gt;left!=nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right!=nullptr) q.push(cur_node-&gt;right); &#125; res.push_back(cur_layer); is_odd = !is_odd; &#125; return res; &#125;&#125;; 解法三: 利用双端队列时间复杂度: $O(n)$空间复杂度: $O(n)$ 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; zigzagLevelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if (root == nullptr) return res; std::deque&lt;TreeNode*&gt; dqTree; dqTree.push_back(root); int depth = 0; while (!dqTree.empty()) &#123; depth++; int len = dqTree.size(); vector&lt;int&gt; tmpRes; for (int i = 0; i &lt; len; i++) &#123; if (depth &amp; 1) &#123; auto node = dqTree.front(); dqTree.pop_front(); tmpRes.push_back(node-&gt;val); if (node-&gt;left != nullptr) dqTree.push_back(node-&gt;left); if (node-&gt;right != nullptr) dqTree.push_back(node-&gt;right); &#125; else &#123; auto node = dqTree.back(); dqTree.pop_back(); tmpRes.push_back(node-&gt;val); if (node-&gt;right != nullptr) dqTree.push_front(node-&gt;right); if (node-&gt;left != nullptr) dqTree.push_front(node-&gt;left); &#125; &#125; res.push_back(tmpRes); &#125; return res; &#125;&#125;; 105. Construct Binary Tree from Preorder and Inorder TraversalDescription: 根据先序和中序遍历构造二叉树Given preorder and inorder traversal of a tree, construct the binary tree. Note:You may assume that duplicates do not exist in the tree.(如果没有该条件则通常无法还原唯一的二叉树) For example, given preorder = [3,9,20,15,7]inorder = [9,3,15,20,7]Return the following binary tree:12345 3 / \9 20 / \ 15 7 解法一: 递归时间复杂度: $O(n^2)$, 在中序遍历中查找根节点的复杂度为 $O(n)$, 先序序列中总共有 $n$ 个根节点, 所以需要查找 $n$ 次空间复杂度: 根据树的结构, 最坏情况下的递归深度为 $O(n)$. 先取先序遍历中的第一个节点为根节点, 然后在中序遍历冲查找该节点, 以该节点为界限将数组分成两边, 分别为左子树和右子树, 根据左子树和右子树的长度在先序遍历中也划分对应长度的两个数组, 然后将两个数组分别作为左子树的先序和中序, 以及右子树的先序和中序进行递归构建. 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: TreeNode* helper(vector&lt;int&gt; &amp;preorder, int i, int j, vector&lt;int&gt; &amp;inorder, int k, int l)&#123; // tree 8 4 5 3 7 3 // preorder 8 [4 3 3 7] [5] // inorder [3 3 4 7] 8 [5] if(i &gt;= j || k &gt;= l)&#123;// 注意, 这里的 j 和 l 均为超尾下标 return nullptr; &#125; int root_val = preorder[i]; auto in_index = find(inorder.begin()+k, inorder.begin()+l, root_val); int dis = in_index - inorder.begin() - k; TreeNode *root = new TreeNode(root_val); root-&gt;left = helper(preorder, i+1, i+1+dis, inorder, k, k+dis); root-&gt;right = helper(preorder, i+1+dis, j, inorder, k+dis+1, l); return root; &#125;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; return helper(preorder, 0, preorder.size(), inorder, 0, inorder.size()); &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$空间复杂度: $O(n)$ 先将 preorder[i] 压入栈中, 如果当前 preorder 的元素与 inorder 中的元素不匹配, 则将 preorder 中的值构造成节点压入栈中, 并且新构造的节点一定是栈顶的左孩子. 重复该过程直到元素值匹配为止: preorder[i] = inorder[index] 当先序和中序的值匹配时, 则将节点出栈, 直到不再匹配为止. TODO: 该解法还没彻底搞清, 暂时搁置 1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; stack&lt;TreeNode*&gt; s; if(preorder.empty()) return nullptr; TreeNode *root = new TreeNode(preorder[0]); s.push(root); int index = 0; for(int i=1; i &lt; preorder.size(); i++)&#123; TreeNode* cur = s.top(); if(cur-&gt;val != inorder[index])&#123; cur-&gt;left = new TreeNode(preorder[i]); s.push(cur-&gt;left); &#125;else&#123; while(!s.empty() &amp;&amp; s.top()-&gt;val == inorder[index])&#123; cur = s.top(); s.pop(); index++; &#125; if(index &lt; inorder.size())&#123; cur-&gt;right = new TreeNode(preorder[i]); s.push(cur-&gt;right); &#125; &#125; &#125; return root; &#125;&#125;; 116. Populating Next Right Pointers in Each Node令每个节点中的 next 指针指向它的右兄弟, 如果没有右兄弟, 那么就置为 nullptr, 注意, 题目给定的树是满二叉树 DescriptionGiven a binary tree struct TreeLinkNode { TreeLinkNode left; TreeLinkNode right; TreeLinkNode * next;}Populate each next pointer to point to its next right node. If there is no next right node, the next pointer should be set to NULL. Initially, all next pointers are set to NULL. Note: You may only use constant extra space.Recursive approach is fine, implicit stack space does not count as extra space for this problem.You may assume that it is a perfect binary tree (ie, all leaves are at the same level, and every parent has two children).Example: Given the following perfect binary tree, 1 / \ 2 3 / \ / \4 5 6 7After calling your function, the tree should look like: 1 -&gt; NULL / \ 2 -&gt; 3 -&gt; NULL / \ / \4-&gt;5-&gt;6-&gt;7 -&gt; NULL 解法一: 层次遍历时间复杂度: $O(n)$空间复杂度: $O(n)$ 显而易见可以用层次遍历, 只需额外设置一个节点指针来维护当前节点的前一个节点(左兄弟节点). 但是, 题目中要求只能使用常数空间, 因此该解法不是最优解. 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for binary tree with next pointer. * struct TreeLinkNode &#123; * int val; * TreeLinkNode *left, *right, *next; * TreeLinkNode(int x) : val(x), left(NULL), right(NULL), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: Node* connect(Node* root) &#123; if (root==nullptr) return nullptr; std::queue&lt;Node*&gt; treeQ; treeQ.push(root); while (!treeQ.empty()) &#123; int len = treeQ.size(); for (int i = 0; i &lt; len; i++) &#123; auto node = treeQ.front(); treeQ.pop(); Node* nextNode; if ( i &lt; len -1) &#123; nextNode = treeQ.front(); &#125; else &#123; nextNode = nullptr; &#125; node-&gt;next = nextNode; if (node-&gt;left != nullptr) &#123; treeQ.push(node-&gt;left); &#125; if (node-&gt;right != nullptr) &#123; treeQ.push(node-&gt;right); &#125; &#125; &#125; return root; &#125;&#125;; 解法二: 利用 next 指针的特性时间复杂度: $O(n)$, 每个节点都要访问一次(仅访问一次)空间复杂度: $O(1)$ 由于是满二叉树, 因此我们可以轻易的利用next指针自身的特性来实现层次遍历. 1234567891011121314151617181920class Solution &#123;public: Node* connect(Node* root) &#123; Node* curFirst = root; while (curFirst != nullptr) &#123; Node* curNode = curFirst; while (curNode != nullptr) &#123; if (curNode-&gt;left != nullptr) &#123; curNode-&gt;left-&gt;next = curNode-&gt;right; &#125; if (curNode-&gt;next != nullptr &amp;&amp; curNode-&gt;right != nullptr) &#123; curNode-&gt;right-&gt;next = curNode-&gt;next-&gt;left; &#125; curNode = curNode-&gt;next; &#125; curFirst = curFirst-&gt;left; &#125; return root; &#125;&#125;; 127. Word Ladder实际上是图的BFS(广度优先搜索) DescriptionGiven two words (beginWord and endWord), and a dictionary’s word list, find the length of shortest transformation sequence from beginWord to endWord, such that: Only one letter can be changed at a time.Each transformed word must exist in the word list. Note that beginWord is not a transformed word.Note: Return 0 if there is no such transformation sequence.All words have the same length.All words contain only lowercase alphabetic characters.You may assume no duplicates in the word list.You may assume beginWord and endWord are non-empty and are not the same.Example 1:123456789Input:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]Output: 5Explanation: As one shortest transformation is &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;,return its length 5. Example 2:12345678Input:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]Output: 0Explanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation. 解法一: BFS时间复杂度: $O(nl)$, 其中, $l$ 为单词的长度, $n$ 是单词的数量, 因为广度优先遍历会对每个节点遍历一次, 而每个节点计算邻居时, 需要对 $l$ 个字母进行替换(替换26种, 常数级别), 另外, unordered_set 的 find 复杂度也为常数.空间复杂度: $O(n)$ 需要额外借助队列进行广度优先遍历, 另外还使用了 unordered_set 来存储单词表 我们可以将此题看做是图的广度优先搜索, 首先, 以 beginWord 为图的起始节点, 然后, 那些所有与 beginWord 只有一个字母不相同的单词都可以看做是 beginWord 的邻居节点, 依次类推, 直到找到一个单词, 与 endWord 相同为止, 此时, 返回当前 endWord 与 beginWord 的距离. (距离的记录方式和二叉树层次遍历时的方式差不多, 都是利用当前队列中的元素大小来控制深度的). 需要注意的地方有以下几点: 这里的图和树不太一样, 这里图没有链表指针来指示, 因此, 在每次将某一个单词入队列以后, 都需要在单词列表中删除掉这个单词(或者额外设置标记也行), 以防止重复搜索 题目给的是没有重复单词的单词表, 因此推荐使用 set 结构来进行删除 (erase) 操作, vector 结构的删除 (erase) 操作的时间复杂度较高. 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) &#123; std::unordered_set&lt;string&gt; word_dict; for(auto word : wordList) word_dict.insert(word); std::queue&lt;string&gt; to_visit; //word_dict.erase(beginWord); //beginWord本来就不在字典中 to_visit.push(beginWord); int dist = 1; while(!to_visit.empty())&#123; int len = to_visit.size(); for(int i =0; i&lt;len; i++)&#123; string word = to_visit.front(); to_visit.pop(); if(word == endWord) return dist; add_next_word(word, word_dict, to_visit); &#125; dist++; &#125; return 0; &#125; void add_next_word(string &amp;word, std::unordered_set&lt;string&gt; &amp;word_dict, std::queue&lt;string&gt; &amp;to_visit)&#123; // word_dict.erase(word); for(int i=0; i&lt;word.size(); i++)&#123; char letter = word[i]; for(int k=0; k&lt;26; k++)&#123; word[i] = 'a'+k; if(word_dict.find(word) != word_dict.end())&#123; to_visit.push(word); word_dict.erase(word); &#125; &#125; word[i] = letter; &#125; &#125;&#125;; 130. Surrounded Regions类似于围棋, 将被包裹住(4连通)的字符 O 全部转换成字符 X. DescriptioinGiven a 2D board containing ‘X’ and ‘O’ (the letter O), capture all regions surrounded by ‘X’. A region is captured by flipping all ‘O’s into ‘X’s in that surrounded region. Example: X X X XX O O XX X O XX O X XAfter running your function, the board should be: X X X XX X X XX X X XX O X XExplanation: Surrounded regions shouldn’t be on the border, which means that any ‘O’ on the border of the board are not flipped to ‘X’. Any ‘O’ that is not on the border and it is not connected to an ‘O’ on the border will be flipped to ‘X’. Two cells are connected if they are adjacent cells connected horizontally or vertically. 解法一: 递归时间复杂度: $O(n)$, n 为 board 中的元素个数空间复杂度: $O(n)$, 递归深度优先遍历的递归次数最坏情况下为 n 次. 根据题目的要求, 我们可以从 board 的四个边界开始, 每遇到一次 O 就执行深度优先遍历, 将其相邻的所有 O 都变成另一个字符(如 #). 然后, 在顺序遍历整个 board, 将 board 中所有的 O 变成 X, 将所有的 # 变成 O, 即得解. 123456789101112131415161718192021222324252627282930class Solution &#123;public: void solve(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; if(board.size()==0 || board[0].size()==0) return; for(int i=0, j=0; j&lt;board[i].size(); j++) //上边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=1, j=board[i].size()-1; i&lt;board.size()-1; i++) //右边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=board.size()-1, j=0; j&lt;board[i].size(); j++) //下边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=1, j=0; i&lt;board.size()-1; i++) //左边界 if(board[i][j]=='O') dfs_helper(i,j,board); for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[i].size(); j++)&#123; if(board[i][j]=='O') board[i][j]='X'; else if(board[i][j]=='#') board[i][j]='O'; &#125; &#125; &#125; void dfs_helper(int i, int j, vector&lt;vector&lt;char&gt;&gt; &amp;board)&#123; board[i][j]='#'; if(i&gt;0 &amp;&amp; board[i-1][j]=='O') dfs_helper(i-1, j, board); if(j&gt;0 &amp;&amp; board[i][j-1]=='O') dfs_helper(i, j-1, board); if(i&lt;board.size()-1 &amp;&amp; board[i+1][j]=='O') dfs_helper(i+1, j, board); if(j&lt;board[i].size()-1 &amp;&amp; board[i][j+1]=='O') dfs_helper(i, j+1, board); //注意是 j&lt;board[i].size()-1, 不是 board.size()-1 &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$, n 为 board 中的元素个数空间复杂度: $O(n)$, 额外申请队列的大小为 n 思想和解法一相同, 不过采用 BFS 迭代实现, 利用一个队列来实现 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: void solve(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; if(board.size()==0 || board[0].size()==0) return; for(int i=0, j=0; j&lt;board[i].size(); j++) //上边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=1, j=board[i].size()-1; i&lt;board.size()-1; i++) //右边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=board.size()-1, j=0; j&lt;board[i].size(); j++) //下边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=1, j=0; i&lt;board.size()-1; i++) //左边界 if(board[i][j]=='O') bfs_helper(i,j,board); for(int i=0; i&lt;board.size(); i++)&#123; for(int j=0; j&lt;board[i].size(); j++)&#123; if(board[i][j]=='O') board[i][j]='X'; else if(board[i][j]=='#') board[i][j]='O'; &#125; &#125; &#125; void bfs_helper(int i, int j, vector&lt;vector&lt;char&gt;&gt; &amp;board)&#123; std::queue&lt;int&gt; bfs_q; int len = board[i].size(); bfs_q.push(i*len +j); board[i][j]='#'; while(!bfs_q.empty())&#123; i = bfs_q.front()/len; j = bfs_q.front()%len; bfs_q.pop(); if(i&gt;0 &amp;&amp; board[i-1][j]=='O')&#123; board[i-1][j]='#';bfs_q.push( (i-1)*len+j); &#125; //注意这里一定要更改了字符以后再存入队列, 负责可能引起字符重复入队列, 最终内存超限 if(j&gt;0 &amp;&amp; board[i][j-1]=='O') &#123; board[i][j-1]='#'; bfs_q.push( i*len+j-1); &#125; if(i&lt;board.size()-1 &amp;&amp; board[i+1][j]=='O') &#123; board[i+1][j]='#'; bfs_q.push( (i+1)*len + j );&#125; if(j&lt;board[i].size()-1 &amp;&amp; board[i][j+1]=='O') &#123; board[i][j+1]='#'; bfs_q.push( i*len + j+1); &#125; &#125; &#125;&#125;; 131. Palindrome Partitioning划分回文子串 Description解法一: 回溯+验证回文子串时间复杂度: $O(n\times 2^n)$, 其中, 可能的 partition 情况最多有 $2^n$ 种, 而对于每一种都要进行复杂度为 $O(n)$ 的回文子串检查空间复杂度: $O(n\times 2^n)$ ? 数组 res 的大小最坏情况下可达 $(n\times 2^n)$. 12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; partition(string s) &#123; vector&lt;vector&lt;string&gt;&gt; res; vector&lt;string&gt; part_res; dfs(s, 0, part_res, res); return res; &#125; void dfs(string s, int start, vector&lt;string&gt; &amp;part_res, vector&lt;vector&lt;string&gt;&gt; &amp;res)&#123; if(start == s.size())&#123; res.push_back(part_res); &#125; for(int i=start; i&lt;s.size(); i++)&#123; if(is_palin(start, i, s))&#123; part_res.push_back(s.substr(start, i-start+1)); dfs(s, i+1, part_res, res); part_res.pop_back(); &#125; &#125; &#125; bool is_palin(int start, int end, string s)&#123; while(start &lt; end)&#123; if(s[start]!=s[end]) return false; start++;end--; &#125; return true; &#125;&#125;; 解法二: 回溯+DP时间复杂度: $O(2^n)$, 利用 DP 建立一个 $n\times n$ 的 bool 数组, 其中 dp[i][j] 代表字符串从第 i 个字符开始, 到第 j 个字符组成的子串是否为回文串. 因此, 检查回文串时无需执行 $O(n)$ 的检查.空间复杂度: $O(n\times 2^n + n^2)$, 需要额外的数组空间来实现 DP. 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; partition(string s) &#123; vector&lt;vector&lt;string&gt;&gt; res; vector&lt;string&gt; part_res; vector&lt;vector&lt;bool&gt;&gt; dp(s.size(), vector&lt;bool&gt;(s.size(), false)); for(int j=0; j&lt;s.size(); j++)&#123; for(int i=0; i&lt;=j; i++)&#123; // 注意这两个for循环的顺序和控制条件, dp算法一定要保证在计算当前元素时, 之前的元素已经计算完成并且存入到了数组当中, 否则建立出的dp数组会出现漏解 if(s[i]==s[j] &amp;&amp; (j-i&lt;=2 || dp[i+1][j-1]==true)) dp[i][j]=true; &#125; &#125; dfs(s, 0, part_res, res, dp); return res; &#125; void dfs(string s, int start, vector&lt;string&gt; &amp;part_res, vector&lt;vector&lt;string&gt;&gt; &amp;res, vector&lt;vector&lt;bool&gt;&gt; &amp;dp )&#123; if(start == s.size())&#123; res.push_back(part_res); &#125; for(int i=start; i&lt;s.size(); i++)&#123; if(dp[start][i]==true)&#123; part_res.push_back(s.substr(start, i-start+1)); dfs(s, i+1, part_res, res, dp); part_res.pop_back(); &#125; &#125; &#125; bool is_palin(int start, int end, string s)&#123; while(start &lt; end)&#123; if(s[start]!=s[end]) return false; start++;end--; &#125; return true; &#125;&#125;; 134. Gas Station加油站问题, 根据油量和消耗量判断是否能走完一圈 DescriptionThere are N gas stations along a circular route, where the amount of gas at station i is gas[i]. You have a car with an unlimited gas tank and it costs cost[i] of gas to travel from station i to its next station (i+1). You begin the journey with an empty tank at one of the gas stations. Return the starting gas station’s index if you can travel around the circuit once in the clockwise direction, otherwise return -1. Note: If there exists a solution, it is guaranteed to be unique.Both input arrays are non-empty and have the same length.Each element in the input arrays is a non-negative integer.Example 1: Input:gas = [1,2,3,4,5]cost = [3,4,5,1,2] Output: 3 Explanation:Start at station 3 (index 3) and fill up with 4 unit of gas. Your tank = 0 + 4 = 4Travel to station 4. Your tank = 4 - 1 + 5 = 8Travel to station 0. Your tank = 8 - 2 + 1 = 7Travel to station 1. Your tank = 7 - 3 + 2 = 6Travel to station 2. Your tank = 6 - 4 + 3 = 5Travel to station 3. The cost is 5. Your gas is just enough to travel back to station 3.Therefore, return 3 as the starting index.Example 2: Input:gas = [2,3,4]cost = [3,4,3] Output: -1 Explanation:You can’t start at station 0 or 1, as there is not enough gas to travel to the next station.Let’s start at station 2 and fill up with 4 unit of gas. Your tank = 0 + 4 = 4Travel to station 0. Your tank = 4 - 3 + 2 = 3Travel to station 1. Your tank = 3 - 3 + 3 = 3You cannot travel back to station 2, as it requires 4 unit of gas but you only have 3.Therefore, you can’t travel around the circuit once no matter where you start. 解法: 最优时间复杂度: $O(n)$空间复杂度: $O(1)$ 首先要知道, 如果总油量大于总消耗量, 那么就一定存在一个起始点, 使得可以走完全程. 因此, 设置两个变量 total_left 和 cur_left, 前者存储从0点开始的总的剩余量, 后者存储从起点 start 开始的剩余量. 当 cur_left&lt;=0 时, 说明从 start 开始一直到当前位置之间的任何一个加油站都不能够成为起点, 因此将 start 置为下一个位置, 重新开始, 并令 cur_left=0. 在遍历完所有加油站以后, 如果总的剩余量不小于0, 则此时 start 所指的位置就一定是解.(由题意知, 该解是唯一解). 1234567891011121314151617class Solution &#123;public: int canCompleteCircuit(vector&lt;int&gt;&amp; gas, vector&lt;int&gt;&amp; cost) &#123; int total_left = 0; int cur_left =0; int start=0; for(int i=0; i&lt;gas.size(); i++)&#123; total_left += gas[i]-cost[i]; cur_left += gas[i]-cost[i]; if(cur_left&lt;0)&#123; start = i+1; cur_left=0; &#125; &#125; return total_left &lt; 0 ? -1:start; &#125;&#125;; 138. Copy List with Random Pointer复杂链表的复制, 复制带有随机指针的链表 DescriptionA linked list is given such that each node contains an additional random pointer which could point to any node in the list or null. Return a deep copy of the list. 解法一: 复制+拆分时间复杂度: $O(n)$, 遍历三次链表空间复杂度: $O(1)$, 不包括复制链表占用的空间 先将每个节点复制到对应节点的后面, 然后给随机指针进行赋值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*// Definition for a Node.class Node &#123;public: int val; Node* next; Node* random; Node() &#123;&#125; Node(int _val, Node* _next, Node* _random) &#123; val = _val; next = _next; random = _random; &#125;&#125;;*/class Solution &#123;public: Node* copyRandomList(Node* head) &#123; if (head == nullptr) return nullptr; Node* node = head; Node* copyNode = nullptr; while (node != nullptr) &#123; // 复制节点 copyNode = new Node(node-&gt;val, node-&gt;next, node-&gt;random); node-&gt;next = copyNode; node = node-&gt;next-&gt;next; &#125; node = head; while (node != nullptr) &#123; // 设值 random 的值 copyNode = node-&gt;next; if (node-&gt;random != nullptr) &#123; copyNode-&gt;random = node-&gt;random-&gt;next; &#125; node = node-&gt;next-&gt;next; &#125; node = head; Node* copyHead = head-&gt;next; while (node != nullptr) &#123; // 拆分两个链表 copyNode = node-&gt;next; node-&gt;next = node-&gt;next-&gt;next; if (copyNode-&gt;next != nullptr) &#123; copyNode-&gt;next = copyNode-&gt;next-&gt;next; &#125; node = node-&gt;next; // 不要忘了让 node 指向下一个节点 &#125; return copyHead; &#125;&#125;; 解法二: 一次遍历时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 需要申请链表长度的哈希表 利用一个哈希表来存储已经访问过的节点, 哈希表的键值为: {cur_node, copy_node}, 其中, cur_node 代表旧链表中的节点, copy_node 代表新链表中的节点. 顺序遍历旧链表, 对于旧链表中的每一个节点, 查看其 next 节点是否存在于哈希表 visit 中, 如果存在, 则将 copy_node 的 next 指针指向该节点(键)对应的复制节点(值). 对于 random 指针也是同理 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: RandomListNode *copyRandomList(RandomListNode *head) &#123; if(head==nullptr) return nullptr; RandomListNode *cur_node = head; RandomListNode *copy_node = new RandomListNode(head-&gt;label); unordered_map&lt;RandomListNode *, RandomListNode *&gt; visit; // key: old_node, value: copy_node visit.insert(&#123;cur_node, copy_node&#125;); //注意不要少了花括号 while(cur_node!=nullptr)&#123; RandomListNode *next_node=nullptr; if(cur_node-&gt;next==nullptr) copy_node-&gt;next = nullptr; else if(visit.find(cur_node-&gt;next)==visit.end())&#123; next_node = new RandomListNode(cur_node-&gt;next-&gt;label); copy_node-&gt;next = next_node; visit.insert(&#123;cur_node-&gt;next, next_node&#125;); &#125;else copy_node-&gt;next = visit[cur_node-&gt;next]; RandomListNode *random_node=nullptr; if(cur_node-&gt;random==nullptr) copy_node-&gt;random = nullptr; else if(visit.find(cur_node-&gt;random) == visit.end())&#123; random_node = new RandomListNode(cur_node-&gt;random-&gt;label); copy_node-&gt;random = random_node; visit.insert(&#123;cur_node-&gt;random, random_node&#125;); &#125;else copy_node-&gt;random = visit[cur_node-&gt;random]; cur_node = cur_node-&gt;next; copy_node = copy_node-&gt;next; &#125; return visit[head]; &#125;&#125;; 解法三: 递归时间复杂度: $O(n)$空间复杂度: $O(n)$, 除了哈希表所占空间外, 递归还需额外空间, 但是可以近似看做是 $O(n)$ 123456789101112131415class Solution &#123; unordered_map&lt;RandomListNode *, RandomListNode *&gt; visit;public: RandomListNode *copyRandomList(RandomListNode *head) &#123; if(head==nullptr) return nullptr; if(visit.find(head)!=visit.end()) return visit[head]; RandomListNode *node = new RandomListNode(head-&gt;label); visit.insert(&#123;head, node&#125;); node-&gt;next = copyRandomList(head-&gt;next); node-&gt;random = copyRandomList(head-&gt;random); return node; &#125;&#125;; 139. Word Break判断字符串是否可以划分成字典里面的单词 DescriptionGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, determine if s can be segmented into a space-separated sequence of one or more dictionary words. Note: The same word in the dictionary may be reused multiple times in the segmentation.You may assume the dictionary does not contain duplicate words.Example 1: Input: s = “leetcode”, wordDict = [“leet”, “code”]Output: trueExplanation: Return true because “leetcode” can be segmented as “leet code”.Example 2: Input: s = “applepenapple”, wordDict = [“apple”, “pen”]Output: trueExplanation: Return true because “applepenapple” can be segmented as “apple pen apple”. Note that you are allowed to reuse a dictionary word.Example 3: Input: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]Output: false 解法一: 回溯时间复杂度: 超时空间复杂度: $O(1)$ 123456789101112131415161718192021class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; // 纯回溯实现, 复杂度很高, 很容易超时 unordered_set&lt;string&gt; word_dict(wordDict.begin(), wordDict.end()); return helper(s,-1,word_dict); &#125; bool helper(string &amp;s, int seg, unordered_set&lt;string&gt; &amp;word_dict)&#123; if(seg==s.size()-1) return true; string temp=""; for(int i=seg+1; i&lt;s.size(); i++)&#123; temp+=s[i]; if(word_dict.find(temp) != word_dict.end() &amp;&amp; helper(s, i, word_dict)==true)&#123; return true; &#125; &#125; return false; &#125;&#125;; 解法二: DP时间复杂度: $O(n^2)$, $n$ 为字符串的长度空间复杂度: $O(n)$, dp 数组额外空间, unordered_set 额外空间 1234567891011121314151617181920class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_set&lt;string&gt; word_dict(wordDict.begin(), wordDict.end()); if(wordDict.size()==0) return false; vector&lt;bool&gt; dp(s.size(), false); for(int i=0; i&lt;s.size(); i++)&#123; for(int j=i; j&gt;=0; j--)&#123; if(j-1&lt;0 || dp[j-1]==true)&#123; string temp = s.substr(j, i-j+1); if(word_dict.find(temp) != word_dict.end())&#123; dp[i]=true; break; // break to next i &#125; &#125; &#125; &#125; return dp.back(); &#125;&#125;; 解法三: DP时间复杂度: $O(nm)$, $n$ 为字符串的长度, $m$ 为字典的 size空间复杂度: $O(n)$, dp 数组额外空间 12345678910111213141516171819class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; unordered_set&lt;string&gt; word_dict(wordDict.begin(), wordDict.end()); if(wordDict.size()==0) return false; vector&lt;bool&gt; dp(s.size(), false); for(int i=0; i&lt;s.size(); i++)&#123; for(int j=0; j&lt;wordDict.size(); j++)&#123; if(i&gt;=wordDict[j].size()-1)&#123; int len = wordDict[j].size(); string temp= s.substr(i-len+1, len); if(temp == wordDict[j] &amp;&amp; ((i-len)&lt;0 || dp[i-len]==true))// 这里注意, .size() 返回的类型并不是int, 如果使用i-wordDict[j].size() &lt;0, 就会造成runtime error, 正确做法是进行强制的类型转换, 或者用一个int变量代表之. dp[i]=true; &#125; &#125; &#125; return dp.back(); &#125;&#125;; 更简洁的写法:123456789101112131415class Solution &#123;public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; vector&lt;bool&gt; dp(s.size(), false); for (int i = 0; i &lt; s.size(); i++) &#123; for (auto const&amp; word : wordDict) &#123; int lenW = word.size(); if (!dp[i] and i+1 &gt;= lenW and word == s.substr(i-lenW+1, lenW)) &#123; dp[i] = (i-lenW+1 == 0) ? true : dp[i-lenW]; &#125; &#125; &#125; return dp[s.size() - 1]; &#125;&#125;; 142. Linked List Cycle IIDescription: 求链表中环的开始节点Given a linked list, return the node where the cycle begins. If there is no cycle, return null. Note: Do not modify the linked list. Follow up:Can you solve it without using extra space? 解法一: Floyd 的乌龟和兔子(Floyd 判环算法)时间复杂度: $O(n)$空间复杂度: $O(1)$ 此题更多解析可以看剑指offer第55题 12345678910111213141516171819202122232425262728293031/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *detectCycle(ListNode *head) &#123; if(head==nullptr) return nullptr; ListNode *slow = head; ListNode *fast = head; do&#123; slow = slow-&gt;next; fast = fast-&gt;next; if(fast==nullptr) return fast;// 不存在环 fast = fast-&gt;next; if(fast==nullptr) return fast;// 不存在环 &#125;while(slow!=fast); fast = slow; slow = head; while(fast!=slow)&#123; slow = slow-&gt;next; fast = fast-&gt;next; &#125; return slow; &#125;&#125;; 144. Binary Tree Preorder TraversalDescription: 先根遍历Given a binary tree, return the preorder traversal of its nodes’ values. Example:123456Input: [1,null,2,3] 1 \ 2 / 3 Output: [1,2,3]Follow up: Recursive solution is trivial, could you do it iteratively? 解法一: 递归12345678910111213141516class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; std::vector&lt;int&gt; res; preorder(root, res); return res; &#125; void preorder(TreeNode* root, vector&lt;int&gt;&amp; res) &#123; if (root == nullptr) return; res.push_back(root-&gt;val); preorder(root-&gt;left, res); preorder(root-&gt;right, res); return; &#125;&#125;; 解法二: 迭代12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; std::vector&lt;int&gt; res; std::stack&lt;TreeNode*&gt; s; while (!s.empty() or root != nullptr) &#123; if (root != nullptr) &#123; res.push_back(root-&gt;val); s.push(root); root = root-&gt;left; &#125; else &#123; root = s.top(); s.pop(); root = root-&gt;right; &#125; &#125; return res; &#125;&#125;; 148. Sort List对链表进行排序, 要求时间复杂度为 $O(nlogn)$, 空间复杂度为常数 DescriptionSort a linked list in O(n log n) time using constant space complexity. Example 1:12Input: 4-&gt;2-&gt;1-&gt;3Output: 1-&gt;2-&gt;3-&gt;4 Example 2:12Input: -1-&gt;5-&gt;3-&gt;4-&gt;0Output: -1-&gt;0-&gt;3-&gt;4-&gt;5 解法一: 递归 自顶向下时间复杂度: $O(nlogn)$空间复杂度: $O(logn)$ 首先对于链表的排序最先想到的就是归并排序, 因为题目的要求是空间复杂度为常数, 因为不能使用递归实现(递归会占用额外空间), 但是, 递归是一种很好理解的排序方法, 因此, 这里我们先给链表归并排序的递归实现. 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* sortList(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return head; //链表中至少应有两个元素, 否则不能进行融合, 会产生运行时错误 ListNode *slow=head, *fast=head, *pre=head; // 两指针, 找到最中间的元素, 用slow指向 while(fast!=nullptr &amp;&amp; fast-&gt;next!=nullptr)&#123; pre = slow; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; pre-&gt;next = nullptr; // 将前后两个链断开 ListNode* sort1 = sortList(head); // 将前一半排序 ListNode* sort2 = sortList(slow); // 将后一半排序 return merge_sort(sort1, sort2); // 融合两个有序链表 &#125; ListNode* merge_sort(ListNode* l1, ListNode* l2)&#123; ListNode* dummy = new ListNode(0); ListNode* cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; l2 = l2-&gt;next; &#125; cur = cur-&gt;next; &#125; if(l1!=nullptr) cur-&gt;next = l1; if(l2!=nullptr) cur-&gt;next = l2; // 将最后的一个非空元素加入排序链表 return dummy-&gt;next; &#125;&#125;; 解法二: 迭代 自底向上时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 先两两合并, 再四四合并, 逐渐向上, 直到完全合并. 注意这里之所以可以在 $O(1)$ 的空间复杂度内进行归并排序, 是因为采用了链表的底层结构, 使得 merge 操作可以在 $O(1)$ 的空间复杂度下进行. 但是对于一般的归并排序, 采用的是数组结构, 数组结构在进行 merge 时, 要么在 $O(n)$ 的空间复杂度下执行, 要么每次插入都需要移动其他元素, 增加时间复杂度. 接下来, 我们考虑如何实现归并排序的迭代算法, 代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123;private: ListNode* splitList(ListNode* l1, int blockSize) &#123; while (blockSize &gt; 1 and l1 != nullptr) &#123; l1 = l1-&gt;next; blockSize--; &#125; // 找到 l1 的尾部 if (l1 == nullptr) return l1; ListNode* l2 = l1-&gt;next; // l1 尾部的下一个就是 l2 的头部 l1-&gt;next = nullptr; // split l1 and l2 return l2; &#125; ListNode* mergeList(ListNode* l1, ListNode* l2, ListNode* dummy) &#123; ListNode* cur = dummy; while (l1 != nullptr and l2 != nullptr) &#123; if (l1-&gt;val &lt;= l2-&gt;val) &#123; cur-&gt;next = l1; l1 = l1-&gt;next; &#125; else &#123; cur-&gt;next = l2; l2 = l2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = (l1 != nullptr) ? l1 : l2; while (cur-&gt;next != nullptr) cur = cur-&gt;next; return cur; // 该节点是下一段链表的 dummy 节点 &#125;public: ListNode* sortList(ListNode* head) &#123; ListNode* node = head; int length = 0; while (node != nullptr) &#123; length++; node = node-&gt;next; &#125; ListNode* dummy = new ListNode(0); dummy-&gt;next = head; for (int blockSize = 1; blockSize &lt; length ; blockSize &lt;&lt;= 1) &#123; ListNode* curDummy = dummy; ListNode* curHead = dummy-&gt;next; while (curHead != nullptr) &#123; ListNode* l1 = curHead; ListNode* l2 = splitList(l1, blockSize); curHead = splitList(l2, blockSize); // 获取下一段链表的头节点, 并将l2的尾部置为nullptr curDummy = mergeList(l1, l2, curDummy); // 合并, 并获取当前段的最后一个非空节点 &#125; &#125; return dummy-&gt;next; &#125;&#125;; 150. Evaluate Reverse Polish Notation计算逆波兰表达式 DescriptionEvaluate the value of an arithmetic expression in Reverse Polish Notation. Valid operators are +, -, *, /. Each operand may be an integer or another expression. Note: Division between two integers should truncate toward zero.The given RPN expression is always valid. That means the expression would always evaluate to a result and there won’t be any divide by zero operation.Example 1: Input: [“2”, “1”, “+”, “3”, ““]Output: 9Explanation: ((2 + 1) 3) = 9Example 2: Input: [“4”, “13”, “5”, “/“, “+”]Output: 6Explanation: (4 + (13 / 5)) = 6Example 3: Input: [“10”, “6”, “9”, “3”, “+”, “-11”, ““, “/“, ““, “17”, “+”, “5”, “+”]Output: 22Explanation: ((10 (6 / ((9 + 3) -11))) + 17) + 5= ((10 (6 / (12 -11))) + 17) + 5= ((10 (6 / -132)) + 17) + 5= ((10 0) + 17) + 5= (0 + 17) + 5= 17 + 5= 22 解法一: 栈时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 需要一个额外的栈来存储中间结果 用栈来实现, 从到开始扫描字符串vector, 如果当前字符串不为运算符, 则直接入栈, 如果为运算符 , 则取栈顶两个元素进行运算然后将计算结果入栈. 最终, 栈中只剩一个结果值 需要注意的是: 首先要确保输入的逆波兰表达式是没有问题的, 其次还有要进行零除判断, 这几点本题没有考查, 但仍需注意 1234567891011121314151617181920212223class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; stack&lt;int&gt; polish; for(auto token : tokens)&#123; int a,b,c; if(token.back()=='+' || token.back()=='-' || token.back()=='*' || token.back()=='/')&#123; // 用back的原因是数字有可能是 -13 这种形式 b = polish.top(); polish.pop(); a = polish.top(); polish.pop(); &#125; switch(token.back())&#123; case '+': c=a+b; break; case '-': c=a-b; break; case '*': c=a*b; break; case '/': c= (b==0) ? 0 : a/b; break; default: c = c=std::stoi(token); &#125; polish.push(c); &#125; return polish.top(); &#125;&#125;; 解法二: 栈+异常解法与上面相同, 不同借助了异常, 显得更加简洁 12345678910111213141516171819202122232425262728class Solution &#123;public: int evalRPN(vector&lt;string&gt; &amp;tokens) &#123; stack&lt;int&gt; rpn; for(int i =0; i&lt;tokens.size(); i++)&#123; try&#123; rpn.push(stoi(tokens[i])); &#125; catch (exception e)&#123; int num1 = rpn.top(); rpn.pop(); int num2 = rpn.top(); rpn.pop(); switch(tokens[i][0])&#123; case '+': rpn.push(num2+num1);break; case '-': rpn.push(num2-num1);break; case '*': rpn.push(num2*num1);break; case '/': rpn.push(num2/num1);break; &#125; &#125; &#125; if(rpn.size()==1) return rpn.top(); else return 0; &#125;&#125;; 解法三: 栈+lambda思路与解法一一直, 另一种写法: 借助哈希表和lambda表达式, 使程序更加整洁 12345678910111213141516171819202122class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; unordered_map&lt;string, function&lt;int(int, int)&gt;&gt; op_map=&#123; &#123;"+", [](int a, int b)&#123;return a+b;&#125;&#125;, //注意要用双引号, 因为token是stirng类型, 而不是char类型 &#123;"-", [](int a, int b)&#123;return a-b;&#125;&#125;, &#123;"*", [](int a, int b)&#123;return a*b;&#125;&#125;, &#123;"/", [](int a, int b)&#123;return (b==0) ? 0 : a/b;&#125;&#125; &#125;; stack&lt;int&gt; polish; for(auto token : tokens)&#123; if(!op_map.count(token)) polish.push(std::stoi(token)); else&#123; int b = polish.top(); polish.pop(); int a = polish.top(); polish.pop(); polish.push(op_map[token](a, b)); &#125; &#125; return polish.top(); &#125;&#125;; 解法四: 栈+lambda+异常123456789101112131415161718192021222324class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; std::unordered_map &lt;std::string, std::function&lt;int(int, int)&gt;&gt; op = &#123; &#123;"+", [](int a, int b)&#123;return a+b;&#125;&#125;, &#123;"-", [](int a, int b)&#123;return a-b;&#125;&#125;, &#123;"*", [](int a, int b)&#123;return a*b;&#125;&#125;, &#123;"/", [](int a, int b)&#123;return b == 0 ? 0 : a/b;&#125;&#125; &#125;; std::stack&lt;int&gt; polish; for (auto const&amp; token : tokens) &#123; try &#123; polish.push(std::stoi(token)); &#125; catch (exception e) &#123; int b = polish.top(); polish.pop(); int a = polish.top(); polish.pop(); polish.push(op[token](a, b)); &#125; &#125; return polish.top(); &#125;&#125;; 152. Maximum Product Subarray求连续子序列的最大乘积 DescriptionGiven an integer array nums, find the contiguous subarray within an array (containing at least one number) which has the largest product. Example 1: Input: [2,3,-2,4]Output: 6Explanation: [2,3] has the largest product 6.Example 2: Input: [-2,0,-1]Output: 0Explanation: The result cannot be 2, because [-2,-1] is not a subarray. 解法一: 递归时间复杂度: $O(n)$, 遍历一次空间复杂度: $O(n)$, 递归 $n$ 次 这道题和连续子序列的最大和比较相似, 但是更难一些, 我们需要考虑负负得正这种情况, 因此, 我们不仅仅要维护最大值, 还要维护最小值. 考虑利用递归的方法来实现, 假设我们现在已经知道了以第 i-1 个数为结尾的连续子序列的最大乘积值max和最小乘积值min, 那么如果数组中新来一个数 nums[i], 则以第 i 个数为结尾的连续子序列的最大乘积就一定是max * nums[i], min*nums[i], nums[i]之中的最大者, 最小值为这三者的最小者. 由于我们还不知道最终的连续子序列是以第几个字符为结尾的, 因此我们利用一个变量res来维护当前找到的最大的子序列乘积, 并且随着循环的进行不断更新这个值, 最终, res的值就是我们要求的解, 代码如下: 123456789101112131415161718192021class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0 ) return 0; int res=nums[0]; helper(nums, nums.size()-1, res); return res; &#125; pair&lt;int, int&gt; helper(vector&lt;int&gt; &amp;nums, int index, int &amp;res)&#123; //注意这里要设置一个引用res来不断更新最大值 if(index == 0) return make_pair(nums[0], nums[0]); pair&lt;int, int&gt; max_min = helper(nums, index-1, res); int a = max_min.first * nums[index]; int b = max_min.second * nums[index]; int c = nums[index]; max_min.first = max(a, max(b,c)); max_min.second = min(a, min(b,c)); res = max(res, max_min.first); return max_min; &#125;&#125;; 解法二 迭代实现时间复杂度: $O(n)$空间复杂度: $O(1)$ 思路和解法一相同, 只不过换成了迭代实现123456789101112131415161718class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) return 0; int max_neg = nums[0]; int max_pos = nums[0]; int res = nums[0]; for (int i = 1; i &lt; nums.size(); i++) &#123; int num = nums[i]; int a = num * max_neg; int b = num * max_pos; max_neg = std::min(num, std::min(a, b)); max_pos = std::max(num, std::max(a, b)); if (max_pos &gt; res) res = max_pos; &#125; return res; &#125;&#125;; 解法三: DP 迭代时间复杂度: $O(n)$空间复杂度: $O(n)$, 该解法需要额外数组, 实际上这是不必要的, 详细可看解法二 上面的递归写法, 可以转换成DP迭代, 为此需要两个dp数组, 一个用来保存以第i个元素为结尾的连续子序列的最大值, 另一个保存最小值. 代码如下: 写法一: new数组12345678910111213141516171819202122class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0 ) return 0; int res=nums[0]; int *dp_max = new int[nums.size()](); int *dp_min = new int[nums.size()](); dp_max[0] = nums[0]; dp_min[0] = nums[0]; for(int i = 1; i&lt;nums.size(); i++)&#123; int a = dp_max[i-1]*nums[i]; int b = dp_min[i-1]*nums[i]; int c = nums[i]; dp_max[i] = max(a, max(b,c)); dp_min[i] = min(a, min(b,c)); res = max(res, dp_max[i]); &#125; delete[] dp_max; delete[] dp_min; return res; &#125;&#125;; 写法二: vector数组:1234567891011121314151617181920CCclass Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() == 0 ) return 0; int res=nums[0]; vector&lt;int&gt; dp_max(nums.size(), 0); vector&lt;int&gt; dp_min(nums.size(), 0); dp_max[0] = nums[0]; dp_min[0] = nums[0]; for(int i = 1; i&lt;nums.size(); i++)&#123; int a = dp_max[i-1]*nums[i]; int b = dp_min[i-1]*nums[i]; int c = nums[i]; dp_max[i] = max(a, max(b,c)); dp_min[i] = min(a, min(b,c)); res = max(res, dp_max[i]); &#125; return res; &#125;&#125;; 162. Find Peak ElementDescription: 局部最大值A peak element is an element that is greater than its neighbors. Given an input array nums, where nums[i] ≠ nums[i+1], find a peak element and return its index. The array may contain multiple peaks, in that case return the index to any one of the peaks is fine. You may imagine that nums[-1] = nums[n] = -∞. Example 1: Input: nums = [1,2,3,1]Output: 2Explanation: 3 is a peak element and your function should return the index number 2.Example 2: Input: nums = [1,2,1,3,5,6,4]Output: 1 or 5Explanation: Your function can return either index number 1 where the peak element is 2, or index number 5 where the peak element is 6. 解法一: $O(n)$ 复杂度$O(n)$ 的时间复杂度, 不合符题目要求, 仅仅记录一下. 12345678910111213class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() ==0) return -1; if(nums.size() ==1 || nums[0] &gt; nums[1]) return 0; for(int i=1; i&lt;nums.size()-1; i++)&#123; if(nums[i] &gt; nums[i-1] &amp;&amp; nums[i] &gt; nums[i+1]) return i; &#125; if(nums[nums.size()-2] &lt; nums[nums.size()-1]) return nums.size()-1; &#125;&#125;; 解法二: $O(logn)$ 复杂度二分查找, 分为以下几种情况: If num[i-1] &lt; num[i] &gt; num[i+1], then num[i] is peak If num[i-1] &lt; num[i] &lt; num[i+1], then num[i+1…n-1] must contains a peak If num[i-1] &gt; num[i] &gt; num[i+1], then num[0…i-1] must contains a peak If num[i-1] &gt; num[i] &lt; num[i+1], then both sides have peak 12345678910111213141516class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() ==0) return -1; int low = 0; int high = nums.size()-1; int mid; while(low &lt; high-1)&#123; //避免low和high相邻, 使得mid-1或mid+1可能非法 mid = (low+high)/2; if(nums[mid-1] &lt; nums[mid] &amp;&amp; nums[mid] &gt; nums[mid+1]) return mid; else if(nums[mid] &lt; nums[mid+1]) low = mid+1; else high = mid-1; &#125; return nums[low]&gt;nums[high] ? low : high; // 当low或high相邻时, 即为两端时的情况 &#125;&#125;; 1234567891011121314class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) return -1; int low = 0; int high = nums.size()-1; while (low &lt; high) &#123; int mid = (low + high) / 2; // 向下取整 if (nums[mid] &gt; nums[mid+1]) high = mid; else low = mid + 1; &#125; return low; &#125;&#125;; 递归实现:1234567891011121314151617class Solution &#123;public: int helper(vector&lt;int&gt;&amp; nums, int low, int high) &#123; if (low == high) &#123; return low; &#125; int mid = (low + high) / 2; if (nums[mid] &gt; nums[mid+1])&#123; return helper(nums, low, mid); &#125; else &#123; return helper(nums, mid+1, high); &#125; &#125; int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; return helper(nums, 0, nums.size()-1); &#125;&#125;; 166. Fraction to Recurring DecimalDescription: 无限循环小数Given two integers representing the numerator and denominator of a fraction, return the fraction in string format. If the fractional part is repeating, enclose the repeating part in parentheses. Example 1: Input: numerator = 1, denominator = 2Output: “0.5”Example 2: Input: numerator = 2, denominator = 1Output: “2”Example 3: Input: numerator = 2, denominator = 3Output: “0.(6)” 解法一: 用余数作为哈希表的key时间复杂度: $O(logn)$, 每次都会乘以10再取余数空间复杂度: $O(logn)$, 余数的哈希表 首先, 获取最终浮点数的符号和整数部分, 此处由于可能出现分子为-2147483648, 而分母为-1的情况, 为此, 建议使用long长整型来避免溢出.在计算小数部分时, 将余数作为key, 小数当前位置作为value存入哈希表中, 然后将余数乘以10, 再计算当前小数位的值, 并将取余得到新的余数.题目指明浮点数是无限循环小数, 则如果小数部分没有循环, 那么一定会出现余数为0的情况, 此时, 返回当前的res即可. 如果小数存在循环, 那么循环一定出现在余数相同的时刻, 此时, 将添加后扩号, 并根据哈希表中的value添加前括号. 123456789101112131415161718192021222324252627282930class Solution &#123;public: string fractionToDecimal(int numerator, int denominator) &#123; if(numerator == 0 || denominator == 0) return "0"; string res; if(numerator&lt;0 ^ denominator&lt;0) res+="-"; long numer = (numerator &lt; 0) ? (long)(numerator)*-1 : (long)numerator; // 注意, 不能写成 (long)(numerator*-1) long denom = (denominator &lt; 0) ? (long)(denominator)*-1 : (long)denominator; long integral = numer/denom; res += std::to_string(integral); // 添加整数部分 long rmd = numer % denom; if(rmd!=0) res += "."; // 存在小数 unordered_map &lt;long, long&gt; hash; while(rmd!=0)&#123; if(hash.find(rmd) != hash.end())&#123; // 判断余数 res.insert(hash[rmd], "("); res += ")"; break; &#125; hash[rmd] = res.size(); rmd = rmd*10; long quotient = rmd/denom; res += std::to_string(quotient); rmd = rmd%denom; &#125; return res; &#125;&#125;; 179. Largest NumberDescription: 排列数字使其字符串形式的数字为最大Given a list of non negative integers, arrange them such that they form the largest number. Example 1: Input: [10,2]Output: “210”Example 2: Input: [3,30,34,5,9]Output: “9534330” 解法一: 构造比较函数, 快排排序时间复杂度: $O(nlogn)$, 快排时间复杂度空间复杂度: $O(logn)$, 快排空间复杂度, 如果使用其他排序算法, 可将空间复杂度降为 $O(1)$ 我们可以构造一个新的比较函数来决定两个元素的先后关系, 对于任意两个元素 a 和 b, 首先将其转换成字符串形式 s_a 和 s_b, 我们知道, 若整形 a&gt;b, 则一定有 s_a &gt; s_b, 因此我们可以比较 s_a+s_b 和 s_b+s_a 的大小关系, 根据题目要求, 我们要进行递减排序. 得到比较函数以后, 利用快排排序即可. 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public: string largestNumber(vector&lt;int&gt;&amp; nums) &#123; q_sort(nums, 0, nums.size()-1); if(nums.size()!=0 &amp;&amp; nums[0] == 0) return "0"; // 对于输入[0, 0, 0] 应该返回 "0", 而不是"000", 必须要放在排序后, nums[0] == 0 说明所有元素均为0 string res; for(auto num: nums)&#123; res += std::to_string(num); &#125; return res; &#125; bool str_geq(int a, int b)&#123; string s_a = std::to_string(a); string s_b = std::to_string(b); if(s_a+s_b &gt;= s_b+s_a) return true; //注意是递减排序, 所以为 &gt;= else return false; &#125; int partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low &lt; high)&#123; while(low&lt;high &amp;&amp; str_geq(P, nums[high])) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; str_geq(nums[low], P)) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125; void q_sort(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int mid = partition(nums, low, high); if(mid&gt;low) q_sort(nums, low, mid-1); if(mid&lt;high) q_sort(nums, mid+1, high); &#125;&#125;; 解法二: 利用 STL sort() 函数时间复杂度: $O(nlogn)$, 快排时间复杂度空间复杂度: $O(logn)$, 快排空间复杂度, 如果使用其他排序算法, 可将空间复杂度降为 $O(1)$ 思路与解法一一致, 只不过省略了排序算法的实现, 使用了 STL 的 sort 函数. 需要注意, 在 C++ STL 的 sort 函数中, bool 返回真的时候, 必须是绝对大于或者绝对小于, 对于等于的情况, 只能返回 false(因为当返回 true 时, 元素会继续下一个, 这样对于极端情况, 如所有元素都一样时, 会出现越界, 从而导致段错误) 123456789101112131415161718bool str_geq(int a, int b)&#123; string s_a = std::to_string(a); string s_b = std::to_string(b); if(s_a+s_b &gt; s_b+s_a) return true; // 这里用 &gt;= 会产生运行时错误, 用 &gt; 则可以通过, 为什么? else return false;&#125;class Solution &#123;public: string largestNumber(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end(), str_geq); if(nums.size()!=0 &amp;&amp; nums[0] == 0) return "0"; // 对于输入[0, 0, 0] 应该返回 "0", 而不是"000", 必须要放在排序后, nums[0] == 0 说明所有元素均为0 string res; for(auto num: nums)&#123; res += std::to_string(num); &#125; return res; &#125; &#125;; 200. Number of IslandsDescription: 区块的个数Given a 2d grid map of ‘1’s (land) and ‘0’s (water), count the number of islands. An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water. Example 1: Input:11110110101100000000 Output: 1Example 2: Input:11000110000010000011 Output: 3 解法一: DFS 遍历时间复杂度: $O(n)$, 至多遍历两次 grid空间复杂度: $O(1)$ 遍历 grid 中的每一个元素, 如果为1, 则将与之相连的所有的1都置为0, 并且区块个数加1, 这样, 最坏的情况就是 grid 中的所有数字均为1, 此时, 需要遍历两边数组. 1234567891011121314151617181920212223242526272829class Solution &#123;public: int numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123; int res = 0; for(int i =0 ;i&lt;grid.size(); i++)&#123; for(int j=0; j&lt;grid[i].size(); j++)&#123; if(grid[i][j] == '1')&#123; fill(grid, i, j); res++; &#125; &#125; &#125; return res; &#125; void fill(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int i, int j) &#123; grid[i][j] = '2'; int n = grid.size(); int m = grid[0].size(); int dirs[4][2] = &#123;&#123;-1, 0&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;&#125;; for (auto dir : dirs) &#123; int x = i + dir[0]; int y = j + dir[1]; if (x &gt;=0 &amp;&amp; x &lt; n &amp;&amp; y &gt;=0 &amp;&amp; y &lt; m &amp;&amp; grid[x][y] == '1') &#123; fill(grid, x, y); &#125; &#125; &#125;&#125;; 207. Course ScheduleDescription: 课程表 / 判断有向图是否存在环There are a total of n courses you have to take, labeled from 0 to n-1. Some courses may have prerequisites, for example to take course 0 you have to first take course 1, which is expressed as a pair: [0,1] Given the total number of courses and a list of prerequisite pairs, is it possible for you to finish all courses? Example 1:Input: 2, [[1,0]]Output: trueExplanation:There are a total of 2 courses to take. To take course 1 you should have finished course 0. So it is possible. Example 2:Input: 2, [[1,0],[0,1]]Output: falseExplanation:There are a total of 2 courses to take. To take course 1 you should have finished course 0, and to take course 0 you should also have finished course 1. So it is impossible. 解法一: BFS / 拓扑排序时间复杂度: $O(V+E)$, 统计入度时需要 $O(V)$, 处理队列需要 $O(E)$, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, 入度数组和队列分别需要 $(V)$, 邻接表需要 $O(V+E)$. 首先将图的边表示结构转换成邻接表形式(用vector来实现邻接表, 使其支持随机访问). 然后再申请一个 $O(V)$ 大小的数组来存储每个节点的入度. 在拓扑排序时, 先将所有入度为0的节点添加都一个队列当中, 然后从队列顶端拿出一个节点, 将该节点的所有直接后序节点的入度都减1, 然后再将所有入度为0的节点入队列. 如此迭代下去, 直至所有队列为空. 此时, 如果还有某个节点的入度不为0, 则说明存在环, 应该返回 false, 否则, 返回 true. 1234567891011121314151617181920212223242526class Solution &#123;public: bool canFinish(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;(0)); vector&lt;int&gt; in_degree(numCourses, 0); for(auto p : prerequisites)&#123; graph_c[p.second].push_back(p.first); in_degree[p.first]++; &#125; queue&lt;int&gt; q; // 入度为0的节点队列 for(int i=0; i&lt;numCourses; i++)&#123; if(in_degree[i]==0) q.push(i); //将所有入度为0的节点入队列 &#125; while(!q.empty())&#123; int cur_c = q.front(); q.pop(); for(auto next_c : graph_c[cur_c])&#123; // next_c为cur_c的直接后序课程 in_degree[next_c]--; // 后序节点的入度减1 if(in_degree[next_c]==0) q.push(next_c);//如果减为0, 则入队列 &#125; &#125; for(auto in : in_degree)&#123; if(in!=0) return false; &#125; return true; &#125;&#125;; 解法二: DFS时间复杂度: $O(V+E)$, 复杂度和 BFS 算法近似, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, visit数组和递归栈分别需要 $(V)$, 邻接表需要 $O(V+E)$. 首先, 和 BFS 一样, 建立关于图的邻接表结构, 然后, 申请 $O(V)$ 大小的访问数组visit, 初始值全部为0, 表示所有节点均为访问. 然后, 根据 DFS 算法的执行过程. 将当前正在访问的节点置为-1, 将已经访问过且确认无环的节点置为1. 则则DFS过程中, 如果访问到了一个已经被置为-1的节点, 则说明该节点是当前循环内的正在访问的节点, 因此, 构成了一个环, 返回 false. 如果遇到了一个被置为1的节点, 因为已经确认该节点无环, 因此可以直接返回 true. 12345678910111213141516171819202122232425class Solution &#123;public: bool canFinish(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;(0)); vector&lt;int&gt; visit(numCourses, 0); for(auto p : prerequisites) graph_c[p.second].push_back(p.first); for(int i=0; i&lt;numCourses; i++)&#123; // 因为当前的图并不是一个连通图, 所以必须遍历所有的节点 if(canFinishDFS(graph_c, visit, i) == false) return false; &#125; return true; &#125; bool canFinishDFS(vector&lt;vector&lt;int&gt;&gt; &amp;graph_c, vector&lt;int&gt; &amp;visit, int i)&#123; if(visit[i] == -1) return false; if(visit[i] == 1) return true; visit[i] = -1; // 将当前节点置为正在访问状态 for(auto node : graph_c[i])&#123; if(canFinishDFS(graph_c, visit, node) == false) return false; // 当前节点上存在环 &#125; visit[i] = 1; // 将当前节点置为已经访问过且确认无环状态 return true; // 确认节点i无环, 返回true &#125;&#125;; 208. Implement Trie (Prefix Tree)Description: 实现字典树(前缀树)Implement a trie with insert, search, and startsWith methods. Example:12345678Trie trie = new Trie();trie.insert("apple");trie.search("apple"); // returns truetrie.search("app"); // returns falsetrie.startsWith("app"); // returns truetrie.insert("app"); trie.search("app"); // returns true 解法一https://www.cnblogs.com/grandyang/p/4491665.html 时间复杂度: $O(k)$, 插入, 查找, 找前缀均只需要 $O(k)$复杂度, $k$ 为字符串长度空间复杂度: 与字符串的公共部分的多少有关, 公共部分越多, 越节省空间, 反之, 空间复杂度较高. 最差情况下为 $O(wk)$, 其中, $w$ 为单词的个数, $k$ 为单词的最长长度. 字母字典树是一个26叉树, 树的根节点没有字符, 其他节点有且仅有一个字符, 我们模仿二叉树的定义, 构建一个26叉树的数据结构, 用子节点的编号代表字母(即0号节点代表字母a, 1号代表b,…,25号代表z), 另外需要定义一个布尔值来标识当前节点是否构成一个单词. 插入时, 根据字符串遍历树, 如果当前字符不存在, 则新建一个. 查找和找前缀时, 如果不存在则直接返回false. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class TrieNode&#123;public: TrieNode *child[26]; bool is_word; TrieNode():is_word(false)&#123; for(auto &amp;c : child)&#123; // 对c进行改动, 需要用引用&amp; c = nullptr; &#125; &#125;&#125;;class Trie &#123;private: TrieNode *root;public: /** Initialize your data structure here. */ Trie() &#123; root = new TrieNode(); &#125; /** Inserts a word into the trie. */ void insert(string word) &#123; TrieNode *p = root; for(auto letter : word)&#123; int i = letter - 'a'; if(p-&gt;child[i] == nullptr) p-&gt;child[i]=new TrieNode(); p = p-&gt;child[i]; &#125; p-&gt;is_word = true; &#125; /** Returns if the word is in the trie. */ bool search(string word) &#123; TrieNode *p = root; for(auto letter : word)&#123; int i = letter - 'a'; if(p-&gt;child[i]==nullptr) return false; p = p-&gt;child[i]; &#125; return (p-&gt;is_word == true) ? true : false; &#125; /** Returns if there is any word in the trie that starts with the given prefix. */ bool startsWith(string prefix) &#123; TrieNode *p = root; for(auto letter : prefix)&#123; int i = letter - 'a'; if(p-&gt;child[i]==nullptr) return false; p = p-&gt;child[i]; &#125; return true; &#125;&#125;;/** * Your Trie object will be instantiated and called as such: * Trie obj = new Trie(); * obj.insert(word); * bool param_2 = obj.search(word); * bool param_3 = obj.startsWith(prefix); */ 210. Course Schedule IIDescription: 判断有向图是否有环, 若无环, 则返回拓扑序列There are a total of n courses you have to take, labeled from 0 to n-1. Some courses may have prerequisites, for example to take course 0 you have to first take course 1, which is expressed as a pair: [0,1] Given the total number of courses and a list of prerequisite pairs, return the ordering of courses you should take to finish all courses. There may be multiple correct orders, you just need to return one of them. If it is impossible to finish all courses, return an empty array. Example 1:Input: 2, [[1,0]]Output: [0,1]Explanation:There are a total of 2 courses to take. To take course 1 you should have finished course 0. So the correct course order is [0,1] . Example 2:Input: 4, [[1,0],[2,0],[3,1],[3,2]]Output: [0,1,2,3] or [0,2,1,3]Explanation:There are a total of 4 courses to take. To take course 3 you should have finished both courses 1 and 2. Both courses 1 and 2 should be taken after you finished course 0. So one correct course order is [0,1,2,3]. Another correct ordering is [0,2,1,3] . 解法一: BFS, 拓扑排序时间复杂度: $O(V+E)$, 统计入度时需要 $O(V)$, 处理队列需要 $O(E)$, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, 入度数组和队列分别需要 $(V)$, 邻接表需要 $O(V+E)$, 相比于第207题, 多了一个拓扑序列的数组, 大小为 $O(V)$. 和第207题差不多, 不过在判断是否有环的同时, 还要记录正确的拓扑序列并返回. 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; findOrder(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;()); // 构建图的邻接表 vector&lt;int&gt; in_degree(numCourses);// 构建入度数组 for(auto c_pair : prerequisites)&#123; graph_c[c_pair.second].push_back(c_pair.first); in_degree[c_pair.first]++; &#125; queue&lt;int&gt; q; //入度为0的队列 for(int i=0; i&lt;numCourses; i++)&#123; if(in_degree[i]==0) q.push(i); &#125; vector&lt;int&gt; res; // 记录拓扑序列 while(!q.empty())&#123; int cur_c = q.front(); q.pop(); res.push_back(cur_c); for(auto &amp;next_c : graph_c[cur_c])&#123; in_degree[next_c]--; // 后修课的入度减1 if(in_degree[next_c]==0) q.push(next_c); &#125; &#125; if(res.size() == numCourses) return res; else return vector&lt;int&gt;(); &#125;&#125;; 解法二: DFS时间复杂度: $O(V+E)$, 复杂度和 BFS 算法近似, 其中 $V$ 为节点个数, $E$ 为边的个数空间复杂度: $O(V+E)$, visit数组和递归栈分别需要 $(V)$, 邻接表需要 $O(V+E)$, 拓扑序列需要 $O(V)$. 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; findOrder(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; vector&lt;vector&lt;int&gt;&gt; graph_c(numCourses, vector&lt;int&gt;()); // 构建图的邻接表 vector&lt;int&gt; visit(numCourses, 0);// 构建入度数组 for(auto c_pair : prerequisites)&#123; graph_c[c_pair.second].push_back(c_pair.first); &#125; vector&lt;int&gt; res; for(int i=0; i&lt;numCourses; i++)&#123; //非连通图, 需要遍历所有节点 if(findOrderDFS(graph_c, i, visit, res)==false) return vector&lt;int&gt;(); &#125; std::reverse(res.begin(), res.end()); //等于dfs来说, 最后的课程会先加入结果数组, 因此, res中的序列逆置后才是最终的拓扑序列. return res; &#125; bool findOrderDFS(vector&lt;vector&lt;int&gt;&gt; &amp;graph_c, int i, vector&lt;int&gt; &amp;visit, vector&lt;int&gt; &amp;res)&#123; if(visit[i]==-1) return false; // 重复访问, 存在环 if(visit[i]==1) return true; // 已经访问过且确认无环, 可直接返回 visit[i] = -1; // 置为正在访问状态 for(auto next_c : graph_c[i])&#123; if(findOrderDFS(graph_c, next_c, visit, res) == false) return false; &#125; visit[i] = 1; //确认无环 res.push_back(i); // return true; &#125;&#125;; 215. Kth Largest Element in an ArrayDescription: 找出无序数组中第k大的数Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element. Example 1: Input: [3,2,1,5,6,4] and k = 2Output: 5Example 2: Input: [3,2,3,1,2,4,5,5,6] and k = 4Output: 4 解法一: 小顶堆时间复杂度: $O(nlogk)$, 堆的插入复杂度为 $O(logk)$, 最多需要进行 $n$ 次插入.空间复杂度: $O(k)$, 堆的大小 构建一个大小为 $k$ 的小顶堆, 对于任意一个新来的元素, 如果该元素大于堆顶, 将则堆顶退出, 并将该元素插入. 最终, 堆内的元素就是数组的最大的前 $k$ 个元素, 而堆顶刚好为第 $k$ 大的元素. 123456789101112131415class Solution &#123;public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt; heap_k; for(auto num : nums)&#123; if(heap_k.size() &lt; k)&#123; heap_k.push(num); &#125;else if(num &gt; heap_k.top())&#123; heap_k.pop(); heap_k.push(num); &#125; &#125; return heap_k.top(); &#125;&#125;; 解法二: 部分排序(nth_element)http://www.voidcn.com/article/p-qyrpnkse-gx.html 最优解法 时间复杂度: 平均为 $O(n)$. nth_element 的时间复杂度为 $T(n) = T(n/2) + O(n) = O(n) + O(n/2) + O(n/4) + …$, 也就是 $O(n)$.空间复杂度: $O(1)$, 不占用额外空间 直接调用 STL 的部分排序算法nth_element.nth_element算法将重新排列区间[first, last)的序列元素, 算法执行完毕后, 会使得 第 $k$ 个位置的元素在最终的算法执行完毕后, 和整个区间完全排序后该位置的元素相同. 这个新的nth元素之前的所有元素均 &lt;= (&gt;=) nth元素之后的所有元素.但是该算法并不保证位于第 $k$ 个元素两边区间的元素有序. 该算法和 partial_sort 算法之间一个很大的区别在于: nth_element对于除第 $k$ 位置的元素之外的区间元素的顺序不做保证, 而partial_sort排序后会使得前 $m$ 个数的子区间是有序的. 正因为如此, 在需要无序的前 top_k 个值时, nth_element 相对于 partial_sort 要更快.(只需要找第 $k$ 个值, 其前面的元素即为 top_k, 时间复杂度为 $O(n)$). 如果需要有序, 也可以先使用 nth_element, 再对前 k 个数组排序, 总的复杂度为 $O(n+klogk)$ 1234567class Solution &#123;public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; std::nth_element(nums.begin(), nums.begin()+k-1, nums.end(), std::greater&lt;int&gt;()); return nums[k-1]; &#125;&#125;; 解法三: 基于 Partition时间复杂度: $O(n)$空间复杂度: $O(1)$ 该解法和解法二思路相同, 只不过是我们自己手动实现 Partition 的算法逻辑, 而不是调用 STL 函数. 123456789101112131415161718192021222324252627class Solution &#123;public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123; int low=0, high=nums.size()-1; int pth = Partition(nums, low, high); while(pth != k-1)&#123; if(pth &gt; k-1) high = pth-1; else low = pth+1; pth = Partition(nums, low, high); &#125; return nums[pth]; &#125; int Partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P&gt;= nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P&lt;=nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125;&#125;; 227. Basic Calculator IIDescription: 基本计算器(二)Implement a basic calculator to evaluate a simple expression string. The expression string contains only non-negative integers, +, -, *, / operators and empty spaces . The integer division should truncate toward zero. Example 1: Input: “3+2*2”Output: 7Example 2: Input: “ 3/2 “Output: 1Example 3: Input: “ 3+5 / 2 “Output: 5 解法一: 栈时间复杂度: $O(n)$, 遍历字符串一遍, 遍历栈一遍空间复杂度: $O(n)$, 栈的大小 因为本题没有带括号, 因此优先级关系比较明朗, 可以简单的用栈来实现. 对于任意一个符号, 如果是加号或者减号, 就直接将其后面的数字入栈, 其中减号的情况需要给入栈数字加负号. 如果是乘号或除号, 将先从栈顶取出一个数字, 然后将该数字与符号后的数字进行计算, 并将计算结果入栈. 如此遍历, 直到遍历完所有字符, 最终将栈中的所有数字相加.此题需要注意两个地方, 一是对于第一个数字, 需要在特别的将该数字前的符号对应成加号. 二是需要处理字符串中出现的空格. 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: int calculate(string s) &#123; stack&lt;int&gt; cal_s; for(int i=0; i&lt;s.size(); )&#123; while(i!=s.size() &amp;&amp; s[i] == ' ') i++; // 跳过空格 if(i==s.size()) break; // 达到字符串尾部, 直接跳出 char op; if(cal_s.empty()) op = '+'; else op = s[i++]; int num = 0; while(s[i] == ' ') i++; // 跳过空格 while( i!=s.size() &amp;&amp; s[i] &lt;= '9' &amp;&amp; s[i] &gt;= '0')&#123; num = num*10 + s[i++] - '0'; &#125; int pre_num=0; switch(op)&#123; case '+': cal_s.push(num); break; case '-': cal_s.push(-num); break; case '*': pre_num = cal_s.top(); cal_s.pop(); cal_s.push(pre_num * num); break; case '/': pre_num = cal_s.top(); cal_s.pop(); cal_s.push(pre_num / num); break; default: return op; //error &#125; &#125; int res = 0; while(!cal_s.empty())&#123; res += cal_s.top(); cal_s.pop(); &#125; return res; &#125;&#125;; 解法二: 字符串流时间复杂度: $O(n)$, 遍历每个字符空间复杂度: $O(1)$, 无需额外空间 字符串流可以自动的格式化读取字符串信息, 简化了代码编写量 123456789101112131415161718192021222324class Solution &#123;public: int calculate(string s) &#123; std::istringstream in("+"+s+"+"); long long sum = 0, pre_num = 0, num; char op; while(in&gt;&gt;op) &#123; if (op == '+' or op == '-') &#123; sum += pre_num; in &gt;&gt; pre_num; int sign = (op == '+' ? 1 : -1); pre_num *= sign; &#125; else &#123; in &gt;&gt; num; if (op == '*') &#123; pre_num *= num; &#125; else if (op == '/') &#123; pre_num /= num; &#125; &#125; &#125; return static_cast&lt;int&gt;(sum); &#125;&#125;; 230. Kth Smallest Element in a BSTDescription: 找出二叉搜索树中的最小元素Given a binary search tree, write a function kthSmallest to find the kth smallest element in it. Note:You may assume k is always valid, 1 ≤ k ≤ BST’s total elements. Example 1:1234567Input: root = [3,1,4,null,2], k = 1 3 / \ 1 4 \ 2Output: 1 Example 2:123456789Input: root = [5,3,6,2,4,null,null,1], k = 3 5 / \ 3 6 / \ 2 4 / 1Output: 3 Follow up:What if the BST is modified (insert/delete operations) often and you need to find the kth smallest frequently? How would you optimize the kthSmallest routine? 解法一: 非递归中根遍历时间复杂度: $O(k)$, 遍历到第 $k$ 个元素为止空间复杂度: $O(k)$, 栈中最多存储 $k$ 个元素. 非递归中根遍历二叉搜索树, 当遍历到第k个元素时, 将其返回. 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; if(k&lt;1) return INT_MIN;// error stack&lt;TreeNode*&gt; s; TreeNode* cur = root; int count=0; while(cur!=nullptr || !s.empty())&#123; while(cur!=nullptr)&#123; s.push(cur); cur = cur-&gt;left; &#125; if(!s.empty())&#123; cur = s.top(); s.pop(); if(++count == k)&#123; return cur-&gt;val; &#125; cur = cur-&gt;right; &#125; &#125; return INT_MIN;// error &#125;&#125;; 解法二: 递归中根遍历时间复杂度: $O(k)$空间复杂度: $O(k)$ 12345678910111213141516171819class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; int count = 0; int res = 0; helper(root, count, k, res); return res; &#125; void helper(TreeNode *root, int &amp;count, int &amp;k, int &amp;res)&#123; if(count==k || root == nullptr) return; // 如果已经统计了k个, 则直接返回 helper(root-&gt;left, count, k, res); if(count==k) return; // 如果已经统计了k个, 则直接返回 // 加上该语句可省去后面的过程, 加速迭代结束, 当然不加也可以 else if(++count == k)&#123; // 访问当前节点 res = root-&gt;val; return; &#125; if(count!=k) helper(root-&gt;right, count, k, res); // 如果已经统计了k个, 则不再遍历右子树 &#125;&#125;; 更简洁的写法: 12345678910111213141516171819class Solution &#123; void helper(TreeNode* root, int&amp; count, int k, int&amp; res) &#123; if (root == nullptr) return; helper(root-&gt;left, count, k, res); count++; if(k == count) &#123; res = root-&gt;val; return; &#125; helper(root-&gt;right, count, k, res); &#125;public: int kthSmallest(TreeNode* root, int k) &#123; int count = 0; int res = 0; helper(root, count, k, res); return res; &#125;&#125;; 解法三: 二叉搜索时间复杂度: $O(logn)+ O(n)$, 搜索的复杂度为树的高度, 但是计算count的复杂度为 $O(n)$.空间复杂度: $O(logn)$, 递归占用的空间, 若采用非递归实现, 则空间复杂度为 $O(1)$. 二叉搜索, 统计当前节点之前的元素个数, 如果大于 $k$, 则继续在左子树中搜索第 $k$ 小的元素, 如果 count 小于 $k$ , 则在右子树中搜索第 $k-count-1$ 小的元素. 123456789101112131415161718class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; int count = countNode(root-&gt;left); // 左子树元素个数 if(count+1 &gt; k)&#123; return kthSmallest(root-&gt;left, k); &#125;else if(count+1 &lt; k)&#123; return kthSmallest(root-&gt;right, k - count - 1); &#125;else&#123; return root-&gt;val; &#125; &#125; int countNode(TreeNode* root)&#123; if(root==nullptr) return 0; return 1+countNode(root-&gt;left)+countNode(root-&gt;right); &#125;&#125;; 解答Follow up方法一: 根据解法三我们可以知道, 在计算子树节点个数的时候 int count = countNode(root-&gt;left);, 有很多的重复计算, 因此, 我们可以修改树的结构定义, 使得每个节点都持有其左子树中的节点个数, 那么在查找第 $k$ 小的元素的时候, 就可以用 $O(1)$ 的时间复杂度获取到左子树的节点个数, 因此, 最终查询第 $k$ 小的时间复杂度变为 $O(logn)$. 方法二: 在中根遍历的同时, 用一个大小为 $k$ 的大顶堆(priority_queue), 这些可以将二叉搜索树中最小的 $k$ 个数存储起来, 并且可以用 $O(1)$ 的时间复杂度获取到第 $k$ 小的元素. (二叉搜索树的中根遍历下, 未遍历到的都是较大的元素, 因此无需遍历整个树, 只需要遍历到第 $k$ 个元素即可). 在对树进行修改时, 同步更新大顶堆, 前者时间复杂度为 $O(logn)$, 后者为 $O(logk)$. 236. Lowest Common Ancestor of a Binary TreeDescription: 查找二叉树中任意两个节点的公共祖先Given a binary tree, find the lowest common ancestor (LCA) of two given nodes in the tree. According to the definition of LCA on Wikipedia: “The lowest common ancestor is defined between two nodes p and q as the lowest node in T that has both p and q as descendants (where we allow a node to be a descendant of itself).” Given the following binary tree: root = [3,5,1,6,2,0,8,null,null,7,4]1234567 _______3______ / \ __5__ __1__/ \ / \6 2 0 8 / \ 7 4 Example 1:123Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1Output: 3Explanation: The LCA of nodes 5 and 1 is 3. Example 2:123Input: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 4Output: 5Explanation: The LCA of nodes 5 and 4 is 5, since a node can be a descendant of itself according to the LCA definition. Note: All of the nodes values will be unique. p and q are different and both values will exist in the binary tree. 解法一: 递归时间复杂度: $O(n)$, 需遍历 $n$ 个节点.(任何情况下都需遍历n个节点)空间复杂度: $O(n)$, 需进行 $n$ 次递归调用.( $n$ 包含空节点) 对于最小公共祖先来说, 它相对于其他祖先有一个特点, 即节点 p 和 q 只可能是以下面三种情况分布在树中: p和q分别处于当前节点的左子树 和 右子树之中. p为当前节点, q处于当前节点的左子树 或 右子树之中 q为当前节点, p处于当前节点的左子树 或 右子树之中 而对于其他祖先来说, 绝对不可能出现上面三种情况, 因为 p和q一定处于其他祖先的同一侧子树之中., 即要么都处在右子树中, 要么都处在左子树中. 因此我们可以用p和q在当前节点构成的子树中的分布情况来判断是否为最小祖先. **注意, 题目中说了p, q一定存在, 并且树中节点都是唯一的, 因此, 下面的代码无需对p, q进行存在性检查. 123456789101112131415161718192021222324252627282930/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: TreeNode* res = nullptr;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; res = nullptr; recurseHelper(root, p, q); return res; &#125; bool recurseHelper(TreeNode *root, TreeNode *p, TreeNode *q)&#123; if(root == nullptr) return false; // 遇到空节点, 说明没有目标节点 int left = recurseHelper(root-&gt;left, p, q) ? 1 : 0; // 左子树中有p或q int right = recurseHelper(root-&gt;right, p, q) ? 1 : 0; // 右子树中有p或q int mid = (root==p || root==q) ? 1 : 0; // 找到了p或q, 这里相当于做了存在性检查 if( left+right+mid &gt;= 2) res = root; // 如果左,右或当前节点中有两个以上为true, 则说明当前节点为最小公共祖先 return (left+right+mid)&gt;0; // 只要不是空节点, 就可以返回 true. &#125;&#125;; 上面用了是将res作为成员函数进行赋值, 更好的做法是用指针引用.123456789101112131415161718class Solution &#123;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; TreeNode* res = nullptr; lcaHelper(root, p, q, res); return res; &#125; bool lcaHelper(TreeNode* root, TreeNode* p, TreeNode* q, TreeNode*&amp; res) &#123; if (root == nullptr) return false; int left= lcaHelper(root-&gt;left, p, q, res) ? 1 : 0; int right = lcaHelper(root-&gt;right, p, q, res) ? 1 : 0; int mid = (root == p || root == q) ? 1 : 0; if (left+right+mid &gt;= 2) res = root; return (left+right+mid) &gt; 0; &#125;&#125;; 解法二: 迭代(存储父节点)时间复杂度: $O(n)$, 最坏需遍历 $n$ 个节点.空间复杂度: $O(n+n+n) = O(n)$, 栈, 哈希表, 集合的空间复杂度在最坏情况下均为 $O(n)$ 如果我们能够获取到父节点, 那么我们就可以反向遍历q和p来访问他们的祖先节点. 那么, 第一个公共的祖先节点就一定是 LCA node. 我们可以将节点的父节点指针保存在一个字典(hash)当中. 具体的算法流程如下所示: 从根节点开始遍历整个树(任意一种遍历算法都可以, 只要能找到p和q即可); 直到找到节点p和q之前, 将所有节点的父节点都保存在字典(hash)中; 一旦我们找到了q和q, 我们就将所有p的祖先节点放入了一个集合(set)当中; 然后, 我们反向遍历q的祖先节点, 当找到一个存在时集合中的祖先节点时, 该节点就是第一个公共的租店节点, 也就是 LCA node, 将其返回. 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; std::stack&lt;TreeNode*&gt; s; std::unordered_map&lt;TreeNode*, TreeNode*&gt; hash; std::set&lt;TreeNode*&gt; ancestors; if (root != nullptr) &#123; s.push(root); hash.insert(&#123;root, nullptr&#125;); &#125; else return nullptr; while(hash.find(p) == hash.end() || hash.find(q) == hash.end()) &#123; TreeNode* node = s.top(); s.pop(); if (node-&gt;left != nullptr) &#123; hash.insert(&#123;node-&gt;left, node&#125;); s.push(node-&gt;left); &#125; if (node-&gt;right != nullptr) &#123; hash.insert(&#123;node-&gt;right, node&#125;); s.push(node-&gt;right); &#125; &#125; TreeNode* parent = p; while (parent != nullptr) &#123; ancestors.insert(parent); parent = hash[parent]; &#125; TreeNode* lcaNode = q; while (ancestors.find(lcaNode) == ancestors.end()) &#123; lcaNode = hash[lcaNode]; &#125; return lcaNode; &#125;&#125;; 解法三: 迭代(不存储父节点)时间复杂度: $O(n)$, 最坏需遍历 $n$ 个节点.空间复杂度: $O(n)$, 采用后序遍历, 只需维护一个栈, 空间复杂度在最坏情况下为 $O(n)$ 在解法二中, 我们是通过反向遍历的方法来查找 LCA 的, 实际上我们可以省去这一步, 直接要一个指针时刻指向可能的 LCA, 当我们找到p和q两个节点时, 我们可以直接返回当前的 LCA. 具体算法步骤如下: 从根节点开始; 将(root, root_state)压入栈中, root_state定义了根节点的剩余的子节点是否可以被遍历; 当栈非空时, 查看栈顶元素(parent_node, parent_state); 在遍历parent_node的任何子节点之前, 首先确认parent_node是否是节点p或q; 当首次找到p或q时, 将标志变量one_node_found设置为True. 同时根据栈中的节点跟踪 LCA (栈中的所有元素都是当前节点的祖先); 当再次找到p或q时, 说明我们已经将两个节点都找到了, 此时返回 LCA node. 无论何时访问parent_node的子节点, 都需要将(parent_node, updated_parent_state)更新到栈中. A node finally gets popped off from the stack when the state becomes BOTH_DONE implying both left and right subtrees have been pushed onto the stack and processed. If one_node_found is True then we need to check if the top node being popped could be one of the ancestors of the found node. In that case we need to reduce LCA_index by one. Since one of the ancestors was popped off Whenever both p and q are found, LCA_index would be pointing to an index in the stack which would contain all the common ancestors between p and q. And the LCA_index element has the lowest ancestor common between p and q. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123; enum class State &#123; BOTH_PENDING = 2, // 代表左右子节点均未访问 LEFT_DONE = 1, // 代表已经访问了一个节点 BOTH_DONE = 0 // 代表两个子节点都已经访问, 当前节点可以出栈 &#125;;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; std::stack&lt;std::pair&lt;TreeNode*, State&gt; &gt; s; s.push(std::make_pair(root, State::BOTH_PENDING)); bool one_node_found = false; // 标记是否找到p或q TreeNode* LCA = nullptr; // 跟踪LCA TreeNode* child_node = nullptr; while (!s.empty()) &#123; auto top = s.top(); TreeNode* parent_node = top.first; State parent_state = top.second; if (parent_state != State::BOTH_DONE) &#123; if (parent_state == State::BOTH_PENDING) &#123; if (parent_node == p || parent_node == q) &#123; // 找到了 p 或 q 中的一个, 如果是第二次找到, 则可以返回LCA // 如果是第一次找到, 则更新 LCA. if (one_node_found) &#123; return LCA; &#125; else &#123; one_node_found = true; LCA = parent_node; &#125; &#125; // 当状态为 BOTH_PENDING, 说明左右子树都没遍历, 应先遍历左子树 child_node = parent_node-&gt;left; &#125; else &#123; // 如果状态为 LEFT_DONE, 说明已经遍历完左子树, 该遍历右子树 child_node = parent_node-&gt;right; &#125; s.pop(); parent_state = static_cast&lt;State&gt;(static_cast&lt;int&gt;(parent_state) - 1); s.push(std::make_pair(parent_node, parent_state)); if (child_node != nullptr) &#123; s.push(std::make_pair(child_node, State::BOTH_PENDING)); &#125; &#125; else &#123; // state 为 BOTH_DONE, 说明当前节点可以出栈 // 如果当前节点为LCA, 则需要更新LCA auto node = s.top().first; s.pop(); if (LCA == node &amp;&amp; one_node_found) &#123; LCA = s.top().first; &#125; &#125; &#125; return nullptr; &#125;&#125;; 238. Product of Array Except SelfDescription: 计算数组内其他元素之积(不能使用除法)Given an array nums of n integers where n &gt; 1, return an array output such that output[i] is equal to the product of all the elements of nums except nums[i]. Example:12Input: [1,2,3,4]Output: [24,12,8,6] Note: Please solve it without division and in O(n). Follow up:Could you solve it with constant space complexity? (The output array does not count as extra space for the purpose of space complexity analysis.) 解法一: 借助辅助数组时间复杂度: $O(n)$, 遍历两次数组空间复杂度: $O(n)$, 额外申请 $n$ size 的数组(不计算 res 的空间占用) 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; productExceptSelf(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; from_begin(n); vector&lt;int&gt; from_end(n); from_begin[0] = 1; from_end[n-1] = 1; for(int i = 1; i&lt;n; i++)&#123; from_begin[i] = from_begin[i-1] * nums[i-1]; // from_begin[i] 为 nums[i] 之前的所有元素的乘积 from_end[ n-i-1] = from_end[n-i] * nums[n-i]; // from_end[i] 为 nums[i] 之后所有元素的乘积 &#125; for(int i=0 ;i&lt;n ; i++)&#123; from_end[i] = from_begin[i] * from_end[i]; // 用 nums[i] 之前的所有元素的乘积和 nums[i] 之后所有元素的乘积相乘 &#125; return from_end; &#125;&#125;; 解法二: 用一个变量代替数组时间复杂度: $O(n)$, 两次遍历空间复杂度: $O(1)$, 用变量代替数组 对解法一进行改写, 具体的做法是用一个变量来维护 from_begin 数组中的值(当然也可以选择代替 from_end) 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; productExceptSelf(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); // vector&lt;int&gt; from_begin(n); vector&lt;int&gt; from_end(n); // from_begin[0] = 1; from_end[n-1] = 1; for(int i = 1; i&lt;n; i++)&#123; // from_begin[i] = from_begin[i-1] * nums[i-1]; // from_begin[i] 为 nums[i] 之前的所有元素的乘积 from_end[ n-i-1] = from_end[n-i] * nums[n-i]; // from_end[i] 为 nums[i] 之后所有元素的乘积 &#125; int from_begin = 1; // 用一个变量代替 from_begin 数组的作用 for(int i=0 ;i&lt;n ; i++)&#123; from_end[i] = from_begin * from_end[i]; // 用 nums[i] 之前的所有元素的乘积和 nums[i] 之后所有元素的乘积相乘, 作为结果 from_begin = from_begin * nums[i]; // 维护 from_begin的值 &#125; return from_end; &#125;&#125;; 解法三: 用两个变量代替数组时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$, 不计算结果数组的空间 观察到解法二的做法, 虽然将空间复杂度压缩到 $O(1)$, 但是仍然使用了两次for循环, 实际上, 我们可以同时用变量from_begin和变量from_end替换掉对应的数组, 并且同一个for循环中更新这两个变量, 如下所示.12345678910111213141516class Solution &#123;public: vector&lt;int&gt; productExceptSelf(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int from_begin = 1; int from_end = 1; vector&lt;int&gt; res(n,1); for(int i=0; i&lt;n; i++)&#123; // 同时从前后分别计算, from_begin记录i之前的元素之和, from_end记录i之后的元素之和 res[i] = from_begin * res[i]; from_begin = from_begin * nums[i]; res[n-i-1] = from_end * res[n-i-1]; from_end = from_end * nums[n-i-1]; &#125; return res; &#125;&#125;; 240. Search a 2D Matrix IIDescription: 矩阵搜索Write an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties: Integers in each row are sorted in ascending from left to right.Integers in each column are sorted in ascending from top to bottom. Example:123456789Consider the following matrix:[ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30]] Given target = 5, return true. Given target = 20, return false. 解法一: 从左下角开始时间复杂度: $O(n+m)$, 最多走 $n+m$ 步, $n$ 和 $m$ 分别为矩阵的宽和高空间复杂度: $O(1)$ 123456789101112131415class Solution &#123;public: bool searchMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int target) &#123; if(matrix.size()==0 || matrix[0].size()==0) return false; int i=matrix.size()-1; int j=0; // 从左下角开始搜索 while(i&gt;=0 &amp;&amp; j&lt;matrix[0].size())&#123; if(matrix[i][j] &lt; target) j++; else if(matrix[i][j] &gt; target) i--; else return true; &#125; return false; &#125;&#125;; 279. Perfect SquaresDescription: 找到最少的平方和个数Given a positive integer n, find the least number of perfect square numbers (for example, 1, 4, 9, 16, …) which sum to n. Example 1:123Input: n = 12Output: 3Explanation: 12 = 4 + 4 + 4. Example 2:123Input: n = 13Output: 2Explanation: 13 = 4 + 9. 解法一: 四平方和定理(最优)时间复杂度: $O(\sqrt n)$, 最坏情况为 $O(\sqrt n)$, 最好情况为 $O(1)$.空间复杂度: $O(1)$, 无需额外空间 四平方和定理: 任何一个正整数, 都可以表示成四个整数的平方和(如果不算 0 的话, 就是可以用小于等于 4 个整数的平方和来表示任意一个整数). 对于题目, 要求我们返回组合平方和的数字的 最少 个数(不算0), 因此, 这里还可以使用到两个特别的性质来加速计算: 如果 $n$ 可以被 4 整除, 那么 $n$ 和 $n/4$ 的最少平方和数字个数相同. 如果 $n \% 8=7$, 那么 $n$ 的最少平方和个数一定为 4. 因此, 本题的解法流程如下: 循环整除 4, 降低 $n$ 的大小; 判断是否有 $n \% 8 =7$, 如果有, 则直接返回 4; 查看 $n$ 是否能够拆分成两个数(其中一个可以为0), 如果可以, 则返回 !!i + !!j, 即返回正整数的个数. 此处需要注意, i 需要从 0 开始遍历, 因为对于 $3^2+4^2 = 0^2 + 5^2 = 25$ 来说, 我们希望返回的是后者(即返回最少的平方和个数); 如果上面都不行, 则只可能反正 3(因为 $n&gt;0$). 1234567891011121314class Solution &#123;public: int numSquares(int n) &#123; while(n%4 == 0) n = n/4; if(n%8 == 7) return 4; for(int i=0; i*i&lt;=n; i++)&#123; // i必须从0开始, 否则会找到其他组合, eg: 3^2 + 4^2 = 0^2 + 5^2 int j = sqrt(n - i * i); if(i*i + j*j == n) return !!i+!!j; // 返回1(只有一个正整数)或2(两个都是正整数) &#125; return 3; //既不是4, 也不是1,2, 返回3(因为n&gt;0, 所以不可能返回0) &#125;&#125;; 解法二: DP时间复杂度: $O(n\sqrt n)$, 外层循环约为 $n$ 次, 内层循环约为 $\sqrt n$ 次.空间复杂度: $O(n)$, 需要额外申请 $n+1$ 大小的 DP 数组. 对于解法一来说, 虽然它的时间和空间复杂度最优, 但是其中使用到了很多不常用的定理和性质, 如果不知道这些定理和性质, 很难想到解法一的实现. 因此, 我们更容易想到的是使用动态规划来解决这道题, 具体解题步骤如下: 申请 $n+1$ 大小的 DP 数组, 并令 dp[0]=0, 令其他元素为 INT_MAX, dp[i] 的值代表组成数字 $i$ 所需的最少的平方和数字个数; 由于我们已经求得 dp[0] 的值, 因此, 对于 j=1, 2, ... 来说, 我们可以顺势求得 dp[0+j*j] = dp[0]+1=1. 对于已经求得的 dp[i], 我们可以求得 dp[i+j*j] = min(dp[i+j*j], dp[i]+1), 这里的 min 是为了保证组成数字的平方和个数最少. 最终, 返回 dp.back() 即为组成 $n$ 的最少的平方和个数. 12345678910111213class Solution &#123;public: int numSquares(int n) &#123; vector&lt;int&gt; dp(n+1, INT_MAX); dp[0]=0; // 赋初值 for(int i=0; i&lt;n+1; i++)&#123; for(int j=1; i+j*j &lt; n+1; j++)&#123; dp[i+j*j] = std::min(dp[i+j*j], dp[i]+1); &#125; &#125; return dp.back(); &#125;&#125;; 解法三: DP时间复杂度: $O(n\sqrt n)$, 外层循环约为 $n$ 次, 内层循环约为 $\sqrt n$ 次.空间复杂度: $O(n)$, 需要额外申请 $n+1$ 大小的 DP 数组. 复杂度和解法二没有区别, 但是我们可以从另一个角度来实现 DP 算法, 具体流程如下: 申请只含有一个元素的 DP 数组 dp[0]=0; 根据 dp[0] 的值计算 dp[1].(计算方法和解法二类似, 具体请看代码) 根据 dp[0]~dp[i-1] 的值计算 dp[i]. 当 i==n 时, 返回 dp[i]. 123456789101112131415class Solution &#123;public: int numSquares(int n) &#123; vector&lt;int&gt; dp(1,0); while(dp.size()&lt;=n)&#123; int m = dp.size(); int val = INT_MAX; for(int j=1; j*j &lt;= m; j++)&#123; //这里必须 &lt;= m, 否则会缺少 dp[0]+1 的情况. val = std::min(val, dp[m - j*j] + 1); &#125; dp.push_back(val); &#125; return dp.back(); &#125;&#125;; 解法四: 递归http://www.cnblogs.com/grandyang/p/4800552.html 12345678910111213// Recrusionclass Solution &#123;public: int numSquares(int n) &#123; int res = n, num = 2; while (num * num &lt;= n) &#123; int a = n / (num * num), b = n % (num * num); res = min(res, a + numSquares(b)); ++num; &#125; return res; &#125;&#125;; 287. Find the Duplicate NumberDescription: 寻找重复元素Given an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), prove that at least one duplicate number must exist. Assume that there is only one duplicate number, find the duplicate one. Example 1:12Input: [1,3,4,2,2]Output: 2 Example 2:12Input: [3,1,3,4,2]Output: 3 Note: You must not modify the array (assume the array is read only). You must use only constant, O(1) extra space. Your runtime complexity should be less than O(n2). There is only one duplicate number in the array, but it could be repeated more than once. 解法一: 哈希表时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 哈希表额外空间 这道题用哈希表很容易解, 但是这是最简单的解法之一(更简单的还有暴力法), 因此这里贴出来只用做参考. 1234567891011class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; unordered_set&lt;int&gt; nums_set; for(auto num : nums)&#123; if(nums_set.find(num) != nums_set.end()) return num; nums_set.insert(num); &#125; &#125;&#125;; 另一种解法是不建立哈希表, 而是利用数组的元素值和元素下标建立对应关系, 即将所有的数字放置在数字对应的下标位置上, 这样, 最终重复的元素就会出现的下标为 0 的位置上, 当然, 期间如果已经发现重复, 则可以直接返回, 代码如下: 123456789101112131415class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size() - 1; for (int i = 1; i &lt; n + 1; i++) &#123; if (nums[0] != nums[nums[0]]) &#123; std::swap(nums[0], nums[nums[0]]); &#125; else &#123; return nums[0]; &#125; &#125; return nums[0]; &#125;&#125;; 解法二: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 或者 $O(n)$ 先对数组排序, 然后遍历查找重复元素, 但是这种解法会改变原有数组中的元素分布, 题目要是数组是只读的, 因此该解法也只作为参考贴出 123456789class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; std::sort(nums.begin(), nums.end()); for(int i=0; i&lt;nums.size(); i++)&#123; if(nums[i] == nums[i+1]) return nums[i]; // 一定存在重复元素, 因此 i+1 不会越界 &#125; &#125;&#125;; 解法三: Floyd 的乌龟和兔子(Floy 判圈算法)Floyd’s Tortoise and Hare, 该算法是用来判断链表中是否含有环的. 对于此题, 我们换一个角度来解读, 数组中总共有 $n+1$ 个数, 这些数都是 $[1,n]$ 中的正整数, 因此, 至少会存在一个重复的数, 根据题目的假设, 有且仅有一个重复的数字, 那么, 我们假设该数字为 $k$, 于是, 我们可以将该数组表示成下面的形式(表中的 $x$ 代表该元素的值不为 $k$ ): 下标 $0$ $1$ $2$ … $k$ … $n$ 元素 $x$ $k$ … $k$ $x$ … $x$ 如果我们将上面的 (下标, 元素) 看做是链表结构中的 (val, next), 那么可以看出, 当某一个节点(上面假设为节点 1)的 next 指向 k 以后, k 又会重新指向另一个元素, 但是, 经过一定步数以后, 一定 又会重新指向 k (因为元素存在重复), 这在链表中称之为 “环”, 因此, 这道题就变成了求链表中环的开始节点, 该题正好是剑指offer第55题和 LeetCode第142题 这道题有一个很关键的条件就是, 元素的值是在1~n之间, 因此, 下标 0 位置上的元素值一定不为 0, 只有这样, 我们才可以将下标 0 选做起点, 如果选取其他的下标坐标起点, 那么有可能在第一步就死循环了. 12345678910111213141516171819202122232425262728class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; int slow = 0; // int fast = 0; // 实际上 fast 和 slow 可以指向环前的任意节点, 不影响最终结果. do&#123; // 因为一定存在环, 所以fast不会越界 slow = nums[slow]; fast = nums[fast]; fast = nums[fast]; &#125;while(slow!=fast); int len=1; // 求环长度 fast = nums[fast]; while(slow!=fast)&#123; fast = nums[fast]; len ++; &#125; slow = 0; fast = 0; while(len--)&#123; fast = nums[fast]; // 先让fast走环长的距离 &#125; while(slow!=fast)&#123; // 再次相遇时即为环的开始节点 slow = nums[slow]; fast = nums[fast]; &#125; return slow; &#125;&#125;; 更简洁的写法:上面在求环的开始节点时, 是先求环长, 再让 fast 走环长距离, 然后 slow 和 fast 同步前进, 最终相遇点即为开始点, 这么写比较容易理解, 但难免有些繁琐. 实际上, 我们只需要令 slow 从头开始, 即 slow=0, 接着令 fast 和 slow 同步前进, 那么相遇点就是开始节点. 原因是因为, 二者是从同一点出发的, fast 的步长较快, 当二者相遇时, 他们一定是在环中的某一点相遇, 这个时候再把slow重新放回起点, 那么fast领先slow的距离就等于: 环外的距离 + 若干圈 + 当前圈内已经走的距离. 而此时 fast 距离环入口还有一段距离, 因为第一次相遇点的位置, 因此, 我们如果此时从起点出发, 最终正好可以弥补这一部分距离, 因此, 最终会在环入口相遇. 一句话总结: 令fast和slow一起开始, fast步长是slow步长的二者, 找到二者相遇的点, 然后令slow重新回到起点, 此时步长一致, 再次相遇时即为环的入口点 12345678910111213141516171819class Solution &#123;public: int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; int slow = 0; // head; int fast = 0; // head-&gt;next; 指向head也没错, 因为, 最终仍会slow=fast do&#123; // 因为一定存在环, 所以fast不会越界 slow = nums[slow]; fast = nums[fast]; fast = nums[fast]; &#125;while(slow!=fast); slow = 0; while(slow != fast)&#123; slow = nums[slow]; fast = nums[fast]; &#125; return slow; &#125;&#125;; 289. Game of LifeDescription: 游戏人生According to the Wikipedia’s article: “The Game of Life, also known simply as Life, is a cellular automaton devised by the British mathematician John Horton Conway in 1970.” Given a board with m by n cells, each cell has an initial state live (1) or dead (0). Each cell interacts with its eight neighbors (horizontal, vertical, diagonal) using the following four rules (taken from the above Wikipedia article): Any live cell with fewer than two live neighbors dies, as if caused by under-population. Any live cell with two or three live neighbors lives on to the next generation. Any live cell with more than three live neighbors dies, as if by over-population.. Any dead cell with exactly three live neighbors becomes a live cell, as if by reproduction. Write a function to compute the next state (after one update) of the board given its current state. The next state is created by applying the above rules simultaneously to every cell in the current state, where births and deaths occur simultaneously. Example:1234567891011121314Input:[ [0,1,0], [0,0,1], [1,1,1], [0,0,0]]Output:[ [0,0,0], [1,0,1], [0,1,1], [0,1,0]] Follow up: Could you solve it in-place? Remember that the board needs to be updated at the same time: You cannot update some cells first and then use their updated values to update other cells. In this question, we represent the board using a 2D array. In principle, the board is infinite, which would cause problems when the active area encroaches the border of the array. How would you address these problems? 解法一: 状态机时间复杂度: $O(mn)$, 遍历两次二维数组空间复杂度: $O(1)$, 无需额外空间 根据细胞的更新规则, 我们可以设计出下面的状态转移:0: 从 0 到 0;1: 从 1 到 1:2: 从 1 到 0;3: 从 0 到 1; 因此, 本解法需要遍历两边 board 矩阵, 第一遍先计算每个 cell 的状态, 第二遍根据状态赋予 cell 不同的值, 具体来说就是如果当前状态 board[i][j]%2==0, 那么就令 board[i][j]=0, 反之, 令 board[i][j]=1. 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: void gameOfLife(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123; if(board.size()==0 || board[0].size()==0) return; int n = board.size(); int m = board[0].size(); int direct[8][2]=&#123;&#123;-1,-1&#125;, &#123;-1, 0&#125;, &#123;-1, 1&#125;, &#123; 0,-1&#125;, &#123; 0, 1&#125;, &#123; 1,-1&#125;, &#123; 1, 0&#125;, &#123; 1, 1&#125;&#125;; for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;m; j++)&#123; int count_1 = 0; for(int k=0; k&lt;8; k++)&#123; int i_k = i+direct[k][0]; int j_k = j+direct[k][1]; if(i_k&gt;=0 &amp;&amp; i_k&lt;n &amp;&amp; j_k&gt;=0 &amp;&amp; j_k&lt;m &amp;&amp; (board[i_k][j_k]==1 || board[i_k][j_k]==2) ) count_1++; &#125; if( (count_1&lt;2 || count_1&gt;3) &amp;&amp; board[i][j]==1) board[i][j] = 2; // 2:1-&gt;0, 0:0-&gt;0 else if(count_1==3 &amp;&amp; board[i][j]==0) board[i][j] = 3; // 3:0-&gt;1 // 剩余情况维持不变 &#125; &#125; for(auto &amp;cells : board)&#123; // 如果要对board进行修改, 需要使用引用号 &amp; for(auto &amp;cell : cells) if(cell%2==1) cell=1; else cell=0; &#125; &#125;&#125;; Follow up 常数空间复杂度: 正如解法一 无边界限制: 修改边界空间条件, 使其变成 “循环” 二维矩阵. 300. Longest Increasing SubsequenceDescription: 求最长递增序列(可以不连续)的长度Given an unsorted array of integers, find the length of longest increasing subsequence. Example:123Input: [10,9,2,5,3,7,101,18]Output: 4Explanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4. Note: There may be more than one LIS combination, it is only necessary for you to return the length. Your algorithm should run in O(n2) complexity. Follow up:Could you improve it to O(n log n) time complexity? 解法一: 暴力时间复杂度: $O(2^n)$空间复杂度: $O(n^2)$ 对于任意一个数字, 只有两种情况, 即处于最长递增数组内, 或者不处于最长递增数组内, 需要同时将这两种情况考虑, 然后选择最长的情况. 该方法时间超限. 解法二: Recursion with memorization [Memory Limit Exceeded]解法三: DP分析题目可以得出, 第 $i$ 个下标对应的数字是否存在于递增序列中, 与该下标之后的元素是无关的, 因此, 很自然的想到利用 DP 的方法来解决这道题. 我们令 dp[i] 代表 包含第 $i$ 个下标对应元素的递增序列的长度. 在求取 dp[i+1] 时, 我们需要遍历前面 dp[0~i] 个数组元素才能决定 dp[i+1] 的值, 因此, 时间复杂度为 $O(n^2)$, 空间复杂度为 $O(n)$. (比递归方法好很多). 12345678910111213141516171819class Solution &#123;public: int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; vector&lt;int&gt; dp(nums.size(), 1); int res_max=1; // 记录最长的递增序列长度, 因为最少有一个元素, 所以长度最少为1 for(int i=1; i&lt;nums.size(); i++)&#123; int max_val = 0; for(int j=0; j&lt;i; j++)&#123; if(nums[i] &gt; nums[j])&#123; // 只有当当前元素大于前面的元素时, 才能构成递增序列 max_val = std::max(max_val, dp[j]);//当前元素与nums[j]可以组成递增序列 &#125; &#125; dp[i] = max_val+1; // 将当前元素加入, 因此, 长度增1 res_max = std::max(res_max, dp[i]); //用当前长度更新最长长度的值 &#125; return res_max; &#125;&#125;; 解法四: DP+二分搜索(最优)时间复杂度: $O(nlogn)$, 每次搜索的复杂度为 $O(logn)$, 总共需要搜索 $n$ 次空间复杂度: $O(m)$, $m$ 为最长递增序列的长度. 同样还是 DP 解法, 但是我们重新赋予 dp[] 数组另一个含义, 我们令 dp[] 数组内储存的元素的数量刚好等于当前最长递增序列的数量, 注意, dp[] 数组内的值不一定是递增序列的值. 核心算过过程如下所示: 初始时, 令 dp[] 数组为空, 即 dp=[]; 对于每一个元素 num, 我们查找 num 在 dp 数组中的 upper_bound 迭代器(首个大于 num 的元素的迭代器), 假设取名为 upper;(注意, dp 数组是有序的, 所以这里的查询复杂度为 $O(logn)$) 查看 upper-1 指向的元素是否和 num 相等, 如果相等, 则说明该元素已经存在, 那么就跳过该元素, 重新回到步骤2; 如果 num 大于 dp 数组内的所有元素, 则将 num 添加进 dp 数组; 否则, 就将 dp 数组中大于 num 的第一个元素的值赋为 num. 重复步骤2,3,4, 直到遍历完数组为止. 为了更好的解释这种解法, 我们通过举例进行说明, 假定输入的数字序列为: [4,10,3,4,10,3,2], 那么我们的 dp[] 数组的变化情况如下: dp=[],初始时, 数组为空;dp=[4], 遍历元素4, 加入到数组中;dp=[4,10], 遍历元素10, 10大于所有元素, 将其添加到数组中;dp=[3,10], 遍历元素3, 发现第一个大于3的值为4, 将其赋值为3;dp=[3,4], 遍历元素4, 发现第一个大于4的的值为10, 将其赋值为4;dp=[3,4,10], 遍历元素10, 10大于所有元素, 将其添加到数组中;dp=[3,4,10], 遍历元素3, 3在数组中已经存在, 跳过该元素;dp=[2,4,10], 遍历元素2, 发现第一个大于2个值为3, 将其赋值为2. 综上, 我们可以看到, dp 数组的长度始终等于当前数组的最长子序列的长度, 故而, 直接返回 dp.size() 即为最终的结果. 注意, dp 内的值不一定为递增子序列的值. 1234567891011121314151617class Solution &#123;public: int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; vector&lt;int&gt; dp; for(auto num : nums)&#123; auto upper = std::upper_bound(dp.begin(), dp.end(), num); if(upper!=dp.begin() &amp;&amp; *(upper-1) == num) continue; // 如果num在dp数组中已经存在, 则跳过该num. if(upper==dp.end())&#123; dp.push_back(num); // 当前num比dp数组内的所有值都大, 则添加进dp数组 &#125;else&#123; *upper = num; // 用更小的值替代当前dp数组内的值 &#125; &#125; return dp.size(); // 最终, dp数组的长度即为最长递增序列的长度 &#125;&#125;; 322. Coin ChangeDescription: 硬币凑面额You are given coins of different denominations and a total amount of money amount. Write a function to compute the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return -1. Example 1:123Input: coins = [1, 2, 5], amount = 11Output: 3Explanation: 11 = 5 + 5 + 1 Example 2:12Input: coins = [2], amount = 3Output: -1 解法一: DP时间复杂度: $O(nm)$, $n$ 为总面额的大小, $m$ 为硬币的数量.空间复杂度: $O(n)$, DP 数组的大小为总面额的大小. 当我们求组成面额 $i$ 时所需的最少硬币数时, 我们可以用面额 $j$ 和面额 $i-j$ ($j\in[0,i]$)所需的硬币数之和来代替, 因此, 也就是说只与 $i$ 之前的面额数有关, 所以我们可以考虑使用 DP 算法来求解. 我们令 dp[i] 代表组成面额 $i$ 时所需的最少的硬币数, 要求 dp[i], 我们可以根据硬币的面额来求解, 假设硬币的面额是 $j$, 那么就有 dp[i] = min(dp[j] + dp[i-j]), 其中 dp[j]=1, 因为组成这种面额只需要一个硬币就可以了, 我们根据此公式就可以写出相应的 DP 代码, 如下所示. 12345678910111213141516class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; // 因为不可能为负值, 所以使用无符号整数, 防止溢出 // 额外多了一个0面额, 初值也可以设置为 amount+1, 因为最多的硬币数就是amount个1元. vector&lt;unsigned int&gt; dp(amount+1, amount+1); dp[0] = 0; // 为面额0赋初值 for(int i=1; i&lt;amount+1; i++)&#123; for(int ci=0; ci&lt;coins.size(); ci++)&#123; int j = coins[ci]; if(i &gt;= j) dp[i] = std::min(dp[i], 1+dp[i-j]); // 注意不能少了if语句, 否则会运行时错误 &#125; &#125; return dp[amount] &gt; amount ? -1 : dp[amount]; &#125;&#125;; 你可能会觉得我们进行了一些无用计算, 例如如果 $i$ 为 11, 而 coins 为 [1,5], 那么我们是否只需要计算 dp[6] 就可以了呢? 实际上, 如果有面额为 1 的硬币存在, 那么我们就必须计算所有的小于 $i$ 的dp值, 因为这些都是解, 至于是否为最小数量, 则需要利用 min 来不断筛选. 解法二: DP 递归实现时间复杂度: $O(nm)$, $n$ 为总面额的大小, $m$ 为硬币的数量.空间复杂度: $O(n+n)=O(n)$, DP 数组的大小为总面额的大小, 另外, 递归还需额外占用一定空间. 123456789101112131415161718class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; vector&lt;int&gt; dp(amount+1, INT_MAX); dp[0] = 0; return coin_dfs(coins, amount, dp); &#125; int coin_dfs(vector&lt;int&gt; &amp;coins, int target, vector&lt;int&gt; &amp;dp)&#123; if(target &lt; 0) return -1; // invalid combination if(dp[target] != INT_MAX) return dp[target]; // already computed, return it for(int i=0; i&lt;coins.size(); i++)&#123; int tmp = coin_dfs(coins, target-coins[i], dp); if(tmp&gt;=0) dp[target] = min(dp[target], 1+tmp); &#125; dp[target] = (dp[target] == INT_MAX) ? -1 : dp[target]; return dp[target]; &#125;&#125;; 解法三: 对暴力解法剪枝时间复杂度: $O(logn+mlogm)$, 每次都用当前面额除以硬币面额, 故时间复杂度为 $O(logn)$, $O(mlogm)$ 为对硬币面额的排序复杂度, 当 $m&lt;&lt;n$ 时, 可忽略不计.空间复杂度: $O(logn)$, 无需申请额外空间, 仅仅是递归过程需要占用空间. 下面的方法利用余数对暴力解法进行剪枝, 剪枝后的程序运行速度十分快, 远远快于前两个算法. 123456789101112131415161718192021222324252627class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; int res = INT_MAX; // results count int n = coins.size(); int cur = 0; // current count std::sort(coins.begin(), coins.end()); // sort from small to large helper(coins, amount, n-1, cur, res); return res==INT_MAX ? -1 : res; &#125; void helper(vector&lt;int&gt; &amp;coins, int target, int start, int cur, int &amp;res)&#123; if(target%coins[start]==0)&#123; // 如果可以整除, 说明找到了合适的组合 res = min(res, cur+target/coins[start]); return; &#125; for(int i=target/coins[start]; i&gt;=0; i--)&#123; if(cur+i &gt;= res-1) // 如果当前的硬币数已经超过了 res-1, 说明之后肯定需要更多的硬币, // 因为后面的硬币面额变小了, 所以需要至少cur+i+1个硬币才能凑齐 // 因此, 无需再进行循环, 直接跳出即可 break; if(start&gt;0) // start不能为负值, 因此start要大于0才能继续递归 helper(coins, target-i*coins[start], start-1, cur+i, res); &#125; &#125;&#125;; 关于此算法的更详细解释(http://www.cnblogs.com/grandyang/p/5138186.html):难道这题一定要DP来做吗, 我们来看网友hello_world00提供的一种解法, 这其实是对暴力搜索的解法做了很好的优化, 不仅不会TLE, 而且击败率相当的高！对比Brute Force的方法, 这里在递归函数中做了很好的优化. 首先是判断start是否小于0, 因为我们需要从coin中取硬币, 不能越界. 下面就是优化的核心了, 看target是否能整除coins[start], 这是相当叼的一步, 比如假如我们的目标值是15, 如果我们当前取出了大小为5的硬币, 我们做除法, 可以立马知道只用大小为5的硬币就可以组成目标值target, 那么我们用cur + target/coins[start] 来更新结果res. 之后的for循环也相当叼, 不像暴力搜索中的那样从start位置开始往前遍历coins中的硬币, 而是遍历 target/coins[start] 的次数, 由于不能整除, 我们只需要对余数调用递归函数, 而且我们要把次数每次减1, 并且再次求余数. 举个例子, 比如coins=[1,2,3], amount=11, 那么 11除以3, 得3余2, 那么我们的i从3开始遍历, 这里有一步非常有用的剪枝操作, 没有这一步, 还是会TLE, 而加上了这一步, 直接击败百分之九十九以上, 可以说是天壤之别. 那就是判断若 cur + i &gt;= res - 1 成立, 直接break, 不调用递归. 这里解释一下, cur + i 自不必说, 是当前硬币个数cur 加上新加的i个硬币, 我们都是知道cur+i如果大于等于res的话, 那么res是不会被更新的, 那么为啥这里是大于等于res-1呢？因为能运行到这一步, 说明之前是无法整除的, 那么余数一定存在, 所以再次调用递归函数的target不为0, 那么如果整除的话, cur至少会加上1, 所以又跟res相等了, 还是不会使得res变得更小. 324. Wiggle Sort IIDescription: “驼峰” 排序Given an unsorted array nums, reorder it such that nums[0] &lt; nums[1] &gt; nums[2] &lt; nums[3]…. Example 1:12Input: nums = [1, 5, 1, 1, 6, 4]Output: One possible answer is [1, 4, 1, 5, 1, 6]. Example 2:12Input: nums = [1, 3, 2, 2, 3, 1]Output: One possible answer is [2, 3, 1, 3, 1, 2]. Note:You may assume all input has valid answer. Follow Up:Can you do it in O(n) time and/or in-place with O(1) extra space? 解法一: 排序时间复杂度: $O(nlogn + n)$, 排序的时间复杂度为 $O(nlogn)$, 构造 “驼峰” 数组的复杂度为 $O(n)$空间复杂度: $O(n)$, 额外数组需要占用 $O(n)$ 空间 该问题的解法可能有多个, 我们只需要找到其中一个即可, 核心思路是将一个数组分成两半, 其中前一半的元素都小于后一半的元素, 然后我们只需要依次从两个数组中取值组成新数组, 就可以满足 “驼峰” 排序.首先, 对数组中的元素排序, 这样, 任意的相邻元素, 都满足 nums[i] &lt;= nums[i+1], 我们将数组分成两半, 这样, 前半段的元素都小于等于后半段的元素, 注意, 题目中已经指明数组是合法的有效数组, 所以一定可以组成驼峰, 因此, 我们先取前半段的最后一个元素, 再取后半段的最后一个元素, 这两个元素一定满足绝对小于关系(否则无法形成 “驼峰”), 然后我们再取倒数第二个, 依次类推, 直至取完. 注意, 我们不能从前往后取, 因为不能保证前半段的第二个元素绝对小于后半段的第一个元素, 例如[4,5,5,6], 从前往后取就会变成[4,5,5,6], 不符合驼峰, 从后往前取为[5,6,4,5], 符合驼峰. 1234567891011121314class Solution &#123;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int low = 0, high = nums.size()-1; std::sort(nums.begin(), nums.end()); int mid = (nums.size()+1)/2; // 令mid指向中间的位置 vector&lt;int&gt; tmp; for(int i=mid-1, j=nums.size()-1; i&gt;=0 ; i--, j--)&#123; // 从后往前选择元素, 分别放到tmp中 tmp.push_back(nums[i]); if(j&gt;=mid) tmp.push_back(nums[j]); &#125; nums = tmp; &#125;&#125;; 解法二: partition时间复杂度: $O(n+n)= O(n)$, 查找中位数需要 $O(n)$, 填充数组需要 $O(n)$.空间复杂度: $O(n)$, 填充时使用了额外的数组空间来辅助. 如果当数组中的元素不含有重复时, 此题很容易就用基于 partition 的方法解决, 因为, 我们可以找到将数组分成两个具有绝对小于关系的数组, 然后依次用两个数组填充即可, 但是, 此题的元素是可重复的, 所以必须考虑重复元素的影响.首先我们利用 nth_element() 找到中位数, 虽然 nth_element() 的时间复杂度已经不是 $O(n)$, 但是这里我们为了简化代码, 仍然使用 nth_element() 来查找中位数 mid(后面也会更多稍复杂一点的 partition 算法, 面试时建议使用 nth_element, 注意要向面试官说明复杂度问题), 之后, 对于其他的任意一个数组元素, 都有三种不同的情况: 大于 mid, 将大于 mid 的元素放在数组开始的奇数位上面; 小于 mid, 将小于 mid 的元素放在数组的偶数位上面; 等于 mid, 用所有等于 mid 的元素填充剩下的位置. 由于题目指明输入的数组一定是有效的, 因此当我们进行了上面遍历后, 数组一定会变成 “驼峰” 数组, 因为当和 mid 相等的元素处于 “驼峰” 底部时, 它一定位于偶数位(奇数位都是大于 mid 的元素), 同理, 当 mid 处于 “驼峰” 顶部时, 它一定位于奇数位, 因为偶数位都被小于 mid 的元素填充. 故最终的数组是 “驼峰” 数组. nth_element()(该函数在 C++17 后不是 $O(n)$, 而是 $O(nlogn)$, 但是在 C++11 中仍然是 $O(n)$):12345678910111213141516171819202122class Solution &#123;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); std::nth_element(nums.begin(), nums.begin()+n/2, nums.end()); int mid = nums[n/2]; // 找到中位数 vector&lt;int&gt; res(n, mid); // 先将所有元素置为中位数 int even_i = (n-1)/2*2; // 令 even_i 指向数组的最后一个偶数位 int odd_i = 1; for(int i=0; i&lt;n; i++)&#123; if(nums[i] &gt; mid)&#123; // 将大于中位数的放到前面的奇数位上 res[odd_i] = nums[i]; odd_i += 2; &#125;else if(nums[i] &lt; mid)&#123; //将小于中位数的放到后面的偶数位上 res[even_i] = nums[i]; even_i -= 2; &#125; &#125; // 剩下的位置都是中位数 nums = res; &#125;&#125;; 自己利用partition实现 $O(n)$ 的中位数查找: 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;private: int partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P &lt;= nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P &gt;= nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int low = 0, high = n-1; int target = n/2; while(1)&#123; int m = partition(nums, low, high); if(m &lt; target) low = m + 1; else if(m &gt; target) high = m - 1; else break; &#125; int mid = nums[target]; // 找到中位数 vector&lt;int&gt; res(n, mid); // 先将所有元素置为中位数 int even_i = (n-1)/2*2; // 令 even_i 指向数组的最后一个偶数位 int odd_i = 1; // 指向第一个奇数位 for(int i=0; i&lt;n; i++)&#123; if(nums[i] &gt; mid)&#123; // 将大于中位数的放到前面的奇数位上 res[odd_i] = nums[i]; odd_i += 2; &#125;else if(nums[i] &lt; mid)&#123; //将小于中位数的放到后面的偶数位上 res[even_i] = nums[i]; even_i -= 2; &#125; &#125; // 剩下的位置都是中位数 nums = res; &#125;&#125;; Follow up: three-way partition时间复杂度: $O(n+n) = O(n)$, 找中位数时的复杂度为 $O(n)$, 调整数组的复杂度为 $O(n)$.空间复杂度: $O(1)$, 无需占用额外空间 解法二的时间复杂度满足要求, 问题在于我们如何能够在 $O(1)$ 的空间复杂度限制下, 完成数组的填充工作, 很自然的我们可以想到利用 swap 来实现, 具体流程如下所示: 先令 even_i 指向数组的最后一个偶数位(从0位开始, 0算作偶数位), 令 odd_i 指向第一个奇数位(下标为1). 我们从最后一个偶数位元素(用下标 i 指示)开始进行判断; 如果 nums[i]&lt;mid, 则将 nums[i] 与 nums[even_i] 交换, 交换后, even_i 不可再被访问, 令 even_i -= 2, 同时注意, 由于刚开始的时候 i 与 even_i 是相等的, 故也要令 i -= 2, 当 i&lt;0 以后, 要令 i 指向最后一个奇数位. 如果 nums[i]&gt;mid, 则将 nums[i] 与 nums[odd_i] 交换, 同时令 odd_i += 2, 注意, 此时, i 指向的数字是交换后的原来 odd_i 指向的数字, 因此, 我们需要对该数字进行判断, 故不能改变 i 的值. 如果和 mid 相等, 则无需进行交换填充, 令其保存原值即可, 判断下一个元素, 令 i -=2, 同时还要判断 i 是否小于 0, 若小于, 则需令 i 指向最后的奇数位. nth_element():12345678910111213141516171819202122232425262728class Solution &#123;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); std::nth_element(nums.begin(), nums.begin()+n/2, nums.end()); int mid = nums[n/2]; // 找到中位数 // O(1) 空间复杂度填充数组 int even_i = (n-1)/2*2; int odd_i = 1; int i = even_i; // 令i指向最后一个偶数位 int count = n; while(count--)&#123; //每次都会判断一个元素 if(nums[i] &lt; mid)&#123; std::swap(nums[i], nums[even_i]); even_i -= 2; i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125;else if(nums[i] &gt; mid)&#123; std::swap(nums[i], nums[odd_i]); odd_i += 2; // 奇数位增加 &#125;else&#123; // 保持原值不变, 判断下一个值 i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125; &#125; &#125;&#125;; partition: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123;private: int partition(vector&lt;int&gt; &amp;nums, int low, int high)&#123; int P = nums[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P &lt;= nums[high]) high--; nums[low] = nums[high]; while(low&lt;high &amp;&amp; P &gt;= nums[low]) low++; nums[high] = nums[low]; &#125; nums[low] = P; return low; &#125;public: void wiggleSort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int low = 0, high = n-1; int target = n/2; while(1)&#123; int m = partition(nums, low, high); if(m &lt; target) low = m + 1; else if(m &gt; target) high = m - 1; else break; &#125; int mid = nums[target]; // 找到中位数 // O(1) 空间复杂度填充数组 int even_i = (n-1)/2*2; int odd_i = 1; int i = even_i; // 令i指向最后一个偶数位 int count = n; while(count--)&#123; //每次都会判断一个元素 if(nums[i] &lt; mid)&#123; std::swap(nums[i], nums[even_i]); even_i -= 2; i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125;else if(nums[i] &gt; mid)&#123; std::swap(nums[i], nums[odd_i]); odd_i += 2; // 奇数位增加 &#125;else&#123; // 保持原值不变, 判断下一个值 i -= 2; if(i&lt;0) i = n/2*2 - 1; // 令 i 指向最后一个奇数位 &#125; &#125; &#125;&#125;; 328. Odd Even Linked ListDescription: 奇偶链表Given a singly linked list, group all odd nodes together followed by the even nodes. Please note here we are talking about the node number and not the value in the nodes. You should try to do it in place. The program should run in O(1) space complexity and O(nodes) time complexity. Example 1:12Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULLOutput: 1-&gt;3-&gt;5-&gt;2-&gt;4-&gt;NULL Example 2:12Input: 2-&gt;1-&gt;3-&gt;5-&gt;6-&gt;4-&gt;7-&gt;NULLOutput: 2-&gt;3-&gt;6-&gt;7-&gt;1-&gt;5-&gt;4-&gt;NULL Note:The relative order inside both the even and odd groups should remain as it was in the input.The first node is considered odd, the second node even and so on … 解法一: 一次遍历时间复杂度: $O(n)$, 遍历每个节点一次空间复杂度: $O(1)$, 未使用任何额外空间 我们利用两个变量分别来维护奇数链表和偶数链表, 最后令奇数链表的最后一个节点的 next 指针指向偶数链表的头结点, 代码如下: 123456789101112131415161718192021222324252627282930313233343536/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* oddEvenList(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return head; ListNode *odd_head = head; // 奇数链表头 ListNode *even_head = head-&gt;next; // 偶数链表头 ListNode *odd_node = odd_head; // 奇数链表节点 ListNode *even_node = even_head; // 偶数链表节点 ListNode *node = head-&gt;next-&gt;next; // 令当前节点指向第三个节点 int i = 3; // 记录节点编号(从1开始) while(node!=nullptr)&#123; if(i&amp;1 == 1)&#123; // 奇数链表 odd_node-&gt;next = node; odd_node = odd_node-&gt;next; node = node-&gt;next; &#125;else&#123; // 偶数链表 even_node-&gt;next = node; even_node = even_node-&gt;next; node = node-&gt;next; &#125; i++; &#125; odd_node-&gt;next = even_head; even_node-&gt;next = nullptr; // 少了这句话会超时, 原因是even_node会指向前面的某个节点, 形成环, 使得程序判断时无法终止 return odd_head; &#125;&#125;; 更简洁的写法:1234567891011121314public class Solution &#123; public ListNode oddEvenList(ListNode head) &#123; if (head == null) return null; ListNode odd = head, even = head.next, evenHead = even; while (even != null &amp;&amp; even.next != null) &#123; odd.next = even.next; odd = odd.next; even.next = odd.next; even = even.next; &#125; odd.next = evenHead; return head; &#125;&#125; 334. Increasing Triplet SubsequenceDescription: 递增的三元子序列Given an unsorted array return whether an increasing subsequence of length 3 exists or not in the array. Formally the function should: Return true if there exists i, j, ksuch that arr[i] &lt; arr[j] &lt; arr[k] given 0 ≤ i &lt; j &lt; k ≤ n-1 else return false.Note: Your algorithm should run in O(n) time complexity and O(1) space complexity. Example 1:12Input: [1,2,3,4,5]Output: true Example 2:12Input: [5,4,3,2,1]Output: false 解法一: 用辅助变量指向 min 和 mid时间复杂度: $O(n)$, 每个元素之遍历一次空间复杂度: $O(1)$, 无需额外空间 我们利用两个变量 min 和 mid 分别指向三元子序列中的最小元素和中间元素, 最开始时, 二者赋初值为 INT_MAX, 然后遍历数组, 对于数组中的每一个数 num, 进行如下判断: 是否小于等于 min, 若满足, 则令 min=num; 若不满足(1), 则说明 num &gt; min, 判断 num 是否小于等于 mid, 若满足, 责令 mid=num;(此时 mid 一定大于 min, 且下标也大于 min 下标) 若不满足(1)(2), 则说明 num 不仅大于 min, 而且大于 mid, 同时 num 的下标也大于前两者, 由此, 我们找到了一个满足条件的递增三元组子序列, 可直接返回 true. 否则, 重复以上步骤直至遍历完数组 如果遍历完整个数组后, 仍然找不到符合条件的序列, 则说明不存在这样的序列, 返回 false. 12345678910111213141516class Solution &#123;public: bool increasingTriplet(vector&lt;int&gt;&amp; nums) &#123; if(nums.size() &lt; 3) return false; int min=INT_MAX, mid=INT_MAX; for(auto num : nums)&#123; if(num &lt;= min) // 等于号不能少, 否则会跳到最后的else中, 直接返回true min = num; else if(num &lt;= mid) // 如输入为 11111111 时, 若没有等于号, 则会跳到else中返回true mid = num; else return true; //当前数字比min和mid都大, 所以找到了一个三元组 &#125; return false; &#125;&#125;; 341. Flatten Nested List IteratorDescription: 将嵌套的多维列表展开成一维Given a nested list of integers, implement an iterator to flatten it. Each element is either an integer, or a list — whose elements may also be integers or other lists. Example 1:123Input: [[1,1],2,[1,1]]Output: [1,1,2,1,1]Explanation: By calling next repeatedly until hasNext returns false, the order of elements returned by next should be: [1,1,2,1,1]. Example 2:123Input: [1,[4,[6]]]Output: [1,4,6]Explanation: By calling next repeatedly until hasNext returns false, the order of elements returned by next should be: [1,4,6]. 解法一: 栈PS: 这道题可以在初始化时将列表全部展开并存储, 这样 hasNext() 就可以达到 $O(1)$ 的时间复杂度, 但是, 这是很不好的! 因为实际实现迭代器时, 我们往往只在需要的时候才会对元素进行展开, 这样可以获得最大的平均效率 时间复杂度: $O(n)$, 每个节点至多遍历一次, 其中, next() 复杂度为 $O(1)$, 初始化和 hasNext() 的复杂度均为 $O(n)$空间复杂度: $O(n)$, 栈所需空间 先将数组中的所有元素从后往前的放进栈中, 这样栈顶元素即为数组中的第一个元素, 然后对栈顶元素进行判断, 如果 isInteger() 为真, 则直接返回 true, 否则, 就获取栈顶对应的 vector&lt;NestedInteger&gt; 数组, 并将栈顶 pop(), 然后将数组从后往前再放到栈中, 重复以上操作直至栈为空, 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * // This is the interface that allows for creating nested lists. * // You should not implement it, or speculate about its implementation * class NestedInteger &#123; * public: * // Return true if this NestedInteger holds a single integer, rather than a nested list. * bool isInteger() const; * * // Return the single integer that this NestedInteger holds, if it holds a single integer * // The result is undefined if this NestedInteger holds a nested list * int getInteger() const; * * // Return the nested list that this NestedInteger holds, if it holds a nested list * // The result is undefined if this NestedInteger holds a single integer * const vector&lt;NestedInteger&gt; &amp;getList() const; * &#125;; */class NestedIterator &#123;private: stack&lt;NestedInteger&gt; s;public: NestedIterator(vector&lt;NestedInteger&gt; &amp;nestedList) &#123; for(int i=nestedList.size()-1; i&gt;=0; i--)&#123; s.push(nestedList[i]); &#125; &#125; int next() &#123; auto res = s.top(); s.pop(); return res.getInteger(); &#125; bool hasNext() &#123; while(!s.empty())&#123; NestedInteger top = s.top(); if(top.isInteger()) return true; else&#123; s.pop(); vector&lt;NestedInteger&gt; list = top.getList(); for(int i=list.size()-1; i&gt;=0; i--)&#123; s.push(list[i]); &#125; &#125; &#125; return false; &#125;&#125;;/** * Your NestedIterator object will be instantiated and called as such: * NestedIterator i(nestedList); * while (i.hasNext()) cout &lt;&lt; i.next(); */ 解法二: deque时间复杂度: $O(n)$, 每个节点至多遍历一次, 其中, next() 复杂度为 $O(1)$, 初始化和 hasNext() 的复杂度均为 $O(n)$空间复杂度: $O(n)$, 双端队列所需空间 同样的思路, 也可以用双端队列解决.(栈有的功能双端队列也有) 347. Top K Frequent ElementsDescription: 寻找频率最高的 k 个数字Given a non-empty array of integers, return the k most frequent elements. Example 1:12Input: nums = [1,1,1,2,2,3], k = 2Output: [1,2] Example 2:12Input: nums = [1], k = 1Output: [1] Note:You may assume k is always valid, 1 ≤ k ≤ number of unique elements.Your algorithm’s time complexity must be better than O(n log n), where n is the array’s size. 解法一: 哈希+大顶堆时间复杂度: $O(n+nlogn)=O(nlogn)$, 遍历复杂度为 $O(n)$, 堆排序复杂度为 $O(nlogn)$空间复杂度: $O(n+n) = O(n)$, unordered_map 和 priority_queue 各占 $O(n)$ 大小的空间 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; hash; priority_queue&lt;pair&lt;int, int&gt;&gt; q; vector&lt;int&gt; res; for(auto num : nums) hash[num]++; //对于不存在的关键字, 其值默认为0 for(auto it:hash) q.push(&#123;it.second, it.first&#125;); // 注意, sceond在前作为排序依据 for(int i=0 ; i&lt;k; i++)&#123; res.push_back(q.top().second); q.pop(); // 注意, 因为插入的时候将first插在了第二位, 因此, 获取时应该用second获取数字 &#125; return res; &#125;&#125;; 解法二: 哈希+小顶堆时间复杂度: $O(n+nlogk)=O(nlogk)$, 遍历复杂度为 $O(n)$, 堆排序时, 用小顶堆, 只保存最大的 k 个元素即可.空间复杂度: $O(n+n) = O(n)$, unordered_map 和 priority_queue 各占 $O(n)$ 大小的空间 整体思路和解法一相同, 只不过我们需要得到最大的 $k$ 个元素即可, 因此无需维护 $n$ 大小的大顶堆. 相反, 我们选择维护 $k$ 大小的小顶堆, 对于任意一个新来的元素, 如果它大于堆顶, 则将堆顶退出, 然后将新来元素加入堆中. 因为小顶堆的堆顶是最小的元素, 因此堆中用于 $k-1$ 个比堆顶大的元素, 故这 $k$ 个元素就是最大的 $k$ 个元素, 最终我们只需要将堆中数据依次取出, 然后执行一次 reverse() 即可. 12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; hash; // 注意这里小顶堆的定义, 其元素是 pair 类型 priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int,int&gt;&gt;, std::greater&lt;pair&lt;int,int&gt;&gt;&gt; q; // 小顶堆 vector&lt;int&gt; res; for(auto num : nums) hash[num]++; //对于不存在的关键字, 其值默认为0 for(auto it : hash)&#123; // 注意, 必须是遍历哈希表, 而不能遍历原数组, 因为原数组存在重复数字 if(q.size() &lt; k) q.push(&#123;it.second, it.first&#125;); else if(q.top().first &lt; it.second)&#123; q.pop(); q.push(&#123;it.second, it.first&#125;); &#125; &#125; for(int i=0 ; i&lt;k; i++)&#123; res.push_back(q.top().second); q.pop(); &#125; std::reverse(res.begin(), res.end()); //因为结果是从小顶堆中得到的, 所以需要逆置一下, 也可以不逆置 return res; &#125;&#125;; 解法三: 哈希+桶时间复杂度: $O(n+n+k)=O(n)$, 构建哈希表, 构建桶, 从桶找到 $k$ 个最大数字的复杂度分别为: $O(n)$, $O(n)$, 和 $O(k)$.空间复杂度: $O(n+n) = O(n)$, 哈希表和桶各占 $O(n)$ 当我们拥有关于元素频率的哈希表以后, 我们可以利用此表构建桶结构, 桶的 “关键字” 为元素频率, 之后, 我们可以用 $O(n)$ 的复杂度对桶进行遍历, 当找到 $k$ 个最大元素时, 跳出遍历循环, 代码如下: 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; hash; // 哈希 for(auto &amp;num : nums) hash[num]++; vector&lt;vector&lt;int&gt;&gt; buckets(nums.size()+1); // 根据数组的大小申请桶的空间, 多申请一个是为了方便下标对齐 for(auto h : hash) buckets[h.second].push_back(h.first); // 用频率来做桶的索引, 并且对应数字放入桶中 vector&lt;int&gt; res; for(int i=buckets.size()-1; i&gt;=0; i--)&#123; // 最后往前遍历, 寻找频率最高的k个元素 vector&lt;int&gt; bucket = buckets[i]; for(auto &amp; num : bucket)&#123; res.push_back(num); if(res.size() &gt;= k) return res; // 找到k个元素, 直接返回并退出 &#125; &#125; &#125;&#125;; 378. Kth Smallest Element in a Sorted MatrixDescription: 找到半有序数组中的第 k 小的元素Given a n x n matrix where each of the rows and columns are sorted in ascending order, find the kth smallest element in the matrix. Note that it is the kth smallest element in the sorted order, not the kth distinct element. Example:12345678matrix = [ [ 1, 5, 9], [10, 11, 13], [12, 13, 15]],k = 8,return 13. Note:You may assume k is always valid, 1 ≤ k ≤ n2. 解法一: 堆基于堆的 baseline 解法:最简单的堆解法就是不使用矩阵的有序性质, 直接当成无序数组来做, 我们申请一个 $k$ 大小的大顶堆, 然后遍历矩阵中的所有元素, 如果某元素小于堆顶就将堆顶弹出, 并压入该元素, 最终, 大顶堆的堆顶就是整个矩阵中第 $k$ 小的元素. 该解法的时间复杂度为 $O(nmlogk)$, 空间复杂度为 $O(k)$, 由于没有使用到有序矩阵的性质, 故不做讨论. 更优的基于堆的解法(超屌的解法!): 时间复杂度: $O(klogn)$, $k$ 代表 kth, $n$ 代表矩阵的行数空间复杂度: $O(n)$, 堆的大小, $n$ 代表矩阵的行数 我们需要利用矩阵行列分别有序的性质, 首先, 具体思路如下: 利用将矩阵中每一行的首元素(也就是第一列元素, 同理, 这里也可以用第一行元素)构造一个最小堆(这一步的复杂度小于 $O(nlogn)$), 堆中的元素是一个 pair, 其中 first 为元素的值, second 又是一个 pair, 存储着值的行列坐标 (i, j) 将最小堆中的一个元素弹出(弹出的是当前堆最小的元素), 然后再将弹出元素的同一行的下一个元素(通过元素坐标获取)压入堆, 压入后, 堆会自动排序, 使得最小的元素位于堆顶. 重复步骤(2) k-1 次以后. 我们已经弹出了整个矩阵的最小的 k-1 个元素, 那么现在堆顶中的元素就是第 k 小的元素, 将其返回即可 1234567891011121314151617181920212223242526272829class Solution &#123;public: struct cmp&#123; bool operator()(pair&lt;int, pair&lt;int,int&gt;&gt; &amp;a, pair&lt;int, pair&lt;int,int&gt;&gt; &amp;b)&#123; return a.first &gt; b.first; // 小顶堆 &#125; &#125;; int kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m=matrix[0].size(); priority_queue&lt; pair&lt;int, pair&lt;int, int&gt;&gt;, vector&lt;pair&lt;int, pair&lt;int, int&gt;&gt;&gt;, cmp&gt; min_heap; for(int i=0; i&lt;n; i++)&#123; // 用矩阵每一行的首元素构建堆, 堆的元素组成为&lt;(val, (i,j))&gt; min_heap.push(make_pair(matrix[i][0], make_pair(i, 0))); &#125; int res; while(k--)&#123; int val = min_heap.top().first; int i = min_heap.top().second.first; int j = min_heap.top().second.second; min_heap.pop(); // 弹出堆 res = val; if(j+1&lt;m) // 将同行的下一个元素放入堆 min_heap.push(make_pair(matrix[i][j+1], make_pair(i, j+1))); &#125; return res; &#125;&#125;; 解法二: 二分查找时间复杂度: $O(nlogm\times logD$, $n$ 为矩阵的行数, $m$ 为矩阵的列数, $D$ 为矩阵中最大元素与最小元素之间的差值.空间复杂度: $O(1)$, 没有利用额外空间 算法利用了每一行中, 元素都是有序的这个性质(但是没有用到列有序的性质), 步骤如下: 获取矩阵中元素的最小值 low 和最大值 high 令 mid = (high+low)/2, 然后我们利用 upper_bound() 函数来查找矩阵中第一个大于 mid 的元素(耗时 $O(logn)$), 接着计算这个元素之前的元素数量. 对矩阵的每一行重复这个步骤, 并将所有的元素数量累加起来 如果累加元素数 count &lt; k, 说明, mid 的值较小, 我们令 low=mid+1, 否则, 说明 count&gt;=k, 我们令 high=mid, 注意, 这里的赋值关系最好不要改动, 并且要知道为什么令 high=mid, 而不是 mid-1. 重复上述过程直至 low=high, 此时, low 或 high 的值就是矩阵中第 k 小的值 123456789101112131415161718192021222324252627class Solution &#123;public: int kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m = matrix[0].size(); int low = matrix[0][0]; int high = matrix[n-1][m-1]; //题目中是方阵, 这里故意写成nm的矩阵, 以适应更普通的情况 while(low &lt; high)&#123; int mid = (low+high) / 2; int count = 0; for(int i=0; i&lt;n; i++)&#123; // 找到第一个大于 mid 的数, 然后计算这之前的元素个数 int row_count = std::upper_bound(matrix[i].begin(), matrix[i].end(), mid) - matrix[i].begin(); count += row_count; &#125; if(count &lt; k)&#123; // 注意, 这里不能令小于号来包括等于号时的情况, 因为 (low+high)/2 是偏向左边的, 这样会造成死循环 low = mid + 1; &#125;else&#123; // 当 count&gt;=k 时, 说明 mid之前就能满足 k 个元素, 故令 high=mid; 注意, 这里不要尝试令low=mid high = mid; &#125; // 这里的二分查找不同于普通的数组, 因为 mid 有可能不是数组中的值, 所以即使count=k时, 也不能直接返回mid &#125; return low; // 最终, 当 low=high时, 即为第k小的元素. 因为当, high指向第k小的元素时, 它就不可能再减小, 而只能是low一点点靠近high, 直至相等 &#125;&#125;; 解法三: 二分查找时间复杂度: $O((n+m)logD)$, $n$ 为矩阵行数, $m$ 为矩阵列数, $D$ 为矩阵中元素的最大差值空间复杂度: $O(1)$ 解法二中并没有完全使用到矩阵所有的性质, 考虑到矩阵在列上也是有序的, 我们可以进一步优化算法. 我们应该还记得在剑指offer的第一题中, 考察了这种行列有序数组的元素查找算法, 我们可以在 $O(n+m)$ 的时间里找到指定的元素, 因此, 我们可以利用该算法替换解法二中对每一行执行二分查找的算法, 故而时间复杂度就变成了 $O((n+m)logD)$, 其中, $n$ 为矩阵行数, $m$ 为矩阵列数, $D$ 为矩阵中元素的最大差值, 代码如下. 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; if(matrix.size()==0 || matrix[0].size()==0) return 0; int n = matrix.size(), m = matrix[0].size(); int low = matrix[0][0], high = matrix[n-1][m-1]; while(low &lt; high)&#123; int mid = (low+high) / 2; int count = search(matrix, mid); // 查找小于等于mid的元素数量 if(count &lt; k) low = mid + 1; else high = mid; &#125; return low; &#125; int search(vector&lt;vector&lt;int&gt;&gt; &amp;matrix, int target)&#123; int n = matrix.size(), m = matrix[0].size(); int i = n-1, j=0; // 从左下角开始 int count=0; // 记录小于等于 target 的元素数量 while(i&gt;=0 &amp;&amp; j&lt;m)&#123; if(matrix[i][j] &lt;= target)&#123; j++; count += i+1; &#125;else&#123; i--; &#125; &#125; return count; &#125;&#125;; 380. Insert Delete GetRandom O(1)Description: 常数时间复杂度的插入,删除,和随机获取Design a data structure that supports all following operations in average O(1) time. insert(val): Inserts an item val to the set if not already present. remove(val): Removes an item val from the set if present. getRandom: Returns a random element from current set of elements. Each element must have the same probability of being returned. Example:1234567891011121314151617181920212223// Init an empty set.RandomizedSet randomSet = new RandomizedSet();// Inserts 1 to the set. Returns true as 1 was inserted successfully.randomSet.insert(1);// Returns false as 2 does not exist in the set.randomSet.remove(2);// Inserts 2 to the set, returns true. Set now contains [1,2].randomSet.insert(2);// getRandom should return either 1 or 2 randomly.randomSet.getRandom();// Removes 1 from the set, returns true. Set now contains [2].randomSet.remove(1);// 2 was already in the set, so return false.randomSet.insert(2);// Since 2 is the only number in the set, getRandom always return 2.randomSet.getRandom(); 解法一: 哈希表+数组时间复杂度: $O(1)$, 符合题意空间复杂度: $O(n)$, 数组和哈希表的大小各为 $O(n)$. 解题思路: 插入: 用数组的 push_back() 存储新来的元素, 同时存入哈希表, key 为元素值, val 为元素在数组中的下标; 删除: 先用哈希表获取元素的下标, 然后将数组中的该元素和数组的最后一个元素交换, 接着用 pop_back() 删除该元素, 然后用 erase() 从哈希表中删除该元素, 最后在哈希表中更新被交换元素的下标; 获取随机元素: 利用 C++ 的内置随机函数 rand() 来获取随机数. 但是注意, rand() 对生成的随机数质量无法保证, 在 C++11 中, 已经建议使用随机数生成设施来替换 rand(). 另外注意: 如果想要使用 srand() 来播种, 那么不能将该语句放在 getRandom() 函数中, 因为重复播种会使得每次生成的随机数都一样, 正确的做法是将其放在构造函数中, 只进行一次播种. 123456789101112131415161718192021222324252627282930313233343536373839404142434445class RandomizedSet &#123;private: vector&lt;int&gt; vec; unordered_map&lt;int, int&gt; hash;public: /** Initialize your data structure here. */ RandomizedSet() &#123; srand(time(0)); &#125; /** Inserts a value to the set. Returns true if the set did not already contain the specified element. */ bool insert(int val) &#123; if(hash.find(val) != hash.end()) return false; vec.push_back(val); hash[val] = vec.size()-1; return true; &#125; /** Removes a value from the set. Returns true if the set contained the specified element. */ bool remove(int val) &#123; if(hash.find(val) == hash.end()) return false; int i = hash[val]; int j = vec.size() - 1; swap(vec[i], vec[j]); vec.pop_back(); // 将元素和最后一位元素交换, 然后在删除, 满足 O(1) 复杂度 hash[vec[i]] = i; hash.erase(val); // 在哈希表中删除指定键值 return true; &#125; /** Get a random element from the set. */ int getRandom() &#123; // srand(time(0)); // 不能放在这里, 要放只能放在构造函数中 return vec[rand()%vec.size()]; // rand 无法保证生成的随机数质量, C++11推荐用随机数生成设施来替换该函数 &#125;&#125;;/** * Your RandomizedSet object will be instantiated and called as such: * RandomizedSet obj = new RandomizedSet(); * bool param_1 = obj.insert(val); * bool param_2 = obj.remove(val); * int param_3 = obj.getRandom(); */ 384. Shuffle an ArrayDescription: 打乱数组Shuffle a set of numbers without duplicates. Example:123456789101112// Init an array with set 1, 2, and 3.int[] nums = &#123;1,2,3&#125;;Solution solution = new Solution(nums);// Shuffle the array [1,2,3] and return its result. Any permutation of [1,2,3] must equally likely to be returned.solution.shuffle();// Resets the array back to its original configuration [1,2,3].solution.reset();// Returns the random shuffling of array [1,2,3].solution.shuffle(); 解法一: 随机交换时间复杂度: $O(n)$, 打乱需要 $O(n)$, reset 为 $O(1)$空间复杂度: $O(n)$ shuffle: 打乱时, 遍历数组的下标, 然后随机生成一个下标, 令二者指向的元素交换. 更多分析请看Knuth shuffle算法 reset: 直接返回缓存的原始数组 123456789101112131415161718192021222324252627282930class Solution &#123;private: vector&lt;int&gt; v;public: Solution(vector&lt;int&gt; nums): v(nums)&#123; std::srand(std::time(0)); &#125; /** Resets the array to its original configuration and return it. */ vector&lt;int&gt; reset() &#123; return v; &#125; /** Returns a random shuffling of the array. */ vector&lt;int&gt; shuffle() &#123; vector&lt;int&gt; sv(v); for(int i=0; i&lt;sv.size(); i++)&#123; int j = i + rand() % (sv.size()-i); //这里生成的 j 只可能在 i 之后 swap(sv[i], sv[j]); &#125; return sv; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(nums); * vector&lt;int&gt; param_1 = obj.reset(); * vector&lt;int&gt; param_2 = obj.shuffle();**/ 395. Longest Substring with At Least K Repeating CharactersDescriptionFind the length of the longest substring T of a given string (consists of lowercase letters only) such that every character in T appears no less than k times. Example 1:1234567Input:s = &quot;aaabb&quot;, k = 3Output:3The longest substring is &quot;aaa&quot;, as &apos;a&apos; is repeated 3 times. Example 2:1234567Input:s = &quot;ababbc&quot;, k = 2Output:5The longest substring is &quot;ababb&quot;, as &apos;a&apos; is repeated 2 times and &apos;b&apos; is repeated 3 times. 解法一: 哈希表+位标志时间复杂度: 平均情况下为 $O(n)$, 最坏情况(待查找子串不存在)下为 $O(n^2)$空间复杂度: $O(26 + 1)$, 26 为哈希表的大小, 1 为 mask 的大小. 对于字母集, 可以利用哈希表来实现 $O(n)$ 复杂度的字符数量统计, 我们设置一个变量 mask, 该变量每一个比特位上的值有两种含义: 当某比特位为 1 时, 代表该比特位对应的字母在当前字符子串中的数量小于 k, 反之, 则该比特位为 0. 那么, 只要当 mask=0, 就说明此时的子串符合题目的要求, 我们计算当前子串的长度, 并更新最长长度值, 由于子串必须是连续的, 所以下一个子串的开始字符一定不会在当前子串的结束字符之前, 因为如果这样的话, 就一定会在当前子串的结束字符处终止, 故判断下一个子串时, 我们可以从当前子串结束字符的下一位开始判断. 代码如下: 123456789101112131415161718192021222324252627282930class Solution &#123;public: int longestSubstring(string s, int k) &#123; int n = s.size(); int res = 0; for(int i=0; i+k &lt;= n; )&#123; // i 代表其实字符的位置 int max_end = i; // 注意要把这三行放在第一个for循环内部, 每次都要初始化一次 unsigned int mask = 0; int hash[26] = &#123;0&#125;; for(int j=i; j&lt;n; j++)&#123; // j 代表终止字符的位置, 从 i 开始 int t = s[j] - 'a'; hash[t]++; if(hash[t] &lt; k) mask |= (1&lt;&lt;t); // set t bit to 1 else mask &amp;= (~(1&lt;&lt;t)); //这里外边的括号可以省, 但是位操作最好显式加括号 if(mask == 0)&#123; // 如果mask=0, 说明所有的字符要么没有出现, 要么数量&gt;=k. int length = j-i+1; res = std::max(res, length); max_end = j; &#125; &#125; i = max_end + 1; // 下一个最长的子串的开始一定不会在 i 与 max_end 之间, // 因为如果在这之间, 那么就一定会在 max_end 处终止 &#125; return res; &#125;&#125;; 解法二: 分而治之, 递归时间复杂度: $O(n)$, 最坏情况下为 $O(n)$, 因为递归调用的深度最多为 26, 而每一层的复杂度约为 $O(n)$. (这种说法是网上的说法, 但是这里我个人觉得最坏情况是 $O(n^2), 只不过有的递归调用很快退出, 是的程序运行时间很短)空间复杂度: $O(26+log_{26}n)$, 哈希表空间为, 递归占用空间为 $O(log_{26}n)$. 对于任意的字符串, 我们都执行下面的算法步骤: 根据当前的字符串, 构建相应的哈希表, 表内数据为没一个字符的出现次数, 所以哈希表的大小为 26(或 256); 如果哈希表内所有字符的出现次数都满足条件(出现 0 次出现 k 次以上), 那么当前字符串满足条件, 可直接输出长度 如果字符串中存在不满足条件的字符, 那么就以这些字符 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; int helper(string &amp;s, int l, int r, int k)&#123; int hash[256]=&#123;0&#125;; for(int i=l; i&lt;=r; i++)&#123; // 构建 l,r 范围内的字符数哈希表 hash[s[i]]++; &#125; bool flag = true; for(int i=l; i&lt;=r; i++)&#123; // 如果当前 l, r范围内的字符满足要求, 则直接返回 if(hash[s[i]] &amp;&amp; hash[s[i]] &lt; k)&#123; flag = false; break; &#125; &#125; if(flag) return (r-l+1); int res=0; int i = l; for(int j=l; j&lt;=r; j++)&#123; //以所有不满足条件的字符为分界线, 递归获取前半段和后半段的最长子串长度 if(hash[s[j]] &amp;&amp; hash[s[j]] &lt; k)&#123; res = std::max(res, helper(s, i, j-1, k)); i = j+1; // 这里虽然对于多个相同的不满足条件的字符会进行多次调用 // 但是由于传入的子串很短, 所以会很快接结束调用, 故可忽略不计此次调用 &#125; &#125; return std::max(res, helper(s, i, r, k));// i, r 为最后一段 &#125;public: int longestSubstring(string s, int k) &#123; int l = 0, r = s.size()-1; return helper(s, l, r, k); &#125;&#125;; 解法三: 更简洁的递归时间复杂度: $O(n)$, 最差情况下为 $O(kn)$, 详细见下面的分析空间复杂度: $O(n)$, 哈希+递归 真正的 $O(n)$ 复杂度的实现: 和上面的思路一致, 也是利用不满足条件的字符作为分隔(因为只有符合条件的字符组成的字符串从 有可能 具有正确的长度), 但是不同于上面程序的是, 此次我们只对满足条件的子串进行递归, 故而那些重复的不满足条件的字符不会被重复用于递归(上面的代码就是重复调用了, 因为是在发现 &lt;k 时就进行调用), 下面的代码更加精炼易懂, 我们首先会跳过所有不满足条件的字符, 然后从满足条件的字符开始, 找到连续的满足条件的子串的最后一个字符, 然后对这个子串进行递归调用, 也就是说, 我们最多会进行不超过 k 次递归调用, 因为最坏的情况是 26 个字符中, 只有一个字符不满足条件, 而这个字符最多将字符串分割成 k 段, 如果分割成 k+1 段, 那么就必须用 k 个字符, 此时与假设矛盾. 123456789101112131415161718192021222324252627class Solution &#123; int helper(string &amp;s, int l, int r, int k)&#123; int hash[26] = &#123;0&#125;; for(int i=l; i&lt;=r; i++) hash[s[i]-'a']++; // 构建哈希 int res=0; for(int i=l; i&lt;=r; )&#123; while(i&lt;=r &amp;&amp; hash[s[i]-'a']&lt;k) i++; // 跳过不符合的字符, 注意也要跳过未出现的字符, 所以=0也要跳过 if(i&gt;r) break; // 如果所有字符都不符合, 则直接break int j = i; while(j&lt;=r &amp;&amp; hash[s[j]-'a']&gt;=k) j++; // 找到当前子串中符合条件的最后一个连续字符 j--; // 此时 j 指向的是符合条件字符的下一个位置, 因此, 我们要令 j-- //if(j&gt;r) j=r; // j如果超限, 说明所有字符都符合, 则令 j 指向尾部字符即可 if(i==l &amp;&amp; j==r) return r-l+1; // 当前范围所有字符满足条件, 直接返回长度 res = std::max(res, helper(s, i, j, k)); // 对符合条件的子串进行调用, 最多会进行不超过 k 次调用 i = j+1; // 开始下一个子串的查询 &#125; return res; &#125;public: int longestSubstring(string s, int k) &#123; int l = 0, r = s.size()-1; return helper(s, l, r, k); &#125;&#125;; 上面的边界控制比较麻烦, 下面我们用超尾的方式来进行边界控制, 会使程序更加简洁, 如下所示: 1234567891011121314151617181920212223242526class Solution &#123; int helper(string &amp;s, int begin, int end, int k)&#123; int hash[26] = &#123;0&#125;; for(int i=begin; i&lt;end; i++) hash[s[i]-'a']++; // 构建哈希 int res=0; for(int i=begin; i&lt;end; )&#123; while(i&lt;end &amp;&amp; hash[s[i]-'a']&lt;k) i++; // 跳过不符合的字符, 注意也要跳过未出现的字符, 所以=0也要跳过 if(i==end) break; // 如果所有字符都不符合, 则直接break int j = i; while(j&lt;end &amp;&amp; hash[s[j]-'a']&gt;=k) j++; // 找到当前子串中符合条件的最后一个连续字符 //当使用超尾时, 无需对j特殊处理 if(i==begin &amp;&amp; j==end) return end-begin; // 当前范围所有字符满足条件, 直接返回长度 res = std::max(res, helper(s, i, j, k)); // 对符合条件的子串进行调用, 最多会进行不超过 k 次调用 i = j+1; // 开始下一个子串的查询 &#125; return res; &#125;public: int longestSubstring(string s, int k) &#123; int begin = 0, end = s.size(); return helper(s, begin, end, k); &#125;&#125;; 454. 4Sum IIDescription: 4 数之和为零的可能组合数Given four lists A, B, C, D of integer values, compute how many tuples (i, j, k, l) there are such that A[i] + B[j] + C[k] + D[l] is zero. To make problem a bit easier, all A, B, C, D have same length of N where 0 ≤ N ≤ 500. All integers are in the range of -228 to 228 - 1 and the result is guaranteed to be at most 231 - 1. Example:12345678910111213Input:A = [ 1, 2]B = [-2,-1]C = [-1, 2]D = [ 0, 2]Output:2Explanation:The two tuples are:1. (0, 0, 0, 1) -&gt; A[0] + B[0] + C[0] + D[1] = 1 + (-2) + (-1) + 2 = 02. (1, 1, 0, 0) -&gt; A[1] + B[1] + C[0] + D[0] = 2 + (-1) + (-1) + 0 = 0 解法一: 先求两两之和时间复杂度: $O(n^2+n^2)=O(n^2)$, 前者为 A, B 两两和的复杂度, 后者为 C, D 两两和的复杂度.空间复杂度: $O(n^2)$, 哈希表占用的空间 先求 A 与 B 的两两之和, 并将和作为键存于哈希表中, 哈希表中的值为和的出现次数, 然后再求 C, D 的两两之和, 同时查询哈希表中是否存在 C, D 和的负数, 若存在, 则说明可以组成零. 代码如下: 12345678910111213141516171819class Solution &#123;public: int fourSumCount(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B, vector&lt;int&gt;&amp; C, vector&lt;int&gt;&amp; D) &#123; unordered_map &lt;int, int&gt; hash; for(auto a : A)&#123; for(auto b : B)&#123; hash[a+b]++; &#125; &#125; int res = 0; for(auto c : C)&#123; for(auto d : D)&#123; int target = -(c+d); res += hash[target]; &#125; &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人简历总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本篇文章因为某些原因被暂时加密, 如果希望继续浏览请输入正确的密码 Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++ 基础问题汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-Cpp%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[C++ 在 C 的基础上加了什么 包含全部的 C 语言部分 面向对象编程思想, 封装, 继承, 多态 泛型编程, 模板 STL 库 define 宏定义define 是 C 语言的宏定义, 在编译时会直接进行替换. 注意, 替换不会额外添加其他字符. 12345678#define SUM(x) 3*x*x+1int main()&#123; int i = 3, j = 6; std::cout &lt;&lt; SUM(i+j) &lt;&lt; std::endl; // 输出: 3*i+j*i+j+1 = 3*3+6*3+6+1 = 34 std::cout &lt;&lt; SUM((i+j)) &lt;&lt; std::endl; // 输出: 3 * (i+j) * (i+j)+1 = 3 * (3+6) * (3+6)+1 = 3*9*9+1 = 244&#125; C++ 的编译和链接过程C++ 编译和链接 结构体和联合体有什么区别 结构体和联合体都是由多个不同的数据类型成员组成, 但在任何同一时刻, 联合体中只存放了一个被选中的成员(所有成员共用一块地址空间), 而结构体的所有成员都存在(不同成员的存放地址不同) 对于联合体的不同成员赋值, 将会对覆盖其他成员, 原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的 封装, 继承, 多态, 重载, 重写/覆盖概念解析 封装: 是指将数据和相关的函数放在一起作为一个整体, 一般称之为”类”, 封装的意义在于保护或者放置数据被无意间破坏. 继承: 通常是指类的继承, 主要目的是为了重用代码, 节省开发时间. 多态: 是指”一个接口, 多种形态”, 在 C++ 中的多态主要是通过虚函数实现的. 重载: 是指同名函数具有不同的函数签名(参数个数及参数类型), 程序调用函数时, 会根据不同的函数签名决定调用哪个函数 重写/覆盖: 是指子类重写父类的方法(需要有virtual关键字), 声明完成一致, 实现不同. 隐藏: 派生类实现了一个与基类中同名的函数, 则基类中的同名函数会被隐藏(无论参数列表是否相同) 多态性是指相同对象收到不同消息或不同对象收到相同消息时产生不同的行为. C++ 支持两种多态性, 分别是编译时多态性和运行时多态性: 编译时多态性: 通过重载, 模板等实现. 运行时多态: 通过虚函数的继承实现. 通过声明基类的指针或者引用, 利用该指针或引用指向任意一个子类对象, 调用相应的虚函数, 可以根据指向子类的不同而实现不同的方法. 简单介绍一下 C++ 的继承机制要注意区分访问权限机制与继承方式机制的区别, 访问机制如下:public: 可以从类内部, 类外部和派生类中直接访问protected: 可以从类内部和派生类中进行访问private: 只能在类的内部进行访问, 注意派生类也不能访问基类的私有成员 继承方式的不同会影响派生类中成员的新的访问权限, 具体影响如下: 公有继承: 基类中的访问权限维持不变. 无法访问父类的私有成员. 保护继承: 会将父类中的公有成员的访问权限变成私有, 其余维持不变. 无法访问父类的私有成员. 私有继承: 会将父类中的公有和保护成员的访问权限变成私有, 无法访问父类的私有成员. 虚拟继承: 虚拟继承时多重继承中特有的概念, 虚拟基类是为了解决多重继承而出现的, 如类 D 继承自类 B 和 类 C, 而类 B 和类 C 都继承自类 A, 此时类 D 中会继承两次 A. 为了节省空间, 可以将 B, C 对 A 的继承定义为虚拟继承, 而 A 成了虚拟基类, 此时只需要继承一次. friend 可以突破 private 访问权限的限制 C++ 标准规定, 如果派生类中声明的成员与基类的成员同名, 那么, 基类的成员就会被覆盖, 哪怕基类的成员与派生类的成员的数据类型和参数个数完全不同. 基类类的私有成员也会被继承, 但是无法访问, 要想访问, 必须通过父类提供的公有接口 子类不能从父类继承的函数不能继承的有: (如果不显式定义下面的函数, 编译器会生成默认形式的函数) 构造函数: 虽然不会继承, 但是在派生类调用构造函数前, 会先调用基类的构造函数 析构函数: 先调用派生类的析构函数, 再调用基类的构造函数 拷贝构造函数 赋值操作符=重载函数: 除了赋值运算符重载函数以外, 其他的运算符重载函数都可以被派生类继承. 重载, 隐藏和重写/覆盖的区别从定义上来说: 重载: 是指允许存在多个 同名 函数, 但是这些函数的 参数签名不同 (参数个数, 参数类型, const) 隐藏: 是指派生类的函数屏蔽了与其同名的基类函数, 注意 只要是同名函数, 不管参数列表是否相同, 基类函数都会被隐藏 重写: 是在继承时体现的, 是指子类重新定义父类虚函数的方法, 其中父类函数必须有virtual关键字, 且不能有static, 子类函数与父类函数签名相同, 且返回值也要相同(或者 返回值协变 ), 访问权限修饰符可以不同. 从实现原理上来说: 重载: 编译器会根据函数不同的函数签名, 对这些同名函数的名称做一些修饰, 然后这些同名函数就成了不同的函数(至少对编译器来说是这样的), 这些修饰后的同名函数的调用, 在编译期间就已经确定了, 因此它们的地址也已经确定了, 因此, 重载与多态无关 隐藏: 由于屏蔽了基类的函数, 因此在调用时会调用派生类的函数 重写: 重写与多态息息相关. 当子类重新定义了父类的虚函数以后, 父类指针会根据赋给它的不同的子类指针, 动态 的调用属于子类的该函数, 这样的函数调用在编译期间是无法确定的(无法给出子类的虚函数的地址). 只有在执行阶段, 子类的函数地址才能够确定. 嵌套类对嵌套类访问权的控制规则与对常规类相同. 在 Queue 类声明中声明 Node 类并没有赋予 Queue 类任何对 Node 类的访问特征, 也没有赋予 Node 类任何对 Queue 类的访问特权. 访问权限 可被访问的范围: public: 类中函数, 子类函数, 友元函数, 类的对象 protected: 类中函数, 子类函数, 友元函数 private: 类中函数, 友元函数 继承方式的属性变化: public: 不发生变化 protected: public 变为 protected private: public 和 protected 变为 private 范围解析运算符 全局作用域符(::name): 用于名称(类, 类成员, 成员函数, 变量等)前, 表示作用域为全局命名空间 类作用域符(class::name): 用于表示指定类型的作用域范围是具体某个类的 命名空间作用域符(namespace::name): 用于表示指定类型的作用域范围是具体某个命名空间的 1234567int count = 10; //全局(::)的countint main()&#123; int count = 20; //局部的count std::cout&lt;&lt;::count; // 输出 10, std为命名空间 std::cout&lt;&lt;count; // 输出 20&#125; 避免文件被多次编译 pragma once: 编程器相关, 有的编译器支持, 有的编译器不支持(大部分都支持). ifndef/define/endif: C/C++ 语言的宏定义, 在所有编译器上都是有效的. float 与 0 比较时需要注意什么需要注意精度表示的问题, 不能使用f == 0 而应使用f&lt;0.00001 &amp;&amp; f&gt;0.00001类似的语句. 什么情况下会发生运行时错误 Runtime Error数组越界访问, 除数为0 , 堆栈溢出 数组和指向数组名的指针有什么区别数组的内存空间要么在静态存储区中(全局数组), 要么在栈中. 而指针可以随时指向任意类型的内存块.在使用sizeof运算符时, 数组返回的是整个数组所占的字节数, 指针返回的是指针变量本身的字节数. C++/C 语言没有办法知道指针所指的内存容量, 除非在申请内存时记住它, 注意当数组作为函数的参数进行传递时, 该数组名就会自动退化为同类型的指针, 也就是说此时再使用sizeof时, 返回的是指针变量的大小, 而不是数组大小 初始化列表(initialization list)C++11 新特性-初始化列表 哪些情况下只能用初始化列表(initialization list) 而不能用赋值 (assignment) 初始化列表中的初始化顺序是怎样的? C++是不是类型安全的?不是, 因为两个不同类型的指针之间可以强制转换. 函数参数的入栈顺序从右往左, 原因是为了支持可变长参数.通过堆栈分析可知, 自左向右的入栈方式, 最前面的参数被压在栈底, 除非知道参数个数, 否则是无法通过栈指针的相对位移求得最左边的参数的, 这样就变成了左边参数个数的不确定, 这个动态参数个数的方向相反, 因此, C/C++ 中函数参数采用自右向左的入栈顺序, 主要原因是为了支持可变长的参数形式.]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode算法题(Easy)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-1%2F</url>
    <content type="text"><![CDATA[001. Two SumDescription: 求出能组合出目标数的两个元素Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 解法一: 穷举时间复杂度: $O(n^2)$空间复杂度: $O(1)$ 12345678910111213class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; for(int i = 0; i&lt;nums.size(); i++)&#123; for(int j = i+1; j&lt;nums.size(); j++)&#123; if(nums[i] + nums[j] == target)&#123; vector&lt;int&gt; res =&#123;i,j&#125;; return res; &#125; &#125; &#125; &#125;&#125;; 解法二 : 哈希表, 两次遍历注意, 题目中说数组的解恰好只有一个, 这是一种很强的假设, 解法二在面对有多个解时, 也只会输出一个这里要特别注意: 同一个元素不能使用两次, 但是数组中的元素是可以重复的, 重复的元素看作是两个元素. hash表中最终存储的将会是重复元素的最后一个下标, 因此, 在进行比较时, 使用 i!= nums_map[target-nums[i]] 来判断它们是否为同一个元素, 而不能使用nums_map[nums[i]] != nums_map[target-nums[i]] 时间复杂度: $O(n)$ 遍历两次空间复杂度: $O(n)$ 123456789101112131415class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; nums_map; for(int i = 0 ;i&lt;nums.size(); i++)&#123; nums_map.insert(&#123;nums[i], i&#125;); &#125; for(int i = 0 ; i&lt;nums.size(); i++)&#123; if(nums_map.count(target-nums[i]) == 1 &amp;&amp; i!= nums_map[target-nums[i]])&#123; vector&lt;int&gt; res = &#123;i, nums_map[target-nums[i]]&#125;; //这里一定要用i,而不能用nums_map[nums[i]] , 上面也同理 return res; &#125; &#125; &#125;&#125;; 解法三: 哈希表 一次遍历事实上, 可以将hash表的插入和查找对应元素的操作放在 一个循环里, 这样就只需要进行一次遍历 时间复杂度: $O(n)$ 遍历一次空间复杂度: $O(n)$ 12345678910111213class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; nums_map; for(int i = 0 ;i&lt;nums.size(); i++)&#123; if(nums_map.count(target-nums[i]) == 1 &amp;&amp; i!= nums_map[target-nums[i]])&#123; vector&lt;int&gt; res = &#123;i, nums_map[target-nums[i]]&#125;; return res; &#125; nums_map.insert(&#123;nums[i], i&#125;); &#125; &#125;&#125;; 扩展问题How would you approach the problem if the input array is very large (but limited range) and cannot fit in the memory ? This is a follow-up question for this problem. 007. Reverse IntegerDescription: 将数字逆置Given a 32-bit signed integer, reverse digits of an integer. Example 1:12Input: 123Output: 321 Example 2:12Input: -123Output: -321 Example 3:12Input: 120Output: 21 解法一: 取余数这道题本身不难, 只要不断对x的绝对值取余数, 就可以得到反转的整数, 但是, 该题的核心考察点在于边界条件的判断, 稍不注意, 很容易漏解(如果不进行边界判断, 即使写出了解决方法, 面试官也很不满意) x为0 x反转后的值,超过了int型数据的表示范围, 检查方法是先用long存储, 然后看情况决定返回值正负. 1234567891011121314151617class Solution &#123;public: int reverse(int x) &#123; if(x==0) return x; int abs_x = abs(x); int sign_x = x&gt;0? 1:-1; long res = 0; // 为了看int是否越界,特意将res声明为long型 while( abs_x!=0 )&#123; res = res*10 + abs_x%10; if(res &gt; INT_MAX || res &lt; INT_MIN) return 0; //这一句就是最主要的考察点,看int是否越界 abs_x = abs_x/10 ; &#125; if(sign_x ==-1) return 0-res; return res; &#125;&#125;; 013. Roman to IntegerDescriptionRoman numerals are represented by seven different symbols: I, V, X, L, C, D and M. Symbol ValueI 1V 5X 10L 50C 100D 500M 1000For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9.X can be placed before L (50) and C (100) to make 40 and 90.C can be placed before D (500) and M (1000) to make 400 and 900.Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999. Example 1: Input: “III”Output: 3Example 2: Input: “IV”Output: 4Example 3: Input: “IX”Output: 9Example 4: Input: “LVIII”Output: 58Explanation: L = 50, V= 5, III = 3.Example 5: Input: “MCMXCIV”Output: 1994Explanation: M = 1000, CM = 900, XC = 90 and IV = 4. 解法一: 顺序扫描时间复杂度: $O(n)$ 顺序扫描, 如果当前字符比下一个字符小, 说明是 ‘4’ 或 ‘9’ 的情况, 用下一个字符的值减去当前字符的值 12345678910111213141516171819202122232425class Solution &#123;public: int romanToInt(string s) &#123; unordered_map&lt;char, int&gt; roman_char; roman_char['I'] = 1; roman_char['V'] = 5; roman_char['X'] = 10; roman_char['L'] = 50; roman_char['C'] = 100; roman_char['D'] = 500; roman_char['M'] = 1000; int res = 0; for(int i =0; i&lt;s.size() ; i++)&#123; if( i&lt;s.size()-1 &amp;&amp; roman_char[s[i]] &lt; roman_char[s[i+1]])&#123; res += roman_char[s[i+1]]-roman_char[s[i]]; i++; &#125; else res += roman_char[s[i]]; &#125; return res; &#125;&#125;; 扩展问题: 异常检测上面的解法虽然可以通过OJ, 但是此题还需要进行特别的异常诊断, 即要能够判断出当前输入的罗马输出是否合法! 如 “IVIV” 就是典型的不合法输入, 对于此输入, 上面的程序会输出 , 这显然不正确 014. Longest Common PrefixDescription: 最长公共前缀Write a function to find the longest common prefix string amongst an array of strings.If there is no common prefix, return an empty string “”. Example 1:12Input: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]Output: &quot;fl&quot; Example 2:123Input: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]Output: &quot;&quot;Explanation: There is no common prefix among the input strings. Note:All given inputs are in lowercase letters a-z. 解法一: 顺序比较时间复杂度: $O(S)$, $S$ 为所有字符串中的字符总数空间复杂度: $O(1)$, 没有使用额外的空间 暴力求解, 先求第一个字符串与第二个字符串最长公共前缀, 然后利用该前缀与第三个字符串比较, 知道公共前缀为空或者比较完所有字符串. 12345678910111213141516class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if(strs.size()==0 || strs[0].size()==0) return ""; string prefix = strs[0]; for(int i=0; i&lt;strs.size() &amp;&amp; !prefix.empty(); i++)&#123; int j=0; while(j&lt;prefix.size()&amp;&amp;j&lt;strs[i].size() &amp;&amp;prefix[j] == strs[i][j])&#123; j++; &#125; prefix = prefix.substr(0, j); &#125; return prefix; &#125;&#125;; 解法二: 垂直比较时间复杂度: $O(S)$, $S$ 为所有字符串中的字符总数, 最好情况下复杂度为 $O(n\min(s)$, $\min(s)$ 为字符串数组中的最短字符串长度.空间复杂度: $O(1)$, 没有使用额外的空间 顺序比较所有字符串的值, 直到遇到第一次不相等的位置, 然后输出前面的公共前缀, 需要额外注意处理以下几种特殊情况:输入 输入为: [] 或 [“”] 应该直接返回”” 输入为: [“abc”] 应该直接返回”abc” 123456789101112131415161718class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if(strs.size() ==0 || strs[0]=="") return ""; if(strs.size() ==1 ) return strs[0]; for(int i =0 ;; i++)&#123; for(int k = 1; k&lt;strs.size(); k++)&#123; if(strs[0][i] != strs[k][i])&#123; if(i&gt;0) return strs[0].substr(0,i); else return ""; &#125; &#125; &#125; return ""; &#125;&#125;; 020. Valid ParenthesesDescriptionGiven a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid.An input string is valid if:Open brackets must be closed by the same type of brackets.Open brackets must be closed in the correct order.Note that an empty string is also considered valid. Example 1:12Input: &quot;()&quot;Output: true Example 2:12Input: &quot;()[]&#123;&#125;&quot;Output: true Example 3:12Input: &quot;(]&quot;Output: false Example 4:12Input: &quot;([)]&quot;Output: false Example 5:12Input: &quot;&#123;[]&#125;&quot;Output: true 解法一: 栈时间复杂度: $O(n)$空间复杂度: $O(n)$ 写法一:123456789101112131415161718class Solution &#123;public: bool isValid(string s) &#123; stack&lt;char&gt; s_brack; for(int i = 0; i&lt;s.size(); i++)&#123; char c='\0'; if(s[i] == ')') c='('; else if(s[i] == ']') c='['; else if(s[i] == '&#125;') c='&#123;'; if(!s_brack.empty() &amp;&amp; c == s_brack.top()) s_brack.pop(); else s_brack.push(s[i]); &#125; if(!s_brack.empty()) return false; return true; &#125;&#125;; 写法二:123456789101112131415161718class Solution &#123;public: bool isValid(string s) &#123; stack&lt;char&gt; parent; for(auto c : s)&#123; if(c=='(' || c=='&#123;' || c=='[') parent.push(c); else if(parent.empty()) return false; else if((c==')' &amp;&amp; parent.top()=='(') || (c=='&#125;' &amp;&amp; parent.top()=='&#123;') || (c==']' &amp;&amp; parent.top()=='['))&#123; parent.pop(); &#125;else return false; &#125; return parent.empty() ? true : false; &#125;&#125;; 021. Merge Two Sorted ListsDescriptionMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists. Example: Input: 1-&gt;2-&gt;4, 1-&gt;3-&gt;4Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 解法一: 遍历融合时间复杂度: $O(min(m,n))$ 空间复杂度: $O(1)$ 12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if(l1 == nullptr) return l2; if(l2 == nullptr) return l1; ListNode* head=nullptr; if(l1-&gt;val &lt; l2-&gt;val) &#123; head = l1; l1 = l1-&gt;next; &#125; else&#123; head = l2; l2 = l2-&gt;next; &#125; ListNode* cur = head; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur= cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l2==nullptr) cur-&gt;next = l1; else if(l1 == nullptr) cur-&gt;next = l2; return head; &#125;&#125;; 上面开关头结点的过程过于复杂, 可以用dummy指针简化这个过程 1234567891011121314151617181920212223242526272829303132/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if(l1 == nullptr) return l2; if(l2 == nullptr) return l1; ListNode* dummy=new ListNode(0); ListNode* cur = dummy; while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; if(l1-&gt;val &lt; l2-&gt;val)&#123; cur-&gt;next = l1; cur = cur-&gt;next; l1 = l1-&gt;next; &#125;else&#123; cur-&gt;next = l2; cur = cur-&gt;next; l2 = l2-&gt;next; &#125; &#125; if(l2==nullptr) cur-&gt;next = l1; else if(l1 == nullptr) cur-&gt;next = l2; return dummy-&gt;next; &#125;&#125;; 026. Remove Duplicates from Sorted ArrayDescriptionGiven a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. 解法一:遍历, 两种写法, 后者相当精简 123456789101112131415161718192021class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; int same = nums[0]; int length = 1; for(int i=1; i&lt;nums.size(); i++)&#123; if(nums[i] == same)&#123; nums.erase(nums.begin()+i); i--; continue; &#125; else&#123; same = nums[i]; length++; &#125; &#125; return length; &#125;&#125;; 123456789101112class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.empty()) return 0; int length=1; for(auto n:nums)&#123; if(n&gt;nums[length-1]) nums[length++]=n; &#125; return length; &#125;&#125;; 028. Implement strStr()字符串匹配算法, 更详细的解析请看字符串匹配算法解析 description: KMP, 判断是否为子串Return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. Example 1: Input: haystack = “hello”, needle = “ll”Output: 2Example 2: Input: haystack = “aaaaa”, needle = “bba”Output: -1Clarification: What should we return when needle is an empty string? This is a great question to ask during an interview. For the purpose of this problem, we will return 0 when needle is an empty string. This is consistent to C’s strstr() and Java’s indexOf(). 解法一: 暴力解法二: KMP求解next数组: 求解某个位置 $k$ 的next数组值是一个循环的过程, 需要不断检查以 位置 $k-1$ 的next值 为下标的元素的 下一位元素 与 当前位置 $k$ 元素 是否相等, 如果相等, 则 next[k] = next[k-1]+1, 如果不相等, 则 038. Count and SayDescriptionThe count-and-say sequence is the sequence of integers with the first five terms as following: 1 11 21 1211 1112211 is read off as “one 1” or 11.11 is read off as “two 1s” or 21.21 is read off as “one 2, then one 1” or 1211. Given an integer n where 1 ≤ n ≤ 30, generate the nth term of the count-and-say sequence. Note: Each term of the sequence of integers will be represented as a string. 解法一: 依次查看上一次的数字时间复杂度: $O(nm)$ m为数字字符串的长度空间复杂度: $O(m)$ 每次根据上一次的数字更新当前的数字字符串, 如此迭代直到达到指定次数 12345678910111213141516171819202122class Solution &#123;public: string countAndSay(int n) &#123; string res="1"; int i=1; while(i&lt;n)&#123; string tmp; for(int u=0; u&lt;res.size(); u++)&#123; char c=res[u]; int count = 1; while(u+1&lt;res.size() &amp;&amp; res[u+1]==c)&#123; count++; u++; &#125; tmp += to_string(count)+c; &#125; res.swap(tmp); i++; &#125; return res; &#125;&#125;; 053. Maximum Subarray连续子数组的最大和 DescriptionGiven an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum. Example: Input: [-2,1,-3,4,-1,2,1,-5,4],Output: 6Explanation: [4,-1,2,1] has the largest sum = 6.Follow up: If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle. 解法: 记录当前最大值时间复杂度: $O(n)$根据数组性质，设置两个变量，一个记录当前的最大值，一个记录当前的子序列之和。首先，如果当前子序列之和为负，那么就是说，从当前位置开始的子序列，比从之前位置开始的子序列大，那么就可以不考虑从之前位置开始的子序列，之前累计的和也被抛弃 1234567891011121314class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; int sum = 0; int max_sum = INT_MIN; //数组有可能全负, 所以不能赋值为0 for(auto num : nums)&#123; if(num &gt; max_sum) max_sum = num; //主要是为了预防数组中全是负数的情况 sum += num; if(sum!=0 &amp;&amp; sum&gt;max_sum) max_sum = sum; // sum!=0 , 为了预防数组全负时, 0一定大于sum, 造成的错解 if(sum &lt;0) sum =0; &#125; return max_sum; &#125;&#125;; 更简洁的写法: 1234567891011121314151617class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) return 0; int tmpRes = nums[0]; int res = nums[0]; for (int i = 1; i &lt; nums.size(); i++) &#123; if (tmpRes &lt; 0) &#123; tmpRes = nums[i]; &#125; else &#123; tmpRes += nums[i]; &#125; res = std::max(res, tmpRes); &#125; return res; &#125;&#125;; 066. Plus One数组代表一个整数, 模拟整数的加法 DescriptionGiven a non-empty array of digits representing a non-negative integer, plus one to the integer. The digits are stored such that the most significant digit is at the head of the list, and each element in the array contain a single digit. You may assume the integer does not contain any leading zero, except the number 0 itself. Example 1: Input: [1,2,3]Output: [1,2,4]Explanation: The array represents the integer 123.Example 2: Input: [4,3,2,1]Output: [4,3,2,2]Explanation: The array represents the integer 4321. 解法一: 直接模拟时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt;&amp; digits) &#123; int carry = 0, last_i = digits.size()-1; digits[last_i] += 1; if(digits[last_i] &gt; 9) &#123; digits[last_i] = 0; carry=1; &#125; for(int i = last_i-1; i&gt;=0 &amp;&amp; carry ; i--)&#123; digits[i] += carry; if(digits[i] &gt; 9) digits[i] = 0; else carry = 0; &#125; if(carry == 1) digits.insert(digits.begin(), 1); return digits; &#125;&#125;; 另一种写法:12345678910111213141516class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt;&amp; digits) &#123; int carry = 0; int one = 1; int cur = digits.size()-1; for(int cur=digits.size()-1; cur&gt;=0; cur--)&#123; digits[cur] += one + carry; one = 0; carry = digits[cur] / 10; digits[cur] = digits[cur] % 10; &#125; if(carry) digits.insert(digits.begin(), 1); return digits; &#125;&#125;; 解法二: 不使用加法(更快更简单, 击败100%)123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt; &amp;digits) &#123; //未考虑前缀0的情况 for(int i = digits.size() - 1; i &gt;= 0; i--) &#123; if(digits[i] != 9) &#123; digits[i] ++; break; &#125; digits[i] = 0; &#125; if(digits[0] == 0) digits.insert(digits.begin(), 1); return digits; &#125;&#125;; 069. Sqrt(x)实现开方算法 DescriptionImplement int sqrt(int x). Compute and return the square root of x, where x is guaranteed to be a non-negative integer. Since the return type is an integer, the decimal digits are truncated and only the integer part of the result is returned. Example 1:12Input: 4Output: 2 Example 2:123Input: 8Output: 2Explanation: The square root of 8 is 2.82842..., and since the decimal part is truncated, 2 is returned. 解法一: 二分法时间复杂度: $O(logn)$空间复杂度: $O(1)$ 123456789101112131415161718class Solution &#123;public: int mySqrt(int x) &#123; double low=0, high=x; double res = high; while( std::abs(res*res - x) &gt; 0.00001 )&#123; if(res*res &gt; x)&#123; high = res; res = (low+high)/2; &#125;else&#123; low = res; res = (low+high)/2; &#125; &#125; if(ceil(res)*ceil(res)==x) return ceil(res); // 为了能够正确截断, 必须加上此句 return int(res); &#125;&#125;; 解法二: 牛顿迭代法时间复杂度: $O(logn)$空间复杂度: $O(1)$ 相当于求解 $f(res)=res^2 - x = 0$ 中 $res$ 的解. 则对于任意一点 $(res, f(res))$, 都有切线方程: f(res) - 0 = f'(res)(res-res')其中, $res’$ 是该直线与 $x$ 轴的交点. 令新的 $res$ 为该值, 就可以不断逼近 $f(res)$ 的零点, $res’$ 的值为: res' = res- \frac{f(res)}{f'(res)} = res- \frac{res^2-x}{2\times res} = \frac{res^2 + x}{2\times res}1234567891011class Solution &#123;public: int mySqrt(int x) &#123; double res = x; while( std::abs(res*res - x) &gt; 0.00001 )&#123; res = (res*res+x) / (2*res); &#125; if(ceil(res)*ceil(res)==x) return ceil(res); // 为了能够正确截断, 必须加上此句 return int(res); &#125;&#125;; 解法三: 按位检索时间复杂度: $O(logn)$空间复杂度: $O(1)$ 由于本题要返回的是整数, 而上面的两种方法都是针对double类型的精确开根方法, 时间复杂度为 $O(logn)$, 实际上, 当只需要返回整数时, 我们可以按整数的位进行检索, 而整数总共只有32位(传入的x位int型, 所以开根后不可能超过int), 因此时间复杂度只有 $O(32)$ , 也就是 $O(1)$. 注意: 由于该方法是首先找到比 x 大的那一位, 因此有可能超过int上限, 所以要换成long整型 找到后依然需要进行二分查找来找到最终的返回值 12345678910111213141516class Solution &#123;public: int mySqrt(int x) &#123; long res=0; int h=0; while( long(1&lt;&lt;h) * long(1&lt;&lt;h) &lt;= x) h++; long b = 1&lt;&lt;(h-1); while( b &gt; 0)&#123; if( (res+b) * (res+b) &lt;= x) res += b; b = b/2; &#125; return res; &#125;&#125;; 070. Climbing Stairs实际上就是斐波那契数列, 更具体分析可看牛客的跳台阶 DescriptionYou are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Note: Given n will be a positive integer. Example 1: Input: 2Output: 2Explanation: There are two ways to climb to the top. 1 step + 1 step 2 stepsExample 2: Input: 3Output: 3Explanation: There are three ways to climb to the top. 1 step + 1 step + 1 step 1 step + 2 steps 2 steps + 1 step 解法一: 递归解法二: 迭代123456789101112131415class Solution &#123;public: int climbStairs(int n) &#123; if(n==0) return 0; if(n==1) return 1; int n1 = 1; int n2 = 2; for(int i=3; i&lt;=n; i++)&#123; int temp = n2; n2 = n1+n2; n1 = temp; &#125; return n2; &#125;&#125;; 088. Merge Sorted Array融合两个有序数组, 其中第一个数组的元素长度为n, 第二个为m, 题目假设第一个数组的空间为n+m. Description解法一: 后移+插入融合1234567891011121314151617181920212223class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) &#123; for(int i =n+m-1; i&gt;=n; i--) nums1[i]=nums1[i-n]; //for(int i =n; i&lt;n+m; i++) 注意, 这样写是有问题的, 例如对于 [1,2,3,4,0], 这种情况, 从前往后的复制方法会造成元素覆盖 // nums1[i]=nums1[i-n]; int i =n, j=0, k=0; while(i&lt;n+m &amp;&amp; j&lt;n)&#123; if(nums1[i] &lt; nums2[j])&#123; nums1[k] = nums1[i]; k++; i++; &#125;else&#123; nums1[k] = nums2[j]; k++; j++; &#125; &#125; while(i&lt;n+m) nums1[k++] = nums1[i++]; while(j&lt;n) nums1[k++] = nums2[j++]; &#125;&#125;; 101. Symmetric Tree判断一个二叉树是否为对称的.(与自身镜像相等) DescriptionGiven a binary tree, check whether it is a mirror of itself (ie, symmetric around its center). For example, this binary tree [1,2,2,3,4,4,3] is symmetric:12345 1 / \ 2 2 / \ / \3 4 4 3 But the following [1,2,2,null,3,null,3] is not:12345 1 / \2 2 \ \ 3 3 Note:Bonus points if you could solve it both recursively and iteratively. 解法一: 递归时间复杂度: $O(n)$ , 遍历了整个树中的每个节点一次空间复杂度: $O(n)$ , 调用递归的次数与树的高度有关, 在最差的情况下, 树的高度为n. 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; if(root==nullptr) return true; return isSymHelper(root-&gt;left, root-&gt;right); &#125; bool isSymHelper(TreeNode* subRoot1, TreeNode* subRoot2)&#123; if(subRoot1 == nullptr &amp;&amp; subRoot2 == nullptr) return true; if(subRoot1 == nullptr || subRoot2 == nullptr) return false; if(subRoot1-&gt;val != subRoot2-&gt;val) return false; bool b1 = isSymHelper(subRoot1-&gt;left, subRoot2-&gt;right); bool b2 = isSymHelper(subRoot1-&gt;right, subRoot2-&gt;left); return b1&amp;&amp;b2; &#125;&#125;; 更整洁的写法:1234567891011121314class Solution &#123; bool is_sym(TreeNode* t1, TreeNode* t2)&#123; if(t1==nullptr &amp;&amp; t2==nullptr) return true; if(t1==nullptr || t2==nullptr) return false; if(t1-&gt;val == t2-&gt;val) return is_sym(t1-&gt;left, t2-&gt;right) &amp;&amp; is_sym(t2-&gt;left, t1-&gt;right); else return false; &#125;public: bool isSymmetric(TreeNode* root) &#123; if(root==nullptr) return true; return is_sym(root-&gt;left, root-&gt;right); &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$ , 遍历了整个树中的每个节点一次空间复杂度: $O(n)$ , 层次遍历创建了两个队列, 其大小总和刚好为n. (有一种说法是: 层次遍历我们最多只会同时保存两层的节点数, 而最后一层的节点数最多为 $logn$, 所以空间复杂度实际上是 $O(logn)$ (常数项被约掉), 这种说法对吗??) 层次遍历, 注意不应该左子树和右子树做非空检查, 因此判断是否对称时, 需要包含节点为空的情况.(因为不需要知道当前的深度, 所以也不用维护深度信息) 123456789101112131415161718192021class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; if(root==nullptr) return true; queue&lt;TreeNode*&gt; q1; queue&lt;TreeNode*&gt; q2; q1.push(root-&gt;left); q2.push(root-&gt;right); TreeNode * cur1, * cur2; while(!q1.empty() &amp;&amp; !q2.empty())&#123; cur1 = q1.front(); q1.pop(); cur2 = q2.front(); q2.pop(); if(cur1==nullptr &amp;&amp; cur2 ==nullptr) continue; if(cur1==nullptr || cur2 == nullptr) return false; if(cur1-&gt;val != cur2-&gt;val) return false; q1.push(cur1-&gt;left); q1.push(cur1-&gt;right); q2.push(cur2-&gt;right); q2.push(cur2-&gt;left); &#125; return true; &#125;&#125;; 解法三: 迭代时间复杂度: $O(n)$空间复杂度: $O(n)$ 只是用一个队列, 对每一层都进行回文检查123456789101112131415161718192021222324252627282930class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; if (root == nullptr) return true; std::queue&lt;TreeNode*&gt; queueTree; queueTree.push(root); while (!queueTree.empty()) &#123; int len = queueTree.size(); std::vector&lt;double&gt; vec; for (int i = 0; i &lt; len; i++) &#123; auto node = queueTree.front(); queueTree.pop(); if (node == nullptr) &#123; vec.push_back(0.5); &#125; else &#123; vec.push_back(node-&gt;val); queueTree.push(node-&gt;left); queueTree.push(node-&gt;right); &#125; &#125; int n = vec.size(); for (int i = 0; i &lt; n/2; i++) &#123; if (vec[i] != vec[n - i - 1]) &#123; return false; &#125; &#125; &#125; return true; &#125;&#125;; 104. Maximum Depth of Binary Tree求二叉树的最大深度(树的深度) DescriptionGiven a binary tree, find its maximum depth. The maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node. Note: A leaf is a node with no children. Example: Given binary tree [3,9,20,null,null,15,7],12345 3 / \9 20 / \ 15 7 return its depth = 3. 解法一: 层次遍历时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int maxDepth(TreeNode* root) &#123; if(root == nullptr) return 0; std::queue&lt;TreeNode*&gt; q; q.push(root); int depth = 0; TreeNode* cur_node; while(!q.empty())&#123; int layer_len = q.size(); depth++; for(int i=0; i&lt;layer_len; i++)&#123; cur_node = q.front(); q.pop(); if(cur_node-&gt;left!=nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right!=nullptr) q.push(cur_node-&gt;right); &#125; &#125; return depth; &#125;&#125;; 解法二: 递归12345678910111213class Solution &#123;private: int height(TreeNode *root)&#123; if(root == nullptr) return 0; int left_height = height(root-&gt;left); int right_height = height(root-&gt;right); return 1+max(left_height, right_height); &#125;public: int maxDepth(TreeNode* root) &#123; return height(root); &#125;&#125;; 108. Convert Sorted Array to Binary Search Tree根据 有序数组 构造平衡二叉搜索树(不唯一, 只要符合规则即可) DescriptionGiven an array where elements are sorted in ascending order, convert it to a height balanced BST. For this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1. Example:123456789Given the sorted array: [-10,-3,0,5,9],One possible answer is: [0,-3,9,-10,null,5], which represents the following height balanced BST: 0 / \ -3 9 / / -10 5 解法一: 递归构造时间复杂度: $O(n)$空间复杂度: $O(n)$, 递归了n次(每个节点都被访问了一次) 由于题目给的条件是 有序数组 , 因此大大降低了了构造难度, 可以每次将数组的中间位置作为根节点, 然后分别将两边的数组作为一个新的子数组进行构造, 无需考虑插入新节点引起的二叉搜索树不平衡的问题.12345678910111213141516171819202122232425/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) &#123; return construct_BST(nums, 0, nums.size()-1); &#125; TreeNode* construct_BST(vector&lt;int&gt;&amp; nums, int low, int high)&#123; if(low&gt;high) return nullptr; int mid = (low+high)/2; TreeNode* root = new TreeNode(nums[mid]); root-&gt;left = construct_BST(nums, low, mid-1); root-&gt;right = construct_BST(nums, mid+1, high); return root; &#125;&#125;; 解法二: 迭代时间复杂度: $O(n)$, 只不过需要遍历两次树的size空间复杂度: $O(n)$, 层次遍历的队列和中根遍历的栈 先用层次遍历构造一个完全二叉树(以却确保树是平衡的), 然后在利用中根遍历对树中的每个元素进行赋值. 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;public: TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) &#123; int tree_len = nums.size(); if(tree_len == 0) return nullptr; std::queue&lt;TreeNode*&gt; q; TreeNode* root = new TreeNode(0); q.push(root); tree_len--; TreeNode* cur_node; int layer_len = 1; while(tree_len&gt;0)&#123; layer_len *= 2; for(int i=0; i&lt;layer_len &amp;&amp; tree_len&gt;0; i++)&#123; cur_node = q.front(); q.pop(); TreeNode* left = new TreeNode(0); cur_node-&gt;left = left; q.push(cur_node-&gt;left); tree_len--; if(tree_len&gt;0)&#123; TreeNode *right = new TreeNode(0); cur_node-&gt;right = right; q.push(cur_node-&gt;right); tree_len--; &#125; &#125; &#125; std::stack&lt;TreeNode*&gt; s; cur_node = root; int i = 0; while(!s.empty() || cur_node!=nullptr)&#123; while(cur_node!=nullptr)&#123; s.push(cur_node); cur_node = cur_node-&gt;left; &#125; if(!s.empty())&#123; cur_node = s.top(); s.pop(); cur_node-&gt;val =nums[i++]; cur_node = cur_node-&gt;right; &#125; &#125; return root; &#125;&#125;; 解法三: 迭代(只中根遍历一次)【链接】Loading…https://leetcode.com/problems/convert-sorted-array-to-binary-search-tree/discuss/35218/Java-Iterative-Solution 111. minimum depth of binary tree题目描述Given a binary tree, find its minimum depth. The minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node. Note: A leaf is a node with no children. Example:1234567Given binary tree [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7 解法一:层次优先遍历,遇到的首个叶子结点(左右子树为空)即为最短的深度 注意: 利用while内嵌for循环的方式, 可以省去对每个结点depth的维护, 只需要每次进入for循环之前, depth++即可(因为一个for循环会将当前层所有的结点都入队列, for循环结束后, 意味着进入了下一层, 所以depth++即可) 123456789101112131415161718192021class Solution &#123;public: int run(TreeNode *root) &#123; queue&lt;TreeNode*&gt; q_node; if(root==nullptr) return 0; q_node.push(root); int depth = 0; while(!q_node.empty())&#123; const int size = q_node.size(); depth++; for(int i = 0; i&lt; size; i++)&#123; TreeNode* node = q_node.front(); q_node.pop(); if(node-&gt;left!=nullptr) q_node.push(node-&gt;left); if(node-&gt;right!=nullptr) q_node.push(node-&gt;right); if(node-&gt;left==nullptr &amp;&amp; node-&gt;right == nullptr) return depth; &#125; &#125; return -1; &#125;&#125;; 解法二(递归):让当前结点为空, 则当前结点深度为0, 若当前结点左子树为空, 则当前结点深度等于左子树深度, 反之 ,等于右子树深度. 若当前结点左右子树均不为空, 则当前结点的 最小深度 等于左右子树深度 较小者 加1 123456789101112131415class Solution &#123;public: int run(TreeNode* root) &#123; if(root== nullptr) return 0; if(root-&gt;left==nullptr) return run(root-&gt;right) + 1; else if(root-&gt;right ==nullptr) return run(root-&gt;left) + 1; else&#123; int depth1=run(root-&gt;left); int depth2=run(root-&gt;right); return depth1&lt;depth2 ? depth1+1 : depth2+1; &#125; &#125;&#125;; 118. Pascal’s TrianglePascal 三角形 DescriptionGiven a non-negative integer numRows, generate the first numRows of Pascal’s triangle. Example:123456789Input: 5Output:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 解法一: 按照三角形的性质进行赋值赋值时, 每一行的两端都是1, 无需重复赋值, 注意控制好边界条件 1234567891011121314class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; generate(int numRows) &#123; vector&lt;vector&lt;int&gt;&gt; res; for(int i =0; i&lt;numRows; i++)&#123; vector&lt;int&gt; temp(i+1, 1); for(int j=1; j&lt;i; j++)&#123; // 两边默认为1, 无需重复赋值 temp[j] = res[i-1][j-1]+res[i-1][j];// i和j的值只有在大于1时才会进入循环, 所以无需担心i-1或j-1&lt;0 &#125; res.push_back(temp); &#125; return res; &#125;&#125;; 121. Best Time to Buy and Sell Stock获取最大的股票利润 DescriptionSay you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1:123Input: [7,1,5,3,6,4]Output: 5Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price. Example 2:123Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 解法一: 穷举计算所有可能性, $O(n^2)$ 解法二: 一次遍历时间复杂度: $O(n)$空间复杂度: $O(1)$ 维护两个变量 min_price 和 max_profit, 每次检查元素, 一方面如果当前价格更低, 则更改 min_price 变量, 另一方面如果当前利润超过 max_profit, 则更新之. 1234567891011121314class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size() == 0) return 0; int min_price=prices[0], max_profit=0; for(int i=0; i&lt;prices.size(); i++)&#123; if(prices[i] &lt;= min_price)&#123; min_price = prices[i]; &#125; if(prices[i]-min_price &gt; max_profit) max_profit = prices[i]-min_price; &#125; return max_profit; &#125;&#125;; 同样也是一次遍历, 下面的写法更加简洁, 我们这里记录一个变量 buy, 用来指示可能的买入下标, 之后, 如果下一个价格比 buy 对应的价格高, 我们就尝试更新最大利润, 否则, 就改变 buy 到当前的价格下标1234567891011121314class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int maxfit = 0; int buy = 0; for(int i=1; i&lt;prices.size(); i++)&#123; if(prices[buy] &lt; prices[i])&#123; maxfit = max(maxfit, prices[i] - prices[buy]); &#125;else buy = i; &#125; return maxfit; &#125;&#125;; 实际上, 我们只需要用一个变量记录迄今为止遇到的最小的股票值即可, 然后对于每一个新值, 我们都更新最高利润和最小值即可, 代码如下:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if (prices.empty()) return 0; int low = prices[0]; int res = 0; for (auto const p : prices) &#123; res = std::max(res, p - low); low = std::min(low, p); &#125; return res; &#125;&#125;; 122. Best Time to Buy and Sell Stock II可以多次交易, 统计最大利润和 DescriptionSay you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Note: You may not engage in multiple transactions at the same time (i.e., you must sell the stock before you buy again). Example 1:123Input: [7,1,5,3,6,4]Output: 7Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4.Then buy on day 4 (price = 3) and sell on day 5 (price = 6), profit = 6-3 = 3. Example 2:123Input: [1,2,3,4,5]Output: 4Explanation: Buy on day 1 (price = 1) and sell on day 5 (price = 5), profit = 5-1 = 4. Note that you cannot buy on day 1, buy on day 2 and sell them later, as you are engaging multiple transactions at the same time. You must sell before buying again. Example 3:123Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 解法一: 用变量维护最低价格时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 寻找递增序列, 一旦出现递减的情况, 则说明应该及时卖出, 并将 min_price 重新赋值. 因为最后一个元素后面没有值来判断是否递减, 因此需要对最后一个元素进行单独判断12345678910111213141516171819class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size() ==0) return 0 ; int min_price = prices[0]; int sum_profit = 0, pre_price=prices[0]; for(int i=1; i&lt;prices.size(); i++)&#123; if(prices[i] &lt; pre_price)&#123; //如果小于之前的price, 则说明此时应该卖出 sum_profit += pre_price-min_price; //计算卖出利润 min_price = prices[i]; &#125; pre_price = prices[i]; if(i==prices.size()-1 &amp;&amp; prices[i] &gt; min_price) //到了最后一个元素, 查看是否应该卖出 sum_profit += prices[i] - min_price; &#125; return sum_profit; &#125;&#125;; 同样和上一道题一样, 利用 buy 可以更加整洁的实现:12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int max_profit = 0; int buy = 0; for(int i=1; i&lt;prices.size(); i++)&#123; if(prices[buy] &lt; prices[i]) max_profit += prices[i] - prices[buy]; buy = i; &#125; return max_profit; &#125;&#125;; 解法二: 每两个相邻数字当做一次交易时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 实际上和解法一本质相同, 只不过在累加利润上有一点小区别.该解法是将每两个相邻数字看做是一次交易, 如果后者大于前者, 说明应该执行交易, 并累加交易所的利润.12345678910Cclass Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int sum_profit = 0; for(int i =1 ; i&lt;prices.size(); i++)&#123; if(prices[i] &gt; prices[i-1]) sum_profit += prices[i] - prices[i-1]; &#125; return sum_profit; &#125;&#125;; 125 Valid Palindrome判断是否为回文子串 DescriptionGiven a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases. Note: For the purpose of this problem, we define empty string as valid palindrome. Example 1: Input: “A man, a plan, a canal: Panama”Output: trueExample 2: Input: “race a car”Output: false 解法一: 前后两个指示变量, 向中间遍历判断时间复杂度: $O(n)$, 遍历一次空间复杂度: $O(1)$, 只额外用了两个变量 需要注意的是将大小写字母转换成同大写或者同小写的形式再进行判断 写法一:123456789101112131415161718192021222324class Solution &#123;public: bool isPalindrome(string s) &#123; for(int i=0, j=s.size()-1; i&lt;j; )&#123; if(is_alphanumeric(s[i]) == false)&#123; i++; continue; &#125; if(is_alphanumeric(s[j]) == false)&#123; j--; continue; &#125; if(std::tolower(s[i]) != std::tolower(s[j])) return false; i++; j--; &#125; return true; &#125; bool is_alphanumeric(char c)&#123; if(c&gt;='0' &amp;&amp; c&lt;='9') return true; else if(c&gt;='a' &amp;&amp; c&lt;='z') return true; else if(c&gt;='A' &amp;&amp; c&lt;='Z') return true; else return false; &#125;&#125;; 写法二: 12345678910111213141516171819class Solution &#123;public: bool isPalindrome(string s) &#123; for(int i=0, j=s.size()-1; i&lt;=j;i++,j-- )&#123; while(i&lt;s.size() &amp;&amp; is_alphanumeric(s[i]) == false) i++; while(j&gt;=0 &amp;&amp; is_alphanumeric(s[j]) == false) j--; if(std::tolower(s[i]) != std::tolower(s[j])) return false; &#125; return true; &#125; bool is_alphanumeric(char c)&#123; if(c&gt;='0' &amp;&amp; c&lt;='9') return true; else if(c&gt;='a' &amp;&amp; c&lt;='z') return true; else if(c&gt;='A' &amp;&amp; c&lt;='Z') return true; else return false; &#125;&#125;; 136. Single Number数组中有一个数字出现了1次(奇数次), 其他均出现了2次(偶数次), 找到出现1次(奇数次)的数字. DescriptionGiven a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? Example 1: Input: [2,2,1]Output: 1Example 2: Input: [4,1,2,1,2]Output: 4 解法一: 哈希时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 哈希表额外空间 遍历数组, 对于每一个数, 如果当前的数存在于hash表中, 则将表中哈希删除, 如果不存在, 则添加到哈希表中, 最终, 哈希表中存在的值就是只出现一次的值 解法二: 数学公式2\times (a + b + c) - (a+b+a+b+c) = c. 将数组中的元素转换为 set(无重复元素), 然后利用上面的公式纠结时间复杂度: $O(n + n)=O(n)$, 转换为 set 需要 $O(n), 公式求解遍历也需要 $O(n)$空间复杂度: $O(n)$. set 所占额外空间 解法三: 异或任何数和0异或不变, 和自身异或变为0123456789class Solution &#123;public: int singleNumber(vector&lt;int&gt;&amp; nums) &#123; int res=0; for(auto num : nums) res ^= num; return res; &#125;&#125;; 其他更多扩展问题可看剑指Offer第40题. 141. Linked List CycleDescriptionGiven a linked list, determine if it has a cycle in it. Follow up:Can you solve it without using extra space? 解法一: Floyd Cycle(Floyd 判圈算法)时间复杂度: $O(n+k)$, 可以认为是$O(n)$, $n$ 为链表长度, $k$ 为环长空间复杂度: $O(1)$ 从头结点开始，slow每次走一步，fast每次走两步，那么只要有环，slow和fast就一定会在环中的某个节点处相遇，如果无环，则fast一定先到达空指针 12345678910111213class Solution &#123;public: bool hasCycle(ListNode *head) &#123; if (head == nullptr or head-&gt;next == nullptr) return false; ListNode* fast = head; ListNode* slow = head; do &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; while (slow != fast and fast!=nullptr and fast-&gt;next != nullptr); return slow == fast ? true : false; &#125;&#125;; 1234567891011121314151617181920212223/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool hasCycle(ListNode *head) &#123; if(head==nullptr) return false; ListNode* slow=head, *fast=head-&gt;next; while(fast!=nullptr &amp;&amp; slow != fast)&#123; slow= slow-&gt;next; if(fast-&gt;next == nullptr) return false; fast = fast-&gt;next-&gt;next; &#125; if(fast==nullptr) return false; return true; &#125;&#125;; 更多扩展见牛客第55题, 链表中环的入口节点 155. Min Stack获取栈中最小的元素 DescriptionDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) — Push element x onto stack.pop() — Removes the element on top of the stack.top() — Get the top element.getMin() — Retrieve the minimum element in the stack.Example:MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); —&gt; Returns -3.minStack.pop();minStack.top(); —&gt; Returns 0.minStack.getMin(); —&gt; Returns -2. 解法一: 两个栈时间复杂度: $O(1)$空间复杂度: $O(n)$, 两个栈 申请两个栈, 一个栈正常操作, 另一个栈只有当当前元素小于或等于栈顶元素时才入栈 1234567891011121314151617181920212223242526272829303132333435363738class MinStack &#123;private: stack&lt;int&gt; s1; stack&lt;int&gt; s2;public: /** initialize your data structure here. */ MinStack()&#123; &#125; void push(int x) &#123; s1.push(x); if(s2.empty() || x &lt;= s2.top()) s2.push(x); &#125; void pop() &#123; if(s1.top() == s2.top()) s2.pop(); s1.pop(); &#125; int top() &#123; return s1.top(); &#125; int getMin() &#123; return s2.top(); &#125;&#125;;/** * Your MinStack object will be instantiated and called as such: * MinStack obj = new MinStack(); * obj.push(x); * obj.pop(); * int param_3 = obj.top(); * int param_4 = obj.getMin(); */ 160. Intersection of Two Linked Lists两个链表的第一个公共节点 DescriptionWrite a program to find the node at which the intersection of two singly linked lists begins. For example, the following two linked lists:12345A: a1 → a2 ↘ c1 → c2 → c3 ↗ B: b1 → b2 → b3 begin to intersect at node c1. Notes: If the two linked lists have no intersection at all, return null.The linked lists must retain their original structure after the function returns.You may assume there are no cycles anywhere in the entire linked structure.Your code should preferably run in O(n) time and use only O(1) memory. 解法一：栈时间复杂度: $O(m+n)$, 遍历两个链表空间复杂度: $O(m+n)$, 两个栈 分析公共子节点的特点，首先，是单向链表，因此，从第一个公共子节点开始，后面的都是一样的，所以最好是能从链表的最后一项还是比较。但由于是单向链表，因此只能从头访问，从能访问最后的节点。 就像是先进先出一样 因此，考虑用两个辅助栈来帮助实现～ 1234567891011121314151617181920212223242526272829303132/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) &#123; stack&lt;ListNode*&gt; s1; stack&lt;ListNode*&gt; s2; for(ListNode* cur = pHead1; cur!=nullptr; cur = cur-&gt;next)&#123; s1.push(cur); &#125; for(ListNode* cur = pHead2; cur!=nullptr; cur = cur-&gt;next)&#123; s2.push(cur); &#125; ListNode* firstCN = nullptr; while(!s1.empty() &amp;&amp; !s2.empty())&#123; if(s1.top() == s2.top())&#123; firstCN = s1.top(); s1.pop(); s2.pop(); &#125;else break; &#125; return firstCN; &#125;&#125;; 解法二: 常数空间复杂度时间复杂度: $O(m+n)$, 遍历两次空间复杂度: $O(1)$, 不使用额外空间 首先遍历得到两个链表的长度, 然后先让长链表前进长度差个节点, 接着两个链表共同向前遍历, 当相遇时即为第一个公共节点. 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) &#123; int lengthA = 0; ListNode* nodeA = headA; while (nodeA != nullptr) &#123; nodeA = nodeA-&gt;next; lengthA++; &#125; int lengthB = 0; ListNode* nodeB = headB; while (nodeB != nullptr) &#123; nodeB = nodeB-&gt;next; lengthB++; &#125; ListNode* longNode = lengthA &gt; lengthB ? headA : headB; ListNode* shortNode = lengthA &gt; lengthB ? headB : headA; int l = std::abs(lengthA - lengthB); while (l--) &#123; longNode = longNode-&gt;next; &#125; while (shortNode != longNode) &#123; shortNode = shortNode-&gt;next; longNode = longNode-&gt;next; &#125; return shortNode; &#125;&#125;; 169 Majority ElementDescription: 找出数组中超过一半的数字Given an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times. You may assume that the array is non-empty and the majority element always exist in the array. Example 1: Input: [3,2,3]Output: 3Example 2: Input: [2,2,1,1,1,2,2]Output: 2 题目中指明了该数字一定存在, 所以无需进行count检查, 如果该数字有可能不存在, 则根据情况需要进行 $O(n)$ 复杂度的count检查(即检查当前的数字是否出现了大于 n/2 次). 解法一: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 先排序, 然后取中间元素, 即为 majority element.(如有需要可进行count检查, $O(n)$) 解法二: 哈希时间复杂度: $O(n)$空间复杂度: $O(n)$ 每个元素的值为哈希的 key, 每个元素出现的次数为哈希的 value, 如果某个 key 的 value 大于 n/2, 则该元素即为 majority element.哈希法记录的元素的出现次数, 所以无需进行 count 检查. 12345678910class Solution &#123;public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; unordered_map&lt; int, int&gt; hash; for(auto num: nums)&#123; hash[num]++; if(hash[num] &gt; nums.size()/2) return num; &#125; &#125;&#125;; 解法三: 同增异减如果数组中存在这样一个数，那么这个数的出现次数一定大于其他所有数的出现次数总和，因此，设置两个变量，一个 cur_num 用来存储当前数组中的可能解，另一个 count 为统计差值. 即每遇到一个和可能解相同的元素, 就 count++, 否则, count—. 如果 count=0, 则说明当前的可能解已经注定不是最终的解, 则令新的元素为可能解.最终, 对可能解进行 $O(n)$ 的 count 检查, 判断是否存在 majority element (题目假设一定存在, 所以可以不做此检查). 12345678910111213141516171819class Solution &#123;public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; int major = 0; int count = 0; for (auto const num : nums) &#123; if (num == major) &#123; count++; &#125; else &#123; count--; if (count &lt; 0) &#123; major = num; count = 1; &#125; &#125; &#125; return major; // 因为题目保证major一定存在, 所以可以直接返回, 否则的话还需要再判断major的个数是否大于 n/2 &#125;&#125;; 解法四: 随机如果确定数组中存在 majority element 的话, 则我们可以从数组中随机选取一个元素, 并判断这个元素是否为 majority element. 这种解法依赖于统计学的概率知识, 实际的时间复杂度与数组的组成规律有关. 171. Excel Sheet Column NumberDescription: Excel列表数字Given a column title as appear in an Excel sheet, return its corresponding column number. For example: A -&gt; 1 B -&gt; 2 C -&gt; 3 ... Z -&gt; 26 AA -&gt; 27 AB -&gt; 28 ... Example 1: Input: “A”Output: 1Example 2: Input: “AB”Output: 28Example 3: Input: “ZY”Output: 701 解法一: 遍历字符串时间复杂度: $O(n)$空间复杂度: $O(1)$ 12345678910class Solution &#123;public: int titleToNumber(string s) &#123; int res=0; for(auto c : s)&#123; res += res*25 + int(c-'A') + 1; &#125; return res; &#125;&#125;; 172. Factorial Trailing ZeroesDescription: 阶乘的尾部含有0的个数解法一: 统计5的个数首先, 求出阶乘值在取余求0个数的方法肯定不可以, 阶乘会轻松溢出(n=13时就已经 int 溢出了) 时间复杂度: $O(logn)$, 以5位基数空间复杂度: $O(1)$ 因为尾部的0只可能来自于 $2\times 5$ 这样的数, 对于 $n$ 的阶乘 $1\times 2\times 3\times, …, n$ 来说, $2$ 一定是充足的, 所以我们只需要统计 $5$ 的个数就可以.统计时, 每个5个数字会出现一次5, 每隔25个数字会额外出现一次5, 每个125个数字又会额外出现一次5…, 如此循环下去, 最终5的个数就是尾部0的个数. 1234567891011class Solution &#123;public: int trailingZeroes(int n) &#123; int res = 0; for(long i =5; n/i &gt;0; i*=5)&#123; //注意这里的i的字节数一定要大于n, 因为n有可能为INT_MAX, 而 n/i &gt;0 时, i必须&gt;n res += n/i; &#125; return res; &#125;&#125;; 解法二: 另一个角度时间复杂度: $O(logn)$, 以5位基数空间复杂度: $O(1)$ (迭代), $O(logn)$ (递归需额外空间) 核心思想是相同的, 同样是统计5的出现个数, 只不过这里我们是先求出 n 中 5 的倍数, 然后再求 n/5 中 5 的倍数, 实际上这里就是相当于求 n 中 25 的倍数. 因此, 和解法一是相同的, 只不过解法二因为是通过减小 n, 而不是增大 i (5,25,125,..)的方式来统计 5 个数, 因此解法二有个好处就是可以不使用 long 类型的变量, 下面分别是该方法的递归实现和迭代实现. 递归:123456class Solution &#123;public: int trailingZeroes(int n) &#123; return n &lt; 5 ? 0 : n / 5 + trailingZeroes(n / 5); &#125;&#125;; 迭代:1234567891011class Solution &#123;public: int trailingZeroes(int n) &#123; int res=0; while(n&gt;=5)&#123; res += n/5; n /= 5; &#125; return res; &#125;&#125;; 189. Rotate ArrayDescription: 循环右移数组Given an array, rotate the array to the right by k steps, where k is non-negative. Example 1: Input: [1,2,3,4,5,6,7] and k = 3Output: [5,6,7,1,2,3,4]Explanation:rotate 1 steps to the right: [7,1,2,3,4,5,6]rotate 2 steps to the right: [6,7,1,2,3,4,5]rotate 3 steps to the right: [5,6,7,1,2,3,4] Example 2: Input: [-1,-100,3,99] and k = 2Output: [3,99,-1,-100]Explanation:rotate 1 steps to the right: [99,-1,-100,3]rotate 2 steps to the right: [3,99,-1,-100] Note:Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.Could you do it in-place with O(1) extra space? 解法一: 暴力时间复杂度: $O(nk)$空间复杂度: $O(1)$ 所有的数字每次移动一步, 攻移动 k 次. 超时 解法二: 使用额外数组时间复杂度: $O(n)$空间复杂度: $O(n)$ 申请一个长度相等的数组, 复制原数组中的 $i$ 号元素到新数组中的 $i+k$ 号位置. 解法三: 循环置换时间复杂度: $O(n)$, 遍历一次空间复杂度: $O(1)$ 每次直接将元素放置在正确的位置, 放置前, 需要用一个临时变量将被放置的元素保存起来以防止覆盖, 然后将临时变量的元素再直接放到正确的位置, 循环进行, 知道临时变量指向了最开始的变量, 然后再继续从下一个元素开始这个过程. 在代码中设置一个 count 变量, 用来统计放置的次数, 当次数等于数组长度时, 说明已经完成移动. 123456789101112131415161718class Solution &#123;public: void rotate(vector&lt;int&gt;&amp; nums, int k) &#123; int count=0; for(int start=0; count&lt;nums.size(); start++)&#123; int cur_pos = start; int cur_val = nums[start]; do&#123; int next_pos = (cur_pos + k) % nums.size(); int temp = nums[next_pos]; nums[next_pos] = cur_val; cur_pos = next_pos; cur_val = temp; count++; &#125;while(start!=cur_pos); &#125; &#125;&#125;; 解法四: reverse时间复杂度: $O(n)$, 调用扫除 reverse 函数空间复杂度: $O(1)$ 12345678class Solution &#123;public: void rotate(vector&lt;int&gt;&amp; nums, int k) &#123; std::reverse(nums.begin(), nums.end()-k); std::reverse(nums.end()-k, nums.end()); std::reverse(nums.begin(), nums.end()); &#125;&#125;; 190. Reverse BitsDescription: 按位逆置Reverse bits of a given 32 bits unsigned integer. Example: Input: 43261596Output: 964176192Explanation: 43261596 represented in binary as 00000010100101000001111010011100, return 964176192 represented in binary as 00111001011110000010100101000000.Follow up:If this function is called many times, how would you optimize it? 解法一: 按位进行32次操作每次取 n 的最后一位, 如果为 1, 则令res左移一位并加一, 如果为0, 则只左移一位. 进行32次(n的32位). 12345678910class Solution &#123;public: uint32_t reverseBits(uint32_t n) &#123; uint32_t res= 0; for(int i=0; i&lt;32; i++)&#123; res = (res&lt;&lt;1) | ((n&gt;&gt;i)&amp;1); //res = (res&lt;&lt;1) | (n&amp;1); n = (n&gt;&gt;1); &#125; return res; &#125;&#125;; 解法二: 按位二分进行5次操作先将前16位和后16位交换(利用位移和位操作实现)然后再将16位中的前8位和后8位交换然后再将8位中的前4位和后4位交换然后再将4位中的前2位和后2位交换最后将2位中的前1位和后1位交换. 上述交换全部采用位操作实现, 因此, 速度上有所优化. 1234567891011class Solution &#123;public: uint32_t reverseBits(uint32_t n) &#123; n = (n&gt;&gt;16) | (n&lt;&lt;16); n = ( ((n &amp; 0xff00ff00)&gt;&gt;8) | ((n &amp; 0x00ff00ff)&lt;&lt;8) ); n = ( ((n &amp; 0xf0f0f0f0)&gt;&gt;4) | ((n &amp; 0x0f0f0f0f)&lt;&lt;4) ); n = ( ((n &amp; 0xcccccccc)&gt;&gt;2) | ((n &amp; 0x33333333)&lt;&lt;2) ); n = ( ((n &amp; 0xaaaaaaaa)&gt;&gt;1) | ((n &amp; 0x55555555)&lt;&lt;1) ); return n; &#125;&#125;; 191. Number of 1 BitsDescription: 统计二进制中1的个数Write a function that takes an unsigned integer and returns the number of ‘1’ bits it has (also known as the Hamming weight). Example 1: Input: 11Output: 3Explanation: Integer 11 has binary representation 00000000000000000000000000001011Example 2: Input: 128Output: 1Explanation: Integer 128 has binary representation 00000000000000000000000010000000 解法一: 逐位统计时间复杂度: $O(1)$, 循环32次空间复杂度: $O(1)$ 查看每一位上的二进制是否为1, 若为1, 则count++ 12345678910class Solution &#123;public: int hammingWeight(uint32_t n) &#123; int count=0; for(int i=0; i&lt;32; i++)&#123; if( (n &amp; (1&lt;&lt;i)) != 0) count++; &#125; return count; &#125;&#125;; 解法二: 和 $n-1$ 按位与时间复杂度: $O(1)$, 循环次数为二进制中1的个数.空间复杂度: $O(1)$ 1234567891011class Solution &#123;public: int hammingWeight(uint32_t n) &#123; int count=0; while(n!=0)&#123; count++; n = n&amp;(n-1); &#125; return count; &#125;&#125;; 198. House RobberDescription: 房屋小偷获取最大收益You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night. Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police. Example 1: Input: [1,2,3,1]Output: 4Explanation:Rob house 1 (money = 1) and then rob house 3 (money = 3).Total amount you can rob = 1 + 3 = 4.Example 2: Input: [2,7,9,3,1]Output: 12Explanation:Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1).Total amount you can rob = 2 + 9 + 1 = 12. 解法一: DP时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 依据 DP 的思想, 对于一个任意价格的房子, 我们有两种选择: 偷或不偷. 如果选择不偷, 那么前 $(i+1)$ 个房子的最大收益, 就应该是前 $i$ 个房子的最大收益(偷或者不偷第 $i$ 个房子收益中的较大者), 如果选择偷, 那么就不能偷第 $i$ 个房子.根据上面的描述, 我们可以维护两个变量 cur_rob 和 cur_nrob, 前者代表偷第 $i$ 个房子的收益, 后者代表不偷第 $i$ 个房子的收益, 则最大收益就应该为二者中的较大者. 详细代码如下: 12345678910111213class Solution &#123;public: int rob(vector&lt;int&gt;&amp; nums) &#123; int cur_rob=0; int cur_nrob=0; for(int i =0; i&lt;nums.size(); i++)&#123; int temp = cur_nrob; cur_nrob = std::max(cur_rob, cur_nrob); cur_rob = temp+nums[i]; &#125; return std::max(cur_rob, cur_nrob); &#125;&#125;; 解法二: 根据房屋的编号奇偶性时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$ 因为偷取的房屋不能相邻, 因此我们可以维护两个变量, even 是前偶数个房屋的最大收益, odd 是前奇数个房屋的最大收益, 对于任意的一个新来的房屋, 如果该新房屋的编号为奇数, 那么它的最大收益就是 odd+new 和 even 当中的较大者(因为不能相邻, 所以只能令 odd+new). 对于偶数的情况同理. 最终返回 odd 和 even 的较大者.(因为有可能包含最后一个元素, 也有可能不包含) 代码如下: 123456789101112class Solution &#123;public: int rob(vector&lt;int&gt;&amp; nums) &#123; int odd=0; int even=0; for(int i=0; i&lt;nums.size(); i++)&#123; if(i%2==0) even = std::max(odd, even+nums[i]); else odd = std::max(odd+nums[i], even); &#125; return std::max(odd, even); &#125;&#125;; 202. Happy NumberDescription: 判断一个数字是否是 Happer NumberWrite an algorithm to determine if a number is “happy”. A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Example: Input: 19Output: trueExplanation:12 + 92 = 8282 + 22 = 6862 + 82 = 10012 + 02 + 02 = 1 解法一: 模拟计算过程时间复杂度: $O(logn)$, 基数为10空间复杂度: 未知, 取决于无序集合的size. 按照题目中的逻辑, 模拟整个计算过程, 如果出现1, 则返回 true, 如果出现循环(即在集合中发现已存在元素), 则返回 false. 1234567891011121314151617class Solution &#123;public: bool isHappy(int n) &#123; unordered_set&lt;int&gt; num_set; while(n!=1 &amp;&amp; num_set.find(n)==num_set.end())&#123; num_set.insert(n); int temp = 0; while(n!=0)&#123; temp += (n%10) * (n%10); n = n/10; &#125; n = temp; &#125; if(n==1) return true; return false; &#125;&#125;; 解法二: Floyd 判圈算法时间复杂度: $O(logn)$, 时间复杂度不变空间复杂度: $O(1)$ 利用 Floyd 判圈算法维护两个变量 slow 和 fast, fast 每次都比 flow 多走一步, 那么, 当 fast==1 时, 说明应该返回 true, 当 slow==fast 时, 说明存在循环, 应该返回 false. 123456789101112131415161718192021class Solution &#123;public: bool isHappy(int n) &#123; int slow=n, fast=n; do&#123; slow = digitSquareSum(slow); fast = digitSquareSum(fast); fast = digitSquareSum(fast); &#125;while(fast!=1 &amp;&amp; slow!=fast); if(fast == 1) return true; return false; &#125; int digitSquareSum(int n)&#123; int temp = 0; while(n!=0)&#123; temp += (n%10) * (n%10); n = n/10; &#125; return temp; &#125;&#125;; 204. Count PrimesDescription: 素数的个数Count the number of prime numbers less than a non-negative number, n. Example: Input: 10Output: 4Explanation: There are 4 prime numbers less than 10, they are 2, 3, 5, 7. 解法一: 填充非素数时间复杂度: $O(n)$, 至多遍历两次 $n$ 大小的数组, 可优化为只遍历一次.空间复杂度: $O(n)$, 申请了 $n$ 大小的一维布尔数组来标识是否为负数 如上图, 我们从 $2\times 2$ 开始填充, 将所有能与2相乘切乘积小于 $n$ 的数对应下标置为 false, 然后从 $3\times 3$ 开始填充(注意不是从 $3\times 2$, 因为这样会与前面的 $2\times 3$ 重复), 接着从 $4\times 4$ 开始填充, 因此, 填充的开始位置最大为 $\sqrt{n}$. 另外需要注意的是, 0 和 1 均不是素数. 123456789101112131415161718class Solution &#123;public: int countPrimes(int n) &#123; if(n==0 || n==1) return 0; int div_n = sqrt(n)+1; // 注意这里是开根号 vector&lt;bool&gt; is_primes(n, true); for(int i=2; i&lt;div_n; i++)&#123; for(int j=i*i; j&lt;n; j+=i)&#123; is_primes[j]=false; &#125; &#125; int res_count=0; for(auto primes : is_primes)&#123; if(primes==true) res_count++; &#125; return res_count-2; //去掉0和1的情况 &#125;&#125;; 优化1: 因为任何一个合数都可以拆分成素数的乘积, 因此我们只在当前元素为素数的时候才开始填充, 例如, 对于4, 我们不填充16, 20, ..等数字, 因为这些数字在开始元素为2的时候已经填充过了. 因此, 可以避免这些重复填充, 减少迭代次数, 代码如下(多加了一条if语句). 12345678910111213141516class Solution &#123;public: int countPrimes(int n) &#123; if(n==0 || n==1) return 0; int div_n = sqrt(n)+1; // 注意这里是开根号 vector&lt;bool&gt; is_primes(n, true); for(int i=2; i&lt;div_n; i++)&#123; if(is_primes[i])&#123; for(int j=i*i; j&lt;n; j+=i)&#123; is_primes[j]=false; &#125; &#125; &#125; return std::count(is_primes.begin(), is_primes.end(), true)-2; //去掉0和1的情况 &#125;&#125;; 优化2: 只遍历一次. 首先我们将判断数组isPrime的初始状态设为true, 这样, 每次只在遇到奇数时才检查其是否为素数, 如果该奇数是素数, 那么就将该奇数的倍数全部置为非素数, 同时, 将速度的count加1. 这样, 不仅可以减少判断次数(不再判断偶数), 同时可以在一次遍历的时间内完成素数统计. 12345678910111213141516171819class Solution &#123;public: int countPrimes(int n) &#123; std::vector&lt;bool&gt; isPrime(n, true); // 默认全是素数 int upper = std::sqrt(n); // 控制 i*i, 防止越界 if (n &lt;= 2) return 0; // 判断 0 ~ n-1 是否为素数, 当 n = 2 时, 返回0 int count = 1; // 2 也为素数 for (int i = 3; i &lt; n; i+=2) &#123; // 只有奇数才有可能是速度, 并且 1 不是素数 if (isPrime[i]) &#123; count++; if (i &gt; upper) continue; // 这里必须进行判断, 否则 i*i 有可能越界 for (int j = i*i; j &lt; n; j+=i) &#123; // 将 i 的倍数全部置为非素数 isPrime[j] = false; &#125; &#125; &#125; return count; &#125;&#125;; 206. Reverse Linked ListDescription: 逆置链表Reverse a singly linked list. Example: Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULLOutput: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 解法一: 迭代时间复杂度: $O(n)$, 遍历一次链表空间复杂度: $O(1)$, 借助3个复制指针完成逆置 123456789101112131415161718192021222324/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head==nullptr) return head; ListNode* pre = nullptr; ListNode* cur = head; ListNode* next = head-&gt;next; while(cur!=nullptr)&#123; next = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = next; &#125; return pre; &#125;&#125;; 解法二: 递归时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(n)$, 迭代需要占用 $O(n)$ 大小的栈空间 12345678910class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return head; ListNode *P = reverseList(head-&gt;next); //令下一个开始的节点逆置, 返回新链表的头结点 head-&gt;next-&gt;next = head; // 将当前节点逆置 head-&gt;next=nullptr; // 将当前节点的下一个置空, 主要是处理新的尾节点, 其他节点的next会在递归中正确赋值 return P; //返回新的头结点 &#125;&#125;; 217. Contains DuplicateDescription: 判断数组中是否有重复元素Given an array of integers, find if the array contains any duplicates. Your function should return true if any value appears at least twice in the array, and it should return false if every element is distinct. Example 1: Input: [1,2,3,1]Output: trueExample 2: Input: [1,2,3,4]Output: falseExample 3: Input: [1,1,1,3,3,4,3,2,4,2]Output: true 解法一: 暴力时间复杂度: $O(n^2)$, 暴力求解, 双重循环空间复杂度: $O(1)$, 无需额外空间 时间超限, 无法通过 OJ 解法二: 排序+遍历时间复杂度: $O(nlogn)$, 先排序, 然后遍历看是否有相邻元素相等, 即 $O(nlogn + n)$, 也就是 $O(nlogn)$.空间复杂度: $O(1)$, 基于不同的排序算法决定, 使用堆排序则为 $O(1)$. 解法三: unordered_set(哈希)时间复杂度: $O(n)$, 遍历一遍数组, 在 unordered_set 中查询的复杂度为常数空间复杂度: $O(n)$, unordered_set占用额外空间 12345678910111213class Solution &#123;public: bool containsDuplicate(vector&lt;int&gt;&amp; nums) &#123; std::unordered_set&lt;int&gt; nums_set; for(auto num : nums)&#123; if(nums_set.find(num) == nums_set.end()) nums_set.insert(num); else return true; &#125; return false; &#125;&#125;; 234. Palindrome Linked ListDescription: 回文链表判断Given a singly linked list, determine if it is a palindrome. Example 1:12Input: 1-&gt;2Output: false Example 2:12Input: 1-&gt;2-&gt;2-&gt;1Output: true Follow up:Could you do it in O(n) time and O(1) space? 解法一: 借助辅助数组时间复杂度: $O(n)$, 两次遍历空间复杂度: $O(n)$, 额外数组 最简单的做法就是遍历链表, 将其转换成一个可随机访问的数组, 然后进行回文串的判断. 解法二: 不借助辅助数组时间复杂度: $O(n)$空间复杂度: $O(1)$ 先利用两个指针变量slow和fast找到链表的中点(slow每次走一步, fast每次走两步), 然后将后半段逆置, 接着将前半段和后半段进行比较. 最后根据具体需要将链表后半段复原. (在实际工作中, 不存在 $O(1)$ 空间复杂度的解法, 因为通常情况下是不允许修改链表的值的). 不复原链表: 12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* node) &#123; ListNode* prev = nullptr; while(node != nullptr) &#123; auto tmp = node-&gt;next; node-&gt;next = prev; prev = node; node = tmp; &#125; return prev; &#125; bool isPalindrome(ListNode* head) &#123; ListNode* fast = head; ListNode* slow = head; while (fast != nullptr &amp;&amp; fast-&gt;next != nullptr) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; if (fast != nullptr) &#123; // 奇数个节点, 始终令slow指向后半段的开始节点 slow = slow-&gt;next; &#125; slow = reverseList(slow); // 令slow指向后半段逆置后的开始节点 fast = head; while(slow != nullptr &amp;&amp; fast-&gt;val == slow-&gt;val) &#123; fast = fast-&gt;next; slow = slow-&gt;next; &#125; return slow == nullptr ? true : false; &#125;&#125;; 复原链表: 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;public: bool isPalindrome(ListNode* head) &#123; if(head==nullptr || head-&gt;next==nullptr) return true; ListNode* slow = head; ListNode* fast = head-&gt;next; while(fast!=nullptr &amp;&amp; fast-&gt;next!=nullptr)&#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; ListNode *rail = slow; // 记录前半段的最后一个节点, 以便复原链表 slow = slow-&gt;next; // 令slow指向回文串后半段的第一个节点 ListNode *rhead = reverseList(slow); // 令fast 指向回文串后半段逆置后的连接头(奇数回文串时, 中间的节点算作前半段) slow = head; fast = rhead; bool res=true; while(slow!=nullptr &amp;&amp; fast!=nullptr)&#123; if(slow-&gt;val != fast-&gt;val)&#123; res = false; break; &#125; slow = slow-&gt;next; fast = fast-&gt;next; &#125; rail-&gt;next = reverseList(rhead); // 复原链表 return res; &#125; ListNode *reverseList(ListNode *cur)&#123; ListNode* next = cur-&gt;next; ListNode* pre = nullptr; while(cur != nullptr)&#123; cur-&gt;next = pre; pre = cur; cur = next; if(next!=nullptr) next = next-&gt;next; &#125; return pre; &#125;&#125;; 237. Delete Node in a Linked ListDescription: 删除链表中的某个节点Write a function to delete a node (except the tail) in a singly linked list, given only access to that node. Given linked list — head = [4,5,1,9], which looks like following:14 -&gt; 5 -&gt; 1 -&gt; 9 Example 1:123Input: head = [4,5,1,9], node = 5Output: [4,1,9]Explanation: You are given the second node with value 5, the linked list should become 4 -&gt; 1 -&gt; 9 after calling your function. Example 2:123Input: head = [4,5,1,9], node = 1Output: [4,5,9]Explanation: You are given the third node with value 1, the linked list should become 4 -&gt; 5 -&gt; 9 after calling your function. Note:The linked list will have at least two elements.All of the nodes’ values will be unique.The given node will not be the tail and it will always be a valid node of the linked list.Do not return anything from your function. 解法一: 复制+跳过节点时间复杂度: $O(1)$空间复杂度: $O(1)$ 这是一道非常取巧(也可以说是投机)的题, 题目给的参数是需要删除的节点指针, 同时该指针不会是最后一个节点, 因此我们可以利用先复制, 再跳过的方式实现删除. 123456789101112131415c/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: void deleteNode(ListNode* node) &#123; node-&gt;val = node-&gt;next-&gt;val; // 题目假设node 不是最后一个节点 node-&gt;next = node-&gt;next-&gt;next; // 跳过node节点 &#125;&#125;; 242. Valid Anagram变位词: 改变某个词或短语的字母顺序后构成的新词或短语 Description: 判断变位词Given two strings s and t , write a function to determine if t is an anagram of s. Example 1:12Input: s = &quot;anagram&quot;, t = &quot;nagaram&quot;Output: true Example 2:12Input: s = &quot;rat&quot;, t = &quot;car&quot;Output: false Note:You may assume the string contains only lowercase alphabets. Follow up:What if the inputs contain unicode characters? How would you adapt your solution to such case? 解法一: 排序时间复杂度: $O(nlogn)$, 对两个字符串进行排序空间复杂度: $O(1)$, 可以原地排序, 不占用额外空间 对两个字符串排序后, 看是否相等. 该方式可以无缝的解决 Follow up 中的问题. 解法二: 哈希表时间复杂度: $O(n1+n2)$, $n1$, $n2$ 分别为两个字符串的长度, 二者必须相等, 否则一定不是变位词.空间复杂度: $O(1)$, 哈希表的 size 为 26, 常数级 构造一个字母哈希表, 先统计 12345678910111213141516171819202122class Solution &#123;public: bool isAnagram(string s, string t) &#123; if(s.size() != t.size()) return false; int ana_hash[26]=&#123;0&#125;; for(auto c : s)&#123; ana_hash[c-'a']++; &#125; for(auto c : t)&#123; ana_hash[c-'a']--; if (ana_hash[c-'a'] &lt; 0) return false; &#125; /* 因为长度相等, 所以一旦不是异构词, 就一定会出现某个哈希位上的值小于0的情况, 因此无需在这里再次判断 for(auto i : ana_hash)&#123; if(i != 0) return false; &#125; */ return true; &#125;&#125;; 解答 Follow up:用 unordered_map 来代替数组哈希表, 此时复杂度与输入的字符种类数目有关, 哈希表的空间复杂度变成 $O(n)$. 268. Missing NumberDescription: 缺失的数字Given an array containing n distinct numbers taken from 0, 1, 2, …, n, find the one that is missing from the array. Example 1: Input: [3,0,1]Output: 2Example 2: Input: [9,6,4,2,3,5,7,0,1]Output: 8Note:Your algorithm should run in linear runtime complexity. Could you implement it using only constant extra space complexity? 解法一: 排序时间复杂度: $O(nlogn)$空间复杂度: $O(1)$ 或 $O(n)$ 解法二: 哈希表时间复杂度: $O(n)$, 两次遍历, 第一次构建哈希, 第二次查询缺失数字空间复杂度: $O(n)$, 哈希表所占空间 另一种解法: 用下表做哈希, 将数字放置在与下标相同的位置上, 最终放错位置的元素的下标就是缺失的数字, 如果位置都正确, 则缺失 n. 复杂度与哈希表相同, 代码实现如下: 12345678910111213141516171819class Solution &#123;public: int missingNumber(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); for (int i = 0; i &lt; n; ) &#123; if (i != nums[i] &amp;&amp; nums[i] &lt; n) &#123; std::swap(nums[i], nums[nums[i]]); &#125; else &#123; i++; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if (i != nums[i]) &#123; return i; &#125; &#125; return n; &#125;&#125;; 解法三: 异或时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$, 无需额外空间 因为题目是从 0, 1, 2, ..., n 共 $n+1$ 个数字中选出了 $n$ 个不相同的数字, 因此, 如果将 $n+1$ 大小的数组和 $n$ 大小的数组合并成一个大数组, 那么在大数组中, 除了那个缺失的数字以外, 所有的数字都恰好出现了两次, 因此题目变成了求数组中出现一次的唯一数字, 此时可以利用异或在 $O(n)$ 时间复杂度内解决. 该解法还可以解决丢失两个数字, 丢失三个数字的情况, 具体可参考用异或解决奇数偶数数字的问题. 1234567891011class Solution &#123;public: int missingNumber(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int res = n; for(int i=0; i&lt;n; i++)&#123; res = res ^ i ^ nums[i]; &#125; return res; &#125;&#125;; 解法四: 高斯求和公式时间复杂度: $O(n)$, 一次遍历空间复杂度: $O(1)$, 无需任何额外空间 前 $n$ 项和的求和公式为: $1+2+3+\cdots+n = \frac{(n+1)n}{2}$因此, 我们只需要计算出当前数组的和, 然后在计算当前和与高斯和之间的差即可. 1234567891011class Solution &#123;public: int missingNumber(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int gauss_sum = n*(n+1)/2; int sum = 0; for(auto num : nums) sum += num; return gauss_sum - sum; &#125;&#125;; 283. Move ZeroesDescription: 将 0 移动到最后, 保持其他元素相对位置不变Given an array nums, write a function to move all 0’s to the end of it while maintaining the relative order of the non-zero elements. Example: Input: [0,1,0,3,12]Output: [1,3,12,0,0]Note: You must do this in-place without making a copy of the array.Minimize the total number of operations. 解法一: 交换法时间复杂度: $O(n)$空间复杂度: $O(1)$, 无需额外空间 利用交换将不符合要求的元素交换, 具体做法如下: 令 i 指向第一个 0 元素; 令 j 指向 i 之后的第一个非 0 元素; (注意 j 必须在 i 的后面才能执行交换) 交换 i 和 j 指向的元素, 更新 i 和 j 的值. 重复以上步骤, 直到 j 越界. 1234567891011121314151617class Solution &#123;public: void moveZeroes(vector&lt;int&gt;&amp; nums) &#123; int i = 0, j = 0; while(nums[i]!=0) i++; j = i; while(nums[j]==0) j++; while(j &lt; nums.size())&#123; std::swap(nums[i], nums[j]); while(nums[i]!=0) i++; j = i; while(nums[j]==0) j++; &#125; return; &#125;&#125;; 解法二: 更简洁的交换法时间复杂度: $O(n)$空间复杂度: $O(1)$ 这道题可以从另一个角度来理解, 即可以看做是要将所有的非 0 元素保持相对位置不变地移动到数组的前面, 那么我们可以遍历数组, 并用一个变量 i 来记录当前元素之前的非 0 元素的个数, 那么如果当前元素为非 0 元素, 则可以令当前元素与 nums[i] 交换, 同时 i++, 这样便可以同时保证将非 0 元素移动到数组前以及保持相对位置不变两个条件.123456789101112class Solution &#123;public: void moveZeroes(vector&lt;int&gt;&amp; nums) &#123; for(int i=0, j=0; j&lt;nums.size(); j++)&#123; if(nums[j] != 0)&#123; std::swap(nums[i], nums[j]); i++; // 非0元素个数加1 &#125; &#125; return; &#125;&#125;; 326. Power of ThreeDescription: 三的幂次Given an integer, write a function to determine if it is a power of three. Example 1:12Input: 27Output: true Example 2:12Input: 0Output: false Example 3:12Input: 9Output: true Example 4:12Input: 45Output: false 解法一: 自下而上(超时)时间复杂度: $O(logn)$, 计算3的幂次, 总共需要计算 $log_3n$ 次空间复杂度: $O(1)$ 该方法从 3 开始, 逐渐计算 3 的幂次, 但是由于对于任何数都要计算 $log3n$ 次, 故当数很大时会超时 12345678910class Solution &#123;public: bool isPowerOfThree(int n) &#123; int pow = 1; while(pow &lt; n)&#123; pow = pow*3; &#125; return pow==n ? true : false; &#125;&#125;; 解法二: 自上而下时间复杂度: $O(logn)$, 利用除法判断是否能整除 3, 当不能整除时, 可以提前退出, 起到剪枝效果, 最多需要计算 $log_3n$ 次空间复杂度: $O(1)$ 解法一采用的自下而上的乘法方法对于任何的数字都需要进行 $log_3n$ 次乘法才能判断是否为 3 的幂次, 这显然是不需要的, 我们只需要利用除法, 不断判断是否能被 3 整除即可, 一旦发现不能整除, 则肯定不是 3 的幂次, 可提前退出, 代码如下: 12345678910class Solution &#123;public: bool isPowerOfThree(int n) &#123; if(n&lt;1) return false; while (n%3 == 0)&#123; n /= 3; &#125; return n==1; &#125;&#125;; 解法三: 进制转换(不使用循环或迭代)十进制的 pow 形式为: 10, 100, 1000 (分别代表十, 一百, 一千)二进制的 pow 形式为: 10, 100, 1000 (分别代表二, 四, 八)因此我们可以推出三进制的形式为: 10, 100, 1000 (分别代表三, 九, 二十七) 故此, 我们可以将十进制先转换成三进制, 然后判断三进制形式是否首位为一, 其他位均为零, 如果满足, 则说明当前的数字是三的幂次. 该方法不需要循环和迭代(实际上在转换的过程仍然使用了循环和迭代). 12 344. Reverse StringDescription: 反转字符串Write a function that takes a string as input and returns the string reversed. Example 1:12Input: &quot;hello&quot;Output: &quot;olleh&quot; Example 2:12Input: &quot;A man, a plan, a canal: Panama&quot;Output: &quot;amanaP :lanac a ,nalp a ,nam A&quot; 解法一: 使用 reverse 函数时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567class Solution &#123;public: string reverseString(string s) &#123; std::reverse(s.begin(), s.end()); return s; &#125;&#125;; 解法二: 基于 swap时间复杂度: $O(n)$空间复杂度: $O(1)$ 12345678910class Solution &#123;public: string reverseString(string s) &#123; int len = s.size(); for(int i=0; i&lt;len/2; i++)&#123; std::swap(s[i], s[len-1-i]); &#125; return s; &#125;&#125;; 350. Intersection of Two Arrays IIDescription: 求两数组的交集Given two arrays, write a function to compute their intersection. Example 1:12Input: nums1 = [1,2,2,1], nums2 = [2,2]Output: [2,2] Example 2:12Input: nums1 = [4,9,5], nums2 = [9,4,9,8,4]Output: [4,9] Note:Each element in the result should appear as many times as it shows in both arrays.The result can be in any order. Follow up: What if the given array is already sorted? How would you optimize your algorithm? What if nums1’s size is small compared to nums2’s size? Which algorithm is better? What if elements of nums2 are stored on disk, and the memory is limited such that you cannot load all elements into the memory at once? 解法一: 哈希时间复杂度: $O(n1+n2)$, 构建哈希表和查询哈希表, 需要将两数组的元素都遍历一次空间复杂度: $O(n1)$, 用 nums1 构建哈希表, 然后用 nums2 进行查询.(也可以多做一步判断, 选择用数组长度较小数组来构建哈希表, 减少空间复杂度) 用一个数组构建哈希表, 哈希表的键为元素值, 哈希表的值为元素的出现次数, 然后用另一个数组的元素对哈希表进行查询, 如果能找到, 则将该元素加入结果数组 res, 并将哈希表对应键的值减一, 如果减到零, 则删除该键. 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; unordered_map&lt;int, int&gt; hash; // 构建哈希 for(auto &amp;num : nums1) hash[num]++; vector&lt;int&gt; res; for(auto &amp;num : nums2)&#123; if(hash.find(num) != hash.end())&#123; res.push_back(num); hash[num]--; if(hash[num]==0) hash.erase(num); // 当键对应值为0时, 将该键擦除 &#125; &#125; return res; &#125;&#125;; 解法二: 排序时间复杂度: $O(n1logn1 + n2logn2 + n1 + n2) = max(n1, n2)\times log(max(n1, n2))$空间复杂度: $O(1)$ 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; std::sort(nums1.begin(), nums1.end()); std::sort(nums2.begin(), nums2.end()); int i1=0, i2=0; // 设置两个指示变量 vector&lt;int&gt; res; while(i1&lt;nums1.size() &amp;&amp; i2&lt;nums2.size())&#123; if(nums1[i1] == nums2[i2])&#123; res.push_back(nums1[i1]); i1++; i2++; &#125;else if(nums1[i1] &lt; nums2[i2]) i1++; else i2++; &#125; return res; &#125;&#125;; Follow up当给定数组已经有序时可以设置两个指示变量, 分别指向两个数组, 然后按照指向元素的大小关系进行判断并递进, 这样, 时间复杂度为 $O(n1+n2)$, 空间复杂度为 $O(1)$, 代码可见解法二. 当 nums1 远远小于 nums2 时正如前面所说, 选用元素数量较少的数组来构建哈希表, 可以降低空间复杂度 如果 nums2 存放在磁盘上, 同时内存不足以加载整个 nums2 数组将 nums2 分片, 逐个求交集, 最后再合并 371. Sum of Two IntegersDescription: 不用加减乘除做加法Calculate the sum of two integers a and b, but you are not allowed to use the operator + and -. Example 1:12Input: a = 1, b = 2Output: 3 Example 2:12Input: a = -2, b = 3Output: 1 解法一: 位操作(递归)对于两个数相加, 例如 759+674, 在计算机中我们可以按照如下步骤求解: 不考虑进位, 相加得到 323; 只考虑进位, 进位为 1110; 将上面两个数字相加, 得到 1433, 即为最终结果 因此, 我们可以用 异或 求得不考虑进位的加, 用 与操作 来得到当前数字的进位, 由于进位与数字相加后, 有可能产生新的进位, 所以我们还要假设将新的进位加上, 直到进位位为0, 此时可以此时返回当前的和, 代码如下所示 123456789class Solution &#123;public: int getSum(int a, int b) &#123; if(b==0) return a ; // 如果进位为0, 则可直接返回 int sum = a ^ b; // 计算不带进位的加法 int carry = (a &amp; b) &lt;&lt; 1; // 计算进位 return getSum(sum, carry); // 结合并返回 &#125;&#125;; 上面的代码可以简化成一行: 123456class Solution &#123;public: int getSum(int a, int b) &#123; return b==0 ? a : getSum(a^b, (a&amp;b)&lt;&lt;1); &#125; &#125;; 解法二: 位操作(迭代)思路和解法一相同, 只不过写成了迭代的形式 1234567891011class Solution &#123;public: int getSum(int a, int b) &#123; while(b!=0)&#123; int tmp = a ^ b; // 不考虑进位的加 b = (a&amp;b) &lt;&lt; 1; // 进位 a = tmp; &#125; return a; &#125; &#125;; 387. First Unique Character in a StringDescription: 寻找字符串中的首个不重复字符Given a string, find the first non-repeating character in it and return it’s index. If it doesn’t exist, return -1. Examples:12345s = &quot;leetcode&quot;return 0.s = &quot;loveleetcode&quot;,return 2. Note: You may assume the string contain only lowercase letters. 解法一: 哈希表时间复杂度: $O(n+n)=O(n)$, 第一个 $n$ 用于建立哈希表, 第二个 $n$ 用于查询首个出现次数为 1 的字符, $n$ 为字符串的长度空间复杂度: $O(26)$, 哈希表的大小为字符集的大小 26 (如果是 unicode 字符, 就为 256). 遍历两边字符串, 第一遍构建哈希表, 第二遍按照字符串序列查询, 遇到值 1 的字符出现时, 就将其下标返回 12345678910111213class Solution &#123;public: int firstUniqChar(string s) &#123; unordered_map&lt;char, int&gt; hash; for(auto c : s)&#123; hash[c]++; &#125; for(int i=0; i&lt;s.size(); i++)&#123; if(hash[s[i]]==1) return i; &#125; return -1; &#125;&#125;; 412. Fizz BuzzDescription: 输出指定字符串Write a program that outputs the string representation of numbers from 1 to n. But for multiples of three it should output “Fizz” instead of the number and for the multiples of five output “Buzz”. For numbers which are multiples of both three and five output “FizzBuzz”. Example:1234567891011121314151617181920n = 15,Return:[ &quot;1&quot;, &quot;2&quot;, &quot;Fizz&quot;, &quot;4&quot;, &quot;Buzz&quot;, &quot;Fizz&quot;, &quot;7&quot;, &quot;8&quot;, &quot;Fizz&quot;, &quot;Buzz&quot;, &quot;11&quot;, &quot;Fizz&quot;, &quot;13&quot;, &quot;14&quot;, &quot;FizzBuzz&quot;] 解法一: 条件判断直接输出时间复杂度: $O(n)$空间复杂度: $O(1)$ 1234567891011121314151617class Solution &#123;public: vector&lt;string&gt; fizzBuzz(int n) &#123; vector&lt;string&gt; res; for(int i=1; i&lt;=n; i++)&#123; if(i%15==0) res.push_back("FizzBuzz"); else if(i%5==0) res.push_back("Buzz"); else if(i%3==0) res.push_back("Fizz"); else res.push_back(std::to_string(i)); &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反向传播算法完整推导]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95%E5%AE%8C%E6%95%B4%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[链式法则神经网络计算过程对于神经网络中的单个神经元来说, 若输入信号为向量 $\vec x=(x_1, x_2, x_3, x_4, x_5)$ , 该层的权重为 $\vec w = (w_1, w_2, w_3, w_4, w_5)$, 偏置项为 $b$ , 那么该层的输出就为(其中$f$为激活函数): y= f(\sum_{i=1}^{n}w_i x_i +b)化简成向量形式($\vec w , \vec x$均为列向量)为: y = f(\vec w ^T \vec x +b)对于多层网络来说, 如下图所示 第一层为输入层, 神经元数量对应原始数据维数, 这一层不对数据进行输出, 直接输出 第二层为隐藏层, 可以有多个隐藏层, 每层神经元数量为中间特征维数(一般自定), 每层都具有一个权重矩阵, 将输入信号与权重矩阵做点乘运算, 加上偏置量以后按激活函数输出 第三层为输出层, 同样有一个权重矩阵, 若用于分类, 则神经元数量等于要分类的类别数 如果激活函数使用sigmoid函数, 则第二层和第三层的输出分别为(第一层输出为原始数据): 符号说明: $x$ : 向量 $x$ $x_i$ : 向量 $x$ 的第 $i$ 项 $x^{(i)}$ : 第 $i$ 个样本向量 $x_j^{(i)} : 第 $i$ 个样本向量中的 第 $j$ 项 几个重要结论 条件说明 说明及问题 结论 给定如下线性映射函数: $u = W x$ 其中 $x$ 是 $n$ 维向量, $W$ 是 $m\times n$ 的矩阵, $u$ 是 $m$维向量, 假设存在函数 $f(u)$ , 试求 $\nabla _w f$ 及 $\nabla _x f$ 因为 $w_{ij}$ 只与 $u_i, x_j$ 有关(画出矩阵相乘示意图即可), 所以有: $\frac{\partial f}{\partial w_{ij}} = \sum_{k=1}^{m} \frac{\partial f}{\partial u_k} \frac{\partial u_k}{\partial w_{ij}} = \sum_{k=1}^{m} \Big( \frac{\partial f}{\partial u_k} \frac{\partial \sum_{l=1}^{n} (w_{kl} x_l)}{\partial w_{ij}}\Big) = \frac{\partial f}{\partial u_i} \frac{\partial \sum_{l=1}^{n}(w_{il} x_l)} {\partial w_{ij}} = \frac {\partial f}{\partial u_i} x_j$ 上式写成矩阵形式为: $\nabla _W f = (\nabla _u f) x^T$ 因为 $x_i$与每一个 $u_k$ 都有关, 所以可得: $\frac{\partial f}{x_i} = \sum_{k=1}^{m} \frac{\partial f}{\partial u_k} \frac{\partial u_k}{\partial x_i} = \sum_{k=1}^{m} \Big( \frac{\partial f}{u_k} \frac{\partial \sum_{l=1}^{n} w_{kl} x_l}{\partial x_i} \Big)= \sum_{k=1}^{m} \Big( \frac{\partial f}{u_k} w_{ki} \Big) = [w_{1i}, w_{2i},…, w_{mi}]\left[ \begin{matrix} \frac{\partial f}{u_1} \\ \frac{\partial f}{u_2} \\ … \\ \frac{\partial f}{u_2} \end{matrix} \right]$ 上式写成矩阵形式为: $\nabla _x f = W^T \nabla _u f$ 给定如下向量到向量的映射: $z=g(u)$ 写成分量形式为: $z_i = g(u_i)$ 在这里, 每个 $z_i$ 只和 $x_i$ 有关, 且每个分量采用了相同的映射函数$g$ 假设存在函数 $f(z)$, 试求 $\nabla _u f$ $\frac{\partial f}{\partial u_i} = \frac{\partial f}{\partial z_i} \frac{\partial z_i}{\partial u_i} = \frac{\partial f}{\partial z_i} g’(u_i)$ $\nabla _u f = \nabla _z f \odot g’(u)$ 给定下面的复合函数 # 推导过程说明 详细推导 简洁推导 反向传播中的一些特殊环节RuLe激活函数的导数ReLU 激活函数的公式定义如下: ReLu(x) = \begin{cases} x, & x > 0 \\ 0, & x\le 0 \end{cases}可以看出, RuLu函数在 $x=0$ 处是不可微的, 为了解决这个问题, 在深度学习框架中, 往往会将其在 $x=0$ 处的导数置为0, 如下所示: ReLu'(x) = \begin{cases} 1, & x > 0 \\ 0, & x\le 0 \end{cases}Pooling池化层的反向梯度传播CNN网络中另外一个不可导的环节就是Pooling层的池化操作, 因为Pooling操作会使得feature map的尺寸发生变化. 解决这个问题的方法就是把一个该层某个位置的梯度反向传播到前一层所有与这个位置相关联的位置. 这是需要 保证传递的梯度总和不变. max pooling mean pooling Referencehttps://zhuanlan.zhihu.com/p/39195266 https://zhuanlan.zhihu.com/pytlab]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xml.etree.ElementTree 处理 XML 格式数据]]></title>
    <url>%2Fz_post%2FPython-XML%2F</url>
    <content type="text"><![CDATA[ElementTree生来就是为了处理XML, 它在Python标准库中有两种实现：一种是纯Python实现的, 如xml.etree.ElementTree, 另一种是速度快一点的xml.etree.cElementTree. 注意：尽量使用C语言实现的那种, 因为它速度更快, 而且消耗的内存更少. a. 遍历根节点的下一层 b. 下标访问各个标签、属性、文本 c. 查找root下的指定标签 d. 遍历XML文件 e. 修改XML文件 导入包1234try: import xml.etree.cElementTree as ETexcept: import xml.etree.ElementTree as ET 解析 xml 文件12345678xmlFilePath = os.path.abspath('test.xml')try: tree = ET.parse(xmlFilePath) # 或者 tree = ET.ElementTree(xmlFilePath) root = tree.getroot() # 获取根节点except Exception as e: print('parse xml failed!') sys.exit() 逐层遍历123456789101112print(root.tag, root.attrib, root.text)for child in root: print(child.tag, child.attrib, child.text)# 递归遍历全部:def traverseXml(element): if len(element) &gt; 0: # 叶节点的len为0 for child in element: print(child.tag, child.attrib) traverseXml(child)traverseXml(root) 根据签名查找需要的标签12item_lists = root.findall('item') # 只能找到儿子, 不能找到孙子, 返回的是儿子们组成的列表item = root.find('item') # 返回的是单个的儿子 获取叶子节点的值当访问到叶子节点时, 就可以利用 text 来得到相应的标签了 12345678910obj_bbox_setobjects = root.findall('object')for obj in objects: obj_name = obj.find('name').text bbox = obj.find('bndbox') x1 = int(bbox.find('xmin').text) y1 = int(bbox.find('ymin').text) x2 = int(bbox.find('xmax').text) y2 = int(bbox.find('ymax').text) obj_bbox_set.append([x1, x2, y1, y2, obj_name]) 创建 XML 类型的数据文件先创建 root Element, 然后创建 SubElement, 最后将 root 传入 ElementTree(element), 创建 tree, 调用 tree.write() 方法写入文件 1234567891011121314151617181920212223import xml.etree.ElementTree as ETdef subElement(root, tag, text): ele = ET.SubElement(root, tag) ele.text = text ele.tail = '\n'root = ET.Element("note")to = root.makeelement("to", &#123;&#125;)to.text = "peter"to.tail = '\n'root.append(to)subElement(root, "from", "marry")subElement(root, "heading", "Reminder")subElement(root, "body", "Don't forget the meeting!")tree = ET.ElementTree(root)tree.write("note.xml", encoding="utf-8", xml_declaration=True) 效果:123456&lt;?xml version=&apos;1.0&apos; encoding=&apos;utf-8&apos;?&gt;&lt;note&gt;&lt;to&gt;peter&lt;/to&gt;&lt;from&gt;marry&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Don&apos;t forget the meeting!&lt;/body&gt;&lt;/note&gt;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ResNet (CVPR, 2016)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-ResNet-CVPR2016%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/malefactor/article/details/67637785 文章: Deep Residual Learning for Image Recognition作者: Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun备注: MSRA, Best Paper 核心亮点本文突破了传统的卷积神经网络结构, 首次提出了残差网络, 并成功的将网络的深度提升到了一个很高的层级上, 同时解决了深层网络的模型退化问题, 对整个深度学习领域产生了重大影响. 提出动机首先文章提出了一个假设:有一个L层的深度神经网络, 如果我们在上面加入一层, 直观来讲得到的L+1层深度神经网络的效果应该至少不会比L层的差. 因为可以简单的学习出最后一层为前一层的恒等映射, 并且其它层参数设置不变.(说明是这种更深的网络是存在是的性能不下降的解的)但是, 通过实验发现, 当网络层数加深时, 网络的性能会下降(说明后面几层网络层没有学习到恒等映射这个解), 也就是所谓的”模型退化”问题, 如图1所示. 观察上述现象后, 作者认为产生模型退化的根本原因很大程度上也许不在于过拟合, 而在于梯度消失问题. 为了解决模型退化问题, 作者基于以上假设, 提出了深度残差学习框架, 没有直接堆叠网络层来 fit 期望的映射函数, 而是选择让这些网络层来 fit 一个残差映射. 也就是说, 如果我们期望得到的映射函数为 $H(x)$, 那么我们不是通过堆叠网络来直接学习这个映射函数, 而是学习对应的残差函数: $F(x):=H(x)-x$. 那么, 原始的映射函数就可以通过 $F(x)+x$ 得到(如图2所示). 我们假设这个残差映射比原始的映射函数更容易学习和优化. 极端情况下, 如果一个恒等映射是最优的, 那么相对于使得网络层学习到 $H(x)=x$ 这个映射关系, 它应该更加容易使得残差部分 $F(x) \rightarrow 0$.(原因可以看后文) 残差学习(Residual Learning)首先, 我们假设 $H(x)$ 就是几层网络层堆叠后希望学习到的映射函数(underlying mapping), 而 $x$ 代表了这几层网络的输入. 在神经网络中, 我们通常假设几层非线性的网络相堆叠可以渐进的拟合一个复杂函数, 那我们也可以等价的假设这些网络层可以渐进的拟合对应的残差函数: $H(x) - x$(姑且假设 $H(x)$ 和 $x$ 维度相同). 因此, 我们不需要令网络层来近似函数 $H(x)$, 相反, 我们希望这些网络层能够近似函数 $F(x):=H(x) - x$. 原始的映射函数也可以通过 $F(x)+x$ 得到.这种残差定义方式是收到了图1中的违反直觉的现象的启发而得出的. 正如我们之前所说的, 如果我们仅仅在模型中添加了一些恒等连接层, 那么得到的新的更深的模型的精度应该至少不会比之前的差, 但是模型还是出现了退化问题, 这说明很有可能是模型在学习的时候, 很难直接通过多层的非线性网络层学习到这种恒等映射. 然而, 通过本文的残差学习定义, 如果恒等连接层是最优的, 那么模型在学习时可以简单的令非线性的网络层函数 $F(x)$ 为0, 以此来使模型学习到恒等映射.在实际情况中, 往往不太可能使恒等映射是最优的, 但是本文提出的残差方法可以帮助模型提前为解决问题提供便利(precondition the problem). 核心思想为: 如果最优的映射函数相对于 zero mapping 更接近恒等映射, 那么相对于学习一个新的映射函数, 应该更容易的找到与恒等映射相关的扰动. 在实验中(图7), 我们发现这些学习后的残差函数大多具有很小的响应(标准差 standard deviations), 这说明本文的恒等映射提供了一种合理的先验条件(preconditioning). 恒等短接(identity shortcut connection)ResNet提出的恒等短接用于直接跳过一个或多个层, 以便让离输入层近的网络更加靠近输出层, 残差块的结构如下图所示: 在本文中, 我们可以将一个 building block 定义成下面的形式: y = F(x, \{W_i\}) + x \tag 1上式中, $x,y$ 分别代表着这个 block 的输入和输出, 而函数 $F(x, \{W_i\})$ 代表着需要学习的残差映射. 以图2为例, 该残差块具有两个网络层, 因此 $F=W_2 \sigma (W_1 x)$, 其中, $\sigma$ 代表 ReLU, 同时为了简化表示, 忽略了偏向量. 操作 $F + x$ 是通过 element-wise addition 的短接实现的. 我们采用 $\sigma(y)$ 作为本残差模块的输出. 可以看出, 恒等短接的方式有一个好处就是既不会引入任何额外参数, 也不会带来计算成本. 这样一来我们就可以很公平的与其他卷积网络模型在各种参数上进行对比.注意, 公式(1)中 $x$ 和 $F$ 的维度必须相同. 如果不同的话(即 changing the input/output channels), 我们可以利用一个线性投影矩阵 $W_s$ 来让维度匹配: y = F(x, \{W_i\}) + W_s x \tag 2我们也在可以在公式(1)用添加方阵 $W_s$(不改变维度). 但是通过实验我们发现, 当维度相同时, 直接相加就已经足够了, 因此我们只会在维度不同时才使用矩阵 $W_s$.函数 $F$ 的形式是灵活的, 本文中包含了两种形式(如图5, 分别为两层和三层). 如果只使用一层的残差模块, 这近乎于是普通的线性层了, 貌似并不能获得什么提升.上面的讨论为了方便我们使用的是全连接层, 但是残差模块同样可以用于卷积层, 在两个 feature maps 之间 channel by channel 的执行 element-wise addition. 网络结构(Network Architectures)我们通过实验验证了多种不同的 plain/residual 网络, 并且观察到了相同的现象, 下面我们介绍两种网络以供讨论. Plain Network如图3中间所示, 我们对 VGG-19 进行扩展, 得到了 plain baseline. 图中的卷积层大多为 3×3 大小, 并且遵守两条设计规则: 1), 对于输入和输出的 feature map 具有相同的 size 时, 卷积层也和设定为相同数量的卷积核(即当输出不改变尺寸时, 也不应改变通道数); 2), 如果 feature map size 减半, 那么卷积核的数量会变为双倍, 以此来保持每一层的时间复杂度. 我们在执行 downsampling 时, 是通过利用 stride=2 的卷积层实现的(即没有用 max pooling 层). 网络的最后会接一个全局平均池化层和一个1000路的 softmax 全连接层. 图3中的网络总共的层数为34层.值得注意的是: ResNet 虽然比 VGGNet 的层深更深, 但是却拥有更低的复杂度, VGG-19 的 FLOPs (multiply-adds) 次数约为 19.6 billion, ResNet 的 FLOPs 如表1所示.(复杂度低的原因主要是去掉了两次全连接层) 残差网络(Residual Network)基于上面的 Plain 网络, 我们向其中添加 shortcut connections(如图3右侧所示), 如此, 便可以将网络转换成残差网络(residual network). 当残差模块的输入和输出的维度相同时(实线), 就是可直接使用公式(1)来建立短接. 当输入和输出的维度不同时(虚线), 我们考虑了两中方法: (A), shorcut 仍然通过恒等连接来实现, 对于升高的那些维度, 直接用0填充, 这个方法不会引入额外的参数; (B), 利用公式(2)的矩阵来使维度匹配(利用1×1卷积实现). 另外, 对于输入输出的特征图谱 size 不同的情况, 我们通过将卷积层的 stride 设置为2来实现. 实现细节(Implementation)training: scale augmentation(image 的最短边被随机放缩到256或480) horizaontal flip 224 random crop per-pixel mean subtracted 标准color augmentation 在每一个卷积层之后, 激活层之前, 都是用了BN 使用了msra初始化方法. 训练时没有使用预训练模型(train from scratch) SGD batch size = 256 lr 从0.1开始,每当 error 停滞(plateaus)时, 缩小1/10 总训练迭代次数为 $60\times 10^4$ weight decay 为 0.0001 momentum 为 0.9 没有使用dropout testing: 10-crop multi-scales: {224, 256, 384, 480, 640} 实验(Experiments)图像分类(Image Classification)不同层的模型结构和参数如表1所示(both plain and residual). 表2的数据显示出较深的34层的 plain 网络相比于它的 residual 版本, 具有更高的错误率. Plain Network为了揭示其中的原因, 我们比较了这两个网络在训练/验证过程中错误率如图4所示. 我们观察到, 对于 plain 版本的网络, 18层的网络的解空间只是34层网络的解空间的一个子集, 但是更深的34层网络却发生了模型退化的问题. 我们认为造成优化困难的原因不太可能是因为梯度消失问题而产生的. 因为这些 plain network 在每一个卷积层之后的应用了 BN, 这就保证了在前向传播过程中的信号具有非零的方差(which ensures forward propagated signals to have non-zero variances). 同时, 我们也验证了在反向传播过程中梯度值保持着健康的归一化. 所以不论是前向传播过程还是反向传播过程, 都没有出现信号消失的现象.因此, 具体是什么原因导致了 plain network 难以优化还有待讨论(The reason for such opti- mization difficulties will be studied in the future). Residual Network接下来我们评估了 ResNet-18 和 ResNet-34 两个网络, 基本的网络结构和对应的 Plain-18 和 Plain-34 相同, 只是在每一对 3×3 的卷积层之间添加了 shortcut connection. 在第一次对比当中(表2和图4右侧), 我们采用了恒等连接和零填充的短接方式, 因此相对于 plain 版本的网络并没有引入新的参数.从表2和图4中, 我们观察到了三个结论: ResNet-34 比 ResNet-18 的错误率更低(说明找到了解空间中另一个更优的解, 而此时 ResNet-34 的解空间和 Plain-34 的解空间是完全相同的). 更重要的是, ResNet-34 不仅在训练数据集上错误率更低, 在验证集上的错误率也更低, 说明确实找到了一个泛化能力更好的解, 而不是因为过拟合. 图4中的 ResNet 相比于 PlainNet, 错误率更低, 说明了 ResNet 的有效性. 对于错误率相当的 Plain-18 和 ResNet-18, ResNet 的收敛速度更快, 说明残差模块的存在确实可以加快模型的训练速度. 恒等连接与映射连接(Identity / Projection Shortcuts)上面我们讨论了一种 parameter-free 的恒等短接的方式, 接下来我们将研究一下引入参数的映射短接(Projection Shortcuts). 在表3中我们给出了三个选项: (A). 使用恒等映射, 如果需要改变输出维度时, 对增加的维度用0来填充, 不会增加任何参数.(这种就是之前讨论的 parameter-free 的恒等短接) (B). 在输入输出维度一致时使用恒等映射, 不一致时使用矩阵映射以保证维度一致, 增加部分参数. (C). 对所有的block均使用矩阵映射, 大量增加参数 如表3所示, 这三种方式相比于对应的 PlainNet 都可以取得较大的精度提升, 我们可以发现, 在效果上 C&gt;B&gt;A，我们认为这是因为在 A 中的 zero-padded dimensions 实际上并没有进行残差学习. 由于 A/B/C 之间的差距比较小，而线性变换需要引进额外的参数, 因此这是一个可以根据实际问题进行权衡的事情.(通常不要用C, 因为增加的参数较多, 且性能提升并不是很明显). Deeper Bottleneck Architectures 接下来, 我们讨论一下本文在 ImageNet 中使用的更深的网络. 为了取得更快的训练速度, 我们将残差网络的 building block 修改成了 bottleneck building block.(如图5所示, 左右两种 block 的复杂度相同). 其中, 1×1 的卷积层负责降维和升维, 使得 3×3 的卷积层需要处理维度更小.对于 bottleneck 结构来说, parameter-free 的恒等短接尤其重要. 如果用矩阵映射替换了 bottleneck 中的恒等短接, 那么因为 shortcuts 需要处理的维度很高, 使得模型的 size 和时间复杂度都会加倍. 因此, 对于 bottlenect 来说, 选择恒等短接可以大大降低模型复杂度. ResNet-50:把 ResNet-34 中的每一个2层的 building block 换成3层的 bottlenect block. ResNet-101/152:在 conv4 阶段使用更多的 bottleneck block.(ResNet-152 在 conv3 也使用了更多的 bottleneck block). 在表4和表5中, 我们将本文的 ResNet 与目前最好的模型进行了对比. 结果显示本文的 ResNet 具有更高的精度. CIFAR-10 and Analysis表6 图6 图7 表7 表8 表9 表10 表11 表12 表13 表14 简述 ResNet 的原理首先, ResNet 提出了一个直觉上比较合理的假设, 那就是对于一个深度为 $L$ 的神经网络, 如果我们在上面加入一层, 那么新得到的 $L+1$ 层深度的神经网络的性能至少不应该比 $L$ 层的神经网络差. 因为我们可以简单的将新加入的网络层设为前一层的拷贝(通过恒等映射即可实现), 而其他层维持原来的参数即可. 也就是说, $L+1$ 层的神经网络至少存在一个解可以达到 $L$ 层神经网络的性能. 但是, 在实际训练过程中, 我们发现有时候深层的神经网络反而具有更大的训练误差, 根据反向传播原理, 我们有理由认为这种误差是因为深度神经网络的梯度消失问题造成的. ResNet 从这个角度出发, 提出了残差模块作为网络的基本结构. 该模块首先是两层神经网络的简单叠加, 这时输入数据 $x$ 会经过这两个网络层的变换得到 $H(x)$, 在进行反向传播时, 较浅层的网络层相比于较深层的网络层更容易发生梯度消失现象(因为连乘更多). ResNet 的想法也非常直接, 它认为既然较浅层的网络层较难训练, 那么我们就直接将它短接到更深网络层, 这样, 中间被跳过的两层网络需要拟合的目标就不再是最终输出的 $H(x)$, 而是最终输出和输入之间的残差 $F(x)$, 即 $F(x) = H(x) - x$. 这样一来, 如果某一层的输出已经较好的拟合了期望结果, 那么它们的梯度就会被直接传送到两层网络之前, 从而减少了深度神经网络中由于连乘问题导致的梯度消失现象, 进而使得网络有可能拟合到更好的结果上. ResNet 的残差模块分为基本的 ResNet Block 和经过卷积分解的 Bottleneck 两种形式. 对于层数较浅的 ResNet-18 和 ResNet-34 来说, 使用的是基本的 ResNet Block 作为网络的基本单元, 而对于较深的 ResNet-50, 101, 152等, 使用的是经过卷积分解的 Bottleneck 作为网络的基本单元. ResNet 网络的整体结构还是遵循经典的五段式结构, 具体来, 第一段为 Stem 段, 使用了 $7\times 7$ 的传统卷积核, 后面四段是残差模块组成的卷积段, 每一段使用的残差模块的数量都不同一样, 深层残差网络的残差模块主要在导数第二个卷积段大量堆叠. ResNet 中可以使用哪些短接方式基本来说, 有三中选项可以选择 (A). 使用恒等映射, 如果需要改变输出维度时, 对增加的维度用0来填充, 不会增加任何参数.(这种就是之前讨论的 parameter-free 的恒等短接) (B). 在输入输出维度一致时使用恒等映射, 不一致时使用矩阵映射以保证维度一致, 增加部分参数. (C). 对所有的block均使用矩阵映射, 大量增加参数 在效果上, 通常 C&gt;B&gt;A, 我们认为这是因为在 A 中的 zero-padded dimensions 实际上并没有进行残差学习. 但是由于 A/B/C 之间的差距比较小, 而线性变换需要引进额外的参数, 因此这是一个可以根据实际问题进行权衡的事情(通常不要用C, 因为增加的参数较多, 且性能提升并不是很明显).对于 bottleneck 结构来说, parameter-free 的恒等短接尤其重要. 如果用矩阵映射替换了 bottleneck 中的恒等短接, 那么因为 shortcuts 需要处理的维度很高, 使得模型的 size 和时间复杂度都会加倍. 因此, 对于 bottlenect 来说, 选择恒等短接可以大大降低模型复杂度. 如何理解所谓的残差 $F(x)$ 比原始目标 $H(x)$ 更容易优化假设我们要学习一种从输入x到输出H(x)的mapping, 最简单的例子, 假设解空间里的函数只有两个，就是在这两个可能的mapping 函数里面选择一个更好的。如果是非resnet的情况，那么给定 $H(5)＝5.1$ 和 $H(5)＝5.2$ 这两个函数映射, 其对应权重参数分别是 $H(x) = wx = \frac{5.1}{5} x$ 和 $H(x) =w x = \frac{5.2}{5} x$ ，这两个函数的w近似的都近似等于1, 或者说一个 $w$ 是另一个 $w$ 的1.04/1.02＝1.0196倍. 也就是说，如果用sgd来选择参数 $w$ 的话，是容易认为两个 $w$ 很像的(对数据不敏感, 导致训练慢，学错)。但是resnet就不同了，在resnet下，原输入输出数据相当于变成了 $H(5)=0.1$ 和 $H(5)=0.2$, 这两个对应的潜在函数变成了 $F(x)= wx = \frac{0.1}{5} x$ 和 $H(x) = wx = \frac{0.2}{5} x$ , 两个 $w$ 的关系变成了一个 $w$ 是另一个 $w$ 的0.2／0.1 ＝ 2倍，所以 $w$ 的选取对于数据集非常敏感了。 这是基于这个原因，resnet里面的参数 $w$ 会更加”准确”反映数据的细微变化。(因此也更容易学到不同数据的特征) 另一方面, 由于恒等连接的存在, 当我们令学得的 $F(x)=0$ 时, 那么就有 $H(x)=x$, 所以如果我们将残差模块拼接在普通的 vgg 网络之后, 最终的模型性能也不会比 vgg 差, 因为后面几层相当于是一种恒等短接, 也可以认为是为模型的性能做到了一种保底措施. 为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5关于为什么是 $x$ 而不是 $\lambda_i x$,主要是因为如果是 $\lambda_i x$ 的话,梯度里面 就会有一项 $\lambda_i$ 的连乘 $\prod_{i=1}^{L-1}{\lambda_i}$，就是从输出到当前层之间经过的 shortcut上的所有$\lambda_i$相乘，假如$\lambda_i$都大于 1 那经过多层之后就会爆炸，都小于1就会趋向0而引发梯度消失. 具体公式分析可见下面关于”用简单缩放来替代恒等连接”的讨论 ResNet 到底解决了一个什么问题既然可以通过初试化和归一化（BN层）解决梯度弥散或爆炸的问题，那Resnet提出的那条通路是在解决什么问题呢？在He的原文中有提到是解决深层网络的一种模型退化问题，但并未明确说明是什么问题！ 今年2月份有篇文章，正好跟这个问题一样。The Shattered Gradients Problem: If resnets are the answer, then what is the question?大意是神经网络越来越深的时候，反传回来的梯度之间的相关性会越来越差，最后接近白噪声。因为我们知道图像是具备局部相关性的，那其实可以认为梯度也应该具备类似的相关性，这样更新的梯度才有意义，如果梯度接近白噪声，那梯度更新可能根本就是在做随机扰动。有了梯度相关性这个指标之后，作者分析了一系列的结构和激活函数，发现resnet在保持梯度相关性方面很优秀（相关性衰减从 到了 ）。这一点其实也很好理解，从梯度流来看，有一路梯度是保持原样不动地往回传，这部分的相关性是非常强的。 ResNet 残差模块中激活层应该如何放置推荐采用预激活的方式来放置激活层: BN+ReLU+Conv]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[被忽视的Patition算法]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E8%A2%AB%E5%BF%BD%E8%A7%86%E7%9A%84Patition%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[如果你学习过算法，那么肯定听说过快速排序的大名，但是对于快速排序中用到的 partition 算法，你了解的够多吗？或许是快速排序太过于光芒四射，使得我们往往会忽视掉同样重要的 partition 算法。 Partition 可不只用在快速排序中，还可以用于Selection algorithm（在无序数组中寻找第K大的值）中。 Partition实现用 Two Pointers 的思想，保持头尾两个指针向中间扫描，每次在头部找到大于pivot的值，同时在尾部找到小于pivot的值，然后将它们做一个交换，就可以一次把这两个数字放到最终的位置。一种比较明智的写法如下： 123456789101112int partition(vector&lt;int&gt; &amp; arr, int low, int high)&#123; int pivot = arr[low]; while(low&lt;high)&#123; //比较时如果少了等于号,就有可能会陷入死循环,两个重复的数不断交换 while(low&lt;high &amp;&amp; arr[low]&lt;=pivot) low++; arr[high] = arr[low]; while(low&lt;high &amp;&amp; arr[high]&gt;=pivot) high--; arr[low] = arr[high]; &#125; arr[low] = pivot; return low;&#125; 上面的算法虽然没有显式用的swap,但实际上也相当于进行了swap操作,如下图所示: Partition应用快排1234567void quick_sort(vector&lt;int&gt; &amp; arr, int low, int high)&#123; if(low &gt;= high) return; mid = partition(arr,low,high); if(mid&gt;low) quick_sort(arr, low,mid-1); if(mid&lt;high) quick_sort(arr,mid+1, high);&#125; 复杂度:$O(nlogn)$ 寻找无序数组中第K大的值首先用 partition 将数组分为两部分，得到分界点下标 pos，然后分三种情况： pos == k-1，则找到第 K 大的值，arr[pos]； pos &gt; k-1，则第 K 大的值在左边部分的数组。 pos &lt; k-1，则第 K 大的值在右边部分的数组。 123456789101112int find_kth_number(int k)&#123; int low = 0; int high = arr.size()-1; while(low&lt; high)&#123; pos = partition(arr,low,high); if(pos==k-1) return arr[k-1]; else if (pos &lt; k-1) low = pos+1; else high = pos-1; &#125;&#125; 时间复杂度 $O(n)$ 分析:考虑最坏情况下，每次 partition 将数组分为长度为 N-1 和 1 的两部分，然后在长的一边继续寻找第 K 大，此时时间复杂度为 O(N^2 )。不过如果在开始之前将数组进行随机打乱，那么可以尽量避免最坏情况的出现。而在最好情况下，每次将数组均分为长度相同的两半，运行时间 T(N) = N + T(N/2)，时间复杂度是 O(N)。 Partition 进阶接下来先考虑这样一个问题，给定红、白、蓝三种颜色的小球若干个，将其排成一列，使相同颜色的小球相邻，三种颜色先后顺序为红，白，蓝。这就是经典的 Dutch national flag problem。 我们可以针对红，蓝，白三种颜色的球分别计数，然后根据计数结果来重新放球。不过如果我们将问题进一步抽象，也就是说将一个数组按照某个target值分为三部分，使得左边部分的值小于 target，中间部分等于 target，右边部分大于 target，这样就不能再用简单的计数来确定排序后的结果。这时候，就可以用到另一种 partition 算法： three-way-partition 。它的思路稍微复杂一点，用三个指针将数组分为四个部分，通过一次扫描最终将数组分为 &lt;，=，&gt; 的三部分，如下图所示:]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《百面机器学习》]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-Book-%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[第一章 特征工程1. 特征归一化7. 图像数据不足时的处理方法在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题?一个模型的信息来源主要有两个方面: 训练数据中蕴含的信息 模型形成过程中(包括构造, 学习, 推理等), 人们提供的先验信息 当训练数据不足时, 说明模型从原始数据中获取的信息比较少, 这种情况下要想保证模型的效果, 就需要更多的先验信息 先验信息可以作用在模型上, 例如让模型采用特定的内在结构, 条件假设或添加其他一些约束条件 先验信息也可以直接施加在数据集上, 让其展现处更多的,更有用的信息, 以利于后续模型的训练和学习. 具体到图像分类任务上训练数据不足带来的问题主要表现在过拟合方面. 所以, 对应的处理方法大致分为两类: 基于模型的方法: 采用降低过拟合风险的措施,包括简化模型(如将非线性简化成线性), 添加约束项以缩小假设空间(如L1和L2正则化), 集成学习, Dropout超参数等. 基于数据的方法, 主要通过数据扩充(Data Augmentation), 即根据一些先验知识, 在保持特定信息的前提下, 对原始数据进行适合变换以达到扩充数据集的效果. 在图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换： 观察角度：一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等 噪声扰动：椒盐噪声、高斯白噪声 颜色变换：在RGB颜色空间上进行主成分分析 其他：亮度、清晰度、对比度、锐度 其他扩充数据方法：特征提取, 在图像的特征空间内进行变换：数据扩充or上采样技术，如SMOTE（Synthetic Minority Over-sampling Technique)。 最后，迁移学习或者用GAN合成一些新样本也可帮助解决数据不足问题。 第三章 经典算法1. 支持向量机知识点: SVM模型推导, 核函数, SMO(Sequential Minimal Optimizaiton)算法 问题1: 在空间上线性可分的两类点, 分别向SVM分类的超平面上做投降, 这些点在超平面上的投影仍然是线性可分的吗首先明确下题目概念: 当前的空间已经是线性可分的空间,有可能是样本空间,也有可能是映射后的特征空间. 题目问的是将当前空间中的点全部投影都当前的分类超平面上, 提问在分类超平面上投影的点是否仍然线性可分. 先说结论: 对于任意线性可分的两组点, 它们在SVM分类的超平面上的投影都是线性不可分的 解释一(反证法直观推导): 首先根据拉格朗日对偶优化问题的公式和KKT条件要求,可以知道, SVM的分类结果仅仅依赖于支持向量, 那么此时我们假设存在一个SVM分类超平面使所有支持向量在该超平面上的投影依然线性可分, 那么根据初等几何只是我们可以知道, 两个类别中距离最近的两个点, 它们连线的中垂线所组成的新的超平面是相较于当前超平面更优的解. 这与我们的假设相矛盾, 故线性可分的两组点, 投影到超平面上以后是线性不可分的.(具体可画图或看p53) 解释二(超平面分离定理,Separatin Hyperplane Theorem, SHT): STH定理描述: 对于不想交的两个凸集, 存在一个超平面, 将两个凸集分离. 对于二维的情况, 两个凸集间的距离最短两点连线的中垂线就是一个将它们分离的超平面 根据此定理, 我们先对线性可分的这两组点求格子的凸包, 而SVM求得的超平面就是这两个凸包上距离最短的两点连线的中垂线,根据凸包的性质容易知道, 凸包上的点要么是样本点, 要么是两个样本点之间连线上的点, 那么, 两个凸包之间距离最短的两个点可以分为三个情况: 1)两边都是样本点, 2)两边都不是样本点, 3)一边是一边不是. 不论对于哪种情况, 当对中垂线(超平面)投影后, 两类点都是线性不可分的(具体可画图或者看p54) 问题2: 是否存在一组参数使SVM训练误差为0?问题详细描述: 一个使用高斯核( $K(x,z) = e^{-| x- z|^2/\gamma^2})$ 训练的SVM中, 试证明若给定训练集中 不存在两个点在同一个位置 (如果在同一个位置,则这两个点不可分), 则存在一组参数 $\vec \alpha$ 和参数 $\gamma$, 使得SVM的训练误差为0. 结论:存在(可想象成是过拟合) 公式证明: TODO 以上推导证明可以看出, 对于任意样本的预测结果 $f(\vec x^{(i)})$, 与样本真实标签 $y^{(i)}$ 的距离都小于1 , 因此, 当训练样本为正例时, 由于 $y^{(i)}=1$, 则必有 $f(\vec x^{(i)}) &gt;0 $, 样本被预测为正例. 负例也是同理. 因此所有样本的类别都被正确预测, 训练误差为0. 问题3: 训练误差为0的SVM分类器一定存在吗问题详细描述: 虽然在问题2中找到了一组参数使得SVM的训练误差为0, 但是这组参数不一定是满足SVM条件的一个解, 在实际训练一个 不加入松弛变量 的SVM模型时, 是否能保证得到的SVM分类器满足训练误差为0呢? 结论: 存在 上一题找到了一组参数使得SVM的分类器训练误差为0, 但是训练误差为0的参数并不一定是SVM模型的一个解, 它还需要满足限制条件 $y^{(i)} f(x^{(i)}) \geq 1$ . 因为SVM模型中解的限制条件为 $y^{(i)} f(x^{(i)}) \geq 1$ (等号为支持向量样本点) , 而上题我们只得到了 $y^{(i)} f(x^{(i)}) &gt; 0$, 因此需要找到另一组参数满足更强的条件 TODO公式推导 根据以上推导过程, 可以找到一个SVM的解, 同时一定使模型分类误差为0 问题4: 加入松弛变量的SVM的训练误差可以为0吗结论: 不一定能得到训练误差为0的模型(但不是一定不能, 具体看问题) 这是由于加入松弛变量后, 优化目标变成了 $\min_{\vec w, b, x_i^{(i)}} \frac{1}{2} |\vec w |^2_2 + C \sum_{i=1}^{m} x_i^{(i)}$ ,并不再是仅仅使训练误差最小, 同时还会考虑后面的惩罚项, 而当C的取值较小时, 一个带有训练误差, 但参数项较小的点将会称为更优的结果. 2. 逻辑回归逻辑回归通常用来解决二分类问题(也可以解决多分类问题), 我通过 Logistic 函数将拟合函数的输出值归一化到 (0, 1) 之间, 我们可以将其认为是分类为 1 类的预测概率. Logistic 函数公式(和 Sigmoid 函数形式形式相同)如下: g(z) = \frac{1}{1+e^{-z}}Logistic(Sigmoid) 函数的求导公式有一个特性: $g’(z) = g(z)(1 - g(z))$. 逻辑回归本质上还是线性回归, 只是在特征到结果的映射中加入了一层函数映射, 即先把特征线性求和, 然后使用函数 $g(z)$ 将连续结果值映射到 (0, 1) 之间, 我们将线性回归模型的表达式代入到 Logistic(Sigmoid) 函数之中, 就得到了逻辑回归的表达式: h_\theta (x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^Tx}}问题1: 逻辑回归相比于线性回归, 有何异同?最本质区别: 逻辑回归处理的是分类问题, 线性回归处理的是回归问题. 在逻辑回归中, 因变量的取值是一个 二元分布(不是二项分布). 而线性回归中实际上求解的是对真实函数关系的一个近似拟合. 实际上, 我们将逻辑回归的公式整理一下, 就可以得到 $log\frac{p}{1-p} = \theta^T x$, 其中, $p = P(y=1 | x)$, 也就是将给定输入 $x$ 预测为正样本的概率. 那也就是说, 逻辑回归实际上也可以看做是对 $log\frac{p}{1-p}$ 的线性回归. 但是在关于逻辑回归的讨论中, 我们均认为 $y$ 是因变量, 而不是 $\frac{p}{1-p}$, 这便引出逻辑回归与线性回归最大的区别, 即 逻辑回归中的因变量是离散的, 而 线性回归中的因变量是连续的. 并且在自变量 $x$ 和超参数 $\theta$ 确定的情况下, 逻辑回归可以看做是广义线性模型在因变量 $y$ 服从二元分布时的一个特殊情况, 而使用最小二乘法求解线性回归时, 我们认为因变量 $y$ 服从正态分布. 当使用逻辑回归处理多标签的分类问题时, 有哪些常见做法, 分别应用于哪些场景, 它们之间又有怎样的关系?使用哪一种办法处理多分类取决于具体问题的定义. 如果一个样本只对应于一个标签此时, 我们可以假设每个样本属于不同标签的概率服从于几何分布, 即使用多项逻辑回归(Softmax Regression)来进行分类 h_theta (x) = \begin{bmatrix} p(y = 1 | x; \theta) \\ p(y = 2 | x; \theta) \\ ... \\ p(y = k | x; \theta) \end{bmatrix} = \frac{1}{\sum^k_{j=1} e^{\theta^T_j x}} \begin{bmatrix} e^{\theta^T_1 x} \\ e^{\theta^T_2 x} \\ ... \\ e^{\theta^T_k x} \end{bmatrix}上式中, $\theta_1, \theta_2, …, \theta_k \in \mathbb{R}^n$ 为模型的参数, 而 $\frac{1}{\sum^k_{j=1} e^{e^T_j x}}$ 可以看做是对概率的归一化. 当只有两类时, 我们可以利用参数冗余的特点消除掉一个参数, 这样, 就可以得到和逻辑回归一直的公式, 因此, 多项逻辑回归实际上是二分类逻辑回归在多分类标签下的一种扩展. 当存在一个样本属于多个标签的情况此时, 我们可以训练 $k$ 个二分类的逻辑回归分类器, 第 $i$ 个分类器用以区分每个样本是否可以归为第 $i$ 类, 训练该分类器时, 需要把标签重新整理为”第 $i$ 类标签”与”其他类标签两类”. 这也是 SVM 在处理多分类问题时的方法. 第八章 采样1. 采样的作用第九章 前向神经网络1. 多层感知机与布尔函数问题1: 多层感知机表示异或逻辑时最少需要几个隐含层(仅考虑二元输入)?考虑零个隐藏层的情况(等同于逻辑回归): 逻辑回归公式如下: Z = sigmoid(AX+BY+C)具体的真值表为: // TODO表格 接着考虑下面的情况: //TODO 由上可知, 采用逻辑回归(即不带隐藏层的感知机)无法精确学习出一个输出为异或的模型表示 考虑具有一个隐藏层的情况: 如下图, 假设有两个隐藏单元, //TODO 问题2: 如果只使用一个隐层, 需要多少隐节点能够实现包含n元输入的任意布尔函数?//TODO 完善 结论: 在最差情况下, n元布尔函数的析取范式最多包含 $2^{(n-1)}$ 个不可规约的合取范式(异或), 因此对于单隐层的感知机, 需要 $2^{(n-1)}$ 个隐层节点实现 问题3: 考虑多隐层的情况, 实现包含n元输入的任意布尔函数最少需要多少个网络节点和网络层?// TODO 2. 深度神经网络中的激活函数为什么要使用激活函数: 在现实世界里, 往往会遇到线性不可分问题(如XOR异或函数), 需要非线性变换对数据的分布进行重新映射. 对于深度神经网络, 我们在每一层线性变换后叠加一个非线性激活函数, 以避免多层网络等效于单层线性函数, 从而获得更强大的学习和拟合能力 问题1: 写出常用激活函数及其导数 激活函数 形式 导数形式 Sigmoid $f(x) =\frac{1}{1+e^{-x}}$ $f’(x) = f(x)(1-f(x))$ Tanh $f(x) = tanh(x)= \frac{e^x-e^{-x}}{e^x+e^{-x}}$ $f’(x) = 1-(f(z))^2$ ReLU $f(x)=max(0,x)=\begin{cases} 0 &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}$ $f’(x)=\begin{cases} 0 &amp; x\leq 0 \\ 1 &amp; x&gt;0 \end{cases}$ Leaky ReLU $f(x)=max(\alpha x,x)=\begin{cases} \alpha x &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases} \alpha 通常为0.1$ $f(x)=max(\alpha x,x)=\begin{cases} \alpha &amp; x \leq 0 \\ 1 &amp; x&gt;0 \end{cases}$ Maxout $f(x) = max(w_1^T x + b_1, w_2^T x + b_2)$ $f(x) = max(w_1, w_2)$ ELU $f(x) = \begin{cases} x &amp; x \geq 0 \\ \alpha(e^x - 1) &amp; x&lt;0 \end{cases}$ $f(x) = \begin{cases} 1 &amp; x \geq 0 \\ \alpha e^x &amp; x&lt;0 \end{cases}$ 更多关于激活函数的讨论见[这里] 问题2: 为什么Sigmoid和Tanh激活函数会导致梯度消失的现象主要原因是它们在输入值过大或过小时都具有神经元饱和问题, 也就是说当输入很小或很大时, 其导数趋近于0, 又因为神经网络训练时依赖的是梯度下降法, 而根据链式法则的特点, 导数在趋近于0时就会出现梯度消失现象,导致浅层网络权重更新停滞 问题3: ReLU系列的激活函数相对于Sigmoid和Tanh激活函数的有点是什么,它们有什么局限性?优点: 计算上,ReLU只需要一个阈值, 复杂度低 ReLU在正无穷范围内, 都具有非饱和性, 可以提供相对宽的激活边界, 缓解梯度消失问题 ReLU的负无穷总是输出0, 通过单侧抑制提供了网络的稀疏表达能力, 经过ReLU激活的神经元输出中会有很多的0, 形成了稀疏矩阵, 通过实验发现, 这样的稀疏矩阵可以提高网络的性能. 局限性: 主要在于其训练过程中会导致神经元死亡. 这是由于ReLU在遇到负梯度时会将其置为0, 且在之后也不被任何数据激活,即流经该神经元的梯度永远为0, 不对任何数据产生相应. 在实际训练中, 如果学习率设置较大, 会导致超过一定比例的神经元不可逆死亡, 进而参数梯度无法更新, 整个训练过程失败 解决方法: Leaky ReLU. Leaky ReLU的参数 $\alpha$ 通常是一个很小的值, 也就是说可以实现一定程度上的单侧抑制,保证了网络的稀疏表达能力. 同时, 在输入为负时, 保留了部分信息, 避免了神经元死亡问题 但是LeakyReLU的缺点就是参数 $\alpha$ 的选择需要大量实验和先验知识, 这无疑给训练带来的麻烦, 基于此, PReLU选择将 $\alpha$ 作为网络中一个可学习的参数, 进行反向传播训练. 还有一个就是RReLU, 它令 $\alpha$的选择服从一定的分布, 并进行随机采样, 这在一定程度上能起到正则化的作用 3. 多层感知机的反向传播算法在网络训练中, 前向传播最终产生一个标量损失函数, 反向传播算法(Back Propagation)则将损失函数的信息沿网络层向后传播用以计算梯度, 打到优化网络参数的目的 问题1: 写出多层感知机的平方误差和交叉熵损失函数问题2: 根据问题1中定义的损失函数, 推导各层参数更新的梯度计算公式问题3: 平方误差损失函数和交叉熵损失函数分别适合什么场景?一般来说, 平方损失更适合输出为连续, 并且最后一层不含Sigmoid或者Softmax激活函数的神经网络; 而交叉熵则更适合二分类或多分类的场景. 为何平方损失函数不适合最后一层含有Sigmoid或Softmax激活函数的神经网络? 回顾平方损失函数相对于输出层的导数: \delta = - (y - a^{(L)})f'(z^{(L)})最后一项为激活函数的导数, 当激活函数为Sigmoid或者Softmax时, 其梯度很容易趋于饱和, 使得基于梯度的学习速度非常缓慢. 而交叉熵损失函数相对于输出层的导数是线性的, 因此不会存在学习速度过慢的问题 扩展问题: 多分类为什么选用交叉熵做损失函数, 而不用平方损失?Golik P, Doetsch P, Ney H. Cross-Entropy vs. Squared Error Training: a Theoretical and Experimental Comparison https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/ https://blog.csdn.net/u014313009/article/details/51043064 https://www.cnblogs.com/daniel-D/p/7931835.html#header-n1247 4. 神经网络训练技巧避免过拟合的办法: 数据增强, 正则化, 模型融合(其中dropout是模型融合方法中最高效和常用的技巧) 其他更多提升训练效果的还有如: 学习率, 权重衰减系数, dropout比例, 初始化等等 问题1: 神经网络训练时是否可以将全部参数初始化为0?首先, 在神经网络中, 每一层中的任意神经元都是同构的, 它们拥有相同的输入, 如果再将参数全部初始化为同样的值(如0), 那么输出也就是相同的, 反过来它们的梯度也都是相同的. 那么无论是前向传播还是反向传播的取值都是完全相同的, 那么每一个神经元都是基于input做相同的事情, 这样一来, 不同的神经元根本无法学到不同的特征, 这样就失去网络学习特征的意义了 不仅是初始化为0, 只要是初始化为同一个常数, 就会有这样的问题, 如果是常数, 虽然层与层之间的输出不一致 ,但是每一层内部的所有神经元结果一致, 仍然不是我们希望的那样#https://zhuanlan.zhihu.com/p/27190255 问题2: 为什么Dropout可以抑制过拟合? 它的工作原理和实现?Dropout是指在深度网络的训练中, 以一定的概率随机的”临时丢弃”一部分神经元节点. 具体来讲, Dropout作用于每份小批量训练数据, 由于其随机丢弃部分神经元的机制, 相当于每次迭代都在训练不同结构的神经网络, 可以被认为是一种实用的大规模深度神经网络的模型继承算法. 对于包含 $N$ 个神经元节点的网络, 在Dropout的作用下可以看作为 $2^N$ 个模型的集成, 这 $2^N$ 个模型可认为是原始网络的子网络, 它们共享部分权值, 并且拥有相同的网络层数, 而模型整个的参数数目不变, 大大简化了运算. 对于任意神经元来说, 每次训练中都与一组随机挑选的不同的神经元集合共同进行优化, 这个过程会减弱全体神经元之间的联合适应性, 减少过拟合的风险, 增强泛化能力. 工作原理和实现: 应用Dropout包括训练和预测两个阶段, 在训练阶段中, 每个神经元节点需要增加一个概率系数, 在前向传播时, 会以这个概率选择是否丢弃当前的神经元 在测试阶段的前向传播计算时, 每个神经元的参数都会预先乘以概率系数p, 以恢复在训练中该神经元只有p的概率被用于整个神经网络的前向传播计算 问题3: 批量归一化的基本动机与原理是什么? 在卷积网络中如何使用?动机: 神经网络训练过程的本质是学习数据分布, 如果训练数据与测试数据的分布不同将大大降低网络的繁华能力, 因此需要在训练开始前对所有输入数据进行归一化处理. 然后随着网络训练的进行, 每个隐层的参数变化使得后一层的输入发生变化, 从而每一批训练数据的分布也随之改变, 致使网络在每次迭代中都需要拟合不同的数据分布, 增大训练的复杂度以及过拟合的风险. 原理: 批量归一化方法是针对每一批数据, 在网络的每一层输入之前增加归一化处理(均值为0, 标准差为1), 将所有批数据都强制统一到特定的分布下, 这样可以看作是在每一层输入和上一层输出之间加入了新的计算层, 对数据的分布进行了额外的约束,也就是隐含的增加了正则项, 从而增强模型的泛化能力. 但如果仅仅是这样, 同时也会降低模型的拟合能力, 归一化后的输入分布被强制为0均值和1标准差, 这在一定程度上掩盖了数据本身具有的一些特征, 因此, 为了恢复这些特征, 对归一化后的数据进行线性变换, 引入了两个新的参数 $\gamma$ 和 $\beta$ ,对于每一个卷积核都具有不同的 $\gamma$ 和 $\beta$, 在一定程度了可以保留原始数据中更多的信息, 从而更加有利于优化的过程, 提高模型的泛化能力 使用时需要注意的问题: 在卷积网络中应用时, 需要注意卷积神经网络的参数共享机制, 每一个卷积核的参数在不同的位置的神经元当中是共享的, 因此也应该一起被归一化, 如果有 $f$ 个卷积核, 就对应 $f$ 个特征图和 $f$ 组不同的BN参数. 5. 深度卷积神经网络卷积神经网络的特点是每层的神经元节点只响应前一层局部区域范围内的神经元(全连接会响应前一层的全部节点). 相较于其他网络模型, 卷积操作的参数共享特性使得需要优化的参数数目大大缩减, 提高了模型的训练效率以及可扩展性. 问题1: 卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用稀疏交互(Sparse Interaction): 对于全连接网络来说, 任意一个神经元都会与之前层的所有神经元产生交互, 形成稠密的连接结构, 而在卷积神经网络中, 卷积核尺寸远远小于输入数据的维度, 卷积核会在输入数据上进行类型窗口滑动似的扫描, 然后依次计算出输出神经元的值, 这样每个输出神经元仅仅与前一层特定局部区域内的神经元存在连接, 这种特性就成为稀疏交互. 稀疏交互的作用: 首先第一个很直观的作用就是大大降低了需要优化的参数数目, 是模型更加精简. 另外, 稀疏交互的实际意义还在于, 对于普通的图像, 文本, 语音等数据, 它们都具有较为明显的局部特征结构, 这样, 我们可以先让神经网络学习局部的特征, 再将局部的特征组合起来形成更复杂和抽象的特征, 进而达到识别目标的目的. 参数共享(Parameter Sharing): 参数共享是指在同一个模型的不同模块中使用相同的参数, 它是卷积运算的固有属性. 在卷积神经网络中, 卷积核中的每一个元素将作用于所有局部输入的特定位置上, 根据参数共享的思想, 我们队每个卷积核, 只需要学习一组参数, 而不需要针对不同的输入对每个局部位置的参数都进行优化, 这大大降低了模型的存储需求. 参数共享的作用: 参数共享的实际意义在于可以使得卷积层具有平移不变性. 对于图片来说, 不管图片中的物体出现在图片的哪个位置, 卷积层由于参数共享的作用, 它都会将这个物体看做是同一类, 也就是说, 对图片上的某个物体先进行卷积, 然后在将输出平移, 与先将图片中的物体平移, 再对平移后的物体进行卷积, 其输出结果是相等的 问题2: 常用的池化操作有哪些? 池化的作用是什么?常用的池化操作主要针对非重叠区域(即stride的值设置成大于等于pooling窗口的size), 包括均值池化(mean pooling), 最大池化(max pooling)等. 均值池化: 能够抑制由于邻域大小受限造成估计值方差增大的现象, 特点是对背景的保留效果更好 最大池化: 能够抑制网络参数误差造成估计值偏移的现象, 特点是更好地提取纹理信息 其他特殊的池化方式: 相邻重叠区域的池化: 采用比窗口宽度更小的步长, 使得窗口在每次滑动时存在重叠区域 空间金字塔池化: 主要考虑了多尺度信息的描述, 例如同时计算1×1, 2×2, 4×4 的矩阵池化, 并将结果拼接在一起作为一下网络层的输入 池化的本质是降采样. 除了能显著降低参数数量外, 还能保持对平移, 伸缩, 旋转操作的不变性. 平移不变性: 输入为(1,3,5) 和(5,1,3)时, 最大池化都将取值5 伸缩(尺度)不变性: 如果原先神经元在最大池化操作之后输出5, 那么经过伸缩(尺度变换)后, 最大池化操作的输出很大概率仍然是5(主要最大值不变) 旋转不变性: 对于任意角度的输入, 都会有对应的过滤器与之匹配并最终使神经元的输出引起大的激活, 无论哪个神经元获得了激活, 在经过最大池化操作后, 对于此局部特征, 输出都会具有大的激活 综上, 池化主要有以下作用: 降维, 减少模型参数, 防止过拟合, 提高模型泛化能力 实现非线性 扩大感受野 实现平移, 伸缩, 旋转不变性 下面的图与降采样有异曲同工之处, 可以帮助理解(https://www.zhihu.com/question/36686900): 问题3: 卷积神经网络如何用于文本分类任务?卷积神经网络的核心思想是捕捉局部特征, 对于文本数据来说, 局部特征就是由若干单词组成的滑动窗口, 类似于 N-gram. 下面分别从输入层, 卷积层, 池化层和输出层来说一下如何将卷积神经网络应用于文本数据. 输入层: 输入层通常是一个 $N\times K$ 的矩阵, 其中 $N$ 为单词总数, $K$ 是每个单词对应向量的维度. 每个单词的 $K$ 维向量可以是预先在其他语料库中训练好的, 也可以作为未知的参数由网络训练得到. 这两种方法各有优势. 预训练的词嵌入: 可以利用其它语料库得到更多的先验知识 作为未知参数训练: 能够更好的抓住与当前任务相关联的特征 卷积层: 在输入的 $N\times K$ 维的矩阵上, 我们定义不同大小的滑动窗口进行卷积操作: c_i = f(w \cdot x_{i:i+h-1} + b)其中 $x_{i:i+h-1}$ 代表由输入矩阵的第 $i$ 行到第 $i+h-1$ 行所组成的一个大小为 $h\times K$ 的滑动窗口, 假设 $h$ 为2, 则每次在 $2\times K$ 的滑动窗口上进行卷积, 并得到 $N-2$ 个结果, 再将这 $N-2$ 个结果拼接起来得到 $N-2$ 维的特征向量, 这样, 通过定义不同的滑动窗口, 就可以提取出不同的特征向量, 构成卷积层的输出. 池化层: 池化层阶段从每个不同的特征向量筛选出 $K’$ (为了与上文的 $K$ 区分, 此处用 $K’$)个最大的特征, 成为 K-MAX 池化(也可以使用平均池化, 将每个特征向量平均), 最终达到的效果是将不同长度的句子通过池化得到一个定长的向量表示(长度为滑动窗口的个数) 输出层: 得到文本的向量表示后, 根据具体任务定义输出层的网络结构, 对于分类任务, 通常是用全连接层和Softmax激活函数输出每个类别的概率. 6. 深度残差网络问题: ResNet的提出背景和核心理论是什么?提出背景: 解决或缓解深层的神经网络训练中的梯度消失问题. ResNet中的一个重要假设: 假设有一个L层的深度神经网络, 如果我们在上面加入一层, 直观来讲得到的L+1层深度神经网络的效果应该至少不会比L层的差. 因为可以简单的设最后一层为前一层的拷贝(相当于恒等映射), 并且其它层参数设置不变. 但是最终实验发现: 层数更深的神经网络反而会具有更大的训练误差, 因此, 作者认为深层网络效果差的原因很大程度上也许不在于过拟合, 而在于梯度消失问题. ( 关于梯度消失问题的讨论可见这里) 解决办法: 根据梯度消失问题的根本原因所在(链式法则连乘), ResNet通过调整网络结构来解决上述问题. ResNet的结构设计思想为: 既然离输入近的神经网络层较难训练, 那么我们可以将它短接到更靠近输出的层 首先考虑两层神经网络的简单叠加, 在反向传播时, 有关ResNet更详细的讨论可以看这里]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑回归与线性回归]]></title>
    <url>%2Fz_post%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[逻辑回归和线性回归的定义逻辑回归定义逻辑回归通常用来解决二分类问题(也可以解决多分类问题), 用于估计某种事物的可能性. 我通过 Logistic 函数将拟合函数的输出值归一化到 (0, 1) 之间, 我们可以将其认为是分类为 1 类的预测概率. Logistic 函数公式(和 Sigmoid 函数形式形式相同)如下: g(z) = \frac{1}{1+e^{-z}}Logistic(Sigmoid) 函数的求导公式有一个特性: $g’(z) = g(z)(1 - g(z))$. 线性回归定义:线性回归通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的相互依赖关系. 其公式通常表示如下: y = \theta^T x + e 逻辑回归与线性回归的联系和区别联系逻辑回归本质上还是线性回归, 只是在特征到结果的映射中加入了一层函数映射, 即先把特征线性求和, 然后使用函数 $g(z)$ 将连续结果值映射到 (0, 1) 之间, 我们将线性回归模型的表达式代入到 Logistic(Sigmoid) 函数之中, 就得到了逻辑回归的表达式: h_\theta (x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^Tx}}实际上, 我们将逻辑回归的公式整理一下, 就可以得到 $log\frac{p}{1-p} = \theta^T x$, 其中, $p = P(y=1 | x)$, 也就是将给定输入 $x$ 预测为正样本的概率. 那也就是说, 逻辑回归实际上也可以看做是对 $log\frac{p}{1-p}$ 的线性回归. 但是在关于逻辑回归的讨论中, 我们均认为 $y$ 是因变量, 而不是 $\frac{p}{1-p}$, 这便引出逻辑回归与线性回归最大的区别, 即 逻辑回归中的因变量是离散的, 而 线性回归中的因变量是连续的. 并且在自变量 $x$ 和超参数 $\theta$ 确定的情况下, 逻辑回归可以看做是广义线性模型在因变量 $y$ 服从二元分布时的一个特殊情况, 而使用最小二乘法求解线性回归时, 我们认为因变量 $y$ 服从正态分布. 区别:最本质区别: 逻辑回归处理的是分类问题, 线性回归处理的是回归问题. 在逻辑回归中, 因变量的取值是一个 二元分布(不是二项分布). 而线性回归中实际上求解的是对真实函数关系的一个近似拟合. 对于一个二分类问题, 如果数据集中存在一些离异值, 在不清洗数据的情况下, 选择逻辑回归还是 SVM? 为什么?用 SVM, 因为 SVM 的分类只与支持向量有关, 所以对离异值的忍受能力更强. 逻辑回归和 SVM 的区别是什么? 哪个是参数模型? 分别适合在什么情况下使用?二者区别两种方法都是常见的分类算法, 从目标函数上看, 区别在于逻辑回归采用的是 log 损失, 而 SVM 采用的是 hinge 损失. 这两个损失函数的目的都是增加对分类影响较大的数据点的权重, 减少与分类关系较小的数据点的权重. SVM 的处理方法是只考虑支持向量, 也就是和分类最相关的少数点, 去学习分类器. 而逻辑回归通过非线性映射, 大大减小了离分类平面较远的点的权重, 相对提升了与分类最相关的数据点的权重. 两者的根本目的都是一样的. 此外, 根据需要, 两个方法都可以增加不同的正则化项, 如 L1, L2 等. 所以在很多实验中, 两种算法的结果是很接近的.但是逻辑回归相对来说模型更加简单, 并且实现起来, 特别是大规模线性分类时比较方便. 而 SVM 的实现和优化相对来说复杂一些, 但是 SVM 的理论基础更加牢固, 有一套结构化风险最小化的理论基础, 另外, SVM 转化成对偶问题后, 分类只需要计算与少数几个支持向量的距离即可, 这在进行复杂核函数计算时有时很明显, 能够大大简化模型和计算量 损失函数: 逻辑回归和 SVM 的损失函数分别为: \text{Logistic: } \frac{1}{n} \sum^n_{i=1} - \log g(y_i [ w_0 + x^T_i w_1]) + \frac{\lambda}{2}\| w_1 \|\text{SVM: } \frac{1}{n}\sum^n_{i=1}(1 - y_i[w_0 + x^T_i w_1])^{+} + \frac{\lambda}{2}\| w_1 \|上式中, $g(z) = \frac{1}{1 + exp^(-z)}$. 可以看出, 逻辑回归采用的是对数损失(log loss), 而 SVM 采用的是铰链损失(hinge loss), 即: LR 损失: $Loss(z) = log(1 + exp(-z))$ SVM 损失: $Loss(z) = (1 - z)^{+}$ 逻辑回归产出的是概率值, 而 SVM 只能产出正负类, 因此 LR 的预估结果更容易解释.SVM 主要关注的是 “支持向量”, 也就是和分类最相关的少数点, 即关注局部关键信息; 而逻辑回归是在全局进行优化的, 这导致 SVM 天然比逻辑回归有更好的泛化能力, 防止过拟合. 参数模型和非参数模型LR 是参数模型, SVM 是非参数模型 定义: 参数模型通常假设总体随机变量服从某一个分布, 该分布由一些参数确定(比如正态分布的均值和方差), 在此基础上构建的模型称为参数模型; 非参数模型对于总体的分布不做任何假设, 只是知道总体是一个随机变量, 其分布是存在的(分布中也可能存在参数), 但是无法知道其分布的形式, 更不知道分布的相关参数, 只有在给定一些样本的条件下, 能够依据非参数统计的方法进行推断. 因此, 问题中有没有参数, 并不是参数模型和非参数模型的区别. 其主要区别在于总体的分布形式是否已知. 为何强调 “参数” 与 “非参数”, 主要原因在于参数模型的分布可以由参数直接确定. 参数算法包括两部分: (1) 选择目标函数的形式; (2) 从训练数据中学习目标函数的系数. LR 会预先假设目标函数(直线或其他), 因此它是参数模型. 其他参数模型还有: 线性成分分析, 感知机.参数模型的优点: 简单: 理论容易理解, 结果容易解释 快速: 参数模型的学习和训练速度较快 数据更少: 通常不需要大量的数据也可以较好的拟合? 参数模型的缺点: 约束: 以选定函数形式的方式来学习本身就限制了模型的解空间 有限的复杂度: 通常只能应对简单的问题 拟合度小: 实际中通常无法和潜在的目标函数温和. 非参数算法: 对于目标函数的形式不作过多的假设. 当有用许多数据而先验知识很少时, 非参数学习通常很有用, 因为此时不需要关注参数的选取. 常用的非参数算法包括: K 最近邻, 决策树, SVM, 朴素贝叶斯, 神经网络.非参数算法的优点: 可变性: 可以拟合许多不同的函数形式 模型强大: 对于目标函数不作假设或者作微小的假设 表现良好: 对于预测结果表现通常较好 非参数算法的局限性: 需要更多数据: 对于拟合目标函数需要更多的训练数据 速度慢: 参数更多, 所以训练通常较慢 分别适合在什么情况下使用令 $n = 特征数量$, $m = 训练样本数量$, 则: 如果 $n &gt; m$, 则使用 LR 或者不带核函数的 SVM, 因为特征数相对于训练样本数已经够大了, 使用线性模型就能取得不错的效果, 不需要过于复杂的模型; 如果 $n &lt; m$, 则使用 SVM(高斯核函数), 因为在训练样本数量足够大而特征数量较小的情况下, 可以通过复杂核函数的 SVM 来获得更好的预测性能, 而且因为训练样本数量并没有达到百万级, 使用复杂核函数的 SVM 也不会导致运算过慢; 如果 $n &lt;&lt; m$, 此时因为训练样本数量特别大, 使用复杂核函数的 SVM 会导致训练过慢, 因此应该考虑通过引入更多特征, 然后使用 LR 或者不带核函数的 SVM 来训练更好的模型 在实际使用中, 通常当数据非常非常大(几个 G, 几万维度特征), 跑不动 SVM 时, 用 LR. 如今数据量大幅增加, 相比来说 LR 反而用的更多了.]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的函数指针和函数对象]]></title>
    <url>%2Fz_post%2FCpp-%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E5%92%8C%E5%87%BD%E6%95%B0%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[两方面用途: 函数调用 作为函数参数进行传递 123const double * (*pf[3])(const double *, int) = &#123;f1, f2, f3&#125;// pf 是一个函数指针数组, 数组中的每一个元素都是一个函数指针,// 指向了形式为 const double * (const double *, int) 的函数 函数指针函数指针：指向函数地址的指针变量。 在C++编译时，每一个函数都有一个入口地址，该地址是存储函数机器语言代码的内存的开始地址。函数指针主要有两方面的用途：调用函数和用作函数参数。函数指针的声明方法如下所示： 123456789101112double pam(int);double (* pf)(int); //将星号与函数名括起来，表示当前星号修饰的是函数名，而不是类型 //可以理解为将pam替换成了(*pf)//通常，要声明指向特定类型的指针，可以首先编写这种函数的原型，然后用(*pf)替换函数名即可pf = pam; // 函数名pam本身就是函数地址，所以可直接赋值，无需用取址符，但是要求pam的特征标必须与pf相同pf = &amp;pam; //但实际上，也可以使用取址符，效果与上面 等价（why？）//以下三种方式都是合法且等价的double x = pam(4);double y = (* pf)(5);double z = pf(6); 从上面的语句可以看出，C++同时允许使用带星号和不带星号的函数指针，最神奇的是效果居然是等价的（对于给函数指针赋值时，函数名带取址符和不带取址符的效果也是等价的！）！ 导致以上“神奇事情”发生的原因是，在C++指定函数指针标准时，出现了两种不同的声音：一种学派认为，由于pf是函数指针，而*pf是函数，因此应将(*pf)()用作函数调用。另一种学派认为，由于函数名是指向该函数的指针，指向函数的指针的行为应该与函数名相似，因此应将pf()用作函数调用使用。C++进行了折衷——这两种方式都是正确的，虽然看上去它们在逻辑上是相冲突的。 返回指向函数的指针12int (* func(int))(double, double);// func 具有形参表, 因此它本身是一个参数为 (int) 的函数, 而该函数的返回值则是一个指向 int(double, double) 的函数指针. 下面的声明语句指出了一个函数指针数组，其中每个指针都指向这样的函数：将const double*和int作为参数，返回一个const double *1const double* (* pa[3]) (const double * , int ) = &#123;f1,f2,f3&#125;; 这里不能使用auto，因为auto只能用于单值初始化，而不能用于初始化列表，但声明数组pa后，可以使用auto：1auto pb = pa; // pa和pb都是指向函数指针的指针(数组首地址)，使用时可以用下标法，也可以当做指针使用：123456const double *px = pa[0](av,3);const double *py = (* pa[0])(av,3); //如果带星号，则不能少括号//要获得值，可使用运算符double x = *pa[0](av,3); //少了括号以后，会取得返回值地址指向的值double y = *(* pb[1])(av,3); 如果继续声明了指向函数指针整个数组的指针，则使用方法又有些不同，见下面：12345auto pc = &amp;pa; //pc指向pa的地址*pd[3]; // 相当于 pa[3],代表一个包含三个指针的指针数组(* pd)[3]; // 代表pc是一个函数指针，指向含3个元素的指针数组 函数对象函数对象的实质是对运算符()的重载, 函数对象也叫做仿函数。 12345678class A&#123;public: int operator()(int x)&#123;return x;&#125;&#125;;A a;std::cout &lt;&lt; a(5) std::endl; 函数对象与函数指针的比较函数对象的优势在于，可以把附加对象保存在函数对象中，也可以存储一些其他的额外信息，甚至可以用来封装类成员函数指针。 但是，函数对象本身并不是指针，因此在使用函数指针的场合中，往往无能为力。例如，不能将对象传给qsort函数！因为它只接受函数指针。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11新特性enable_if与SFINAE用法解析]]></title>
    <url>%2Fz_post%2FCpp-enable-if%E7%94%A8%E6%B3%95%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[SFINAESDINAE的全称是Substitution failure is not an error。意思是“匹配失败并非错误” 通常，在使用模板时，编译器会根据传入的参数来推导最适合的模板函数，在这个推导过程中只要有一个可以正确推导出来（但是不能有多个，否则会引起歧义），那么其他几个模板推导就是会产生编译错误，程序也可以正常通过。如下面的代码所示：123456789101112131415struct Test &#123; typedef int foo;&#125;;template &lt;typename T&gt;void f(typename T::foo) &#123;&#125; // Definition #1template &lt;typename T&gt;void f(T) &#123;&#125; // Definition #2int main() &#123; f&lt;Test&gt;(10); // Call #1. f&lt;int&gt;(10); // Call #2. Without error (even though there is no int::foo) //thanks to SFINAE.&#125; std::enable_if这是一个模板类，该模板可能的实现如下：（也许会有其他版本，但大意都差不多）12345template&lt;bool B, class T = void&gt;struct enable_if &#123;&#125;; //在C++中，struct和class除了默认访问权限不同外，无任何差异template&lt;class T&gt;struct enable_if&lt;true, T&gt; &#123; typedef T type; &#125;; 以上表示，若B为true，则std::enable_if模板类拥有公开成员typedef type ，等于T；否则，无该成员。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十七章～第十八章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter17-18%2F</url>
    <content type="text"><![CDATA[18.3 新的类功能18.3.1 特殊的成员函数18.3.2 默认的方法和禁用的方法在C++中，如果只在程序中提供了移动构造函数，那么编译器将不会自动创建默认的构造函数、复制构造函数和复制赋值构造函数。在这种情况下，可以使用关键字default显式的声明这些方法的默认版本：（即只给出函数头，后接=default，则这些方法的默认版本就会被创建） 12345678class Someclass&#123; public: Someclass(Someclass &amp;&amp;); Someclass() = default; Someclass(const Someclass &amp;) = default; Someclass&amp; operator=(const Someclass &amp;) = default;&#125; 另一方面，关键字delete可用于禁止编译器使用特定的方法，例如，要禁止复制对象，可禁用复制构造函数和复制赋值运算符（之前是通过将其访问权限设值为private来实现的，现在的实现方法更容易理解，且不易犯错）：12 关键字default智能用于6个特殊的成员函数，但delete可用于任何成员函数。delete的一种可能用法是禁止特定的转换。 18.4 Lambda 函数C++ 11 中提供了 Lambda 函数(表达式), 它们提供了一种有用的服务, 对使用函数谓词的 STL 算法来说尤其如此. 18.4.1 比较函数指针, 函数对象(仿函数)和 Lambda 函数 函数指针可以完成基本的函数功能, 并且可以作为参数传递给 STL 的算法函数. 仿函数本身是一个类的对象, 因此, 它不仅仅可以完成函数的功能, 还能在此基础上封装更多的信息, 以完成更加复杂的功能, 同样, 仿函数(类实例)也可以作为参数传递给接受函数指针为参数的函数. Lambda 表达式可以创建匿名函数, 即无需给函数命名, 在 C++11 中, 对于接受函数指针或仿函数的函数, 可以使用 lambda 表达式作为其参数. lambda 表达式的返回类型是通过decltype根据返回值判断得到的, 如果 lambda 中不包含返回语句, 那么推断出的返回类型将为void. 注意, 仅当 lambda 表达式完全由一条返回语句组成时, 自动类型推断才管用, 否则, 需要使用新增的返回类型后置语法, 如下所示:1[](double x)-&gt;double &#123;int y = x; return x - y;&#125;; // 返回值类型为 double 18.4.2 为何使用 lambda 距离: 让定义位于使用的地方附近, 这样就无需翻阅多页的源代码, 以了解函数的实际功能. 同时, 在修改代码时, 如果需要修改的代码涉及到的内容都在附近, 那么也会更加方便. 从这种角度看, 函数指针就无法满足这种要求, 因为不能在函数内部定义其他函数. 另外, 对于距离这一点, 仿函数也有同样的优势, 因为我们可以在函数的内部定义类. 简洁: 相比于函数指针的定义和仿函数的定义来说, lambda 表达式的定义更加简洁, 我们可以给一个 lambda 表达式指定名称, 这样可以通过该名称多次使用对应的 lambda 表达式. 效率: 通常, 函数指针会阻止内联, 因为编译器传统上不会内联其地址被获取的函数, 函数地址的概念意味着非内联函数. 而仿函数和 lambda 通常不会阻止内联. 功能: lambda 表达式具有一些额外的功能, 具体地说, lambda 表达式可以访问作用域内的任何动态变量, 我们只要将需要的变量放在捕获括号里面即可. 18.6 可变参数模板可变参数模板(variadic template)可以创建能够接受可变数量参数的模板函数和模板类. 要创建可变参数模板, 需要理解几个要点: 模板参数包(parameter pack) 函数参数包 展开参数包(unpack) 递归 18.6.1 模板和函数参数包C++11 提供了一个用省略号表示的元运算符(meta-operator), 让您能够声明表示模板参数包的标识符, 模板参数包基本上是一个类型列表. 同样, 它还让您能够声明表示函数参数包的标识符, 而函数参数包基本上是一个值列表. 其语法如下:1234template&lt;typename... Args&gt; // Args 是一个模板参数包void show_list(Args... args) &#123; // args是一个函数参数包 ...&#125; 上面的代码中, Args是一个模板参数包, 而args是一个函数参数包. Args与T的差别在于, T与一种类型匹配, 而Args与任意数量(包括零)的类型匹配. 对于下面的函数调用:1show_list('S', 80, "sweet", 4.5); 在上面的情况下, 参数包Args包含与函数调用中的参数匹配的类型: char, int, const char* 和 double. 我们可以用使用模板类型T一样使用Args, Args... args 意味着函数参数包args包含的值列表与模板参数包Args包含类型列表匹配—-无论是类型还是数量都匹配. 在上面的示例中, args包含值&#39;S&#39;, 80, &quot;sweet&quot;, 4.5. 18.6.2 展开参数包我们无法通过索引来获取参数包中的参数, 也就是不能使用Args[2]来访问包中的第三个类型. 相反, 可将省略号放在函数参数包名的右边, 将参数包展开, 如下所示:1234template&lt;typename... Args&gt;void show_list(Args... args) &#123; show_list(args...); // 将展开后的 args 传递给 show_list, 但是这样会造成无限递归.&#125; 18.6.3 在可变参数模板函数中使用递归展开参数后, 如果我们直接在show_list函数中进行展开, 那么它又会将新展开的参数作为参数包进行展开, 这样就会导致无限递归, 因此, 我们需要正确的使用递归来对参数包进行展开. 这里的核心理念是, 将函数参数包展开,对列表中的第一项进行处理, 再将余下的内容传递给递归调用, 以此类推, 直到列表为空. 与常规递归一样, 确保递归终止很重要(可通过添加一个只处理单项的模板来实现最后一项的特殊处理, 同时还可以起到结束递归的作用), 这里的技巧是将模板头改为如下所示:12template&lt;typename T, typename... Args&gt;void show_list(T value, Args... args) 对于上述定义, 我们每次递归调用时, args都会变短, 这样, 最终就可以终止递归. 具体例子见p829.]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的友元]]></title>
    <url>%2Fz_post%2FCpp-%E5%8F%8B%E5%85%83%2F</url>
    <content type="text"><![CDATA[友元函数的简单介绍除了private, public, protected访问权限外, C++ 提供了另外一种形式的访问权限: 友元. 友元有三种: 友元函数 友元类 友元成员函数注意, 指定那些类, 函数, 或成员函数为友元 只能从类内部定义, 而不能从外部强加友情. 因此, 尽管友元被授予从外部访问类的私有部分的权限, 但它们并不与面向对象的编程思想相悖, 相反, 它们提高了公有接口的灵活性.友元函数 为什么需要友元?在为类重载二元运算符时(带两个参数的运算符), 常常需要友元. 例如对于某自定义类Time来说, 重载加法和减法运算符时, 两个操作数都是Time类型的, 因此并无太大影响. 但是当重载乘法运算符时, 有可能一个操作数类型为Time, 而另一个类型为double, 这样一来, 就会限制运算符的使用方式. 由于 运算符左侧的操作数是调用对象, 重载后的乘法运算符不再符合交换律, 如下所示:12A = B * 2.75 // 通过, 相当于, A = B.operator*(2.75)A = 2.75 * B // 失败, 2.75 没有重载运算符 解决上面问题的一个办法就是使用 非成员函数, 因为非成员函数不是由对象调用的, 因此它使用的所有元素(包括对象)都是显式参数. 当乘法是非成员函数时, 函数调用形式如下所示:12A = B * 2.75 // 通过, 相当于, A = B.operator*(2.75)A = 2.75 * B // 通过, 相当于, A = operator*(2.75, B) 对于非成员重载运算符来说, 运算符表达式左边的操作数对应运算符函数的第一个参数, 运算符表达式右边的操作数对应运算符函数的第二个参数. 但是这里又存在一个问题, 那就是非成员函数不能直接访问类的私有数据, 为此, 就引出了友元函数. 创建友元函数 创建友元的第一步是将其原型 放在类声明中 ，并在原型声明前加上关键字friend：p391 12345friend Time operator*(double m, const Time &amp; t);//可以解决2.75*time的乘法重载的问题，2.75不是Time对象，因此无法调用成员重载函数，需要借助友元非成员函数实现。//该声明意味着：// 1、虽然该函数是在类声明中声明的，但它不是成员函数，因此不能使用成员运算符来调用;// 2、虽然该函数不是成员函数，但它与成员函数的访问权限相同。 编写友元函数的定义。因为它不是成员函数，所以不能使用类名::限定符，另外，定义时不要在函数头使用关键字friend。p392 综上: 如果要为类重载运算符, 并将非类对象的项作为其第一个操作数, 则可以使用友元函数来反转操作数的顺序. 常用的友元：重载&lt;&lt;运算符cout是一个ostream对象，对于每种基本类型ostream类声明中都包含了相应的重载的operator&lt;&lt;()定义。因此，对于不同的基本类型，&lt;&lt;运算符在cout对象中可以表现出不同行为。要让cout能够识别自定义的类型, 不建议修改iostream文件的重载定义, 反向, 我们通过类声明来让类知道如何使用cout.p392 &lt;&lt;的第一种重载版本 如果直接通过类声明来重载operator&lt;&lt;()函数，那么在使用时就会像这样，time&lt;&lt;cout;，其中，time是Time类的实例，而cout是Time类重载函数的参数，为了看起来不那么迷惑，利用友元函数，使其第一个参数为ostream对象，这样一来，就可以使用cout&lt;&lt;time的形式（运算符左侧操作数是第一个参数）。p393 123456void operator&lt;&lt;(ostream &amp;os, const Time &amp;t)&#123; os&lt;&lt;t.hours&lt;&lt;t.minutes; //os是cout的引用，别名，省去了拷贝副本的时间&#125;cout&lt;&lt;time1; //等价于下式operator&lt;&lt;(cout,time1); &lt;&lt;的第二种重载版本 上面的重载方法有一些问题，那就是无法使用cout&lt;&lt;time1&lt;&lt;time2&lt;&lt;endl;这样的形式，解决方法如下：p394 1234ostream &amp; operator&lt;&lt;(ostream &amp; os, const Time &amp; t)&#123; os&lt;&lt;t.hours&lt;&lt;t.minutes; return os; //返回os的引用，以便实现连续使用&lt;&lt;的操作。&#125; 警告: 只有在类声明中的原型中才能使用friend关键字, 除非函数定义也是原型, 否则不能再函数定义中使用该关键字. 另外注意, 在成员函数和友元函数都可以的情况下, 只能二选一, 否则如果都进行定义, 编译器无法确定到底要使用哪种定义, 造成二义性错误. 友元类类并非只能拥有友元函数, 也可以将类作为友元, 在这种情况下, 友元类的所有方法都可以访问原始类的私有成员和保护成员. 在一个类的内部声明中之前加上friend关键字, 可以使该类称为原始类的友元:1234class A &#123;public: friend class B; // 注意这里是类型 class B, 而不能是 B b 这种声明变量的形式, B 的定义仍然在外部&#125;; 友元声明可以位于公有, 私有或保护部分, 其所在的位置都无关紧要. 最终的效果都是使得类 B 可以访问类 A 的所有成员. 友元类成员函数如果对友元进行更进一步的限制, 我们可以只将特定的成员函数指定为另一个类的友元, 而不必让整个类成为友元, 但是这样做必须小心排列各种生命和定义的顺序.举例: 让Remote::set_chan()成为Tv类的友元的方法是, 在Tv类声明中将其声明为友元:1234class Tv &#123; friend void Remote::set_chan(Tv&amp; t, int c); ...&#125;; 然而, 要使编译器能够处理这条语句, 它必须知道Remote的定义. 否则, 它无法知道Remote是一个类, 更不能知道set_chan是这个类的方法. 这意味着我们应该将Remote的定义放到Tv的定义前面. 但是Remote的方法中又提到了Tv对象, 而这意味着Tv定义应当位于Remote定义之前. 避开这种循环依赖的方法是, 使用 前向声明(forward declaration), 为此, 需要在Remote定义的前面插入下面的语句:123class Tv; // foward declarationclass Remote &#123;...&#125;;class Tv &#123;...&#125;; 不能使用下面的排列顺序:123class Remote;class Tv &#123;...&#125;;class Remote &#123;...&#125;; 原因在于, 在编译器在Tv类的声明中看到Remote的一个方法被声明为Tv类的友元之前, 应该先看到Remote类的声明和set_chan()方法的声明. 其他友元关系 两个类互为友元 一个非成员函数作为两个类共同的友元.]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的mt19937]]></title>
    <url>%2Fz_post%2FCpp-mt19937%2F</url>
    <content type="text"><![CDATA[std::mersenne_twister_engine该类型是一个基于梅森缠绕器算啊费的随机数生成器，可以产生高质量的无符号随机整数 mt19937 和 mt19937_64这两个类型分别是具有预先定义参数的随机数引擎，有松本与西村设计 成员函数seed、operator、discard、min、max 等等 非成员函数operator==、operator!=、等等 成员对象word_size、state_size等等 具体见：https://zh.cppreference.com/w/cpp/numeric/random/mersenne_twister_engine]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的pragma和#ifndef组合语句的联系与区别]]></title>
    <url>%2Fz_post%2FCpp-pragma%E5%92%8Cifndef%E7%BB%84%E5%90%88%E8%AF%AD%E5%8F%A5%E7%9A%84%E8%81%94%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在C++中，为了避免同一个文件被include多次，常常需要在文中加上一些保证，主要有两种方式，二者用法如下：1#pragma once 12345#ifndef __HEAD__#define __HEAD__#endif 通常，在能够支持这两种方式的编译器上，二者没有太大的区别。下面简介说一下二者格子的优缺点： 对于#ifndef方式来说，不光可以保证同一个文件不会被包含多级，也能保证内容完全相同的两个文件不会被不小心同时包含，但这样就需要编译器每次都扫描头文件内部，因此会使得编译时间相对较长。另外一个缺点就是该方式需要自定义宏名称，当项目很大时，宏名称有“撞车”的风险。 对于#pragma once方式来说，首先是需要code的代码很少，另外不需要自定义宏名称，避免了“撞车”的风险，但是#pragma once提供的保证仅仅是：同一个物理意义上的文件不会被包含多次。如果两个文件内容完全一样，则该方式仍然会重复包含。 结合以上分析，我个人倾向于使用#pragma once，因为需要code的代码更少，无需自想宏名称，另外，出现包含多个内容相同的文件的情况也很很少的（除非有意，否则不太可能出现这种情况）。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉常见问题详细解答]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AF%A6%E7%BB%86%E8%A7%A3%E7%AD%94%2F</url>
    <content type="text"><![CDATA[简述一下现在的 SOTA 模型比较经典的, 比如 R-CNN 系列, YOLO, 以及 SSD 等属于比较具有代表性的一些模型. 在此基础上, 从 17 年开始, 又有很多新的模型出现, 按照不同的关注角度来分, 大致有这么几类.首先是对卷积网络的特征金字塔的构建和生成进行优化和改进的模型, 比如 FPN 和 M2Det 等.其次是从感受野的角度进行优化的模型, 比如 Deformable ConvNet, RFBNet.还有从 bounding box 回归角度进行优化的 RefineDet.然后还有从损失函数及样本不均衡角度进行优化, 使用 Focal Loss 的 RetinaNet等. 在 feature map 的多尺度金字塔特征上进行优化: SSD, FPN, PFPNet, M2Det 在 bbox 回归上进行优化: RefineDet 然后也可以在感受野上进行优化: DCN, RFBNet 以另一种角度来选取 bbox: CornerNet 在 anchor 的生成上进行优化: CornerNet, MetaAnchor 对 NMS 和 IoU 上进行优化: Soft-NMS, Sofer-NMS, Fitness NMS, Relation Network, IoUNet, Cascade R-CNN 在 backbone 网络上优化: DetNet 在损失函数和样本不均衡上进行优化: Focal Loss, Gradient Harmonized(梯度均衡) 针对移动端设备: Pelee 多尺度问题: SNIP, SNIPER 小目标检测: STDNet, Augmentation for small od. 超大目标检测: HKRM FPN,RefineDet, RFBNetSTDN 简要说一下 SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别SSD 是通过使用 backbone(VGG16) 的最后两个卷积段的特征图谱和 4 个额外卷积层特征图谱来构建特征金字塔的.FPN 是通过融合深层和浅层的特征图谱来构建特征金字塔. 主要做法是将最后一层特征图谱进行不断的上采样得到 top-down 结构的特征图谱, 然后与原始的 down-top 结构的特征图谱相结合, 从而得到新的表征能力更强的特征金字塔结构.M2Det 主要是从现在特征金字塔的一些缺点出发进行优化, 它认为, 现有金字塔结构中每一个尺度的特征仅仅来自于 backbone 中单一层级(level)的特征. 这样一来, 小尺度的特征图谱往往缺少浅层低级的语义信息, 而大尺度的特征图谱又缺少深层的高级语义信息. 因此, 作者就提出了融合多个层级特征的 Multi-Level FPN (MLFPN). 从而可以让小尺寸的特征图谱上包含有更多的低级语义信息, 让大尺寸的特征图谱包含更多的高级语义信息. 你知道有哪些常用的训练 Trick 有哪些数据增广方法? 怎么实现的? 颜色变换(Convert Color): BGR 与 HSV 格式随机切换. HSV 模型的三维表示是从 RGB 立方体以旧换新儿来的, 设想从 RGB 沿立方体对角线的白色顶点向黑色顶点观察, 就可以看到立方体的六边形外形. 六边形边界表示色彩, 水平轴表示纯度, 明度沿垂直测量. 随机对比度和亮度: 像素最大最小值的差值影响对比度, 像素的整体大小影响亮度, 通过公式 $g(i, j) = a\times f(i,j) + b$ 控制, $a$ 影响的是对比度, $b$ 影响的图像的亮度. 随机饱和度(Random Saturation): 先将图片转换成 HSV 格式, 然后对 S 通道乘以一个随机值 随机色度(Random Hue): 先将图片转换成 HSV 格式, 然后对 H 通过进行修改 随机交换通道, 增加噪声 FCN 是如何降低计算量的?面对 $384\times 384$ 的图像, 让含全连接层的初始卷积神经网络以 32 像素的步长独立对图像中的 $224\times 224$ 块进行多次评价, 其效果和使用全卷积网络进行一次评价时相同的. 后者通过权值共享起到了加速计算的作用. 简单说一下 PyTorch 和 TensorFlow 的区别两个框架虽然都是在张量上运行, 并且将模型都看做是一个有向非循环图(DAG), 但是二者对于图的定义不同. TensorFlow 是基于静态计算图, 因此是先定义再运行, 一次定义多次运行, 而 PyTorch 是基于动态计算图的, 是在运行过程中被定义的, 在运行的时候进行构建, 可以多次构建多次运行.动态图的还有一个好处就是比较容易调试, 在 PyTorch 中, 代码报错的地方, 往往就是代码错写的地方, 而静态图需要先根据代码生成 Graph 对象, 然后在 session.run() 时报错, 但是这种报错几乎很难直接找到代码中对应的出错段落. 链接】Variable和Tensor合并后，PyTorch的代码要怎么改https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/80105285 你觉得目标检测领域还有哪些可以继续改进或者优化的地方 首先是精确度和速度的考量, 相对于精度较高的 Faster RCNN, RFCN 相关系列模型来说, 个人觉得速度更快的 YOLO 系列和 SSD 系列的模型在实际场景应用中会更加实用, 近年来的主要代表有 RefineDet, RFBNet 等都是基于 SSD 模型的研究. 其次是目标的选框步骤, 从最开始的 Region Based , Anchor Based 到现在的基于角点, 甚至基于 segmentation, 包括 semantic segmentation 和 instance segmentation. 今年比较有代表性的就是 CornerNet. 就目前来说, 目标的选框方法很多还是基于 RPN 的 anchor 思想, 所以, 未来的研究中, 新的更好的目标选框方法依旧是研究的一个重要方向. 多尺度问题(尺度变换问题), 目标常见的三种思路, 采用专门设计的尺度变换模块, STDN: Scale-Transferrable Object Detection. one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？浅层感受野较小, 并且语义信息比较低级深层感受野较大, 包含更多高级语义信息 【链接】onestage目标检测算法中,浅层特征图检测小目https://www.zhihu.com/question/305729744/answer/555781620]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《OpenCV3编程入门》]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-OpenCV3%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>OpenCV</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNet]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-MobileNet%2F</url>
    <content type="text"><![CDATA[文章: MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications作者: Andrew G.Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam机构: GoogleURL: https://arxiv.org/abs/1704.04861 摘要我们提出了 一类 针对移动和嵌入式视觉应用的有效模型, 称之为 MobileNets. MobileNets 基于一种流线型结构(streamlined architecture), 并且使用 深度可分离卷积(depthwise separable convolutions) 来构建轻量级的深度神经网络. 我们引入了两个简单的全局超参数, 它们可以有效的在速度和精度之间权衡. 这些超参数允许模型构建器根据问题的约束为其应用程序选择适当大小的模型. 我们在资源分配和模型精度的权衡上进行了大量的实验, 并与其它流行的 ImageNet 分类模型相比, 表现出了较强的性能. 然后, 我们演示了 MobileNets 在各个领域的有效性, 包括目标检测, 细粒度分类, 人脸属性识别和大规模地理定位等. 介绍本文介绍了一种高效的网络架构和两个超参数, 以便构建非常小的, 低延迟的模型, 这些模型可以很容易的匹配移动和嵌入式视觉应用程序的设计需求. 前人工作SqueezeNet, Factorized CNN, Quantized CNN. MobileNets 的目的是减少模型大小的同时加速模型速度.(有些 papers 只关注模型大小) MobileNet Architecture本节我们将介绍 MobileNet 中的核心网络层, 即深度可分离卷积层(depthwise separable). 然后会介绍 MobileNet 的网络结构和两个超参数: width multiplier, resolution multiplier. Depthwise Separable Convolution深度可分离卷积实际上是一个卷积分解的形式, 它将标准的卷积分解为深度卷积(depthwise convolution)和 $1\times 1$ 卷积(也叫点卷积). 对于 MobileNets 来说, 深度卷积会对 每个输入通道 应用一个单独的过滤器(filter). 然后点卷积(pointwise convolution)会使用 $1\times 1$ 的卷积来融合深度卷积层的输出. 一个标准的卷积层会在使用 filters 的同时将输入融合启动, 并形成一个新的输出. 但是深度可分离卷积将这个过程分为了两层, 一层用于 filtering, 另一层用于 combining. 这种分解可以大大减少计算量和模型大小. 图2(a)代表标准卷积, (b)代表深度卷积, (c)代表点卷积. 如果标准卷积接受一个尺度为 $D_F\times D_F\times M$ 的特征图谱 F, 输出一个尺度为 $D_G\times D_G\times N$ 的特征图谱 G, 那么 $M$ 就是输入图谱的通道数(input depth), $N$ 就是核的数量, 也是输出图谱的通道数. 该卷积层的参数量为: $D_K\times D_K\times M\times N$, $D_K$ 代表卷积核的大小. 标准卷积核的计算成本(乘法次数)为 $D_K\times D_K\times M\times N\times D_F\times D_F$, 即: $卷积乘法次数 = 核尺寸\times 输入通道数\times 输出通道数\times 输入图谱尺寸$. 深度可分离卷积由两个网络层组成: depthwise conv 和 pointwise conv. 前者对每个输入通道 分别应用 filter(可以理解成分为多个 group, 每个 group 内的特征图谱的深度为 1), 后者用于组合前者的输出. MobileNets 在这两个网络层中都使用了 BN 和 ReLU. Depthwise Conv 可以用公式表达如下(with one filter per input channel): \hat G_{k, l, m} = \sum_{i, j}\hat K_{i,j,m} \cdot F_{k+i-1, l+j-1, m}Depthwise Conv 的计算成本(乘法次数)为 $D_K\times D_K\times M\times D_F\times D_F$, 可以看出, 由于 Depthwise Conv 是对每个通道单独进行 filter, 所以其乘法次数无需计入输出图谱的通道数. 虽然 Depthwise Conv 可以大大节省参数量和计算成本, 但是它仅仅对每个通道进行的 filter 操作, 而没有将这些通道结合起来, 因此, 我们添加额外的一层 $1\times 1$ 的卷积网络来计算这些 Depthwise Conv 输出值的线性组合. Depthwise Conv 和 Pointwise Conv 的联合使用就被称为深度可分离卷积, 他们计算成本为 $D_K\cdot D_K\cdot M\cdot D_F\cdot D_F + M\cdot N\cdot D_F\cdot D_F$, 其中, $D_K$ 代表核的大小, $N, M$ 分别代表输入输出通道数, $D_F$ 代表输入图谱的大小.最终, 计算成本的降低程度如下所示: \frac{D_K\cdot D_K\cdot M\cdot D_F\cdot D_F + M\cdot N\cdot \cdot D_F\cdot D_F}{D_K\cdot D_K\cdot M\cdot N\cdot D_F\cdot D_F} = \frac{1}{N} + \frac{1}{D_K^2}MobileNet 使用了 $3\times 3$ 的深度可分离卷积, 它的计算量比标准卷积低了 8~9 倍, 并且精度只降低了一点.空间维度的卷积分解(InceptionV3 中使用的)并不能节省很多额外的计算, 因为只有很少的计算花费在深度卷积上. Network Structure and TrainingMobileNet 除了第一层是一个完整的卷积之外, 其余层都是建立在深度可分离卷积层之上的. 通过这种简单的卷积结构, 我们可以很容易的探索网络的拓扑结构, 从而找到一个较好的网络模型. MobileNet 的网络结构如表1所示. 所有的网络层后面都具有 BatchNorm 层和 ReLU 层, 网络最后的分类层由 GAP + FC + Sofmax 组成. 图3显示了标准卷积以及深度可分离卷积之间的区别. MobileNet 中的下采样操作同时通过步长为2的深度卷积(Conv dw/s2)完成的. 如果将 Depthwise Conv 和 Pointwise Conv 算作独立的层, 那么 MobileNet 的深度就为 28 层. 仅仅根据较少的乘法加法操作(Mult-Adds)来确定网络的结构是不够的, 同样重要的是确保这些操作能够有效的实现. 举例来说, 除非具有非常高的稀疏程度, 否则非结构化的稀疏矩阵运算通常不会比密集矩阵的运算速度快. 我们的模型结构几乎将所有的计算都放在了密集的 $1\times 1$ 卷积当中. 这可以通过高度优化的通用矩阵乘法(GEMM)函数来实现. 卷积操作通常由 GEMM 实现, 但是需要在内存进行名为 im2col 的初始重新排序, 以便将其映射到 GEMM 当中. 而 $1\times 1$ 卷积不需要在内存中重新排序, 可以直接使用 GEMM 实现. 并且, MobileNets 95% 的计算时间都花费在 $1\times 1$ 卷积中, 同时其 75% 的参数都存在于 $1\times 1$ 卷积中, 具体如表2所示 相比于训练大模型, 我们在训练小模型的时候会使用更少的正则化技术和数据增广技术, 因为小模型通常不太容易过拟合(参数少). 另外, 由于 Depthwise Conv 的参数非常少, 因此在 Depthwise Conv 上需要很少或者不添加 weight decay(L2), 这一点是非常重要的. Width Multiplier: Thinner Models尽管 MobileNet 的网络结构已经非常小并且延迟性很低, 但是对于某些特殊的应用场景我们也许需要使用模型更小, 更快. 为此, 我们引入了一个非常简单的超参数 $\alpha$, 称之为 width multiplier. 它的作用是 使网络在每一层均匀的变薄. 当给定一个网络层和 width multiplier $\alpha$ 时, 该网络层的输入通道数 $M$ 会变成 $\alpha M$, 输出通道数 $N$ 会变成 $alpha N$. 如此一来, 深度可分离卷积的计算成本就变成了: D_K\cdot D_K\cdot \alpha M\cdot D_F\cdot D_F + \alpha M\cdot \alpha N \cdot D_F\cdot D_F当 $\alpha = 1$ 时, MobileNet 不发生变化, 当 $alpha &lt; 1$ 时, MobileNet 的参数量和计算量会减少, $\alpha$ 的取值一般为 1, 0.75, 0.5 或 0.25. Width multiplier 可以使得网络的计算成本和参数量大约降低 $\alpha^2$. Resolution Multiplier: Reduced Representation超参数 Resolution Multiplier($\rho$) 会用在 input image 和每一层的特征图谱上, 会将 resolution 降低相同的比例. 在实际使用中, 我们是通过设置输入图谱的分辨率来隐式的使用 $rho$ 的. 当同时使用 $alpha$ 和 $rho$ 以后, 深度可分解卷积的计算成本就变成了: D_K\cdot D_K\cdot \alpha M\cdot \rho D_F\cdot \rho D_F + \alpha M\cdot \alpha N \cdot \rho D_F\cdot \rho D_FResolution multiplier 可以使计算量降低 $\rho^2$. 表3展示了标准的 $3\times 3$ 卷积层在 $14\times 14\times 512$ 的特征图谱上的乘法加法操作和参数量与深度可分离卷积之间的对比. ExperimentsModel ChoicesModel Shrinking Hyperparameters 简述 MobileNet 的原理MobileNet 的设计原则是要构建出模型 size 小, 并且执行速度的卷积网络. 它的整体结构框架和 AlexNet 以及 VGGNet 类似, 都是通过不断堆叠卷积层的方式来构建深层的卷积神经网络. 但与传统卷积网络不同的是, MobileNet 在初第一层使用了标准的卷积层之外, 其余的卷积层都是基于深度可分离卷积构建的. 具体来说, 标准的卷积层在进行操作时, 包括 filter 和 combining 两步, 而深度可分离卷积将这两步分成两个网络层执行, 第一层是 Depthwise Convolution, 它是对输入图谱的每一个通道分别进行操作, 因此它的计算量只与 核的大小, 输入图谱的尺寸, 以及输出图谱的通道数有关, 与输入图谱的通道数无关. 然后, 第二层是一个 $1\times 1$ 的卷积层, 它负责融合前一层输出的特征图谱, 由于它的核尺寸为 1, 因此它的计算量只与 输入图谱的通道数, 输出图谱的尺寸和通道数有关. 由于在卷积网络中, 通常 特征图谱的通道数要远远大于特征图谱的尺寸, 因此, 深度可分离卷积的主要计算量(95%)都集中在 $1\times 1$ 的卷积层. 并且当卷积层使用 im2col+ GEMM 的方式实现时, $1\times 1$ 的卷积层不需要在内存中重新排序, 因此它的实际执行速度很快. 最后, 原文还给出了两个超参数来进一步压缩模型大小, 分别 width multiplier $\alpha$ 和 resolution multiplier $rho$, 前者通过控制特征图谱的通道数来实现, 后者通过通过输入图片的尺寸来实现. 解释为何 $1\times 1$ 卷积层不需要重新排序: 卷积层底层是如何实现的]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的有关int的各种形式以及为什么要有size_t类型]]></title>
    <url>%2Fz_post%2FCpp-%E6%9C%89%E5%85%B3int%E7%9A%84%E5%90%84%E7%A7%8D%E5%BD%A2%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[int,int32_t,int64_t 数据类型特别是int相关的类型在不同位数机器的平台下长度不同。C99标准并不规定具体数据类型的长度大小，只规定级别。作下比较： 16位平台 char 1个字节8位short 2个字节16位int 2个字节16位long 4个字节32位指针 2个字节 32位平台 char 1个字节8位short 2个字节16位int 4个字节32位long 4个字节long long 8个字节指针 4个字节 64位平台 char 1个字节short 2个字节int 4个字节long 8个字节（区别）long long 8个字节指针 8个字节（区别） 为了保证平台的通用性，程序中尽量不要使用long数据库型。同时，通过int_32t等形式来明确int型数据所占有的位数。 另外 还有size_t size_t是一些C/C++标准在stddef.h中定义的。这个类型足以用来表示对象的大小。 size_t的真实类型与操作系统有关，在32位架构中被普遍定义为： typedef unsigned int size_t; 而在64位架构中被定义为： typedef unsigned long size_t;size_t在32位架构上是4字节，在64位架构上是8字节，在不同架构上进行编译时需要注意这个问题。而int在不同架构下都是4字节，与size_t不同；且int为带符号数，size_t为无符号数。 size_t 这个类型的意义：size_t和unsigned int有所不同,size_t的取值range是目标平台下最大可能的数组尺寸,一些平台下size_t的范围小于int的正数范围,又或者大于unsigned int.最典型的,在x64下,int还是4,但size_t是8.这意味着你在x64下最大可能开辟的数组尺寸是2^64.如果你使用int或者unsigned int,那么在x64下如果你的代码中全部使用uint作为数组的尺寸标记,那么你就会失去控制2^32尺寸以上的数组的机会.虽然现在在x64上开辟一个大于2^32大小的连续数组依然是个不大可能的事情,但是……….“640K内存对于任何人来说都足够了”——比尔盖茨 学过计算机组成原理应该不会对此有疑问。int小于等于数据线宽度，size_t大于等于地址线宽度。size_t存在的最大原因可能是因为：地址线宽度历史中经常都是大于数据线宽度的。在数据只有8位的年代，地址率先进入10位，12位，在数据16位的年代，地址也已经进入了20位，24位。目前的int普遍是32位，而size_t在主流平台中都是64位。size_t为什么存在？因为无论int还是unsigned都很可能小于size_t需要的大小，所以必须有个size_t。—补充：据说题主对_t有疑惑。这个问题很简单，仅仅是因为作者选择这样的命名作为编码规范而已。类型名与变量名共享相同的命名空间，所以通常需要在命名方面刻意区分出来。在遥远的 C 时代，发明者很可能是想建议所有的类型名后面加_t，只不过这并没有成为更普遍的编码规范罢了。而现今Java的规范倒比较容易让人接受：大写开头的是类型名，小写开头的是变量名跟函数名，虽然具体细则有不同，但原意都是一样的：变量与类型共享同一个命名空间，因而需要在命名规则上刻意区分开来。 为什么size_t 重要？https://jeremybai.github.io/blog/2014/09/10/size-t 前言：使用size_t可能会提高代码的可移植性、有效性或者可读性，或许同时提高这三者。 在标准C库中的许多函数使用的参数或者返回值都是表示的用字节表示的对象大小，比如说malloc(n) 函数的参数n指明了需要申请的空间大小，还有memcpy(s1, s2, n)的最后一个参数，表明需要复制的内存大小，strlen(s)函数的返回值表明了以’\0’结尾的字符串的长度（不包括’\0’），其返回值并不是该字符串的实际长度，因为要去掉’\0’。 或许你会认为这些参数或者返回值应该被申明为int类型（或者long或者unsigned），但是事实上并不是。C标准中将他们定义为size_t。标准中记载malloc的申明应该出现在，定义为： void *malloc(size_t n); memcpy和strlen的申明应该出现在中： void memcpy(void s1, void const s2, size_t n);size_t strlen(char const s); size_t还经常出现在C++标准库中，此外，C++库中经常会使用一个相似的类型size_type，用的可能比size_t还要多。 据我所知，大部分的C和C++程序员害怕这些库使用size_t，因为他们不知道size_t代表什么或者为什么这些库需要使用它，归根结底，原因在于他们什么时候什么地方需要用到它。 可移植性问题 早期的C语言（由Brian Kernighan 和 Dennis Ritchie 在The C Programming Language书中所写，Prentice-Hall, 1978）并没有提供size_t类型，C标准委员会为了解决移植性问题将size_t引入，举例如下： 让我们来写一个可移植的标准memcpy函数，我们将会看到一些不同的申明和它们在不同平台不同大小的地址空间上编译下的情况。 回忆memcpy(s1, s2, n)函数，它将s2指向地址开始的n个字节拷贝到s2指向的地址，返回s1，这个函数可以拷贝任何数据类型，所以参数和返回值的类型应该为可以指向任何类型的void，同时，源地址不应该被改变，所以第二个参数s2类型应该为const void，这些都不是问题。 真正的问题在于我们如何申明第三个参数，它代表了源对象的大小，我相信大部分程序员都会选择int： void memcpy(void s1, void const *s2, int n); 使用int类型在大部分情况下都是可以的，但是并不是所有情况下都可以。int是有符号的，它可以表示负数，但是，大小不可能是复数。所以我们可以使用unsigned int代替它让第三个参数表示的范围更大。 在大部分机器上，unsigned int的最大值要比int的最大值大两倍，比如说再也给16位的机器上，unsigned int的最大值为65535，int的最大值为32767。 尽管int类型的大小依赖于C编译器的实现，但是在给定的平台上int对象的大小和unsigned int对象的大小是一样的。因此，使用unsigned int修饰第三个参数的代价与int是相同的： void memcpy(void s1, void const *s2, unsigned int n); 这样似乎没有问题了，unsigned int可以表示最大类型的对象大小了，这种情况只有在整形和指针类型具有相同大小的情况下，比如说在IP16中，整形和指针都占2个字节（16位），而在IP32上面，整形和指针都占4个字节（32位）。（参见下面C数据模型表示法） C数据模型表示法 最近，我偶然发现几篇文章，他们使用简明的标记来表述不同目标平台下c语言数据的实现。我还没有找到这个标记的来源，正式的语法，甚至连名字都没有，但他似乎很简单，即使没有正规的定义也可以很容易使用起来。这些标记的一边形式形如： I nI L nL LL nLL P nP。 其中每个大写字母（或成对出现）代表一个C的数据类型，每一个对应的n是这个类型包含的位数。I代表int，L代表long，LL代表long long，以及P代表指针（指向数据，而不是函数）。每个字母和数字都是可选的。 例如，I16P32架构支持16位int和32位指针类型，没有指明是否支持long或者long long。如果两个连续的类型具有相同的大小，通常省略第一个数字。例如，你可以将I16L32P32写为I16LP32，这是一个支持16位int，32位long，和32位指针的架构。 标记通常把字母分类在一起，所以可以按照其对应的数字升序排列。例如，IL32LL64P32表示支持32位int，32位long，64位long long和32位指针的架构；然而，通常写作ILP32LL64。 不幸的是，这种memcpy的申明在I16LP32架构上（整形是16-bit 长整形和指针类型时32-bits）显得不够用了，比如说摩托罗拉第一代处理器68000，在这种情况下，处理器可能拷贝的数据大于65535个字节，但是这个函数第三个参数n不能处理这么大的数据。 什么？你说很容易就可以改正？只需要把memcpy的第三个参数的类型修改一下： void memcpy(void s1, void const *s2, unsigned long n); 你可以在I16LP32目标架构上使用这个函数了，它可以处理更大的数据。而且在IP16和IP32平台上效果也还行，说明它确实给出了memcpy的一种移植性较好的申明。但是，在IP16平台上相比于使用unsigned int，你使用unsigned long可能会使你的代码运行效率大打折扣（代码量变大而且运行变慢）。 在标准C中规定，长整形（无论无符号或者有符号）至少占用32位，因此在IP16平台上支持标准C的话，那么它一定是IP16L32 平台。这些平台通常使用一对16位的字来实现32位的长整形。在这种情况下，移动一个长整形需要两条机器指令，每条移动一个16位的块。事实上，这个平台上的大部分的32位操作都需要至上两条指令。 因此，以可移植性为名将memcpy的第三个参数申明为unsigned long而降低某些平台的性能是我们所不希望看到的。使用size_t可以有效避免这种情况。 size_t类型是一个类型定义，通常将一些无符号的整形定义为size_t，比如说unsigned int或者unsigned long，甚至unsigned long long。每一个标准C实现应该选择足够大的无符号整形来代表该平台上最大可能出现的对象大小。 使用size_t size_t的定义在, , , , 和这些标准C头文件中，也出现在相应的C++头文件, 等等中，你应该在你的头文件中至少包含一个这样的头文件在使用size_t之前。 包含以上任何C头文件（由C或C++编译的程序）表明将size_t作为全局关键字。包含以上任何C++头文件（当你只能在C++中做某种操作时）表明将size_t作为std命名空间的成员。 根据定义，size_t是sizeof关键字（注：sizeof是关键字，并非运算符）运算结果的类型。所以，应当通过适当的方式声明n来完成赋值： n = sizeof(thing); 考虑到可移植性和程序效率，n应该被申明为size_t类型。类似的，下面的foo函数的参数也应当被申明为sizeof： foo(sizeof(thing)); 参数中带有size_t的函数通常会含有局部变量用来对数组的大小或者索引进行计算，在这种情况下，size_t是个不错的选择。 适当地使用size_t还会使你的代码变得如同自带文档。当你看到一个对象声明为size_t类型，你马上就知道它代表字节大小或数组索引，而不是错误代码或者是一个普通的算术值。 在我接下来的一些文章的例子中会使用size_t，敬请期待！]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的aligned_alloc]]></title>
    <url>%2Fz_post%2FCpp-aligned-alloc%2F</url>
    <content type="text"><![CDATA[std::aligned_alloc定义于头文件 void* aligned_alloc( std::size_t alignment, std::size_t size );(C++17 起) 分配 size 字节的未初始化存储，由 alignment 指定其对齐。 size 参数必须是 alignment 的整数倍。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的lambda表达式]]></title>
    <url>%2Fz_post%2FCpp-lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[C++中的lambda与函数对象lambda表达式是C++11中引入的一项新技术，利用lambda表达式可以编写内嵌的匿名函数，用以替换独立函数或者函数对象，并且使代码更可读。但是从本质上来讲，lambda表达式只是一种语法糖，因为所有其能完成的工作都可以用其它稍微复杂的代码来实现。但是它简便的语法却给C++带来了深远的影响。 如果从广义上说，lambda表达式产生的是函数对象。函数对象的本质上是一个类而不是一个函数，在类中，对象重载了函数调用运算符()，从而使对象能够项函数一样被调用，我们称这些对象为函数对象（Function Object）或者仿函数（Functor）。相比lambda表达式，函数对象有自己独特的优势。下面我们开始具体讲解这两项黑科技。 lambda表达式先从一个简单的例子开始，我们定义一个输出字符串的lambda表达式，如下所示，表达式一般都是从方括号[]开始，然后结束于花括号{}：12auto basic_lambda = []&#123;cout&lt;&lt;"Hello Lambda"&lt;&lt;endl;&#125;; //定义简单的lambda表达式basic_lambda(); //调用 下面分别是包含参数和返回类型的lambda表达式：12auto add = [] (int a, int b)-&gt;int &#123; return a+b;&#125;; //返回类型需要用`-&gt;`符号指出auto multiply = [](int a, int b) &#123;return a*b;&#125; //一般可以省略返回类型，通过自动推断就能得到返回类型 lambda表达式最前面的方括号提供了“闭包”功能。每当定义一个lambda表达式以后，编译器会自动生成一个 匿名类 ，并且这个类重载了()运算符，我们将其称之为闭包类型（closure type）。在运行时，这个lambda表达式会返回一个匿名的闭包实例，并且该实例是一个右值。闭包的一个强大之处在于其可以通过传值或引用的方式捕捉其封装作用域内的变量，lambda表达式前面的方括号就是用来定义捕捉模式以及变量的lambda捕捉块，如下所示：123456int main()&#123; int x = 10; // 定义作用域内的x，方便下面的lambda捕捉 auto add_x = [x](int a)&#123; return a+x;&#125;; // 传值捕捉x auto multiply_x = [&amp;x](int a) &#123;return a*x;&#125;; //引用捕捉x&#125; 当lambda捕捉块为空时，表示没有捕捉任何变量。对于传值方式捕捉的变量x，lambda表达式会在生成的匿名类中添加一个非静态的数据成员，由于闭包类重载()运算符是使用了const属性，所以不能在lambda表达式中修改传值方式捕捉的变量，但是如果把lambda标记为mutable，则可以改变(但是这里的改变只会对 lambda 表达式内部的代码有影响, 对外部不起作用)，如下所示：12345int x = 10;auto add_x = [x](int a) mutable&#123; x * = 2; return a+x;&#125;;cout&lt;&lt;add_x(10)&lt;&lt;endk; //输出30return 0; 而对于引用方式捕捉的变量，无论是否标记为mutable，都可以对变量进行修改，并且修改的值会影响到外部, 至于会不会在匿名类中创建数据成员，需要看不同编译器的具体实现。 lambda表达式只能作为右值，也就是说，它是不能被赋值的12345auto a=[]&#123; cout&lt;&lt;"A"&lt;&lt;endl; &#125;;auto b=[]&#123; cout&lt;&lt;"B"&lt;&lt;endl; &#125;;a = b; // 非法，lambda表达式变量只能做右值auto c = a; // 合法，生成一个副本 造成以上原因是因为禁用了赋值运算符：1ClosureType&amp; operator=(const ClosureType&amp;) = delete; 但是没有禁用复制构造函数，所以仍然可以用是一个lambda表达式去初始化另一个（通过产生副本）。 关于lambda的捕捉块，主要有以下用法： []：默认不捕捉变量 [=]：默认以值捕捉所有变量（最好不要用） [&amp;]：默认以引用捕捉所有变量（最好不要用） [x]：仅以值捕捉变量x，其他变量不捕捉 [&amp;x]：仅以引用捕捉x，其他变量不捕捉 [=, &amp;x]：默认以值捕捉所有变量，但是x是例外，通过引用捕捉 [&amp;, x]：默认以引用捕捉所有变量，但是x是例外，通过值捕捉 [this]：通过引用捕捉当前对象（其实是复制指针） [* this]：通过传值方式捕捉当前对象 通过以上的说明，可以看到lambda表达式可以作为返回值，赋值给对应类型的函数指针，但是使用函数指针貌似并不是那么方便，于是STL在头文件&lt;functional&gt;中定义了一个多态的函数对象封装std::function，其功能类似于函数指针。它可以绑定到任何类函数对象，只要参数与返回类型相同。如下面的返回一个bool且接收两个int的函数包装器：1std::function&lt;bool(int, int)&gt; wrapper = [](int x, int y) &#123; return x&lt;y; &#125;; lambda表达式还有一个很重要的应用是其可以作为函数的参数，如下所示：1234int value = 3;vector&lt;int&gt; v&#123;1,2,3,4,5,6,7&#125;;int count == std::count_if(v.begin, v.end(), [value](int x)&#123;return x&gt;value;&#125;); 下面给出lambda表达式的完整语法：1234567// 完整语法[ capture-list ] ( params ) mutable(optional) constexpr(optional)(c++17) exception attribute -&gt; ret &#123; body &#125;// 可选的简化语法[ capture-list ] ( params ) -&gt; ret &#123; body &#125; [ capture-list ] ( params ) &#123; body &#125; [ capture-list ] &#123; body &#125; capture-list：捕捉列表，这个不用多说，前面已经讲过，记住它不能省略； params：参数列表，可以省略（但是后面必须紧跟函数体）； mutable：可选，将lambda表达式标记为mutable后，函数体就可以修改传值方式捕获的变量； constexpr：可选，C++17，可以指定lambda表达式是一个常量函数； exception：可选，指定lambda表达式可以抛出的异常； attribute：可选，指定lambda表达式的特性； ret：可选，返回值类型； body：函数执行体。 lambda新特性（C++14）在C++14中，lambda又得到了增强，一个是泛型lambda表达式，一个是lambda可以捕捉表达式。 lambda捕捉表达式前面讲过，lambda表达式可以按传值或者引用捕捉在其作用域范围内的变量。而有时候，我们希望捕捉不在其作用域范围内的变量，而且最重要的是我们希望捕捉右值。所以C++14中引入了表达式捕捉，其允许用任何类型的表达式初始化捕捉的变量，如下：12345678// 利用表达式捕获，可以更灵活地处理作用域内的变量int x = 4;auto y = [&amp;r = x, x = x + 1] &#123; r += 2; return x * x; &#125;();// 此时 x 更新为6，y 为25// 直接用字面值初始化变量auto z = [str = "string"]&#123; return str; &#125;();// 此时z是const char* 类型，存储字符串 string 可以看到捕捉表达式扩大了lambda表达式的捕捉能力，有时候你可以用std::move初始化变量。这对不能复制只能移动的对象很重要，比如std::unique_ptr，因为其不支持复制操作，你无法以值方式捕捉到它。但是利用lambda捕捉表达式，可以通过移动来捕捉它： 123auto myPi = std::make_unique&lt;double&gt;(3.1415);auto circle_area = [pi = std::move(myPi)](double r) &#123; return *pi * r * r; &#125;;cout &lt;&lt; circle_area(1.0) &lt;&lt; endl; // 3.1415 泛型lambda表达式从C++14开始，lambda表达式支持泛型：其参数可以使用自动推断类型的功能，而不需要显示地声明具体类型。这就如同函数模板一样，参数要使用类型自动推断功能，只需要将其类型指定为auto，类型推断规则与函数模板一样。这里给出一个简单例子： 1234auto add = [](auto x, auto y) &#123; return x + y; &#125;;int x = add(2, 3); // 5double y = add(2.5, 3.5); // 6.0 函数对象函数对象是一个广泛的概念，因为所有具有函数行为的对象都可以称为函数对象。这是一个高级抽象，我们不关心对象到底是什么，只要其具有函数行为即可。函数行为是指可以使用()调用并传递参数，如下所示：1function(arg1, arg2, ...); //函数调用 由此，lambda表达式也是一个函数对象。该函数对象实际上是一个匿名类的实例，且这个类实现了函数调用运算符()。 泛型提供了高级抽象，不论是lambda表达式、函数对象、还是函数指针，都可以传入到STL算法中（如for_each）。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的枚举类]]></title>
    <url>%2Fz_post%2FCpp-%E6%9E%9A%E4%B8%BE%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[p372一、简述 强类型枚举（Strongly-typed enums），号称枚举类型，是C++11中的新语法，用以解决传统C++枚举类型存在的缺陷。传统C++中枚举常量被暴漏在外层作用域中，这样若是同一作用域下有两个不同的枚举类型，但含有相同的枚举常量也是不可的，比如： enum Side{Right,Left};enum Thing{Wrong,Right};这是不能一起用的。 另外一个缺陷是传统枚举值总是被隐式转换为整形，用户无法自定义类型。C++11中的强类型枚举解决了这些问题。————————————————————————— 二、强类型枚举 强类型枚举使用enum class语法来声明，如下： enum class Enumeration{ VAL1, VAL2, VAL3=100, VAL4};这样，枚举类型时安全的，枚举值也不会被隐式转换为整数，无法和整数数值比较，比如（Enumeration：：VAL4==10会触发编译错误）。 另外枚举类型所使用的类型默认为int类型，也可指定其他类型，比如： enum calss Enum:unsigned int{VAL1,VAL2};正如前面所说，强类型枚举能解决传统枚举不同枚举类下同枚举值名的问题，使用枚举类型的枚举名时，必须指明所属范围，比如：Enum::VAL1，而单独的VAL1则不再具有意义。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的mutable关键字]]></title>
    <url>%2Fz_post%2FCpp-mutable%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[在C++中，mutable是为了突破const的限制而设置的。被mutable修饰的变量，将永远处于可变的状态，即使在一个const函数中，甚至结构体变量或者类对象为const，其mutable成员也可以被修改。 mutable在类中只能够修饰非静态数据成员。mutable 数据成员的使用看上去像是骗术，因为它能够使const函数修改对象的数据成员。然而，明智地使用 mutable 关键字可以提高代码质量，因为它能够让你向用户隐藏实现细节，而无须使用不确定的东西。我们知道，如果类的成员函数不会改变对象的状态，那么这个成员函数一般会声明成const的。但是，有些时候，我们需要在const的函数里面修改一些跟类状态无关的数据成员，那么这个数据成员就应该被mutalbe来修饰。 12345678910111213141516171819202122232425262728293031323334struct tagData&#123; int a; mutable int b;&#125;;class clsData&#123;public: int a; mutable int b; void show() const &#123; a = 2;//错误，不能在const成员函数中修改普通变量 b = 5;//正确 printf("a: %d, b: %d\r\n"); &#125;&#125;;int _tmain(int argc, _TCHAR* argv[])&#123; //结构体变量为const，其mutable成员也可以被修改 const tagData dat = &#123;0, 0&#125;; dat.a = 8;//编译错误 dat.b = 9;//编译通过 //类对象为const，其mutable成员也可以被修改 clsData cls; cls.show(); return 0;&#125; const承诺的是一旦某个变量被其修饰，那么只要不使用强制转换(const_cast)，在任何情况下该变量的值都不会被改变，无论有意还是无意，而被const修饰的函数也一样，一旦某个函数被const修饰，那么它便不能直接或间接改变任何函数体以外的变量的值，即使是调用一个可能造成这种改变的函数都不行。这种承诺在语法上也作出严格的保证，任何可能违反这种承诺的行为都会被编译器检查出来。 mutable的承诺是如果某个变量被其修饰，那么这个变量将永远处于可变的状态，即使在一个const函数中。这与const形成了一个对称的定义，一个永远不变，而另外一个是永远可变。 看一个变量或函数是否应该是const，只需看它是否应该是constant或invariant，而看一个变量是否应该是mutable，也只需看它是否是forever mutative。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用CUDA进行一维数组的矢量求和]]></title>
    <url>%2Fz_post%2FCUDA-CUDA%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0-%E4%B8%80%E7%BB%B4%E6%95%B0%E7%BB%84%E7%9A%84%E7%9F%A2%E9%87%8F%E6%B1%82%E5%92%8C%2F</url>
    <content type="text"><![CDATA[基于GPU的一维数组的矢量求和 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;cstdio&gt;#define N 20//如果忘记写global，会报错：error: a host function call cannot be configured__global__ void add(int *a, int *b, int *c)&#123; int tid = blockIdx.x; if(tid&lt; N)&#123; c[tid] = a[tid] + b[tid]; &#125;&#125;int main()&#123; int a[N]; int b[N]; int c[N]; int *dev_a, *dev_b, *dev_c; /*cudaMalloc((void**)&amp;dev_a, N*sizeof(int));*/ /*cudaMalloc((void**)&amp;dev_b, N*sizeof(int));*/ /*cudaMalloc((void**)&amp;dev_c, N*sizeof(int));*/ cudaMalloc(&amp;dev_a, N*sizeof(int)); cudaMalloc(&amp;dev_b, N*sizeof(int)); cudaMalloc(&amp;dev_c, N*sizeof(int)); for(int i =0 ; i&lt;N; i++)&#123; a[i] = i; b[i] = i; &#125; cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice); add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a,dev_b,dev_c); cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost); cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c); for(int i =0 ;i&lt;N; i++)&#123; //如果错误的访问量dev_c[i]，会报告段错误 std::cout&lt;&lt;c[i]&lt;&lt;std::endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++-踩坑]]></title>
    <url>%2Fz_post%2FCpp-%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[gcc/g++的编译链接原理及注意事项LINUX下默认搜索头文件及库文件的路径 编译连接 多个文件编译在linux下编译，下面有三个文件，分别是1.cpp 和 2.cpp 和myhead.h 文件。 1.cpp 123456789#include &lt;iostream&gt;#include "myhead.h"using namespace std;int main()&#123; print(); cout&lt;&lt;"yes !"&lt;&lt;endl; return 0;&#125; 2.cpp 123456789#include &lt;iostream&gt;#include "myhead.h"using namespace std;void print()&#123; std::cout&lt;&lt;" print "&lt;&lt;std::endl; cout&lt;&lt;&#125; myhead.h 12345#ifndef __myhead_h#define __myhead_hvoid print();#endif 假如他们都在一个目录下面，那么编译流程： 12g++ -c 2.cpp #将2.cpp 编译成2.o 文件g++ 1.cpp -o a.out 2.o #多个文件一起链接 or123g++ -c 2.cppg++ -c 1.cppg++ 1.o 2.o -o test 重写C++中异常类的what方法待补充完善：错误原因以及为什么这么修改坑源在实现项目ZeroTensor的专属异常类时，需要实现exception类的what方法。 出现问题及解决办法首先需要看一下exception基类中关于what方法的原始定义： 12 下面是正确的重写方式 1const char *what() const throw() override &#123; return error_msg_.c_str(); &#125; 如果去掉throw() ， 则会报错： 12looser throw specifier for ‘virtual const char* zerotensor::ZerotensorError::what() const’ const char *what() const override &#123; return error_msg_.c_str(); &#125; 如果将char * 改为 string，则会报错： 12error: ‘const string zerotensor::ZerotensorError::what() const’ cannot be overloaded const string what() const throw() override &#123; return error_msg_; &#125; 声明模板类对象，报错“undefined reference to”坑源实现ZeroTensor项目中的Shape3D类时，为了可以处理多种类型的数据（int，double等），需要使用模板类 出现问题和解决办法在实现的时候将模板类的声明和定义写在的不同位置，编译时报错：1undefined reference to XXXX 这是因为模板类并不是普通的类和成员函数！它们只是说明了如何生成类和成员函数定义。因此，不能将模板成员函数放在独立的实现文件中。 由于模板不是函数，因此它们不能单独编译。模板必须与特定的模板实例化请求一起使用。为此，最简单的方法是将所有模板信息放在一个头文件中，并在要使用这些模板的文件中包含该头文件！ 还有另一种解决办法就是在stack.h文件的末尾加上#include stack.cpp，并在stack.cpp文件中去掉对应的包含语句。 string.substr坑源: leetcode, 第140题, Word Brak II s.substr(word.size()) 可以通过, 但是s.substr(0, word.size()) 报错 runtime error. 原因:1basic_string substr(size_type pos=0, size_type count=npos) const; 当只指定一个参数时, 该参数表示的是 pos 的位置, 而 count 则默认会是字符串中剩余字符的数量. 如果 pos 的值大于字符串的size, 则会报运行时错误(runtime error). vector数据的内存分配问题首先，要知道，程序所拥有的栈资源是及其有限的（Linux下用ulimit -a或者ulimit -s可查当前栈的大小。 因此在写程序时，绝对不能肆意使用占空间，否则就会报出Segmentation fault。 在用vector实现三维数据时，以下的代码就会产生段错误 123456789101112131415161718#include &lt;vector&gt;using namespace std;int main() &#123; int HEIGHT=2,WIDTH=3,DEPTH=5; // construct array3D[HEIGHT][WIDTH][DEPTH] vector&lt;vector&lt;vector&lt;double&gt; &gt; &gt; array3D; array3D.resize(HEIGHT); for (int i = 0; i &lt; HEIGHT; ++i) &#123; array3D[i].resize(WIDTH); for (int j = 0; j &lt; WIDTH; ++j) array3D[i][j].resize(DEPTH); &#125; return 0;&#125; 以上出现段错误的原因在于申请了过多的vecotr，导致占空间不够用，从而出现段错误，现在来看以下vector在内存中具体是如何存储的，首先看一下以下三种方式的声明： 1234std::vector&lt;T&gt; vec;std::vector&lt;T&gt;* Vec = new std::vector&lt;T&gt;();std::vector&lt;T*&gt; vec; 假设T是一个类型或者一个定义好的类，则以上三种情况的内存分配情况如下： 对于std::vector&lt;T&gt; vec；vec在栈上（stack），而其中的元素T保存在堆上（heap）； 对于std::vector&lt;T&gt;* Vec = new std::vector&lt;T&gt;()；vec和其中的元素T都保存在堆上； 对于std::vector&lt;T*&gt; vec；vec在栈上（stack），而其中的元素T保存在堆上（heap）；和第一种情况类似。 存储在栈上的元素，往往无需手动管理内存空间，通常会自动释放，而在堆上的空间，则需要手动管理。 在实现项目ZeroTensor的专属异常类时，需要实现exception类的what方法。出现问题及解决办法首先需要看一下exception基类中关于what方法的原始定义： 12 下面是正确的重写方式 1const char *what() const throw() override &#123; return error_msg_.c_str(); &#125; 如果去掉throw() ， 则会报错： 12looser throw specifier for ‘virtual const char* zerotensor::ZerotensorError::what() const’ const char *what() const override &#123; return error_msg_.c_str(); &#125; 如果将char * 改为 string，则会报错： 12error: ‘const string zerotensor::ZerotensorError::what() const’ cannot be overloaded const string what() const throw() override &#123; return error_msg_; &#125;]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十六章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter16%2F</url>
    <content type="text"><![CDATA[第十六章 string类和标准模板库16.1 string 类头文件： string：支持的是string类 string.h / cstring： 支持的是C-风格字符串的C库字符串函数 16.1.1 构造字符串string类的构造函数如下（用ctor标识，这是传统C++中构造函数的缩写，表中的NBTS（null-terminated string）标识以空字符结束的字符串——传统的C字符串，size_type 是一个依赖于实现的整型，在头文件string中定义）： 构造函数 描述 string(const char *s) 将string对象初始化为s指向的NBTS string(size_type n, char c) 创建一个包含n个元素的string对象，其中每个元素都被初始化为字符c string(const string &amp;str) 将一个string对象初始化为string对象str（复制构造函数） string() 创建一个默认的string对象，长度为0（默认构造函数） string(const char *, size_type n) 将string对象初始化为s指向的NBTS的前n个字符，即使超过了NBTS的结尾 template string(Iter begin, Iter end) 将string对象初始化为区间[begin,end)内的字符，其中begin和end的行为就像指针，用于指定位置，范围包括begin在内，但不包括end string(const string &amp;str, size_type pos = 0, size_type n = npos) 将一个stirng对象初始化为对象str从位置pos开始到结尾的字符，或从pos开始的n个字符 string(string &amp;&amp; str) noexcept C++11新增，它将一个string对象初始化为对象str，并可能修改str（移动构造函数） string(initializer_list il) C++11新增，它将一个string对象初始化为初始化列表il中的字符 在使用构造函数时都进行了简化，即隐藏了这样一个事实：string实际上是模板具体化basic_string&lt;char&gt;的一个typedef，同时省略了与内存管理相关的参数 16.1.2 string类输入对于C-风格字符串，有3种方式：12345char info[100];cin &gt;&gt; info; //read a word 遇到空格换行停止cin.getline(info, 100); // read a line, discard \ncin.get(info, 100); // read a line, leave \n in queue 对于string对象，有两种方式：123string stuff;cin &gt;&gt; stuff; // read a wordgetline(cin, stuff); // read a line, discard \n 两个版本的getline都有一个可选参数，用于指定使用哪个字符来确定输入的边界。在功能上，它们之间主要的区别在于，string版本的getline()将自动调整目标string对象的大小，使之刚好能够存储输入的字符。1234567char fname[10];string lname;cin &gt;&gt; fname; // could be a problem if input size &gt; 9 chcin &gt;&gt; lname; // can read a very,very long wordcin.getline(fname,10); // may truncate inputgetline(cin, fname); // no truncation 在设计方面的一个区别是，读取C-风格字符串的函数是istream类的方法，而string版本是独立的函数。这就是对于C-风格字符串输入，cin是调用对象；而对于string对象输入，cin是一个函数参数的原因。这种规则也适用于&lt;&lt;形式：1123cin.operator&gt;&gt;(fname);operator&gt;&gt;(cin, lname); string类可以自动调整对象的大小，使之与输入匹配，但也存在一些限制： string对象的最大允许长度： 由常量string::npos 指定，通常是最大的unsigned int值 程序可以使用的内存量 string版本的getline()函数从输入中读取字符，并将其存储到目标string中，知道发生下列三种情况之一： 到达文件尾，在这种情况下，输入流的eofbit将被设置，这意味着方法fail()和eof()都将返回true； 遇到分界字符（默认为\n），在这种情况下，将把分解字符从输入流中删除，但不存储它 读取的字符数打到最大允许值（string::npos与可供分配的内存字节数中较小的一个），在这种情况下，将设置输入流的failbit，这意味着方法fail()返回true。 16.1.3 使用字符串C++对每个关系运算符进行了重载，以便能够将string对象与另一个string对象或C-风格字符穿进行比较：123operator&lt;(const string &amp;, const string &amp;);operator==(const string &amp;, const char *);operator!=(const char *, const string &amp;); size()和length()方法都返回字符串中的字符数，二者没有区别，前者是为提供STL兼容性添加的，后者是较早版本的string类使用的方法名。 可以以多种不同的方式在字符串中搜索给定的子字符串或字符。下表描述是了find()方法的4个版本。 方法原型 描述 size_type find(const string &amp;st ,size_type pos=0) const 从字符串的pos位置开始，查找子字符串str。如果找到，则返回该字符串首次出现时其首字符的索引；否则，返回string::npos size_type find(const char* s, size_type pos=0) const 从字符串的pos位置开始，查找子字符串s。如果找到，则返回该字符串首次出现时其首字符的索引；否则，返回string::npos size_type find(const char *s, size_type pos=0,size_type n) 从字符串的pos位置开始，查找s的前n个字符组成的子字符串。如果找到，则返回该子字符串首次出现时其首字符的索引；否则，返回string::npos size_type find(char ch, size_type pos = 0) const 从字符串的pos位置开始，查找字符ch。如果找到，则返回该字符首次出现的位置；否则，返回string::npos 除此之外，string库还提供了其他相关的方法：rfind() ,find_first_of(), find_last_of(), find_first_not_of(), find_last_not_of()等等。 16.1.4 stirng类还提供了哪些功能更详细的可以查看附录F. capacity(): 返回当前分配给字符串的内存块大小reserve(): 请求能够申请的最小的内存块c_str(): 返回一个指向 C 风格字符串的指针(char *) 16.1.5 字符串种类表面上看起来string类是基于char类型的，但是，实际上，string库是基于一个模板类的：12345template&lt; class CharT, class Traits = std::char_traits&lt;CharT&gt;, class Allocator = std::allocator&lt;CharT&gt;&gt; class basic_string; 模板basic_string有四个具体化，每个具体化都有一个typedef名称，如string对应basic_string&lt;char&gt;、wstring对应basic_string&lt;wchar_t&gt;、u16string对应basic_string&lt;char16_t&gt;等等。 16.2 智能指针模板类智能指针是行为类似于指针的 类对象 。共有三种可以帮助管理动态内存分配的智能指针模板： auto_ptr unique_ptr shared_ptr 模板auto_ptr是C++98提供的解决方案，C++11已将其摒弃，并提供了后两种解决方案。 16.2.1 使用智能指针以上三个智能指针模板（auto_prt,unique_ptr,shared_ptr)都定义了类似指针的对象，可以将new获得的地址赋给这种对象。 当智能指针过期时，其析构函数将使用delete来释放内存，因此，如果将new返回的地址赋给这种对象，将无需记住稍后释放这些内存。（要创建智能指针，需包含头文件memory） 16.2.2 有关智能指针的注意事项当多个指针对象指向同一个对象时，三种智能指针的区别： auto_ptr：调用多次析构函数，执行多次delete，报错 unique_ptr：建立所有权（ownership）概念，对于特定的对象，只能有一个智能指针可拥有它，在删除后，会将所有权转让 shared_ptr：利用引用计数（reference counting），仅当最后一个指针过期时，才调用delete。 16.2.3 unique_ptr为何优于auto_prtunique_ptr更安全： 它使用了C++11新增的移动构造函数和右值引用unique_ptr可以用于数组的变体：auto_ptr智能使用new和delete，而unique_ptr可以还可以使用new []和delete []。 警告： 使用new分配内存时，才能使用auto_ptr和shared_ptr，使用new[]分配内存时，不能使用它们 不使用new分配内存时，不能使用auto_ptr和shared_ptr 不使用new和new[]分配内存时，不能使用unique_ptr 16.2.4 选择智能指针如果程序要使用多个指向同一个对象的指针，应选择shared_ptr。 16.3 标准模板库STL提供了一组表示容器、迭代器、函数对象和算法的模板。 容器：是一个与数组类似的单元，可以存储若干个值。STL容器是同质的，即存储的值的类型相同 迭代器：能够用来遍历容器的对象，与能够遍历数组的指针类似，是广义指针 函数对象：类似于函数的对象，可以是类对象或函数指针 算法：完成特定任务（如find，verse等）。 STL不是面对对象的变成，而是一种不同的编程模式——泛型编程（generic programming） 关于更多个STL方法和函数可以看附录G 16.3.1 模板类vector分配器：与string类相似，各种STL容器模板都接受一个可选的模板参数，该参数指定使用哪个分配器对象来管理内存。如果省略了该模板参数的值，则容器类模板将默认使用allocator&lt;T&gt;类，这个类使用new和delete。 123template &lt;class T, class Allocator = allocator&lt;T&gt; &gt;class vector &#123;...&#125; 16.3.2 可对矢量执行的操作每个容器类都定义了一个合适的迭代器，该迭代器的类型是一个名为iterator的typedef，其作用域为整个类。 1vector&lt;double&gt;::iterator pd; // pd an iterator 超尾(past-the-end) ：一种迭代器，指向容器的最后一个元素的后面，就像是C-风格字符串最后一个字符后面的空字符一样，由end()成员函数标识。 16.3.3 对矢量可执行的其他操作对于搜索、排序、随机排序等等很常见的操作，矢量模板类并没有包含！！ 但是 ，STL从更广泛的角度定义了非成员（non-member）函数来执行这些操作，即不是为每个容器类定义find()函数，而是定义了一个适用于所有容器类的非成员函数find()。这种设计理念省去了大量重复的工作。 另一方面，STL有时也会定义一个功能相同的成员函数。这是因为对有些操作来说，类特定算法的效率比同于算法高，比如，vector的成员函数swap()的效率比非成员函数swap()高，但非成员函数可以交换冷儿类型不同的容器的内容。 16.3.4 基于范围的for循环（C++11）第五章的示例： 123double prices[5] = &#123;4.99, 10.99, 6.87, 7.99, 8.48&#125;;for (double x : prices) cout &lt;&lt; x &lt;&lt; std::endl; 在这种for循环中，先声明一个类型与容器内容类型相同的变量，然后写明容器名称，接下来就可以访问，如下面的代码可以写的更加精简： 1234for_each(books.begin(), books.end(), ShowReview); //for_each形式for( auto x:books) ShowReview(x)); // 注意，for_each不能修改容器的容器，而基于范围的for循环可以通过指定一个引用参数来修改内容。例如，假设有如下函数：1void InflateReview(Review &amp;r) &#123;r.rating++;&#125; 可使用如下循环的books的每个元素执行该函数1for(auto &amp;x:books) InflateReview(x); 16.4 泛型编程面向对象编程关注的是编程的数据方面，而泛型编程关注的是算法。它们之间的共同点是抽象和创建可重用代码，但它们的理念决然不同。泛型编程旨在编写独立于数据类型的代码。 16.4.1 为何使用迭代器模板使得算法独立于存储的数据类型，而迭代器使算法独立于使用的容器类型。 例如，在使用find函数时，可以用迭代器来实现不依赖于具体类型的查找。 实际上，作为一种编程风格，最好避免直接使用迭代器，而应尽可能使用STL函数(如for_each()）来处理细节。也可以使用C++11新增的基于范围的for循环。 16.4.2 迭代器类型不同的算头对迭代器要求不同，有的只要求可读，有的要求可随机访问等等。STL定义了5种不迭代器，并根据所需的迭代器类型对算法进行了描述： 输入迭代器 输出迭代器 正向迭代器 双向迭代器 随机访问迭代器 对于不同的算法，需要的迭代器不同，如下面两种算法分别需要输入迭代器和随机访问迭代器 12345template&lt;typename InputIterator, typename T&gt;InputIterator find(InputIterator first, InputIterator last, const T &amp;value);template&lt;typename RandomAccessIterator&gt;void sort(RandomAccessIterator first, RandomAccessIterator last); 对于这5种迭代器，都可以执行解除引用操作（即*运算符），也可进行比较，看其是相等还是不相等（==，！=运算符）。如果两个迭代器相同，则对它们执行解除引用操作得到的值将相同。 输入迭代器 &emsp;&emsp;术语“输入”是从程序的角度出发的，即来自容器的信息被视为输入（从迭代器传到程序中），因此，输入迭代器可被程序用来读取容器中的信息。需要输入迭代器的算法将不会修改容器中的值 &emsp;&emsp;输入迭代器必须能做访问容器中所有的值，这是通过支持++运算符（前缀格式operator++和后缀格式operator++(int)）来实现的。 &emsp;&emsp; 注意： 并不能保证输入迭代器第二次遍历容器时，顺序不变。另外，输入迭代器被递增后，也不能保证其先前的值仍然可以被解除引用。基于输入迭代器的任何算法都应当是单通行（single-pass）的，不依赖于前一次便利时的迭代器值，也不依赖于本次遍历中前面的迭代器值。—— 输入迭代器是单向迭代器，可以递增，但不能倒退 输出迭代器 &emsp;&emsp;同理，“输出”指用于将信息从程序传输给容器的迭代器（从程序输出到迭代器中），输出迭代器智能解除引用让程序修改容器值，而不能读取容器内的值。输出迭代器也是单通行的，只能写不能读。 正向迭代器 &emsp;&emsp; 只是用++运算符遍历容器，每次沿容器向前移动一个元素。与输入和输出迭代器不同的是，它总是按相同的顺序遍历一系列值，另外，将正向迭代器递增后，仍然可以对前面的迭代器值解除引用，并得到对应的值 。这些特征使得正向迭代器是多通行的（可以多次通行容器）。 双向迭代器 &emsp;&emsp;双向迭代器具有正向迭代器的所有特性，且同时支持两种（前缀和后缀）递减运算符。 随机访问迭代器 &emsp;&emsp;有些算法（如排序和二分检索）要求能够直接跳到容器中的任何一个元素（将想数组下标访问一样），因此就有了随机访问迭代器。该迭代器具有双向迭代器的所有特性，同时添加了支持随机访问的操作和用于对元素进行排序的关系运算符。 16.4.3 迭代器层次结构可以看出，迭代器类型形成了一个层次结构。后面的迭代器不仅拥有之前迭代器的所有功能，同时还有自己的功能。 每个容器类都定义了一个类级typedef名称——iterator。（实际上这使用指针实现的，并不是一种新的类型）。 16.4.4 概念、改进和模型STL有若干个用C++语言无法表达的特性，如迭代器种类。正向迭代器是一系列要求，而不是类型。（迭代器通常可以用常规指针实现，所以迭代器本身并不是一种类型）。 STL使用术语“概念（concept）”来描述一系列的要求。 概念可以具有类似继承的关系，就像双向迭代器继承了正向迭代器的功能。然而，不能将C++继承机制用于迭代器，但从概念上看，它确实能够继承，有些STL文献使用属于改进（refinement）来表示这种概念上的继承，因此，双向迭代器是对正向迭代器概念的一种改进。 概念的具体实现被称为模型（model）。因此，指向int的常规指针是一个随机访问迭代器模型，同时也是一个正向迭代器模型。 将指针用作迭代器 &emsp;&emsp;迭代器是广义上的指针，其本身就是一种指针，因此，STL算法可以使用指针来对基于指针的非STL容器进行操作。例如，可将STL算法用于数组。123const int SIZE = 100;double Receipts[SIZE];sort(Receipts,Receipts+SIZE); //用STL的sort算法对数组进行排序 &emsp;&emsp;STL提供了一些预定义迭代器，如ostream_iterator和istream_iterator模板等，都定义在iterator头文件中。 其他有用的迭代器 &emsp;&emsp;头文件iterator还提供了其他一些专用的预定义迭代器类型，它们是reverse_iterator, back_insert_iterator, front_insert_iterator和insert_iterator等。 16.4.5 容器种类 容器概念：概念是具有名称（如容器、序列容器、关联容器等）的通用类别 容器类型：是可用于创建具体容器对象的模板。以前的11个容器类型为：deque, list, queue, priority_queue, stack, vector, map, multimap, set, multiset和bitset。 C++11新增了：forward_list, unordered_map, unordered_multimap, unordered_set和unordered_multiset，且不再将bitset视为容器，而将其视为一种独立的类别。 容器概念 &emsp;&emsp;没有与基本容器概念对应的类型，但概念描述了所有容器类都通用的元素。存储在容器中的类型必须是可复制构造和可赋值的。STL特定操作的时间复杂度有三种，分别是：编译时间、固定时间和线性时间。 C++11新增的容器要求 &emsp;&emsp;下表列出了C++11新增的通用容器要求，其中，复制赋值和移动赋值之间的差别在于，复制操作保留源对象，而移动操作可修改源对象，还可能转让所有权，而不做任何复制。如果源对象是临时的，移动操作的效率将高于常规复制。 表达式 返回类型 说明 复杂度 X u(rv); 调用移动构造函数后，u和值和rv的原始值相同 线性 X u = rv; 作用同上 a = rv; X&amp; 调用移动赋值运算符后，u的值和rv的原始值相同 线性 a.cbegin() const_iterator 返回指向容器第一个元素的const迭代器 固定 a.cend() const_iterator 返回超尾值的const迭代器 固定 序列 16.4.6 关联容器16.4.7 无序关联容器16.5 函数对象函数对象也叫做仿函数 (funtor). 仿函数是可以以函数方式与()运算符结合使用的任意对象. 重载后的()运算符将使得能够响函数那样使用类对象. 16.5.1 仿函数概念16.5.2 预定义的仿函数16.5.3 自适应仿函数16.7.3 使用initializer_list]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11 新特性-初始化列表]]></title>
    <url>%2Fz_post%2FCpp-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[构造函数与初始化列表初始化列表只能用于构造函数 在类的实现中，构造函数体内“初始化”的实际上是赋值而不是初始化。也就是说，当代码运行到构造函数内部时，初始化列表已经执行完了，因此相当于是先初始化了一遍，然后又赋值了一遍，重复计算，浪费效率，因此应该优先使用初始化列表。同时，当没有默认的无参构造函数时，就一定会使用初始化列表。(即使自己没有在含参构造函数中都是基本数据类型, 不强制显式使用初始化列表, 也会自动调用初始化列表, 而在构造函数内部执行的仅仅是赋值) 创建派生类对象时，程序首先调用基类构造函数，然后再调用派生类构造函数。基类构造函数负责初始化继承的数据成员；派生类构造函数主要用于初始化新增的数据成员。派生类构造函数总是需要调用一个基类构造函数。当基类没有默认的构造函数时，就必须显式指明调用哪一个构造函数。在继承关系中, 必须显式的在初始化列表中对基类初始化, 因为只有基类初始化完成后, 才能进行子类初始化, 而当进入子类构造函数内部时, 子类初始化已经完成. 注意：除了虚基类以外，类只能将值传递会相邻的基类，但后者可以使用相同的机制将信息传递给上层相邻的基类，以此类推。 C++的类对象创建过程C++ 在创建类时需要经过两个阶段：分配空间（Allocation）和初始化（Initialization） 分配空间创建C++类对象的第一步就是为其分配内存空间。对于全局对象，静态对象以及分配在栈区域内的对象，对它们的内存分配是在编译阶段就完成了，而对于分配在堆区域内的对象，它们的分配是在运行时动态进行的。内存空间的分配过程涉及到两个关键的问题：需要分配空间的大小以及是否有足够的内存空间来满足分配。 初始化首先需要区分两个概念：初始化（Initialization）和赋值（Assignment）。初始化早于赋值，它是随着对象的诞生一起进行的。而赋值是在对象诞生以后又给予它一个新的值。 在C++中，提供了类成员的初始化列表，并且初始化列表是先于构造函数体内的代码执行的。 哪些情况下只能用初始化列表(initialization list) 而不能用赋值 (assignment)对于以下三种情况，必须使用成员初始化列表 需要初始化的数据成员是对象的情况（包含继承情况下，通过显示调用父类的构造函数对父类数据成员进行初始化） 需要初始化const修饰的类成员 需要初始化引用成员数据 子类初始化父类的私有成员，需要在（并且只能在）参数初始化列表中显示调用父类的构造函数。（这种其实可以并到第一种情况，因为初始化私有成员，就意味着初始化对象） 类对象是默认使用初始化列表的，当没有无参构造函数时，就必须显式使用初始化列表（所以不论如何，都会使用到初始化列表）。 当类成员中含有一个const对象时，或者一个引用时，必须经过成员初始化列表进行初始化，因为const对象或者引用在声明的同时必须初始化，而在构造函数中，做的是对它们的赋值，并不是初始化。 初始化列表的顺序构造函数需要初始化的数据成员，不论是否显式的出现在构造函数的成员初始化列表中，都会在该处完成初始化，并且初始化的顺序和变量声明时的顺序是一致的，与列表中的先后顺序无关]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中类的对象和对象指针之间的区别]]></title>
    <url>%2Fz_post%2FCpp-%E7%B1%BB%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%92%8C%E5%AF%B9%E8%B1%A1%E6%8C%87%E9%92%88%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[很关键的一点：定义对象实例时，分配了内存，指针变量则未分配类对象所需内存。 类的指针:他是一个内存地址值,他指向内存中存放的类对象(包括一些成员变量所赋的值).对象,他是利用类的构造函数在内存中分配一块内存(包括一些成员变量所赋的值). 指针变量是间接访问，但可实现多态（通过父类指针可调用子类对象），并且没有调用构造函数。直接声明可直接访问，但不能实现多态，声明即调用了构造函数（已分配了内存）。 类的对象:用的是内存栈,是个局部的临时变量.类的指针:用的是内存堆,是个永久变量,除非你释放它. 1.在类的声明尚未完成的情况下，可以声明指向该类的指针，但是不可声明该类的对象… 例如：含有纯虚成员函数的抽象类。2.父类的指针可以指向子类的对象.. 在应用时: 1.引用成员: 对象用” . “操作符; 指针用” -&gt; “操作符. 2.生命期: 若是成员变量,则是类的析构函数来释放空间;若是函数中的临时变量,则作用域是该函数体内.而指针,则需利用delete 在相应的地方释放分配的内存块. 注意:用new ,一定要delete.. C++的精髓之一就是多态性，只有指针或者引用可以达到多态。对象不行类指针的优点：第一实现多态。第二，在函数调用，传指针参数。不管你的对象或结构参数多么庞大，你用指针，传过去的就是4个字节。如果用对象，参数传递占用的资源就太大了]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的const关键字]]></title>
    <url>%2Fz_post%2FCpp-const%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[const与#define相比, 有何优点? const常量具有数据类型, 而宏常量没有数据类型. 编译器可以对前者进行类型安全检查, 而对后者只会进行字符替换, 没有类型安全检查, 容易发生意想不到的错误. 从编译的角度来看, const定义的常量在程序运行过程中只有一份拷贝(因为对应的是内存地址, 全局的只读变量, 在静态区), 而#define相当于字符替换, 每一次替换相当于打了一次拷贝. 有些集成化的调试工具可以对const常量进行调试, 但是不能对宏常量进行调试. const常用形式及代表含义 含义 使用形式 及 作用 const常量 const int Max = 100; int const Max =100 const与int的位置可互换，二者等价 修饰后的变量在程序的任意位置将不能再被修改，就如同常数一样，任何修改该变量的尝试都会导致编译错误（由于常量在定义以后就不能再被修改，所以定义时必须初始化）。 对于类中的const成员变量必须通过初始化列表进行初始化 const引用 const int i = 1024； const int &amp;ref_i = i; int const &amp;ref2_i = i后两句等价int &amp;const ref3_i = i这种方式未定义，会报错：‘const’ qualifiers cannot be applied to ‘int&amp;’ cosnt引用是指向const对象或者普通对象的引用，该引用ref_i可以读取对象i的值，但是，不能修改 i的值，任何对ref_i的赋值都是非法的。 并且 不能用普通引用指向const常量（int &amp;ref4_i = i; // 非法）。（注意，一旦引用被定义，它就不能再指向其它对象，这是引用本身的性质，这也是为什么引用必须进行初始化的原因）。 总结来说就是const引用只是表明：保证不会通过此引用间接的改变被引用的对象！ const指针 1）int age = 39; const int *ptr = &amp;age; 2）const int age = 98; const int *ptr = &amp;age;3）const int age = 32; int *ptr = &amp;age;4）int age = 90; int * const ptr = &amp;age; 对于1），const修饰的是int，表明ptr指向一个const int，但是ptr和age本身都不是const，不能使用ptr来修改age的值，但是age自身可以修改自己的值，同时，ptr也可以转而指向其它变量； 对于2），const修饰的是int，表明ptr指向一个const int，同时age本身就是const，说明既不能通过ptr，也不能通过age来修改变量age的值，但是ptr本身仍然不是const，因此可以转而指向其它变量；对于3），C++禁止将const变量的地址赋给非const指针（除非使用强制类型转换）；对于4），const修饰的是*，表明ptr本身是一个常量指针，这使得ptr自身的值不能改变，也就是只能指向age，不能指向其它变量 const函数参数 void fun(const int * i); void fun(const int &amp; i); 不能在函数体内修改指针或引用指向的值，但是这里指针可以转而指向其他值（其实没多大用，因为指针本身就是值传递，即使改变指向，也不会影响实参的指向，除非用二级指针） const函数返回值 const int fun( int i); 阻止用户修改返回值，返回值必须要相应的赋给一个具有const属性的变量 const成员函数 &lt;类型说明符&gt; &lt;函数名&gt; ( &lt;参数表&gt; ) const; 不会修改类的成员数据，也不能调用其它非const成员函数。 可以利用const限定符实现函数重载。 const对象默认会调用const成员函数 const限定符和static的区别 静态变量的值虽然只能进行一次初始化，但是它的值是可变的。而const的值是不可变的。 const定义的变量在超出其作用域后空间就会被释放，而static定义的静态变量不会释放空间，而是一直存在，知道程序结束 static表示静态，类的静态成员函数、静态成员变量都是和类相关的，而不是和具体的对象相关，即使没有具体对象，也能调用静态成员函数和静态成员变量。而类则是和具体的对象相关的，不同的对象独占一个const变量 static静态成员变量不能在类的内部进行初始化，智能在类的外部进行初始化，并且初始化时不能加static关键字。之后，无需创建对象也能通过类使用该静态变量，同时 由于const变量只是针对于某个类的对象而言的，类可以创建多个不同的对象，每个对象都有自己的const变量，又因为const变量值只能进行一次初始化而不仅再次赋值，因此， const变量也不能在类的内部初始化，而只能在类构造函数的初始化列表中进行 。 如果想要创建整个类的恒定变量，那么应用使用static const来声明（const枚举量也可以） 关于const的其它注意事项将非const指针赋给const指针（两级间接关系）p222 const引用与不可寻址值const引用可以用不同类型的对象初始化（主要能从一种类型转换到另一种类型即可），也可以用字面常量初始化，如下所示： 12345double dval = 3.14159;//下3行仅对const引用才是合法的const int &amp;ir = 1024;const int &amp;ir2 = dval; //隐式类型转换，生成临时变量const double &amp;dr = dval + 1.0; 首先要知道，上面的初始化对于非cosnt引用是不合法的，将导致编译错误！ 原因：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如文字常量，以及不同类型的对象，编译器为了实现引用，必须生成一个临时对象，将该对象的值置入临时对象中，引用实际上指向该对象（对该引用的操作就是对该临时对象的操作），但用户不能访问它。因此，C++为了不让用户通过引用修改该临时变量，强制要求必须使用const引用。 const引用与临时变量由于上面提到的原因， C++引用类型在面对会产生临时变量的语句时，必须使用const引用来指向！！切记！！ 1234567891011int i = 100;int *&amp;p_i = &amp;i;//错误int *const &amp;p_i = &amp;i; //正确写法，const修饰int *//&amp;代表p_i是一个引用（别名），*代表这个引用（别名）是一个指向int类型的指针，//而后面的&amp;i代表取i的地址，注意，这里会生成一个存储地址的临时变量，因此，指向该临时变量的引用（别名）必须为const，//也就是说，这个指向int的指针本身必须是const的，因为不能修改临时变量的值const int i = 100;int *&amp;p_i = &amp;i;// 错误，有临时变量生成，引用必须是constint *const &amp;p_i = &amp;i; //错误，由于i本身就是cosnt，因此指针必须是一个指向cosnt int的指针const int *const &amp;p_i = i;//正确 const引用与非const引用在内存中的对比内存地址都是一样的，网上有的写不一样，是错误的！ 1234567891011cosnt int t = 9;const int &amp;k = t;cout&lt;&lt;&amp;k&lt;&lt;endl; // 0012FF74cout&lt;&lt;&amp;t&lt;&lt;endl; // 0012FF74int t = 9;int &amp;k = t;const int &amp;m = t;cout&lt;&lt;&amp;k&lt;&lt;endl; // 0012FF74cout&lt;&lt;&amp;m&lt;&lt;endl; // 0012FF74cout&lt;&lt;&amp;t&lt;&lt;endl; // 0012FF74 不允许非const引用指向需要临时对象的对象或值，即，编译器产生临时变量的时候引用必须为const!!!!切记！！12345678910int iv = 100;int * &amp;pir = &amp;iv;//错误，非const引用对需要临时对象的引用int *const &amp;pir = &amp;iv;//okconst int ival = 1024;int *&amp;pi_ref = &amp;ival; //错误，非const引用是非法的const int *&amp;pi_ref = &amp;ival; //错误，需要临时变量，且引用的是指针，而pi_ref是一个非常量指针const int * const &amp;pi_ref = &amp;ival; //正确//补充const int *p = &amp;ival;const int *&amp;pi_ref = p; //正确 const变量的生存期、作用域和链接性临时变量一般会在语句块的末尾自动释放，但是有两个例外： 将临时对象作为初始化因子，例如string s = string(&quot;hello world&quot;); 将一个常量引用变量绑定到这个临时对象上。 作用域在全局作用域中声明的const变量，只能在当前文件中访问，如果要在其他文件中使用，则必须用extern显式的声明const变量全局变量。（在C中，可以不用extern？） 用const修饰函数参数是否应将void Func(int x) 改写为void Func(const int &amp;x)，以便提高效率？完全没有必要，因为内部数据类型的参数不存在构造、析构的过程，而复制也非常快，“值传递”和“引用传递”的效率几乎相当。问题是如此的缠绵，我只好将“const &amp;”修饰输入参数的用法总结一下。对于非内部数据类型的输入参数，应该将“值传递”的方式改为“const 引用传递”，目的是提高效率。例如将void Func(A a) 改为void Func(const A &amp;a)。 对于内部数据类型的输入参数，不要将“值传递”的方式改为“const 引用传递”。否则既达不到提高效率的目的，又降低了函数的可理解性。例如void Func(int x) 不应该改为void Func(const int &amp;x)。 用const修饰函数的返回值 修饰内置类型的返回值时, 加const没有意义 修饰自定义类型的返回值时, 此时的返回值不能作为左值使用, 既不能被赋值, 也不能被修改 修饰指针或引用的返回值时, 取决于我们想让用户干什么 用const修饰类的成员函数表明该函数 不能修改类对象的数据成员, 并且不能调用非 const 函数 (因为非const函数有可能会修改数据成员) 1int GetCount(void) const; // const 成员函数 在修饰成员函数时, const 关键字不能与 static 关键字同时使用, 因为 static 关键字修饰的是静态成员函数, 其不含有this指针, 因此不能实例化, 而 const 成员函数必须具体到某一实例. 类中的const常量有时我们希望某些常量只在类中有效, 由于#define定义的宏常量是全局的, 因此不能达到目的, 但是直接用const修饰数据成员并不是我们想要的含义, const数据成员只在某个对象(注意是对象, 不是类)生存期内是常量, 而对于整个类而言却是可变的, 因为类可以创建多个对象, 不同的对象其const数据成员的值可以不同. 从上面的概念我们可以得出, 不能在类声明中初始化const数据成员, 而应该在类的构造函数的初始化表中进行. 要建立整个类中的常量, 则应该使用枚举常量, 枚举常量的缺点是, 它的隐含数据类型是整数, 其最大值有限, 且不能表示浮点数.]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的virtual关键字]]></title>
    <url>%2Fz_post%2FCpp-virutal%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[虚函数与运行多态多态：多态按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会用到多态。C++ 多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。 先看最简单的情况，也就是最普通形式的继承，且父类和子类的方法都是一般成员方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Car&#123; public: Car()&#123;cout&lt;&lt;"Car constructor"&lt;&lt;endl;&#125; ~Car()&#123;cout&lt;&lt;"Car destructor"&lt;&lt;endl;&#125; // 若将成员成员函数声明为const，则该函数不允许修改类的数据成员 void start() const&#123;cout&lt;&lt;"car start"&lt;&lt;endl;&#125; void stop() const&#123;cout&lt;&lt;"car stop"&lt;&lt;endl;&#125;&#125;;//Benz类，单一继承自Carclass Benz : public Car&#123; public: Benz()&#123;cout&lt;&lt;"Benz constructor"&lt;&lt;endl;&#125; ~Benz()&#123;cout&lt;&lt;"Benz destructor"&lt;&lt;endl;&#125; void start() const&#123;cout&lt;&lt;"Benz start"&lt;&lt;endl;&#125; void stop() const&#123;cout&lt;&lt;"Benz stop"&lt;&lt;endl;&#125;&#125;;// Baoma类，单一继承自Carclass Baoma:public Car&#123; public: Baoma()&#123;cout&lt;&lt;"Baoma constructor"&lt;&lt;endl;&#125; ~Baoma()&#123;cout&lt;&lt;"Baoma destructor"&lt;&lt;endl; &#125; void start() const&#123;cout&lt;&lt;"Baoma start"&lt;&lt;endl;&#125; void stop() const&#123;cout&lt;&lt;"Baoma stop"&lt;&lt;endl;&#125; private: int speed;&#125;;//以上三个类均具有start和stop的同名成员函数//调用成员函数start和stopvoid carFunction(Car *car)&#123; car-&gt;start(); car-&gt;stop();&#125;int main(int argc,char *argv[])&#123; Car *benz = new Benz(); cout&lt;&lt; size of(Benz)&lt;&lt;endl; carFunction(benz); Car *baoma = new Baoma(); cout&lt;&lt; size of(Baoma)&lt;&lt;endl; carFunction(baoma); delete benz; delete baoma; return 0;&#125; 输出结果如下：123456789101112Car constructorBenz constructor1 //内部没有成员变量,因此只有一个字节的空间car startcar stopCar constructorBaoma constructor4 //函数是不占用内存的,baoma中有一个int类型.所以 size of为4car startcar stopCar destructorCar destructor 首先，为什么Benz类内部明明没有任何变量，还具有一个字节的 size ？这是因为C++编译器不允许对象为零长度（试想一个长度为0的对象在内存中怎么存放？怎么获取它的地址？）。为了避免这种情况，C++强制给这种类插入一个缺省成员，长度为1。如果有自定义的变量，那么变量将取代这个缺省成员。 其次，Benz和Baoma都是继承自Car类，根据 里氏替换原则 ，父类能够出现的地方，那么子类也一定能出现。依赖抽象而不去依赖具体,在上述的函数调用过程中,我们传进去的是benz和baoma指针.但是在调用函数的时候,它并没有去调用子类的方法,这也就是一般成员函数的局限性,就是在编译的时候,一般性的函数已经被静态的编译进去,所以在调用的时候不能去选择动态调用. 另外, 这里的指针都是基类指针, 如果函数不是 virtual 的，则进行的是静态绑定，即在编译期间就决定了其调用的函数. 所以, 在删除时, 只会调用基类的析构函数, 而不会调用子类的析构函数. 如果将指针的类型声明为子类类型, 那么调用顺序是先调用子类的析构函数, 再调用基类的析构函数. 里氏替换原则：派生类（子类）对象可以在程式中代替其基类（超类）对象 加入vitural关键字修饰的函数,将父类函数变为虚函数,看看变化：在某个类中的某个函数之间加了 virtual 关键字以后, 该函数就会变成虚函数, 同时, 该类的所有派生类都会默认将此函数当做是虚函数, 无需显式使用 virtual 关键字注明. 派生类经常(但不总是)覆盖它要继承的虚函数, 如果派生类没有覆盖基类中的某个虚函数, 则派生类会自动继承基类版本的虚函数作为自己的虚函数. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//和上面几乎一样，都是一般的成员方法，只不过加上了virtual关键字#include&lt;iostream&gt;using namespace::std;class Car&#123; public: Car()&#123; cout&lt;&lt;"Car constructor"&lt;&lt;endl; &#125; ~Car()&#123; cout&lt;&lt;"Car destructor"&lt;&lt;endl; &#125; virtual void start() &#123; cout&lt;&lt;"car start"&lt;&lt;endl; &#125; virtual void stop() &#123; cout&lt;&lt;"car stop"&lt;&lt;endl; &#125;&#125;;class Benz : public Car&#123; public: Benz()&#123; cout&lt;&lt;"Benz constructor"&lt;&lt;endl; &#125; ~Benz()&#123; cout&lt;&lt;"Benz destructor"&lt;&lt;endl; &#125; //子类继承父类,如果是虚函数,可以写上vitural也可以不写 virtual void start() &#123; cout&lt;&lt;"Benz start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Benz stop"&lt;&lt;endl; &#125;&#125;;class Baoma:public Car&#123; public: Baoma()&#123; cout&lt;&lt;"Baoma constructor"&lt;&lt;endl; &#125; ~Baoma()&#123; cout&lt;&lt;"Baoma destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Baoma start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Baoma stop"&lt;&lt;endl; &#125; private: int speed;&#125;;void carFunction(Car *car)&#123; car-&gt;start(); car-&gt;stop();&#125;int main(int argc,char *argv[])&#123; Car *benz = new Benz(); cout&lt;&lt; size of(Benz)&lt;&lt;endl; carFunction(benz); Car *baoma = new Baoma(); cout&lt;&lt; size of(Baoma)&lt;&lt;endl; carFunction(baoma); delete benz; delete baoma; return 0;&#125; 输出结果如下： 12345678910111213Car constructorBenz constructor8Benz startBenz stopCar constructorBaoma constructor16Baoma startBaoma stopCar destructorCar destructor 从上面的输出结果中可以看到,加入了虚函数之后,调用不同指针对象指定函数的时候,这个时候都是去自动调用当前对象类中的具体函数形式,而不是像一般函数的调用一样,只是去调用父类的函数.这就是virtural关键字的作用,因为一般函数调用编译的时候是静态编译的时候就已经决定了,加入了virtural的函数,一个类中函数的调用并不是在编译的时候决定下来的,而是在运行时候被确定的,这也就是虚函数. 虚函数就是由于在编写代码的时候并不能确定被调用的是基类的函数还是哪个派生类的函数，所以被 为“虚”函数。 虚函数只能借助于指针或者引用来达到多态的效果， 直接声明的类对象无法达到多态目的。 这里可以看到, 指针 size 不再是1和4, 而是变成了8和16, 这是因为虚函数需要一张虚函数表来维护, 因此会使类的 size 改变, 具体原理可看下一节. 另外, 注意到这里在删除指针时, 由于指针的类型是基类, 因此同样只会调用基类的析构函数. 总结： 虚函数的调用取决于指向或者引用的对象的类型，而不是指针或者引用自身的类型。 注意: C++中的虚函数的作用主要是实现了多态的机制。关于多态，简而言之就是用父类型别的指针指向其子类的实例，然后通过父类的指针调用实际子类的成员函数。 对C++ 了解的人都应该知道虚函数（Virtual Function）是通过一张虚函数表（Virtual Table）来实现的。简称为V-Table。在这个表中，主是要一个类的虚函数的地址表，这张表解决了继承、覆盖的问题，保证其容真实反应实际的函数。这样，在有虚函数的类的实例中这个表被分配在了这个实例的内存中，所以，当我们用父类的指针来操作一个子类的时候，这张虚函数表就显得由为重要了，它就像一个地图一样，指明了实际所应该调用的函数 带有虚函数的对象自身确实插入了一些指针信息，而且这个指针信息并不随着虚函数的增加而增大,这也就是为什么上述增加了虚函数后,出现了 size 变大的现象 虚函数表与虚函数表指针“多态” 的关键在于通过基类指针或者引用调用一个虚函数时, 无法在编译过程中确定到底调用的是基类还是派生类的函数, 只有在运行阶段才能确定, 这种机制是如何实现的呢? C++ 中虚函数这种多态的性质是通过虚函数表指针和一张虚函数表来实现的： vptr(虚函数表指针, 占 4 个字节): 一个指向虚函数表的指针，每个对象 都会拥有这样的一个指针. C++ 的编译器将虚函数表指针存放在对象实例中最前面的位置, 这是为了保证取得虚函数表时具有最高的性能. vtable(虚函数表): 每一个含有虚函数的类都会维护一个虚函数表，里面按照声明顺序记录了该类的全部虚函数的地址 在进行虚函数的调用时, 编译器会根据基类指针所指向(或者基类引用所引用)的对象中的虚函数表指针找到该类的虚函数表, 然后在虚函数表中查找要调用的虚函数的地址, 可以简单的认为虚函数表是以函数名作为索引来查找的, 不过实际上会使用更高效的查找方法. 最后, 根据找到的虚函数的地址进行函数调用. 上面简单介绍了虚函数表的作用, 下面我们详细讨论一下虚函数表的注意事项. 每个包含了虚函数的类都包含一个虚函数表. 当基类包含虚函数时, 继承它的派生类也会自动维护一张虚函数表. 当一个类(A)继承另一个类(B)时, 类A会继承类B的函数的调用权, 所以如果一个基类包含了虚函数, 那么其继承类也可调用这些虚函数, 换句话说, 如果一个类继承了包含虚函数的基类, 那么这个类也拥有自己的虚表. 虚表是一个指针数组, 其元素是指向虚函数的指针. 虚表是对应类而言的, 而不是对应某个具体的对象, 一个类只需要一个虚表即可, 同一个类的所有对象都共享同一张虚函数表. 虚表指针时对应与对象而言的, 每个具体的对象都会持有一个虚表指针, 它们都指向了该类的虚函数表. 为了使用虚表, 类或对象内部都会包含一个虚表指针, 用来指向自己所使用的虚表. 为了让每个包含虚表的类的对象都拥有一个虚表指针, 编译器会在类中添加一个指针*__vptr来指向自己的虚表, 这样, 类的对象在创建时便拥有了这个指针, 且这个指针的值会自动被设置为指向类的虚表. 假设类A是虚基类, 类B继承类A, 类C又继承类B, 则它们的虚表关系如下图所示: 可以看到, 类A, B, C 中都会有一个专门的指针来指向虚表(一般都处于类或对象实例的最前面, 主要是为了提高取得函数表的速度), 并且指向的不是同一个虚表, 而是每个类都有自己的虚表, 只不过这些虚表最终指向的虚函数有可能相同(也有可能不同). 接下来看看下面这个简单的例子：12345678910111213class A&#123;public: virtual void fun();&#125;;class B&#123;public: void fun();&#125;; size of(A) &gt; size of(B) // true，因为A比B多了一个虚函数表指针 下面再来看看刚刚那个加薪的例子，其多态调用的形式如下图： 通常情况下，编译器在下面两处地方添加额外的代码来维护和使用虚函数表指针： 在每个构造函数中。此处添加的代码会设置被创建对象的虚函数表指针指向对应类的虚函数表 在每次进行多态函数调用时。 无论何时调用了多态函数，编译器都会首先查找vptr指向的地址（也就是指向对象对应的类的虚函数表），一旦找到后，就会使用该地址内存储的函数（而不是基类的函数）。 单继承时的虚函数表无虚函数覆盖:维护了一个虚函数表, 并且表中函数指针指向基类的各个虚函数. 子类中新添加的虚函数会放到虚函数表的后面 虚函数覆盖:对于同签名的函数, 会用子类的虚函数覆盖掉基类的同签名虚函数, 同样也只是维护一个虚函数表. 多重继承时的虚函数表多重继承会有多个虚函数表, 几重继承, 就会有几个虚函数表. 这些表按照派生的顺序依次排列, 如果子类改写了父类的虚函数, 那么就会用子类自己的虚函数覆盖虚函数表的相应位置, 如果子类有新的虚函数, 那么就会添加到第一个函数表的末尾. 假设类B继承了包含虚函数的类A1和类A2, 则其虚函数表的情况如下所示: 无虚函数覆盖:继承了几个基类, 就会维护几张虚函数表(按照继承顺序在实例最开始排列), 并且表中函数指针会指向其基类的各个虚函数, 子类中新添加的虚函数会放到第一个虚函数表的后面 虚函数覆盖:会用子类中的同签名虚函数同时覆盖多个基类中的同签名虚函数. 其余与无覆盖时的情况相同. 多重继承时的类型转换:在多重继承时, 用基类指针指向派生类对象, 派生类对象中新添加的虚函数会被添加到 第一个虚函数表的后面, 因此, 为什么虚函数表指针的类型为void *因为对于虚函数表来说, 一个类中的所有虚函数都会放到这个表中, 但是不同的虚函数对应的函数指针类型各不相同, 所以这个表的类型也就无法确定. 为什么虚函数表前要加const因为虚函数表是在编译时, 由编译器自动生成的, 并且不会发生改变, 当有多个B类的实例时, 每个实例都会维护一个虚函数表指针, 但是这些指针指向的都是同一个虚函数表, 该表是一个常量表. 类的 size 与虚函数从上面一节的代码示例中我们已经发现, 在 C++ 中, 普通函数只是一种表示, 其本身并不会占有任何内存, 而如果类中没有任何变量或者虚函数时, 类的 size 不会为1, 而是会自动插入一个字节, 并且在类的 size 大于1的时候, 该字节会被覆盖掉. 下面我们就从头开始讨论一下在 C++ 中是如何计算类的 size 的. 类的 size 为零123456789101112131415161718192021222324252627#include&lt;iostream&gt;using namespace::std;class Car&#123; public: Car()&#123; cout&lt;&lt;"Car constructor"&lt;&lt;endl; &#125; ~Car()&#123; cout&lt;&lt;"Car destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"car start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"car stop"&lt;&lt;endl; &#125;&#125;;int main(int argc,char *argv[])&#123; Car *p_car = new Car(); Car car; cout&lt;&lt; size of(Car)&lt;&lt;endl; // 类的 size cout&lt;&lt; size of(car)&lt;&lt;endl; // 对象的 size cout&lt;&lt; size of(p_car)&lt;&lt;endl; // 对象指针的 size return 0;&#125; 上面的输出为:123456Car constructorCar constructor118Car destructor 我们知道, 在 C++ 中, 普通函数只是在名义上存在于类中, 实际上函数的 size 并不会包括在类中, 因此, 这个类的 size 应该为0, 但是对于 size 为0的类我们无法存储其地址, 因此会额外赋予一个字节的 size , 注意当类的 size 不为0时, 这个字节就会被覆盖. 类中字节非对齐1234567891011121314151617181920212223242526272829#include&lt;iostream&gt;using namespace::std;class Car&#123; public: Car()&#123; cout&lt;&lt;"Car constructor"&lt;&lt;endl; &#125; ~Car()&#123; cout&lt;&lt;"Car destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"car start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"car stop"&lt;&lt;endl; &#125; private: char c;&#125;;int main(int argc,char *argv[])&#123; Car *p_car = new Car(); Car car; cout&lt;&lt; size of(Car)&lt;&lt;endl; // 类的 size cout&lt;&lt; size of(car)&lt;&lt;endl; // 对象的 size cout&lt;&lt; size of(p_car)&lt;&lt;endl; // 对象指针的 size return 0;&#125; 上面代码的输出为:123456Car constructorCar constructor118Car destructor 我们逐行来分析一下, 首先, 前两行代表调用了类的构造函数, 分别对应的对象指针和对象, 接下来, 我们求得类Car的 size 为1个字节, 这是因为在类中有一个char类型的变量, 对象car的 size 也为一个字节, 与类的 size 保持一致, 而对象指针的 size 为8个字节 , 因为对象指针的 size 仅与当前平台的编译器有关, 与类的 size 无关, 无论类的 size 是多少, 其对象指针的值都为8. 再来看一下继承时的情况:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include&lt;iostream&gt;using namespace::std;class Base1&#123; public: Base1()&#123; cout&lt;&lt;"Base1 constructor"&lt;&lt;endl; &#125; ~Base1()&#123; cout&lt;&lt;"Base1 destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Base1 start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Base1 stop"&lt;&lt;endl; &#125; private: char c;&#125;;class Base2&#123; public: Base2()&#123; cout&lt;&lt;"Base2 constructor"&lt;&lt;endl; &#125; ~Base2()&#123; cout&lt;&lt;"Base2 destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Base2 start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Base2 stop"&lt;&lt;endl; &#125; private: char c;&#125;;class Derived:public Base1, public Base2&#123; public: Derived()&#123; cout&lt;&lt;"Derived constructor"&lt;&lt;endl; &#125; ~Derived()&#123; cout&lt;&lt;"Derived destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Derived start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Derived stop"&lt;&lt;endl; &#125; private: char c;&#125;;int main(int argc,char *argv[])&#123; Base1 *p = new Derived(); Derived d; cout&lt;&lt; size of(Derived)&lt;&lt;endl; // 类的 size cout&lt;&lt; size of(d)&lt;&lt;endl; // 对象的 size cout&lt;&lt; size of(p)&lt;&lt;endl; // 对象指针的 size return 0;&#125; 输出为:123456789101112Base1 constructorBase2 constructorDerived constructorBase1 constructorBase2 constructorDerived constructor338Derived destructorBase2 destructorBase1 destructor 可以看到总共的 size 为两个基类所占空间和子类所占空间之和(同名不会冲突, 可以通过命名空间区分).这里只调用了一次析构函数, 因为new对应的内存必须要delete才能释放. 上面的两段代码并没有进行字节对齐, 原因是因为之后更大的变量出现, 所以可以用当前的 size 而无需进行对齐 对齐方式: 变量存放的起始地址相对于结构的起始地址的偏移量必须为某个数值的倍数. 同时会根据当前结构中的元素的最大字节数将总的 size 补成最大字节数的倍数. Char偏移量必须为sizeof(char)``即1的倍数int偏移量必须为sizeof(int)即4的倍数float偏移量必须为sizeof(float)即4的倍数double偏移量必须为sizeof(double)即8的倍数Short偏移量必须为sizeof(short)即2的倍数 虚函数表指针 偏移量必须为sizeof(vptr)`, 即8的倍数(64位系统) 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;using namespace::std;class Car&#123; public: Car()&#123; cout&lt;&lt;"Car constructor"&lt;&lt;endl; &#125; ~Car()&#123; cout&lt;&lt;"Car destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"car start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"car stop"&lt;&lt;endl; &#125; private: char c; int speed1; int speed2; int speed3; int speed4;&#125;;int main(int argc,char *argv[])&#123; Car *p_car = new Car(); Car car; cout&lt;&lt; size of(Car)&lt;&lt;endl; // 类的 size cout&lt;&lt; size of(car)&lt;&lt;endl; // 对象的 size cout&lt;&lt; size of(p_car)&lt;&lt;endl; // 对象指针的 size return 0;&#125; 代码与上面的代码基本相同, 只不过多了4个int类型的变量, 输出结果如下:123456Car constructorCar constructor20208Car destructor 按理说, 类中的 size 应为: $4\times 4 + 1 = 17$ 字节, 但是这里却为20字节, 这是因为 在C++中, 会对类进行字节对齐, 这点和 struct 有些相似, 对齐后, 会使类的 size 变成4个整数倍. 注意这里对象指针的 size 依然为8个字节, 与类的 size 无关. 最后, 只调用了一次析构函数, 这是因为用 new 申请的内存不会自动释放, 必须使用 delete 手动释放才可以. 虚函数对类 size 的影响注意, 对于不同的系统和编译器, sizeof的计算结果可能不一样, 简单来说, 虚函数表指针在32位系统中占4个字节, 在64位系统中占8个字节 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include&lt;iostream&gt;using namespace::std;class Base1&#123; public: Base1()&#123; cout&lt;&lt;"Base1 constructor"&lt;&lt;endl; &#125; ~Base1()&#123; cout&lt;&lt;"Base1 destructor"&lt;&lt;endl; &#125; virtual void start() &#123; cout&lt;&lt;"Base1 start"&lt;&lt;endl; &#125; virtual void stop() &#123; cout&lt;&lt;"Base1 stop"&lt;&lt;endl; &#125;&#125;;class Base2&#123; public: Base2()&#123; cout&lt;&lt;"Base2 constructor"&lt;&lt;endl; &#125; ~Base2()&#123; cout&lt;&lt;"Base2 destructor"&lt;&lt;endl; &#125; virtual void start() &#123; cout&lt;&lt;"Base2 start"&lt;&lt;endl; &#125; void stop() &#123; //同一个类中只会有一个虚函数表指针, 所以这里为虚或者不为虚, 最终的类的 size 是相同的 cout&lt;&lt;"Base2 stop"&lt;&lt;endl; &#125;&#125;;class Derived:public Base1, public Base2&#123; public: Derived()&#123; cout&lt;&lt;"Derived constructor"&lt;&lt;endl; &#125; ~Derived()&#123; cout&lt;&lt;"Derived destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Derived start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Derived stop"&lt;&lt;endl; &#125;&#125;;int main(int argc,char *argv[])&#123; Base1 *p = new Derived(); Derived d; cout&lt;&lt; size of(Derived)&lt;&lt;endl; // 类的 size cout&lt;&lt; size of(d)&lt;&lt;endl; // 对象的 size cout&lt;&lt; size of(p)&lt;&lt;endl; // 对象指针的 size return 0;&#125; 输出结果如下:123456789101112Base1 constructorBase2 constructorDerived constructorBase1 constructorBase2 constructorDerived constructor16168Derived destructorBase2 destructorBase1 destructor 从上面的代码中可以看出, Base1 类中具有两个虚函数, Base2 类中具有一个虚函数, 因为对于同一个类来说, 只会维护一个虚函数表指针, 所以不论类中的虚函数的个数为多少个, 都只会产生一个虚函数表指针, 同时这里由于子类继承了两个虚基类, 所以会有两个虚函数表, 也就是要维护两个虚函数表指针, 因此其类的 size 为 $8+8=16$. 而对于对象指针p来说, size 与类无关. 最后, 析构函数也只调用了一次, 因为没有用delete手动释放new对应的内存. 如果使用了虚函数, 则类的对齐方式会发生变化, 不再是与4的倍数对齐, 而是与8的倍数对齐, 如下所示, 在每个类中增加了char类型的变量, 按理说增加的总字节数应该为3, 但是由于字节对齐, 类的 size 会变成8个倍数: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include&lt;iostream&gt;using namespace::std;class Base1&#123; public: Base1()&#123; cout&lt;&lt;"Base1 constructor"&lt;&lt;endl; &#125; ~Base1()&#123; cout&lt;&lt;"Base1 destructor"&lt;&lt;endl; &#125; virtual void start() &#123; cout&lt;&lt;"Base1 start"&lt;&lt;endl; &#125; virtual void stop() &#123; cout&lt;&lt;"Base1 stop"&lt;&lt;endl; &#125; private: char c;&#125;;class Base2&#123; public: Base2()&#123; cout&lt;&lt;"Base2 constructor"&lt;&lt;endl; &#125; ~Base2()&#123; cout&lt;&lt;"Base2 destructor"&lt;&lt;endl; &#125; virtual void start() &#123; cout&lt;&lt;"Base2 start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Base2 stop"&lt;&lt;endl; &#125; private: char c;&#125;;class Derived:public Base1, public Base2&#123; public: Derived()&#123; cout&lt;&lt;"Derived constructor"&lt;&lt;endl; &#125; ~Derived()&#123; cout&lt;&lt;"Derived destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Derived start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Derived stop"&lt;&lt;endl; &#125; private: char c;&#125;;int main(int argc,char *argv[])&#123; Base1 *p = new Derived(); Derived d; cout&lt;&lt; size of(Derived)&lt;&lt;endl; // 类的 size cout&lt;&lt; size of(d)&lt;&lt;endl; // 对象的 size cout&lt;&lt; size of(p)&lt;&lt;endl; // 对象指针的 size return 0;&#125; 虚函数控制下的运行多态有什么用？假如我们在公司的人事管理系统中定义了一个基类 Employee(员工)，里面包含了升职、加薪等虚函数。 由于Manager(管理人员)和Engineer(工程人员)的加薪和晋升流程是不一样的，因此我们需要实现一些继承类并重写这些函数。 有了上面这些以后，到了一年一度每个人都要加薪的时候，我们只需要一个简单的操作就可以完成，如下所示123456void globalRaiseSalary(Employee *emp[], int n)&#123; for (int i = 0; i &lt; n; i++) emp[i]-&gt;raiseSalary(); // 会根据emp具体指向的对象类型，来选择合适的函数行为 // Polymorphic Call: Calls raiseSalary() // according to the actual object, not according to the type of pointer&#125; 虚函数使得我们可以创建一个统一的基类指针，并且调用不同子类的函数而无需知道子类对象究竟是什么 虚函数中的默认参数先看下面的代码12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Base&#123;public: virtual void fun ( int x = 0 ) &#123; cout &lt;&lt; "Base::fun(), x = " &lt;&lt; x &lt;&lt; endl; &#125;&#125;;class Derived : public Base&#123;public: // 这里的virtual关键字可以省略，因为只要基类里面被声明为虚函数，那么在子类中默认都是虚的 virtual void fun ( int x )// 或者定义为 virtual void fun ( int x = 10) &#123; cout &lt;&lt; "Derived::fun(), x = " &lt;&lt; x &lt;&lt; endl; &#125;&#125;;int main()&#123; Derived d1; Base *bp = &amp;d1; bp-&gt;fun(); return 0;&#125; 上面的代码输出始终为：1Derived::fun(), x = 0 解释： 首先，参数的默认值是不算做函数签名的，因此，即使基类有默认值，子类没有，这两个函数的函数签名仍然被认为是相同的，所以在调用bp-&gt;fun();，仍然调用了子类的fun函数，但是因为没有给出x的值，所以采用了基类函数给出的默认值0. 当基类给出默认值0，子类给出默认值10时，返回结果仍然是默认值0，这是因为，参数的默认值是静态绑定的，而虚函数是动态绑定的，因此， 默认参数的使用需要看指针或者引用本身的类型，而不是指向对象的类型。-小结：根据上面的分析，在虚函数中最好不要使用默认参数，否则很容易引起误会！ 静态函数可以被声明为虚函数吗静态函数不可以声明为虚函数，同时也不能被const和volatile关键字修饰。如下面的声明都是错误的：123virtual static void fun()&#123;&#125;static void fun() const &#123;&#125; // 函数不能被const修饰，但是返回值可以 原因主要有两个方面： static成员函数不属于任何类对象或类实例，所以即使给此函数加上virtual也是没有意义的 虚函数依靠vptr和vtable来处理，vptr是一个指针，在类的构造函数中创建生成，并且只能用this指针来访问它，静态成员函数没有this指针，所以无法访问vptr。 构造函数可以为虚函数吗构造函数不可以声明为虚函数。同时除了inline之外，构造函数不允许使用其他任何关键字，原因如下： 尽管虚函数表vtable是在编译阶段就已经建立的，但指向虚函数表的指针vptr是在运行阶段实例化对象时才产生的。 如果类含有虚函数，编译器会在构造函数中添加代码来创建vptr。 问题来了，如果构造函数是虚的，那么它需要vptr来访问vtable，可这个时候vptr还没产生。 因此，构造函数不可以为虚函数。 我们之所以使用虚函数，是因为需要在信息不全的情况下进行多态运行。而构造函数是用来初始化实例的，实例的类型必须是明确的。 因此，构造函数没有必要被声明为虚函数。 析构函数可以为虚函数吗析构函数可以声明为虚函数。如果我们需要删除一个指向派生类的基类指针时，应该把析构函数声明为虚函数。事实上，只要一个类有可能会被其他类所继承，就应该声明虚析构函数（哪怕该析构函数不执行任何操作）。原因是因为基类指针被删除后, 不会调用派生类的析构函数, 只会调用基类的析构函数, 因此, 需要将析构函数声明为虚的, 来使得进行 delete时, 调用子类的虚构函数： 1234567891011121314151617181920212223242526272829#include&lt;iostream&gt;using namespace std;class base &#123; public: base() &#123; cout&lt;&lt;"Constructing base \n"; &#125; // virtual ~base() ~base() &#123; cout&lt;&lt;"Destructing base \n"; &#125; &#125;;class derived: public base &#123; public: derived() &#123; cout&lt;&lt;"Constructing derived \n"; &#125; ~derived() &#123; cout&lt;&lt;"Destructing derived \n"; &#125;&#125;;int main(void)&#123; derived *d = new derived(); base *b = d; delete b; return 0;&#125; 以上代码输出：123Constructing baseConstructing derivedDestructing base 可见，继承类的析构函数没有被调用，delete时只根据指针类型调用了基类的析构函数。 正确的操作是，基类和继承类的析构函数都应该被调用，解决方法是将基类的析构函数声明为虚函数。 如下所示:1234567891011121314151617181920212223242526272829#include&lt;iostream&gt;using namespace std;class base &#123; public: base() &#123; cout&lt;&lt;"Constructing base \n"; &#125; virtual ~base() //~base() &#123; cout&lt;&lt;"Destructing base \n"; &#125; &#125;;class derived: public base &#123; public: derived() &#123; cout&lt;&lt;"Constructing derived \n"; &#125; ~derived() &#123; cout&lt;&lt;"Destructing derived \n"; &#125;&#125;;int main(void)&#123; derived *d = new derived(); base *b = d; delete b; return 0;&#125; 输出结果为:1234Constructing baseConstructing derivedDestructing derivedDestructing base 虚函数可以为私有函数吗虚函数可以被私有化，但有一些细节需要注意12345678910111213141516171819202122#include&lt;iostream&gt;using namespace std;class Derived;class Base &#123;private: virtual void fun() &#123; cout &lt;&lt; "Base Fun"; &#125;friend int main();&#125;;class Derived: public Base &#123;public: void fun() &#123; cout &lt;&lt; "Derived Fun"; &#125;&#125;;int main()&#123; Base *ptr = new Derived; ptr-&gt;fun(); return 0;&#125; 输出结果为：1Derived fun() 基类指针指向继承类对象，则调用继承类对象的函数 int main()必须声明为Base类的友元，否则编译失败。编译器报错：ptr无法访问私有函数。当然，把基类声明为public，继承类为private，该问题就不存在了。 虚函数可以被内联吗通常类成员函数都会被编译器考虑是否进行内联。但通过基类指针或者引用调用的虚函数必定不能被内联。当然，实体对象调用虚函数或者静态调用时可以被内联，虚析构函数的静态调用也一定会被内联展开。 纯虚函数与抽象类纯虚函数：在基类中只声明不定义的虚函数，同时要求任何派生类都要实现该虚函数。在基类中实现纯虚函数的方法是在函数原型后加“=0”。 抽象类：含有纯虚函数的类为抽象类 纯虚函数的特点以及用途总结如下： 如果不在继承类中实现该函数，则继承类仍为抽象类； 派生类仅仅只是继承纯虚函数的接口，因此使用纯虚函数可以规范接口形式 抽象类无法实例化对象 抽象类可以有构造函数 析构函数被声明为纯虚函数是一种特例，允许其有具体实现。（有些时候，想要使一个类称为抽象类，但刚好有没有任何合适的纯虚函数，最简单的方法就是声明一个纯虚的析构函数） 不要重写非虚函数在 Effective C++ 中写到: 不要重写继承来的非虚函数. 因为在子类中重写父类的非虚函数在设计上是矛盾的: 一方面, 父类定义了普通的非虚函数, 意味着该函数是父类的不变式, 子类如果重写了父类的不变式, 那么父类和子类的关系就不再是”is-a”关系. 另一方面, 如果父类的非虚函数在子类中提供了不同的实现, 那么该函数就不应该是父类的不变式, 因此应该将该函数声明为虚函数.]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的 extern 关键字]]></title>
    <url>%2Fz_post%2FCpp-extern%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[extern 关键字的主要作用是什么? 置于变量或者函数前: 表明该变量或者函数定义在别的文件中 extern&quot;C&quot;: 让编译器以 C 语言的命名规则来查找函数 置于变量或者函数前 在变量或者函数之前加上extern关键字表明这是一个声明, 其定义可能在其他文件处, 注意不能对变量进行初始化或者对函数进行定义, 否则表明这是一个定义而不是声明. extern&quot;C&quot;extern “C”的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern “C”后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。 如何令 const 对象可以在多个文件中共享默认情况下, const 对象仅在本文件内有效, 我们可以通过 extern 关键字来使得 const 对象在多个文件中共享. 一个源文件定义了char a[6], 在另一个文件使用extern char *a进行声明, 可以吗?不可以, 因为指向类型 T 的指针并不等价与类型 T 数组, 提示我们声明和定义要严格一样的格式. 在 C++ 程序中调用被 C 编译器编译后的函数, 为什么要加 extern “C”因为 C++ 重载, 而 C 不重载, 函数名编译的结果都不一样, 因此如果 C++ 直接调用 C 的函数, 因为二者编译的不同, 就会失败. 当函数提供方单方面修改函数原型时, 使用方却没有修改, 这时候编译会怎么样? 链接时会怎么样? 如何解决?在编译时, 由于 extern 说明该函数是在别处定义的, 所以编译器不会报错. 但是在链接时, 由于找不到对应的链接对应, 所以无法链接. 目前业界针对这种情况的处理没有一个很完美的方案, 通常的做法是人提供方自己在xxx_pub.h中提供对外部接口的声明, 然后调用方直接include该文件, 从而省去extern这一步, 以避免这种错误. extern 和 static 可以同时修饰一个变量吗?extern和static是一对矛盾的修饰符, 二者不能同时修饰一个变量, 因为static表明变量的链接性是内部的, 而extern恰好相反.]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的static关键字]]></title>
    <url>%2Fz_post%2FCpp-static%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[static 关键字的作用是什么 用法 示例 说明 在局部变量前使用static int main(){ static int a;} 该变量具有静态持续性, 但是无链接性 静态成员数据 class A{static int a}; int A::a = 1 只能在类外部定义并初始化静态成员变量, 不能在类内部声明时定义或初始化静态变量, 因为声明只是描述了如何分配内存, 但实际上并不真正分配内存 静态成员函数 与成员数据类似 无this指针 const static成员数据 class Myclass{ public: const static int a = 3; 声明并在内部初始化(也可在在外部初始化, 注意不带static关键字) 首先：在类中声明的静态变量，一定要进行初始化，并且，如果不是const static类型的静态变量，则需要在类外初始化，同时初始化的时候一定要带上类名和作用域解析符。 123456789101112131415161718192021class sum&#123; public: static int i ; static int s; sum()&#123;i++; s+=i;&#125;; ~sum()&#123;&#125;; static void set()&#123; //静态函数只能使用静态变量 i = 0; s = 0; &#125;; &#125;;int sum::i =0; // 非const static类型，要在类外初始化int sum::s = 0; // 且必须带上类名sum和作用域解析符class Solution &#123;public: int Sum_Solution(int n) &#123; sum::set(); // 直接用类名调用函数，则该函数必须是静态的 sum a[n]; return sum::s; &#125;&#125;; 都有哪些存储持续性类型和链接性类型存储持续性C++使用三种（在C++11中是四种）不同的方案来存储数据，这些方案的区别就在于 数据保留在内存中的时间 ：(Primer p304) 自动存储持续性: 在程序开始执行其所在的函数或者代码块时被创建, 在执行完函数或代码块时, 其内存会被自动释放. 静态存储持续性: 在整个程序运行过程当中都存在 线程存储持续性（C++11） 动态存储持续性: 用new运算符分配的内存将一直存在(堆中), 直到使用delete运算符将其释放或者 程序结束 为止. 作用域和链接性 和C语言一样，C++也为 静态 存储持续性变量提供了3种链接性(其他类型的持续性变量均是无链接性的)，这三种链接性都在整个程序执行期间存在，与自动变量相比，它们的寿命更长。(Primer p309) 外部链接性（可在其他文件中访问） 内部链接性（只能在当前文件中访问） 无链接性（只能在当前函数或代码块中访问，与自动变量不同的是，就算不在函数中，变量也存在，只是不能访问） 由于静态变量的数目在程序运行期间是不变的，因此程序不需要使用特殊的装置（如栈）来管理它们, 而是将它们放在 全局数据区。编译器将分配固定的内存块来存储所有的静态变量，这些变量在整个程序执行期间一直存在。另外，如果没有显式地初始化静态变量，编译器将把它设置为0。在默认情况下，静态 数组和结构将每个元素或成员的所有位都设置为0。p309 创建三种链接性的静态持续变量：p309 外部链接性：必须在代码块的外面声明 内部链接性：必须在代码块的外面声明，并使用static限定符 无链接性：必须在代码块内部声明，并使用static限定符123456789int global = 1000; //静态持续变量，外部链接性，作用域为整个文件static int one_file = 50; //静态持续变量，内部链接性，作用域为整个文件int main()&#123; ...&#125;void funct1(int n)&#123; static int count = 0; //静态持续变量，无链接性，作用域为局部 int llama = 0;&#125; 五种变量存储方式：p310 自动 寄存器 静态，无链接 静态，外部链接 静态，内部链接 关键字重载： 关键字的含义取决于上下文，static用于局部声明，以指出变量是无链接性的静态变量时，表示的是存储持续性。而用于代码块外的声明时，static表示内部链接性，因为位于代码块外的变量已经是静态持续性了。p310 静态变量的初始化： 静态变量有三种初始化方式：零初始化（变量设为零）、常量表达式初始化和动态初始化。 零初始化和常量表达式初始化被统称为静态初始化，这意味着在编译器处理文件时初始化变量，动态初始化意味着变量将在编译后初始化。p310 静态变量的初始化过程： 首先，所有静态变量都被零初始化，而不管程序员是否显式地初始化了它。接下来，如果使用常量表达式初始化了变量，且编译器仅根据文件内容（包括被包含的头文件）就可计算表达式，编译器将执行常量表达式初始化。必要时，编译器将执行简单计算。最后，剩下的变量将被动态初始化。 常量表达式并非只能是使用字面常量的算术表达式。（sizeof运算符也可以）p310 链接性为外部的变量通常简称为外部变量，也称全局变量，它们的存储持续性为静态，作用域为整个文件。p310 静态持续性、外部链接性 单定义规则（One Definition Rule，ODR）： 变量只能定义一次。为满足这种需求，C++提供了两种变量声明：p311 定义声明（简称定义）：为变量分配存储空间。 引用声明（简称声明）：不给变量分配存储空间，引用已有的变量。使用关键字extern12double up; //定义声明extern int blem; //blem在别处定义 如果要在多个文件中使用外部变量，只需在一个文件中包含该变量的定义（单定义规则），但在使用该变量的其他所有文件中，都必须使用关键字extern声明它。p311 1234567//file01.cppextern int cats = 20; // 由于初始化，所以这里是定义而非声明int dogs = 22; //定义//即使去掉file01.cpp文件中的extern也无妨，效果相同。//file02.cppextern int cats; //使用extern且无初始化，说明使用的是其他文件的catsextern int dogs; //同上 静态持续性、内部链接性 将作用域为整个文件的变量声明为静态外部变量（内部链接性），就不必担心其名称与其他文件中的外部变量发生冲突. 通常, 当在函数体内定义一个变量时, 该变量是一个自动存储变量, 每当运行到该语句时都会给该局部变量分配 栈内存, 而随着程序退出函数体, 系统就会自动收回这一部分内存. 但有时候我们需要在两次调用之间对变量的值进行保存. 通常的想法是定义一个全局变量来实现, 但是这样一来, 变量就不再属于该函数本身了. 因此, 可以使用静态局部变量来解决, 静态局部变量保存在全局数据区, 而不是保存在栈中, 每次的值保持到下一次调用, 直到下次赋新值.123456789101112131415//file1int errors = 20;//file2int errors = 5;int main()&#123; cout&lt;&lt;errors; //报错，errors与file1中的外部变量重定义 ...&#125;//解决方法：file2static int errors = 5;int main()&#123; cout&lt;&lt;errors; // 输出5&#125; 静态存储持续性、无链接性 局部静态变量：虽然该变量只在该代码块中可用，但它在该代码块不处于活动状态时仍然存在。因此在两次函数调用之间，静态局部变量的值将 保持不变 。 另外，如果初始化了静态局部变量，则程序 只在启动时进行一次初始化 。以后再调用函数时，将不会被再次初始化。p315 全局变量的链接性是怎么样的? 全局常量呢? 存储说明符（storage class specifier）：p317 auto（在C++11中不再是说明符） register static extern thread_local（C++11新增的） mutable：即使结构（或类）变量为const，其某个成员也可以被修改 cv-限定符（cv-qualifer）：p317 const：内存被初始化后，程序便不能再对它进行修改 volatile：即使程序代码没有对内存单元进行修改，其值也可能发生变化 在默认情况下 全局变量的链接性为外部，但 const全局常量的链接性为内部 (因为是全局的, 所以默认已经具有静态持续性) 。因此，将一组常量放在头文件中，其他引用该头文件的文件都相当于自己定义了私有的常量，这就是能够将常量定义放在头文件中而不会重定义的原因。p318 如果处于某种原因，程序员希望某个常量的链接性为外部的，则可以使用extern关键字来覆盖默认的内部链接性，extern const int states = 50;，在这种情况下，必须在所有使用该常量的文件中使用extern关键字来声明它。同时这种情况下就不能将该常量放在头文件中了, 因为链接性已经变成外部, 这样会引起重复定义. p318 const全局常量的链接性为内部, 因此可以放在头文件中而不会重定义 函数存储持续性和是否受 static 关键字影响? static 关键字修饰函数时, 其什么作用?当static关键字作用于函数时, 它改变的只是函数的链接性, 函数的持续性永远为静态 C++不允许在一个函数中定义另一个函数，因此 所有函数的存储持续性都自动为静态，即在整个程序执行期间都一直存在 。p318 在默认情况下，函数的链接性为外部。即可以在文件间共享，使用extern来指出函数实在另一个文件中定义的（可选）。p318 可以使用关键字static将函数的链接性设置为内部 ，使之只能在一个文件中使用，必须同时在原型和函数定义中使用该关键字。p318 内联函数不受单定义规则的约束，这允许程序员能够将内联函数的定义放在头文件中。但是C++要求同一个函数的所有内联定义都必须相同。 p319 C++查找函数顺序：静态（在本文件中找）——外部（在所有的程序文件中找）——在库函数中找。因此如果定义了一个与库函数同名的函数，编译器优先使用程序员定义的版本（C++不推荐这样做）。p319 语言链接性 不同的语言采用了不同的链接性，为了解决这种问题，需要特别指定函数采用的链接性（默认为C++链接性）。p319 静态成员数据和静态成员函数有哪些特点?类的静态成员在类实例化之前就存在了, 并分配了内存, 而函数的静态局部变量会在执行函数时才分配内存. 静态成员数据在类内的数据成员的声明前加上关键字static, 该数据成员就是类内的静态数据成员, 具有以下特点: 静态数据成员被当作是 类的成员 (注意与具体对象无关), 无论这个类的对象被定义了多少个, 静态数据成员在程序中也只有一份拷贝(只分配一次内存), 由该类型的所有对象共同持有. 静态数据成员存储在全局数据区. 由于静态数据成员在定义时必须分配空间, 所以只能在类中对静态数据成员声明, 而不能在类中对静态数据成员进行定义, 需要放到类外定义, 且定义时不要加static关键字, 但是必须指明命名空间. 如下所示: 12345678class Myclass&#123;public: int getprivate: int a = 1; static float Sum; // 不能再类内部声明时定义或初始化静态变量, 因为声明只是描述了如何分配内存, 但实际上并不真正分配内存&#125;float Myclass::Sum = 0; // 只能在类外部定义并初始化静态成员变量 静态数据成员和普通数据成员一样要遵从public, protected, private等访问规则. 因为静态数据成员是独立于具体对象的, 因此, 即使没有产生任何类的实例, 我们仍然可以对其进行访问. 如果静态数据成员的访问权限允许的话(public), 可以通过下面两种方式来直接访问: &lt;类对象名&gt;.&lt;静态数据成员名&gt; &lt;类名&gt;::&lt;静态数据成员名&gt; 同全局变量相比(静态持续性, 外部链接性), 使用静态数据成员有两个优势: 静态数据成员没有进入程序的全局命名空间, 因此不存在与程序中其他全局变量名冲突的可能性 可以实现信息隐藏, 静态数据成员可以是private成员, 而全局变量不能. 静态成员函数与静态数据成员一样, 也可以创建一个静态成员函数, 它为类的全部对象服务, 而不是为某一个具体的对象服务 ,具有以下特点: 在定义(实现)静态成员函数时, 同样不能带有关键字static 静态成员之间可以互相访问, 包括静态成员函数访问静态数据成员和静态成员函数 非静态成员函数可以任意的访问静态成员和非静态成员. 静态成员函数不能访问任何非静态成员 由于没有this指针上的开销, 因此静态成员函数在速度上会小优于类的全局函数 类对象或对象指针可以像调用普通函数一样使用.或-&gt;来调用静态成员函数, 也可以使用&lt;类名&gt;::&lt;静态成员函数名&gt;()的方式来调用 静态成员函数与 this 指针普通的成员函数一般都隐含了一个this指针, this指针指向类的对象本身, 因为普通成员函数总是属于类的某个具体对象, 通常情况下, this指针是缺省的, 如函数 func() 实际上是this-&gt;func(), 但是与普通函数相比, 静态成员函数由于不与任何对象相联系, 因此它不具有this指针, 从这个意义上讲, 它就 无法访问属于类对象的非静态数据成员, 也无法访问非静态成员函数, 只能访问或调用静态的数据或函数. 用 const static 来修饰成员数据需要注意什么?需要注意必须在声明时初始化或者类外部初始化, 不能再构造函数初始化列表中初始化 const 只是对于单个类对象来说是常量, 而对于整个类来说实际上是变量, 如果要维护一个对于整个类来说的常量, 应该使用const static或者static cosnt(二者等价)来声明, 与普通static成员数据不太一样的是, const static成员数据需要在类中声明的同时就进行初始化(因为const数据在定义是必须初始化, 而static又使得该变量独立于具体对象, 所以必须在声明时初始化或者在类外部初始化, 也不能在构造函数初始化列表中初始化) :123456789class Myclass&#123;public: const static int a = 3; // 声明并初始化 cosnt int b = 4; //这样是可以的, 但是这样所有变量的b都为4,且不能改变, 还不如声明为const static //所以最好还是在构造函数的初始化列表中对非静态const进行初始化 static const int c;&#125;const int Myclass::c = 5; //在类外部初始化. 不要带static关键字 静态函数不能被const修饰，但是返回值可以1234static void fun() const &#123;&#125; // 函数不能被const修饰，但是返回值可以const static int() &#123;&#125; // 该静态函数返回值的类型是 const intstatic const int() &#123;&#125; // 该静态函数返回值的类型是 const int 注意: C++ 中不能同时用static和const修饰成员函数, 因为 C++ 编译器在实现const的成员函数的时候为了确保该函数不会修改类中参数的值, 会在函数中添加一个隐式的参数const this*, 但当一个成员为static的时候, 该函数是没有this指针的, 也就是说此时的const和static是冲突的, 不能一起使用.]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CornerNet (ECCV, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-CornerNet-ECCV2018%2F</url>
    <content type="text"><![CDATA[文章: CornerNet: Detecting Objects as Paired Keypoints作者: Hei Law, Jia Deng机构: University of Michigan 摘要本文提出了一种新的检测方法, 即利用一对关键点(左上角和右下角)来检测物体, 我们仅用了单一的神经网络来搭建该模型, 并命名为 CornerNet. 通过一对关键点来检测物体, 可以省去设计 anchor boxes 的步骤. 除此之外, 我们还引入了 corner pooling, 这是一个新型的池化层, 可以帮助网络更好的定位 corner. 实验表明 CornerNet 在 MS COCO 上取得了 42.1% AP, 超过了所有的 one-stage 模型. Introduction现有的 sota 目标检测方法中的一个很常用的组成元素是 anchor boxes. anchor boxes 用在 one-stage 方法中时, 可以取得与 two-stage 相媲美的性能表现.但是使用 anchor boxes 具有两个缺点:第一, 通常来说, 我们会生成大量的 anchor boxes. (eg, more than 40k in DSSD). 这是因为检测器是被训练来决定每一个 anchor box 是否与 gt box 有足够大的交集的, 因此, 必须有足够多的 anchor boxes 才能保证尽可能的覆盖所有的 gt boxes. 最终, 仅仅只有一小部分的 anchor box 会有 gt box 的交并比大于一定值, 因此, 这会造成正样本和负样本之间的不均衡, 同时会降低训练速度.第二, 使用 anchor boxes 会引入很多的超参数和设计选择. 包括需要多少个 boxes, 它们的 sizes 是多少, 以及它们的宽高比是多少等等. 这些选择很大程度上是通过特别的启发式规则做出的, 并且在结合 multiscale 结构时会变得更加复杂在本文中, 我们提出了一个舍弃了 anchor boxes 设计的 one-stage 检测模型, 命名为 CornerNet. 我们利用一对关键点(左上角和右下角)来检测物体. 我们利用一个单一的卷积网络来预测同一对象类别的所有实例的 左上角和右下角的热图(heatmap), 以及每个检测到的角的 embedding vector. 这些 embeddings 用于对属于同一对象的一对角进行分组, 网络被训练为预测它们的类似 embeddings。我们的灵感来自于人体关键点检测的一篇文章. 图1展示了本文方法的整体流程(overall pipeline). CornerNet 中另一个新颖的组成要素就是 corner pooling, 它可以帮助卷积网络更好的定位 bbox 的 corner. bbox 的 corner 经常处于物体的外侧, 如图2所示. 在这种情况下, 不能基于局部特征对某个 corner 进行定位. 相反的, 为了决定某个像素位置上是否存在一个 top-left corner, 我们需要水平向右寻找物体的最高边界, 同时需要垂直向下寻找最左边界. 这种特点启发我们提出了 corner pooling layer: 它包含两个特征图, 在每一个像素位置上, 它对第一个特征图谱右侧的所有特征向量进行最大池化操作, 对第二个特征图谱下方的所有特征向量进行最大池化操作, 然后将两个池化后的结果相加. 示例如图3所示. 我们假设了两个原因 来解释为什么检测 corners 会比检测 bbox centers 或者 proposals 的效果好. 第一, 定位 anchor box 更难一些, 因为它需要依赖物体的4个边界才能确定, 但是 corner 只需要物体的两个边界就可以确定, corner pooling 也是如此, 它编码了关于 corner 的一些明确的先验知识. 第二, corners 提供了一种更加有效的方式来密集的对 boxes 的空间进行离散化: 我们只需要 $O(wh)$ 的 corners, 而 anchor boxes 需要的复杂度是 $O(w^2h^2)$. 我们通过实验证明了 CornerNet 的有效性, 同时通过消融实验发现, corner pooling 对于 CornerNet 的性能表现来说很重要. Related WorksTwo-stage object detectors: R-CNN, SPP, RPN, R-FCNOne-stage object detectors: YOLO, SSD, DSSD, RON, YOLO9000, RetinaNet, RefineDetDeNetMulti-person pose estimation CornerNet在 CornerNet 中, 我们利用一对关键点(左上角和右下角)来检测物体. 卷积网络会预测两组热图(heatmaps)来表示不同物体类别的 corners locations, 一组用于表示左上角, 一组用于表示右下角. 同时, 网络还会为每个检测到的 corner 预测一个 embedding vector, 其特点是同一个物体的两个角点(corners)的 embeddings vector 之间的距离会非常小. 为了产生更紧密的边界框, 网络还会预测偏移量, 以稍微调整角点的位置. 得到预测的 heatmaps, embeddings 和 offsets 之后, 我们会使用简单的后处理算法来获取最终的 bboxes. 图4展示了 CornerNet 的整体结构, 我们使用 Hourglass 网络作为 backbone 网络, 之后接着是两个预测模块(prediction modules). 其中一个用来预测左上角点, 另一个预测右下角点. 每一个模块都有自己的 corner pooling 来池化从 hourglass 网络得到的特征, 然后再预测 heatmaps, embeddings, 和 offsets. 和其他目标检测器不同, 我们不使用不同尺度的特征图谱来检测不同尺度的物体. 我们仅仅使用 hourglass network 输出的特征进行检测. Detecting Corners我们预测两组热图, 每一组热图都具有 $C$ 个通道, $C$ 代表了物体类别的数量, 热图的尺寸为 $H\times W$. 注意, 这里没有背景的通道(background channel). 每一个 channel 都是一个二值的 mask, 用于指示某个类别的角点位置.对于每个角点来说, 都会有一个 gt positive location, 而其他的 locations 都将是负样本. 在训练阶段, 我们不会等价的惩罚负样本, 我们减少了在正样本的一定半径内负样本的惩罚. 这是因为对于一对假的角点检测来说, 如果它们接近各自的真实位置, 那么就仍然可以产生一个与真实框差不多的框, 如图5所示. 我们通过确保半径内的一对点将生成一个至少与真实框具有 $t$ IoU ($t=0.7$)以上的边界框, 从而根据物体的大小来确定半径的值. 在给定半径以后, 减少惩罚的数量通过一个非规范的 2D 高斯分布给出: $e^{-\frac{x^2 + y^2}{2\sigma^2}}$, 其中心位于正样本的位置, $\sigma$ 的大小是半径的三分之一. 设 $p_{cij}$ 为预测热图中 $c$ 类在位置 $(i,j)$ 处的得分，$y_{cij}$ 为使用 unnormalized 高斯增广的 gt 热图。我们设计了一种 focal loss[23]的变体: L_{det} = \frac{-1}{N}\sum_{c=1}^{C} \sum_{i=1}^{H} \sum_{j=1}^{W} \begin{cases} (1-p_{cij})^\alpha log(p_{cij}) && y_{cij} = 1 \\ (1-y_{cij})^{beta} (p_{cij})^\alpha log(1 - p_{cij}) && otherwise \end{cases} \tag 1其中 $N$ 是图像中物体的数量, $\alpha$ 和 $\beta$ 是用于控制每个点贡献度的超参数. (我们在所有实验中设置 $alpha=2, \beta=4$)。$y_{cij}$ 使用 Gaussian bumps 进行编码，$(1-y_{cij})$ 项减少了对 gt locations 的惩罚。 许多网络[15,28]使用向下采样层来收集全局信息同时减少内存使用。当它们应用于完全卷积的图像时，输出的大小通常小于图像。因此，需要将图像中的位置 $(x, y)$ 映射到 heatmap 中的位置 $(x/n, y/n)$ ，其中 $n$ 为下采样因子。当我们将热图中的位置重新映射到输入图像时，可能会丢失一些精度，这将极大地影响 gt 和小边界框的 IoU 大小。为了解决这个问题，我们预测 location offsets，以便在将它们重新映射到输入分辨率之前稍微调整转角位置。 o_k = \bigg(\frac{x_k}{n} - \bigg\lfloor \frac{x_k}{n} \bigg\rfloor, \frac{y_k}{n} - \bigg\lfloor \frac{y_k}{n} \bigg\rfloor \bigg) \tag 2其中 $o_k$ 为 offsets，$x_k$ 和 $y_k$ 为角点 $k$ 的 $x$ 和 $y$坐标，我们会预测一组被左上角所共享的 offsets, 以及另一组被右下角所共享的 offets. 在训练阶段，我们在 ground-truth corner 位置使用 smooth L1 Loss. L_{off} = \frac{1}{N} \sum_{k=1}^{N} SmoothL1Loss(o_k, \hat o_k) \tag 3Grouping Corners图像中可能出现多个对象，因此可以检测到多个左上角和右下角。我们需要确定左上角和右下角的一对是否来自同一个边框。我们的方法受到Newell等人提出的用于多人姿态估计任务的 Associative Embedding 的启发。Newell等人检测了所有的人类关节，并为每个检测到的关节生成一个 embeddings。他们根据 embeddings 之间的距离对关节进行分组。我们遵循Newell等人的方法使用一维的 embeddings。设 $e_{t_k}$ 为对象 $k$ 的左上角的 embeddings，$e_{b_k}$ 为对象 $k$ 的右下角的 embeddings。与[26]一样，我们使用 “pull” loss 训练网络对各个角进行分组，使用 “push” loss 分离各个角点: L_{pull} = \frac{1}{N}\sum^N_{k=1}[(e_{t_k}-e_k)^2 + (e_{b_k}-e_k)^2], \tag 4L_{push} = \frac{1}{N(N-1)} \sum^N_{k=1} \sum^N_{j=1, j\neq k} max(0, \Delta - |e_k - e_j|), \tag 5上式中, $e_k$ 是 $e_{t_k}$ 和 $e_{b_k}$ 的平均值, 在本文所有实验中, 设置 $\Delta = 1$. 与 offset loss 类似，我们只对 gt corner location 计算损失。 可以看出, $L_{pull}$ 的目的就是让属于同一个物体角点的 embeddings 距离越来越小, $L_{push}$ 的目的就是让不同物体的角点距离越来越大. Corner Pooling如图2所示, 我们往往不能从局部的特征中推断出角点的位置. 为了确定一个像素点是不是 左上角角点, 我们需要水平和垂直的向右向下看才能确定, 因此我们提出了 corner pooling 来更好的确定角点. 假设我们想确定位置 $(i, j)$ 处的像素是否为左上角角点。设 $f_t$ 和 $f_l$ 分别为左上 corner pooling化层输入的 feature map, 设 $f_{t_{ij}}$ 和 $f_{l_{ij}}$ 分别为 $f_t$ 和 $f_l$ 中位置 $(i,j)$ 处的向量。在 $H×W$ 的 feature map 中，角点池化层首先将 $f_t$ 中 $(i,j)$ 和 $(i,H)$ 之间的所有特征向量都最大池化到一个特征向量 $t_{ij}$，将 $f_l$ 中 $(i,j)$ 和 $(W,j)$ 之间的所有特征向量最大池化到一个特征向量 $l_{ij}$。最后，将 $t_{ij}$ 和 $l_{ij}$ 相加。计算公式如下: t_{ij} = \begin{cases} \max(f_{t_{ij}}, t_{(i+1)j}) && i < H \\ f_{t_{Hj}} && otherwise \end{cases} \tag 6l_{ij} = \begin{cases} \max(f_{l_{ij}}, t_{i(j+1)}) && i < H \\ f_{l_{iW}} && otherwise \end{cases} \tag 7$t_{ij}$ 和 $l_{ij}$ 可以利用动态规划高效得到, 如图6所示 我们以类似的方式定义了右下角的池化层。它将 $(0,j)$ 和 $(i,j)$ 之间的所有特征向量和 $(i, 0)$ 和 $(i,j)$ 之间的所有特征向量使用最大池化汇集在一起，然后再将汇集的结果相加。在预测模块中使用角点池层来预测 heatmaps, embeddings, 和 offsets. 预测模块的结构如图7所示。模块的第一部分是 residual block[15]的修改版本。在这个修改后的残块中，我们将第一个3×3卷积模块替换为一个角点池化模块，该角点池化模块首先用两个3×3卷积模块处理来自主干网的特征，卷积模块有128个信道，然后应用 corner pooling层。在剩余块的设计之后，我们将合并后的特征输入到一个3×3的对流bn层，该层有256个通道，并添加相应的 projection shortcut。修改后的残差块后面是一个具有256通道的3×3卷积模块和3个 Conv-relu-Conv层，生成 heatmaps, embeddings 和 offsets. Hourglass NetworkCornerNet使用 hourglass 网络[28]作为其骨干网络。 hourglass 网络首先被引入到人体姿态估计任务中。它是一个完全卷积的神经网络，由一个或多个 hourglass 模块组成。 hourglass 模块首先通过一系列卷积和最大池化层对输入特征进行采样。然后通过一系列上采样和卷积层对特征进行上采样，使其恢复到原始分辨率。由于细节在最大池层中丢失，因此添加了 skip layers，以将细节带回上采样的特征。 hourglass 模块以一个统一的结构捕获全局和局部特征。当多个 hourglass 模块在网络中堆叠时， hourglass 模块可以重新处理这些特征来捕获更高级别的信息。这些特征使得 hourglass 网络也成为目标检测的理想选择。事实上，许多当前的检测器(FPN, DSSD)已经采用了类似 hourglass 网络的网络。 我们的 hourglass 网络由两个 hourglass 模块组成，我们对 hourglass 模块的架构做了一些修改。我们没有使用最大池，而是简单地使用stride 2来降低特征分辨率。我们将特征分辨率降低了5倍，同时增加了特征通道的数量(256,384,384,384,512)。当我们对特征进行上采样时，我们应用了两个剩余模块，然后是一个最近邻上采样。每个 skip 连接还包含2个 residual 模块。 hourglass 模块中有4个 residual 模块，中间有512个通道。在 hourglass 模块之前，我们使用一个具有 stride 2 和128通道的7×7卷积模块和一个具有stride 2和256通道的残块[15]，将图像分辨率降低了4倍.在[28]之后，我们还在培训中增加了 intermediate supervision。但是，我们没有将中间预测添加回网络，因为我们发现这会损害网络的性能。我们对第一个 hourglass 模块的输入和输出都应用了一个3×3 Conv-BN 模块。然后，我们通过按元素顺序添加一个ReLU和一个包含256个通道的剩余块来合并它们，然后将其用作第二个 hourglass 模块的输入。 hourglass 网络的深度为104。与许多其他最先进的探测器不同，我们只使用整个网络最后一层的特性来进行预测。 ExperimentsTraining Details略… Testing Details在测试过程中，我们使用一个简单的后处理算法从热图、嵌入和偏移量生成边界框。我们首先应用非最大抑制(NMS)使用一个3×3最大池层的角落热图。然后我们从热图中选择前100个左上角和前100个右下角。角的位置由相应的偏移量来调整。我们计算了左上角和右下角嵌入点之间的L1距离。距离大于0.5或包含来自不同类别的角的对将被拒绝。使用左上角和右下角的平均分数作为检测分数。 Ablation StudyCorner Pooling corner pooling是角网的重要组成部分。为了理解它对性能的贡献，我们训练了另一个没有 corner pooling但具有相同数量参数的网络。如表1所示 Reducing penalty to negative locations 我们减少了对一个正位置周围的负位置的惩罚，在一个由物体大小决定的半径内(第3.2节)。为了理解这如何帮助训练角网，我们训练一个没有惩罚减少的网络和另一个半径固定为2.5的网络。我们将它们与验证集上的角网进行比较。如表2所示 Error Analysis: CornerNet 同时输出 heatmaps、 offsets 和 embeddings，所有这些都会影响检测性能。如果一个物体的任何一个角丢失了，该物体的检测结果就会丢失;需要精确的偏移量来生成紧密的边界框;不正确的嵌入将导致许多错误的边界框。为了了解每个部分对最终误差的影响，我们用 gt 值替换预测的热图和偏移量，并对验证集的性能进行评估，从而进行误差分析。如表3所示, 这说明，尽管在检测角点和分组角点方面仍有很大的改进空间，但主要的瓶颈是检测角点。 图 8 展示了两组检测效果图: Comparisons with state-of-the-art detectors]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《GPU高性能编程CUDA实战 CUDA By Example》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-GPU%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8BCUDA%E5%AE%9E%E6%88%98CUDAByExample%2F</url>
    <content type="text"><![CDATA[第一章 为什么需要CUDA1.1 本章目标了解历史和发展历程 1.2 并行处理的历史中央处理器性能的提升逐渐变得困难 1.3 GPU计算的崛起1.4 CUDA1.4.1 CUDA架构是什么cuda架构包含了一个统一的着色器流水线，使得执行通用计算的程序能够对芯片上的每个数学逻辑单元（Arithmetic Logic Unit，ALU）进行排列。另外，NVIDIA在实现ALU时都确保它们满足IEEE单精度浮点数学运算的需求，并且可以使用一个裁剪后的指令集来执行通用计算，而不是仅限于执行图形计算。此外，GPU上的执行单元不仅能任意地读写内存，同时还能访问由软件管理的缓存，也称为共享内存。 CUDA架构的所有这些功能都是为了使GPU不仅能执行传统的图形计算，还能高效的执行通用计算。 1.4.2 CUDA架构的使用NVIDIA专门开发了一款编译器来编译CUDA C语言。现在，用户不再需要了解OpenGL或者DirectX图形编程结构，也不需要将通用计算问题伪装为图形计算问题。 1.5 CUDA的应用医学影像、流体力学等等 第二张 入门2.1 本章目标配置环境 2.2 开发环境 支持CUDA的图形处理器 NVIDIA设备驱动程序 CUDA开发工具箱 标准C编译器 由于CUDA C应用程序将在两个不同的处理器上执行计算，因此需要两个编译器。其中一个编译器为GPU编译代码，另一个为CPU编译代码。 第三章 CUDA简介3.1 本章目标第一段cuda c代码、了解host和device之间的区别、了解其他信息 3.2 第一个程序3.2.1 Hello，World！将CPU以及系统的内存成为主机（host）。而将GPU及其内存成为设备（device）。 在GPU设备上执行的函数通常称为核函数（kernel）。 没有核函数，只考虑在主机运行的CUDA代码和标准的C在很大程度上是没有区别的。 12345int main(void)&#123; printf("Hello, World!\n"); return 0;&#125; 3.2.2 核函数调用在上面的示例中添加核函数 1234567891011#include &lt;iostream&gt;__global__ void kernel(void)&#123;&#125;int main(void)&#123; kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); printf("Hello,World!\n"); return 0;&#125; 上面的代码有两处新增： 一个空的核函数kernel()，并且带有修饰符__global__ 对这个空的核函数的调用语句，并且带有修饰字符&lt;&lt;&gt;&gt; cuda的host代码默认是由系统的标准C编译器来编译的（如Linux的GNU gcc和Windodws的VS），NVIDIA工具只是将代码交给host编译器，它表现出的行为就好像CUDA不存在一样。 而当遇到具有__global__修饰符的函数时，编译器就会将该函数编译为在device上运行。在此例子中，函数kernel()将被交给编译device代码的编译器，而main()函数将被交给host编译器。 而对kernel()函数的调用语句则使用了一种尖括号和两个数值的方式。这将在后面相似介绍。 3.2.3 传递参数以下代码展示了如何像核函数传递参数并取得返回结果 123456789101112131415161718192021#include "stdio.h"__global__ void add(int a, int b, int *c)&#123; *c = a+b;&#125;int main()&#123; int c; int *dev_c; HANDLE_ERROR(cudaMalloc((void**)&amp;dev_c, size(int))); add&lt;&lt;&lt;1,1&gt;&gt;&gt;(2,7,dev_c); HANDLE_ERROR(cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost)); printf("2+7 = %d\n",c); cudaFree(dev_c); return 0;&#125; 以上多行代码包含两个概念： 可以像调用C函数那样将参数传递给核函数 当设备执行任何有用的操作时，都需要分配内存，例如将计算值返回给主机 cudaMalloc()函数：（注意，分配内存的指针不是该函数的返回值，这点与malloc()不同） 参数一： 一个指针，指向用于保存新分配内存地址的变量。注意，由于C语言中，指针传递是本身也是值传递的，所以为了使指针本身的值（不是指针地址指向的值）可以改变，因此在传递时要使用双重指针void**，这样做的主要原因还是因为分配内存的指针最终不是通过函数返回，而是直接改变参数值导致的（如果传的是一重指针，则改变的是pd指向的内存空间的数据，而不是pd本身，所以pd也就不能指向GPU的内存了）。 参数二：分配内存的大小 CUDA C的简单行及其强大功能在很大成都上都是来源于它淡化了主机代码和设备代码之间的差异。然而，程序员一定不能在主机代码中对cudaMalloc()返回的指针进行解引用（Dereference）。主机代码可以将这个指针作为参数传递，对其执行算术运算，甚至可以将其转换为另一种不同的类型。但是，绝对不饿昆虫使用这个指针来读取或写入内存。 CUDA中对设备指针的使用限制总结如下： 可以将cudaMalloc()分配的指针传递给在设备上执行的函数 可以在设备代码中使用cudaMalloc()分配的指针进行内存读写操作 可以将cudaMalloc()分配的指针传递给在主机上执行的函数 不能在主机代码中使用cudaMalloc()分配的指针进行内存读写操作 在主机代码中，可以通过调用cudaMemcpy()来访问设备上的内存。这个函数调用的行为类型与标准C中的memcpy()，只不过多了一个参数来指定设备内存指针究竟是源指针还是目标指针。如，当最后一个参数为cudaMemcpyDeviceToHost时，代表运行时源指针是一个设备指针，而目标指针是以个主机指针。此外还有参数cudaMemcpyHostToDevice和cudaMemcpyDeviceToDevice等，如果源指针和目标指针都是位于主机上，那么可以直接调用标准C的memcpy()函数。 3.3查询设备对于拥有多个支持CUDA的设备，需要通过某种方式来确定使用的是哪一个设备。 首先，我们希望知道在系统中有多少个设备是支持CUDA架构的，并且这些设备能够运行基于CUDA C编写的核函数。要获得CUDA设备的数量，可以调用cudaGetDeviceCount()。12int count;HANDLE_ERROR(cudaGetDeviceCount(&amp;count)); 在调用cudaGetDeviceCount()后，可以对每个设备进行迭代，并查询各个设备的相关信息。CUDA runtime将返回一个cudaDeviceProp类型的结构，其中包含了设备的相关属性。相关属性的含义可见书p20。可以利用cudaGetDeviceProperties()来获得i号设备的属性: 12345678910111213#include &lt;iostream&gt;int main()&#123; cudaDeviceProp prop; int count; cudaGetDeviceCount(&amp;count); for(int i =0 ; i&lt; count; i++)&#123; cudaGetDeviceProperties(&amp;prop, i); //对设备的属性执行某些操作 &#125; std::cout&lt;&lt;count&lt;&lt;std::endl;&#125; 在知道了每个可用的属性以后，接下来就可以进行一些具体的操作，如：1std::cout&lt;&lt;prop.major&lt;&lt;std::endl; 3.4 设备属性的使用根据在cudaGetDeviceCount()和cudaGetDeviceProperties()中返回的结果，我们可以对每个设备进行迭代，来找到我们期望的某些达到要求的设备。但是这种迭代操作执行起来有些繁琐，因此CUDA runtime提供了一种自动方式来执行这个迭代操作。首先，找出希望设备拥有的属性并将这些属性填充到一个cudaDeviceProp结构。1234cudaDeviceProp prop;memset(&amp;prop, 0 , sizeof(cudaDeviceProp));prop.major = 1;prop.minor = 3; 之后，将该结构传递给cudaChooseDevice()，这样CUDA runtime运行时将查找是否存在某个设备满足这些条件，并返回一个设备ID，我们可以将这个设备ID传递给cudaSetDevice()。随后，所有的设备操作都将在这个设备上执行。 12345678910111213141516#include &lt;iostream&gt;using std::cout;using std::endl;int main()&#123; cudaDeviceProp prop; memset(&amp;prop, 0 , sizeof(cudaDeviceProp)); prop.major = 1; prop.minor = 3; int dev; cudaGetDevice(&amp;dev); cudaChooseDevice(&amp;dev, &amp;prop); cout&lt;&lt;"ID:"&lt;&lt;dev&lt;&lt;endl;&#125; 第四章 CUDA C并行编程4.1 本章目标 了解CUDA在实现并行性时采用的一种重要方式。 用CUDAC编写第一段并行代码 4.2 CUDA并行编程4.2.1 矢量求和运算假设有两组数据，将这两组数据中对应的元素两两想加，并将结果保存在第三个数组中。 基于CPU的矢量求和 123456789#define N 10void add(int *a, int *b, int *c)&#123; int tid = 0; //这是第0个CPU，因此索引从0开始 while(tid&lt;N)&#123; c[tid] = a[tid] + b[tid]; tid += 1; // 由于只有一个CPU，因此每次递增1 &#125;&#125; &emsp;&emsp;上面将代码特意写成方便修改为并行代码的形式，如，在双核处理器上，tid的设置可以分别为0和1，tid递增的大小可以改为2等。这就相当于在两个CPU上，一个执行奇数位想加，一个执行偶数位想加。 基于GPU的矢量求和 首先给出mian()函数： 123456789101112131415161718192021222324252627282930#define N 10int main()&#123; int a[N],b[N],c[N]; int *dev_a, *dev_b, *dev_c; //在GPU上分配内存，注意这里要知道为什么使用void** cudaMalloc( (void**)&amp;dev_a, N*sizeof(int)); cudaMalloc( (void**)&amp;dev_a, N*sizeof(int)); cudaMalloc( (void**)&amp;dev_a, N*sizeof(int)); ...//创建a，b数组并赋值 //将数组a，b复制到GPU cudaMemcpy(dev_a, a, N*sizeof(int),cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice); add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a, dev_b, dev_c); //将数组c从GPU复制到CPU cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost); ...//显式结果 //释放GPU上分配的内存 cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c); return 0;&#125; 看一下核函数的调用：1add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a, dev_b, dev_c); 尖括号中的两个数值将传递给runtime，作用是告诉runtime如何启动核函数： 第一个参数：表示设备在执行款核函数时使用的并行线程块的数量。 参数二：需要多少个线程格（Grid）（一格表示N个线程块的集合） 我们将每个并行执行环境都称为一个线程块（Block），对于此例，将有N个线程块在GPU上运行（N个运行核函数的副本）。 问题：如何在代码中知道当前正在运行的是哪一个线程块？ 回答：利用变量blockIdx.x 。 这是一个内置变量，在CUDA runtime中已经预先定义了这个变量，无需在代码中声明，该变量中包含的值就是当前执行设备代码的线程块的索引。 接下来是GPU版本的add()函数： 123456__global__ void add(int *a, int *b, int *c)&#123; int tid = blockIdx.x; //计算机该索引处的数据 if(tid &lt; N) c[tid] = a[tid] + b[tid];&#125; 当启动核函数时，我们将并行线程块的数量指定为N。这个并行线程块集合就称为一个“线程格（Grid）”。因此，此例表示我们想要一个一维的线程格，其中每个线程格包含N个线程块，每个线程块的blockInx.x的值都是不同的，cuda会为每个设备代码副本提供不同的blockInx.x。 需要注意的一点是：在启动线程块数组时，数组每一维（N）的最大数量不能超过65535。这是一种硬件限制，如过启动的线程块数量超过了这个限制，那么程序将运行失败。 4.2.2 一个有趣的示例绘制Julia集的曲线 Julia集算法：通过下面的迭代等式对复平面中的点求值。如果在计算某个点时，迭代等式的计算结果是发散的，那么这个点就不属于Julia集合。 Z_{n+1} = Z_n^2 + C 基于CPU的Julia集 先看main函数，它通过工具库创建了一个大小合适的位图图像，接着，将一个指向位图数据的指针传递给了核函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//julia.cpp#include&lt;iostream&gt;#include "opencv2/core/core.hpp"#include "opencv2/highgui/highgui.hpp"using namespace cv;void kernel(Mat&amp; M);int julia(int x, int y);//定义一个通用结构来保存复数值,r为实部，i为虚部struct cuComplex&#123; float r; float i; cuComplex(float a , float b ):r(a),i(b)&#123;&#125; float magnitude2()&#123;return r*r+i*i;&#125; cuComplex operator*(const cuComplex&amp; a)&#123; return cuComplex(r*a.r-i*a.i, i*a.r + r*a.i); &#125; cuComplex operator+(const cuComplex&amp; a)&#123; return cuComplex(a.r+r, a.i+i); &#125;&#125;;int DIM = 800;int main()&#123; cv::Mat M(DIM,DIM,CV_8UC1); kernel(M); imshow("Test",M); //窗口中显示图像 imwrite("E:/灰度图.jpg",M); //保存生成的图片 waitKey(0); //等待按任意键后窗口自动关闭 getchar(); return 0;&#125;void kernel(Mat&amp; M)&#123; for (int y=0;y&lt;M.rows;y++)//遍历每一行每一列并设置其像素值 &#123; for (int x=0;x&lt;M.cols;x++) &#123; int juliaValue = julia(x,y); M.at&lt;uchar&gt;(x,y)=155*juliaValue+100; &#125; &#125;&#125;//判断函数，如果该点属于集合返回1，否则返回0int julia(int x, int y)&#123; const float scale = 1.5; float jx = scale*(float)(DIM/2 - x)/(DIM / 2); float jy = scale*(float)(DIM/2 - y)/(DIM / 2); cuComplex c(-0.8, 0.154); cuComplex a(jx,jy); int i = 0; for(i = 0; i&lt;200; i++)&#123; a = a*a+c; if(a.magnitude2() &gt; 1000) return 0; &#125; return 1;&#125; 下面是kernel核函数对将要绘制的所有点进行迭代，并在每次迭代时调用julia来判断该点是否属于Julia集（“是”则涂红色，“否”则涂黑色）。 该函数首先将像素坐标转换为复数空间的坐标，为了将复平面的原点定位到图像中心，代码将像素位置移动了MID/2，然后，为了确保图像的范围为-1.0到1.0，我们将图像的坐标缩放了DIM/2倍。在计算处复空间中的点之后，需要判断这个点是否属于Julia集。通过迭代判断（本示例迭代200次，在每次迭代完成后，都会判断结果是否超过某个阈值），如果属于集合，就返回1，否则，返回0。最后运行指令g++ julia.cpppkg-config —cflags —libs opencv-o julia生成的效果图如下： 基于GPU的Julia集 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include&lt;iostream&gt;#include &quot;opencv2/core/core.hpp&quot;#include &quot;opencv2/highgui/highgui.hpp&quot;using namespace cv;__global__ void kernel(unsigned char* ptr);__device__ int julia(int x, int y);const int DIM = 800;struct cuComplex&#123; float r; float i; __device__ cuComplex(float a , float b ):r(a),i(b)&#123;&#125; __device__ float magnitude2()&#123;return r*r+i*i;&#125; __device__ cuComplex operator*(const cuComplex&amp; a)&#123; return cuComplex(r*a.r-i*a.i, i*a.r + r*a.i); &#125; __device__ cuComplex operator+(const cuComplex&amp; a)&#123; return cuComplex(a.r+r, a.i+i); &#125;&#125;;int main()&#123; cv::Mat M(DIM,DIM,CV_8UC1); unsigned char bitmap[DIM][DIM]; unsigned char *dev_bitmap; //定义一定char二维数组，用来存储GPU传过来的结果 cudaMalloc(&amp;dev_bitmap, DIM*DIM); dim3 grid(DIM,DIM); kernel&lt;&lt;&lt;grid,1&gt;&gt;&gt;(dev_bitmap); cudaMemcpy(bitmap,dev_bitmap, DIM*DIM , cudaMemcpyDeviceToHost); for (int y=0;y&lt;M.rows;y++) //遍历每一行每一列并设置其像素值 &#123; for (int x=0;x&lt;M.cols;x++) &#123; M.at&lt;uchar&gt;(x,y)=bitmap[y][x]; //M.at&lt;uchar&gt;(x,y)=juliaValue+100; &#125; &#125; imshow(&quot;Test&quot;,M); //窗口中显示图像 waitKey(0); getchar(); return 0;&#125;__global__ void kernel(unsigned char* ptr)&#123; int x = blockIdx.x; int y = blockIdx.y; int offset = x+ y*gridDim.x; int juliaValue = julia(x,y); ptr[offset] = 255*juliaValue;&#125;__device__ int julia(int x, int y)&#123; const float scale = 1.5; float jx = scale*(float)(DIM/2 - x)/(DIM/2); float jy = scale*(float)(DIM/2 - y)/(DIM/2); cuComplex c(-0.8, 0.156); cuComplex a(jx,jy); int i = 0 ; for(i = 0; i&lt;200; i++)&#123; a = a*a +c; if(a.magnitude2() &gt; 1000) return 0; &#125; return 1;&#125; 这里需要注意的是，在程序中指定了多个并行线程块来执行函数kernel。并且，使用了一种新的类型来声明了一个二维的线程格：1dim3 grid(DIM, DIM); 类型dim3并不是标准C定义的类型，它可以表是一个三维数组，至于为什么不直接用二维数组，CUDA开发人员主要是为了日后的扩展，所以用三维数组来表示二维数组，数组的第三维默认为1。下面的代码将线程块grid传递给CUDA运行时：1kernel&lt;&lt;&lt;grid,1&gt;&gt;&gt;(dev_bitmap); 代码中还使用了修饰符__device__，这代表代码将在GPU而不是主机上运行，由于这些函数已声明为__device__，因此只能从其他__device__函数或者__global__函数中调用它们。 通常，我们将在GPU上启动的线程块集合称为一个线程格。从名字的含义可以看出，线程格既可以是一维的线程块集合，也可以是二维的线程块集合。核函数的每个副本都可以通过内置变量blockIdx来判断哪个线程块正在执行它。塌秧，还可以通过内置变量gridDim来获得线程格的大小。 第五章 线程协作5.1 本章目标 了解CUDA C中的线程 了解不同线程之间的通信机制 了解并行执行线程的同步机制 5.2 并行线程块的分解当启动核函数时，我们会指定第一个参数的值，也就是指定多个并行副本，我们将这些兵行副本称为线程块（Block）。尖括号中的第二个参数表示CUDA运行时在每个线程块中创建的线程数量，因此，总共启动的线程数量可按下面的公式计算： N个线程块 \times M个线程每线程块 = N个并行线程5.2.1 矢量求和：重新回顾使用线程块中的并行线程，能够完成一些并行线程块无法完成的工作。 1.使用线程实现GPU上的矢量求和（即在一个线程块内设置多条线程）相较于之前的矢量求和，需要修改两个地方，第一是将下面的代码#1式改成代码#2式：123add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a, dev_b, dev_C);add&lt;&lt;&lt;1,N&gt;&gt;&gt;(dev_a, dev_b, dev_c); 第二是修改索引方式，有限现在只有一个线程块，所以不能再用blockIdx来获取索引了，而应使用线程索引，如下所示：1int tid = threadIdx.x; 完整的代码如下所是：12345678910111213141516171819202122232425262728293031323334353637#include&lt;iostream&gt;const int N = 10;/*#define N 20*/__global__ void add(int * dev_a, int* dev_b, int* dev_c)&#123; int tid = threadIdx.x; //注意此处使用的是线程索引 if(tid&lt;N) dev_c[tid] = dev_a[tid] + dev_b[tid];&#125;int main()&#123; int a[N]; int b[N]; int c[N]; for(int i=0;i&lt;N;i++) a[i]=i; for(int i=0;i&lt;N;i++) b[i]=i; int* dev_a; int* dev_b; int* dev_c; cudaMalloc(&amp;dev_a, sizeof(int)*N); cudaMalloc(&amp;dev_b, sizeof(int)*N); cudaMalloc(&amp;dev_c, sizeof(int)*N); cudaMemcpy(dev_a,a,sizeof(int)*N, cudaMemcpyHostToDevice); //第一个参数为目的地址，第二个为原地址，第三个为空间大小 cudaMemcpy(dev_b,b,sizeof(int)*N, cudaMemcpyHostToDevice); add&lt;&lt;&lt;1,N&gt;&gt;&gt;(dev_a,dev_b,dev_c); //线程块数为1，每块内的线程数为N cudaMemcpy(c, dev_c, sizeof(int)*N, cudaMemcpyDeviceToHost); for(auto x:c) std::cout&lt;&lt;x&lt;&lt;std::endl;&#125; 2.在GPU上对更长的矢量求和之前在第四章我们提到，由于硬件原因，线程块的数量不能超过65535。 同样，对于启动核函数时每个线程块中的线程数量，也有一定的限制。具体来说，最大的线程数量不能超过设备属性结构中maxThreadsPerBlock域的值。对于很多图形处理器而言，这个限制值是每个线程块512个线程（目前GTX 980Ti为1024个）。通过下面的代码可以获得当前机器上的最大线程数：12345678910111213#include &lt;iostream&gt;int main()&#123; cudaDeviceProp prop; int count; cudaGetDeviceCount(&amp;count); for(int i =0 ; i&lt; count; i++)&#123; cudaGetDeviceProperties(&amp;prop, i); std::cout&lt;&lt;count&lt;&lt;std::endl; std::cout&lt;&lt;prop.maxThreadsPerBlock&lt;&lt;std::endl; &#125;&#125;//output：1024 为了通过并行对长度大于1024的矢量进行相加，必须将线程和线程块结合起来才能实现，因此仍然需要改动两个地方：核函数中的索引计算方法和核函数的调用方式：（使用多个线程块，并且每个线程块包含多个线程） 首先是修改索引计算方法：12int tid = threadIdx.x + blockIdx.x * blockDim.x; 在上面的赋值语句中使用了一个新的内置变量，blockDim。对于所有线程块来说，这个变量是一个常数，保存的是线程块中每一维的线程数量。（回顾第四章，在gridDim中保存了一个类似的值，即在线程格中每一维的线程块数量。但要知道，gridDim是二维的，blockDim是三维的，只是很少用的高维索引值） 另一处修改是核函数调用本身，为了保证最终启动的线程数量不少于预期量，可以通过一种常见的技术来对需要启动的线程块数量进行向上取整，如下所示：1add&lt;&lt;&lt; (N+127)/128, 128 &gt;&gt;&gt; (dev_a, dev_b, dev_c); 上面的代码当N不是128的整数倍时，会启动过多的线程，这时候，判断语句if (tid&lt;N)就表现处作用了，它可以确保进行计算的线程的不会对越过数组边界的内存进行读取或写入：12if (tid &lt; N) c[tid] = a[tid] + b[tid]; 3.在GPU上对任意长度的矢量求和]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SNIP (CVPR, 2018)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SNIP%2F</url>
    <content type="text"><![CDATA[文章: An Analysis of Scale Invariance in Object Detection - SNIP作者: Bharat Singh, Larry S.Davis备注: Maryland 摘要本文分析了在极端尺度变化下的目标识别和检测的各种技术, 通过对不同输入数据配置的检测器进行训练, 比较了尺度固定(scale specific)和尺度不变(scale invariant)检测器的不同设计. 通过对不同网络结构在 ImageNet 上对小目标分类的性能评估, 我们发现 CNN 对尺度变化并不具有足够的鲁棒性. 在此基础上, 本文提出了在图像金字塔(image pyramid)的相同尺度上训练和测试检测器. 由于小物体和大物体分别在更小的尺度和更大的尺度上难以识别, 因此, 我们提出了一种新的图像金字塔尺度归一化(Scale Normalization for Image Pyramids, SNIP)训练方案, 该方案可以根据图像尺寸的大小, 有选择的反向传播不同大小对象实例的梯度. 在 COCO 数据集上, 我们的单模型表现为 45.7%, 三个模型的融合表型为 48.3%. 我们使用了现成的(off-the-shelf) ImageNet-1000 预训练模型, 并且只在边框监督下训练. Introduction相比于图像分类, 为什么目标检测任务更难? 其中一个重要的影响因素就是, 跨实例的大幅尺度变化, 尤其是检测非常小的物体时所带来的挑战. 但有趣的是, ImageNet 中的中型物体相对于图片的尺寸大约有 55.4%, 而 COCO 中只有 10.6%. 因此, COCO 中的大多数对象实例都小于图像区域的 1%! 更糟糕的是, COCO 中最小和最大的 10% 个对象实例占图片的比例分别是 0.024 和 0.472, 如图 1 所示. 因此, detectors 需要处理的尺度变化是非常巨大的, 这对卷积神经网络的尺度不变性提出了极大的挑战. 此外, ImageNet 和 COCO 数据集在对象实例尺度上的差异也会导致从预训练 ImageNet 模型中进行 fine-tuning 时出现较大的 domain-shift. 在本文中, 我们首先提供了证明这些问题存在性的证据, 然后提出了一种称为图像金字塔尺度归一化(Scale Normalization for Image Pyramids)的训练方法, 从而在 COCO 上实现了 sota detectors. 为了解决尺度变化和小物体检测的问题, 有很多方案被提出: 特征金字塔, 空洞(dilated)卷积, 可形变(deformable)卷积, …, 尽管这些 architectural innovations 极大的提升了目标检测的性能, 但是和 training 相关的许多问题都还没有得到解决: 为了获得较好的目标检测结果, 对图像进行上采样是至关重要的吗? 既然检测数据集中图像的典型大小时 480x640, 那么为什么将它们的样本提高到 800x1200 是一种常见的做法? 我们能否再 ImageNet 的低分辨率图像上以较小的步长对 CNN 进行预训练, 然后在检测数据集中对它们进行 fine-tuning, 以检测小物体吗? 当从预训练的分类模型中对目标检测任务进行 fine-tuning 时, 我们应该将图片进行适当放缩以使得参与训练的物体尺寸被限制在一个范围内(64x64 ~ 256x256), 还是应该令所有尺寸(16x16 ~ 800x1000)的物体都参与训练? 我们在 ImageNet 和 COCO 上设计了相应的实验来寻找这些问题的答案. 在第三节中, 我们通过在现有网络上测试不同尺度的图像作为输入时的 ImageNet 的分类性能, 研究了 scale variation 的影响. 我们还对 CNN 的结构进行了小的修改, 以便对不同尺度的图像进行分类. 这些实验揭示了上采样操作对小目标检测的重要性.Section 5: 分析尺度变化对目标检测的影响Section 6: SNIP Related WorkScale Space Theory: 学习具有尺度不变性的特征, 在传统检测领域非常流行 Dilated/Atrous Conv Deformable Conv Up-sampling: 图片在训练阶段放大 1.5~2 倍, 在测试阶段放大 4 倍. (可以提升特征图谱的尺度) 特征金字塔: 浅层的特征图谱和深层的特征图谱具有互相补充的信息.(smaller objects are trained on higher resolution layers, while larger objects are trained on lower resolution layers). 但是, 尽管特征金字塔能够有效地利用网络中所有层的特征, 但是对于检测非常小/大的物体来说, 它们并不是替代图像金字塔的一个好选择. Image Classification at Multiple Scales本节讨论 domain shift 的影响(training 阶段和 inference 阶段的图片分辨率不同). Naive Multi-Scale Inference: 首先, 对 ImageNet 的图像进行 down-sampling, 或者 48, 64, 80, 96, 128 等不同分辨率的图像. 然后将这些图像全部 up-sampling 到 224 分辨率, 并将其作为输入提供给一个针对 224x224 大小图像进行训练的 CNN 结构, 如图 3 中的 CNN-B 所示. 图 4(a) 中显示了具有 ResNet-101 backbone 的 CNN-B 的 top-1 精度. 我们观察到, 随着 training 和 testing 图像分辨率的差异逐渐增大, CNN 的性能也逐渐下降. 对没有经过训练的分辨率进行 testing 是次优的, 至少对于图像分类来说如此. Resolution Specific Classifiers: 基于上述观察, 提高小目标探测器性能的一个简单的解决方案是在 ImageNet 上对不同步长的分类网络进行预训练. 毕竟, 在 CIFAR10 上获得最佳性能的网络架构不同于 Imagenet. 在 ImageNet 分类网络中, 第一个卷积层的步长为 2, 接着是最大池化层的步长为 2x2, 两次下采样可能会消除小对象中存在的大部分图像信号. 因此, 我们在训练输入为 48x48 的图像时, 将第一层的卷积层核改为 3x3, 步长改为 1, 如图 3 所示. 同样, 同于 96x96 的图像, 将核改为 5x5, 步长改为 2. 同时还是用了一些常用的数据增广技术. 如图 4 所示, 这些网络(CNN-S)的表现均强于 CNN-B. 因此, 对接收低分辨率图像为输入的不同网络结构进行预训练, 然后将其应用于低分辨率目标的检测是一个更好的选择. Fine-tuning High-Resolution Classifiers: 另一个小目标检测的简单解决方案是对上采样的低分辨率图像在 CNN-B 上进行 finetuning, 从而得到 CNN-B-FT(如图 3 所示). 在上采样的低分辨率图像上, CNN-B-FT 的性能优于 CNN-S, 如图 4 所示. 实验结果表明, 在高分辨率图像上学习的 filters 也可以用于低分辨率图像的识别, 因此, 与其将步长减少 2, 不如将图像上采样 2 倍, 然后对使用高分辨率图像预训练的网络进行 fine-tuning. 在训练 object detectors 时, 我们可以使用不太的网络结构对不同分辨率的对象进行训练, 也可以令所有的分辨率都使用同一体系结构. 由于在 ImageNet 上进行训练是有益的, 并且在较大的目标实例上学习的 filters 有助于对较小的目标实例进行分类, 因此对图像进行上采样并使用在高分辨率图像上进行预训练的网络应该比专门用于较小对象进行分类的网络更好. Fortunately, 现有的 object detectors 通过对图像进行上采样来检测较小的对象, 而不是使用不同的网络结构. 本文的分析支持这种做法, 并将其与其他的替代方法进行比较, 以强调差异. BackgroundDeformable-RFCN Data Variation or Correct Scale?第三节的研究证明, 在 training 和 testing 阶段之间的使用的分辨率的差异性可以导致性能显著下降. 不幸的是, 这种分辨率上的差异性是当前的 GPU 内存限制造成的, 训练时的分辨率(800x1200)低于测试时(1400x2000)的分辨率. 本节分析了图像分辨率, 目标实例的尺寸和数据变化对 detectors 的影响. 我们在不同的 settings 下对 detectors 进行训练, 并在 1400x2000 的图像上对小物体(低于 32x32 像素)进行检测. 实验结果如表 1 所示. Training at different resolutions: 我们首先训练两种不同分辨率(800x1400, 1400x2000)下的所有对象实例训练 detectors, 如图 5(1) 所示. 实验结果和预期一样, 1400 的表现强于 800, 因为前者在训练和推理时采用了相同的分辨率. 但是, 这种提升很少(only marginal), 这是为什么呢, 为了回答这个问题, 我们思考了在用大分辨率的图像进行训练时, 中型目标和大型目标会受到什么影响? 很明显, 这些物体变的太大而无法正确的分类了(图像变大的另一个影响就是感受野变小了), 在高分辨率下的训练可以将小物体放大以获得更好的分类, 但是这样会降低中型物体和大型物体的检测效果. Scale specific detectors: 我们用 1400x2000 的分辨率训练了另一个 detectors, 同时忽略了所有中型和大型物体(原始像素大于 80), 以此消除大型物体的有害影响, 如图 5(2) 所示. 但是不幸的是, 实验结果甚至比 800 像素下的训练还要差, 产生这种现象的原因是因为由于忽略了中型物体和大型物体(站物体总数约 30%), 我们失去了外观和姿态变化的一个重要来源, 而这种忽略带来的性能损害要远大于其带来的好处. Multi-Scale Training(MST): 最后, 我们评估了在训练过程使用随机分辨率来提升 detectors 尺度不变性的常见方法, 称为多尺度训练(MST), 如图 5(3) 所示. 它可以使用一个参与训练的对象实例在不同的尺度下被观察到, 但是同时它也会被极大或者极小的物体影响性能. 它的性能表现和 800 像素下的训练结果相似. 由此, 我们的结论是, 在训练时不仅要在一个合适的尺度下训练, 同时还应该能够捕捉物体上尽可能多的变化. 下一节我们将介绍本文的训练方法, 它取得了很大的性能提升. Object Detection on an Image Pyramid我们的目标是将上面结论中的两个关键因素结合起来, 即将训练图片的尺寸控制在合理范围内的同时, 使参与训练的物体在外观和形态上具有更多的多样性. 我们还讨论了在当前 GPU 内存限制下, 在图像金字塔上训练 detectors 的细节. Scale Normalization for Image PyramidsSNIP 是 MST 的修改版本, 其中只有分辨率接近 ImageNet(224) 尺寸的物体实例才会被用来训练 detector. 在 MST 中, 每一张图片都会在不同的分辨率下被观察到, 因此, 在高分辨率(1400x2000)下大型物体很难被检测识别, 在低分辨率(480x800)下小型物体很难被检测识别. 幸运的是, 每个对象实例都会在多个分辨率下进行训练, 而其中正好有一些处在我们期望的分辨率范围内. 为了消除过大或者过小的极端尺度对象, 我们只对处于所需尺度范围内的对象进行训练, 对于其他的对象则不会进行反向传播计算. 为了更有效的训练, SNIP 在训练过程中使用了所有的对象实例(但不是都会参与 BP 计算), 这有助于捕获外观和姿态的所有变化, 同时减少了预训练网络在 scale-space 中的 domain-shift. 最终结果如图 1 所示, it outperforms all the other approaches. 实验结果证明了 SNIP 在检测小物体上的有效性. 接下来我们将会讨论 SNIP 的实现细节. 在训练分类器时, 所有的 gt boxes 都会被用来给 proposals 分配标签. 在训练期间, 我们不会选择超出特定分辨率范围的 proposals 和 gt boxes. 对于一个特定的分辨率 $i$, 如果 RoI 的面积 $ar(r)$ 落在了 $[s_i^c, e_i^c]$ 区间内, 我们就将其标记为有效样本, 否则将其标记为无效样本. 同样, RPN 在训练时也使用所有的 gt boxes 来为 anchor 分配标签. 最后, 那些与 invalid gt box 的交并比大于 0.3 的 anchors 都会在训练中剔除(即, 他们的梯度设置为 0). 在 Inference 阶段, 我们在每个分辨率下都使用 RPN 来生成 proposals, 并在每个分辨率下进行单独分类, 如图 6 所示. 和训练阶段相同, 我们在每个分辨率下没有选择落在特定范围外的检测结果(是 detectin, 不是 proposals). 在分类和回归操作完成后, 我们使用 soft-NMS 来融合多个分辨率下的检测结果, 以便获取最终的检测结果, 如图 6 所示. 池化后的 RoI 的分辨率和预训练的网络相匹配, 因此在 fine-tuning 期间网络更容易学习. 对于像 R-FCN 这样将 RoI 分成子部分并使用 position sensitive filters 的方法, 这边的更加重要. 例如, 如果 RoI 的大小为 48 个像素(在 conv5 中就会变成 3 像素), 并且每个轴上都有 7 个 filters, 那么特征和 filters 之间的位置对应关系就会丢失. Sampling Sub-Images用深度卷积网络训练高分辨率的图像需要更多的 GPU 显存. 因此, 我们对图片进行剪裁, 以使得他们可以适应 GPU 的显存大小. 我们的目标是生成最小数量的 1000x1000 尺寸的 chips(sub-images), 并让这些 chips 覆盖图像中的所有小目标. 这有助于加速训练, 因为在没有小目标物体的地方不需要进行计算. 为此, 我们为每张图像生成 50 个随机定位的芯片, 大小为 1000x1000. 我们将覆盖最多目标对象的 chips 添加到我们的训练集中, 在覆盖图片中的所有目标物体之前, 我们队其余对象重复这个采样和选择过程. 由于 chips 是随机生成的, 而 proposals boxes 通常在图像边界上有一个边, 因此为了加速采样过程, 我们将芯片对于到图像的边界. 我们发现, 平均情况下, 对于 1400x2000 的图像, 可以生成 1.7 个尺寸为 1000x1000 的 chips. 在图片分辨率为 800x1200 或者 480x640 , 或者图片中不包含小物体时, 这个采样步骤是不需要的. 随机剪裁并不是 detectors 性能提高的原因. 为了验证这一点, 我们使用了非剪裁的高分辨率图像(1400x2000)来训练 ResNet-50, 并且没有发现 mAP 的变化. Datasets and Evaluationsmall objects: less than 32medium objects: from 32 to 96large objects: greater than 96 Training Details在三个不同的分辨率上训练 Deformable-RFCN: 480x800, 800x1200, 1400x2000, 第一个值代表 shorter side 的长度, 第二个值代表边长的最大值;training: 7 epochs for classifier while RPN is trained for 6 epochs.warmup learning rate: 0.0005 for 1000 iterations, then 0.005. step down is performed at 4.33 epochs for RPN and 5.33 epochs otherwise.valid range: $[0, 80], [40, 160], [120, \infity]$ SNIP doubles the training time Improving RPNExperiments表 2 展示了 single scale model, multi-scale testing, multi-scale training + multi-scale testing 的性能 表 3 展示了 Average Recall 的性能表现, 使用更强的分类网络(DPN-92)也能够提升 AR. 表 4 展示了各个模型与 SNIP 的消融对比实验]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十五章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter15%2F</url>
    <content type="text"><![CDATA[第十五章 友元、异常和其他15.1 友元类并非只能拥有友元函数，也可以将类作为友元。在这种情况下，友元类的所有方法都可以访问原始类的私有成员和保护成员。哪些函数、成员函数或类为友元是由类定义的，而不能从外部强加友情。因此 ，尽管友元被授予从外部访问类的私有部分的权限，但它们并不与面向对象的编程思想相悖。 15.1.1 友元类关于需要使用友元类的情况，可以想象电视机类和遥控器类之间的关系，首先，它们不是is-a，其次，也不是has-a，但是它们确实存在某个关系，这就是——友元。下面的语句使Remote成为友元类，友元声明可以位于公有、私有或保护部分，其所在的位置无关紧要。由于Remote类中访问了Tv类的成员，因此，编译器必须了解Tv类以后，才能处理Remote类，最简单的方法是首先定义Tv类，另一种方法是使用前向声明（forward delaration），这将稍后介绍。12345class Tv&#123; ... friend class Remote; ...&#125;; 以上代码，在电视机类里面声明遥控器类为友元类以后，遥控器类就可以访问电视机类的私有成员变量，而无需让电视机类修改自身的访问权限，就是说电视机对外界的访问权限是不变的，并没有破坏类的封装行。 15.1.2 友元成员函数可以选择仅让特定的类成员变成另一个类的友元，而不必让整个类成员友元，但是这样做稍微有点麻烦，必须小心排列各种声明和定义的顺序。 123class TV&#123; friend void Remote::set_chanel(TV &amp;t, int c);&#125; 要使编译器能够处理上面的代码，它必须知道Remote的定义，否则，它无法知道Remote是类还是别的什么，也无法确定set_chanel是这个类的方法。而前面又说了，Tv应定义在Remote定义之前，这就导致了循环依赖问题。避开这种问题的方法是使用前向声明（forward declaration）。为此，需要在Remote定义的前面插入下面的语句：1class Tv; 这样，新的排列顺序如下：1234567class Tv;class Remote &#123; ...&#125;;class Tv&#123; ...&#125;; 注意，Tv类与Remote类的定义不可以调换，因为编译器在Tv类的声明者是看到Remote的一个方法被声明为Tv类的友元之前，应该先看到Remote类的声明和set_chanel()方法的声明。 15.1.3 其他友元关系可以通过让类彼此成为对方的友元来实现互相影响对象的功能。即除了Remote是Tv的友元外，Tv还是Remote的友元。需要注意一点的是，对于使用Remote对象的Tv方法，其原型可在Remote类声明之前声明，但必须在Remote类声明之后定义，以便编译器有足够的信息来编译该方法。 15.1.4 共同的友元需要使用友元的另一种情况是，函数需要访问两个类的私有数据。因此，可以将函数左右两个类的友元 15.2 嵌套类（内部类）在C++中，可以将类声明放在另一个类中，在另一个类中声明的类被成为嵌套类（nested class），它通过提供新的类型类作用域来避免名称混乱。包含类的成员函数可以创建和使用被嵌套类的对象，而仅当声明位于公有部分，才能在包含类的外面使用嵌套类，而且必须使用作用域解析符。 对类进行嵌套与包含并不同。包含意味着将类对象作为另一个类的成员，而对类进行嵌套不会创建类成员，而是 定义了一种类型 ，可以在包含类的其他方法内声明该类型的变量，该类型仅在包含嵌套类声明的类中有效。 15.2.1 嵌套类和访问权限 作用域 &emsp;&emsp;如果嵌套类是在另一个类的私有部分声明的，则只有这个类知道它。也就是说，只能通过这个类的成员来使用嵌套类，就像私有变量一样。而这个类的派生类，和外部的程序都无法访问到该嵌套类。 &emsp;&emsp;如果嵌套类是在另一个类的保护部分声明的，则它对于后者及其派生类都是可见的，但是对于外部师姐是不可见的。 &emsp;&emsp;如果嵌套类是在另一个类的公有部分声明的，则允许后者、后者的派生类以及外部世界访问它。并且，由于嵌套类的作用域为包含它的类，因此在外部世界使用它时，必须使用类限定符。 &emsp;&emsp;嵌套结构和枚举的作用域与嵌套类相同。下表总结了嵌套类、结构和枚举的作用域特征 声明位置 包含它的类是否可以使用它 从包含它的类派生的类是否可以使用它 在外部是否可以使用 私有部分 是 否 否 保护部分 是 是 否 公有部分 是 是 是，通过类限定符使用 访问控制 &emsp;&emsp; 类可见后，起决定作用的将是访问控制。对嵌套类访问权的控制规则与对常规类相同。例如，在Queue类声明中声明了Node嵌套类，这并没有赋予Queue类任何对Node类的访问特权，也没有赋予Node类任何对Queue类的访问特权。因此，Queue类对象只能显式的访问Node对象的公有成员。 15.2.2 模板中的嵌套模板类可以正常使用嵌套类，不会带来额外的问题。 15.3 异常程序有时会遇到运行阶段错误，导致程序无法正常的走下去。如，试图打开一个不可用的文件、请求过多的内存、遭遇不能接受的值等等。 C++的异常处理机制是一个相对较新的功能，有些老式编译器可能没有实现，有些编译器可能默认关闭这种特性，需要在选项中开启。比如“零除” 这种异常，很多新编译器通过生成一个表示无穷大的特殊浮点值来处理，cout将其显示为Inf、inf、INF等，有些编译器可能会直接崩溃。 15.3.1 调用abort()abort()函数的原型位于头文件cstdlib（stdlib.h）中，其典型实现是向标准错误流发送消息abnormal program termination（程序异常终止），然后终止程序。它还返回一个随实现而异的值，告诉操作系统（或者父进程），处理失败。abort()是否刷新文件缓冲区（用于存储读写到文件中的数据的内存区域）取决于实现。如果愿意，也可以使用exit()，该函数刷新文件缓冲区，但不显示消息。 15.3.2 返回错误码一种比异常终止更灵活的方法是，使用函数的返回值来指出问题。如果某些函数的任何数值返回都是有效的，那么可以增加一个指针参数或引用参数，来将返回值返回，同时将函数的返回值改成bool类型，来指出是否返回成功。 另一种方法使用一个全局变量。可能问题的函数可以在出现问题时将该全局变量设值为特定的值，而调用程序可以检查该变量。 15.3.3 异常机制C++异常是对程序运行过程中发生的异常情况的一种响应。异常提供了将控制权从程序的一个部分传递到另一个部分的途径。对异常的处理有三个组成部分： 引发异常 使用处理程序捕获异常 使用try块处理异常 throw语句实际上是跳转，即命令程序跳到另一条语句。throw关键字表示引发异常，紧随其后的值（例如字符串或对象）指出了异常的特征。 程序使用异常处理程序（exception handler）来捕获异常，异常处理程序位于要处理问题的程序中，catch关键字表示捕获异常。处理程序以关键字catch开头，随后是位于括号中的类型声明，他指出了异常处理程序要响应的异常类型。 catch关键字和异常类型用作标签，指出当异常被引发时，程序应跳到这个为止执行。异常处理程序也被称为catch块。 try块标识可能引起特定异常的代码块，他后面跟一个或多个catch块。try块是由关键字try只是的，关键字try的后面是一个由花括号括起的代码块，表明需要注意这些代码引发的异常。 在默认情况下，如果函数引发了异常，而没有try块或没有匹配的处理程序时，程序将调用abort()函数。（默认行为可修改）。 15.3.4 将对象用作异常类型通常，引发异常的函数将传递一个对象。这样做的重要优点之一是，可以使用不同的异常类型来区分不同的函数在不同情况下引发的异常。另外，对象可以携带信息，程序员可以根据这些信息来确定引发异常的原因。 根据不同的对象类型，可以跟不同的catch块进行匹配，类型不匹配的catch块将跳过不执行。 15.3.5 异常规范和C++11C++98新增了异常规范（exception specification）的功能，但是在C++11中却被摒弃了。 新增关键字noexcept指出函数不会引发异。 15.3.6 栈解退C++中处理函数的调用和返回时，会让程序将调用函数的指令的地址（返回地址）放到栈中。当被调用的函数执行完毕后，程序将使用该地址来确定从哪里开始继续执行。另外，函数调用将参数放到栈中。在栈中，这些函数参数被视为自动变量。如果被调用的函数创建了新的自动变量，则这些变量也将被添加到栈中。如果被调用的函数调用了另一个函数，则后者的信息将被添加到栈中，以此类推。 现在假设函数由于出现异常（而不是由于返回）而终止，则程序也将释放栈中的内存，但不会在释放栈的第一个返回地址后停止，而是继续释放栈，直到找到一个位于try块中的返回地址。随后，控制权将转到块尾的异常处理程序，而不是函数调用后面的第一条语句。——这个过程被称为栈解退。 栈解退的意义在于：对于普通的函数返回来说，仅仅会调用该函数放在栈中的对象的析构函数，而throw语句则处理try块和throw之间整个函数调用序列放在栈中的对象。所以，如果没有栈解退这种特性，则引发异常后，对于中间函数调用放在栈中的自动类对象，其析构函数将不会被调用。 也就是说：程序进行栈解退以回到能够捕获异常的地方时，将释放栈中的自动存储型变量。如果变量是类对象，将为该对象调用析构函数。 15.3.7 其他异常特性虽然throw-catch机制类似于函数返回机制，但还是有些不同之处： 函数fun()中的返回语句将控制权返回到调用fun()的函数，但throw语句将控制权向上返回到第一个包含能够捕获相应异常的try-catch组合。 引发异常时编译器总是创建一个临时拷贝，即使异常规范和catch块中指定的是引用。 1234567891011121314151617181920class problem&#123;...&#125;;...void super() throw(problem)&#123; ... if( oh_no )&#123; problem oops; throw oops; &#125;&#125;...try&#123; super();&#125;catch(problem &amp;p)&#123; //这里p虽然声明为引用，但是p指向的是oops的副本而不是oops本身，这是件好事，因为函数`super()`执行完毕后，oops将不复存在。//既然如此，为何还要特意声明为引用？因为引用还有另一个重要特征：基类引用可以执行派生类对象。//这有一个很大的用法在于，假设有一个异常类层次结构，并要分别处理不同的异常类型，则使用基类引用将能够捕获任何异常对象；//而使用派生类对象只能捕获它所属类及从这个类派生而来的类的对象。引发的异常对象将被第一个与之匹配的catch块捕获。//这意味着catch块的排列顺序应该与派生顺序相反。也就是要将捕获派生类的catch放前面，捕获基类的catch放后面 //statements&#125; 15.3.8 exception类较新的C++编译器将异常合并到语言中，并在exception头文件（以前为exception.h或except.h定义了exception类，C++可以把它用作其他异常类的基类。 C++库定义了很多基于exceptin的异常类型 stdexcept异常类 &emsp;&emsp;头文件stdexcept定义了其他几个异常类，首先，该文件定义了logic_error和runtime_error类，它们都是以公有方式从exception派生而来的。这两个新类被用作两个派生类系列的基类。 &emsp;&emsp;异常类系列logic_error描述了典型的逻辑错误： domain_error; invalid_argument; length_error; out_of_bounds. &emsp;&emsp;runtime_error异常类系列描述了可能在运行期间发生但难以预计和防范的错误： range_error; overflow_error; underflow_error. &emsp;&emsp;一般，logic_error系列异常表明存在可以通过编程修复的问题，而runtime_error系列异常表明存在无法避免的问题。 &emsp;&emsp;如果上述库类不能满足需求，则应该从logic或runtime异常类中进行派生（而不是从exception），以确保派生出来的异常类可以归入同一个继承层次结构中。 bad_alloc异常和new &emsp;&emsp;对于使用new导致的内存分配问题，C++的最新处理方式是让new引发bad_alloc异常。头文件new包含bad_alloc类的声明，他是从exception类公有派生出来的。但在以前，当无法分配请求的内存量时，new返回一个空指针。 空指针和new &emsp;&emsp;老代码的逻辑是根据new返回的指针是否为空来判断是否失败的，为兼容这种情况，C++标准提供了一种在失败时返回空指针的new，如下所示： 1234567Big* pb;pb = new(std::nothrow) Big[10000];if(pb==0)&#123; cout&lt;&lt;"error"; exit(EXIT_FAILURE);1&#125; 15.3.9 异常、类和继承异常、类和继承以三种方式相互关联： 像C++标准库一样，从一个异常类派生出另一个 在类定义中嵌套异常类声明，从而将异常类组合到类中去 上面的嵌套声明通过继承传给子类 15.3.10 异常何时会迷失方向异常被引发后，在两种情况下会导致问题： 如果异常是在带异常规范的函数中引发的（C++11虽然摈弃了异常规范，但仍有人使用），则必须与规范列表中的某种异常匹配，否则称为意外异常（unexpected exception）。在默认情况下，程序会异常终止。 如果异常不是在函数中引发的（或者函数没有异常规范），则必须捕获该异常，如果没被捕获，则被称为未捕获异常（uncaught exception）。在默认情况下，程序会异常终止。 可以对以上默认情况进行修改： 未捕获异常：未捕获异常不会导致程序理科异常终止。相反，程序将首先调用函数terminate()。在默认情况下，terminate()调用abort()函数。可以使用set_terminate()函数指定terminate()应调用的函数来修改其默认行为：1234567void my_quit()&#123; cout&lt;&lt;"quit"; exit(5); // 退出状态值设为5&#125;...set_terminate(my_quit); 意外异常：通过给函数指定异常规范，可以让函数的用户知道要捕获哪些异常，如下所示：1234567double Argn(double , double ) throw (out_of_bounds);try&#123; x = Argn(a,b);&#125;catch(out_of_bounds &amp; ex)&#123; ...&#125; C++11摒弃它的原因之一是：异常规范机制处理起来比较麻烦。p640 在意外异常发生时，将调用unexpected()函数，这个函数将调用terminate()，后者在默认情况下调用abort()。 C++提供了一个set_unexpected ()函数，但限制更严格。p640 15.3.11 有关异常的注意事项从前面关于如何使用异常的讨论可知，应在设计程序时就加入异常处理功能，而不是以后再添加。 但是这样做会增加代码量，同时异常和动态内存分配并非总能协同工作。 一句话：异常处理很复杂 15.4 RTTIRTTI：运行阶段类型识别（RunTime Type Identification） 这是一项比较新的特性，一些旧的C++编译器不支持，还有一些编译器提供了开关RTTI的设值。 15.4.1 RTTI的用途RTTI旨在为程序在运行阶段确定对象的类型提供一种标准方式。 15.4.2 RTTI的工作原理C++有三个支持RTTI的元素： 如果可能的话，dynamic_cast运算符将使用一个只想基类的指针来生成一个只想派生类的指针；否则，该运算符返回0——空指针 typeid运算符返回一个指出对象的类型的值 type_info结构存储了有关特定类型的信息 RTTI只适用于包含虚函数的类： 只能将RTTI用于包含虚函数的类层次结构，原因在于只有对于这种类层次结构，才应该将派生类对象的地址赋给基类指针。 dynamic_cast运算符 &emsp;&emsp; 该运算符是最常用的RTTI组件， 它不能回答“指针指向的是哪类对象”这样的问题， 但能够回答“是否可以安全地将对象的地址赋给特定类型的指针”这样的问题。 &emsp;&emsp; 与知道“是哪类对象”相比，知道“类型转换是否安全”更通用，也更有用。主要是因为，通常项知道类型的原因在于：知道类型后，就可以知道调用特定的方法是否安全。 而要调用方法，类型并不一定要完全匹配，而可以是定义了方法的虚拟版本的基类类型。 &emsp;&emsp; 用法：ym1Superb* pm = dynamic_cast&lt;Superb *&gt;(pg); &emsp;&emsp; 通常，如果指向的对象(*pt)的类型为Type或从Type直接间接派生而来的类型，则下面的表达式将指针pt转换为Type类型的指针，并作为结果赋给ps，否则ps结果为0，即空指针：1ps = dynamic_cast&lt;Type *&gt;(pt) &emsp;&emsp; 也可以将dynamic_cast用于引用，其用法稍微有点不同：没有与空指针对应的引用值，因此无法使用特殊的引用值来指针失败。当请求不正确时，dynamic_cast将引发类型为bad_cast的异常，这种异常是从exception类派生而来的，在头文件typeinfo中定义，可以像下面这样使用：1234567#include &lt;typeinfo&gt;...try&#123; Superb &amp; rs = dynamic_cast&lt;Superb&amp;&gt;(rg);&#125;catch(bad_cast&amp;)&#123; ...&#125; typeid运算符和type_info类 &emsp;&emsp;typeid运算符使得能够确定两个对象是否为同种类型。它与sizeof有些相像，可以接受两种参数： 类名 结果为对象的表达式 &emsp;&emsp;typeid运算符返回一个对type_info对象的引用，其中，type_info是头文件typeinfo中定义的一个类。type_info类重载了==和!=运算符，可以进行类型间的比较。下面的代码判断pg指向的是否是一个Magnificent对象：1typeid(Magnificent) == typeid(* pg); //只会判断指针的类型，当基类指针指向子类时，得到的也是基类的类型 &emsp;&emsp;如果pg是一个空指针，程序将引发bad_typeid异常。该异常类型是从exception类派生而来的，是在头文件typeinfo中声明的。 误用RTTI的例子 如果在扩展的if else语句系列使用了typeid，则应高了是否应该是否虚函数和dynamic_cast。 15.5 类型转换运算符C语言中的类型转换运算符太过松散，因此，在C++中，提供了更严格的限制允许的类型转换，并添加4个类型转换运算符，使转换过程更规范： dynamic_cast const_cast static_cast reinterpret_cast const_cast 运算符用于执行只有一种用途的类型转换，即改变值为const或volatile，其语法与dynamic_cast运算符相同。1const_cast &lt;type-name&gt; (expression) 如果类型的其他方面也被修改，则上述类型转换将出错。也就是说，除了const或volatile特征可以不同外，type-name和expression的类型必须相同。 提供该运算符的原因是，有时候可能需要这样一个值，它在大多数时候是常量，而有时有事可以修改的。此时就可以声明为const，并在需要的时候使用const_cast。 static_cast运算符的语法与其他类型转换运算符相同：1static_cast &lt;type-name&gt; (expression) 仅当type-name可被隐式转换成expression所属的类型或expression可被隐式转换为type-name所属的类型时，上述转换才是合法的，否则将出错。 reinterpret_cast运算符用于天生危险的类型转换。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Focal Loss (ICCV, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FocalLoss-ICCV2017%2F</url>
    <content type="text"><![CDATA[文章: Focal Loss for Dense Object Detection作者: Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár机构: FAIR 核心亮点(1) 分析并指出了One Stage方法精度不高的原因: 极度不平衡的正负样本比例: anchor是一种类似sliding windows的选框方式, 这会使得正负样本的比例接近1000:1, 而且绝大部分负样本都是easy example. 梯度优化过程被easy example过度影响: 这些easy example的loss虽然不高, 但由于数量众多, 最终合起来会对loss有很大的贡献, 从而导致优化的时候过度关注这些easy example, 这样会收敛到一个不够好的结果. (2) 提出了解决正负样本比例和easy example 问题的Focal loss: FL(p_t) = -(1-p_t)^{\gamma} log(p_t)核心思想很简单, 就是在优化过程中逐渐减低那些easy example的权重, 这样会使得训练优化过程对更有意义的样本有更高的偏置. PS:注一: 为什么Focal Loss没有用在Two Stage方法上面? 这是因为以RCNN为代表的一系列Two Stage会在区域候选推荐阶段采用两个问题来降低正负样本比例和easy example问题带来的影响: 采用NMS算法将物体位置候选框降低到一到两千个，更重要的是，这一到两千个可能位置并不是随机选取的，它们移除了大量的负样本（背景框） 采用了biased-minibatch的采样策略, 比如，OHEM 或者保证正样本和负样本的比例为1：3进行训练（这其实相当于起到了 $\alpha$ 因子的作用 Focal Loss 的两个重要性质: 当一个样本被分错的时候, $p_t$ 是很小的, 比如当 $y=1$ 时, $p_t$ 要小于0.5才算是错分类, 此时 $p_t$ 就比较小, 反之亦然, 因此调制系数就会趋近于1, 也就是说相比原来的loss没有太大的改变, 而当 $pt$ 趋近于1的时候, 说明此时分类正确而且是易分类样本, 调制系数就会趋近于0, 也就是该样本对总的loss的贡献度很小. 当 $gamma=0$ 的时候, focal loss就是传统的交叉熵损失, 随着 $gamma$ 的增加, 调制系数的影响力也会增加 摘要迄今为止, 精度最高的目标检测器是基于 R-CNN 推广的两阶段方法, 其中分类器应用于一组稀疏的候选框(这里的稀疏是指经过启发式规则采样后, 入选的anchor只有一小部分). 相比之下, one-stage 模型是对可能的目标位置进行常规且密集的采样, 他拥有更快的速度, 但是精度却不如 two-stage 模型. 在本文中, 我们将探讨为什么会出现这种情况. 我们发现, 在 one-stage 检测器训练过程中, 前后背景的样本数量会出现极度的不均衡, 这是造成精度低的主要原因. 因此, 我们提出通过对标准交叉熵损失函数重新构造来解决类别不平衡问题, 构造的原则是让它降低那些易区分样本(well-classified examples)对于 loss 的贡献度). 我们新提出的 Focal Loss 会重点训练一组稀疏的 难样例(hard examples), 并且会防止检测器在训练过程中被大量的 简单负样例(easy negatives) 所淹没. 为了评价 focal loss 的有效性, 我们设计并训练了一个简单的 one-stage 检测器, 称之为 RetinaNet. 我们的结果显示, 当使用 Focal Loss 进行训练时, RetinaNet 有能力同时保持精度和速度上的领先. 介绍目前的 sota 目标检测模型都是基于 two-stage, proposal-driven 的. 类似于 R-CNN, 第一阶段会 产生一组稀疏的候选位置, 第二阶段 会对每个候选位置进行分类. 目前, two-stage 模型在精确度上遥遥领先. 暂且不考虑 two-stage 模型的成功性, 一个很自然的问题就是: 简单的 one-stage 模型能否达到类似的精度? One-stage 模型通常会对物体的位置, 尺寸和宽高比进行密集的采样. 最近的 one-stage 模型, 如 YOLO 和 SSD, 显示出了很有希望的结果, 与 sota 的 two-stage 模型相比, 能产生精度较高且更快的模型(不如 two-stage 高). 本文更进一步的推进了这个概念: 我们首次提出了可以在精度上超过 two-stage 模型的 one-stage 模型. 为了实现这一目标, 我们认为训练过程中的类别不平衡问题是阻碍 one-stage 模型达到更高精度的主要障碍, 同时我们提出了一种新的损失函数来消除这一障碍. 在 R-CNN 系列模型中, 类别不均衡问题是通过 two-stage 结构和启发式的采样算法来解决的. 在第一阶段, 候选框生成算法(SS, EB, RPN)会大量的降低候选框的数量, 将大量的背景样本剔除. 在第二阶段, 会使用启发式的算法, 例如固定正负样本比例为 1:3, 或者使用难样例挖掘(OHEM), 以此来保证正负样本的平衡性. 相比之下, one-stage 检测器必须处理一组更大的候选框位置, 这些候选框是在图片上均匀采样生成的. 在实际中, 通常会枚举超过 100k 的位置, 这些位置密集的覆盖了物体可能的位置, 尺寸和宽高比. 虽然可以采用类似的启发式的抽样方法, 但是效率很低, 因为训练过程中的易分类负样本仍然占据主导地位. 这种低效率是目标检测中的一个经典问题, 通常利用 bootstrapping 或者 hard example mining 来解决. 在本文中, 我们提出一种新的损失函数来作为一个更有效的方法解决样本不均衡问题. 如图1所示, 该损失函数一个可以动态缩放的交叉熵损失, 当对正确类别的置信度增加时($p^t$ 趋近于1), 比例因子($1-p^t$)将衰减为零. 从直觉上来说, 该比例因子能够自动降低训练过程中易分类样本的对损失函数的贡献度, 并能够快速的将模型集中在难样例上面. 实验显示我们提出的 Focal Loss 可以训练出一个具有更高精确度的 one-stage 模型. 最后, 我们还注意到 Focal Loss 的确切形式并不是最重要的, 我们还展示了其他实例也可以获得类似的结果. 为了证明 focal loss 的有效性, 我们设计并提出了一个 one-stage 的检测器称为 RetinaNet, 以其对输入图像中的目标位置的密集采样而命名. 该网络使用了高效的内部特征金字塔结构和 anchor boxes, 借鉴了各种最新的目标检测观点. RetinaNet 不仅高效, 而且准确. 我们的最优模型使用了 ResNet-101-FPN 作为 backbone, 达到了 COCO 39.1 mAP, 5fps, 对比结果如图2所示 Related WorkClassic Object DetectorsSliding-window, HOG, DPMs,主要是基于sliding-window paradigm的一类方法：HOG， DPMs等等。虽然滑动窗口类的方法在目标检测领域处于一线地位，但是随着deep learning的出现和研究，滑动窗口方法渐渐失去光芒。 Two-stage Detectorstwo-stage方法的先驱是Selective Search work，它会首先提取出一个稀疏的候选框集合（稀疏是指只有很少一部分包含物体），然后对这些候选框进行分类，看是否包含物体，或包含哪种物体。之后，RCNN的诞生标志着深度学习技术成功引入目标检测领域，利用cnn网络对特征的高度抽象和提取，rcnn在物体检测的准确率上大幅度提高，后期的RCNN系列又不断的提出新的方法来提升准确率和速度，到Faster RCNN时，提出了RPN网络，将候选框选取阶段和分类阶段都放在了统一个网络，使之可以进行端到端训练。后续还有更多的关于这一系列的工作继续被人们研究着。 One-stage DetectorsOverFeat算是首个现代的基于深度学习的one-stage检测方法，而最近的SSD和YOLO更是激起了人名对one-stage方法的研究热情，但是one-stage方法最令人诟病的地方就在于它们较低的准确率。为此，本文的工作就是想要知道是否one-stage检测算法可以在精确度上匹敌two-stage检测算法，同时还要保持一定的检测速度。于是，作者提出了Focal Loss，一种新的损失函数，利用这个损失函数，可以在保持现在模型大框架不变的基础上，达到最好的检测水平！ Class Imbalance不管是传统的one-stage检测方法如boosted detectors， DMPs，还是最近的方法SSD，都会在训练阶段面临 $10^4\sim 10^5$ 个候选区域，这其中会包含大量的背景区域，也就是负样本，这种不平衡会造成两个问题： 在训练时，在大多数位置都是容易分类的负样本，这样只会贡献更多无用的信号 大量的易分类负样本会导致模型在一定程度上的退化对于此问题，常用的解决方案是在训练阶段设计更复杂的样本抽取策略，但是这样速度就会受影响。而本文提出的Focal Loss，不仅解决了样本不均的问题，而且不需要增加额外的抽取策略，避免了易分类负样本淹没损失梯度. Robust Estimation 有很多工作乐于设计健壮的损失函数. 相对于有的工作关注那些离异值的贡献. Focal Loss 实际上关注的是降低 inliers(easy examples) 的权重系数. Focal Loss我们从交叉熵损失(CE)出发, 引入了 Focal Loss 进行二元分类(将 Focal Loss 扩展到多类情况是简单易行的, 我们在本文中主要关注二分类损失) CE(p,y) = \begin{cases} -log(p) & \text {if y=1} \\ -log(1-p) & \text{otherwise}\end{cases} \tag 1上式中, $y\in \{\pm 1\}$ 代表真实物体的类别, $p \in [0, 1]$ 是模型预测物体属于类别 $y=1$ 的概率. 为了便于表示，我们定义 $p_t$ 为 p_t = \begin{cases} p & \text{if y = 1} \\ 1-p & \text{otherwise} \end{cases} \tag 2于是对上面的公式进行改写: $CE(p,y) = CE(p_t) = -log(p_t)$. CE 损失可以看做是图1中的蓝色线条. 从图中可以看出 CE 损失的一个重要性质, 那就是即使是易分类样本($p_t \gg 0.5$), 也会产生较大的损失. 当对大量的易分类样本的损失求和时, 这些损失值就可能会淹没其他一些样本较少的类别.当二分类问题中的样本分布不均时，数量多的负样本的损失值对最终函数的影响会淹没数量少的样本产生的影响。多分类问题也是如此。 Balanced Cross Entropy一个常用的解决办法就是引入一个权重因子 $\alpha \in [0,1]$，然后分别令 $\alpha$ 和 $1 - \alpha$作为两个类别的权重，$\alpha$ 的取值可以是根据类别出现的频率决定，也可以作为超参数，利用交叉验证(cross validation)来选取较好的值。为了符号定义方便, 我们用类似于 $p_t$ 的方法来定义 $\alpha_t$, 我们给出 $\alpha$ CE 损失如下所示: CE(p_t) = -\alpha log(p_t) \tag 3这种损失是 CE 的一个简单的扩展, 我们将其作为 Focal Loss 的 baseline. Focal Loss Definition本文的实验结果表明，类别分布不均衡会对交叉熵损失函数带来很大的影响。那些很容易被分类的负样本（背景等）贡献了大部分损失, 并且主导了 BP 中的梯度。尽管 baseline 方法的 $\alpha$ 因子可以平衡正负样本之间的比例，但它仍然不能把握好简单样本和困难样本的比例（应该困难样本多一些，简单样本少一些，这样有利于模型的健壮性）。于是，作者就提出了 Focal Loss 来降低易分类负样本的权重, 从而更多的关注难负样例.具体来说, 我们向交叉熵损失中引入了一个 “调制因子(modulating factor)” $(1-p_t)^\gamma$ ，其中 $\gamma \geq 0$ ，我们定义 focal loss 损失函数形式如下: FL(p_t) = -(1-p_t)^{\gamma}log(p_t) \tag 4对于不同的聚焦参数 $\gamma \in [0, 5]$ 值下的 Focal Loss 的作用如图1所示. 我们注意到, focal loss 具有两个性质: 当一个样本的 $p_t$ 很小 时(说明 此样本被错分类, 并且错的很离谱, 如 $y=1$ 而 $p=0$, 或者 $y=0$ 而 $p=1$), 调制因子的值趋近于1, 此时损失函数不会受到影响; 当一个样本的 $p_t$ 很大 时(说明 此样本被正确分类, 并且置信度很高, 如 $y=1$ 且 $p=1$, 或者 $y=0$ 且 $p=0$), 调制因子的值趋近于0, 此时损失函数的权重会被降低. 聚焦参数 $\gamma$ 的值会平滑的调整易分类样本的权重降低比例. 当 $\gamma = 0$ 的时候, Focal Loss 就和普通的交叉熵相同, 当 $\gamma$ 升高的时候, 调制因子影响力就会增强. (在实验中, 我们发现 $\gamma=2$ 是一个不错的选择). 直观上来讲，这个 “调制因子” 降低了易分类样本对于损失的贡献度, 并且扩展了样本接受较低损失的范围。例如, 当 $\gamma = 2$ 时, 一个 $p_t = 0.9$ 的样本具有的损失比 CE 损失低 100 倍, 当 $p_t = 0.968$ 左右时, 比 CE 损失低 1000 倍. 这反过来又增加了纠正错误分类示例的重要性.同时，还应注意到，Focal Loss的形式不是唯一固定的，在实际使用中, 我们使用了具有 $\alpha$ 因子的 Focal Loss 变体: FL(p_t) = -\alpha_t(1-p_t)^\gamma log(p_t) \tag 5后文的大部分实验都使用的是上面这个形式的Focal Loss, 因为它比不使用 $\alpha$ 因子的损失表现效果更好一点. 最后, 我们注意到损失层的实现将计算 $p$ 的 sigmoid 操作与损失计算相结合, 使得数值更加稳定. Class Imbalance and Model Initialization二值分类模型在初始的时候，对两个类别的预测概率是均等的，在这种初始化条件下，如果某一个类别出现的次数过多，就会对损失函数产生较大的影响。为了解决这个问题，作者特意提出了“先入为主”的概念，也就是使得模型在开始的时候，对稀有类别（如前景类别）的预测概率的初始值设置的低一些，如0.01 。 经过实验表明，这样的方法可以提升模型训练的稳定性。 Class Imbalance and Two-stage DetectorsTwo-stage Detector 并没有使用类似 $\alpha$ 因此的方法来解决样本不均的问题。相反的，它们通过两个机制来降低这个问题带来的影响：（1）two-stage模式和（2）biased minibatch取样。首先，two-stage模式会在第一阶段就将近乎无限物体位置可能性降低到一到两千个，更重要的是，这一到两千个可能位置并不是随机选取的，它们移除了大量的易分类负样本（背景框）。第二，这些方法还设计了biased minibatch的取样策略，比如，保证正样本和负样本的比例为1：3进行训练（这其实相当于起到了 $\alpha$ 因子的作用。 RetinaNet DetectorRetinaNet是一个单一的、统一的网络，它由一个backbone网络和两个task-specific子网络组成。backbone网络是现成的，主要负责计算卷积特征图谱。第一个子网络负责物体分类任务，第二个子网络负责bounding box回归任务，它们都是在backbone网络输出的卷积图谱上进行计算的。 Feature Pyramid Network Backbone： 采用了FPN作为backbone网络。 Anchors: 和FPN一样，对P3到P7使用了不同大小的anchors Classification Subnet： 该子网络是一个较小的FCN，连接在FPN的每一层。 值得注意的一点是，该子网络并不与Box Regression Subnet共享参数，二者是互相独立的。 Box Regresion Subnet： 与分类子网络并行，该子网络也是一个FCN网络，连接在FPN的每一层上。目标是让anchor通过位移回归到gt box附近。 Inference and TrainingInference： RetinaNet是有基于FPN和backbone和两个基于FCN的子网络组成的一个统一的单一网络，因此，在inference阶段，只需要简单的通过前向传播经过整个网络即可。为了提高速度，本文在每个FPN层级上，只会处理最多1000个box prediction。 Focal Loss： 使用了上文提到的Focal Loss。取 $\gamma=2$ 。在训练阶段，本文强调将focal loss应用到所有100k个anchors上，主要目的是为了与RPN和SSD等模型作对比。 从实验结果上看，当 $\gamma$ 的值取得较大时，$\alpha$ 的值就应该取消一些（for$\gamma=2$ , $\alpha = 0.25$ works best)。 Initialization： 本文分别实现了ResNet-50-FPN和ResNet-101-FPN。 对其中初始值可参见原文。 Optimization： 使用了SGD优化方法，在8个GPU上训练，每个minibatch有16张图片（一个GPU包含2张图片）。 损失函数为focal loss和标准smooth L1损失函数之和。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLOv3]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-YOLOv3-Arxiv2018%2F</url>
    <content type="text"><![CDATA[摘要作者对YOLOv2进行了一些改进，使之在保持实时检测的同时，准确率又有所提升了。 介绍作者说他这一年（18年）基本没干啥，就是打打电话，玩玩推特，偶尔还帮别人干点活。。 然后因为只对YOLO做了一些改进，但是并没什么特别的地方，因此就写了这一篇技术报告,而没有选择发表成论文形式。 The Deal作者说了，他们大部分的工作都是从别人那里吸取好的点子，同时训练了一个新的分类器网络（比别人的好，恩。。） Bounding Box Prediction和YOLO9000一样，在预测bounding box时使用了dimension clusters和anchor boxes。 YOLOv3在预测每个bouding box的objectness score时，使用的是logistic regression。 与faster rcnn不同的是，我们的系统只会给每个gt object指派一个bounding box。如果没有指派的话，就说明没有对象的box坐标，只有objectness。 Class Prediction每个box使用了多标签分类，我们不选择softmax是因为发现它很难取得好的效果，因此，改用一个单独的logistic classifiers。在训练阶段，使用binary cross-entropy loss来进行类别预测。 Predictions Across ScalesYOLOv3在三种不同的scales下进行预测。 Feature Extractor作者使用了一个新的网络模型来提取特征，主要是在Darknet-19中引入了residual network stuff，最终模型的卷积层数达到53层，也就是Darknet-53。 Training仍然使用不带hard negative mining的图片训练。同时使用了multi-scale training，data augmentation，batch normalization，以及其他的一些标准程序。 How We Do根据不同的评价标准，YOLO的性能差异较大，总的来说主要是因为YOLO虽然能标出物体的大致位置，但是画出的框并不是“完美”，使得在IOU要求高的评价标准上，YOLO的得分很低。 另外， 之前的YOLO在检测小物体上往往有很多瓶颈，而目前的YOLO已经在慢慢克服这方面的缺陷 Things We Tried That Didn’t WorkAnchor box $x,y$ offset predictions Linear $x,y$ predictions instread of logistic Focal loss Dual IOU thresholds and truth assignment What This All means最后，作者说了为什么要选择其他的评价标准。 对于人类来说，很难直接区分出IOU0.3和IOU0.5之间的差别，那么我们要求计算机这样做是否合理呢（我认为是合理的。。。） 最后作者说出了对计算机视觉未来发展的一些“愿景”。（作者反对隐私泄漏和军事用途）]]></content>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位操作(Bit Manipulation)算法总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E4%BD%8D%E6%93%8D%E4%BD%9C%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[https://leetcode.com/problems/sum-of-two-integers/discuss/84278/A-summary%3A-how-to-use-bit-manipulation-to-solve-problems-easily-and-efficiently]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[YOLO9000]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-YOLOv2-CVPR2017%2F</url>
    <content type="text"><![CDATA[核心亮点https://zhuanlan.zhihu.com/p/35325884 关键技术论文细节背景介绍https://zhuanlan.zhihu.com/p/40659490 摘要本文提出了一个新的，实时目标检测模型，YOLO9000。首先，作者使用了不同的提升技巧来优化YOLO模型，同时，利用多尺度的训练方法，YOLO可以方便的在speed和accuracy之间进行tradeoff。在67FPS时，YOLOv2可以在VOC2007上活得76.8的mAP，在40FPS时，YOLOv2可以或者78.6mAP，超过了Faster RCNN和SSD的性能表现。尽管只有200个类里面的44个类的数据，YOLO9000仍然可以在ImageNet上获得19.7的mAP，对于不在COCO里面的156个类，YOLO可以获得16.0的mAP。9000的含义是说YOLO-v2可以运行在超过9000个不同的物体类别，同时保持实时检测。 介绍目前关于分类任务的数据集数量远远超过检测任务的数据集大小，而短期内，检测任务的数据集数量无法快速增长。对此，本文提出了一个新的方法来利用现有的分类任务的数据集，进而扩充当前目标检测系统的检测范围。 同时，本文还提出了一个联合训练方法，使得我们可以同时在检测数据集和分类数据集上训练检测器。（检测数据集提升定位能力，分类数据集提升类别容量和系统健壮性） 本文分两步：首先将YOLO升级到YOLOv2,然后利用本文提出的数据集联合方法来进行联合训练。 BetterYOLO的主要缺点在于定位错误和较低的召回率。 本文在优化这些缺点时，并不是选择扩大网络的规模，而是将整个网络简化，使表征信息更容易学习。根据之前的工作，我们采用了很多方法来提升YOLO的性能。 Batch Normalization：在所有的卷积层之上加上BN，可以提升2%的mAP，并且可以去掉dropout层而不产生过拟合。 高分辨率分类器 High Resolution Classifier：之前的YOLO是利用ImageNet的224大小的图像预训练的，然后在检测时，会将224的图像放大到448尺寸。在YOLOv2,首先在448的ImageNet图像上进行finetune 10 epochs。这给了一定时间让网络适应更大的尺寸大小，然后再在该网络进行物体检测的finetune。 这可以提升4%mAP。 Convolutional With Anchor Boxes：YOLO使用叠在卷积层之上的全连接层的特征提取器来直接预测bounding box的坐标。 相比于YOLO，Faster RCNN使用了精心挑选的方式来获得预测的boundign box，它在anchor box的基础上进行预测，并且其预测层是卷积层。为此，本文移除了YOLO的全连接层，改用anchor box来预测bouding box。 首先，移除了一个pool层，从而使网络卷积层的输出有更高的分辨率。另外，还将网络的输入图像的分辨率降到416,这么做的原因是作者希望在特征图谱上得到奇数个locations，这样一来，就由一个center cell。YOLO的结构可以使416的图像降到13×13的大小。 在使用anchor box时，我们将类别预测问题从位置标定问题中分离出来，然后为每个anchor box预测类别和是否有物体。和YOLO一样，预测是否有物体时会预测gt和proposed box的IOU，类别预测时会计算给定有物体的条件下给出属于每个class的条件概率。 原来的YOLO会对每张图片产生98个box，而使用anchor box后，每张图片会产生上千个box。 不用anchor box时，本文的模型可以达到69.5的mAP和81%的recall。而是用了anchor box后，可以到大69.2的mAP和88%的recall。虽然mAP变低了，但是recall的提升说明本模型还有很大的提升空间。 Dimension Cluster：在使用anchor box时，主要遇到了两个问题。 第一：anchor box的维度是手动标定的。 anchor值的选择会对最终结果有一定影响。为了解决这个问题，我们不采用手动标定的方法，而是对训练集的boudning boxes用k-means clustering来自动找到较好的anchor值。如果使用基于欧式距离的标准k-means，那么更大的box就会产生更多的error。为了不让box的大小对最终的anchor值有影响，我们使用下面的式子作为距离度量： d(\text{box},\text{centroid}) = 1 - IOU(\text{box}, \text{centroid})最终在模型复杂度和高召回率的权衡下，本文选择 $k=5$ 。 直接位置预测 Direct location prediction使用anchor box的第二问题就是：模型不稳定，尤其是在早起迭代阶段。稳定性差的主要来源是box的坐标 $(x,y)$ ，在RPN网络中，网络会预测 $t_x$ 和 $t_y$ ，于是 $(x,y)$ 的值可以通过下面的公式计算得到： x = (t_x*w_a) - x_ay = (t_y*h_a) - y_a本文不使用上面的方法，而是使用YOLO中的方法，预测相对于grid cell位置的相对坐标，这将gt限制在了0到1之间。这样的参数设置使得参数更容易学习，网络更加稳定。 Fine-Grained Features精细化的13×13的特征图谱对于标定大物体来说已经足够了，同时，由于特征更加细粒度，使得它在标定更小的物体时有一定提升。 Faster RCNN和SSD都在不同的特征图谱上执行，因此，它们得到的是一个区间的图像分辨率大小。 本文采用一个更简单的测率，直接添加一个passthrough层，使得从更早的26×26的层中得到特征。 这个passthrough层将高分辨率的特征和低分辨率的特征连接起来，通过将相邻特征堆叠到不同的channes？ 这将26×26×512的特征图谱变成了一个13×13×2048的特征图谱。 Multi-Scale Training为了使模型更加健壮，使用了不同尺度的图片来训练模型。在训练时，每经过一段迭代次数后，都会改变接受输入图片的size。由于本文的模型输出的尺寸会变成原来1/32,因此选择以下尺寸：{320,352,…,608}。 这样一来，一个网络可以在不同的分辨率下进行目标检测，可以取得更好的效果。 Faster大多数目标检测网络使用了VGG16作为基础网络，但是VGG16需要30.69billion浮点运算，十分复杂。 而本文使用基于GoogleNet的自定义网络，只需要8.52billion浮点运算。（但是精确性低于VGGnet） Darknet最终网络起名为Darknet-19。 具有19个卷积层和5个最大池化层。 Training for classification将网络在标准Imagenet 1000上进行训练。 SDG的初始学习率为0.1, 递减指数为0.4,权重递减为0.0005,momentum为0.9。 在训练时，使用了标准的数据增广方法：random crops，ratations，hue，saturation，exposure shifts等。 Training for detection将上面训练好的网络的最后一层卷积层移除，然后加上三个具有1024个filter的3×3卷积层，并在其中跟一个1×1的卷积层，使输出是我们需要的结果。 比如，对于VOC，需要有5个box，每个box有5个coordinates和20个class，所以需要125个filetes。 同时使用了passthrough层，以便模型可以使用fine grain features。 Stronger本文提出了一种可以联合训练分类数据和检测数据的机制。本文的方法使用检测数据的图像标签来学习物体位置信息，使用分类数据的标签来扩充可以检测的物体的类别。 在训练阶段，我们了检测数据和分类数据混合。当网络模型看到一个带有检测标签的图片时，就会对YOLOv2的整个损失函数进行BP求导，当看到分类图片时，则只会对分类部分的损失函数进行BP求导。 上面的方法具有一些难点：]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的内存分配和动态内存]]></title>
    <url>%2Fz_post%2FCpp-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[描述 C++ 的内存分配方式以及它们之间的区别?在 C++ 中, 内存区分为5个区, 分别是: 堆, 栈, 自由存储区, 全局/静态存储区, 常量存储区. 栈: 函数内的局部变量的存储单元都会在栈上创建, 函数执行结束时这些存储单元会被自动释放 堆: 也称为动态内存. 程序在运行的时候用malloc申请任意大小的内存, 程序员自己负责在何时使用和释放这些内存. 动态内存的生存期由程序员自己决定, 使用非常灵活, 但相关的内存泄漏问题也尝尝发生. 自由存储区域: 程序在运行时候利用new申请的内存空间. 全局/静态存储区域: 存储全局变量和静态变量, 处于该内存的变量在程序的整个运行期间都一直存在. 常量存储区: 存储常量字符串, 程序结束后由系统释放. 自由存储区和堆的区别从技术上来说, 堆(heap)是 C 语言和操作系统的术语, 它是操作系统所维护的一块特殊内存, 提供了动态分配的功能, 当运行程序调用malloc()时就会从堆中分配内存, 之后会调用free()将内存归还. 而自由存储区是 C++ 中通过new和delete动态分配和释放对象的 抽象概念, 通过new来申请的内存区域成为自由存储区. 实际上, 基本所有的 C++ 编译器都默认使用堆来实现自由存储区, 也就是说, 缺省的 全局运算符 new和delete大多会通过malloc和free来实现, 这时候我们说new申请的内存在自由存储区上或者在堆中都是正确的. 但是程序员可以通过重载new和delete运算符, 来改用其他内存实现自由存储区, 这时候自由存储区就区别于堆了. 我们所需要记住的是: 堆是操作系统维护的一块特殊内存, 而自由存储区是 C++ 中通过new和delete动态分配和释放对象的抽象概念. 二者并不完全等价. new 和 malloc 的区别(1). 申请的内存位置new操作符从 自由存储区 上为对象动态分配内存空间, 而malloc函数从 堆 上动态分配内存. 自由存储区是 C++ 基于new操作符的一个抽象概念, 凡是通过new操作符进行内存申请, 那么该内存就是自由存储区. 而堆是操作系统中的术语, 是操作系统所维护的一块特殊内存, 用于程序的内存动态分配, C 语言使用malloc从堆上分配内存, 使用free释放已经分配的对应内存.自由存储区是否在堆上(问题等价于new申请的内存是否在堆上), 这取决于new运算符的实现细节. 自由存储区不仅可以是堆, 还可以是静态存储区, 这主要看new实现时在哪里为对象分配内存. (2). 返回类型安全性new 运算符内存分配成功时, 返回的是对象类型的指针, 类型严格与对象匹配, 无序进行类型转换, 故new是类型安全的运算符. 而malloc内存分配成功时返回的是void *, 需要通过强制类型转换将void *指针转换成需要的类型. (3). 内存分配失败时的返回值new内存分配失败时, 会抛出bad_alloc异常;malloc分配内存失败时会返回NULL.因此, 二者在判断是否分配成功时的代码逻辑不太, 如下所示:1234567891011121314// mallocint* a = (int*)malloc(sizeof(int));if (a == NULL) &#123; ...&#125; else &#123; ...&#125;// newtry &#123; int* a = new int();&#125; catch (bad_alloc) &#123; ...&#125; (4). 是否调用构造函数/析构函数new和delete会调用对象的构造函数/析构函数以完成对象的构造/析构. 而malloc则不会. (5). 对数组的处理C++ 提供了new[]和delete[]来专门处理数组类型. 但是对于malloc和free来说, 它并不关心分配的内存是否为数组, 需要程序员自行决定参数的合理设置. delete 会调用对象的析构函数, 和new对应 free 只会释放内存, 和malloc. malloc/free是C++/C 语言的标准库函数, new/deletec是C++语言的运算符, 因此, 我们可以通过重载new和delete运算符, 来完成自定义的功能. 它们都可用于申请动态内存和释放内存, 对于非内部数据类型的对象而言, 光用 malloc/free 无法满足动态对象的要求, 对象在创建的同时要自动执行构造函数, 在消亡之时要自动执行析构函数, 由于malloc/free是库函数而不是运算符, 因此不在编译器控制权限之内, 不能够把执行构造函数和析构函数的任务强加于malloc/free. 因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new, 以及一个能完成清理与释放内存工作的运算符delete. new 运算符, operator new, new 表达式运算符new和new[]实际上是分别调用了如下函数:12void * operator new(std::size_t);void * operator new[](std::size_t); 当我们在使用一个new的时候, 它就变成了一个表达式的形式, 如下所示:1Test* test = new Test; new表达式的行为主要有两步: 执行operator new()函数, 在堆空间中搜索合适的内存并进行分配 调用相应的构造函数构造对象, 初始化这块内存空间. delete 和 delete []的区别delete只会调用一次析构函数, 而delete[]会调用数组内每一个成员的析构函数. 在More Effective C++中有更为详细的解释: 当delete操作符用于数组时, 它为每个数组元素调用析构函数, 然后调用operator delete来释放内存 在对 内建数据类型 使用时, delete和delete[]是等价的, 因此delete[]会调用数组元素的析构函数, 但是内部数据类型没有析构函数, 所以可以直接使用. 如何限制一个类对象只在栈(堆)上分配空间?在C++中，类的对象建立分为两种，一种是静态建立，如A a；另一种是动态建立，如A* ptr=new A；这两种方式是有区别的。 静态建立类对象：是由编译器为对象在栈空间中分配内存，是通过直接移动栈顶指针，挪出适当的空间，然后在这片内存空间上调用构造函数形成一个栈对象。使用这种方法，直接调用类的构造函数。 动态建立类对象：是使用new运算符将对象建立在堆空间中。这个过程分为两步，第一步是执行operator new()函数，在堆空间中搜索合适的内存并进行分配；第二步是调用构造函数构造对象，初始化这片内存空间。这种方法，间接调用类的构造函数。 (1). 只在对上分配类对象就是不能静态建立类对象, 即不能直接调用类的构造函数.首先要知道, 当对象建立在栈上面时, 是由编译器分配内存空间的, 当对象使用完以后, 编译器会调用析构函数来释放对象所占的空间. 实际上, 编译器在为类对象分配栈空间时, 会检查类的析构函数的访问性(其他非静态函数也会检查), 如果类的析构函数是私有的, 则编程器不会在栈空间上为类对象分配内存. 因此, 我们只需要将析构函数设为私有, 类对象就无法建立在栈上了, 如下所示:1234567class A&#123;public: A()&#123;&#125; void destroy()&#123;delete this;&#125;private: ~A()&#123;&#125;&#125; 注意, 由于new表达式会在分配内存以后调用构造函数, 因此构造函数必须是公有的, 同时, 由于delete此时无法访问私有的析构函数, 因此必须提供一个destroy函数, 来进行内存空间的释放. 存在问题: 无法解决继承问题: 为了实现多态, 析构函数通常要设为virtual, 因此析构函数不能设为private, 此时我们可以使用protected, 这样, 子类可以访问析构函数, 而外部无法访问. new和destroy的对应关系容易引起误解, 解决办法是将构造函数也设置为protected, 然后提供一个create函数和destroy对应. (2). 只在栈上分配类对象只有使用new运算符，对象才会建立在堆上，因此，只要禁用new运算符就可以实现类对象只能建立在栈上。虽然你不能影响new operator的能力（因为那是C++语言内建的），但是你可以利用一个事实：new operator 总是先调用 operator new，而后者我们是可以自行声明重写的。 因此，将operator new()设为私有即可禁止对象被new在堆上。 代码如下：123456789class A &#123; private: void* operator new(size_t t)&#123;&#125; // 注意函数的第一个参数和返回值都是固定的 void operator delete(void* ptr)&#123;&#125; // 重载了new就需要重载delete public: A()&#123;&#125; ~A()&#123;&#125; &#125;;]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLO v1]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-YOLOv1-CVPR2016%2F</url>
    <content type="text"><![CDATA[文章: You Only Look Once: Unified, Real-Time Object Detection 作者: oseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi 核心亮点(1) 将检测问题看做是回归问题对于给定的输入图像, YOLO会使用一个单一的网络 同时 给出bounding box的预测结果和对应的类别概率. (2) 没有Region Proposal的过程YOLO采用 $S\times S$ 的网格划分来确定候选框, 如果某个物体的中心落在了某个cell里, 那么这个cell就负责该物体的检测. PS:注一: YOLO中采用 $S\times S$ 的网格划分来确定候选框, 这实际上是一种很粗糙的选框方式, 同时也导致了YOLO在面对小目标物以及群落目标物时, 性能较差.(因为YOLOv1的同一个cell无法预测多个目标) 背景介绍YOLO将目标检测问题看作是一个回归问题，进而从整张图像中直接得到bounding boxes和对应的class probabilities。 之前的工作都是将检测任务看成是一个分类问题，如RCNN，通过区域提取，分类，区域修正，去重等等一系列工作得到检测结果，这样的模型十分复杂而且很难优化，因为区域提取和分类任务必须单独训练，麻烦且难以调试。 本文将目标检测问题看成是一个回归问题，直接从图片像素中得到bounding box坐标和class probabilities。 YOLO具有三大优点： Fast。 由于不用按照复杂的pipeline进行运作，YOLO只需要一个卷积网络就可以同时预测出多个物体，因此十分快 YOLO在进行推理时，可以看到整幅图片，因此，可以隐式地对物体的周围像素进行分析。这使得YOLO不容易在背景中错误识别。反观Fast RCNN，经常会将背景中的非物体检测出来。 YOLO的泛化性更好，可以学到更一般的特征。在自然图像上训练后，YOLO在艺术图像上可以取得相比于RCNN更好的检测效果。 关键技术YOLO没有提取候选区域的过程, 与之相对的, YOLO采用网格划分的方式来确定物体的候选区域框, 具体来说, YOLO会将图像按照 $S\times S$ 的大小划分成多个cell, 之后, 如果哪个物体的中心落在了某个cell里面, 那么这个cell就负责检测这个物体, 如下图中, 狗的中心落在了红色cell内, 则这个cell负责预测狗. “物体落在哪个cell, 哪个cell就负责预测这个物体” 分为训练和测试两个阶段: 训练阶段. 在训练阶段, 如果物体中心落在这个cell, 那么就给这个cell打上这个物体的label, 让这个cell和该物体关联起来 测试阶段. cell会根据已经训练好的参数来决定自己负责预测哪个物体. 网络的整体架构如下图所示: 从图中可以看出, YOLO网络的输出网格是 7×7 大小的, 另外, 输出的channel数目30, 在每一个cell内, 前20个元素是每个类别的概率值, 然后2个元素对应2个边界框的置信度, 最后8个元素时2个边界框的 $(x,y,w,h)$.(每个cell会预测两个框, 最后选择IOU较大的来复杂物体的预测) 根据网络的输出, 我们可以知道, YOLO的预测目标主要有三个: 类别预测, Confidence预测, Bounding box预测. 在训练阶段，该模型要优化下面的联合目标损失函数(第一行是bounding box预测, 接下来是confidence预测, 最后是类别预测) \lambda_{coord} \sum_{i=0}^{S^2} \sum_{j=0}^B I_{ij}^{obj}[(x_i-\hat x_x)^2 + (y_i - \hat y_i)^2] \ + \lambda_{coord}\sum_{i=0}^{S^2} \sum_{j=0}^B I_{ij}^{obj} [(\sqrt w_i - \sqrt{\hat w_i})^2 +(\sqrt h_i - \sqrt{\hat h_i})^2]+ \sum_{i=0}^{S^2}\sum_{j=0}^B I_{ij}^{obj} (C_i - \hat C_i)^2 + \lambda_{noobj}\sum_{i=0}^{S^2}\sum_{j=0}^{B} I_{ij}^{noobj}(C_i-\hat C_i)^2+ \sum_{i=0}^{S^2} I_i^{obj} \sum_{c\in \text{classes}} (p_i(c) - \hat p_i(c))^2需要注意的是, 网络并不会总是计算所有的loss项, 具体地说: 对于有物体中心落入的cell, 需要计算分类loss, 两个confidenceloss, 但只计算IOU较大的bounding box loss 对于没有物体中心落入的cell, 只需要计算confidence loss. 另外, 我们发现每一项的计算(即使是分类)都是 L2 loss, 从另一角度体现出YOLO把分类问题转化为了回归问题. 一体化检测YOLO使用整幅图像的特征图谱进行预测，同时预测所有物体的所有bounding box。这样的设计思想，可以使得YOLO进行端到端的训练，并且能够进行实时检测。 系统将整张图片划分成 $S \times S$ 大小的网格。 如果某个物体落入了网格中的某一格，那么这个格子就负责检测该物体。 每个格子会预测B个bounding boxes和B个confidence scores。这些confidence scores反映了模型对这个box里面是否有物体，并且有多大的把握确定。 将confidence定义为 $Pr(Object)\times IOU_{pred}^{truth}$ 。 $IOU_{pred}^{truth}$ 代表真实框和预测框之间的IOU值。 每一个bounding box包含5个预测值：x，y，w，h，和confidence。 每一个grid cell预测C个conditional class probabilities，记为 $Pr(Class_i|Object)$ 。 C与B的个数之间没有直接关系。 在测试阶段，我们将conditional class probabilities和individual box confidence predictions相乘： Pr(Class_i|Object)\times Pr(Object)\times IOU_{pred}^{truth} = Pr(Class_i)\times IOU_{pred}^{truth}由此可以得到针对每个box的特定class的confidence scores。这些scores代表着特定calss出现在box里面的概率，以及预测出来的box在多大程度上适应这个object。 最终预测的tensor维度： $S\times S\times (B\times 5+ C)$ 。 网络设计YOLO：收到GoogleNet的启发，公有24层卷积层和2层全连接层 但是没有使用Inception模块，而是使用了 $3\times 3$ 的卷积层和一个 $1 \times 1$ 的reduction layers（减少depth） fast YOLO：9个卷积层和2个全连接层。 训练首先在ImageNet上进行了预训练。 预训练时，使用前20个卷积层，加上一个平均池化层，和一个全连接层。 使用了Darknet framework。 Ren et al证明在预训练的网络上添加卷积层和全连接层可以提升性能。因此，本文添加了4个卷积层和2个全连接层，都赋予随机初始值。 模型的输入图像像素为448 。 最后一层同时预测class probabities和bounding box coordinates。 我们将box的宽和高都归一化到占图片宽高值的比例，因此coordinates的值在0到1之间。coordiantes的x和y归一化到对特定cell的相对位移，所以它们的值也在0到1之间。 本文最后一层使用线性激活函数，其他层均使用leaky rectified linear 激活函数，如下所示： \phi(x) = \begin{cases} x & \text{if } x>0 \\ 0.1x& \text{otherwise} \end{cases}本文的优化函数为平方和误差。 由于它对localization error的权重和对classification的权重是一样的，因此该函数并不能够很好的匹配我们的目标。为了解决问题，提升了bounding box coordinate predictions的loss，同时降低了confidence predictions的loss。 作者使用了 $\lambda_{coord} = 5$和 $\lambda_{noobj} = 0.5$ 来实现这一目标。 同时为了更好的针对小目标，本文对bounding box的宽和高都使用了平方跟。 YOLO对每个grid cell都会预测出多个bounding boxes，而在训练阶段，我们只需要一个bouding box 来对每个物体负责。选取的原则是与GT有最高的IOU值。 在训练阶段，本文优化下面的联合目标损失函数： \lambda_{coord} \sum_{i=0}^{S^2} \sum_{j=0}^B I_{ij}^{obj}[(x_i-\hat x_x)^2 + (y_i - \hat y_i)^2] \ + \lambda_{coord}\sum_{i=0}^{S^2} \sum_{j=0}^B I_{ij}^{obj} [(\sqrt w_i - \sqrt{\hat w_i})^2 +(\sqrt h_i - \sqrt{\hat h_i})^2]+ \sum_{i=0}^{S^2}\sum_{j=0}^B I_{ij}^{obj} (C_i - \hat C_i)^2 + \lambda_{noobj}\sum_{i=0}^{S^2}\sum_{j=0}^{B} I_{ij}^{noobj}(C_i-\hat C_i)^2+ \sum_{i=0}^{S^2} I_i^{obj} \sum_{c\in \text{classes}} (p_i(c) - \hat p_i(c))^2batch size为64，a momentum of 0.9 and a decay of 0.0005。 推理阶段平均每张图片会得到98个bounding boxes。 虽然采用了非极大值抑制，但是提升的效果并不高，不如RCNN和DPM那么明显。 YOLO的局限性难以检测小物体和堆积在一起的物体，比如鸟群。 另外，YOLO对于不同大小的物体，其采取的损失函数是一样的，因此，在面对大物体时，细微的差别可能不会引起IOU的大幅变化，但是在面对小物体时，就会产生较大波动。YOLO的错误来源主要是由于定位错误。 和其他检测系统的比较Deformable parts models： DPM使用了滑动窗口的方法来做目标检测。它的检测是由分离的好几段过程完成的。 相比来说，作者的模型统一了所有这些过程，并且取得了更快更好的效果（基本来说就是把DPM吊打了。。。，不过毕竟DPM是2010年的产品，不吊打说不过去了。。） RCNN： RCNN没有使用滑动窗口的方法来获取bounding box，而是使用了Selective Search（之后也不用SS方法了，提出了RPN，继承到模型内部了）。同理，RCNN也是一种多阶段的方法，先画框，再检测，分两步走。YOLO在一定程度了也借鉴了RCNN及其变体的思想，但是YOLO是基于grid cell进行proposes bounding box的，所以最后只生成了98个框，而RCNN的框多大2000个，所以YOLO在速度上肯定是远超RCNN了，另外精度上也比RCNN高（不过RCNN只是region based检测方法的雏形，所以并不说明YOLO比RCNN整个系列都好）。 Other Fast Detectors： RCNN其他系列来了，作为后出生的Fast RCNN和Faster RCNN，当然视为自家的兄弟出了口气，在精度上爆了YOLO，但是速度还是不及YOLO（YOLO是真的快，真正意义上的实时监测系统） Deep MultiBox 14年出来的，SPPNet使用了它进行选框 OverFeat 13年的一篇文章 MultiGrasp 这是Joseph自己的工作，在YOLO之间发的，解决的任务是检测一张的图片中某个包含物体的区域，比YOLO要解决的任务简单的多，没什么好说的 实验 Experiments首先是在VOC2007上做了实验，然后专门针对YOLO和Fast RCNN进行比较，虽然整体mAP没有Fast高，但是在背景上的假正例比Fast少。接着，还给出2012VOC的实验结果。最后，还做了一个从自然图像训练，然后检测艺术作品的实验，提出YOLO可以学到更一般化的特征。 Comparison to Other Real-Time Systems]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[排序算法 平均时间复杂度 最坏/最好时间复杂度 空间复杂度 是否稳定 冒泡排序 $O(n^2)$ $O(n^2)$ / $O(n)$ $O(1)$ 稳定 选择排序 $O(n^2)$ $O(n^2)$ / $O(n^2)$ $O(1)$ 不稳定 插入排序 $O(n^2)$ $O(n^2)$ / $O(n)$ $O(1)$ 稳定 希尔排序 $O(nlogn)$ 与步长 $d$ 有关 / $O(nlogn)$ $O(1)$ 不稳定 快速排序 $O(nlogn)$ $O(n^2)$ / $O(nlogn)$ $O(logn) \sim O(n)$ 不稳定 归并排序 $O(nlogn)$ $O(nlogn)$ / $O(nlogn)$ $O(n)$ 稳定 堆排序 $O(nlogn)$ $O(nlogn)$ / $O(nlogn)$ $O(1)$ 不稳定 计数排序 $O(n+k)$ $O(n+k)$ $O(n+k)$ 稳定 基数排序 $O(d\times (n+r))$ $O(d\times (n+r))$ $O(n+r)$ 稳定 桶排序 $O(n+m)$ $O(n+m)$ $O(n)$ 稳定 冒泡排序从后往前, 相邻的数据两两比较, 一趟完成后, 第一个元素为最大/小值 时间复杂度: $O(n^2)$最好情况: $O(n)$, 当某次遍历没有发生交换, 则说明已经有序最坏情况: $O(n^2)$, 数组刚好是逆序空间复杂度: $O(1)$稳定性: 是稳定的, 主要就是 遇到相等的元素时不要进行交换操作 即可 1234567891011void bubble_sort(vector&lt;int&gt; &amp;input)&#123; for(int i=0; i&lt;input.size(); i++)&#123; for(int bubble = input.size()-1; bubble&gt;i; bubble--)&#123; if(input[bubble-1] &lt; input[bubble] )&#123; //为了保证排序的稳定性, 这里不要用 &lt;= int temp = input[bubble]; input[bubble] = input[bubble-1]; input[bubble-1] = temp; &#125; &#125; &#125;&#125; 冒泡排序的改进: 鸡尾酒排序 冒泡排序是只在一个方向上进行排序, 鸡尾酒排序是从前往后和从后往前交替排序(即先找最大, 再找最小). 在面对大部分元素已经有序的数组时, 鸡尾酒排序的时间复杂度接近于 $O(n)$. 选择(交换)排序初始时在序列中找到最小(大)元素, 放到序列的起始位置, 然后再从剩余的序列中继续寻找最小(大)元素, 并将其放到起始位置的下一个位置, 以此类推, 知道所有元素排序完毕. 时间复杂度: $O(n^2)$最好情况: $O(n^2$, 复杂度与序列元素分布形式无关最坏情况: $O(n^2$, 复杂度与序列元素分布形式无关空间复杂度: $O(1)$稳定性: 选择排序是不稳定的排序算法, 不稳定性发生在最小元素与 A[i] 交换的时刻. 因为选择排序在交换两个元素时, 是不考虑其他元素的相对位置的, 所以, 不管怎么样, 只要发生交换, 就一定会造成不稳定. 但是!!! 如果使用链表或者新开辟一个数组的话, 选择排序也是稳定的, 但实际上这种方法就没有交换的过程, 对于链表来说, 是把节点从链表中拿出来, 组成新的链表, 而不会对原来链表中的元素进行交换. 对于新开辟数组来说, 相当于是用空间换取稳定性, 同样也没有交换过程. 插入排序将数据分为两个部分, 有序部分和无序部分, 一开始有序部分包含只包含第一个元素, 依次将无序部分的元素插入到有序部分 ( 插入的时间复杂度为 $O(n)$ ), 直到所有元素插入完毕. 插入分为数组插入和链表插入(其实堆排序也算是一种插入排序) 下面的时间和空间复杂度均指 数组直接插入, 对于链表, 时间和空间都是 $O(n)$ 时间复杂度: $O(n^2)$最好情况: $O(n)$, 对于已经有序的序列来说, 每一次插入的复杂度都是 $O(1)$, 共插入 $O(n)$ 次.最坏情况: $O(n^2)$, 对于逆序的序列来说, 每一次插入的复杂度都是 $O(n)$, 共插入 $O(n)$ 次.空间复杂度: $O(1)$稳定性: 只要在插入遇到相等元素时, 将新插入的放在最后, 那么就是稳定的. 插入排序不适合对于数据量比较大的排序应用. 但是, 如果需要排序的数据量很小, 比如量级小于千, 那么插入排序还是一个不错的选择. 插入排序在工业级函数库中也有着广泛的应用, 在 STL 的 sort 算法和 stdlib 的 qsort 算法中, 都将插入排序作为快速排序的补充, 用于少量元素的排序(通常为8个或以下). 二分插入排序:直接插入在查找插入位置时, 可以采用二分查找的方式(因为已经有序), 这样可以减少查找插入位置时花费的时间. 希尔排序希尔排序(Shell Sort), 也叫 递减增量排序, 是插入排序中一种更高效的改进版本. 插入排序具有以下两点性质: 对于几乎已经排好序的数据操作时, 效率很高, 可以达到线性排序的效率; 插入排序在每次往前插入时只能将数据移动一位, 这使得效率较低.因此, 希尔排序的思想是: 首先选取一个合适的步长(gap &lt; n)作为间隔, 并将所有元素划分成 gap 个子序列, 每个子序列内部元素之间的距离都是 gap. 分别对每个子序列使用直接插入排序. 缩小步长 gap 的值, 重复上面的分组和插入排序过程, 直到 gap = 1 为止. 时间复杂度: $O(nlogn)$最好情况: $O(n^{1.3})$, 实际中的时间复杂度与 gap 的值和序列元素的分布情况有关.最坏情况: $O(n^2)$, 当 gap 的值为 1 时, 希尔排序就退化成了插入排序.空间复杂度: $O(1)$稳定性: 希尔排序是不稳定的算法, 因此对于相同的两个数, 可以由于分在不同的组中而导致它们的相对顺序发生变化. 比如序列：{ 3, 5, 10, 8, 7, 2, 8, 1, 20, 6 }, h=2时分成两个子序列 { 3, 10, 7, 8, 20 } 和 { 5, 8, 2, 1, 6 }, 未排序之前第二个子序列中的8在前面, 现在对两个子序列进行插入排序, 得到 { 3, 7, 8, 10, 20 } 和 { 1, 2, 5, 6, 8 }, 即 { 3, 1, 7, 2, 8, 5, 10, 6, 20, 8 }, 两个8的相对次序发生了改变. 快速排序时间复杂度: $O(nlogn)$最好情况: $O(nlogn)$, 每次选取的基准都是中位数, 这样每次都可以均匀的划分出两个分区, 只需要 $logn$ 次划分就能结束递归, 每次划分(Partition)的复杂度是 $O(n)$, 因此, 时间复杂度为 $O(nlogn)$.最坏情况: $O(n^2)$, 每次选取的基准都是最大(小)元素, 导致只划分出了一个分区, 这样, 需要 $n-1$ 次划分才能结束递归.空间复杂度: $O(logn)$, 主要是递归造成的栈空间的使用, 具体复杂度取决于递归的深度, 最坏情况下为 $O(n)$.稳定性: 快速排序是不稳定的排序算法, 不稳定性发生在于基准元素交换的时刻. 快排在划分两边的元素时, 会直接交换某两个元素的位置, 并且这种交换与其他元素的值没有关系, 因此, 如果刚好有相同元素, 很容易就会破坏稳定性. 简单优化:快排的期望时间复杂度为 $O(nlogn)$ , 最坏时间复杂度为 $O(n^2)$, 为了避免出现最坏的情况, 可进行如下改进: 哨兵元素的选择: 为了使每次划分的数不至于使两边相差过大, 我们可以选择三者取中法选择哨兵, 一般根据首尾元素和中间元素进行选择. 小数据量的改进: 递归的快排大概在n&lt;13的时候比插入要慢, 所以我们在n&lt;13的时候可以采用插入排序 相同数字的改进, 在存在大量相同数字的时候, 可以用两个指针保存相同数字的信息, 在划分时不用把它们算进去(这啥意思?//TODO) 递归的优化. 快排有两次递归调用, 我们可以用循环代替后面的一次递归. 空间复杂度: $logn$对于就地快排来说, 它本身使用的空间是 $O(1)$ 的, 但是快排在 递归调用过程中, 就需要消耗一定的空间来保存哨兵及两端元素的下标, 而对于快排的非递归实现中, 需要借助两个栈来模拟系统对于数组low和high的存储情况(递归中的哨兵下标实际上会作为下一次递归的low或者high), : 最优的情况下空间复杂度为: $O(logn)$, 每一次都平分数组 最差的情况下空间复杂度为: $O(n)$, 每一次两边都极度失衡 (主要与进行迭代的次数有关, 迭代次数多了, 占用的内存就多了) 注意: 最好写出对输入的low和high进行越界检查的部分!! 这个有时候需要特别跟面试官提一声 递归实现:要知道Partition内部使用&lt;=的原因所在, 写成&lt;, 会造成死循环(当遇到相等元素时, 会无限交换) 另外, 如果令 P=input[low] , 那么一定要 high--在前, 否则会造成元素覆盖12345678910111213141516171819202122void quickSort(vector&lt;int&gt;&amp; input, int low, int high)&#123; if(input.size()==0 || low&lt;0 || low&gt;=input.size() || high&lt;0 || high&gt;=input.size())&#123; cout&lt;&lt;&quot;error&quot;; exit(0); &#125; int mid = Partition(input, low, high); if(mid&lt;high) quickSort(input, mid+1, high); if(mid&gt;low) quickSort(input, low, mid-1);&#125;int Partition(vector&lt;int&gt;&amp; input, int low, int high)&#123; int p = input[low]; while(low&lt;high)&#123; // 一定要high在前, 否则会造成数组元素覆盖, 回忆头条面试惨痛经历! while(low&lt;high &amp;&amp; p&lt;=input[high]) high--; //这里注意, 如果忘了写=号, 就会陷入死循环 input[low] = input[high]; while(low&lt;high &amp;&amp; p&gt;=input[low]) low++; input[high] = input[low]; &#125; input[low] = p; return low;&#125; 这里Partition用的是&lt;=，那么在high位元素和p相等时，并不会执行交换，而是会high—, 如果忘了写等号, 就会陷入死循环。 非递归实现:12345678910111213141516171819202122232425262728293031323334int partition(vector&lt;int&gt; &amp;input, int low, int high)&#123; int P = input[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; P &lt;= input[high]) high--; input[low] = input[high]; while(low&lt;high &amp;&amp; P &gt;= input[low]) low++; input[high] = input[low]; &#125; input[low] = P; return low;&#125;void quick_sort(vector&lt;int&gt; &amp;input, int low, int high)&#123; if(input.size()==0 || low&lt;0 || low&gt;=input.size() || high&lt;0 || high&gt;=input.size())&#123; cout&lt;&lt;"error"; exit(0); &#125; stack&lt;int&gt; qs_stack; qs_stack.push(high); //入栈顺序一定要注意, 要与后面的操作对应好 qs_stack.push(low); while(!qs_stack.empty())&#123; low = qs_stack.top(); qs_stack.pop(); // low后入栈, 所以就应该先出栈 high = qs_stack.top(); qs_stack.pop(); if(low &gt;= high) continue; int mid = partition(input, low, high); if(low&lt;mid)&#123; qs_stack.push(mid-1);//入栈顺序一定要注意, qs_stack.push(low); &#125; if(mid&lt;high)&#123; qs_stack.push(high);//入栈顺序一定要注意, qs_stack.push(mid+1); &#125; &#125;&#125; 归并排序核心思想是将两个有序数列进行合并，使其成为一个新的有序数列（时间复杂度为 $O(n)$ ）: 将序列没相邻的两个数组进行归并(merge)操作, 形成floor(n/2)个序列, 排序后每个序列包含两个元素 将上述序列在此归并, 形成floor(n/2)个序列, 每个序列包含四个元素 重复上述归并操作, 直到所有元素归并完毕 时间复杂度: $O(nlogn)$ 归并排序即使在最坏情况下, 时间复杂度也是 $O(nlogn)$, 这是它的一大优点.最好情况: $O(nlogn)$最好情况: $O(nlogn)$空间复杂度: $(n)$, 需要借助临时数组(也可以不用), 同时, 递归也需要占用空间.稳定性: 归并排序是稳定的排序算法, 在归并排序过程中, 相同元素有可能出现在同一组内或者不同组内, 如果在同一组内, 则默认就是稳定的, 如果在不同组内, 则根据组的前后位置来判断相同元素的顺序. 因此它是稳定的. 在合并时，由两种选择，一种是不使用额外空间的插入合并，这样会增加时间开销。另一种是使用额外空间的合并，这样不增加时间开销，但是需要额外空间。（当然，如果使用的是链表，则没有这种情况，可以既不增加时间，也不增加空间开销） 常规递归排序:12345678910111213141516171819202122232425262728293031323334void mergesort(vector&lt;int&gt;&amp; a,int first, int last)&#123; if(first&lt;last)&#123; mid = (last+first)/2; mergesort(a, first, mid); mergesort(a, mid+1, last); mergeArray(a, first,mid,mid+1,last); &#125;&#125;void mergeArray(vector&lt;int&gt;&amp; a, int first1,int last1,int first2,int last2)&#123; vector&lt;int&gt; temp; int i = first1; int j = first2; while(i&lt;=last1 &amp;&amp; j&lt;=last2)&#123; if(a.at(i) &lt; a.at(j))&#123; temp.push_back(a.at(i)); i++; &#125; else&#123; temp.push_back(a.at(j)); j++; &#125; &#125; while(i&lt;=last1)&#123; temp.push_back(a.at(i)); i++; &#125; while(j&lt;=last2)&#123; temp.push_back(a.at(j)); j++; &#125; for(int i = 0; i&lt;temp.size(); i++) a.at(first1+i) = temp.at(i);&#125; 原地归并排, 不借助辅助数组 123456789101112131415161718192021222324252627void swap_memory(vector&lt;int&gt; &amp;data, int start1, int end1, int start2, int end2)&#123; std::reverse(data.begin()+start1, data.begin()+end1); std::reverse(data.begin()+start2, data.begin()+end2); std::reverse(data.begin()+start1, data.begin()+end2);&#125;void merge_sort(vector&lt;int&gt; &amp;data, int start, int end)&#123; int mid = (start+end)/2; if(start &lt; end)&#123; merge_sort(data, start, mid); merge_sort(data, mid+1, end); merge_inplace(data, start, mid, mid+1, end); &#125;&#125;void merge_inplace(vector&lt;int&gt; &amp;data, int start1, int end1, int start2, int end2)&#123; int i = start1; int j = start2; while(i&lt;j &amp;&amp; j&lt;=end2)&#123; while(i&lt;j &amp;&amp; data[i] &lt;= data[j]) i++; int index = j; while(i&lt;j &amp;&amp; data[j] &lt;= data[i]) j++; swap_memory(data, i, index-1, index, j-1); &#125;&#125; 堆排序时间复杂度: $O(nlogn)$ 堆排序即使在最坏情况下, 时间复杂度也是 $O(nlogn)$, 这是它的一大优点. (完全二叉树)最好情况: $O(nlogn)$最坏情况: $O(nlogn)$空间复杂度: $(1)$, 直接在数组上构建堆, 不需要借助临时数组稳定性: 堆排序是不稳定的排序算法, 不稳定性发生在弹出堆顶元素, 进行对调整的时刻. 堆简介堆排序与快速排序，归并排序一样都是时间复杂度为 $O(nlogn)$ 的几种常见排序方法 堆（二叉堆）可以视为一棵完全的二叉树，完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示（普通的一般的二叉树通常用链表作为基本容器表示），每一个结点对应数组中的一个元素。 如下图,是一个堆和数组的相互关系: 因此,对于给定的某个节点的下标i, 可以很容易计算出这个节点的父节点, 子节点的下标 Parent(i) = floor((i-1)/2)，i 的父节点下标 Left(i) = 2i + 1，i 的左子节点下标 Right(i) = 2(i + 1)，i 的右子节点下标 堆一般分为两种,大顶堆和小顶堆, 前者每个节点的值都大于它的子节点,后者反之 大顶堆: 小顶堆: 堆排序原理堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： 最大堆调整（Max-Heapify）：将堆作调整，使得子节点永远小于父节点 创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆 堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 基于上面的三种操作,可以进行堆的插入和删除: 插入: 将新元素放置在数组末尾,然后进行堆调整 删除: 移除堆顶,然后将数组末尾元素置于堆顶,然后进行堆调整(删除主要用于排序) 最大堆调整（MAX‐HEAPIFY）的作用是保持最大堆的性质，是创建最大堆的核心子程序，作用过程如图所示： 代码实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243// 递归实现void max_heapify(vector&lt;int&gt; &amp;vec, int index, int heap_size)&#123; int imax = index //mark max index int ileft = index*2+1; // left child int iright = index*2+2; // right child if (ileft &lt; heap_size &amp;&amp; vec[imax] &lt; vec[ileft])&#123; imax = ileft; &#125; if(iright &lt; heap_size &amp;&amp; vec[imax] &lt; vec[iright])&#123; imax = iright; &#125; if( imax != index)&#123; std::swap(vec[imax], vec[index]); max_heapify(vec, imax, heap_size); //由于变换了当前节点,因此子树的堆结构可能被破坏, //递归调整, 这里imax的坐标是左右子节点的下标之一(因为进行了交换) &#125; // 堆是自下而上进行调整的,所以在调整当前节点符合堆要求之前,子树已经符合堆要求, //除非进行了节点交换,否则子树的堆结构不会被破坏, 无需进行额外处理&#125;//非递归实现void max_heapify(vector&lt;int&gt; &amp;vec, int index, int heap_size)&#123; while(true)&#123; int imax = index; int ileft = 2*index+1; int iright = 2*index+2; if(ileft &lt; heap_size &amp;&amp; vec[imax] &lt; vec[ileft])&#123; imax = ileft; &#125; if(iright &lt; heap_size &amp;&amp; vec[imax] &lt; vec[iright])&#123; imax = iright; &#125; if( imax != index )&#123; std::(vec[imax], vec[index]); index = imax; //产生了交换, 可能破坏了左右子树的堆结构, 令index为左右子树之一的下标, 继续调整 &#125;else&#123; break; //如果没有交换，说明当前结构的堆结构已经完成，直接跳出 &#125; &#125;&#125; 创建最大堆（Build-Max-Heap）的作用是将一个数组改造成一个最大堆，接受数组和堆大小两个参数，Build-Max-Heap 将自下而上的调用 Max-Heapify 来改造数组，建立最大堆。因为 Max-Heapify 能够保证下标 i 的结点之后结点都满足最大堆的性质，所以自下而上的调用 Max-Heapify 能够在改造过程中保持这一性质。如果最大堆的数量元素是 n，那么 Build-Max-Heap 从 Parent(n) 开始，往上依次调用 Max-Heapify。 代码实现: 123456789//创建堆void build_maxheap(vector&lt;int&gt; &amp;vec)&#123; int lasti_parent = std::floor((vec.size()-1)/2); for( int i = lasti_parent ; i&gt;=0 ; i--)&#123; max_heapify(vec, i , vec.size()) //从下到上对每个节点进行堆调整，无需从叶子节点开始 //堆的size需要传整个size过去,因为下标从针对整个堆而言的 &#125;&#125; 创建好堆以后,就可以通过移除堆顶来进行排序,每次将堆顶元素和数组末尾元素进行交换(这样可以不借助额外空间完成排序)，然后对数组的前n-1个元素重新进行堆调整构成新的大顶堆, 重复此过程知道堆中只剩下一个元素, 如下图所示: 12345678//代码实现void heap_sort(vector&lt;int&gt; &amp;vec)&#123; build_maxheap(vec); for(int i = vec.size()-1 ; i &gt; 0; i--)&#123; //重复n-1次 std::swap(vec[0] , vec[i]) // Heapify(vec, 0, i); //堆的大小变为i, 所以必须要设置一个变量来标识堆的size,而不是用vec.size() &#125;&#125; 计数排序计数排序是 非比较 排序算法, 适用于已知序列中的元素值在 $(0, k)$ 区间内的情况.(整数) 首先将每个元素出现的次数数出来, 然后算出该元素在最终有序序列中的绝对位置, 再依次将初始序列中元素, 根据确定的最终位置进行移动. 计算最终位置采用的思想是, 假设序列中小于元素 a 的个数为 x, 则可以直接将 a 放到第 x+1 位置上, 另外需要注意存在几个相同元素时要做适当调整, 不能将元素放在同一个位置上. 计数排序的步骤如下: 统计数组 A 中每个值 A[i] 出现的次数, 存入计数数组C[A[i]], 数组 C 的大小为 k; 从前向后, 使数组 C 中的每个值等于其和前一项的相加和, 这样, 数组 C[A[i]] 的含义就变成了代表数组 A 中 小于等于 A[i] 的元素个数. 从后往前填充排序数组 B: 将数组元素 A[i] 放在数组 B 的第 C[A[i]] 个位置(下标为 C[A[i]] - 1), 每放一个元素就将 C[A[i]] 递减(从后往前填充可保证对于相同元素的稳定性, 即位置相对靠后的元素在 B 中的位置也相对靠后). 时间复杂度: $O(n+k)$最好情况: $O(n+k)$最坏情况: $O(n+k)$空间复杂度: $(n+k)$, 需要统计每个元素的个数, 同时在进行元素安放时, 也需要额外空间.稳定性: 计数排序是稳定的排序算法, 因为在计算绝对位置的时候, 可以根据相同元素的前后关系决定绝对位置的前后. 基数排序基数排序是 非比较 排序算法. 它首先将所有待比较正整数统一为同样的数位长度, 其中数位断的数前面补零. 然后, 从最低位开始进行基数为 10 的计数排序, 一直到最高位计数排序完后, 数列就变成了一个有序序列. 时间复杂度: $O(d\times (n+r))$, 其中, $d$ 代表位数, $r$ 代表基数, $n$ 代表是数组元素个数, 一趟分配的时间复杂度是 $O(n)$, 一趟收集的时间复杂度是 $O(r)$, 共进行 $d$ 趟分配和手机.最好情况: $O(d\times (n+r))$最坏情况: $O(d\times (n+r))$空间复杂度: $(r+n)$稳定性: 基数排序是稳定的排序算法, 因为它不需要比较数值的大小. 桶排序桶排序是非比较排序算法. 工作原理是将数组分到有限数量的桶里, 然后每个桶的内部再分别排序(有可能使用别的排序算是或者以递归方式继续使用桶排序进行排序). 时间复杂度: $O(n+m)$, 其中 $n$ 为待排序的元素个数, $m$ 为桶的个数.最好情况: $O(n+m)$最坏情况: $O(n+m)$空间复杂度: $(n)$ 所有桶内的元素个数之和为 n.稳定性: 桶排序是稳定的排序算法, 因为它不需要比较数值的大小, 没有交换元素的相对位置. 桶排序适用于数据分布相对均匀或者数据跨度范围不大时使用, 否则, 会消耗大量的空间 应用:(1). 一年的全国高考考生人数为500万，分数使用标准分，最低100 ，最高900 ，没有小数，要求对这500万元素的数组进行排序。分析：对500W数据排序，如果基于比较的先进排序，平均比较次数为 $O(5000000*log5000000)≈1.112亿$。但是我们发现，这些数据都有特殊的条件： 100=&lt;score&lt;=900。那么我们就可以考虑桶排序这样一个“投机取巧”的办法、让其在毫秒级别就完成500万排序。方法：创建801(900-100)个桶。将每个考生的分数丢进 $f(score)=score-100$ 的桶中。这个过程从头到尾遍历一遍数据只需要500W次。然后根据桶号大小依次将桶中数值输出，即可以得到一个有序的序列。而且可以很容易的得到100分有多少人，501分有多少人。实际上，桶排序对数据的条件有特殊要求，如果上面的分数不是从100-900，而是从0-2亿，那么分配2亿个桶显然是不可能的。所以桶排序有其局限性，适合元素值集合并不大的情况 (2) 在一个文件中有10G个整数，乱序排列，要求找出中位数。内存限制为2G。只写出思路即可（内存限制为2G意思是可以使用2G空间来运行程序，而不考虑本机上其他软件内存占用情况。） 关于中位数：数据排序后，位置在最中间的数值。即将数据分成两部分，一部分大于该数值，一部分小于该数值。中位数的位置：当样本数为奇数时，中位数=(N+1)/2 ; 当样本数为偶数时，中位数为N/2与1+N/2的均值（那么10G个数的中位数，就第5G大的数与第5G+1大的数的均值了）。分析：既然要找中位数，很简单就是排序的想法。那么基于字节的桶排序是一个可行的方法。思想：将整型的每1byte作为一个关键字，也就是说一个整形可以拆成4个keys，而且最高位的keys越大，整数越大。如果高位keys相同，则比较次高位的keys。整个比较过程类似于字符串的字典序。第一步:把10G整数每2G读入一次内存，然后一次遍历这536,870,912即（102410241024）*2 /4个数据。每个数据用位运算”&gt;&gt;”取出最高8位(31-24)。这8bits(0-255)最多表示256个桶，那么可以根据8bit的值来确定丢入第几个桶。最后把每个桶写入一个磁盘文件中，同时在内存中统计每个桶内数据的数量NUM[256]。代价：(1) 10G数据依次读入内存的IO代价(这个是无法避免的，CPU不能直接在磁盘上运算)。(2)在内存中遍历536,870,912个数据，这是一个O(n)的线性时间复杂度。(3)把256个桶写回到256个磁盘文件空间中，这个代价是额外的，也就是多付出一倍的10G数据转移的时间。第二步：根据内存中256个桶内的数量NUM[256]，计算中位数在第几个桶中。很显然，2,684,354,560个数中位数是第1,342,177,280个。假设前127个桶的数据量相加，发现少于1,342,177,280，把第128个桶数据量加上，大于1,342,177,280。说明，中位数必在磁盘的第128个桶中。而且在这个桶的第1,342,177,280-N(0-127)个数位上。N(0-127)表示前127个桶的数据量之和。然后把第128个文件中的整数读入内存。(若数据大致是均匀分布的，每个文件的大小估计在10G/256=40M左右，当然也不一定，但是超过2G的可能性很小)。注意，变态的情况下，这个需要读入的第128号文件仍然大于2G，那么整个读入仍然可以按照第一步分批来进行读取。代价：(1)循环计算255个桶中的数据量累加，需要O(M)的代价，其中m&lt;255。(2)读入一个大概80M左右文件大小的IO代价。第三步：继续以内存中的某个桶内整数的次高8bit（他们的最高8bit是一样的）进行桶排序(23-16)。过程和第一步相同，也是256个桶。第四步：一直下去，直到最低字节(7-0bit)的桶排序结束。我相信这个时候完全可以在内存中使用一次快排就可以了。整个过程的时间复杂度在O(n)的线性级别上(没有任何循环嵌套)。但主要时间消耗在第一步的第二次内存-磁盘数据交换上，即10G数据分255个文件写回磁盘上。一般而言，如果第二步过后，内存可以容纳下存在中位数的某一个文件的话，直接快排就可以了（修改者注：我想，继续桶排序但不写回磁盘，效率会更高？）。]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Grasp_detection]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-Grasp_detection%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的 this 指针]]></title>
    <url>%2Fz_post%2FCpp-this%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[this指针是一个 隐含于 每一个非静态成员函数中的特殊指针. 它指向正在被该成员函数操作的那个对象 当一个对象调用其成员函数时, 编译程序会先将对象的地址赋给this指针, 然后调用成员函数, 每次成员函数存取数据成员时, 会隐含使用this指针. 当一个成员函数被调用时, 自动向它传递一个隐含的参数, 该参数是一个指向这个成员函数所在的对象的指针 this指针被隐含的声明为: ClassName *const this, 这意味着不能给this指针不能再指向其他对象, 在ClassName类的const成员函数中, this指针的类型为const ClassName* const, 这说明也不能对this指针所指向的这种对象进行赋值操作. this并不是一个常规变量, 而是一个 右值, 所以不能取得this的地址.(不能&amp;this, 左值右值的区别就在于是否可以取地址) 在以下场景中, 经常需要显式使用this指针: 为实现对象的链式引用 为避免对同一对象进行赋值操作(this.obj = obj, 在构造函数中这种很常用) 为实现一些数据结构时, 如list]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 手册]]></title>
    <url>%2Fz_post%2FCpp-%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[闲杂123Array &lt; Stack&lt;int&gt; &gt; array_stack;//在C++98中，要求至少用一个空白符将两个&gt;符号分开，以免与运算符&gt;&gt;混淆，C++11不要求这样做 花括号与分号在结构体与类定义大括号后面需要分号；其余可要可不要if else、try catch等组合语句如果在中间加了分号会将一个语句块分成两个 cmath123456789#include &lt;cmath&gt;or#include &lt;math.h&gt;ceil(),floor() 向上、向下取整，不在命名std里面。ceil(5/2); // 2ceil(5.0/2); // 3floor(5.0/2); // 2: 数组对于内置数据类型元素的数组，必须使用()来显示指定程序执行初始化操作，否则程序不执行初始化操作： 123int *pia = new int[10]; // 每个元素都没有初始化int *pia2 = new int[10] (); // 每个元素初始化为0 类类型元素的数组，则无论是否使用（），都会自动调用其默认构造函数来初始化： 123string *psa = new string[10]; // 每个元素调用默认构造函数初始化string *psa = new string[10](); // 每个元素调用默认构造函数初始化 std::find()返回范围 [first, last) 中满足特定判别标准的首个元素迭代器，查找失败则返回end迭代器 std::sort()1234567891011// 自定义函数必须写在最外吗，否则无法通过bool mysort(int a, int b)&#123; return a&gt;b; &#125; //降序int main()&#123; std::vector&lt;int&gt; v = &#123;2,3,5,787,8,5&#125;; std::sort(v.begin(), v.end(), mysort); for(auto iter = v.begin(); iter!= v.end(); iter++)&#123; std::cout&lt;&lt;* iter&lt;&lt;std::endl; &#125;&#125; lamda 表达式:123std::sort(s.begin(), s.end(), [](int a, int b) &#123; return b &lt; a; &#125;); 重载operator()运算符1234567struct &#123; bool operator()(int a, int b) const &#123; return a &lt; b; &#125;&#125; customLess;std::sort(s.begin(), s.end(), customLess); //升序 std::reverse()反转[first, last)范围中的元素顺序. (借助 std::swap()实现)123std::vector&lt;int&gt; v&#123;1,2,3&#125;;std::reverse(std::begin(v), std::end(v));std::reverse(v.begin(), v.end()); vector常用操作截取vector中的一部分作为一个新的vector12 清空：clear() 在最后添加元素：push_back() 初始化123vector&lt;string&gt; v3(5, "hello"); // 创建有5个值为“hello”的string类对象的容器std::vector&lt;int&gt; v = &#123;7, 5, 16, 8&#125;; 判断某元素是否存在123vector&lt;string&gt; vStr;int nRet = std::count(vStr.begin(), vStr.end(), "abc");//返回向量中，“abc”元素的个数 at：访问指定字符，有边界检查 str.at(1) front：访问首字符 (C++11) str.front() back：访问最后的字符（C++11）Cpp string类常用操作截取子串s.substr(pos, n) 截取s中从pos开始（包括0）的n个字符的子串，并返回 s.substr(pos) 截取s中从从pos开始（包括0）到末尾的所有字符的子串，并返回 替换子串s.replace(pos, n, s1) 用s1替换s中从pos开始（包括0）的n个字符的子串 查找子串s.find(s1) 查找s中第一次出现s1的位置，并返回（包括0） s.rfind(s1) 查找s中最后次出现s1的位置，并返回（包括0） s.find_first_of(s1) 查找在s1中任意一个字符在s中第一次出现的位置，并返回（包括0） s.find_last_of(s1) 查找在s1中任意一个字符在s中最后一次出现的位置，并返回（包括0） s.fin_first_not_of(s1) 查找s中第一个不属于s1中的字符的位置，并返回（包括0） s.fin_last_not_of(s1) 查找s中最后一个不属于s1中的字符的位置，并返回（包括0） 判断字符串string里面是否含有某个字符串利用string::size_type string::find(string &amp;);函数 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string a="abcdefghigklmn"; string b="def"; string c="123"; string::size_type idx; idx=a.find(b);//在a中查找b. if(idx == string::npos )//不存在。 cout &lt;&lt; "not found\n"; else//存在。 cout &lt;&lt;"found\n"; idx=a.find(c);//在a中查找c。 if(idx == string::npos )//不存在。 cout &lt;&lt; "not found\n"; else//存在。 cout &lt;&lt;"found\n"; return 0;&#125; c++字符串比较大小的两种方法 compare函数的使用： 123456789#include &lt;iostream&gt;using namespace std;int main()&#123; string str1="hello"; cout&lt;&lt;str1.compare("helloo")&lt;&lt;endl;//返回-1； cout&lt;&lt;str1.compare("hello")&lt;&lt;endl;//返回0 ； cout&lt;&lt;str1.compare("hell")&lt;&lt;endl;//返回1；&#125; 使用strcmp(aa1.c_str(),bb2.c_str()) 1234567891011121314#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int main()&#123; char* str1="hello"; char* str2="hell"; char* str3="helloo"; char* str4="hello"; //原型extern int strcmp(const char* s1,const char* s2); cout&lt;&lt;strcmp(str1,str2)&lt;&lt;endl;//返回1； cout&lt;&lt;strcmp(str1,str3)&lt;&lt;endl;//返回-1； cout&lt;&lt;strcmp(str1,str4)&lt;&lt;endl;//返回0.&#125; 统计字符串中某个字符出现了多少次使用算法库里面的count函数，使用方法是count（begin，end，‘a’），其中begin指的是起始地址，end指的是结束地址，第三个参数指的是需要查找的字符 123456789101112#include &lt;iostream&gt;#include &lt;algotirhm&gt;#include &lt;string&gt;using namespace std;int main()&#123; string temp = "aaabcdaaa!!!"; int num = count(temp.begin(),temp.end(),'a'); cout &lt;&lt;"在字符串" &lt;&lt; temp &lt;&lt; "中，" &lt;&lt;"字母a出现的次数是" &lt;&lt; num &lt;&lt; endl; return 0 ；&#125; 元素访问at：访问指定字符，有边界检查 str.at(1) front：访问首字符 (C++11) str.front() back：访问最后的字符（C++11）Cpp c_str：返回不可修改的C字符数组版本（带’\0’） str.c_str() 交换string的值成员函数： string::swap(string&amp; str) 主要用于交换两个string的值，用法如下： 1234567891011121314151617181920212223242526// swap strings#include &lt;iostream&gt;#include &lt;string&gt;main ()&#123; std::string buyer ("money"); std::string seller ("goods"); std::cout &lt;&lt; "Before the swap, buyer has " &lt;&lt; buyer; std::cout &lt;&lt; " and seller has " &lt;&lt; seller &lt;&lt; '\n'; seller.swap (buyer); std::cout &lt;&lt; " After the swap, buyer has " &lt;&lt; buyer; std::cout &lt;&lt; " and seller has " &lt;&lt; seller &lt;&lt; '\n'; return 0;&#125;/*output:Before the swap, buyer has money and seller has goods After the swap, buyer has goods and seller has money*/ 非成员函数std::swap()可以将string内部的两个元素进行交互。同时，也可以对两个string进行交换 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;string&gt;int main()&#123; std::string str1 = "abc"; std::swap(str1.at(0), str1.at(1)); std::cout&lt;&lt;str1&lt;&lt;std::endl; std::string str2 = "def"; std::swap(str1, str2); std::cout&lt;&lt;str1&lt;&lt;std::endl; return 0;&#125;/*output:bacdef*/ vector连续存储结果, 每个元素在内存上是连续的, 支持 高效的随机访问和尾端插入/删除操作, 但其他位置的插入/删除操作效率低下, 可以看做是一个数组, 但是与数组的区别为: 内存空间的扩展. vector 支持动态大小的数据存储, 而数组则必须指定大小, 但需要扩展空间时, 需要手动实现. vector的内存分配原理及实现:在STL内部实现时, 首先分配一个较大的内存空间预备存储, 即capacity()函数返回的大小, 当超过此分配的空间时, 会再重新分配一块更大的内存空间(VS6.0是两倍, VS2005是1.5倍). 通常默认的内存分配能完成大部分情况下的存储操作. 扩展空间的步骤: 配置一块新空间 将就元素一一移动到新地址中 把原来的空间释放掉 vector的数据安排以及操作方式, 与数组模板Array十分相似, 两者唯一的差别在于空间利用的灵活性, Array的空间扩展需要手动实现 deque双端队列: double-end queue连续存储结果, 即每个元素在内存上是连续的, 类似于vector, 不同之处在于, deque提供了两级数组结构, 第一级完全类似于vector, 代表实际容器, 另一级维护容器的首位地址, 这样, deque除了具有vector的所有功能之外, 还支持高校的首/尾端的插入/删除操作. 优点: 随机访问方便, 支持[]操作符和.at()访问函数 可在两端进行push, pop操作 缺点:占用内存多 list非连续存储结构, 具有两链表结构, 每个元素维护一对前向和后向指针, 因此支持前向/后向遍历. 支持高效的随机插入/删除操作, 但是随机访问效率低下, 且由于需要额外维护指针, 开销也比较大. 每一个节点都包括一个信息块info, 一个前驱指针Pre, 一个后驱指针Post. 优先: 不使用连续内存完成插入和删除操作 在内部方便的进行插入和删除操作 可以在两端push, pop 缺点: 不能进行随机访问, 即不支持[]操作符和.at()访问函数 相对于vector占用内存多 list与vector的区别 vector为存储的对象分配一块连续的地址空间, 随机访问效率很高. 但是插入和删除需要移动大量的数据, 效率较低. 尤其当vector内部元素较复杂, 需要调用复制构造函数时, 效率更低. list中的对象是离散的, 随机访问需要遍历整个链表, 访问效率比vector低, 但是在list中插入元素, 尤其在首尾插入时, 效率很高. vector 是 单向的 的, 而 list 是双向的 (vector为什么单向???) vector 中的 iterator 在使用后就释放了, 但是 list 不同, 它的迭代器在使用后还可以继续使用, 是链表所特有的. queuedequemap1、map简介Map是STL的一个关联容器，它提供一对一（其中第一个可以称为关键字，每个关键字只能在map中出现一次，第二个可能称为该关键字的值）的数据 处理能力，由于这个特性，它完成有可能在我们处理一对一数据的时候，在编程上提供快速通道。这里说下map内部数据的组织，map内部自建一颗红黑树(一 种非严格意义上的平衡二叉树)，这颗树具有对数据自动排序的功能，所以在map内部所有的数据都是有序的，后边我们会见识到有序的好处。map是一类关联式容器。它的特点是增加和删除节点对迭代器的影响很小，除了那个操作节点，对其他的节点都没有什么影响。对于迭代器来说，可以修改实值，而不能修改key。 2、map的功能 自动建立Key － value的对应。key 和 value可以是任意你需要的类型。 根据key值快速查找记录，查找的复杂度基本是Log(N)，如果有1000个记录，最多查找10次，1,000,000个记录，最多查找20次。 快速插入Key -Value 记录。 快速删除记录 根据Key 修改value记录。 遍历所有记录。-3. 使用map 1#include &lt;map&gt; //注意，STL头文件没有扩展名.h 4. map的构造函数map共提供了6个构造函数，这块涉及到内存分配器这些东西，略过不表，在下面我们将接触到一些map的构造方法，这里要说下的就是，我们通常用如下方法构造一个map：1map&lt;int, string&gt; mapStudent; 5. 数据的插入unordered_map与map的区别在STL中, map对应的数据结构是红黑树, 红黑树是一种近似于平衡的二叉查找树, 里面的数据是有序的, 在红黑树上做查找的时间为 $O(lonN)$. 而unordered_map对应哈希表, 哈希表的特点就是查找效率高, 时间复杂度基本为 $O(1)$, 而额外空间复杂度较高. 基本使用1234567891011#include &lt;iostream&gt;#include &lt;unordered_map&gt;#include &lt;string&gt;int main()&#123; std::unordered_map&lt;int, std::string&gt; hmap; hmap.insert(std::make_pair(1, "Scala")); hmap.insert(&#123;3, "three"&#125;); hmap.insert(&#123; &#123;4, "Four"&#125;, &#123;5, "Five"&#125;&#125;); cout&lt;&lt;hmap[1]&#125; set基于红黑树实现 unordered_set基于哈希表实现, 会将传入的值处理成相应的键值, 该键值对应着一个特定的位置, 因此, unordered_set 的各项操作的复杂度平均为常数级(最差为线性), 同时, unordered_set 也是一种 set, 因此, 其关键字不能有重复(重复的会自动合并). 12345678910111213unordered_set&lt;string&gt; stringSet;stringSet.insert("code");stringSet.insert("fast");string key1 = "fast";stringSet.find(key1); // return iter, 指向 faststring key2 = "slow"stringSet.find(key2); // return stringSet.end()vector&lt;int&gt; nums &#123;1,2,3,4,5,6,7,8,9&#125;;unordered_set&lt;int&gt; sets(nums.begin(), nums.end())int key;sets.count(key); // 返回拥有关键key的元素个数, 即只会返回1或0. 优先级&amp; | 的优先级较低, 通常情况下需要使用括号括起来. 三元运算符 ?: 的优先级也很低, 当其进行算数运算时, 也建议使用括号括起来.]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CUDA C Programming Guide》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CUDACProgrammingGuide-md%2F</url>
    <content type="text"><![CDATA[第一章 介绍GPU在进行浮点数运算时超高的精确度和速度，其原因在于GPU很擅长解决计算密集型和高并行计算。 多核CPU和GPU的一个挑战在于怎么编写并行的程序来利用这些多核。 CUDA并行变成模式就是希望用一个较低的学习曲线来解决这个问题。 三个关键的抽象：线程组等级、共享内存、障碍同步 第二章 编程模型2.1 Kernelskernel程序用__global__定义。并且用一种新的执行配置语法&lt;&lt;&lt;...&gt;&gt;&gt;来决定CUDA的线程数量。每一个线程都会在给定的“线程ID”下执行kernel，线程ID可以通过kernel内部的threadIdx变量来获取。 下面的代码显示了向量加法。 总共启动了N个线程，每个都执行一个对应位相加运算。 123456789101112//Kernel definition__global__ void VecAdd(float* A, float* B, float* C)&#123; int i = threadIdx.x; C[i] = A[i] + B[i];&#125;int main()&#123; ... // Kernel invocation with N threads VecAdd&lt;&lt;&lt;1,N&gt;&gt;&gt;(A,B,C);&#125; 2.2 线程结构（Thread Hierarchy）为了方便，threadIdx包含三个组成向量，因此，线程可以使用一维，二维或者三维的thread index，由此，可以表示一维，二维或者三维的线程块（“thread block”）。 线程的索引和它的线程ID是直接关联的。对于一维线程块来说，它们是一样的。对于二维线程块来说，索引为 $(x，y)$ 的线程，其线程ID为：$(x+yD_x)$ 。对于三维线程块来说，索引为 $(x,y,z)$ 的线程，其线程ID为： $(x+ yD_x +zD_xD_y)$ 。 下面的代码显示了矩阵加法。 123456789101112131415//Kernel definition__global__ void MatAdd(float A[N][N], float B[N][N], float C[C][C])&#123; int i = threadIdx.x; int j =threadIndx.y; C[i][j] = A[i][j] + B[i][j];&#125;int main()&#123; ... //Kernel invocation with one block of N*N*1 threads int numBlocks = 1; dim3 threadsPerBlock(N,N); //&lt;&lt;&lt;&gt;&gt;&gt;语法可以接受int类型或者dim3类型的数据 MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A,B,C);&#125; thread block的索引可以通过blockIdx变量获得，thread block的维度的size可以通过blockDim变量获得。 扩展上面的MatAdd()代码，使其可以处理多blocks，代码如下： 123456789101112131415161718//Kernel definition__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])&#123; int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadInx.y; if(i&lt;N &amp;&amp; j&lt;N)&#123; C[i][j] = A[i][j] + B[i][j]; &#125;&#125;int main()&#123; ... //Kernel invocation dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ...&#125; 线程块必须独立执行，因此它们必须能够在任意的顺序下并行执行。 CUDA使用__syncthreads()来协调共享内存和各个线程之间的执行。 2.3 内存结构（Memory Hierarchy）由两种额外的只读内存空间可以被所有线程访问到：常量内存空间（constant memory spaces）和纹理内存空间（texture memory spaces）。 2.4 异构编程CUDA编程模型假设所有线程都是在物理上单个的设备上运行的，每个设备都当做是主机的从处理程序。比如，kernel在GPU上执行，而剩下的C程序在CPU上执行。 CUDA编程模型还假设主机和设备都DRAM中各自维护自己的内存，对应这“主机内存（host memory）”和“设备内存（divice memory）”。因此，程序通过调用CUDA运行时来管理主机和设备的内存。 2.5 计算能力（Compute Capability）计算能力用设备的版本号标识，有时也称为“SM version”。有major revision number“X”和minor revision number“Y”组成，记为X.Y。 第三章 编程接口（Programming Interface）CUDA提供了诸多扩展语法来并行变成（如kernel），任何包含这些扩展语法的源文件都需要需要nvcc编译器来编译。 3.1 Compilation with NVCCKernels can be written using the CUDA instruction set architecture, called PTX, whichis described in the PTX reference manual. 3.1.1 编译工作流3.1.1.1 离线编译 Offline Compilationnvcc编译器可以编译包含host code和device code的混合代码。nvcc首先会将device code从host code中分离出来，然后，会进行以下两步： 编译device code到assembly form（PTX code）或者binary form（cubin objec） 修改host code，将&lt;&lt;&lt;...&gt;&gt;&gt;语法替换成必要的CUDA C运行时函数。 被修改的host code要么输出成C code，要么把直接输出成object code。 3.1.1.2 即时编译 Just-in-Time Compilation二进制兼容性 Binary CompatibilityBinary code is architecture-specific。通过-code=sm_35的形式来指定特定的architecture。注意，编译好的二进制代码是向上兼容的，也就是如果二进制代码设定的计算能力版本号为 $X.y$ ，那么该代码就只能运行在 $X.z$上，其中 $z\ge y$ 。 3.1.3 PTX 兼容性一些PTX指令仅仅支持在高计算机能力版本的GPU中使用。 指针某些计算能力版本的PTX code总是可以转换成binary code，进而都更高计算能力的版本中使用。 其他有些版本，则不能直接使用。 3.1.4 应用兼容性为了满足bianry兼容性和PTX兼容性，推荐使用即时编译。 通过-gencode、-arch和-code编译选项来指定计算能力版本号及其兼容性。 3.1.5 C/C++ 兼容性CUDA源文件的前端遵循C++语法规则。host code可以完美支持C++语言发。但是，device code支持C++语法中的一个子集，详细可以参见C/C++ Language Support。 3.1.6 64-Bit Compatibility64位的nvcc会将device code编译成64位模式（即，指针占64位）。此时host code必须在32位模式下执行。 32位device、host同理 -m64 选项可以切换nvcc的位数。 3.2 CUDA C Runtime运行时使用cudart库实现。 或者使用cudart.lib、libcudart.a进行静态链接，或者使用cudart.dll、cudart.so进行动态链接。 正如前面异构编程提到的。CUDA编程模型将系统看走是由device和host组成的一个整体，二者管理各自的内存。 3.2.1 初始化没有专门的初始化函数在初始化阶段，runtime为系统中的每一个device创建上下文。 3.2.2 设备内存 Device MemoryKernels操控device memory之外的代码。所以runtime会提供allocate，deallocate和copy等函数来复制device memory，同时在host和device内存之间传输数据。 Divice memory可以申请linear memory或者CUDA arrays。 CUDA arrays是不透明的内存形式，专门用于优化texture fetching。 Linear memory存在于40位的地址空间中，可以使用cudaMalloc()函数申请，用cudaFree()函数释放，同时，可以用cudaMemcpy()函数来将数据在host和device之间交换。 cudaMallocPitch()和cudaMalloc3D()推荐用来申请2D和3D数组。cudaMemcpy2D。 cudaGetSymbolAddress()用来检索指向内存的地址。 cudaGetSymbolSize()可以得到申请内存的大小。 3.2.3 共享内存 Shared MemoryShared Memory在Thread Hierarchy上要比global memory更快。 矩阵乘法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// Matrices are stored in row-major order:// M(row, col) = *(M.elements + row * M.width + col)typedef struct &#123;int width;int height;float* elements;&#125; Matrix;// Thread block size#define BLOCK_SIZE 16// Forward declaration of the matrix multiplication kernel__global__ void MatMulKernel(const Matrix, const Matrix, Matrix);// Matrix multiplication - Host code// Matrix dimensions are assumed to be multiples of BLOCK_SIZEvoid MatMul(const Matrix A, const Matrix B, Matrix C)&#123;// Load A and B to device memoryMatrix d_A;d_A.width = A.width; d_A.height = A.height;size_t size = A.width * A.height * sizeof(float);cudaMalloc(&amp;d_A.elements, size);cudaMemcpy(d_A.elements, A.elements, size,cudaMemcpyHostToDevice);Matrix d_B;d_B.width = B.width; d_B.height = B.height;size = B.width * B.height * sizeof(float);cudaMalloc(&amp;d_B.elements, size);cudaMemcpy(d_B.elements, B.elements, size,cudaMemcpyHostToDevice);// Allocate C in device memoryMatrix d_C;d_C.width = C.width; d_C.height = C.height;size = C.width * C.height * sizeof(float);cudaMalloc(&amp;d_C.elements, size);// Invoke kerneldim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);dim3 dimGrid(B.width / dimBlock.x, A.height / dimBlock.y);MatMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_A, d_B, d_C);// Read C from device memorycudaMemcpy(C.elements, Cd.elements, size,cudaMemcpyDeviceToHost);&#125;// Free device memorycudaFree(d_A.elements);cudaFree(d_B.elements);cudaFree(d_C.elements);// Matrix multiplication kernel called by MatMul()__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C)&#123;// Each thread computes one element of C// by accumulating results into Cvaluefloat Cvalue = 0;int row = blockIdx.y * blockDim.y + threadIdx.y;int col = blockIdx.x * blockDim.x + threadIdx.x;for (int e = 0; e &lt; A.width; ++e)Cvalue += A.elements[row * A.width + e]* B.elements[e * B.width + col];C.elements[row * C.width + col] = Cvalue;&#125; 3.2.4 Page-Locked Host Memoryplhm有诸多好处，如： 可以使copy更快 可以直接映射到地址空间，消除copy到device memory的需求 在fron-side bus上， plhm的bandwidth更高。 但是，plhm是稀缺资源，因此，在申请时一定要注意不能过度使用。 3.2.4.1 移动内存 Portable Memory一块page-locked内存可以备用在与任意一个设备的连接上。但是默认情况下，使用page-locked内存的好处仅仅会在当前block所申请的设备（或者那些共享了内存的设备）上显现。 为了使这些好处对于所有设备来说都是可行的，block需要将flag cudaHostAllocPortable传递到cudaHostAlloc中去，或者将flag cudaHostRegisterPortable传递到cudaHostRegister中去。 3.2.4.2 Write-Combining Memory该内存通过释放L1和L2的缓存资源，使得更多缓存资源可以给后面的应用使用。 从host中读取write-combining 内存比较慢，所以常常只用于写。 3.2.4.3 Mapped Memory使用cduaHostAllocMapped或者cudaHostRegisterMapped可以使一块page-locked host内存映射到设备的地址空间中。 因此，这样的内存块往往有两个地址，分别是host地址和device地址。 直接kernel中访问host内存有以下几点优势： 无需在device中申请内存块，也无需在device和host中来还传输数据 在执行kernel时，无需使用“流”来overlap数据的传输 3.2.5 异步并发执行 Asynchronous Concurrent ExecutionCUDA将下列操作当作一个独立的任务，它们可以互相并发执行： 在host上计算 在device上计算 将host上的内存传输到device上 将device上的内存传输到host上 3.2.5.1 在Host和Device之间并发执行通过异步调用，许多device操作都可以排成队列，进而利用CUDA driver来执行。这减轻了host线程管理device的负担，使得它可以执行其他任务。下列device操作相对于host来说是异步的。 启动Kernel 将内存拷贝到一个单一的deivce内存中 将内存从host拷贝到device中小于64将内存从host拷贝到device中小于64KB的内存块中 用带有Async后缀的函数来进行内存拷贝 内存设定函数的调用（Memory set function calls） 3.2.5.2 Concurrent Kernel Execution计算能力告诉2.x的版本可以并发启动多个kernels。 可以通过concurrentKernel设备属性来查看是否支持并发启动。 3.2.5.3 Overlap of Data Tranfer and Kernel Execution有一些设备可以从GPU利用kernel执行来进行异步的内存拷贝，应用需要想设备询问是否具有这种功能，可以通过检查asyncEngineCoune设备属性来查看，如果大于0就是支持的。 3.2.5.4 并发数据传输 Concurrent Data Transfers一些计算能力在2.x以上的设备可以在进行数据传输是进行overlap，应用可以通过asyncEngineCount来检查设备是否支持该功能 3.2.5.5 流 Streams应用通过“流”来管理并发的操作。一个“流”代表这一串由“命令”组成的序列 3.2.5.5.1 创建和销毁：Creation and Destruction下面的代码创建了两个流，同时在page-locked内存中申请了flaot类型的hosrtPtr 123456cudaStream_t stream[2];for (int i = 0; i &lt; 2; ++i)cudaStreamCreate(&amp;stream[i]);float* hostPtr;cudaMallocHost(&amp;hostPtr, 2 * size); 这两条流都经过下面的代码定义，执行一个从host到device的内存拷贝操作，一个kernel启动操作，以及一个从device到host的的内存拷贝操作。 123456789for (int i = 0; i &lt; 2; ++i) &#123;cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,size, cudaMemcpyHostToDevice, stream[i]);MyKernel &lt;&lt;&lt;100, 512, 0, stream[i]&gt;&gt;&gt;(outputDevPtr + i * size, inputDevPtr + i * size, size);cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,size, cudaMemcpyDeviceToHost, stream[i]);&#125; 通过cudaStreamDestroy()可以释放流： 1234for (int i =0;i&lt;2;i++)&#123; cudaStreamDestroy(stream[i]);&#125; 3.2.5.5.2 默认流 Default Stream对于使用--default-stream per-thread编译选项的代码来说，默认流是一条常规的流，并且每个主线程都有它自己的默认流 对于使用--default-stream legacy编译选项的代码来说，默认流是一条特殊的流，被称为NULL stream ，并且每一个设备都具有一条单一的NULL stream供所有的host线程使用。它的特殊性源自于它会隐式的进行同步操作。 3.2.5.5.3 显式同步以下几种方式可以对流进行显式同步操作： cudaDeviceSynchronize() cudaStreamSynchronize() cudaStreamWaitEvent() cudaStreamQuery() 为了避免不必要的速率降低，以上所有的同步函数通常用于timing purpoese或者用于孤立一个拷贝或启动的失败。 3.2.5.5.4 隐式同步从两个不同流传过来的指令中的其中一条出现了问题，那么就无法并发运行。 同步操作越晚执行越好。 3.2.5.5.5 Overlapping 行为对于两个流里面的操作，如一个是从host拷贝内存到device，另一个是从device拷贝内存到host，则这两条指令直接存在Overlap。 3.2.5.5.6 回调函数Callbacks运行时提供了可以在流中的任何位置插入回调函数的指令：cudaStreamAddCallback()。 3.2.5.5.7 流优先级 Stream Priorities相对优先级使用cudaStreamCreateWithPriority() 获取优先级范围[highest priority,lowest priority]使用cudaDeviceGetStramPriorityRange。 下面的代码包含了获取当前设备的优先级范围： 1234567// get the range of stream priorities for this deviceint priority_high, priority_low;cudaDeviceGetStreamPriorityRange(&amp;priority_low, &amp;priority_high);// create streams with highest and lowest available prioritiescudaStream_t st_high, st_low;cudaStreamCreateWithPriority(&amp;st_high, cudaStreamNonBlocking, priority_high);cudaStreamCreateWithPriority(&amp;st_low, cudaStreamNonBlocking, priority_low); 3.2.5.6 事件 Eventsruntime 同时还提供了密切监视device进程的方法，主要是通过appliocation来异步记录事件完成时的事件点。 3.2.5.6.1 创建和销毁下面的代码创建了2个事件：123cudaEvent_t event1, event2;cudaEventCreate(&amp;event1);cudaEventCreate(&amp;event2); 下面的代码销毁了2个事件：12cudaEventDestroy(event1);cudaEventDestroy(event2); 3.2.5.6.2 运行时间下面的代码可以用来监视事件的运行时间（从start到end）1234567891011121314cudaEventRecord(start, 0);for (int i = 0; i &lt; 2; ++i) &#123;cudaMemcpyAsync(inputDev + i * size, inputHost + i * size,size, cudaMemcpyHostToDevice, stream[i]);MyKernel&lt;&lt;&lt;100, 512, 0, stream[i]&gt;&gt;&gt;(outputDev + i * size, inputDev + i * size, size);cudaMemcpyAsync(outputHost + i * size, outputDev + i * size,size, cudaMemcpyDeviceToHost, stream[i]);&#125;cudaEventRecord(stop, 0);cudaEventSynchronize(stop);float elapsedTime;cudaEventElapsedTime(&amp;elapsedTime, start, stop); 3.2.5.7 同步调用可以使用cudaSetDeviceFlags()配合一些特定的flags？？ 3.2.6 Multi-Device System3.2.6.1 Device Enumeration一个host系统可以有多个devices，下面的代码展示了如何枚举这些设备，并查询它们的属性，决定可启用CUDA的设备数量。 123456789int deviceCount;cudaGetDeviceCount(&amp; deviceCount);int device;for( device = 0; device&lt;deviceCount; device++)&#123; cudaDeviceProp deviceProp; cudaGetDeviceProperties(&amp;deviceProp, device); printf("Device %d has compute capability %d.%d. \n"), device, deviceProp.major, deviceProp.minor);&#125; 3.2.6.2 Device Selectionhost线程可以在任何时候使用cudaSetDevice()来设置device。device的内存申请和kernel启动都会在当前设置的device上进行，如果没有调用该函数，则当前的设备默认为0. 下面的代码展示了如何设置当前的device，以及申请内存和执行kernel 123456789size_t size = 1024 * sizeof(float);cudaSetDevice(0);float* p0;cudaMalloc(&amp;p0, size);// Allocate memory on device 0MyKernel&lt;&lt;&lt;1000, 128&gt;&gt;&gt;(p0);// Launch kernel on device 0cudaSetDevice(1);// Set device 1 as currentfloat* p1;cudaMalloc(&amp;p1,size);// Allocate memory on device 1MyKernel&lt;&lt;&lt;1000,128&gt;&gt;&gt;(p1);// Launch kernel on device 1 3.2.6.3 Stream and Event Behavior如果stream没有绑定到当前的device，那么kernel launch就会失败 即使stream没有绑定到当前的device，memory copy也会成功 如果input event和input stream 绑定到了不同的diveces上面，那么cudaEventRecord() will fail 如果两个input events绑定到了不同的devices上面，那么cudaEventElapsedTime() will fail 即使input event绑定到了不同于当前device的device上面，cudaEventSynchronize()和cudaEventQuery()仍然will succeed]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中关于*、&、*&以及&*的解析.md]]></title>
    <url>%2Fz_post%2FCpp-%E5%85%B3%E4%BA%8E%E6%8C%87%E9%92%88%EF%BC%8C%E6%8C%87%E9%92%88%E5%BC%95%E7%94%A8%E7%9A%84%E8%A7%A3%E6%9E%90-md%2F</url>
    <content type="text"><![CDATA[由一道牛客网《剑指offer》的编程题引发的思考，题目如下： 二叉搜索树与双向链表：输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的节点，只能调整树中结点指针的指向。 按照递归的解题思路，有如下解答： 12345678910111213141516171819202122232425262728293031323334/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return nullptr; TreeNode* prenode = nullptr; recurve(pRootOfTree,prenode); while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left; return pRootOfTree; &#125; void recurve(TreeNode* root, TreeNode*&amp; prenode)&#123; if(root-&gt;left!=nullptr) recurve(root-&gt;left,prenode); root-&gt;left = prenode; if(prenode!=nullptr) prenode-&gt;right = root; prenode = root; if(root-&gt;right!=nullptr) recurve(root-&gt;right,prenode); &#125;&#125;; 代码中23行使用了TreeNode*&amp; prenode，这里，如果缺少了&amp;，则结果会出错！ 以下，对C++中*、&amp;、*&amp;以及&amp;* 四种形式展开讨论。 * 代表指针&amp; 代表引用、别名指针和引用的区别之一： 参数传递时，不管是传值还是传指针，函数都会产生一个临时副本变量，但在传引用时，不会生成临时变量。 *&amp; 首先是一个指针，然后前面的&amp;代表是这个指针的引用。 指针的引用其实就是指针的一个别名，和指针具有相同的地址。&amp;* 首先是一个变量的引用，然后是指向这个引用的指针，但是，因为引用不是对象，没有实际的地址，因此 不能定义指向引用的指针 。问题：向函数中传递指针和传递指针的引用的区别 如果传递的是指针，那么会先复制该指针，在函数内部使用的是复制后的指针，这个指针与原来的指针虽然指向相同的地址，但是如果在函数内部将复制后的指针指向了另外的地址，那么不会影响原来的指针。 但是对于传递指针的引用，如果将传递进来的指针指向了新的地址，那么原始的指针也会指向新的地址，这也是为什么在该题中，必须使用指针的引用，而不能使用指针的原因。就是因为在这段代码中，要对指针指向的值进行更改，而在递归的函数中，又需要保证prenode指向的值保持统一，因此，必须使用指针的引用来使在不同层的递归函数中，prenode指向的值都是一样的。 在传递指针的引用时，还有另外一个问题，那就是如果由于原始的指针不再指向原始对象了，所以如果没有其他指针指向该原始对象的话，就会造成内存泄漏。同理，如果在函数内释放了指针的引用，那么在函数外部就不能在使用原来的指针了，因为原来的内存已经被释放了。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中NULL和nullptr之间的区别.md]]></title>
    <url>%2Fz_post%2FCpp-NULL%E3%80%81null%E5%92%8Cnullptr%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB-md%2F</url>
    <content type="text"><![CDATA[首先，C++中没有null，只有NULL和nullptr。 NULL引渡自C语言，一般由宏定义实现，而nullptr则是C++11的新增关键字。在C语言中，NULL被定义为(void*)0,而在C++语言中，NULL则被定义为整数0，编译器一般对其实际定义如下：12345#ifdef __cplusplus#define NULL 0#else#define NULL ((void *)0)#endif 出现C++和C定义不一致的原因是，在C++中不允许(void*)类型进行隐式转换，例如：12345char* a =&quot; Hello&quot;;void foo(void* p)&#123;&#125;foo(a); 以上这种调用方式在C++中是不允许的，在C++中指针必须有明确的类型定义。如上需使用foo((char*)a)才可以;但是将NULL定义为0带来的另一个问题是无法与整数的零区分。因为C++中允许有函数重载，所以可以试想如下函数定义情况： 123void func(int data);void func(char* data); 那么在传入NULL参数时，编译器将无法确定到底使用哪个函数定义，造成编译时错误。nullptr在C++11被引入用于解决这一问题，nullptr可以明确区分整型和指针类型，能够根据环境自动转换成相应的指针类型，但不会被转换为任何整型，所以不会造成参数传递错误。nullptr的一种实现方式如下： 1234567const class nullptr_t&#123;public: template&lt;class T&gt; inline operator T*() const&#123; return 0; &#125; template&lt;class C, class T&gt; inline operator T C::*() const &#123; return 0; &#125;private: void operator&amp;() const;&#125; nullptr = &#123;&#125;; 以上通过模板类和运算符重载的方式来对不同类型的指针进行实例化从而解决了(void*)指针带来参数类型不明的问题，另外由于nullptr是明确的指针类型，所以不会与整形变量相混淆。但nullptr仍然存在一定问题，例如： 123void fun(char* p);void fun(int* p); 在这种情况下存在对不同指针类型的函数重载，此时如果传入nullptr指针则仍然存在无法区分应实际调用哪个函数，这种情况下必须显示的指明参数类型。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Video-based Sign Language Recognition without Temporal Segmentation]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-Video_based_Sign_Language_Recognition%2F</url>
    <content type="text"><![CDATA[摘要世界上具有上百万的聋哑患者使用手语进行交流，因此，实现从手语到自然语言的翻译是一件非常有意义的事情。目前，手语识别（SLR）问题主要由两量子问题组成：逐个单词进行识别的独立SLR、对整个句子进行翻译的连续SLR。 目前现有的连续SLR方法基本上都是用独立SLR作为基本模块, 同时结合额外的预处理和后处理操作来实现, 这里的预处理一般是指时域分割,后处理指句子合成. 但是, 时域分割问题本身的误差不可避免就会不断的传递给后续的步骤, 更糟糕的是, 这种独立SLR模块需要经过十分费劲的标注过程来使得一段视频中每一个动作都有与之对应的单词标签. 光这一点就对数据集的获取造成了不小的阻碍. 为了解决这些困难和挑战, 作者就提出了一种新的连续手语识别模型框架, 将其命名为Hierarchical Attention Network with Latent Space(LS-HAN)(基于隐式空间的多级注意力网络), 这个网络框架可以免去时域分割的预处理过程. LS-HAN有三部分组成: 一个双流卷积神经网络: 用于生成视频的特征表示. 隐式空间: 用于建立视频与自然语言之间的语义联系(semantic gap) 多级的注意力网络: 基于隐式空间的识别网络 介绍——Introduction在SLR问题中的一个关键挑战在于表示肢体运动、手势和面部表情的关系描述器的设计。目前主要有两类：手工设计特征 和 基于CNN和特征提取方法。 本文欲计划设计一个双流的3D-CNN模型，用于对视频特征进行提取。 时域分割问题在连续SLR中是一个十分困难的问题。 普遍的解决思路是将连续的SLR解析成独立的单词进行识别，这样就需要解决时域分割问题。 由于需要翻译的动作十分多样，因此很难进行检测，同时，时域分割作为一个预处理步骤，会将分割误差传递给后续步骤。并且，对每个动作打标签也是一项很耗时的任务。 受到基于LSTM的视频描述工作的启发，我们利用一个等级式的注意力网络（Hierarchical Attention Network HAN）规避了时域分割问题。HAN是在考虑结构信息和注意力机制之后，对LSTM的一个扩展。大体思路是将整个视频流送入的HAN中，然后一个单词一个单词的将句子输出。 但是，HAN仅仅是通过前一个单词，来预测后一个单词的最大可能性，忽略了video和句子之间的关系。最终结果是，它可能会出现鲁棒性问题。为了改善这个问题，本文引入隐式共建模型来挖掘视频和句子之间的关系。 一句话总结，本文主要的贡献点有以下三个： 一个新的双流3D CNN，用于生成全局和局部的视频特征表征 一个新的LS-HAN框架，可以规避连续SLR中的时域分割问题 对提出的LS-HAN框架中的相关性损失函数和分辨损失函数进行联合优化 编辑了目前最大的针对连续SLR问题的现代汉语手语识别数据集 相关工作连续SLR大多数现有的SLR研究都是针对独立SLR来做, 有点类似于动作识别。更具挑战性的问题是连续SLR的研究。大多数现有的连续SLR方法都将句子级别的识别分为以下三个阶段：视频时域分割，独立单词识别，基于语言模型的句子融合。例如，DTW-HMM提出了一个基于粗粒度时域分割的阈值矩阵。2017年提出了一个新的基于HMM的语言模型。最近，transitional movements吸引了很多的关注，因为它们可以当作时域分割的基础。 尽管采用时域分割很普遍，但是时域分割问题本质上是很难解决的：因为手语之间的过度动作transitional movements在识别时，依然显得很脆弱和混乱。更糟糕的是, 将连续的SLR任务转化为独立的SLR任务, 需要对大量的数据进行标注, 这是很耗时耗力的. 视频描述生成图像描述生成是一个相关的研究领域，它通过描述视频序列中的场景/物体/动作来生成一段简单的话。一个流行的方法是序列到序列，视频到文本的方法，它将两个LSTM置于CNN之上。 还有的文章使用注意力机制来自动选择可能性最大的帧. 还有其他更多关于LSTM的扩展。 抛开视频描述生成和手语翻译在目标和技术手段上的一些相似之处，二者依然是两个完全不同的任务。前者仅仅是对输入视频的一个简单的总结, 但是后者必须要在语义层面上建立视频与自然语言之间的联系. ( 如对于同一段视频, 前者输出一个人在比划手势是正确的输出, 而后者必须输出这个人比划的收拾的具体含义) 基于潜在空间的学习潜在空间模型是一个用来在不同模态的语义鸿沟之间建立联系的流行的工具。 例如, 有文章使用隐式空间和LSTM结合进行联合学习, 将其用于生成视频描述. 手语视频特征表示手语视频主要由身体的上半部分决定，尤其是手势动作。识别手势动作的主要挑战是手的形态和方向具有很强的不确定性, 由此会组合出大量不同的手势动作。 受到最近深度学习技术在目标检测任务上的进展，我们提出了一个双流的3D CNN模型，用于生成视频特征的表征。这个3DCNN模型会同时接受整个视频帧和剪裁后的手势图像，并且独立的送到两个流中去，最终会通过一个融合机制，将它们融合在一起。因此，这个模型可以提取出整体信息和局部信息的特征编码。 手势检测和跟踪我们首先用fasterrcnn预训练了VOC2007数据，然后，从CSL中选取了400帧进行finetune。之后，所有的视频都逐帧处理。 当手的性状变化很大, 或者被衣服遮挡时, faster rcnn的检测可能会失败, 因此,使用了compressive tracking 双流3D CNN本文基于 C3D（Tran et al 2015） 设计了一个3D CNN双流模型, 该模型将一段手语动作等分成16帧, 并从中提取相应的时序特征. 模型的输入是一串视频截图（16帧）。模型中的上行流被设计用来提取全局手部位置和移动(global hand locations/motions), 缩放到227×227. 下行流关注局部手势信息, 输入是剪裁后的图片(227×227). 这里的这个局部信息就是跟踪两只手, 然后在两只手上画bounding box, 最后将两只手的特征信息按照多通道的方式添加在一起, 送入网络当中. 不管是上行流还是下行流, 他们的网络结构都是一样的, 包含8个卷积层和5个池化层. 最后是两个全连接层, 上行流和下行流的特征图谱会在这里结合. 双流CNN模型首先会对独立的SLR数据集进行预训练。训练完以后会把网络的softmax和最后一层fully connected layer都拿掉. (也就是说我们要的只是前面的卷积网络特征提取器, 深度学习, 说白了, 就是特征学习, 留下最后一层全连接层, 主要是为了将多维度的卷积特征图谱转换成一个一维向量, 方便后面的流程). 这个全连接层上面有4096个神经元, 因此, 最后输出的就是一个4096长度的一维向量. 上面的整个过程就可以看做是用一个滑动窗口在时间维度上对视频流不断的截图, 然后将截图源源不断的送入到神经网络当中, 目的是为了获取每一种视频截图的特征表征, 由于采用了这种双流结构, 因此这种特征表征结合了全局和局部信息(全局就是手移动的轨迹和位置, 局部就是手具体做了什么动作), 某种程度上可以认为是将当前的视频截图编码成了一个4096维的特征向量, 这个特征向量可以高度概括这一帧当中的信息, 最终, 一整段视频就会被编码一连串的4096为的向量, 最终就成了一个n×4096为的特征矩阵, n就是总共截取的帧数. LS-HAN ModelHAN(Hierarchical Attention Network) 是LSTM的一种扩展, 主要针对输入数据使用了注意力机制. 模型的损失函数同时考虑了视频与句子之间的相关性误差 $E_r$, 以及HAN的识别误差 $E_c$. \min_{\theta_r, \theta_c} \frac{1}{N}上式中, N 代表了训练集中的实例数量, $V^{(i)},S^{(i)}$ 代表第 $i$ 个视频实例(注意这里不是截图)和句子, $\theta_r, \theta_c$ 分别代表隐式空间和HAN的参数. R是正则项. $\lambda_1, \lambda_2$ 用于调节这三项的权重占比. 下面对这个损失函数的每一项具体介绍 视频和句子之间的隐式空间如图2所示，我们模型框架的输入是视频和对应标注好的句子。视频用提取到的global-local特征表示，句子中的每一个单词都用one hot向量表示。我们令视频为 $V=(v_1,v_2,…,v_n)$, 令句子为 $S=(s_1,s_2,…,s_m)$, 这里每一个 $v_i$ 都代表的是视频中的一个截图的特征向量, n表示总共的截图数量, $s_i$ 表示句子中的每一个单词的one-hot向量,m为单词数目. 隐式空间的目标就是构建一个”空间”, 在这个空间里面, 可以建立起视频截图特征向量和句子单词onehot向量之间的联系, 也就是说, 我们要将 $V$ 和 $S$ 映射到同一个隐式空间中去, 于是, 映射后的视频截图和句子可以表示成: $f_v(V) = (v_1’, v_2’, …,v_n’)$ 和 $f_s(S) = (s_1’, s_2’,…,s_m’)$ 这里, $f_v$ 和 $f_s$ 分别对应这一个映射函数, 可以用矩阵表示: f_v(x) = T_vx, f_s(x) = T_s x其中, 权重矩阵 $T_v \in R^{D_s\times D_c}$, $T_s \in R^{D_s\times D_w}$, $D_s$ 就是隐式空间的维度. 接下来, 我们就需要衡量 $f_v(V)$ 和 $f_s(S)$ 之间的相关程度. 用DTW(Dynamic Time Warping)算法来找到最小的累加和距离,同时还会考虑时域的路径. (因为视频片段和word基本是一一对应的) D[i,j] = min(D[i-1, j], D[i-1, j-1]) + d(i,j)d(i,j) = \|T_vv_i - T_s s_j\|_ 2上式中, $D[i,j]$ 代表了 $(v_1’,…v_i’)$ 和 $(s_1’,…s_j’)$ 的距离, 而$d(i,j)$ 则代表了 $v_i’$ 和 $s_j’$ 之间的距离(二范式). 于是, 我们将视频实例和一个句子之间的损失定义为: E_r(V,S;\theta_r) = D(n,m)上面的DTW算法有一个假设前提, 那就是如果句子中的单词出现在前面, 那么与这个单词对应的视频片段也应该出现在前面. 正常来说这样的假设不是特别合理, 比如说对于视频描述这个任务来说, 这个假设就很不合适, 但是手语识别他有自身的特殊性, 在进行短句子的手语动作时, 这种假设是可行的, 而这篇文章使用的数据集中的句子都不超过10个词, 所以这里我们就暂时认为这个假设是对的吧. 上面还有个warping path的概念, 实际上就调整视频和句子之间的对齐程度. 上面公式的具体实现不是贪心, 而是基于回溯的, 所以最后找到的就是最小的. 隐式空间的目标是建立连接语义鸿沟的空间。 将视频截图和句子映射到同一个隐式空间中。 Dynamic Time Warping（DTW）算法：衡量 $f_v 和 f_s$之间的相关性。 Recognition with HAN受到最近sequence to sequence模型的启发，识别问题可以看作是在给定video的情况下，求句子的log条件分布率的估计。（LSTM）。 首先，输入帧序列通过隐式空间进行编码，然后，根据每一个帧序列的特征向量来预测对应的单词。 扩展HAN中的编码器使其能够反应多级结构(从clips到word, 或者从word到clips)，同时引入注意力机制。 如图4所示, 蓝色的输入分别代表隐式空间中的clips序列特征和words序列特征. 可以看出, 该模型包含两个编码器和一个解码器。每一个编码器都是一个带有注意力机制的 bidirectional LSTM，而解码器一个单独的LSTM。 clip编码器将视频截图编码，使其对齐到单词向量上。如图5所示, 本文在经验上选取了3种对齐机制：（实验证明3比较好，因为本文选择3） 将clips分成两个子序列 (总共就两个word) 每两个clips分出一个子序列 (总共有L/2个word) 均分出7个子序列（因为在训练集中的句子平均含有7个单词）。 经过编码以后, 会生成对应的特征表示向量, 然后就需要进行解码, 在解码的时候我们是知道标注的真实句子信息的, 首先 #START 表示开始符号, 根据隐式向量的特征表示, LSTM会先预测第一个单词 $y_1$, 然后, 继续用LSTM在当前处的输出 $h_t$ 和第一个真实单词’the’的onehot向量来预测第二个单词, 就是这样一直下去, 直到遇到#END为止. 用Softmax函数在输入为 $h_t$ 下条件下输出 $y_t$ 的概率 (概率最大的那个就是当前cell的输出): p(y_t | h_t)这一部分的损失函数为(这里这个是log损失函数, 如果预测结果是正确项的条件概率越接近于1, 则log对应项就越小): E_c(V,S;\theta_r, \theta_c)Learning and Recognition of LS-HAN Model最终, 我们的损失函数可以写成下面这样: \min_{T_v,T_s,\theta}在进行训练优化时, 分别对隐式空间的参数 $T_v, T_s$ 和HAN的参数 $\theta$ 求偏导 实验数据总共有两个开源数据，一个是CSL，另一个是德国手语数据集RWTH-PHONEIX-Weather。 CSL包含25k个标注的视频实例，总共超过100小时，共50位手语者。17K用于训练，2K用于验证，6K用于测试。每一个视频实例都会与一个完整的句子相关联. RWTH-PHONEIX-Weather包含7K天气预测的句子，共9位手语者。 所有的视频均为25帧每秒，分辨率为210×260 。 5672用于训练, 540用于验证, 629用于测试. 实验设置每一段视频都会被分成16帧, 要么缩放, 要么裁剪, 输入大小为 227×227. 输出是4096长度的一维向量, 正如前面介绍的那样. Evaluation Metircs 评价标准Accuracy = 1 - \frac{S + I + D}{N} \times 100%上式中, SID分别代表将预测句子转换成真实句子所需要的最少的替换(substitution), 插入(insertion)和删除(deletion)操作, N代表句子的真实长度. 注意, 由于这三种操作都会降低准确率, 因此准确率是有可能为负值的 (顺便我还感觉这个评价标准也太粗糙了, 感觉不是精心设计过的标准, 但是貌似还有人用, 而且一般好的实验都是会用很多不同标准横向纵向去比较的, 所以我感觉作者只用这一个评价标准, 要么就是手语识别没有特别好, 特征规范的通用标准, 要么就是作者在别的标准上表现不好, 这个表现我也没太查到, 所以也只是猜测.). 实验结果和分析先来看表2, 因为本文的方法主要是基于LSTM来做的, 因此, 第一部分是各种LSTM的变种方法, 这些变种方法基本都不是用来解决手语识别问题的, 所以精度差是自然的(我也不知道作者为啥要这么比, 感觉有点不公平). 再看第二部分, 第二部分确确实实都是针对手语识别问题, 而且都是针对连续手语识别问题, 但是这些方法居然比第一部分的还低, 这我就有点搞不懂了, 然后我看到这个年份, 我就感觉这个数据怎么这么奇怪啊, 07年到14年这都7年的时间就提升了0.01, 我就感觉匪夷所思. 我感觉这篇文章整个的模型结构和设计思路还是挺不错的, 但是这个实验部分就真的支撑数据让人有点不信服. 表3: 这个表3看起来勉强还行, 是和最近发表的paper方法比较的, 这个精度提升确实不高. HAN和LS的关系]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[argparse-命令行解析模块]]></title>
    <url>%2Fz_post%2FPython-argparse%2F</url>
    <content type="text"><![CDATA[官方文档 https://docs.python.org/3/library/argparse.html http://www.cnblogs.com/lovemyspring/p/3214598.html ArgumentParserArgumentParser objectshttps://docs.python.org/3/library/argparse.html#argparse.ArgumentParser1class argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True) Create a new ArgumentParser object. All parameters should be passed as keyword arguments. Each parameter has its own more detailed description below, but in short they are: prog - The name of the program (default: sys.argv[0]) usage - The string describing the program usage (default: generated from arguments added to parser) description - Text to display before the argument help (default: none) epilog - Text to display after the argument help (default: none) parents - A list of ArgumentParser objects whose arguments should also be included formatter_class - A class for customizing the help output prefix_chars - The set of characters that prefix optional arguments (default: ‘-‘) fromfile_prefix_chars - The set of characters that prefix files from which additional arguments should be read (default: None) argument_default - The global default value for arguments (default: None) conflict_handler - The strategy for resolving conflicting optionals (usually unnecessary) add_help - Add a -h/—help option to the parser (default: True) allow_abbrev - Allows long options to be abbreviated if the abbreviation is unambiguous. (default: True) add_argumenthttps://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument12ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])Define how a single command-line argument should be parsed. Each parameter has its own more detailed description below, but in short they are: name or flags - Either a name or a list of option strings, e.g. foo or -f, —foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. dest - The name of the attribute to be added to the object returned by parse_args(). 最常用法示例123456789101112131415import argparseparser = argparse.ArgumentParser(description="PyTorch Detection")parser.add_argument( "--config-file", # 这里虽然是 config-file, 但需要用 args.config_file来访问, 但是不能用 args.config-file 访问. dest="cfg_file", # 可以用 args.cfg_file 来访问该参数, 比 args.confi-file简洁 type=str, # 类型 default="", # 参数的默认值 choices=["option1", "option2"] # 只能选择其一 metavar="FILE", # 可以在命令行中替代 --config-file help="path to config file", # 帮助信息 nargs=1, # 参数的个数, 默认为1) 12345parser.add_argument( "opts", # 前面没有'--' default=None, nargs=argparse.REMAINDER # 这一行不能少, 否则会报错)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十四章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter14%2F</url>
    <content type="text"><![CDATA[第十四章 C++中的代码重用除了公有继承之外，还有其他促进代码重用的方法： 包含/组合/层次话：在类中使用另一个类的对象做成员 私有或保护继承：用于实现has-a关系，即新的类将包含另一个类的对象 14.1 包含对象成员的类string类 valarray类：这是一个模板类 14.2 私有继承另一种实现has-a关系的途径——私有继承。 使用私有继承，基类的公有成员和保护成员都将成为派生类的私有成员。这意味着基类方法将不会成为派生对象公有接口的一部分，但可以在派生类的成员函数中使用它们。 “包含”是将对象作为一个命名的成员添加到类中，而“私有继承”将对象作为一个未被命名的继承对象添加到类中。 初始化基类组件，对于继承类，需要使用成员初始化列表语法，使用类名而不是成员名称来标识构造函数。 访问基类的方法：可以通过将私有的成员函数包含在一个公有函数中来访问该私有方法。 访问基类对象：通过this指针和强制类型转换来创建对应的对象或引用 访问基类的友元函数：用类名显式的限定函数名不适合友元函数，这是因为友元不属于类。然而，可以通过显式的转换为基类来调用正确的函数。 14.2.2 使用包含还是私有继承。通常，应使用包含来建立has-a关系。如果新类需要访问原有类的保护成员，或需要重新定义虚函数，则应使用私有继承。 14.2.3 保护继承保护继承是私有继承的变体。使用保护继承时，基类的公有成员和保护成员都将成为派生类的保护成员。 当从派生类派生出另一个类时，私有继承和保护继承之间的区别在于： 使用私有继承时，第三代类将不能使用基类的接口，这是因为继承的公有方法在派生类中将变成私有方法。使用保护继承时，基类的公有方法在第二代中将变成受保护的，因此第三代派生类可以使用它们。 各种继承方式: 特征 公有继承 保护继承 私有继承 公有成员变成 派生类的公有成员 派生类的保护成员 派生类的私有成员 保护成员变成 派生类的保护成员 派生类的保护成员 派生类的私有成员 私有成员变成 只能通过基类接口访问 只能通过基类接口访问 只能通过基类接口访问 能否隐式向上转换 能 能（但只能在派生类中） 否 隐式向上转换（implicit upcasting）：意味着无需进行显式类型转换，就可以将基类指针或引用指向派生类对象。 14.2.4 使用using重新定义访问权限使用保护派生或私有派生时，基类的公有成员将成为保护成员或私有成员。假设要设即为的方法在派生类外面可用，方法之一是定义一个使用该基类方法的派生类方法。 另一种方法是，将函数调用包装在另一个函数调用中，即使用一个using声明来指出派生类可以使用特定的基类成员，即使采用的是私有派生。例如，假设希望通过Student类能够使用valarray的方法min()和max()，可以如下书写：12345class Student: private std::string, private std::valarray&lt;double&gt;&#123; public: using std::valarray&lt;double&gt;::min; using std::valarray&lt;double&gt;::max;&#125; 注意：using声明只使用成员名——没有圆括号、函数特征表和返回类型。 有一种老式的不带using声明的方法，它看起来就像是不包含关键字using的using声明，但是这种方法已被摒弃，即将体制使用。 14.3 多重继承MI描述的是有多个直接基类的类，与单继承一样，公有MI表示的也是is-a关系。例如，可以从Waiter类和Singer类派生出SingingWaiter类。 私有MI和保护MI可以表示has-a关系。 MI可能会带来很多新问题，其中最重要的问题是： 从两个不同的基类继承同名方法; 从两个或更多相关基类那里继承同一个类的多个实例。 14.3.1 有多少个Work如果多个类来自于同一个基类，而当前类又继承这多个类，那么，就会有多个最原始的基类副本，者造成了二义性。 为了解决以上问题，C++引入了一种新技术——虚基类（virtual base calss），使MI成为可能。 虚基类：虚基类使得从多个类（它们的基类相同）派生出的对象之只继承一个基类对象。 新的构造函数规则：使用虚基类时，需要对类构造函数采用一种新的方法。对于非虚基类，唯一可以出现在初始化列表中的构造函数是即时基类构造函数。但这些构造函数可能需要将信息传递给其基类。（详细请看p558） 14.3.2 哪个方法因为多重继承，有时会继承多个同名方法，因此，需要指出使用哪一个方法。 可以使用作用域解析运算符来指定使用的方法：12SingingWaiter newhire("Elise", 2005, 6, soprano);newhire.Singer::Show(); 然而，更好的方法是在SingingWaiter中重新定义Show()，并指出要使用哪个Show()。如下所示： 123void SingingWaiter::Show()&#123; Singer::Show;&#125; 对于多继承，使用模块化的方式而不是递增方式来在派生类的同名函数中使用基类函数，即提供一个只显示Work组件的方法和一个只显示Waiter组件 或 Singer组件的方法。然后，在SingingWaiter::Show()方法中将组件组合起来。详细见p559。 总结： 在祖先相同时，使用MI必须引入虚基类，并修改构造函数初始化列表的规则。 下面介绍一些有关MI的问题。 混合使用虚基类和非虚基类 当类通过多条虚途径和非虚途径继承某个特定的基类时，该类将包含一个表示所有的虚途径的基类子对象和分别表示各条非虚途径的多个基类子对象。 虚基类和支配 派生类中的名称优先于直接或间接祖先类中的相同名称。 如果无法用优先规则判断出使用哪个名称，则会导致二义性。 14.4 类模板C++的类模板为生成通用的类声明提供了一种更好的方法（C++最初不支持模板，单模板被引入后，就一直在演化，因此有的编译器可能不支持这里的所有特性）。模板提供参数化（parameterized）类型，即能够将类型名作为参数传递给接收方来建立类或函数。 C++库提供了多个模板类，如vector、array、valarray等等。 14.4.1 定义类模板模板类以下面这样的代码开头：1234567template &lt;class T&gt;class Stack&#123;private: ...public: ...&#125;; 这里使用class并不意味着Type必须是一个类，而只是表明Type是一个通用的类型说明符，在使用模板时，将使用时间的类型替换它。较新的C++实现推荐使用关键字typename来代替class。 当模板被调用时，Type将被具体的类型值（如int或string）取代。 同样，可以使用模板成员函数替换原有类的类方法，每个函数头都将以相同的模板声明打头（如果在类声明中定义了方法，即内联定义，则可以省略模板前缀和类限定符：1234template &lt;typename T&gt;bool Stack&lt;T&gt;::push(const T&amp; item)&#123; ...&#125; 注意： 模板声明本身并不是类和成员函数，它们属于C++编译器指令，说明了如何生成对应的类和成员函数定义。而模板的具体实现则被称为实例化（instantiation）或具体化（specialization）。 不能将模板成员函数放在独立的实现文件中（以前，C++标准确实提供了关键字export，让您能够将模板成员函数放在独立的实现文件中，但支持该关键字的编译器不多，C++11不再这样使用export，而是将其保留用于其他用途）。 由于模板不是函数，它们不能单独编译，模板必须与特定的模板实例化请求一起使用。为此，最简单的方法是就所有模板信息放在一个头文件中，并在要使用这些模板的文件中包含该头文件。 14.4.2 使用模板类可以用所需的具体类型替换泛型名，就可以声明一个类型为模板类的对象： 12Stack&lt;int&gt; kernels;Stack&lt;string&gt; colonels; 注意，必须显式的提供所需的类型，这与常规的函数模板是不同的，因为编译器可以根据函数的参数类型来确定要生成哪种函数。 14.4.3 深入探讨模板类关于使用指针在作为Stack的类型，比如用字符指针替换string来作为T类型。这样会带来一些问题。 char* s：单纯的char* s并没有给s分配合适的空间，这会使s的值存在某些不合适的内存单元中 char s[40]：这虽然分配了空间，但是s的大小固定，且s本身是数组名，虽然代表地址，但是无法进行运算，有些操作会引起冲突。 char* po = new char[40]：这次分配了空间，po也成为了变量，但仍有问题，具体看p573。 但是并不是说不能使用指针作为T，只是在使用时，需要多家注意，考虑谨慎。 14.4.4 数组模板示例和非类型参数使用非类型参数来说模板达到某些目的 12345678910template &lt;typename T, int n&gt;class ArrayTP&#123;private: ...public: ...&#125;;ArrayTP&lt;double,12&gt; one;ArrayTP&lt;double,13&gt; two; 表达式参数方法的主要缺点是，每组数组的大小都将生成自己的模板，而利用构造函数的方法只会生成一个类声明，并将数组大小信息传递给类的构造函数，详细见p578。 14.4.5 模板多功能性可以将常规类的技术用于模板类，模板类可以用作基类，也可用作组件类，还可用作其他模板的类型参数。 递归使用模板 使用多个类型参数 12345678910template &lt;typename T1, typename T2&gt;class Pair&#123;private: T1 a; T2 b;public: T1&amp; first(); T2&amp; second(); ...&#125;; 默认模板参数 可以为类型参数提供默认值：1template &lt;class T1, class T2 = int&gt; class Topo&#123;...&#125;; 14.4.6 模板的具体化模板以泛型的方式描述类，而具体化是使用具体的类型生成类声明。 隐式实例化（implicit instantiation） &emsp;&emsp;声明一个或多个对象，指出所需的类型，编译器使用通用模板提供的处方生成具体的类定义： 1ArrayTP&lt;int, 100&gt; stuff; &emsp;&emsp;编译器在需要对象之前，不会生成类的隐式实例化，如下面的代码，第二条语句才会使编译器生成类定义，并根据定义创建一个对象12ArrayTP&lt;double, 30&gt; *pt;pt = new ArrayTP&lt;double, 30&gt;; 显式实例化（explicit instantiation） &emsp;&emsp;当使用关键字template并指出所需类型来声明类时，编译器将生成类声明的显式实例化。在这种情况下，孙然没有创建或提及类对象，编译器也将生成类声明（包括方法定义）。和隐式实例化一样，也将根据通用模板来生成具体化。（这里没搞懂）1template class ArrayTP&lt;string, 100&gt;; 显式具体化（explicit specialization） &emsp;&emsp;显式具体化是特定类型（用于替换模板中的泛型）的定义。有时候，可能需要在为特殊类型实例化时，对模板进行修改，使其行为不同。在这种情况下，可以创建显式具体化。（这块也没看懂） &emsp;&emsp;另外，假设模板是用&gt;运算符来对值进行比较，对于数字，管用。如果T表示一个type，则只要定义了T::operator&gt;()方法，这也管用。但如果T是由const char*表示的字符串，这将不管用。实际上，模板倒是可以正常工作，但字符串将按地址（按照字母顺序）排序。这要求类定义使用strcmp()，而不是&gt;来对值进行比较。 部分具体化（partial specialization） &emsp;&emsp;C++允许部分具体化，即部分限制模板的通用性。例如，可以给类型参数之一指定具体类型，下面的代码将T2具体化为int，但T1保持不变：1234//general templatetemplate &lt;class T1, class T2&gt; class Pair &#123;...&#125;;//specialization with T2 set to inttemplate &lt;class T1&gt; class Pair&lt;T1, int&gt; &#123;...&#125;; 14.4.7 成员模板模板可用作结构、类或模板类的成员。要完全实现STL的设计，必须使用这项特性。 14.4.8 将模板作为参数模板除了可以包含类型参数（typename T）和非类型参数（int n）之外，还可以包含本身就是模板的参数，如下所示：123template &lt;template &lt;typename T&gt; class Thing&gt; class Crab//其中，template&lt;typename T&gt;class是类型，Thin是参数 14.4.9 模板类和友元模板类声明也可以有友元。模板的友元分三类： 非模板友元 1234567template &lt;class T&gt;class HasFriend&#123;public: friend void counts(); //(1) friend void report(HasFriend &amp;); //(2) 错误 friend void report(HasFriend&lt;T&gt; &amp;); //(3) 正确&#125; &emsp;&emsp;上述代码中的（1）式在模板中将一个常规函数声明为友元，该声明使counts()函数成为模板所有实例化的友元，counts()函数不是通过对象调用的（它是友元，不是成员函数），也没有对象参数。它通过以下几种方式访问HasFriend对象：访问全局对象;使用全局指针访问非全局对象;创建自己的对象;访问独立于对象的模板类的静态数据成员。如果要为友元函数提供模板类参数，则不能通过（2）式来达到目的，原因是不存在HasFriend这样的对象，而只有特定的具体化，如HasFriend&lt;short&gt;，这里short可以用T表示，因为参数传递时就会指明T的类型，因此，要提供模板类参数，必须指明具体化。 约束（bound）模板友元，即友元的类型取决于类被实例化时的类型1234567891011//（1）template &lt;typename T&gt; void counts();template &lt;typename T&gt; void reprot(T&amp;);//（2）template &lt;typename T&gt;class HasFriendT&#123; ... friend void counts&lt;TT&gt;(); friend void report&lt;&gt;(HasFriendT&lt;TT&gt; &amp;);&#125;; &emsp;&emsp;使友元本身成为模板，使累得每一个具体化都获得与友元匹配的具体化，包含三步：首先，在类定义之前声明每个模板函数，如（1）所示，然后，在函数中再次将模板声明为友元，声明中的&lt;&gt;指出这是模板具体化，对于report()，&lt;&gt;可以为空，因为可以从函数参数推断出如下模板类型参数：HasFriendT&lt;TT&gt;，也可以写完整：report&lt;HasFriendT&lt;TT&gt; &gt; (HasFriendT&lt;TT&gt; &amp;)。但counts函数没有参数，因此必须使用模板参数语法&lt;TT&gt;来指明具体化。最后一步是友元提供模板定义。 非约束（unbound）模板友元，即友元的所有具体化都是类的每一个具体化的方式 12345template &lt;typename T&gt;class ManyFriend&#123; ... template &lt;typename C, typename D&gt; friend void show2(C&amp;, D&amp;);&#125;; &emsp;&emsp;对于非约束友元，友元模板类型参数与模板类类型参数是不同的，如上代码所示。 14.4.10 模板别名（C++11）可以使用typedef为模板具体化指定别名：1234567//define three typedef aliasestypedef std::array&lt;double,12&gt; arrd;typedef std::array&lt;int, 12&gt; arri;typedef std:array&lt;std::string,12&gt; arrst;arrd gollons;arri days;arrst months; C++11提供了一种新的可以简化上述任务的方法——使用模板提供一系列别名，如下所示：123456template&lt;typename T&gt; using arrtype = std::array&lt;T,12&gt;;//这将arrtype定义为一个模板别名，可以使用它来指定类型，如下所示arrtype&lt;double&gt; gallons;arrtype&lt;int&gt; days;arrtype&lt;std::string&gt; months;//总之， arrtype&lt;T&gt; 就表示类型 std::array&lt;T,12&gt;]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入应用C++11——代码优化与工程级应用》]]></title>
    <url>%2Fz_post%2FCpp-Book-%E6%B7%B1%E5%85%A5%E5%BA%94%E7%94%A8Cpp11%2F</url>
    <content type="text"><![CDATA[第一章 使用C++11让程序更简洁、更现代1.1 类型推导C++11引入了auto和decltype关键字实现类型推导。 1.1.1 auto类型推导1、auto关键词的新意义auto 可用于隐式类型定义。 不同于Python等动态类型语言（运行时才确定数据类型），隐式类型定义的类型推导发生在编译器。（C++是静态类型语言） 使用auto声明的变量必须立刻初始化，以让编译器推断出它的实际类型，并在 编译 时将auto占位符替换为真正的类型。 2、auto的推导规则 当不声明为指针或引用时，auto的推导结果会将初始化表达式的引用和cv限定符抛弃 当声明为指针或引用时，auto的推导结果将保持初始化表达式的cv属性。 3、auto的限制 auto不能用于函数参数 auto不能用于非静态成员变量 auto无法定义数组 auto无法推导出模板参数 4、什么时候用auto 当类型的名称很长时，可以用auto简化代码 当不确定变量应用被定义成什么类型时，如泛型函数的参数类型。 注意： auto虽然好用，但是不应该过度使用，否则，会严重降低代码的可读性和可维护性。 1.1.2 decltype1、获知表达式的类型 decltype关键字用于在编译时推导出一个表达式的类型，其语法格式为decltype(exp)，该关键字并不会真正计算表达式的值。 2、decltype的推导规则 当exp是标识符、类访问表达式时，decltype(exp)和exp的类型一致 当exp是函数调用时，decltype(exp)和返回值的类型一致 其他情况，若exp是一个左值，则decltype(exp)是exp类型的左值 引用 ，否则和exp类型一致。 3、decltype的实际应用 decltype的应用多出现在泛型编程中。 decltype也经常用在通过变量表达式抽取变量类型上。 1.1.3 返回类型后置语法——auto和decltype的结合使用]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的引用]]></title>
    <url>%2Fz_post%2FCpp-%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是引用? 声明和使用引用时要注意哪些问题?引用就是某个变量的”别名”(alias). 声明一个引用的时候, 切记要对其进行初始化. 声明完毕后, 相当于目标变量具有了两个名称, 即原名称和引用名, 引用名与该变量绑定, 不能再把该引用名作为其他变量名的别名. 对引用求地址, 就是对目标变量取地址, 即我们常说引用名是目标变量名的一个别名. 注意, 引用是不占据空间的, 虽然编译器一般将引用实现为const指针, 即指向位置不可变的指针. 但是一般编译器对引用会设置一些限制条件, 因此从程序员的角度来说, 我们认为引用就是别名, 也就是它不占据空间. 不能建立引用的数组. 因为数组是一个由若干个元素所组成的集合, 所以无法建立一个由引用组成的集合. 但是可以建立数组的引用(即数组的别名) 12345int x=2,y=3,z=4;int&amp; ref[3] = &#123;&amp;x, &amp;y, &amp;z&#125;; //非法!int arr[3]&#123;1,2,3&#125;;int(&amp;ref) [3] = arr; //合法, ref是一个引用, 指向一个包含3个元素的一维数组 引用和指针的关系与区别?关系:编译器一般会将引用实现为const指针, 所以可以将引用看做是一种特殊的指针 区别: 指针也是一种变量, 引用则是变量的别名 指针可以先声明再赋值, 引用必须在定义的同时初始化 指针可以重新指向其他变量, 引用一旦绑定就无法更改(行为上更像是常量指针) 指针占用内存大小, 而引用不占内存大小(编译器会限制对引用的操作, 使得在程序员角度看来, 引用就是别名, 不占内存) C++ PrimerPlus中对 对象 的定义是: 一块能存储数据并具有某种类型的内存空间. 也就是说, 一个对象, 它拥有 值 和 地址 两种属性, 在运行程序时, 计算机会为该对象分配存储空间, 来存储该对象的值, 我们可以通过该对象的地址, 来访问这一块存储空间中的值. 在 C++ 中, 指针 实际上也是一种 对象, 它同样拥有 值 和 地址 两种属性, 只不过指针存储的数据类型是其他对象的地址, 当我们想要通过来地址访问其他对象时, 就要使用”*“来访问. 而对象有常量和变量之分, 指针也一样, 在 C++ 中, 常量指针是指这个指针的值是不可改变的, 也就是它所存储的地址是不可以改变的, 而指向常量的指针是指不能通过该指针来改变这个指针所指向的对象. 引用在行为上就更像是常量指针, 我们可以把它理解成是变量的别名, 在定义一个引用的时候, 程序时把该引用和它的初始值绑定在一起, 也就是说, 我们在定义引用的同时, 就必须对其进行初始化, 并且, 引用一经声明, 就不可以再与其他的变量绑定. 将引用作为函数参数有哪些特点? 由于引用可以看做是const指针, 因此传递引用给函数和传递指针给函数的效果是一样的, 这时, 被调函数的形参就成为原来主调函数中的实参变量或对象的一个别名来使用, 所以在被调函数中对形参变量的操作就是对其相应的目标对象的操作. 使用引用传递参数时, 在内存中并不会产生实参的副本, 因此, 当参数传递的数据较大时, 用引用的空间利用率高 将引用作为函数返回值类型的优势和注意事项?优势:在内存中不会产生被返回值的副本 ( 注意: 正是因为这个原因, 所以返回一个局部变量的引用是不可取的. ) 注意事项: 不能返回局部变量的引用: 因为在内存中不会产生被返回值的副本, 随着该局部变量生存期的结束, 引用指向的变量就失效了, 此时会产生runtime error错误. 不要返回函数内部new分配的内存的引用: 虽然不存在局部变量的自动销毁问题, 但是对于这种情况, 又是会面临其他尴尬局面. 例如, 被函数返回的引用只是作为一个临时变量出现, 而没有被赋予一个实际的变量, 那么这个引用所指向的空间(由new分配)就无法释放 很容易造成内存泄漏. 可以返回对象成员的引用, 但最好是const. 主要原因是当对象的属性与某种业务规则相关联的时候, 其赋值常常与某些其他属性或者对象的状态有关, 因此有必要将赋值操作封装在一个业务规则中. 如果其他对象可以获得该属性的非常量引用(或指针), 那么对该属性的单纯赋值会破坏业务规则的完整性. 引用和流操作符的重载, 因为这两个操作符常常希望被连续使用, 因此这两个操作符重载时的返回值应该是一个仍然支持操作符特性的流引用 http://wyude.lofter.com/post/1cb19406_68f16ad 在什么时候需要使用常引用?如果既要利用引用提高程序的效率, 又要保护传递给函数的数据不在函数中被改变, 就应该使用常引用, 同时如果传入的实参是const类型的变量, 则形参必须也声明为const. 通常, 如果引用型参数在能够被定义为const的情况下, 优先定义为const. 什么是右值引用?左值引用就是对一个左值进行引用的类型。右值引用（C++11新特性）就是对一个右值进行引用的类型，事实上，由于右值通常不具有名字，我们也只能通过引用的方式找到它的存在。 右值引用和左值引用都是属于引用类型。无论是声明一个左值引用还是右值引用，都必须立即进行初始化。而其原因可以理解为是引用类型本身自己并不拥有所绑定对象的内存，只是该对象的一个别名。左值引用是具名变量值的别名，而右值引用则是不具名（匿名）变量的别名。 左值引用通常也不能绑定到右值，但 常量左值引用 是个“万能”的引用类型。它可以接受非常量左值、常量左值、右值对其进行初始化。不过常量左值所引用的右值在它的“余生”中只能是只读的。相对地，非常量左值只能接受非常量左值对其进行初始化。 1234567int &amp;a = 2; # 左值引用绑定到右值，编译失败int b = 2; # 非常量左值const int &amp;c = b; # 常量左值引用绑定到非常量左值，编译通过const int d = 2; # 常量左值const int &amp;e = d; # 常量左值引用绑定到常量左值，编译通过const int &amp;&amp;b =2; # 常量左值引用绑定到右值，编程通过 右值引用本质上也是一种引用，只是它必须且只能绑定在右值上。由于右值引用只能绑定在右值上，而右值要么是字面常量，要么是临时对象，所以： 右值引用的对象，是临时的，即将被销毁 右值引用的对象，不会在其他地方使用 这两个特性意味着：接受和使用右值引用的代码，可以自由的接管所引用对象的资源，而无需担心对其他代码逻辑造成数据破坏 右值值引用通常不能绑定到任何的左值，要想绑定一个左值到右值引用，通常需要std::move()将左值强制转换为右值，例如： 123456int a=2;int b=1;int &amp;&amp;r1 = 3; //编译通过，右值引用可以绑定到字面常量上int &amp;&amp;r2 = a+b; //编译通过，右值引用可以绑定到临时变量上int &amp;&amp;r3 = a; # 编译失败int &amp;&amp;r4 = std::move(a); # 编译通过 右值引用本身是左值右值引用本身是左值，通过下面的代码，我们发现，可以通过右值引用的名字得到他的地址，因此，右值引用本身就是左值：12int&amp;&amp; r1 = 2;std::cout&lt;&lt;&amp;r1; //编译通过，输出r1的地址 下表列出了在C++11中各种引用类型可以引用的值的类型。值得注意的是，只要能够绑定右值的引用类型，都能够延长右值的生命期。 左值、右值的概念:C++11 对 C++98 中的右值进行了扩充。在C++11中右值又分为纯右值（prvalue，Pure Rvalue）和将亡值（xvalue，eXpiring Value）。在C++11中可以取地址的的就是左值，反之，不能取地址的、没有名字的就是右值（将亡值或纯右值）。举个例子，int a = b+c, a 就是左值，其有变量名为a，通过&amp;a可以获取该变量的地址；表达式b+c、函数int func()的返回值是右值，在其被赋值给某一变量前，我们不能通过变量名找到它，＆(b+c)这样的操作则不会通过编译。纯右值的概念等同于我们在C++98标准中右值的概念，指的是临时变量和不跟对象关联的字面量值； 左值与右值的根本区别在于是否允许取地址&amp;运算符获得对应的内存地址 将亡值 是C++11新增的跟右值引用相关的表达式，这样表达式通常是将要被移动的对象（移为他用），比如返回右值引用T&amp;&amp;的函数返回值、std::move的返回值，或者转换为T&amp;&amp;的类型转换函数的返回值。右值引用本身就是一个xvalue。 不能根据在等号左边还是右边来判断左值和右值左值出现在等号右边的情况：12int a = 2;int c = a; 右值出现在等号左边的情况（不能作为赋值的对象，赋值没有意义）：1((i&gt;0) ? i : j) = 1; 右值、将亡值在理解C++11的右值前，先看看C++98中右值的概念：C++98中右值是纯右值，纯右值指的是临时变量值、不跟对象关联的字面量值。临时变量指的是非引用返回的函数返回值、表达式等，例如函数int func()的返回值，表达式a+b；不跟对象关联的字面量值，例如true，2，”C”等。将亡值可以理解为通过“盗取”其他变量内存空间的方式获取到的值。在确保其他变量不再被使用、或即将被销毁时，通过“盗取”的方式可以避免内存空间的释放和分配，能够延长变量值的生命期。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译型语言、解释型语言、静态类型语言、动态类型语言的概念与区别]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E7%BC%96%E8%AF%91%E5%9E%8B%E8%AF%AD%E8%A8%80%E3%80%81%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80%E3%80%81%E9%9D%99%E6%80%81%E7%B1%BB%E5%9E%8B%E8%AF%AD%E8%A8%80%E3%80%81%E5%8A%A8%E6%80%81%E7%B1%BB%E5%9E%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[编译型语言和解释型语言1、编译型语言需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。 优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。 缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。 代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift 2、解释型语言解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。 优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。 缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。 代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby 3、混合型语言既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。比如C#,C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行（博友回复指出）。 Java先生成字节码再在Java虚拟机中解释执行。 严格来说混合型语言属于解释型语言。C#更接近编译型语言。 动态语言和静态语言1、动态语言是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。 主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。 2、静态语言与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。 3、注意：很多人认为解释型语言都是动态语言，这个观点是错的！Java是解释型语言但是不是动态语言，Java不能在运行的时候改变自己结构。反之成立吗？动态语言都是解释型语言。也是错的！Object-C是编译型语言，但是他是动态语言。得益于特有的run time机制（准确说run time不是语法特性是运行时环境，这里不展开）OC代码是可以在运行的时候插入、替换方法的。 C#也是动态语言，通过C#的反射机制可以动态的插入一段代码执行。 动态类型语言和静态类型语言1、动态类型语言很多网上资料把动态类型语言和动态语言混为一谈，简直是误人子弟。动态类型语言和动态语言是完全不同的两个概念。动态类型语言是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态语言说的是运行时改变结构，说的是代码结构。 动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。（Python只有到了运行时才能确定某一个变量的具体类型） 主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。 2、静态类型语言 静态语言的数据类型是在编译其间确定的或者说运行之前确定的，是在编译阶段就完成的，编写代码的时候要明确确定变量的数据类型。 主要语言：C、C++、C#、Java、Object-C。 3、注意：相当一部分程序员，认为解释型语言都是动态类型语言，编译型语言都是静态类型语言。这个也是错的。swift是编译型语言但是它也是动态类型语言。C#和Java是解释型语言也是静态类型语言。 强类型语言和弱类型语言1、强类型语言：强类型语言，一旦一个变量被指定了某个数据类型，如果不经过强制类型转换，那么它就永远是这个数据类型。你不能把一个整形变量当成一个字符串来处理。 主要语言：Java、C#、Python、Object-C、Ruby 2、弱类型语言：数据类型可以被忽略，一个变量可以赋不同数据类型的值。一旦给一个整型变量a赋一个字符串值，那么a就变成字符类型。 主要语言：JavaScript、PHP、C、C++（C和C++有争议，但是确实可以给一个字符变量赋整形值，可能初衷是强类型，形态上接近弱类型） 3、注意：一个语言是不是强类型语言和是不是动态类型语言也没有必然联系。Python是动态类型语言，是强类型语言。JavaScript是动态类型语言，是弱类型语言。Java是静态类型语言，是强类型语言。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[visdom-数据可视化工具(支持PyTorch和Numpy)]]></title>
    <url>%2Fz_post%2FPyTorch-visdom%2F</url>
    <content type="text"><![CDATA[https://zhuanlan.zhihu.com/p/32025746visdom 是一个灵活的可视化工具, 可用来对实时, 大量的数据进行分析, 组织, 共享等, 还可以实现 远程 数据的可视化. 几个基本概念]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[glob模块-文件路径查找]]></title>
    <url>%2Fz_post%2FPython-glob%2F</url>
    <content type="text"><![CDATA[glob模块是Python最简单的模块之一, 内容非常少, 用它可以查找符合特定规则的文件路径名, 查找文件时只会用到三个匹配符: * : 匹配0个或多个字符 ? : 匹配单个字符 [] : 匹配指定范围内的字符, 如[0-9]匹配数字 glob.glob()参数:_(str): 文件路径的正则表达式 返回值:_(list): 符合正则表达式的文件路径列表 备注:返回所有匹配的文件路径列表, 它只有一个参数pathname, 定义了文件路径匹配的规则, 这里可以是绝对路径或者相对路径:123456import globpathes_list = glob.glob("~/Pictures/*.jpg")# 获取Pictures下的所有图片relative_pathes_list = glob.glob("../*.py")# 获取上级目录中的所有.py文件 在 linux, osx 系统中, 通配符的匹配是大小写区分的, 也就是需要特别指定大小写:1extensions = [&apos;jpg&apos;, &apos;JPG&apos;, &apos;jpeg&apos;, &apos;JPEG&apos;] 但是在 windows 当中, 通配符的匹配是不区分大小写的, 因此只需要指定大小写中的一个即可, 两个都指定的话, 会出现重复的情况1extensions = [&apos;jpg&apos;, &apos;jpeg&apos;] glob.iglob获取一个可遍历的对象, 使用它可以逐个获取匹配的文件路径名. 与glob.glob()的区别是: glob.glob()会同时获取到所有的匹配路径, 而glob.iglob()一次只获取一个匹配路径.1234f = glob.iglob("../*.py")print f # &lt;generator object iglob at 0x00B9FF80&gt;for py in f: print(py)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚类分析]]></title>
    <url>%2Fz_post%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简单介绍常用的聚类方法原型聚类: k-means 聚类, LVQ(学习向量量化), 高斯混合聚类密度聚类层次聚类 k-means 聚类算法步骤: 开始时先随机挑选 $k$ 个样本作为初始均值向量, 然后将其余向量按照距离关系分别划分到 $k$ 个簇中, 再对每个簇求新的均值向量, 然后不断重复该过程, 均值向量不再更新为止.]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-%E5%89%91%E6%8C%87offer%2F</url>
    <content type="text"><![CDATA[1. 二维数组中的查找题目描述在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数 解法一: 每一行用一次二分时间复杂度: $O(nlogn)$ (该复杂度无法通过牛客OJ) 123456789101112131415class Solution &#123;public: bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; for( int i = 0; i&lt;array.size(); i++)&#123; int low = 0, high = array[i].size()-1; while(low &lt; high)&#123; int mid = (low+high) / 2; if(target &gt; array[i][mid]) low = mid; else if(target &lt; array[i][mid]) high = mid; else return true; &#125; &#125; return false; &#125;&#125;; 每一行二分需要 logn 的时间, 总共有n行. 解法二: 从左下角开始时间复杂度: $O(n+m)$, 最多走 $n+m$ 步, $n$ 和 $m$ 分别为矩阵的宽和高空间复杂度: $O(1)$ 从左下角开始, 向右为大数方向, 向上为小数方向, 每次至少移动一位, 总共需要移动n次 12345678910111213class Solution &#123;public: bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; int i = array.size()-1; int j = 0, len = array[0].size(); while(i&gt;=0 &amp;&amp; j &lt; len)&#123; if(target &gt; array[i][j]) j++; // target在大数方向 else if(target &lt; array[i][j]) i--; // target在小数方向 else return true; &#125; return false; &#125;&#125;; 2. 替换空格题目描述请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 解法: 从前向后记录空格，从后向前替换空格时间复杂度: $O(n)$ 需要注意, 如果替换的空间超过了length的申请空间, 则需要重新申请空间 123456789101112131415161718192021222324252627282930class Solution &#123;public: void replaceSpace(char *str,int length) &#123; int white_count = 0; int char_count = 0; char *s = str; while(*s!='\0')&#123; if(*s == ' ') white_count++; else char_count++; s++; &#125; char* res_str = str; if(char_count + white_count*3 &gt;length) res_str = new char[char_count+white_count*3 + 1]; int old_length = char_count+white_count+1; int new_length = char_count+white_count*3 + 1; while(old_length &gt;=0 &amp;&amp; new_length &gt;= 0)&#123; if(str[old_length] != ' ')&#123; res_str[new_length--]=str[old_length--]; &#125;else&#123; old_length--; res_str[new_length--]='0'; res_str[new_length--]='2'; res_str[new_length--]='%'; &#125; &#125; str = res_str; &#125;&#125;; 3.从尾到头打印链表题目描述输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。123456789/*** struct ListNode &#123;* int val;* struct ListNode *next;* ListNode(int x) :* val(x), next(NULL) &#123;* &#125;* &#125;;*/ 解法一: reverse时间复杂度: $O(n)$空间复杂度: $O(n)$ 顺序访问, 然后将vector里面的元素逆置. 这两部操作时间复杂度皆为 $O(n)$ 123456789101112class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; res; while(head!=nullptr)&#123; res.push_back(head-&gt;val); head = head-&gt;next; &#125; std::reverse(res.begin(), res.end()); return res; &#125;&#125;; 解法二: swap (实际上依然是reverse)时间复杂度: $O(n)$空间复杂度: $O(n)$ 12345678910111213141516class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; res; if(head == nullptr) return res; while(head!=nullptr)&#123; res.push_back(head-&gt;val); head = head-&gt;next; &#125; int mid = (res.size()-1)/2; int len = res.size()-1; for(int i =0 ;i&lt;=mid;i++) std::swap(res[i], res[len-i]); return res; &#125;&#125;; 解法三: 栈时间复杂度: $O(n)$空间复杂度: $O(2n)$ 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; stack&lt;int&gt; s; vector&lt;int&gt; res; if(head == nullptr) return res; while(head!=nullptr)&#123; s.push(head-&gt;val); head = head-&gt;next; &#125; while(!s.empty())&#123; res.push_back(s.top()); s.pop(); &#125; return res; &#125;&#125;; 4.重建二叉树题目描述输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。 123456789/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */ 首先需要注意一点的是: 这里前序和中序不能包含重复的元素, 否则无法确定前序和中序中节点的对应关系 解法一: 递归时间复杂度: $O(空间复杂度: 根据前序和中序的对应关系, 利用递归完成构建, 构建时, 先构建当前节点, 然后是左右子树. 1234567891011121314151617class Solution &#123;public: TreeNode* reConstructBinaryTree(vector&lt;int&gt; pre,vector&lt;int&gt; vin) &#123; return helper(pre, 0, pre.size()-1, vin, 0, vin.size()-1); &#125; TreeNode* helper(vector&lt;int&gt; &amp;pre, int pre_i, int pre_j, vector&lt;int&gt; &amp;vin, int vin_i, int vin_j)&#123; if(pre_i &gt; pre_j || vin_i &gt; vin_j) return nullptr; TreeNode* node = new TreeNode( pre[pre_i] ); // 当前节点 int v = vin_i; while(pre[pre_i] != vin[v]) v++; //找到前序在中序中的对应节点, 这里可以用哈希表来改进查找的复杂度 node-&gt;left = helper(pre, pre_i+1, pre_i+v-vin_i, vin, vin_i, v-1); node-&gt;right = helper(pre, pre_i+v-vin_i+1, pre_j, vin, v+1, vin_j); return node; &#125;&#125;; 解法二: 迭代123456789101112131415161718192021222324class Solution &#123;public: TreeNode* reConstructBinaryTree(vector&lt;int&gt; pre,vector&lt;int&gt; vin) &#123; stack&lt;TreeNode*&gt; tree_stack; if(pre.size() == 0) return nullptr; TreeNode * root = new TreeNode(pre[0]); tree_stack.push(root); int index = 0; for(int i = 1; i&lt;pre.size() ; i++)&#123; TreeNode * cur_node = tree_stack.top(); if(cur_node-&gt;val != vin[index])&#123; cur_node-&gt;left = new TreeNode(pre[i]); tree_stack.push(cur_node-&gt;left); &#125;else&#123; while( !tree_stack.empty() &amp;&amp; tree_stack.top()-&gt;val == vin[index])&#123; // 注意, 这里不能用cur_node, 而必须用tree_stack.top() cur_node = tree_stack.top(); tree_stack.pop(); index++; &#125; cur_node-&gt;right = new TreeNode(pre[i]); tree_stack.push(cur_node-&gt;right); &#125; &#125; return root; &#125;&#125;; 5.用两个栈实现队列6.旋转数组的最小数字7.斐波那契数列f(n) = \begin{cases} 0, & n=0 \\ 1, & n=1(或2) \\ f(n-1)+f(n-2), & n>2 \end{cases}解法一: 递归(超时,超内存)12345678class Solution &#123;public: int jumpFloor(int number) &#123; if(number==0) return 0; if(number==1 || number==2) return 1; return jumpFloor(number-1)+jumpFloor(number-2); &#125;&#125;; 解法二: 迭代1234567891011121314class Solution &#123;public: int Fibonacci(int n) &#123; if(n ==0) return 0; if(n==1 || n==2) return 1; int n1=1, n2=1; for(int i=3; i&lt;=n; i++)&#123; int temp = n2; n2 = n2+n1; n1 = temp; &#125; return n2; &#125;&#125;; 解法二: 迭代8.跳台阶题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 解法一: 递归(超时, 超内存)设n个台阶的跳法有 $f(n)$ 种, 当青蛙跳上一个台阶后, 剩下的走法就是只有n-1个台阶的走法, 因此就是 $f(n-1)$ , 同理, 如果当前跳了2个台阶, 那么剩下的就是f(n-2), 因此有以下公式: f(n) = \begin{cases} 1, & n=1 \\ 2, & n=2 \\ f(n-1) + f(n-2) & n>1 \end{cases}从上可以看出, 这道题就是斐波那契数列的变种, 不同之处在于初始值不同(因为台阶为2时, 有两种跳法), 因此解法同上. 解法二: 迭代123456789101112131415class Solution &#123;public: int jumpFloor(int number) &#123; if(number==0) return 0; if(number==1) return 1; int n1 = 1; int n2 = 2; for(int i=3; i&lt;=number; i++)&#123; int temp=n2; n2 = n2 + n1; n1 = temp; &#125; return n2; &#125;&#125;; 9.变态跳台阶题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 解法一: 递归对于n个台阶, 可以跳1次, 2次, …., n次, 那么对应的剩下的台阶的跳法就有 $f(n-1), f(n-2), …, f(n-n)$ 种, 所以有下式: f(n) = f(0) + f(1) + f(2) + f(3) + ... + f(n-2) + f(n-1) = f(n-1) + f(n-1)f(n) = \begin{cases} 1, & n=0 \\ 1, & n=1 \\ 2*f(n-1), & n>=2 \end{cases}12345678class Solution &#123;public: int jumpFloorII(int number) &#123; if(number==0) return 1; if(number==1) return 1; return jumpFloorII(number-1) * 2; &#125;&#125;; 10.矩形覆盖对于 $n \times 2$ 大小的矩形, 可以竖着排列一个 $2\times 1$ 矩形, 或者横着排列上下两个 $2\times 1$ 的矩形, 那么对应的剩下的矩形面积就分别为 $(n-1) \times 2$ 和 $(n-2) \times 2$, 所以有下式: f(n) = \begin{cases} 1, & n=1 \\ 2, & n=2 \\ f(n-1) + f(n-2) & n>1 \end{cases}解法一: 递归(超时)解法二: 迭代1234567891011121314class Solution &#123;public: int rectCover(int number) &#123; if(number==0) return 0; if(number==1) return 1; int n1=1, n2=2; for(int i=3; i&lt;=number; i++)&#123; int temp = n2; n2 = n2+n1; n1 = temp; &#125; return n2; &#125;&#125;; 11.二进制中1的个数题目描述输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 解法一: 按位与&amp;时间复杂度: $O(1)$, 因为最多比较32次(long为64次)空间复杂度: $O(1)$ 注意: (n&amp;i) 一定要带括号, 因为它的优先级比==, != 等符号低.123456789101112class Solution &#123;public: int NumberOf1(int n) &#123; int i = 1; int count = 0; while( i!=0 )&#123; if( (n&amp;i) != 0) count++; // 注意, 这里的判断条件是 !=0, 并且 n&amp;i 一定要带括号 i = i &lt;&lt; 1; &#125; return count; &#125;&#125;; 解法二: n&amp;(n-1)一个整数 $n$, 将其与 $n-1$ 按位逻辑与, 得到的数刚好是将 $n$ 最右边的1置为0(其他位不变), 那么一个数有多少个1, 就可以进行多少次这样的操作.1234567891011class Solution &#123;public: int NumberOf1(int n) &#123; int count = 0; while(n!=0)&#123; n = n&amp;(n-1); count++; &#125; return count; &#125;&#125;; 12.数值的整数次方题目描述给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 解法一: 递归当n为偶数时: $x^n = x^{n/2} \times x^{n/2}$当n为奇数时: $x^n = x\times x^{n/2} \times x^{n/2}$ 12345678910class Solution &#123;public: double myPow(double x, int n) &#123; if(n==0) return 1.0; unsigned int un = abs(n); //注意这里必须是 unsigned类型, 就算是long , 也必须带unsigned, 主要是因为abs(INT_MIN)仍为负数INT_MIN! if(n &lt; 0) x = 1/x; return (un%2==0) ? myPow(x*x, un/2) : x*myPow(x*x, un/2); &#125;&#125;; 解法二: 非递归n要么为偶数, 要么为奇数, 就算为奇数, 也可以拆分成 $x\times x^{n-1}$ 的形式, 对于偶数n, 可以写成 $x^{n/2} \times x{n/2}$ 的形式, 对于 $x^{n/2}$, 可以继续按奇数偶数进行拆分. 举例来说, 对于x=2, n=10 , 可以写成 $2^{10} = 2^{5} \times 2^{5}$ 对于 $2^5$ , 可以写成, $2 \times 2^2 \times 2^2$, 可以看出, x每次与自身相乘后, n的次数就会变成原来二分之一, 这样, 可以用循环实现幂乘的操作, 如下所示. 123456789101112131415161718class Solution &#123;public: double myPow(double x, int n) &#123; if(n==0) return 1.0; unsigned int un = abs(n); //注意这里必须是 unsigned类型, 就算是long , 也必须带unsigned, 主要是因为abs(INT_MIN)仍为负数INT_MIN! if(n &lt; 0) x = 1/x; double res =1.0; while(un&gt;0)&#123; if(un%2 == 1)&#123; res * = x; &#125; x * =x; un /= 2; &#125; return res; &#125;&#125;; 13.调整数组顺序使奇数位于偶数前面14.链表中倒数第k个节点题目描述输入一个链表，输出该链表中倒数第k个结点。 解法一: 两个指针时间复杂度: $O(n)$ 遍历一次空间复杂度: $O(1)$ 1234567891011121314class Solution &#123;public: ListNode* FindKthToTail(ListNode* pListHead, unsigned int k) &#123; ListNode* p1 = pListHead, * p2 = pListHead; for(unsigned int i=0 ; i&lt;k; i++)&#123; if(p2==nullptr) return nullptr; p2 = p2-&gt;next; &#125; while(p2 != nullptr)&#123; p1 = p1-&gt;next; p2=p2-&gt;next; &#125; return p1; &#125;&#125;; 15.反转链表题目描述输入一个链表，反转链表后，输出新链表的表头。 解法一: 两个指针pre和cur时间复杂度: $O(n)$ 一次遍历空间复杂度: $O(1)$ 利用两个指针pre和cur维持当前节点和前一个节点, 然后执行反转操作 1234567891011121314class Solution &#123;public: ListNode* ReverseList(ListNode* pHead) &#123; ListNode* pre = nullptr; ListNode* cur = pHead; while(pHead != nullptr)&#123; cur = pHead; pHead = pHead-&gt;next; cur-&gt;next = pre; pre = cur; &#125; return cur; &#125;&#125;; 16.合并两个排序的链表题目描述输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 解法一: 原地合并用辅助指针head申请一个指向头结点的指针, 并用cur维护当前节点, 通过比较大小进行插入合并1234567891011121314151617181920212223242526272829303132/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* Merge(ListNode* pHead1, ListNode* pHead2) &#123; if(pHead1 == nullptr) return pHead2; if(pHead2 == nullptr) return pHead1; ListNode * head = new ListNode(0); ListNode * cur = head; while(pHead1!=nullptr &amp;&amp; pHead2!=nullptr)&#123; if(pHead1-&gt;val &lt; pHead2-&gt;val)&#123; cur-&gt;next = pHead1; cur = cur-&gt;next; pHead1 = pHead1-&gt;next; &#125;else&#123; cur-&gt;next = pHead2; cur = cur-&gt;next; pHead2 = pHead2-&gt;next; &#125; &#125; if(pHead1!=nullptr) cur-&gt;next = pHead1; if(pHead2!=nullptr) cur-&gt;next = pHead2; return head-&gt;next; &#125;&#125;; 解法二: 递归123456789101112131415class Solution &#123;public: ListNode* Merge(ListNode* pHead1, ListNode* pHead2) &#123; if(pHead1==nullptr) return pHead2; if(pHead2==nullptr) return pHead1; if(pHead1-&gt;val &lt; pHead2-&gt;val)&#123; pHead1-&gt;next = Merge(pHead1-&gt;next, pHead2); return pHead1; &#125;else&#123; pHead2-&gt;next = Merge(pHead1, pHead2-&gt;next); return pHead2; &#125; &#125;&#125;; 17.树的子结构题目描述输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） 解法一: 非递归每找到一个相等的节点, 就判断就是为子树 采用的是先根遍历的非递归写法, 在入栈之前就进行判断. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool HasSubtree(TreeNode* pRoot1, TreeNode* pRoot2) &#123; if(pRoot2 == nullptr) return false; std::stack&lt;TreeNode * &gt; pre_root; while(!pre_root.empty() || pRoot1!=nullptr)&#123; while(pRoot1!=nullptr)&#123; if(pRoot1-&gt;val == pRoot2-&gt;val &amp;&amp; is_subtree(pRoot1, pRoot2)) return true; pre_root.push(pRoot1); pRoot1 = pRoot1-&gt;left; &#125; if(!pre_root.empty())&#123; pRoot1 = pre_root.top(); pre_root.pop(); pRoot1 = pRoot1-&gt;right; &#125; &#125; return false; &#125; bool is_subtree(TreeNode * pRoot1, TreeNode * pRoot2)&#123; std::stack&lt;TreeNode * &gt; pre_root; while(!pre_root.empty() || pRoot2!=nullptr)&#123; while(pRoot2!=nullptr)&#123; if(pRoot1==nullptr || pRoot2-&gt;val != pRoot1-&gt;val) return false; pre_root.push(pRoot1); pre_root.push(pRoot2); pRoot1 = pRoot1-&gt;left; pRoot2 = pRoot2-&gt;left; &#125; if(!pre_root.empty())&#123; pRoot2 = pre_root.top(); pre_root.pop(); // 注意入栈与出栈的顺序要刚好相反 pRoot1 = pre_root.top(); pre_root.pop(); pRoot1 = pRoot1-&gt;right; pRoot2 = pRoot2-&gt;right; &#125; &#125; return true; &#125;&#125;; 解法二: 递归123456789101112131415161718class Solution &#123;public: bool HasSubtree(TreeNode* pRoot1, TreeNode* pRoot2) &#123; bool result = false; //用result变量来记录是否已经是子树, 如果result一旦为true, 就直接返回, 不用再继续递归 if(pRoot1 != nullptr &amp;&amp; pRoot2 != nullptr)&#123; result = is_subtree(pRoot1,pRoot2); if(!result) result = HasSubtree(pRoot1-&gt;left, pRoot2); if(!result) result = HasSubtree(pRoot1-&gt;right, pRoot2); &#125; return result; &#125; bool is_subtree(TreeNode* pRoot1, TreeNode* pRoot2)&#123; if(pRoot2 == nullptr ) return true; if(pRoot1==nullptr || pRoot2-&gt;val != pRoot1-&gt;val) return false; return is_subtree(pRoot1-&gt;left, pRoot2-&gt;left) &amp;&amp; is_subtree(pRoot1-&gt;right, pRoot2-&gt;right); &#125;&#125;; 18.二叉树的镜像题目描述操作给定的二叉树，将其变换为源二叉树的镜像。输入描述:二叉树的镜像定义：源二叉树 8 / \ 6 10 / \ / \ 5 7 9 11 镜像二叉树 8 / \ 10 6 / \ / \ 11 9 7 5 解法一: 递归先根遍历 1234567891011121314151617181920/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: void Mirror(TreeNode * pRoot) &#123; if(pRoot == nullptr) return; TreeNode * temp = pRoot-&gt;left; pRoot-&gt;left = pRoot-&gt;right; pRoot-&gt;right = temp; Mirror(pRoot-&gt;left); Mirror(pRoot-&gt;right); &#125;&#125;; 解法二: 非递归先根遍历 1234567891011121314151617181920class Solution &#123;public: void Mirror(TreeNode * pRoot) &#123; std::stack&lt;TreeNode * &gt; pre_root; TreeNode * cur = pRoot; while(!pre_root.empty() || cur!=nullptr)&#123; while(cur!=nullptr)&#123; TreeNode * temp = cur-&gt;left; cur-&gt;left = cur-&gt;right; cur-&gt;right = temp; pre_root.push(cur); cur = cur-&gt;left; &#125; if(!pre_root.empty())&#123; cur = pre_root.top(); pre_root.pop(); cur = cur-&gt;right; &#125; &#125; &#125;&#125;; 19.顺时针打印矩阵题目描述输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 解法一: 按层打印时间复杂度: $O(n)$空间复杂度: $O(n)$ 按照层从外而内进行打印, 需要注意层的边界条件, 以及上下层和左右层之间不能重复. 1234567891011121314151617181920212223class Solution &#123;public: vector&lt;int&gt; printMatrix(vector&lt;vector&lt;int&gt; &gt; matrix) &#123; vector&lt;int&gt; res; if(matrix.size()==0 ||matrix[0].size()==0) return vector&lt;int&gt;&#123;&#125;; int row = matrix.size(), col = matrix[0].size(); int layers = (std::min(row,col) + 1)/2; for(int layer=0; layer&lt;layers; layer++)&#123; for(int i=layer, j=layer; j&lt; col-layer; j++ ) res.push_back(matrix[i][j]); for(int i=layer+1, j=col-layer-1; i&lt;row-layer-1; i++) res.push_back(matrix[i][j]); // 这里的 i &gt; (row-1)/2 也可以写作 layer != row-1-layer, 避免上下重复 for(int i=row-layer-1, j=col-layer-1; i &gt; (row-1)/2 &amp;&amp; j &gt;=layer; j--) res.push_back(matrix[i][j]); // 这里的 j &lt; col/2 也可以写作 layer != col-1-layer, 避免左右重复 for(int i=row-layer-2, j=layer; j &lt; col/2 &amp;&amp; i&gt;layer; i--) res.push_back(matrix[i][j]); &#125; return res; &#125;&#125;; 20.包含min函数的栈题目描述定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的min函数（时间复杂度应为O（1））。 解法: 利用辅助栈实现应用一个辅助栈，压的时候，如果A栈的压入比B栈压入大，B栈不压，，，，小于等于，AB栈同时压入，出栈，如果，AB栈顶元素不等，A出，B不出。 12345678910111213141516171819class Solution &#123;public: stack&lt;int&gt; s1,s2; void push(int value) &#123; s1.push(value); if(s2.empty()) s2.push(value); else if(s1.top() &lt;= s2.top()) s2.push(value); &#125; void pop() &#123; if(s1.top()==s2.top()) s2.pop(); s1.pop(); &#125; int top() &#123; return s1.top(); &#125; int min() &#123; return s2.top(); &#125;&#125;; 21.栈的压入、弹出序列题目描述输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的） 解法: 模拟栈的压入, 弹出123456789101112131415161718192021class Solution &#123;public: bool IsPopOrder(vector&lt;int&gt; pushV,vector&lt;int&gt; popV) &#123; stack&lt;int&gt; s; if(pushV.size()==0) return false; s.push(pushV[0]); int i = 0, j=1; while(!s.empty())&#123; if(s.top() != popV[i])&#123; if(j&lt;pushV.size()) s.push(pushV[j++]); else return false; &#125;else&#123; s.pop(); i++; &#125; &#125; return true; &#125;&#125;; 更简洁的写法: 123456789101112class Solution &#123;public: bool IsPopOrder(vector&lt;int&gt; pushV,vector&lt;int&gt; popV) &#123; stack&lt;int&gt; s; if(pushV.size()==0) return false; for(int i=0, j=0; i&lt;pushV.size() ;)&#123; s.push(pushV[i++]); while(j&lt;popV.size() &amp;&amp; s.top() == popV[j])&#123;s.pop(); j++;&#125; &#125; return s.empty(); &#125;&#125;; 22.从上往下打印二叉树题目描述从上往下打印出二叉树的每个节点，同层节点从左至右打印。 解法: 层次遍历用一个变量cur_len来维护当前层的节点数, 这样就无序额外存储层深等其他信息.12345678910111213141516171819202122232425262728/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;int&gt; PrintFromTopToBottom(TreeNode* root) &#123; vector&lt;int&gt; res; if(root==nullptr) return res; std::queue&lt;TreeNode*&gt; q_tree; q_tree.push(root); while(!q_tree.empty())&#123; int cur_len = q_tree.size(); // 获取当前层节点数目 for(int i=0; i&lt;cur_len; i++)&#123; //直到遍历完当前层节点 TreeNode* cur_node = q_tree.front(); q_tree.pop(); res.push_back(cur_node-&gt;val); if(cur_node-&gt;left != nullptr) q_tree.push(cur_node-&gt;left); if(cur_node-&gt;right != nullptr) q_tree.push(cur_node-&gt;right); &#125; &#125; return res; &#125;&#125;; 23.二叉搜索树的后序遍历序列题目描述输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。 解法: 根据后序序列的特性设计递归判断规则123456789101112131415161718192021class Solution &#123;public: bool VerifySquenceOfBST(vector&lt;int&gt; sequence) &#123; if(sequence.size()==0) return false; return helper(sequence, 0, sequence.size()-1); &#125; bool helper(vector&lt;int&gt; &amp;sequence, int start, int end)&#123; if(start&gt;=end) return true; int cur_i = start; while(cur_i &lt; end &amp;&amp; sequence[cur_i] &lt; sequence[end]) cur_i++; int mid = cur_i; while(cur_i &lt; end)&#123; if(sequence[cur_i] &lt;sequence[end]) return false; cur_i++; &#125; bool b1 = helper(sequence, start, mid-1); bool b2 = helper(sequence, mid, end-1); return b1&amp;&amp;b2; &#125;&#125;; 24.二叉树中和为某一值的路径题目描述输入一颗二叉树的跟节点和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。(注意: 在返回值的list中，数组长度大的数组靠前) 解法一: 递归解法先根遍历 123456789101112131415161718192021222324252627/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;int&gt; v_list; vector&lt;vector&lt;int&gt; &gt; res; int cur_number = 0; vector&lt;vector&lt;int&gt; &gt; FindPath(TreeNode* root,int expectNumber) &#123; if(root==nullptr) return res; cur_number += root-&gt;val; v_list.push_back(root-&gt;val); if(cur_number == expectNumber &amp;&amp; root-&gt;left==nullptr &amp;&amp; root-&gt;right==nullptr) res.push_back(v_list); if(root-&gt;left != nullptr ) FindPath(root-&gt;left, expectNumber); if(root-&gt;right != nullptr) FindPath(root-&gt;right, expectNumber); cur_number -= root-&gt;val; v_list.pop_back(); return res; &#125;&#125;; 另一种写法: 通过减法控制当前的和123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; v_list; vector&lt;vector&lt;int&gt; &gt; res; //int cur_number = 0; vector&lt;vector&lt;int&gt; &gt; FindPath(TreeNode* root,int expectNumber) &#123; if(root==nullptr) return res; expectNumber -= root-&gt;val; // 注意这里是减法 v_list.push_back(root-&gt;val); if(0 == expectNumber &amp;&amp; root-&gt;left==nullptr &amp;&amp; root-&gt;right==nullptr) //条件语句变为 0 == expectNumber res.push_back(v_list); if(root-&gt;left != nullptr ) FindPath(root-&gt;left, expectNumber); if(root-&gt;right != nullptr) FindPath(root-&gt;right, expectNumber); //cur_number -= root-&gt;val; //注意, 可以不加这条语句 v_list.pop_back(); return res; &#125;&#125;; 解法二: 非递归1234567891011121314151617181920212223242526272829303132/*非递归法：后序遍历1.进栈时候，把值同时压入路径的向量数组，修正路径的和2.出栈时候，先判断和是否相等，且该节点是否是叶节点，判断完成后保持和栈一致，抛出路径，修改路径的和3.向量数组和栈的操作要保持一致*/class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; FindPath(TreeNode* root, int expectNumber) &#123; stack&lt;TreeNode*&gt; s; vector&lt;int&gt; v; vector&lt;vector&lt;int&gt; &gt; res; while (root || !s.empty())&#123; while (root)&#123; s.push(root); v.push_back(root-&gt;val); expectNumber -= root-&gt;val; //能左就左，否则向右 root = root-&gt;left ? root-&gt;left : root-&gt;right; &#125; root = s.top(); if (expectNumber == 0 &amp;&amp; root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) res.push_back(v); s.pop(); v.pop_back(); expectNumber += root-&gt;val; //右子数没遍历就遍历，如果遍历就强迫出栈 if (!s.empty() &amp;&amp; s.top()-&gt;left == root) root = s.top()-&gt;right; else root = NULL;//强迫出栈 &#125; return res; &#125;&#125;; 25.复杂链表的复制题目描述输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 注意链表的复制不同于其他复制，在进行链表复制时，必须创建新的节点，同时，不能通过newnode-&gt;next = oldnode-next对新节点进行赋值，这是因为这样赋值会使新链表指向旧链表的节点，造成混乱。 正确解题思路： 先对原链表中的每一个节点进行复制，将复制的节点插入到原节点之后，比如原链表是A-&gt;B-&gt;C，则复制后应该变成A-&gt;A1-&gt;B-&gt;B1-&gt;C-&gt;C1。 再按照原始链表中随机指针的指向，对新节点的随机指针进行赋值。 将链表拆分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*struct RandomListNode &#123; int label; struct RandomListNode *next, *random; RandomListNode(int x) : label(x), next(NULL), random(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: RandomListNode* Clone(RandomListNode* pHead) &#123; if(pHead==NULL) return NULL; //少考虑这种情况会发生段错误 RandomListNode* curnode = pHead; //C++允许在声明结构变量时省略关键字struct，但是C不允许 while(curnode!=NULL)&#123; RandomListNode* clonenode = new RandomListNode(curnode-&gt;label); clonenode-&gt;next = curnode-&gt;next; curnode-&gt;next = clonenode; curnode = clonenode-&gt;next; &#125; curnode = pHead; while(curnode!=NULL)&#123; // 因为random有可能指向前面的节点, 所以必须在拆分链表之前进行random指针的赋值, 而不能在拆分链表的同时进行赋值 if(curnode-&gt;random!=NULL)&#123; //少考虑这种情况会不满足个别用例 curnode-&gt;next-&gt;random = curnode-&gt;random-&gt;next; curnode = curnode-&gt;next-&gt;next; &#125; else&#123; curnode-&gt;next-&gt;random = NULL; curnode = curnode-&gt;next-&gt;next; &#125; &#125; curnode = pHead; RandomListNode* newhead = pHead-&gt;next; RandomListNode* newcur = pHead-&gt;next; while(curnode!=NULL)&#123; if(newcur-&gt;next == NULL)&#123; curnode-&gt;next = NULL; break; &#125; curnode-&gt;next = newcur-&gt;next; newcur-&gt;next = newcur-&gt;next-&gt;next; curnode = curnode-&gt;next; newcur = newcur-&gt;next; &#125; return newhead; &#125;&#125;; 26.二叉搜索树与双向链表题目描述输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的节点，只能调整树中结点指针的指向。 解法一：自己的思路后序遍历，递归实现，首先将左子树全部变成有序的，然后将右子树全部变成有序的。由于在返回时，返回的是左右子树的根节点，因此，在将当前根节点与左右子树拼接时，需要移动到左子树的最后一个元素上（最大），与当前根节点的left拼接。对于右子树，要移动到右子树的第一个元素上（最小），与当前根节点的right拼接。 这里有一个需要注意的地方，以下两种声明方式，指针一定要初始化之后才能使用，会使代码结果表现不同，前者超时，后者通过 12TreeNode* pre,* next;TreeNode* pre=nullptr,* next=nullptr; 123456789101112131415161718192021222324252627282930313233343536373839404142/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return nullptr; TreeNode* node = recurve(pRootOfTree); while(node-&gt;left!=nullptr) node = node-&gt;left; return node; &#125; TreeNode* recurve(TreeNode* pRootOfTree)&#123; TreeNode* pre=nullptr,* next=nullptr; // 这里，如果没有指定nullptr，则程序会超时！！！ if(nullptr!=pRootOfTree-&gt;left) pre = recurve(pRootOfTree-&gt;left); if(nullptr!=pRootOfTree-&gt;right) next = recurve(pRootOfTree-&gt;right); if(pre!=nullptr)&#123; while(pre-&gt;right!=nullptr) pre=pre-&gt;right; pRootOfTree-&gt;left = pre; pre-&gt;right = pRootOfTree; &#125; if(next!=nullptr)&#123; while(next-&gt;left!=nullptr) next = next-&gt;left; pRootOfTree-&gt;right = next; next-&gt;left = pRootOfTree; &#125; return pRootOfTree; &#125;&#125;; 解法二：中序遍历，递归实现由于对搜索二叉树来说，中序遍历的结果就是有序的，因此，只需要通过维护一个prenode指针来标记当前节点的上一个节点即可完成双向有序链表。 注意，这里有一个非常关键的点，那就是TreeNode*&amp; prenode，如果少了&amp;引用标识，则结果错误！具体原因看文章关于*&amp;和*的联系和区别。12345678910111213141516171819202122232425class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return nullptr; TreeNode* prenode = nullptr; recurve(pRootOfTree,prenode); while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left; return pRootOfTree; &#125; void recurve(TreeNode* root, TreeNode*&amp; prenode)&#123; if(root-&gt;left!=nullptr) recurve(root-&gt;left,prenode); root-&gt;left = prenode; if(prenode!=nullptr) prenode-&gt;right = root; prenode = root; if(root-&gt;right!=nullptr) recurve(root-&gt;right,prenode); &#125;&#125;; 解法三：中序遍历，非递归实现基于中序遍历的非递归方法，思路与解法二一致。 但是这里有个疑问，为什么使用下面的代码会发生段错误。1234567while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left;return pRootOfTree;发生段错误的原因主要是因为没有对pRootOfTree进行空指针检查,就直接使用了该指针的成员变量, 访问了本不存在的内存, 从而造成了段错误, 修改方法是在程序前加上空指针检查 以下代码额外设置了一个指针指向第一个节点，以避免使用上面代码带来的段错误。 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: stack&lt;TreeNode*&gt; S_node; TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return pRootOfTree; TreeNode* P = pRootOfTree; // TreeNode* node = pRootOfTree; 进行了空指针检查, 所以不用再使用这个指针了, 下面也是同理 TreeNode* pre = nullptr; while(P!=nullptr||!S_node.empty())&#123; while(P!=nullptr)&#123; S_node.push(P); P = P-&gt;left; &#125; if(!S_node.empty())&#123; P = S_node.top(); P-&gt;left = pre; if(pre!=nullptr)&#123; pre-&gt;right = P; &#125;//else //node = P; pre = P; S_node.pop(); P = P-&gt;right; &#125; &#125; while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left; //return node; return pRootOfTree; &#125;&#125;; 另一种看起来逻辑性更好的写法:123456789101112131415161718192021222324252627282930class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree == nullptr) return pRootOfTree; std::stack&lt;TreeNode*&gt; s_tree; TreeNode* cur_node = pRootOfTree; TreeNode* head = nullptr; //双向链表的头指针 TreeNode* pre_node = nullptr; //双向链表的pre指针 while(!s_tree.empty() || cur_node!=nullptr)&#123; while(cur_node!=nullptr)&#123; s_tree.push(cur_node); cur_node = cur_node-&gt;left; &#125; if(!s_tree.empty())&#123; cur_node = s_tree.top(); s_tree.pop(); if(head==nullptr)&#123; head = cur_node; pre_node = head; &#125;else&#123; pre_node-&gt;right = cur_node; cur_node-&gt;left = pre_node; pre_node = cur_node; &#125; cur_node = cur_node-&gt;right; &#125; &#125; return head; &#125;&#125;; 27.字符串的排列题目描述输入一个字符串，按字典序打印出该字符串中字符的所有排列。例如输入字符串abc，则打印出由字符a，b，c所能排列出来的所有字符串abc，acb，bac，cab和cab。 解法一: 递归思路（没想到）：将一个字符串看成两个部分，前一部分为首位字母，剩下的是后一部分。通过将首位字母与后一部分的所有字符交换（包括跟自己交换），可以得到第一个位置的所有可能情况。然后，再将剩下的部分看作是一个新的字符串，同样将剩余部分分成两部分，其中，第一部分是剩余部分的首位。如此，可以按照递归进行处理。 12345678910111213141516171819202122232425262728class Solution &#123;public: //bool my_sort(string s1, string s2)&#123; return s1&lt;s2;&#125;; vector&lt;string&gt; Permutation(string str) &#123; vector&lt;string&gt; v_string; if(str=="") return v_string; PermutationHelp(v_string, 0, str); std::sort(v_string.begin(), v_string.end()); return v_string; &#125; void PermutationHelp(vector&lt;string&gt;&amp; v_string, int pos, string str)&#123; /* if(pos == 0 )&#123; v_string.push_back(str); PermutationHelp(v_string, pos+1, str); &#125; \*/ //这里i=pos而不是pos+1的原因是：如果用pos+1,会导致丟解，即自己与自己交换的那种情况没有继续向下递归 for(int i=pos; i&lt;str.length(); i++)&#123; std::swap(str.at(pos), str.at(i)); if(std::count(v_string.begin(), v_string.end(), str) == 0) // 重复检查, 这里需要遍历, 会大大提高程序复杂度 v_string.push_back(str); PermutationHelp(v_string, pos+1, str); //std::swap(str.at(pos), str.at(i)); //能够注释本行的原因是因为上面已经利用count进行了重复检查. 但是实际上, 这是一种不太好的做法, 更好的写法在下面, 无需进行count重复检查 &#125; &#125;&#125;; 更简洁的写法:123456789101112131415161718192021222324class Solution &#123;public: vector&lt;string&gt; Permutation(string str) &#123; vector&lt;string&gt; res; if(str == "") return res; permute_helper(res, 0, str); std::sort(res.begin(), res.end()); return res; &#125; void permute_helper(vector&lt;string&gt; &amp;res, int pos , string &amp;str)&#123; if(pos == str.size()) res.push_back(str); // 注意, 这里是在pos==str.size()才将str放入res中, 这与上面的逻辑看起来好像有些矛盾 // 实际上, 当pos==str.size()时, 包含了所有可能情况, 即一次交换也没有发生(只与自身交换), 或者交换了某些位置等情况 else&#123; for(int i = pos; i&lt;str.size(); i++)&#123; if(str[pos] == str[i] &amp;&amp; pos!=i) continue; //防止重复出现, 如"aa", 则只输出一个 [a,a] std::swap(str[pos], str[i]); permute_helper(res, pos+1, str); std::swap(str[pos], str[i]); &#125; &#125; &#125;&#125;; 解法二: 迭代对于已经排列好的n-1个字符, 如果来了第n个字符, 则这个字符可以插入到n-1个字符的n个位置上, 注意控制字符是否重复, 即对于”aaaaa”来说, 如果新来的字符为’a’, 则这个’a’只有一种插法, 因此, 我们做判断: a与位置i(0~3)上的字符如果相等, 则不插入, 故而a只会插入到位置4上.(虽然位置4不存在, 但是插入时是能以超尾位置插入的) 12345678910111213141516171819202122class Solution &#123;public: vector&lt;string&gt; Permutation(string str) &#123; vector&lt;string&gt; res(1,""); if(str=="") &#123;res.pop_back(); return res;&#125; for(int i=0; i&lt;str.size(); i++)&#123; vector&lt;string&gt; res_tmp(std::move(res)); for(int j=0; j&lt;res_tmp.size(); j++)&#123; for(int k=0; k&lt;=res_tmp[0].size(); k++)&#123; if(k&lt;res_tmp[0].size() &amp;&amp; str[i] == res_tmp[j][k]) continue; //跳过重复排列, 例如将a插入a的两端,只选择插一端即可(a插入1位置), 另一端跳过(a插入0位置) string str_tmp = res_tmp[j]; str_tmp.insert(k, 1, str[i]); res.push_back(str_tmp); &#125; &#125; &#125; std::sort(res.begin(), res.end()); return res; &#125;&#125;; 28.数组中出现次数超过一半的数字题目描述：数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 思路一：如果数组是有序的，那么，出现次数超过数组长度一半的数字一定位于数组的中间位置，如果中间位置的数字出现次数小于数组长度的一半，那么就不存在。该方法需要进行排序，所以算法时间复杂度为 $nlog(n)$ 。1234567891011121314class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; //bool mysort(int a, int b) &#123;return a&lt;b;&#125; vector&lt;int&gt; counts; std::sort(numbers.begin(), numbers.end()); int n = std::count(numbers.begin(), numbers.end(), numbers.at((int)numbers.size()/2)); if (n &gt; numbers.size()/2) return numbers.at((int)numbers.size()/2); else return 0; &#125;&#125;; 思路二：Patition根据快排的思想，由于该数字一定在数组的中间位置，那么可以借助Partition来实现，随机选一个数字进行Partition，如果返回的mid索引最终停在N/2处，那么该索引对应的数字就有可能是答案，此时，只需统计该数字的出现次数即可。 该方法的时间复杂度是 $O(n)$ ，因为只会执行一边的Partition，并不会执行另一边. Partition的时间复杂度为 $O(n)$, 找到mid == numbers.size()/2的复杂度为 $O(logn)$, 因此总的时间复杂度为 $O(nlogn)$. 需要注意，具体在代码中看 12345678910111213141516171819202122232425262728293031323334353637383940414243bool mysort(int a, int b) &#123;return a&lt;b;&#125;class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; int low = 0 ; int high = numbers.size()-1; int mid = Partition(numbers, low, high); while(mid != numbers.size()/2)&#123; if(mid &lt; numbers.size()/2)&#123; low = mid + 1; mid = Partition(numbers, low, high); &#125;else&#123; high = mid - 1; mid = Partition(numbers,low, high); &#125; &#125; if(std::count(numbers.begin(), numbers.end(), numbers.at(mid)) &gt; numbers.size()/2) return numbers.at(mid); else return 0; &#125; int Partition(vector&lt;int&gt;&amp; numbers, int low, int high)&#123; int p = numbers.at(low); int mid = low; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; p &lt; numbers.at(high)) high--; //这里如果p用的是&lt;,则需要下面的low++逻辑，否则，会陷入死循环，如果用的是&lt;=，则在返回时，会返回首个元素的坐标 numbers.at(low) = numbers.at(high); if(low!=high) low++; while(low&lt;high &amp;&amp; p &gt; numbers.at(low)) low++; numbers.at(high) = numbers.at(low); if(low!=high) high--; &#125; numbers.at(low) = p; if(low == high) return mid; else return low; &#125;&#125;; 思路三：同增异减如果数组中存在这样一个数，那么这个数的出现次数一定大于其他所有数的出现次数总和，因此，设置两个变量，一个number用来存储数组中的第一个数，另一个num置为1,如果下一个数与number数相同，则num加一，否则减1,如果num被减为0,那么number转而存储下一个数，同时将num置为1。 这样，如果存在这个数，最终这个数一定为number，且num大于1。 123456789101112131415161718// 这个解法是错误的, 不论怎么处理, 最后都要做count&gt;half的检查, 这个方法能通过牛客的原因是因为牛客官方测例不够, 对于&#123;2,2,3,3,5,5&#125;的情况, 很明显应该输出0, 但是这个方法输出的是5class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; int number = numbers.at(0); int num = 1; for(vector&lt;int&gt;::iterator iter = numbers.begin()+1; iter != numbers.end(); iter++)&#123; if(num == 0)&#123; //这里与下面的区别之一是，一定要放在for训练内部的前面 number = * (iter-1); //区别之二这里如果使用iter-1,则无须在最后做count检查 num = 1; &#125; if(number == * iter) num++; else num--; &#125; if(num &gt;= 1) return number; //这里，num只需要&gt;=1 即可，仔细想一想这是为什么，为啥用了iter-1,就不用检查count。 else return 0; &#125;&#125;; 12345678910111213141516171819class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; int number = numbers.at(0); int num = 1; for(int i = 1; i&lt;numbers.size(); i++)&#123; if(num==0)&#123; number = numbers[i-1]; num=1; &#125; if(number == numbers[i]) num++; else num--; &#125; if(count(numbers.begin(), numbers.end(), number) &gt; numbers.size()/2) return number; //由于上面用的是iter，所以最终的num为1的数，只是有可能是我们要得数字，因此，需要进行检查。 else return 0; &#125;&#125;; 29.最小的K个数题目描述：输入n个整数，找出最小的K个数，例如输入4,5,1,6,2,7,3,8，则输出1,2,3,4。 一定要考虑边界情况： 数组为空 k大于数组size k小于0 思路一：最直接的想法，就是先对数组排序，然后输出前k个数。复杂度为 $nlog(n) + n$ 。 快排12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; k_input; if(k &gt; input.size() || input.size()&lt;=0) return k_input; int low = 0; int high = input.size()-1; quickSort(input, low, high); //vector&lt;int&gt; k_input(&amp;input.at(0), &amp;input.at(k-1)); for(int i=0; i&lt;k; i++) k_input.push_back(input.at(i)); return k_input; &#125; void quickSort(vector&lt;int&gt;&amp; input, int low, int high)&#123; int mid = Partition(input, low, high); if(mid&lt;high) quickSort(input, mid+1, high); if(mid&gt;low) quickSort(input, low, mid-1); &#125; int Partition(vector&lt;int&gt;&amp; input, int low, int high)&#123; int p = input[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; p&lt;=input[high]) high--; input[low] = input[high]; while(low&lt;high &amp;&amp; p&gt;=input[low]) low++; input[high] = input[low]; &#125; input[low] = p; return low; &#125;&#125;; 思路二：遍历整个数组，将当前元素与k_input数组进行比较，按照顺序插入，并且超出k的部分删除，最终直接返回k_input。时间复杂度 $O(nk)$ 。（该思想与冒泡排序思想类似）。12345678910111213141516171819202122class Solution &#123;public: vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; k_input; if(k&gt;input.size() || input.size()&lt;=0) return k_input; k_input.push_back(input.at(0)); for(auto iter = input.begin()+1; iter!=input.end(); iter++)&#123; for(int i =0 ;i&lt;k; i++)&#123; if(i == k_input.size())&#123; k_input.push_back(*iter); break; &#125;else if(*iter &lt; k_input.at(i))&#123; k_input.insert(k_input.begin()+i, *iter); break; &#125; &#125; if(k_input.size() &gt; k) k_input.pop_back(); &#125; return k_input; &#125;&#125;; 解法三: 大顶堆遍历数组, 维护一个大顶堆, 每遇到一个比堆顶小的数, 就将其插入大顶堆 (如果是找最大的k个数, 就用小顶堆) 时间复杂度: $O(nlogk)$空间复杂度: $O(k)$ 借助priority_queue数据结构12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; priority_queue&lt;int&gt; q; vector&lt;int&gt; res; if(k&lt;=0 || k&gt;input.size()) return res; // 边界条件检查, 是否会出现段错误或输出结果错误 for(int i=0; i&lt;input.size(); i++)&#123; if(i&lt;k) q.push(input[i]); else if(input[i] &lt; q.top())&#123; q.pop(); q.push(input[i]); &#125; &#125; while(!q.empty())&#123; res.push_back(q.top()); q.pop(); &#125; return res; &#125;&#125;; 利用数组实现堆 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123;public: void heapify(vector&lt;int&gt; &amp;vec_heap, int index, int heap_size)&#123; int max=index; int left=index*2+1; int right = index*2+2; if(left&lt;heap_size &amp;&amp; vec_heap[max] &lt; vec_heap[left])&#123; //int temp = max; // 无需交换max和left, 只需记录max的值即可, 下面的right同理 max = left; //left = temp; &#125; if(right&lt;heap_size &amp;&amp; vec_heap[max] &lt; vec_heap[right])&#123; //int temp = max; max = right; //right = temp; &#125; if(index != max)&#123; std::swap(vec_heap[index], vec_heap[max]); heapify(vec_heap, max, heap_size); &#125; &#125; vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; res; if(k&lt;=0 || k &gt; input.size()) return res; for(int i = 0; i&lt;k;i++)&#123; res.push_back(input[i]); &#125; for(int i=k-1; i&gt;=0;i--)&#123; //初始化堆 heapify(res, i, k); &#125; for(int i = k; i &lt; input.size(); i++)&#123; //i要从k开始, 因为k之前的已经是堆了 if(input[i] &lt; res[0])&#123; res[0] = input[i]; heapify(res, 0, k); &#125; &#125; for(int i = res.size()-1; i&gt;0; i--)&#123; std::swap(res[0], res[i]); heapify(res, 0, i); &#125; return res; &#125;&#125;; 另一种写法:1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: void heapify(vector&lt;int&gt; &amp;vec_heap, int index, int heap_size)&#123; int max = index; int left = index*2 + 1; int right = index*2 + 2; if(left &lt; heap_size &amp;&amp; vec_heap[left] &gt; vec_heap[max]) max=left; if(right &lt; heap_size &amp;&amp; vec_heap[right] &gt; vec_heap[max]) max=right; if(max!=index)&#123; std::swap(vec_heap[max], vec_heap[index]); heapify(vec_heap, max, heap_size); &#125; &#125; vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; res; if(k&lt;=0 || k&gt;input.size()) return res; for(int i=k-1; i&gt;=0; i--) heapify(input, i,k); for(int i=k; i&lt;input.size(); i++)&#123; if(input[i] &lt; input[0])&#123; //std::swap(input[i], input[0]); input[0] = input[i]; heapify(input, 0, k); &#125; &#125; for(int i=k-1; i&gt;=0; i--)&#123; res.push_back(input[0]); std::swap(input[0], input[i]); heapify(input, 0, i); // i变小, 所以从k-1开始 &#125; return res; &#125;&#125;; 解法四: 快速选择算法时间复杂度: 平均为 $O(n)$ 复杂度分析: 每次都会扔掉一半, 所以每次进行检查的元素个数为之前的一半, 所有时间复杂度大致为: T(n) = n + n/2 + n/8 + ... + (n/2)^k = n*(1-2^{-k})/(1-2^{-1}) = 2n也就是说, 只要枢纽元素的选择使得两边的元素数量尽可能均衡, 就可以得到 $O(n)$ 的时间复杂度 123456789101112131415161718192021222324252627class Solution &#123;public: vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; res; if(k&lt;=0 || k&gt;input.size()) return res; quick_select(input, 0, input.size()-1, k); //运行完 quick_select 以后, k之前的元素都比k位置上的元素小 for(int i = 0; i&lt;k; i++) res.push_back(input[i]); return res; &#125; void quick_select(vector&lt;int&gt; &amp;vec, int low, int high, int k)&#123; int P = vec[low] while(low &lt; high)&#123; while(low&lt;high &amp;&amp; P&lt;=vec[high]) high--; vec[low] = vec[high]; while(low&lt;high &amp;&amp; P&gt;=vec[low]) low++; vec[high] = vec[low]; &#125; vec[low] = P; //此时, low所处位置为枢纽元P, low之前的都小于P, low之后的都大于P if(low == k-1) return; //如果low所处位刚好为k-1, 则从这之前的k个元素一定是最小的(包括vec[low]自身) else if( k &lt; low) quick_select(vec, 0, low, k); else quick_select(vec, low+1, high, k); &#125;&#125;; 问题扩展 1输入是两个整数数组, 他们任意两个数的和有可以组成一个数组, 求这个和中的前k个数 分析: 假设两个整数数组为A和B, 各有N个元素, 任意两个数的和组成的数组C就有 $N^2$ 个, 那么可以把这些和看成N个有序数列, 由此, 问题就转变成了在这 $N^2$ 个有序数列里, 找到前k个最小的元素. A[1]+B[1] &lt;= A[1]+B[2] &lt;= A[1]+B[3] &lt;= … A[2]+B[1] &lt;= A[2]+B[2] &lt;= A[2]+B[3] &lt;= … … A[N]+B[1] &lt;= A[N]+B[2] &lt;= A[N]+B[3] &lt;= … 问题扩展 2有两个序列A和B都按照升序排列, 对于 1&lt;=i,j&lt;=k, 求k个最小的(ai+bj), 要求算法尽量高效. 30.连续子数组的最大和题目描述HZ偶尔会拿些专业问题来忽悠那些非计算机专业的同学。今天测试组开完会后,他又发话了:在古老的一维模式识别中,常常需要计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和，你会不会被他忽悠住？(子向量的长度至少是1) 解法一：穷举穷举遍历，时间复杂度 $O(n^2)$ 。 1234567891011121314151617class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; int max=array.at(0); for(auto iter=array.begin(); iter!=array.end(); iter++)&#123; //if(*iter &gt; 0)&#123; int temp = 0; for(auto it = iter; it!=array.end(); it++)&#123; temp += *it; if(temp &gt; max) max = temp; //&#125; &#125; &#125; return max; &#125;&#125;; 另一种写法(感觉更好理解些)12345678910111213141516class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; if(array.size() == 0) return INT_MIN; int max_sum = array[0]; int cur_sum = 0; for(auto x : array)&#123; cur_sum += x; if(cur_sum &gt; max_sum) // 更新max_sum max_sum = cur_sum; if(cur_sum &lt; 0) // 如果当前和为负, 则重置cur_sum cur_sum = 0; &#125; return max_sum; &#125;&#125;; 解法二：最优-两个变量记录sum$O(n)$ 的方法，根据数组性质，设置两个变量，一个记录当前的最大值，一个记录当前的子序列之和。首先，如果当前子序列之和为负，那么就是说，从当前位置开始的子序列，比从之前位置开始的子序列大，那么就可以不考虑从之前位置开始的子序列，之前累计的和也被抛弃。 1234567891011121314class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; if(array.size() == 0) return 0; int max_sum = array[0]; int cur_sum=0; for(int i=0; i&lt;array.size(); i++)&#123; cur_sum += array[i]; if(cur_sum &gt; max_sum) max_sum = cur_sum; if(cur_sum &lt; 0) cur_sum = 0; &#125; return max_sum; &#125;&#125;; 解法三：dp动态规划。与解法二的思路异曲同工，核心思想可有下述公式表示。 $f(i)代表以第i个数字结尾的子数组的连续最大和$ f(x)= \begin{cases} pData[i]& {i=0 或者f(i-1)\le 0} \\ f(i-1)+pData[i]& {i\ne 0 并且 f(i-1) > 0} \end{cases}上面的形式是递归的，通常情况下都用递归的方式来分析动态规划问题，但最终都会基于循环去编码。 上述公式对应的非递归形式就是思路二的代码。 递归写法：1234567891011121314151617181920class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; int max = array.at(0); f(array, array.size()-1, max); return max; &#125; int f(vector&lt;int&gt;&amp; array, int i, int&amp; max)&#123; if(i==0) return array.at(0); int f1 = f(array, i-1, max); if(f1&lt;0) f1 = array.at(i); else&#123; f1 = f1+ array.at(i); &#125; if(f1&gt; max) max =f1; return f1; &#125;&#125;; 31.整数中1出现的次数（从1到整数n中1出现的次数）题目描述求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数（从1 到 n 中1出现的次数）。 解法一：时间复杂度: $O(nm)$, m为数字的长度 直接借助C++函数，先将int转换成string，然后count计算string里面‘1’的个数。（这种方法可能面试不会满意，可以提一下，不过肯定有其他方法） 12345678910111213class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count_1 = 0 ; for(int i = 1; i&lt;=n; i++)&#123; string str = std::to_string(i); count_1 += std::count(str.begin(), str.end(), '1'); &#125; return count_1; &#125;&#125;; 解法二：对每个数字进行除和求余的运算，得到每个数字中1的个数，然后将个数相加。 该方法的复杂度为 $O(nlogn)$ ，该种思想过于直接，时间复杂度较高，属于次等方案。（注意：这里的log底数按理说是10 ，但说大O记法是不考虑常数的，所以直接表示成log就可以） 123456789101112131415161718192021222324class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count =0 ; for(int i =1 ;i&lt;=n;i++)&#123; int i1 = has1(i); if(i1) count+=i1; &#125; return count; &#125; int has1(int num)&#123; int count=0; while(num)&#123; if(num%10 == 1) count++; num /= 10; &#125; return count; &#125;&#125;; 解法三：时间复杂度: $O(logn)$ 设定整数点（如1、10、100等等）作为位置点i（对应n的各位、十位、百位等等），分别对每个数位上为1的情况有多少种进行分析 根据设定的整数位置，对n进行分割，分为两部分，高位n/i，低位n%i 当i表示百位，且百位对应的数&gt;=2时,如n=31456,i=100，则a=314,b=56，此时百位为1的情况有a/10+1=32（最高两位0~31，百位为1,共32种），每一种都包含100个连续的点，即共有(a%10+1) * 100种情况百位为1 当i表示百位，且百位对应的数为1时，如n=31156， i=100，则a=311,b=56，此时百位对应的就是1，则共有a%10(最高两位0-30)种情况是包含100个连续点，当最高两位为31（即a=311），本次只对应部分情况00~56，共b+1种，所有点加起来共有（a%10*100）+(b+1)种情况可以是百位为1 当i表示百位，且百位对应的数为0,如n=31056,i=100，则a=310,b=56，此时百位为1的情况有a/10=31种（最高两位0~30） 综合以上三种情况，当百位对应0或2时，有(a+8)/10次包含所有100个点，当百位为1时，即(a%10==1)为真时，另外需要增加部分情况b+1种 之所以补8，是因为当百位为0 或者 1 时，则a/10==(a+8)/10，当百位&gt;=2，补8会产生进位位，效果等同于(a/10+1) 1234567891011121314class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count = 0; for(int i =1; i&lt;=n; i*=10)&#123; int a = n/i; int b = n%i; count+=(a+8)/10*i+(int)(a%10==1)*(b+1); &#125; return count; &#125;&#125;; 这种方法是一种通用解法, 可以用来求解整数0~n中x的出现次数, 其中, x 代表1~9中(0的情况貌似也差不多?)的任意一个数, 通用写法如下12345678910111213class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count = 0; for(int i = 1; i&lt;=n ;i = i*10)&#123; int a = n/i; int b = n%i; count += (a+(10-x-1))/10 * i + (int)(a%10==x) * (b+1); //在这里根据x的值, 可以求得不同情况下的解, 例如, 若要求8的出现次数, 则为:count += (a+1)/10 * i + (int)(a%10==8) * (b+1); &#125; return count; &#125;&#125;; 解法四：剑指offer的递归方法，没看懂，感觉好像有错误？ 32.把数组排成最小的数题目描述：输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 难点： 找出一个新的排序规则，同时要证明这个排序规则是有效的 看到将两个int整数拼接在一起，就应该想到大数问题 解法一：主要考虑如何制定一个合理的判断规则： 比较两个字符串s1, s2大小的时候，先将它们拼接起来，比较s1+s2,和s2+s1那个大，如果s1+s2大，那说明s2应该放前面，所以按这个规则，s2就应该排在s1前面。 基于上面的规则，首先将vector&lt;int&gt;转换成对应的vector&lt;string&gt;，然后直接利用快排进行排序，最后将排好序的字符串向量拼接输出。 时间复杂度为主要在排序，因此为 $O(nlogn)$ 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123;public: string PrintMinNumber(vector&lt;int&gt; numbers) &#123; if(numbers.size() == 0) return ""; vector&lt;string&gt; str_numbers; for(auto it=numbers.begin(); it!=numbers.end(); it++)&#123; str_numbers.push_back(std::to_string(*it)); &#125; int low =0; int high = numbers.size()-1; quickSort(str_numbers, low, high); string s=""; for(auto it = str_numbers.begin(); it != str_numbers.end(); it++)&#123; s+=*it; &#125; return s; &#125; void quickSort(vector&lt;string&gt;&amp; str_numbers, int low , int high)&#123; int mid = Partition(str_numbers, low, high); if(mid&lt;high) quickSort(str_numbers,mid+1, high); if(mid&gt;low) quickSort(str_numbers, low, mid-1); &#125; int Partition(vector&lt;string&gt;&amp; str_numbers, int low, int high)&#123; string p = str_numbers.at(low); while(low&lt;high)&#123; string s1= p + str_numbers.at(high); string s2= str_numbers.at(high) + p; while(low&lt;high &amp;&amp; s1.compare(s2) &lt;=0)&#123; high--; s1 = p + str_numbers.at(high); s2 = str_numbers.at(high) + p; &#125; str_numbers.at(low) = str_numbers.at(high); s1 = p + str_numbers.at(low); s2 = str_numbers.at(low) + p; while(low&lt;high &amp;&amp; s1.compare(s2) &gt;=0)&#123; low++; s1 = p + str_numbers.at(low); s2 = str_numbers.at(low) + p; &#125; str_numbers.at(high) = str_numbers.at(low); &#125; str_numbers.at(low) = p; return low; &#125;&#125;; 更整洁的写法:1234567891011121314151617181920212223242526272829303132class Solution &#123;public: bool cmp(int a, int b)&#123; string sa = std::to_string(a); string sb = std::to_string(b); return sa+sb &lt;= sb+sa; &#125; string PrintMinNumber(vector&lt;int&gt; numbers) &#123; if(numbers.size()==0) return ""; //!!!!少了这句话会产生段错误 quick_sort(numbers, 0, numbers.size()-1); string res; for(auto num : numbers) res += std::to_string(num); return res; &#125; int partition(vector&lt;int&gt; &amp;numbers, int low, int high)&#123; int P = numbers[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; cmp(P, numbers[high])) high--; numbers[low] = numbers[high]; while(low&lt;high &amp;&amp; cmp(numbers[low], P)) low++; numbers[high] = numbers[low]; &#125; numbers[low] = P; return low; &#125; void quick_sort(vector&lt;int&gt; &amp;numbers, int low , int high)&#123; int mid = partition(numbers, low, high); if(low&lt;mid) quick_sort(numbers, low, mid-1); if(mid&lt;high) quick_sort(numbers, mid+1, high); &#125;&#125;; 用C++的内置排序函数:1234567891011121314151617class Solution &#123;public: struct&#123; bool operator()(int a, int b) const&#123; string sa = std::to_string(a); string sb = std::to_string(b); return sa+sb &lt; sb+sa; &#125; &#125;cmp; string PrintMinNumber(vector&lt;int&gt; numbers) &#123; std::sort(numbers.begin(), numbers.end(), cmp); string res; for(auto num : numbers) res += std::to_string(num); return res; &#125;&#125;; 33.丑数题目描述：把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数 解法一：穷举判断最简单的方法，就是对所有整数进行判断，该方法很容易超时 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: int GetUglyNumber_Solution(int index) &#123; if(index&lt;=0) return 0; int i = 0; int num = 1; int ugly=0; while(i&lt;index)&#123; if(IsUgly(num))&#123; i++; ugly = num; &#125; num++; &#125; num--; return num; &#125; bool IsUgly(int num)&#123; while(num%2==0) num /=2 ; while(num%3==0) num /= 3; while(num%5==0) num /= 5; if(num == 1) return true; else return false; &#125;&#125;; 解法二：根据丑数性质构造丑数时间复杂度: $O(n^2)$空间复杂度: $O(n)$ 用空间换时间，用一个数组将之前的丑数都存起来，然后，在判断下一个丑数时，不用对逐个整数判断，而只是与丑数和2,3,5的乘积进行判断 1234567891011121314151617181920212223242526272829303132333435// 使用指针时，一定要千万注意，指针会改变指向地址的值，使得其他指向该地址的指针，其指向的值也跟着变！class Solution &#123;public: int GetUglyNumber_Solution(int index) &#123; if(index&lt;=0) return 0; int* UglyArray = new int[index]; UglyArray[0] = 1; for(int i = 1 ;i &lt; index; i++)&#123; int *Ugly2 = UglyArray; int *Ugly3 = UglyArray; int *Ugly5 = UglyArray; while(*Ugly2 * 2 &lt;= UglyArray[i-1]) Ugly2++; while(*Ugly3 * 3 &lt;= UglyArray[i-1]) Ugly3++; while(*Ugly5 * 5&lt;= UglyArray[i-1]) Ugly5++; UglyArray[i] = Min(*Ugly2 *2, *Ugly3 *3, *Ugly5 *5); &#125; int num = UglyArray[index-1]; delete[] UglyArray; return num; &#125; int Min(const int&amp; a, const int&amp; b,const int&amp; c)&#123; int x = a&lt;b? a:b; return x&lt;c? x:c; &#125;&#125;;//* 解法三: 最优解法二的思路是正确的, 但是代码的实习上有重复计算, 例如, 最开始丑数集合为 {1}, 经过三次循环后, 丑数集合为 {1, 2, 3, 5}, 此时, 当进行第四次循环时, 会重复计算 1×2, 1×3, 1×5. 根据丑数的定义, 从 1 开始, 可以得到 2,3,5 这三个丑数, 然后从 2,3,5 开始(此时不用管1了), 可以得到 4,6,10,6,9,15,10,15,25 九个丑数, 根据这个思路, 我们可以指定三个变量来指示当前应该与2,3,5相乘的丑数, 而不是从第一个丑数开始遍历. 12345678910111213141516171819class Solution &#123;public: int GetUglyNumber_Solution(int index) &#123; if(index &lt;=1) return 0; vector&lt;int&gt; ugly_numbers(index); ugly_numbers[0] = 1; int t2=0, t3=0, t5=0; for(int i=1; i&lt;index; i++)&#123; int ugly_num = std::min( ugly_numbers[t2]*2, std::min(ugly_numbers[t3]*3, ugly_numbers[t5]*5)); if(ugly_num == ugly_numbers[t2]*2) t2++; // 因为新增的最小丑数为 t2指示的丑数与2相乘, 所以t2之前的数都不可能再与2相乘组成新的丑数, 所以无需检查t2之前的数 if(ugly_num == ugly_numbers[t3]*3) t3++; // 注意, 这里没有用else if 的原因是, 可能会出现重复的情况, 对于这种情况, 重复的指示器都要++, 避免将重复的丑数添加到数组中 if(ugly_num == ugly_numbers[t5]*5) t5++; ugly_numbers[i] = ugly_num; &#125; return ugly_numbers[index-1]; &#125;&#125;; 34.第一个只出现一次的字符题目描述在一个字符串(0&lt;=字符串长度&lt;=10000，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置, 如果没有则返回 -1（需要区分大小写） 解法一（自想）每遇到一个字符，判断其是否是第一次出现，如果是则将它存在一个vector once里面，如果不是，则判断该字符是否在另一个vector more里面，如果没在，则该once中的该字符转移到mul里面，接着判断下一个字符。最终，输出once里面的首个元素。 该方法时间复杂度为 $O(n^2)$，并不令人满意。 123456789101112131415161718192021222324252627282930class Solution &#123;public: int FirstNotRepeatingChar(string str) &#123; vector&lt;int&gt; once_char; vector&lt;char&gt; mul_char; for(int i = 0; i&lt; str.length();i++)&#123; bool isfirst = true; for(auto it = once_char.begin(); it!=once_char.end(); it++)&#123; if(str[*it] == str[i])&#123; isfirst = false; once_char.erase(it); mul_char.push_back(str[i]); break; &#125; &#125; if(isfirst)&#123; auto mul_it = find(mul_char.begin(), mul_char.end(), str[i]); if(mul_it != mul_char.end()) isfirst = false; &#125; if(isfirst)&#123; once_char.push_back(i); &#125; &#125; if(once_char.empty()) return -1; return once_char.front(); &#125;&#125;; 解法二：牛客借助哈希表，时间复杂度为 $O(n)$。哈希表的构造可以用256大小的数组实现，字符对应的int值可作为哈希表的索引，表内的内容存储了该字符出现的次数。总共需要遍历两次字符串，第一次更新数组内字符出现的次数，第二次找到首个出现次数为1的字符。空间复杂度为 $O(1)$ （256是常数） 123456789101112131415161718class Solution &#123;public: int FirstNotRepeatingChar(string str) &#123; int hash_map[256]; for(int i =0;i&lt;256;i++) hash_map[i] = 0; //若少了初始化数组，则通不过，经过验证，数组默认内部不是0,而是随机数？ //有一种更标准初始化为0的方法，无需显式while循环：int hash_map[256]= &#123;0&#125;; for(int i = 0; i&lt;str.length(); i++)&#123; hash_map[int(str[i])]++; &#125; for(int i = 0; i&lt;str.length(); i++)&#123; if(hash_map[int(str[i])] == 1) return i; &#125; return -1; &#125;&#125;; 35.数组中的逆序对题目描述在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007输入描述: 题目保证输入的数组中没有的相同的数字 数据范围： 对于%50的数据,size&lt;=10^4 对于%75的数据,size&lt;=10^5 对于%100的数据,size&lt;=2*10^5 注意：仔细思考，这道题的P的数量会非常大，对于长度为n的数组，其P值最大可为 $\frac{n(n-1)}{2}$ 个。根据体重给出的数据，n最大可为 $2\times 10^5$ ，因此，P最大为 $\frac{2\times 10^5\times(2\times10^5 -1)}{2} \approx 2\times 10^{10}$,因此，使用int类型的数据时，有可能超过限制。所以，要使用long！( int类型数据范围为-21 4748 3648 到 21 4748 3647, 数量级在 $10^9$ 左右) 解法一（自） 暴力求解，时间复杂度 $O(n^2)$ ，这样做肯定不行 解法二（剑指）: 归并排序, 递归实现将数组中的元素进行归并排序, 排序的时候, 如果前面子数组的元素大于后面的元素, 那么可以组成的逆序对的数量就是后面元素剩余的元素数量(两个子数组各自都已经排好序). 这里需要注意的几点： 初始化是，将data数据复制到temp中，然后在递归时，将data和temp数组交换传递，可以不用在数组融合时，将temp中的数据复制到data中， 减少计算次数 数组融合时使用的while循环，条件均为 $&lt;=$ 或 $&gt;=$。 每次得到P的一部分时，都进行取余数，可保证P的值不会过大。（但还是要用long型整数） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class Solution &#123;public: int InversePairs(vector&lt;int&gt; data) &#123; if (data.size() == 0) return 0; vector&lt;int&gt; temp= data; //int P=0; long P = mergeSort(data,temp, 0, data.size()-1); return P%1000000007; &#125; long mergeSort(vector&lt;int&gt;&amp; data,vector&lt;int&gt;&amp; temp, int first, int last)&#123; int mid = (last + first)/2; long inv1=0,inv2=0,inv=0; if(first&lt; last)&#123; //这里，首先temp和data相同，因此对于mergeSort来说，可以顺序颠倒 //此时相当于把temp当前真实数组，而data当作了缓存空间 //经过mergeSort后，data里面数据就是分别排好序的 //所以传向mergeArray时，要把data放前面，把temp放后面 inv1 = mergeSort(temp, data, first, mid); //必须temp在前, 因为temp是已经将子数组排序过的 inv2 = mergeSort(temp, data, mid+1, last); inv = mergeArray(data, temp, first, mid, mid+1, last); //此处data在前的原因是经过mergeSort以后, data变成了排序号的. //上面这种写法的可读性不好, 如果在mergArray函数里面, 使data = temp , 就能写出下面这种可读性较好的形式(但是由于多了赋值操作, 在牛客上会超时). 但是使用for循环只复制需要复制的部分, 就不会超时 /* inv1 = mergeSort(data, temp, first, mid); inv2 = mergeSort(data, temp, mid+1, last); inv = mergeArray(data, temp, first, mid, mid+1, last); */ &#125; return (inv1+inv2+inv)%1000000007; &#125; long mergeArray(vector&lt;int&gt;&amp; data, vector&lt;int&gt;&amp; temp, int first1,int last1,int first2,int last2)&#123; long int inv = 0; int t = last2; int i = last1; int j = last2; while(i&gt;=first1 &amp;&amp; j&gt;=first2)&#123; if(data.at(i) &gt; data.at(j))&#123; temp.at(t) = data.at(i); inv += j-first2+1;; i--; t--; &#125;else&#123; temp.at(t) = data.at(j); j--; t--; &#125; &#125; while(i&gt;=first1)&#123; temp.at(t) = data.at(i); t--; i--; &#125; while(j&gt;=first2)&#123; temp.at(t) = data.at(j); j--; t--; &#125; // data=temp; //这个赋值操作会使得代码整体的可读性较好, 但是可能会超时 /*for(int i=first1; i&lt;=last2; i++) data[i] = temp[i]; //这种复制每次只会复制一部分, 故而没有超时 */ return inv%1000000007; &#125;&#125;; 解法三（剑指）: 归并排序, 迭代实现36.两个链表的第一个公共节点题目描述输入两个链表，找出它们的第一个公共结点。 解法一：栈时间复杂度: $O(m+n)$, 遍历两个链表空间复杂度: $O(m+n)$, 两个栈 分析公共子节点的特点，首先，是单向链表，因此，从第一个公共子节点开始，后面的都是一样的，所以最好是能从链表的最后一项还是比较。但由于是单向链表，因此只能从头访问，从能访问最后的节点。 就像是先进先出一样 因此，考虑用两个辅助栈来帮助实现～ 1234567891011121314151617181920212223242526272829303132/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) &#123; stack&lt;ListNode*&gt; s1; stack&lt;ListNode*&gt; s2; for(ListNode* cur = pHead1; cur!=nullptr; cur = cur-&gt;next)&#123; s1.push(cur); &#125; for(ListNode* cur = pHead2; cur!=nullptr; cur = cur-&gt;next)&#123; s2.push(cur); &#125; ListNode* firstCN = nullptr; while(!s1.empty() &amp;&amp; !s2.empty())&#123; if(s1.top() == s2.top())&#123; firstCN = s1.top(); s1.pop(); s2.pop(); &#125;else break; &#125; return firstCN; &#125;&#125;; 解法二: 常数空间复杂度时间复杂度: $O(m+n)$, 遍历两次空间复杂度: $O(1)$, 不使用额外空间 首先遍历得到两个链表的长度, 然后先让长链表前进长度差个节点, 接着两个链表共同向前遍历, 当相遇时即为第一个公共节点. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) &#123; if(headA==nullptr || headB==nullptr) return nullptr; int lenA = 0; ListNode *curA = headA; while(curA !=nullptr)&#123; lenA++; curA = curA-&gt;next; &#125; int lenB = 0; ListNode *curB = headB; while(curB != nullptr)&#123; lenB++; curB = curB-&gt;next; &#125; if(lenA &gt; lenB)&#123; int len = lenA-lenB; curA = headA; while(len--)&#123; curA = curA-&gt;next; &#125; curB = headB; while(curA!=nullptr &amp;&amp; curB!=nullptr)&#123; if(curA == curB) return curA; curA = curA-&gt;next; curB = curB-&gt;next; &#125; return nullptr; &#125;else&#123; int len = lenB-lenA; curB = headB; while(len--)&#123; curB = curB-&gt;next; &#125; curA = headA; while(curA!=nullptr &amp;&amp; curB!=nullptr)&#123; if(curA == curB) return curA; curA = curA-&gt;next; curB = curB-&gt;next; &#125; return nullptr; &#125; &#125;&#125;; 37.数字在排序数组中出现的次数题目描述统计一个数字在排序数组中出现的次数。 解法一（自想）先利用二分查找找到该数字的下标，然后统计该数字左右两边的相等数的个数，虽然二分查找的时间复杂度为$O(logn)$，但是在对该数左右两边查看相等数个数时，时间复杂度为 $O(n)$，因此，最终的时间复杂度应为 $O(n)$ 。 （这样的复杂度不会让面试官满意） 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int GetNumberOfK(vector&lt;int&gt; data ,int k) &#123; int count = 0; if(data.size() == 0) return count; int index = binarySearch(data, k, 0, data.size()-1); if(index == -1) return count; else&#123; int i = index-1; while(index&lt;data.size() &amp;&amp; data.at(index) == k)&#123; index++; count++; &#125; while(i&gt;=0 &amp;&amp; data.at(i) == k)&#123; i--; count++; &#125; &#125; return count; &#125; int binarySearch(vector&lt;int&gt;&amp; data, int num, int first, int last)&#123; if(first == last)&#123; if(data.at(first) == num) return first; else return -1; &#125; int mid = (first+last)/2; if(data.at(mid) == num) return mid; else if(data.at(mid) &gt; num) return binarySearch(data, num ,first, mid); else return binarySearch(data, num, mid+1, last); &#125;&#125;; 解法二：牛客分析上面的方法，时间复杂度高的主要原因来自于最后的顺序检索。设想一下，如果知道目标数字出现的第一个位置和最后一个位置，是否就不用再进行顺序检索了？ 于是，可以将二分查找算法改成分别查找目标数字的首次出现位置和末次出现位置。也就是说，如果mid上的数字等于num，同时mid-1（mid&gt;0）上的数字不等于num，则mid为首次出现位置，否则，首次出现位置就应该还在前半段，同理，末次出现位置也是相似的道理。 结合以上讨论，将二分查找分成两个函数，分别找首次和末次位置，这样时间复杂度就是 $O(logn)$，无需进行顺序查找。 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;public: int GetNumberOfK(vector&lt;int&gt; data ,int k) &#123; int count = 0; if(data.size() == 0) return count; int index1 = binarySearchFirst(data, k, 0, data.size()-1); int index2 = binarySearchLast(data, k, 0, data.size()-1); if(index1 == -1 || index2 == -1) return 0; else return index2-index1+1; &#125; int binarySearchFirst(vector&lt;int&gt;&amp; data, int num, int first, int last)&#123; if(first &gt; last) return -1; int mid = (first+last)/2; if(data.at(mid) == num)&#123; if(mid == 0 || data.at(mid-1) != num) return mid; else return binarySearchFirst(data, num ,first, mid-1); &#125; else if(data.at(mid) &gt; num) return binarySearchFirst(data, num ,first, mid-1); else return binarySearchFirst(data, num, mid+1, last); &#125; int binarySearchLast(vector&lt;int&gt;&amp; data, int num, int first, int last)&#123; if(first &gt; last) return -1; int mid = (first+last)/2; if(data.at(mid) == num)&#123; if(mid==last || data.at(mid+1)!=num) return mid; else return binarySearchLast(data, num, mid+1, last); &#125; else if(data.at(mid) &gt; num) return binarySearchLast(data, num ,first, mid-1); else return binarySearchLast(data, num, mid+1, last); &#125;&#125;; 解法三: 解法二的非递归实现(更简洁易懂)1234567891011121314151617181920212223class Solution &#123;public: int GetNumberOfK(vector&lt;int&gt; data ,int k) &#123; int low = 0, high = data.size()-1; int first_k = -1, last_k = -1; if(data.size() == 0) return 0; while(low &lt; high)&#123; int mid = (low+high)/2; if(data[mid] &lt; k) low = mid+1; else high = mid; //在data[mid] == k时并不退出, 而是继续判断, 知道low==high时, 才会退出, 此时 low 和 high 都应指向最左侧的k值 &#125; if(data[low] != k) return 0; else first_k = low; high = data.size()-1; while(low &lt; high)&#123; int mid = (low+high+1)/2; // 因为只有 high 会移动到mid的下一位, 而low是等于mid的, 所以必须让mid更偏向右侧, 上面的逻辑也是同理, 希望让mid更偏向左侧 if(k &lt; data[mid]) high = mid-1; else low = mid; &#125; last_k = low; return last_k - first_k + 1; &#125;&#125;; 解法四: 寻找插入位置因为data中都是整数，所以可以稍微变一下，不是搜索k的两个位置，而是搜索 k-0.5 和 k+0.5 这两个数应该插入的位置，然后相减即可。因为数组中不存在 k-0.5 和 k+0.5 这两个数, 因此, 我们只需不断二分查找, 直到 low &gt; high 为止即可. 123456789101112131415class Solution &#123;public: int GetNumberOfK(vector&lt;int&gt; data ,int k) &#123; return binary(data, k+0.5) - binary(data, k-0.5); &#125; int binary(vector&lt;int&gt; &amp;data, double k)&#123; int low =0 , high = data.size()-1; while(low &lt;= high)&#123; // 这里的等于号是必不可少的 int mid = (low+high)/2; if(data[mid] &lt; k) low = mid+1; else high = mid - 1; &#125; return low; &#125;&#125;; 38.二叉树的深度题目描述输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 解法一: 非递归利用BFS广度优先遍历（错了，树没有广度遍历，这个应该叫层次遍历），结合一个专门存储当前节点所处深度的队列实现 利用一个layer_count变量来记录当前层总共的节点数, 每次当pop了当前节点数个节点后, depth都会增1，最终的树深度，就应该等于广度优先遍层次遍历历最后一个访问节点所处的深度。（因为这肯定是最后一层，也就是最深的一层） 123456789101112131415161718192021222324252627282930/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: int TreeDepth(TreeNode* pRoot) &#123; if(pRoot == nullptr) return 0; queue&lt;TreeNode*&gt; tree_q; tree_q.push(pRoot); int depth = 0; while(!tree_q.empty())&#123; int layer_count = tree_q.size(); //记录当前层共有多少节点 for(int i =0 ; i&lt;layer_count; i++)&#123; // 根据当前层节点进行pop TreeNode* cur_node = tree_q.front(); tree_q.pop(); if(cur_node-&gt;left != nullptr) tree_q.push(cur_node-&gt;left); if(cur_node-&gt;right != nullptr) tree_q.push(cur_node-&gt;right); &#125; depth++; &#125; return depth; &#125;&#125;; 解法二：牛客二叉树中的某个节点的深度，就是其左子树深度和右子树深度较大者+1 ， 二叉树的深度就是根节点的深度，所以，利用递归的思想实现。（代码简洁，但是复杂复杂度好像和广度优先一样，都是n？ 是这样吗？） 123456789101112class Solution &#123;public: int TreeDepth(TreeNode* pRoot) &#123; if(pRoot==nullptr) return 0 ; int depth1 = 1, depth2 = 1; if(pRoot-&gt;left!=nullptr) depth1 = TreeDepth(pRoot-&gt;left)+1; if(pRoot-&gt;right!=nullptr) depth2 = TreeDepth(pRoot-&gt;right)+1; return depth1&gt;depth2 ? depth1 : depth2; &#125;&#125;; 更简洁的写法:12345678class Solution &#123;public: int TreeDepth(TreeNode* pRoot) &#123; if(pRoot == nullptr) return 0; return max( TreeDepth(pRoot-&gt;left)+1, TreeDepth(pRoot-&gt;right)+1); &#125;&#125;; 39.平衡二叉树题目描述输入一棵二叉树，判断该二叉树是否是平衡二叉树。 解法一（自想）时间复杂度: $O(n)$, 每个节点至多访问一次空间复杂度: $O(n)$, 有可能需要进行 n 次递归 将题目看作是求左右子树的深度，如果深度差超过1,那么就不是二叉树，返回一个特殊的标识（-1），这种方法属于一边遍历，一边判断，只需要遍历每个节点一次，通过递归实现。时间复杂度为 $O(logn)$ 有一种“不太好”的方法是每遇到一个节点，就单独求一次这个节点对应的树的深度，这种做法要遍历一个节点很多次，是一种典型的不令人满意的做法, 下面的做法采用了剪枝, 使得对每个节点至多访问一次, 是较好的做法 12345678910111213141516171819class Solution &#123;public: bool IsBalanced_Solution(TreeNode* pRoot) &#123; int tdepth = treeDepth(pRoot); if(tdepth!=-1) return true; else return false; &#125; int treeDepth(TreeNode* root)&#123; if(root == nullptr) return 0; int leftdepth = treeDepth(root-&gt;left); if(leftdepth == -1) return -1; int rightdepth = treeDepth(root-&gt;right); if(rightdepth == -1) return -1; if(abs(leftdepth-rightdepth) &gt; 1) return -1; return max(leftdepth,rightdepth) + 1; &#125;&#125;; 更凝练的写法:1234567891011121314class Solution &#123;public: bool IsBalanced_Solution(TreeNode* pRoot) &#123; return tree_depth(pRoot)==-1 ? false : true; &#125; int tree_depth(TreeNode* pRoot)&#123; if(pRoot == nullptr) return 0; int left_depth = tree_depth(pRoot-&gt;left); //注意, 这里没有 +1, if(left_depth==-1) return -1; // 在这里直接断left_depth判断, 如果发现=-1,就一路返回, 无需再求右子树深度 int right_depth = tree_depth(pRoot-&gt;right); //注意, 这里没有 +1 if(right_depth==-1 || abs(left_depth-right_depth) &gt; 1) return -1; return max(left_depth, right_depth) + 1; // 注意, 这有一定要有+1, 因为树深度就等于左右子树最大深度+1 &#125;&#125;; 40.数组中只出现一次的数字题目描述一个整型数组里除了两个数字之外，其他的数字都出现了偶数次。请写程序找出这两个只出现一次的数字。 （暴力解法就不提了，肯定不是最优。） 解法一：异或注：异或运算符还可以实现无中间变量的两个数字互换：123456789int a=2;int b=4;a = a^b; // a = 2^4 = 6b = a^b; // b = 6^4 = 2a = a^b; // a = 6^2 = 4//同理有a = a + b; // a = 2+4 = 6a = a - b; // b = 6-4 = 2a = a - b; // a = 6-2 = 4 异或运算的性质：任何一个数字异或它自己都等于0 。与0异或则保留原值也就是说，如果我们从头到尾依次异或数组中的每一个数字，那么最终的结果刚好是那个只出现一次的数字，因为那些出现两次的数字全部在异或中抵消掉了。 （这里不限定是一次，只要是奇数次都可以） 本题数列中，有两个出现一次的数字，第一次先全部异或，得到的结果是两个一次数字的异或值，该异或值至少有一位的值为1 (即在这一位上, 两个数字一个为0, 一个为1), 因此，找到这一位，然后根据这一位这数组分成两拨，如此一来，每一拨都变成了上面的简单情况。 （同理，如果有N个一次数字，可以通过不断分拨的方法解决, 例如, 如果有3个一次数字, 则找了为1的那一位, 可以将其分成具有2个一次数字和具有一个一次数字的两拨数组） 12345678910111213141516171819class Solution &#123;public: void FindNumsAppearOnce(vector&lt;int&gt; data,int * num1,int * num2) &#123; if(data.size() &lt; 2 ) return; int xor_res = 0; for(auto x : data) xor_res ^= x; int i = 1; while( (xor_res &amp; i) == 0) // 按位异或的优先级小于 '==' 的优先级, 因此一定要用括号括起来 i = i&lt;&lt;1; *num1=0, *num2=0; //return; for(auto x : data)&#123; if( (x &amp; i) != 0) // 按位与的优先级小于 '!=' , 所以必须用括号 *num1 = *num1 ^ x; else *num2 = *num2 ^ x; &#125; &#125;&#125;; 扩展: 数组中只有一个数出现一次，其他数都出现了2次，找出这个数字1234567int find1From2(vector&lt;int&gt; a)&#123; int len = a.size(), res = 0; for(int i = 0; i &lt; len; i++)&#123; res = res ^ a[i]; &#125; return res; &#125; 扩展: 数组中只有一个数出现一次，其他数字都出现了3次(奇数次)，找出这个数字例如数组a[]={2,4,4,4,6,6,6};结果则返回2；思路则是利用位运算，因为其他数字都出现了三次，那么他们的二进制相同位上1的个数则是3的倍数，这样的话，最后统计完3的倍数的位清0，剩下的1则都是那个只出现一次的数的位。(也可以先统计每一位上面1的个数, 最后模3取余)1234567891011121314151617int find1From3(vector&lt;int&gt; a)&#123; int *bits = new int[32]; //因为整数一般为4字节, 32位 int len = a.size(); for(int i = 0; i &lt; len; i++)&#123; for(int j = 0; j &lt; 32; j++)&#123; bits[j] = bits[j] + ( (a[i]&gt;&gt;j) &amp; 1); # 注意这里的括号是必不可少的, 因为 &amp; 的优先级比 + 低得多 &#125; &#125; int res = 0; for(int i = 0; i &lt; 32; i++)&#123; if(bits[i] % 3 !=0)&#123; res = res | (1 &lt;&lt; i); &#125; &#125; delete[] bits; return res;&#125; 可以看出, 这是一种比较通用的解法, 可以求解某个数字出现一次, 而其他数字出现n次的情况(如果n为偶数, 建议用异或实现). 41.和为S的连续正数序列题目描述小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck!输出描述:输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序 解法一（自想）设置两个变量记录当前序列的start位置和end位置，判断当前序列的和: 如果=sum，则存储当前序列，并将start+1,序列前进; 如果&gt;sum,将应减去序列中的最小值，也就是start指向位置的值，然后start+1; 如果&lt;sum，则应该再加上下一个值，也就是end指向的值。 然后再进行上面的循环，直到start指向的位置值为(sum+1)/2,此时就已经不可能出现和为sum的连续序列了。该方法时间复杂度为$O(n)$ 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; FindContinuousSequence(int sum) &#123; vector&lt;vector&lt;int&gt;&gt; results; int tmp = 0; int start = 1; for(int end =start; start &lt;= sum/2 ;)&#123; if(tmp == sum)&#123; vector&lt;int&gt; numseq; for(int i = start ; i&lt;end; i++)&#123; numseq.push_back(i); &#125; results.push_back(numseq); tmp -=start; // 需要注意这里的顺序, 一定要先减去了 start 以后, 才能执行 start++ start++; &#125;else if( tmp &gt; sum)&#123; tmp -= start; start++; &#125;else&#123; tmp += end; end++; &#125; &#125; return results; &#125;&#125;; 解法二: 等差序列求和公式42.和为S的两个数字题目描述输入一个递增排序的数组和一个数字S，在数组中查找两个数，使得他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。输出描述:对应每个测试案例，输出两个数，小的先输出。 解法一（自想）设置两个变量，分别指向数组的第一个位置和最后一个位置，然后将这两个变量所指位置的值相加，分以下三种情况： =sum; 判断二者乘积是否比当前最小值小，如果是，则改变最小值的持有值。 不管是否小，都将num1++ 实际上, 根本无需判断是否比当前最小值小, 因为对于和相同的两组数, 数字差值较大的那一组的成绩一定小于数字差值较小的, 因此, 只要找到符合和为sum条件的两个数字, 即可直接返回, 无需进行任何额外判断. &gt;sum; num2--; &lt;sum; num1++;循环以上三步直到 num1&gt;=num2。最后判断minnum1和minnum2的值，如果二者相等，说明数组里面不存在这样的数对儿，返回空vector，若不相等，则输出这两个值。 结论证明：假设：找到两组满足条件的数组对 $（x，y）$、$（x+a,y-a）$，其中（ $x+y=S, 0&lt;a&lt;y-x$ ） x*y-[(x+a)(y-a)]=x*y-x*y-(y-x)a+a2=a[a-(y-x)]因为 $0&lt;a&lt;y-x$ ,所以 $a-(y-x)&lt;0$ ,所以 $a[a-(y-x)]&lt;0$因此 $(x,y)$ 乘积一定比 $(x+a,y-a)$ 小 当第一次找到符合条件的两个数字时, 它们的乘积就一定是最小的, 所以可以直接退出.12345678910111213141516171819202122class Solution &#123;public: vector&lt;int&gt; FindNumbersWithSum(vector&lt;int&gt; array,int sum) &#123; vector&lt;int&gt; res; if(array.size() &lt; 2) return res; int low = 0, high = array.size()-1; //在使用容器的back()方法访问时，必须要确保容器不是空的，否则会出现段错误（访问越界） while(low &lt; high)&#123; if(array[low] + array[high] == sum)&#123; //首次找到就可返回 res.push_back(array[low]); res.push_back(array[high]); return res; //首次找到就可返回 low++; &#125;else if(array[low] + array[high] &lt; sum) low++; else high--; &#125; return res; &#125;&#125;; 43.左旋转字符串题目描述汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！ 解法一（自想）：利用str.substr(pos,n)注意： 这道题看似简单，实则很容易考虑不全，主要需注意以下几点： n大于str.length()的情况 str.length()=0的情况 n为负数的情况（虽然这里牛客没考虑，我觉得题里没说正数，所以是有负数的可能的） 越是简单的题，越要注意各种情况的考虑，因为这种题的考察点就是考虑是否全面，而不是题怎么解 12345678910111213class Solution &#123;public: string LeftRotateString(string str, int n) &#123; string res = ""; if(str.length() == 0) return str; if (n&gt;=str.length()) n = n % str.length(); if(n&lt;0) n = str.size() + n; 左移n位(负), 等于右移-n位, 等于左移size+n位 res=str.substr(n); res += str.substr(0,n); return res; &#125;&#125;; 解法二（牛客）：反转利用多次反转的方法，首先将字符串按照n的位置分成两部分，然后进行以下三步（abcdefg，2）： 反转前一部分：ba 反转后一部分：gfed 反转整个字符串：bagfed -&gt; defgab 时间复杂度也为$O(n)$ 12345678910111213141516171819class Solution &#123;public: void my_inverse(string &amp;str, int start, int high)&#123; int mid = (start+high)/2; for(int i = start ; i&lt;=mid; i++)&#123; std::swap(str[i], str[high-i+start]); // 这里注意交换时的下标, 因为i是从start开始的, 所以高位的下标应该为high-(i-start) &#125; &#125; string LeftRotateString(string str, int n) &#123; if(n==0) return str; if(n&lt;0) n = str.size() + n; //左移n位(负), 等于右移-n位, 等于左移size+n位 if (n&gt;=str.length()) n = n % str.length(); my_inverse(str, 0, n-1); my_inverse(str, n, str.size()-1); //return str; my_inverse(str, 0, str.size()-1); return str; &#125;&#125;; 利用 std::reverse() 实现:1234567891011121314class Solution &#123;public: string LeftRotateString(string str, int n) &#123; string res = ""; if(str.length() == 0) return str; if (n&gt;=str.length()) n = n % str.length(); if(n&lt;0) n = str.size() + n; //左移-n位, 等于右移n位, 等于左移size-n位 std::reverse(str.begin(), str.begin()+n); std::reverse(str.begin()+n, str.end()); std::reverse(str.begin(), str.end()); return str; &#125;&#125;; 44.翻转单词顺序列牛客最近来了一个新员工Fish，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？ 解法一: 土办法设值两个标记i，j，都从字符串的最后一位开始，如果当前字符不是空格，那么i指向下一个，直到遇到空格为止，此时，将i到j范围内字符提取出来，然后把令j=i。重复以上过程，直到i=0为止。 该解法时间复杂度为 $O(n)$ 而且只需遍历一边字符串。 但是空间复杂度也为 $O(n)$12345678910111213141516171819202122class Solution &#123;public: string ReverseSentence(string str) &#123; if(str.length() == 0) return str; string res = ""; for(int i = str.length()-1, j=str.length()-1; i&gt;=0; )&#123; if(str[i] == ' ')&#123;//这里注意不能用双引号,双引号代表字符串,在C++内部,""与''表示的是不同的东西 res += str.substr(i+1,j-i); res += " "; i--; j = i; &#125;else if(i == 0)&#123; res += str.substr(i,j-i+1); i--; &#125;else&#123; i--; &#125; &#125; return res; &#125;&#125;; 解法二（牛客）：利用reverse执行两次反转首先反转整个字符串，然后以空格为间隔，反转每个单词。时间复杂度也是$O(n)$ (遍历两次).空间复杂度为 $O(1)$1234567891011121314class Solution &#123;public: string ReverseSentence(string str) &#123; std::reverse(str.begin(), str.end()); int i = 0; for(int j = 0; j&lt;=str.size(); j++)&#123; if(str[j] == ' ' || j == str.size())&#123; std::reverse(str.begin()+i, str.begin()+j); i=j+1; &#125; &#125; return str; &#125;&#125;; 45.扑克牌顺子题目描述LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有2个大王,2个小王(一副牌原本是54张)他随机从中抽出了5张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子…..LL不高兴了,他想了想,决定大\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们LL的运气如何， 如果牌能组成顺子就输出true，否则就输出false。为了方便起见,你可以认为大小王是0。 注意:该题目需要注意：1123 这样的顺序返回的是false 解法一(自想):分析能组成顺子的数字的特征，首先，最大的数字和最小的数字他们的差一定要比numbers的size小，否则，肯定连不了顺子。比如12345和2300等。其次，如果数组中出现非0的重复数字，那么也一定不是顺子。因此，代码可以这样写： 找出非0的最大值和最小值 在找最值的时候顺便利用最简单的hash表来存储每个数字出现的次数，hash表长度为14，key值为数字，value值为key值出现的次数，如果value出现&gt;1的情况，则直接返回false 做判断，如果max-min&lt; numbers.size()，则返回true，否则返回false。 以上程序时间复杂度为$O(n)$ ，并且只需要遍历一次numbers。 12345678910111213141516171819202122232425class Solution &#123;public: bool IsContinuous( vector&lt;int&gt; numbers ) &#123; if(numbers.size() == 0) return false; int i = 0; while(numbers[i] == 0) i++; int min=numbers.at(i); int max = numbers.at(i); int zeronum = 0; int count[14] = &#123;0&#125;; for(auto it = numbers.begin(); it!=numbers.end(); it++)&#123; if(*it &lt; min &amp;&amp; *it!=0) min = *it; if(*it &gt; max) max = *it; if(*it == 0) zeronum++; count[*it]++; if(*it != 0 &amp;&amp; count[*it] &gt; 1) return false; &#125; if(max-min &lt;= numbers.size() - 1) return true; else&#123; return false; &#125; &#125;&#125;; 上面对max和min赋值的时候, 有可能会出现需要遍历n次的情况, 用下面的方法稍微改进一下(复杂度不变), 要注意不论是max还是min, 都不能为0.(全0的情况时, 会返回true)12345678910111213141516class Solution &#123;public: bool IsContinuous( vector&lt;int&gt; numbers ) &#123; if(numbers.size() == 0) return false; int poke_hash[14]=&#123;0&#125;; int max_poke = INT_MIN, min_poke = INT_MAX; for(auto item : numbers)&#123; poke_hash[item]++; if(item!=0 &amp;&amp; poke_hash[item]&gt;1) return false; if(item!=0 &amp;&amp; item &lt; min_poke) min_poke = item; else if(item!=0 &amp;&amp; item &gt; max_poke) max_poke = item; if(max_poke!=INT_MIN &amp;&amp; min_poke!=INT_MAX &amp;&amp; max_poke - min_poke &gt;= numbers.size()) return false; &#125; return true; &#125;&#125;; 另一种写法, 可以让判断条件不用写的那么复杂, 推荐使用这种写法:1234567891011121314151617181920class Solution &#123;public: bool IsContinuous( vector&lt;int&gt; numbers ) &#123; int len = numbers.size(); if(len==0) return false; int hash_map[13]&#123;0&#125;; int min=INT_MAX, max=INT_MIN, zero=0; for(auto n : numbers)&#123; if(n==0) continue; else if(hash_map[n-1]&gt;0) return false; else if(n&lt;min) min = n; else if(n&gt;max) max = n; if(min!=INT_MAX &amp;&amp; max!=INT_MIN &amp;&amp; max-min&gt;=len) return false; //如果发现已经不可能出现顺子, 则提前退出 hash_map[n-1]++; &#125; if(min==INT_MAX || max==INT_MIN) return true; if(max - min &lt;len) return true; return false; &#125;&#125;; 解法二（牛客）：排序先排序，在统计0的个数，再用0填补空缺，时间复杂度为 $O(nlogn)$ 不如上面的方法好。 46.圆圈中最后剩下的数：约瑟夫（Josephuse）环问题题目描述0,1,…,n-1这n个数字排成一个圆圈，从数字0开始每次删除m-1处的数字，然后从这个数字的下一位继续从0开始，删除m-1处的数字，求出圆圈里剩下的最后一个数字 解法一（自想）：利用vector维护动态数组模拟约瑟夫环利用一个vector维护一个动态数组，数组内的内容是每个孩子的编号，每次要删除的节点位置，都在index+m-1处，如果index+m-1超过了数组的大小，则对数组的size求余即可。该算法是最简单的一种思路，vector或list在删除时，由于要将后面的元素向前挪，所以erase的时间复杂度为 $O(n)$ ，因此，总的时间复杂度为$O(n^2)$。 空间复杂度为 $O(n)$ 1234567891011121314151617class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if(n&lt;=0 || m&lt;=0) return -1; if(n == 1) return 0; vector&lt;int&gt; joseph_ring; for(int i = 0; i&lt;n; i++) joseph_ring.push_back(i); int index = 0; while(joseph_ring.size() &gt; 1)&#123; index = (index+m-1) % joseph_ring.size(); joseph_ring.erase(joseph_ring.begin() + index); &#125; return joseph_ring[0]; &#125;&#125;; 解法二（牛客）：经典解法，用环形链表模拟圆圈可以用std::list或者std::vector来模拟一个环形链表，由于它们本身不是循环的，因此需要记得手动实现循环逻辑（其实就是解法一） 如果要求不可以使用标准模板库里面的数据容器来模拟环形链表，那么可以自己设计结构体类型，实现一个循环链表。 这里由于链表随机在删除节点时的时间复杂度为 $O(1)$ , 但是无法进行随机访问，只能顺序访问，因此删除时需要先顺序移动到该节点上才行, 所以要时间复杂度仍然为$O(n^2)$ 空间复杂度为$O(n)$。 解法三（牛客）：分析每次删除时的数字规律，总结出以下公式，按照公式编写递归或非递归程序，时间复杂度为 $O(n)$，空间复杂度为 $O(1)$ 。 f(n) = \begin{cases} 0 & n=1 \\ [f(n-1,m)+m]\%n & n>1 \end{cases}思考过程：当把第m个数(下标为m-1)去掉以后, 就只剩下了n-1个数, 此时, 再从下标m开始, 继续进行大小为n-1的约瑟夫环问题. 这里假设我们已经知道了大小为n-1的约瑟夫环问题的解为下标 $x’$, 则 $x’$ 在大小为n的约瑟夫环问题里面的下标应该为: $x = (x’ + m) % n$ . 由此式即可得到上面的递归公式 1234567891011121314//非递归写法class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if(n&lt;=0 || m&lt;=0) return -1; int cur_n=1, res=0; while(cur_n &lt;= n)&#123;// 注意是&lt;=, 因为此处的i代表的是size, 必须要一直计算到i==n为止 res = (res+m) % cur_n; //注意是要除以cur_n, 而不是n cur_n++; &#125; return res; &#125;&#125;; 12345678910递归写法class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if(n&lt;=0 || m&lt;=0) return -1; if(n==1) return 0; return (LastRemaining_Solution(n-1,m)+m)%n; &#125;&#125;; 47.非常规法求前n项和题目描述求1+2+3+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 这道题本身没有实际意义，侧重考察发散性思维和对C++相关机制的理解程度。 解法一：构造函数每声明一个对象，则构造函数都被调用一次，因此，可以借助静态变量来在构造函数内部实现累加操作。 123456789101112131415161718192021class sum&#123; public: static int i ; static int s; sum()&#123;i++; s+=i;&#125;; ~sum()&#123;&#125;; static void set()&#123; i = 0; s = 0; &#125;; &#125;;int sum::i =0;int sum::s = 0;class Solution &#123;public: int Sum_Solution(int n) &#123; sum::set(); sum a[n]; return sum::s; &#125;&#125;; 解法二：虚函数利用虚函数来模拟递归函数，可以在两个类中分别定义函数，其中一个函数充当递归函数的角色，另一个函数处理终止递归的情况，然后在两个函数里二选一。 这里用到了一个小trick，那就是对于整型变量n，执行!!n以后，可以将其转换成布尔值（0和1）。 1234567891011121314151617181920class A&#123; public: virtual int sum(int n)&#123;return 0;&#125;;&#125;;A* Array[2]; //这里必须为指针，否则不会进入B的sum 函数class B : public A&#123; public: virtual int sum(int n)&#123;return Array[!!n]-&gt;sum(n-1) + n;&#125;;&#125;;class Solution &#123;public: int Sum_Solution(int n) &#123; class A a; class B b; Array[0] = &amp;a; Array[1] = &amp;b; return Array[1]-&gt;sum(n); &#125;&#125;; 上面用了虚函数，那么使用普通的函数可以吗？答案是否定的，因为使用普通函数时，无法同时调用两个类的函数，最终只会调用A类的sum函数。 解法三：函数指针同样是上面的思想，不过改为使用函数指针来实现两个函数模拟递归 1234567891011121314151617int A(int n)&#123; return 0;&#125;int B(int n)&#123; static int (*fun[2])(int n) = &#123;A,B&#125;; return fun[!!n](n-1) + n;&#125;class Solution &#123;public: int Sum_Solution(int n) &#123; return B(n); &#125;&#125;; 解法四：模板类使用模板类完成递归，这种方法有一个很大的缺点就是整个过程是在编译阶段完成的，因此无法使用动态的n，而必须是在编译期间就能确定的常量，另外，编译器对递归编译代码的递归深度也是有限制的，所以n不能太大。 48.不用加减乘除做加法49.把字符串转换成整数题目描述将一个字符串转换成一个整数(实现Integer.valueOf(string)的功能，但是string不符合数字要求时返回0)，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0。输入描述: 输入一个字符串,包括数字字母符号,可以为空 输出描述: 如果是合法的数值表达则返回该数字，否则返回0 解法一（自想）：从头开始逐个字符遍历，每次遇到一个“数字”，就将之间的res×10，然后再加上这个数字。需要特别注意“-123”，“+123”等情况。 时间复杂度为 $O(n)$ 。 12345678910111213141516171819202122class Solution &#123;public: int StrToInt(string str) &#123; int res = 0; bool negative = false; int i = 0; if(str[i] == '-')&#123; negative=true; i++; &#125;else if(str[i] == '+') i++; for(; i &lt; str.length() ;i++)&#123; if( str[i] &gt;= '0' &amp;&amp; str[i] &lt;= '9')&#123; res = res*10 + (int)(str[i] - '0'); &#125;else return 0; &#125; if(negative) res = 0 - res; return res; &#125;&#125;; 注意上面的代码虽然已经解决了牛客的题，但是有几点是需要特别注意的！ 首先，题目很简单，所以这道题的考察点只在于是否将所有情况都考虑到了，以下是一些可能的情况，日后再遇到一定要想起来： 首先考虑如何返回错误，首先不能使用可以转换成数值类型（int，bool，char）的数据直接指明错误（比如返回0，无法得知到底是错误当时真的是0），由此，可以创建一个全局的错误变量，如果要返回错误，则返回0并且将该变量状态改变。 非数字类符号不全是错误输出，如：+123、-123 只输入+和-时，要返回错误 string str==&quot;&quot;时，也要返回错误 如果为char str*，则要判断指针是否为空 一定要考虑数值溢出情况（当转换的数字大于最大正数，小于最小负数时，会溢出） 50.数组中重复的数字题目描述在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。 解法一：暴力对于每个数组中的数字，都到前面的数字中去寻找是否有重复的。 时间复杂度： $O(n^2)$ 空间复杂度： $O(1)$ 解法二：哈希建立长度为n的哈希表，每次遇到一个数字x，就在hash[x]增1，如果此时hash[x]变为2，那么就说明有重复。 时间复杂度： $O(n)$ 空间复杂度： $O(n)$ 1234567891011121314151617181920212223class Solution &#123;public: // Parameters: // numbers: an array of integers // length: the length of array numbers // duplication: (Output) the duplicated number in the array number // Return value: true if the input is valid, and there are some duplications in the array number // otherwise false bool duplicate(int numbers[], int length, int* duplication) &#123; vector&lt;int&gt; hash(length); for (int i = 0; i&lt; length; i++)&#123; hash[numbers[i]]++; if(hash[numbers[i]] &gt; 1)&#123; *duplication = numbers[i]; return true; &#125; &#125; return false; &#125;&#125;; 解法三51.构建乘积数组题目描述给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0]A[1]…A[i-1]A[i+1]…A[n-1]。不能使用除法。 解法一（自想）：将乘积看成两段，前i-1项的乘积，和后n-i项的乘积，分开计算，最终合并。时间复杂度： $O(n)$ 空间复杂度： $O(n)$ 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; multiply(const vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; B; int tmp = 1; for(auto it = A.begin(); it!=A.end(); it++)&#123; if(it!=A.begin()) tmp *= *(it-1); B.push_back(tmp); &#125; tmp = 1; for(int i = A.size()-1; i &gt;= 0; i--)&#123; if(i!=A.size()-1) tmp *= A.at(i+1); B.at(i) *= tmp; &#125; return B; &#125;&#125;; 52.正则表达式匹配题目描述请实现一个函数用来匹配包括.和*的正则表达式。模式中的字符.表示任意一个字符，而*表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串aaa与模式a.a和ab*ac*a匹配，但是与aa.a和ab*a均不匹配 解法一：（牛客）主要分两种情况： 当前字符的下一个字符不是* 当前字符的字一个字符是* 对于第一种情况：直接判断是否相等（包含‘.’的情况） 对于第二种情况，需要分情况讨论： 当前字符与pattern当前字符不相等，则patter当前只能出现零次，调用match(str, pattern+2) 当前字符与pattern字符相等（包含‘.’的情况），则pattern的选择有两种，出现零次，或者出现一次以上，这两种情况都必须考虑，否则会丢解，如（aab和a.*ab），因此，需要调用match(str, pattern+2) || match(str+1, pattern) 12345678910111213141516171819202122232425class Solution &#123;public: bool match(char* str, char* pattern) &#123; if( *str == '\0' &amp;&amp; *pattern == '\0') return true; if( *str != '\0' &amp;&amp; *pattern == '\0') return false; if( *(pattern+1) != '*')&#123; if(*str!='\0' &amp;&amp; (*str == *pattern || *pattern=='.')) // *str的条件不能丢 return match(str+1, pattern+1); else return false; &#125;else&#123; if(*str!='\0' &amp;&amp; (*str == *pattern || *pattern=='.')) //这里的if else组合语句是必须的，否则会在不能出现多次时，函数仍然考虑出现多次的情况，造成误解 return match(str, pattern+2) || match(str+1, pattern); else return match(str, pattern+2); &#125; &#125;&#125;; 53.表示数值的字符串题目描述请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。 解法一（自想）：没有难点，考察点主要在于各种情况的考虑（以下均为false）： + - +12.2.2 12e 12e- 12E+4.3 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: bool isNumeric(char* string) &#123; if(*string == &apos;\0&apos;) return false; if(*string == &apos;+&apos; || *string == &apos;-&apos;) string++; if(*string == &apos;\0&apos;) return false; int point_count = 0; while( (*string &gt;= &apos;0&apos; &amp;&amp; *string &lt;= &apos;9&apos;) || *string == &apos;.&apos;)&#123; if (*string == &apos;.&apos;) point_count++; if (point_count &gt; 1) return false; string++; &#125; if(*string == &apos;\0&apos;) return true; if(*string == &apos;e&apos; || *string == &apos;E&apos;) string++; else return false; if(*string == &apos;\0&apos;) return false; if(*string == &apos;+&apos; || *string == &apos;-&apos;) string++; if(*string == &apos;\0&apos;) return false; while( *string &gt;= &apos;0&apos; &amp;&amp; *string &lt;= &apos;9&apos; ) string++; if(*string != &apos;\0&apos;) return false; return true; &#125;&#125;; 54.字符流中第一个不重复的字符解法一（牛客）：哈希表建立一个哈希表和一个char数组（均为256大小），哈希表存储每个字符出现的次数，key为char，value为次数，数组存储所有 曾经 出现过一次的字符。 时间复杂度 $O(n)$ 空间复杂度 $O(1)$ 12345678910111213141516171819202122232425262728class Solution&#123;public: //Insert one char from stringstream char hash_c[256] = &#123;0&#125;; char first_c[256] = &#123;0&#125;; int index =0; void Insert(char ch) &#123; hash_c[ch]++; if(hash_c[ch] == 1)&#123; *(first_c+index) = ch; index++; &#125; &#125; //return the first appearence once char in current stringstream char FirstAppearingOnce() &#123; for(int i =0 ;i&lt;index; i++) if (hash_c[*(first_c+i)] == 1) return *(first_c+i); return '#'; &#125;&#125;; 55.链表中环的入口节点解法一（牛客）: FLoyd 的乌龟和兔子假设有环，并且环中的节点数为n，那么只要设值两个指针，一个slow指针指向头结点，另一个fast指针指向第n+1个节点，然后每次slow指针和fast指针都增1，那么肯定会在环的头部相遇（因为fast刚好比slow领先了一个环的长度） 因此，首先需要判断是否有环，思路是：从头结点开始，slow每次走一步，fast每次走两步，那么只要有环，slow和fast就一定会在环中的某个节点处相遇，如果无环，则fast一定先到达空指针 判断有环后，令fast从当前节点开始，继续往下走（每次走一步），并记录步数，最终遇到slow时的步数就是环的长度. 求得环长后, 先令 fast 走环长距离, 然后再令 slow 和 fast 共同前进, 最终, 相遇点即为开始点. 该方法时间复杂度为 $O(n)$ 空间复杂度为 $O(1)$ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* EntryNodeOfLoop(ListNode* pHead) &#123; ListNode* slow = pHead; ListNode* fast = pHead; while(slow!=nullptr &amp;&amp; fast != nullptr)&#123; if(slow-&gt;next == nullptr) return nullptr; else slow = slow-&gt;next; if(fast-&gt;next == nullptr || fast-&gt;next-&gt;next == nullptr) return nullptr; else fast = fast-&gt;next-&gt;next; if(slow == fast) break; &#125; fast = fast-&gt;next; int step = 1; while(slow != fast)&#123; // 求环长 fast = fast-&gt;next; step++; &#125; fast = pHead; while(step&gt;0)&#123;// 先让 fast 走环长距离 fast = fast-&gt;next; step--; &#125; slow = pHead; while(slow!=fast)&#123; // 相遇点即为开始点 slow = slow-&gt;next; fast = fast-&gt;next; &#125; return slow; &#125;&#125;; 解法二: 优化解法一时间复杂度: $O(n)$空间复杂度: $O(1)$ https://blog.csdn.net/dawn_after_dark/article/details/82564271 比解法一更简洁的写法:上面在求环的开始节点时, 是先求环长, 再让 fast 走环长距离, 然后 slow 和 fast 同步前进, 最终相遇点即为开始点, 这么写比较容易理解, 但难免有些繁琐. 实际上, 我们只需要令 fast=slow, 然后再让 slow 从头开始, 即 slow=0, 接着令 fast 和 slow 同步前进, 那么相遇点就是开始节点. 该性质的证明如下: 假设链表首部到环入口点距离为 $x$, 环长为 $c$, 两者在环内相交的点距离环的入口为 $a$, slow 表示慢指针走的距离, fast 表示快指针走的距离, $n$, $m$ 分别表示快慢指针在相遇时已经走得多少环. $2\times slow = fast$ (因为快指针的速度是慢指针速度的2倍). 那么, 则有下面的公式关系: slow = x + mc + afast = x + nc + a2\times slow = 2(x+mc+a) = x+nc+a = fastx = (n-2m)c - a = (n-2m-1)c + c - a因此, 可以看出链表首部到环入口的距离实则为 $环长倍数+ c-a$, 而此时的环内相遇点 slow 要从当前位置再次回到环入口点所需要的步数也为 $环长倍数+ c-a$, 因此可以采用共同前进的方法, 并且相交点一定为环入口点, 代码如下所示. 123456789101112131415161718192021222324252627282930313233/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* EntryNodeOfLoop(ListNode* pHead) &#123; if(pHead==nullptr) return nullptr; ListNode *fast = pHead; ListNode *slow = pHead; do&#123; slow = slow-&gt;next; fast = fast-&gt;next; if(fast==nullptr) return fast; // 不存在环 fast = fast-&gt;next; if(fast==nullptr) return fast; // 不存在环 &#125;while(slow!=fast); fast = slow; slow = pHead; while(slow!=fast)&#123; slow = slow-&gt;next; fast = fast-&gt;next; // 共同前进 &#125; return slow; &#125;&#125;; 解法三（牛客）： 断链法同理，先判断有环无环 然后记录两个指针，一个当前节点指针cur，一个相邻祖先指针pre，每经过一个节点时，都将pre指针的next置为nullptr，则当cur的next为空时，既为环的首个节点。 该方法的时间复杂度为O(n)，且只需遍历两次，且第二次遍历的时候正好遍历n个节点，但是缺点是会破坏链结构，补救办法是使用额外的标记来替代断链，但是这样会增加额外空间开销 1234567891011121314151617181920212223242526272829303132333435363738394041/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* EntryNodeOfLoop(ListNode* pHead) &#123; ListNode* slow = pHead; ListNode* fast = pHead; if(slow == nullptr) return nullptr; while(slow!=nullptr &amp;&amp; fast != nullptr)&#123; if(slow-&gt;next == nullptr) return nullptr; else slow = slow-&gt;next; if(fast-&gt;next == nullptr || fast-&gt;next-&gt;next == nullptr) return nullptr; else fast = fast-&gt;next-&gt;next; if(slow == fast) break; &#125; if(pHead-&gt;next == pHead) return pHead; //需要特别考虑只有一个节点并且自己组成环的情况 slow = pHead; fast = pHead-&gt;next; while(fast-&gt;next!=nullptr)&#123; slow-&gt;next = nullptr; slow = fast; fast = fast-&gt;next; &#125; return fast; &#125;&#125;; 56.删除链表中重复的结点题目描述在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5 解法一（自想）：这道题本身比较简单，只需要维护一个pre指针和cur指针，分别指向前一个结点和当前结点，如果当前结点和下一个结点的值相等，那么就删除当前结点，最后我pre指针的next值设置为指向未重复的结点 但是！本题恶心了我很久，一直报段错误，主要原因是有的结点没有做空判断，就访问了结点的val或者next成员，此时如果结点是空的，那么就会报段错误，主要有以下这么几个情况： 头结点本身就是重复的，这个需要删除头结点，另外判断是否重复时，还要检查头结点的下一个结点是否为空，如果为空，则不能访问其val值，否则，报段错误 在进行重复判断时，访问cur-&gt;next-&gt;val时，需要先判断cur-&gt;next是否为空，如果为空，则不能访问其val值 123456789101112131415161718192021222324252627282930313233343536373839/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* deleteDuplication(ListNode* pHead) &#123; if(pHead == nullptr || pHead-&gt;next == nullptr) return pHead; ListNode* newHead = new ListNode(0); // 建立一个新的结点，其next用于标识头结点，以便在头结点重复时，指向新的头结点 newHead-&gt;next = pHead; ListNode* cur = pHead; ListNode* pre = newHead; while(cur != nullptr &amp;&amp; cur-&gt;next !=nullptr)&#123; // 注意 这里一定必须是 &amp;&amp; ，如果是|| ，则下面有可能会访问到空结点的val，造成段错误 if(cur-&gt;val == cur-&gt;next-&gt;val)&#123; ListNode* dup = cur-&gt;next; while(cur-&gt;val == dup-&gt;val &amp;&amp; dup!=nullptr)&#123; // 同理，让验证所有欲访问的结点不为空 dup = dup-&gt;next; &#125; cur = dup; pre-&gt;next = cur; &#125;else&#123; cur = cur-&gt;next; pre = pre-&gt;next; &#125; &#125; return newHead-&gt;next; &#125;&#125;; 57.二叉树的下一个节点58.对称的二叉树 题目描述请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。 解法一（牛客）：递归要判断一个树是否对称，需要判断其树的左右子节点是否相等，同时还要判断左子树的右子树和右子树的左子树是否相等，以及左子树的左子树和右子树的右子树是否相等，然后如此递归解之： 12345678910111213141516171819202122232425262728293031/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; if(pRoot == nullptr ) return true; return isSymHelper(pRoot-&gt;left, pRoot-&gt;right); &#125; bool isSymHelper(TreeNode* subRoot1, TreeNode* subRoot2)&#123; if(subRoot1 == nullptr) return subRoot2==nullptr; if(subRoot2 == nullptr) return false; if(subRoot1-&gt;val != subRoot2-&gt;val) return false; bool b1 = isSymHelper(subRoot1-&gt;right, subRoot2-&gt;left); bool b2 = isSymHelper(subRoot1-&gt;left, subRoot2-&gt;right); return b1&amp;&amp;b2; &#125;&#125;; 解法二（牛客）：非递归关键还是知道怎么样才能判断一个二叉树是否对称，只要采用前序、中序、后序、层次遍历等任何一种遍历方法，分为先左后右和先右后左两种方法，只要两次结果相等就说明这棵树是一颗对称二叉树。 1234567891011121314151617181920212223242526272829303132333435363738394041//以下为层次遍历//与普通遍历不同的是，对于这道题，必须要把左右子树都存入到queue中，不论是否为空，因为只有这样才能将整个二叉树的结构存储起来，以便判断/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; queue&lt;TreeNode*&gt; q1; queue&lt;TreeNode*&gt; q2; if( nullptr==pRoot) return true; q1.push(pRoot); q2.push(pRoot); TreeNode* cur1; TreeNode* cur2; while(!q1.empty() &amp;&amp; !q2.empty())&#123; cur1 = q1.front(); q1.pop(); cur2 = q2.front(); q2.pop(); if(cur1 == cur2 &amp;&amp; nullptr == cur1) continue; if(nullptr == cur1 || nullptr == cur2) return false; if(cur1-&gt;val != cur2-&gt;val) return false; q1.push(cur1-&gt;left); q1.push(cur1-&gt;right); q2.push(cur2-&gt;right); q2.push(cur2-&gt;left); &#125; return true; &#125;&#125;; 解法三（牛客）：非递归=非递归算法，利用DFS和BFS=========================== BFS使用Queue来保存成对的节点 出队的时候也是成对成对的 1.若都为空，继续； 2.一个为空，返回false; 3.不为空，比较当前值，值不等，返回false； 确定入队顺序，每次入队都是成对成对的，如left.left， right.right ;left.rigth,right.left 123456789101112131415161718192021222324252627282930313233/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; if(pRoot == nullptr) return true; queue&lt;TreeNode*&gt; q; q.push(pRoot-&gt;left); q.push(pRoot-&gt;right); TreeNode* lnode; TreeNode* rnode; while(!q.empty())&#123; lnode = q.front(); q.pop(); rnode = q.front(); q.pop(); if(nullptr == lnode &amp;&amp; nullptr == rnode) continue; if(nullptr == lnode || nullptr == rnode) return false; if(lnode-&gt;val != rnode-&gt;val) return false; q.push(lnode-&gt;left); q.push(rnode-&gt;right); q.push(lnode-&gt;right); q.push(rnode-&gt;left); &#125; return true; &#125;&#125;; DFS使用stack来保存成对的节点 出栈的时候也是成对成对的 ， 1.若都为空，继续； 2.一个为空，返回false; 3.不为空，比较当前值，值不等，返回false； 确定入栈顺序，每次入栈都是成对成对的，如left.left， right.right ;left.rigth,right.left 12345678910111213141516171819202122232425262728293031323334353637/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; stack&lt;TreeNode*&gt; s; if(pRoot == nullptr) return true; s.push(pRoot-&gt;left); s.push(pRoot-&gt;right); TreeNode* lnode; TreeNode* rnode; while(!s.empty())&#123; rnode = s.top(); s.pop(); lnode = s.top(); s.pop(); if( nullptr==lnode &amp;&amp; nullptr == rnode) continue; if( nullptr == lnode || nullptr == rnode) return false; if(lnode-&gt;val != rnode-&gt;val) return false; s.push(lnode-&gt;left); s.push(rnode-&gt;right); s.push(lnode-&gt;right); s.push(rnode-&gt;left); &#125; return true; &#125;&#125;; 59.按之字形顺序打印二叉树题目描述请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。 解法一（自想, 差评）：利用两个queue，一个用于层次遍历树节点，另一个用于存储对应节点的depth，然后每次访问节点时，都判断当前节点的层数，如果为奇数层，则将该层直接push back到结果向量中，如果为偶数，则将该层数据进行reverse后再push back到结果向量中。 时间复杂度为 $O(n^2)$ 空间复杂度为 $O(n)$ 需要注意的是最后一层的边界条件与其它层不同一样，需要专门判断以下，具体可以看下面的点注释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(pRoot==nullptr) return res; queue&lt;TreeNode*&gt; q_node; queue&lt;int&gt; q_depth; q_node.push(pRoot); q_depth.push(1); TreeNode* cur; int depth; int global_depth = 1; vector&lt;int&gt; cur_layer; while(!q_node.empty())&#123; cur = q_node.front(); q_node.pop(); depth = q_depth.front(); q_depth.pop(); if(cur-&gt;left != nullptr)&#123; q_node.push(cur-&gt;left); q_depth.push(depth+1); &#125; if(cur-&gt;right != nullptr)&#123; q_node.push(cur-&gt;right); q_depth.push(depth+1); &#125; if(depth == global_depth)&#123; cur_layer.push_back(cur-&gt;val); if(q_node.empty())&#123; // 对应最后一层的情况，当到了最后一层时，depth不会再继续增1了， //所以不能通过global depth或depth的大小来判断是否进行pushback， //需要通过看是否达到了最后一个节点来判断 if(global_depth % 2 == 1)&#123; res.push_back(cur_layer); &#125;else&#123; reverse(cur_layer.begin(), cur_layer.end()); res.push_back(cur_layer); &#125; &#125; &#125;else&#123; if(global_depth % 2 == 1)&#123; res.push_back(cur_layer); &#125;else&#123; reverse(cur_layer.begin(), cur_layer.end()); res.push_back(cur_layer); &#125; cur_layer.clear(); cur_layer.push_back(cur-&gt;val); global_depth=depth; if(q_node.empty()) res.push_back(cur_layer); //这句话用于处理最后一层只有一个节点的情况，如果只有一个节点的话， //那么当前queue就为空，不会进入下一次循环，从而导致最后一层没有pushback进去 &#125; &#125; return res; &#125;&#125;; 解法二：利用reverse同样的思路，另一种写法，更加简洁，通过while里面内置for循环，来保证每次for循环都会将一整层的节点放进队列中，无需额外的数组来存储depth信息123456789101112131415161718192021222324252627282930313233链接：https://www.nowcoder.com/questionTerminal/91b69814117f4e8097390d107d2efbe0来源：牛客网class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(pRoot == NULL) return res; queue&lt;TreeNode*&gt; que; que.push(pRoot); bool even = false; while(!que.empty())&#123; vector&lt;int&gt; vec; //将vec声明在内部，省去每次的clear操作，clear操作需要对vector进行遍历，并将每个元素置为null？ const int size = que.size(); //当前存的节点数目就是这一层所有的节点，之前层的到已经被取出, 并且这一层的子节点还没有开始入队列 for(int i=0; i&lt;size; ++i)&#123; //将该层所有节点的子节点入队列，同时当到达该层最后一个节点时终止 TreeNode* tmp = que.front(); que.pop(); vec.push_back(tmp-&gt;val); if(tmp-&gt;left != NULL) que.push(tmp-&gt;left); if(tmp-&gt;right != NULL) que.push(tmp-&gt;right); &#125; if(even) //根据奇偶标识判断是否需要reverse std::reverse(vec.begin(), vec.end()); res.push_back(vec); even = !even; &#125; return res; &#125;&#125;; 解法三: 最优(不用reverse)时间复杂度: $O(n)$空间复杂度: $O(n)$ 在解法二中, 复杂度高的原因是因每次遇到偶数层的时候都要进行 reverse, 实际上, 当我们知道了该层的节点个数以后, 我们可以直接开辟一个指定大小的 vector, 然后根据下标随机访问来填入该层的节点值, 这样一来就不用进行 reverse, 并且空间复杂度与解法二相同 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; zigzagLevelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(root == nullptr) return res; std::queue&lt;TreeNode*&gt; q; q.push(root); bool is_odd = true; TreeNode* cur_node; while(!q.empty())&#123; int layer_len = q.size(); vector&lt;int&gt; cur_layer(layer_len); for(int i=0; i&lt;layer_len; i++)&#123; cur_node = q.front(); q.pop(); if(is_odd==true) cur_layer[i] = cur_node-&gt;val; else cur_layer[layer_len-1-i ] = cur_node-&gt;val; if(cur_node-&gt;left!=nullptr) q.push(cur_node-&gt;left); if(cur_node-&gt;right!=nullptr) q.push(cur_node-&gt;right); &#125; res.push_back(cur_layer); is_odd = !is_odd; &#125; return res; &#125;&#125;; 60.把二叉树打印成多行题目描述从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。 解法一（半自想）：while循环加for循环，无需额外记录层数，具体看59题解法二分析 时间和空间复杂度为 $O(n)$ 123456789101112131415161718192021222324252627282930313233/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(pRoot== nullptr) return res; queue&lt;TreeNode*&gt; q_node; q_node.push(pRoot); while(!q_node.empty())&#123; vector&lt;int&gt; cur_layer; const int cur_size = q_node.size(); for(int i = 0;i&lt;cur_size; i++)&#123; TreeNode* cur_node = q_node.front(); q_node.pop(); cur_layer.push_back(cur_node-&gt;val); if(cur_node-&gt;left != nullptr) q_node.push(cur_node-&gt;left); if(cur_node-&gt;right != nullptr) q_node.push(cur_node-&gt;right); &#125; res.push_back(cur_layer); &#125; return res; &#125;&#125;; 61.序列化二叉树62.二叉搜索树的第k个节点题目描述给定一棵二叉搜索树，请找出其中的第k小的结点。例如， （5，3，7，2，4，6，8） 中，按结点数值大小顺序第三小结点的值为4。 解法一（自想）：中根遍历，遍历到第k个节点时将其输出，如果k大于节点数量，输出nullptr, 时间复杂度 $O(n)$ 12345678910111213141516171819202122232425262728293031323334353637/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* KthNode(TreeNode* pRoot, int k) &#123; if(pRoot == nullptr) return nullptr; stack&lt;TreeNode*&gt; s_node; TreeNode* P = pRoot; //ctor&lt;TreeNode*&gt; vec_node; int cur_k = 0; while(P!=nullptr || !s_node.empty())&#123; while(P!=nullptr)&#123; s_node.push(P); P = P-&gt;left; &#125; if(!s_node.empty())&#123; P = s_node.top(); s_node.pop(); cur_k++; if(cur_k == k) break; P = P-&gt;right; &#125; &#125; if(cur_k == k) return P; return nullptr; &#125;&#125;; 63.数据流中的中位数题目描述如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用Insert()方法读取数据流，使用GetMedian()方法获取当前读取数据的中位数。 解法一(自想):插入时用vector的insert方法,按顺序插入,空间为 $O(n)$ ,时间复杂度为$O(n)$ 返回中位数时直接利用下标,时间复杂度和空间复杂度都为 $O(1)$. 这里关于vector的insert方法,有两个需要注意的点: it = vec.insert(it,num); 如果后序还要继续插入的话, 就必须将insert的结果重新赋值给it, 否则如果没有重新赋值而直接继续使用it的话,会导致段错误, 这里因为已经不需要继续插入了,所以可以用break直接跳出,无需赋值 插入时,如果num比vec里面所有的数都大, 那么会导致插入失败, 此时 ,应使用push_back将num插入到最后 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: vector&lt;int&gt; vec; void Insert(int num) &#123; if(vec.size() == 0)&#123; vec.insert(vec.begin(), num); return; &#125; bool is_insert=false; for(auto it=vec.begin(); it!=vec.end(); it++)&#123; if(*it &gt; num)&#123; vec.insert(it,num); is_insert=true; break; &#125; &#125; if(!is_insert) vec.push_back(num); &#125; double GetMedian() &#123; if(vec.size() == 0) return 0; int x1 = vec.size()/2; int x2 = (vec.size()-1)/2; return (vec[x1]+vec[x2])/2.0; &#125;&#125;; 解法二:插入的时候不考虑排序,在查找中位数时可以使用基于Partition的方法,时间复杂度为 $O(n)$. 解法三:AVL树插入时间复杂度为 $O(logn)$ 找中位数时间复杂度为 $O(1)$ 解法四(牛客):用大顶堆和小顶堆思路: 如果能够保证数据容器左边的数据都小于右边的数据，这样即使左、右两边内部的数据没有排序，也可以根据左边最大的数及右边最小的数得到中位数。如何快速从一个容器中找出最大数？用最大堆实现这个数据容器，因为位于堆顶的就是最大的数据。同样，也可以快速从最小堆中找出最小数。 因此可以用如下思路来解决这个问题：用一个最大堆实现左边的数据容器，用最小堆实现右边的数据容器。往堆中插入一个数据的时间效率是 O(logn)。由于只需 O(1)时间就可以得到位于堆顶的数据，因此得到中位数的时间效率是 O(1)。 首先要保证数据平均分配到两个堆中，因此两个堆中数据的数目之差不能超过 1 还要保证最大堆中里的所有数据都要小于最小堆中的数据 当数据的总数目是偶数时，按照前面分配的规则会把新的数据插入到最小堆中。如果此时新的数据比最大堆中的一些数据要小，怎么办呢？ 可以先把新的数据插入到最大堆中，接着把最大堆中的最大的数字拿出来插入到最小堆中。由于最终插入到最小堆的数字是原最大堆中最大的数字，这样就保证了最小堆中的所有数字都大于最大堆中的数字。 当需要把一个数据插入到最大堆中，但这个数据小于最小堆里的一些数据时，这个情形和前面类似。 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: priority_queue&lt;int, vector&lt;int&gt;, std::less&lt;int&gt; &gt; q_max; priority_queue&lt;int, vector&lt;int&gt;, std::greater&lt;int&gt; &gt; q_min; void Insert(int num) &#123; if( q_max.size()&gt; q_min.size() )&#123; q_max.push(num); int tmp = q_max.top(); q_max.pop(); q_min.push(tmp); &#125;else&#123; q_min.push(num); int tmp = q_min.top(); q_min.pop(); q_max.push(tmp); &#125; &#125; double GetMedian() &#123; double res; if(q_max.size() == q_min.size())&#123; int x1 = q_max.top(); int x2 = q_min.top(); res = (x1+x2)/2.0; &#125;else&#123; res = q_max.top(); &#125; return res; &#125;&#125;; 插入时间复杂度为 $O(logn)$ 找中位数时间复杂度为 $O(1)$ 64.滑动窗口的最大值题目描述给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。 解法一(自想):用最直接的办法, 每次求出滑动窗口内的最大值, 然后存到max_res向量里面, 该方法时间复杂度为 $O(nm)$ . 空间为 $O(n)$ 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; maxInWindows(const vector&lt;int&gt;&amp; num, unsigned int size) &#123; vector&lt;int&gt; max_res; if(size == 0) return max_res; //无符号整数, 要首先考虑size为0的情况, 否则会导致下面的程序数组越界 for(int i = 0 ; i&lt; num.size()-size+1 ; i++)&#123; int tmp_max; //if(i&lt;num.size()) tmp_max = num[i]; //这里的if语句看起来是多余的, 实际上可以帮助进行数组越界检查, 有助于快速确定bug位置 for(int j = i+1; j&lt; i+size ; j++)&#123; if(num[j] &gt; tmp_max) tmp_max = num[j]; // 这里同样可以进行越界检查, 有助于bug定位, bug修复后可去掉 &#125; max_res.push_back(tmp_max); &#125; return max_res; &#125;&#125;; 解法二(讨论区):使用双端队列deque, 从下标0开始, 一直到n-1, 每次进行如下步骤: 当前元素是否比队列中最后一个元素大, 如果大, 说明队列元素以后也不可能再成为较大值, 直接pop, 如此循环, 直到队列为空或者遇到比当前值大的元素 判断队列中队首的元素是否过期(若队空则直接下一步, 无需判断), 若过期, 则pop, 否则, 不管( 只看队首, 队内的元素是否过期不影响算法, 因为就算过期后面也会将其淘汰) 将当前元素的下标存到队尾 将新的队首元素存到结果向量max_res中 注意: 队列里面存的是下标, 而不是元素本身的值, 后面在提到队列的元素值时, 均是指队列中存储的下标对应的元素值. 时间复杂度分析: 不是 $O(n*szie)$ 而是 $O(n)$ ? 原因: 假设队列里面的正好包含size个元素(最多就为size个), 那么这三个元素对应的值一定是递减的, 因为如果不是递减中, 在进行第一个判断时, 就会将其移除, 此时, 如果新来了一个元素, 如果该元素值小于队列中所有的值, 那么就只可能进行一次判断, 而不是循环size次, 而如果均大于队列中的值, 那么队列中的元素个数就会变成1个, 这样, 在下次进行判断时, 只会与一个元素做判断, 如果是元素值位于中间, 那么下一次做判断的元素个数也会减少一部分, 综上, 内部while循环时, 相对于普通的循环嵌套, 该种循环可以认为是常数级(虽然还是与size的大小有关, 但是总体来说, 要做的判断次数比通常的循环小).12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; maxInWindows(const vector&lt;int&gt;&amp; num, unsigned int size) &#123; vector&lt;int&gt; max_res; deque&lt;int&gt; dq_index; for(int i =0; i&lt; num.size(); i++)&#123; while(!dq_index.empty() &amp;&amp; num[i] &gt; num[dq_index.back()] )&#123; dq_index.pop_back(); &#125; if(!dq_index.empty() &amp;&amp; i-dq_index.front()&gt;= size) dq_index.pop_front(); dq_index.push_back(i); if(i&gt;=size-1) max_res.push_back(num[dq_index.front()]); &#125; return max_res; &#125;&#125;; 65.矩阵中的路径题目描述请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一个格子开始，每一步可以在矩阵中向左，向右，向上，向下移动一个格子。如果一条路径经过了矩阵中的某一个格子，则之后不能再次进入这个格子。 例如 a b c e s f c s a d e e 这样的3 X 4 矩阵中包含一条字符串”bcced”的路径，但是矩阵中不包含”abcb”路径，因为字符串的第一个字符b占据了矩阵中的第一行第二个格子之后，路径不能再次进入该格子。 解法一:这是一个可以用回朔法解决的典型题。首先，在矩阵中任选一个格子作为路径的起点。如果路径上的第i个字符不是ch，那么这个格子不可能处在路径上的第i个位置。如果路径上的第i个字符正好是ch，那么往相邻的格子寻找路径上的第i+1个字符。除在矩阵边界上的格子之外，其他格子都有4个相邻的格子。重复这个过程直到路径上的所有字符都在矩阵中找到相应的位置。 由于回朔法的递归特性，路径可以被开成一个栈。当在矩阵中定位了路径中前n个字符的位置之后，在与第n个字符对应的格子的周围都没有找到第n+1个字符，这个时候只要在路径上回到第n-1个字符，重新定位第n个字符。 由于路径不能重复进入矩阵的格子，还需要定义和字符矩阵大小一样的布尔值矩阵，用来标识路径是否已经进入每个格子。 当矩阵中坐标为（row,col）的格子和路径字符串中相应的字符一样时，从4个相邻的格子(row,col-1),(row-1,col),(row,col+1)以及(row+1,col)中去定位路径字符串中下一个字符如果4个相邻的格子都没有匹配字符串中下一个的字符，表明当前路径字符串中字符在矩阵中的定位不正确，我们需要回到前一个，然后重新定位。 一直重复这个过程，直到路径字符串上所有字符都在矩阵中找到合适的位置 本题一定要注意边界条件即特殊情况的判断: 当矩阵所有元素一样时(这种情况一定要注意先) 当矩阵只有一个元素时(这两种情况要注意, 先进入递归程序, 然后再对flag矩阵进行判断, 否则, 当子串和矩阵大小一样时, 就无法判断到下一个字符是否==’\0’了)- 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: bool hasPath(char* matrix, int rows, int cols, char* str) &#123; if(str[0] == &apos;\0&apos;) return true; int* flag_matrix = new int[rows*cols]; for(int i = 0; i&lt;rows; i++)&#123; for(int j =0 ;j&lt;cols; j++)&#123; flag_matrix[i*cols+j] = 1; &#125; &#125; for(int i = 0; i&lt; rows; i++)&#123; for(int j = 0;j&lt; cols; j++)&#123; if(matrix[i*cols+j] == str[0])&#123; bool is_path = hasPath_helper(matrix,flag_matrix,i,j, rows, cols, str, 0); if(is_path) return true; &#125; &#125; &#125; delete []flag_matrix; return false; &#125; bool hasPath_helper(char* matrix,int* flag_matrix, int i, int j, int rows, int cols, char* str,int x)&#123; if(str[x] == &apos;\0&apos;) return true; if(i&lt;0 || i&gt;=rows || j&lt;0 || j&gt;=cols) return false; if(flag_matrix[i*cols+j] == 0 || matrix[i*cols+j] != str[x]) return false; flag_matrix[i*cols+j] = 0; bool is_path = hasPath_helper(matrix, flag_matrix, i, j-1, rows, cols, str, x+1) || hasPath_helper(matrix, flag_matrix, i-1 , j, rows, cols, str, x+1) || hasPath_helper(matrix, flag_matrix, i, j+1, rows, cols, str, x+1) || hasPath_helper(matrix, flag_matrix, i+1, j, rows, cols, str, x+1); flag_matrix[i*cols+j] = 1; return is_path; &#125;&#125;; 66.机器人的运动范围题目描述地上有一个m行和n列的方格。一个机器人从坐标0,0的格子开始移动，每一次只能向左，右，上，下四个方向移动一格，但是不能进入行坐标和列坐标的数位之和大于k的格子。 例如，当k为18时，机器人能够进入方格（35,37），因为3+5+3+7 = 18。但是，它不能进入方格（35,38），因为3+5+3+8 = 19。请问该机器人能够达到多少个格子？ 解法一:回溯法, 如果当前节点的位数值满足要求, 那么从当前节点开始, 满足要求的格子数字应该等于” 1+左+右+上+下”, 其中方向代表这个方向上的满足要求的格子数. 注意每走过一次格子, 需要将flag矩阵中当前格子的标识设为”已走过(1)”, 并且, 由于此任务是统计符合条件的格子总数, 所以和一般的回溯法不同, 不能在递归结束后将该格子的标识重新复位(否则不同路径上回到同一个格子重复计数). 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int mc_helper(int threshold,int cur_i, int cur_j, vector&lt; vector&lt;int&gt; &gt;&amp; flag_matrix)&#123; int rows = flag_matrix.size(); int cols = flag_matrix[0].size(); int cur_val = cur_i/10 + cur_i%10 + cur_j/10 + cur_j%10; if(cur_val &gt; threshold || cur_i&lt;0 || cur_i &gt;=rows || cur_j&lt;0 || cur_j&gt;=cols || flag_matrix[cur_i][cur_j]) return 0; flag_matrix[cur_i][cur_j] = 1; return 1 + mc_helper(threshold, cur_i, cur_j-1, flag_matrix)+ mc_helper(threshold, cur_i, cur_j+1, flag_matrix)+ mc_helper(threshold, cur_i-1, cur_j, flag_matrix)+ mc_helper(threshold, cur_i+1, cur_j, flag_matrix); //flag_matrix[cur_i][cur_j] = 0; //return cur_count; &#125; int movingCount(int threshold, int rows, int cols) &#123; if(rows&lt;=0 || cols&lt;=0) return 0; vector&lt; vector&lt;int&gt; &gt; flag_matrix(rows, vector&lt;int&gt;(cols)); int count = mc_helper(threshold,0, 0, flag_matrix); return count; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FCN-CVPR2015]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FCN-CVPR2015%2F</url>
    <content type="text"><![CDATA[文章: Fully Convolutional Networks for Semantic Segmentation作者: Jonathan Long, Evan Shelhamer, Trevor Darrell 核心亮点全卷积网络: 只有最后一层是全连接层, 并且在针对 object detection 任务进行 fine-tuning 时, 会将该全连接层移除. (但是分类任务仍然需要这一层来输出最后的分类结果) (1) 利用FCN网络进行语义级别的图像分割与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类的方法不同, FCN将全连接层转化为卷积层, 使其可以接受任意尺寸的图像输入, 然后采用反卷积层对卷积层的 feature map 进行上采样, 使它恢复到输入图像相同的尺寸,, 从而可以对每个图像像素都产生一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素的分类. 摘要卷积神经网络是一种功能强大的视觉模型, 它可以生成具有层次结构的特征. 本文证明了卷积网络经过端到端, 像素到像素的训练, 可以在语义分割方面超过现有水平. 我们的核心观点是构建一个 “全卷积” 网络, 它可以接受任意大小的输入, 并通过高效的推理和学习产生相应大小的输出. 我们定义并详细描述了全卷积网络的空间, 解释了它们在 空间密集 预测任务中的应用, 并将它们与之前的模型联系起来. 我们将分类网络(AlexNet, VGGnet, GoogLeNet)应用到全卷积网络中, 并且通过 fine-tuning 将它们学习到的特征迁移到实例分割任务中. 然后, 我们定义了一种新的体系结构, 它结合了来自 深层的, 较粗糙的语义信息和来自浅层的, 教精细的外观信息, 从而可以产生精确和细致的分割结果. 介绍实例分割: 对于每一个像素点都要进行分类. 本文模型无需任何前处理或后处理操作, 如 superpixels, proposals, post-hoc. 本文还定义了一种新式的 “skip” 结构来结合深层粗糙的语义信息和浅层精化的外观信息. 相关工作简单提了一下从分类到实例分割的相关论文. 然后从以下几个方面进行了介绍. Fully convolutional networks： 介绍了全卷积网络的发展的现状, 从90年代开始, 就已经有人开始使用全卷积网络了, 但是全卷积网络相对研究成果还是较少. Dense prediction with convnets： 目前已经有一些工作将convnets应用到了密集型预测任务. 这些方法都包含有以下几点共有特征： 模型较小：模型和容量和感受野都有一定限制. patchwise training：在预测指定像素时, 只将此像素和其周围像素作为输入送入模型里训练, 即每一个像素都会作为中心像素被训练来预测这个像素所属的分类. patch-wise的问题无疑非常明显, 第一：训练中用的patch会大量重叠, 非常低效. 第二：由于patch-wise大量的计算量, 预测的时候很慢. 后处理：超像素映射, 随机field正则化, 局部分类 input shifting and output interlacing for dense output as introduced by OverFeat 多尺寸金字塔处理 tanh非线性包含 融合（ensembles） FCN则没有以上机制. 与现有模型不同, 本文使用image classification作为有监督的预训练, 同时fine-tune全卷积, 以期望从整张输入图片中快速且高效的学到相应的特征. 目前大多数的模型和方法都不是端到端的. Fully convolutional networks在卷积网络中的每一层的数据, 都是一个 shape 为 $h\times w\times d$ 的三维数组, 其中 $h$ 和 $w$ 代表 spatial dimensions, $d$ 代表特征或通道的深度. 在第一层中, $h\times w$ 代表输入图片的尺寸, $d$ 代表图片的颜色三通道. 我们将更深网络层的某个 location 与图片中的像素连关联的部分, 称为感受野或者接受域(receptive fields). 卷积网络是建立在平移不变性之上的, 它的基本组成操作(卷积, 池化, 激活)都是作用在某一个局部区域上的, 并且仅仅依赖于相关联的一部分区域. 我们令 $x_{ij}$ 代表某一特定层上的特定位置 $(i,j)$ 的数据, 那么下一层的 $y_{ij}$ 的数据可通过下式计算: y_{ij} = f_{ks}(\{x_{si+\delta i, sj+\delta j}\}_{0\leq \delta i, \delta j \leq k})上式中, $k$ 为核的尺寸, $s$ 代表 stride 或者 subsampling factor, $f_{ks}$ 代表某种操作. 如果一个网络中只包含卷积层, 那么我们就将其称为全卷积网络, 全卷积网络可以接受任何尺寸的输入, 同时其输出与输入尺寸相关的结果. 全卷积网络由于没有了全连接层的限制, 因此可以接受任意尺寸的输入, 并且生成相应的维度形状. FCN的一个 real-valued 损失函数定义了一个任务：如果损失函数是最后一层中在 spatial dimensions 上的总和 $\ell(x;\theta) = \sum_{ij}\ell’(x_{ij};\theta)$ , 那么它的梯度就会是它所有 spatial components 的梯度的总和. 因此对于在整张图片上 $\ell$ 的 sgd 就是等于将最后一层所有感受野作为一个 minibatch 的$\ell’$的sgd.当这些感受野重合度非常大时, layer-by-layer 方式的前向计算和反向计算相比于 patch-by-patch 的方式, 就变得十分高效. 下面我们将会解释如何将一个分类网络转换成一个生成粗糙图谱的全卷积网络. 对于像素级的预测任务来说, 我们需要将这些粗糙的图谱与图片中的每个像素对应. OverFeat 为此引入了一个 trick(后文介绍)来完成该任务. 我们将这个 trick 重新以网络的方式解释. 作为另一种有效且高效的替换, 我们引入了反卷积来完成 upsampling 操作. Adapting classifiers for dense prediction大多数经典网络结构中都具有全连接层, 该层接受固定尺寸的输入, 同时会输出 non spatial outputs. 这使得全连接层的维度固定, 同时放弃了空间坐标信息(因为全连接都是一维的). 但是, 这些 全连接层同样可以被看做是卷积核覆盖整个输入区域的卷积层. 可以将它们全部强制转换成全卷积网络, 以便可以接受任意尺寸的输入, 同时输出对应的分类图谱(classifization maps). 该转换过程如图2所示 FCN 是如何降低计算量的:面对 $384\times 384$ 的图像, 让含全连接层的初始卷积神经网络以 32 像素的步长独立对图像中的 $224\times 224$ 块进行多次评价, 其效果和使用全卷积网络进行一次评价时相同的. 后者通过权值共享起到了加速计算的作用.首先, 对于输入 shape 为 $2\times 2\times 256$ 的特征图谱来说, 使用全连接的参数量为 $4096 \times 1$ (输入维度, 输出维度), 使用全卷积时, 核大小为 $2\times 2\times 256$, 核的数量为 $1$, 因此, 从参数量上看, 二者是相同的. 也就是说, 如果我们输入的特征图谱的大小和卷积核的大小相同时, 实际上当前的卷积层就可以看做是一个全连接层. 但是, 全连接的输入尺寸是固定的, 因此它只能输出指定维度的结果, 而全卷积层的另一个好处就是不会限制输入的特征图谱的尺寸, 因此, 当输入的特征图谱的尺寸大于当前的核时, 全卷积网络就会输出多个结果, 而实际上, 这些结果对于的输入特征图谱上的区域具有大量的重叠, 因此, 起到了权重共享的作用, 从而可以减少重复计算, 降低模型复杂度. 另一方面, 即使当输入的特征图谱和卷积核的大小一致时, 全卷积和全连接也不是完全等价的. 因为全连接的结构是固定的, 当我们训练时, 全连接上权重会发生变化, 但是连接关系不会改变. 而卷积层除了会学习权重外, 它还会学习节点之间的关系, 对于无用的关系它会直接弱化或过滤掉. AlexNet 处理一张 227 尺寸的图片需要 1.2ms, FCN 版本的 AlexNet 在 500 尺寸的图片上输出 $10\times 10$ 的结果需要 22ms. 因此快了大约 5 倍.($1.2\times 100 = 120$, 大约是 22 的 5 倍). 这些卷积模型的空间输出的特征图谱使得它们称为语义分割之类的密集问题的自然选择. 由于每个输出单元都有 ground truth 可用, 因此前向和后向的传递过程都很简单, 并且都利用了卷积固有的计算效率(以及积极的优化). AlexNet 反向传播过程需要 2.4 ms, FCN 版本在 $10\times 10$ 的输出上反向传播需要 37ms. 尽管我们的全卷积网络可以接受不同尺寸的输入, 但是特征图谱的输出维度是通过 subsampling 来降低的. 我们需要控制核的个数和大小, 使得模型的计算成本不会太高, 这就会使得全卷积网络的输出较为粗糙, 使其从输入图谱的大小减少了一定比例. Shift-and-stitch is filter rarefraction做了很多研究和实验, 但是并没有使用该技术, 作者发现直接通过 upsampling 进行学习更加有效, 如下节描述. Upsampling is backwards strided convolution另一种将粗糙的输出图谱连接到密集像素的方法是插值. 例如, 简单的双线性插值通过线性映射从最近的四个输入计算每个点的输出, 线性映射仅依赖于输入和输出单元的相对位置. 从某种意义上说, 因子为 $f$ 的上采样可以看成是步长为 $1/f$ 的卷积. 因此可以使用反卷积来实现(deconvolution). 该过程很容易实现, 因为主需要逆转正常卷积的计算过程即可. 注意到, 反卷积相对于双线性插值来说有一个好处就是可以进行学习, 而不是固定不变的. 将多个反卷积层和激活层堆叠起来甚至可以学习到非线性的上采样过程. 在实验中, 我们发现, 反卷积对于学习密集预测来说是快速有效点. Patchwise training is loss sampling讨论在大的输入上通过FCN一次计算多个结果, 可以在一定程度上修正loss? Segmentation Architecture我们利用 ImageNet 进行预训练. 之后, 我们通过构建一个 skip architecture 来结合深层和浅层信息. 我们使用逐像素的多项式逻辑回归损失进行训练, 并且使用评价像素 IoU 的标准度量进行验证. From classifier to dense FCN使用 VGG16 和 GoogLeNet(没有使用最后的全局平均池化), 去掉了最后一层分类层, 并且将所有的全连接层转换成全卷积层, 我们添加了一个核大小为 $1\times 1$, 通道数为 21 的卷积层来预测深层粗糙特征图谱上每个位置的类别得分, 后面跟了一个反卷积层对粗糙的特征图谱进行上采样得到更密集的图谱. 这样的设置在 VGG16 backbone 上已经取得了 sota 的效果. 如表1所示. Combining what and where如图3所示, 我们定义了一种新的用于分割任务的全卷积网络, 它结合了不同网络层的特征, 并且精细化了输出的空间精度. 尽管前面介绍的分割网络已经取得了不错的效果, 但是最终预测层的 32 像素的步长使得上采样输出的细节尺度有所限制. 我们通过添加链接来解决这一问题, 这些链接将最终的预测层与较浅的网络层结合在一起, 从而具有更小的步长. 我们可以用一个 DAG 来描述这个过程, 特征会从较浅的层跳到较深的层进行结合. 将精细层和粗糙层结合起来, 可以使得模型在做出局部预测的同时, 考虑全局结构. 我们首先通过一个步长为16像素的网络层上预测我们在 pool4 上添加了一个 $1\times 1$ 的卷积层来生成额外的类别预测, 我们将 conv7(pool4上的预测层) 的输出和 pool2 上采样以后的输出进行融合, 并且将预测结果相加. 我们用双线性插值来初始化上采样, 但是允许上采样网络层学习参数. 最终, 步长为 16 的预测结果会上采样会原始图片, 我们将其称之为 FCN-16s.通过这种 skip net 的形式, 我们可以将最终的 IU 性能提升 3 个百分点. 图4展示了精化后的结果的输出. 用同样的方法可以构建出 FCN-8s. 从表2可以看出, FCN-8s 的提升已经不是很明显了, 因此我们没有继续往下构建. Experimental frameworkOptimization: SGD with momentum, lr = 0.001/0.0001/0.00001, momentum = 0.9, weight decay = 0.00005 / 0.0002. Fine-tuning: fine-tune all layers. Patch Sampling: 在同一张图片上选取 batch, 使得具有较大重叠, 加速训练. 图5 显示了这种形式的采样对收敛的影响. Class Balancing: unnecessary Dense Prediction: 借助双线性插值(初始时)和反卷积(后续进行学习)进行上采样. Augmentation: no noticeable improvement More Training Data: 提升了 3.4 个点 Implementation: Caffe, NVIDIA Tesla K40c.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
        <tag>实例分割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的内联函数]]></title>
    <url>%2Fz_post%2FCpp-%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[在C/C++中, 如果有一些函数被频繁调用, 那么就会不断的进行函数入栈出栈的操作, 这会造成栈空间以及程序运行时间的消耗. 栈空间就是指放置程序的局部数据以及函数内数据的内存空间, 在正常情况下, 栈空间都是有限的, 如果频繁大量的使用就会造成栈空间不足的问题, 函数的死循环递归调用的最终结果就是导致占内存空间的枯竭 特征: 相当于把内联函数里面的内容直接写在了调用内联函数处 (类似于#define或者typedef的那种替换操作) 相当于不用执行进入函数的步骤, 直接执行函数体 相当于 宏, 却比宏多了类型检查, 真正具有函数特性(这也是与#define的区别所在) 在类声明中定义的函数, 除了虚函数的其他函数都会自动隐式的成为内联函数 关键字inline必须与函数定义体放在一起才能使函数成为内联, 仅将inline放在函数声明前不起任何作用 与非内联函数不同的是, inline函数必须在调用该函数的每个文本文件中定义. 当然, 对于同一程序的不同文件, 如果inline函数出现的话,其定义必须相同. 优点: 内敛函数会像宏函数一样在被调用处展开, 省去了参数压栈, 栈帧开辟, 结构返回等步骤, 从而提高了程序的运行速度 内联函数相比宏函数来说, 在代码展开处会做安全检查和类型转换(同普通函数), 而宏定义函数则不会 在类声明中同时定义的成员函数, 会自动转化为内联函数, 因此 内联函数可以访问类的成员变量, 宏定义则不能. 内联函数在运行时可以调试, 而宏定义则不行(因为宏定义是被预定义处理的, 所以不会有人黑的编译符号和调试信息, 调试的时候基本只能用肉眼去看) 缺点: 代码膨胀. 内联函数是以代码膨胀(复制)为代价, 消除函数调用带来的开销. 如果执行函数体内代码的时间, 相比于函数调用的开销较大, 那么效率的收获就会很少. 另一方面, 每一处内联函数的调用都要复制代码, 将使程序的总代码量增大, 消耗更多的内存空间. inline函数无法随着函数库升级而升级. inline函数的改变需要重新编译, 不像非内联函数那样可以直接链接 是否内联, 程序员不可控, 内联函数只是对编译器的建议, 对于最终实现的决定权在于编译器. 虚函数可以是内联函数吗 虚函数在语法上可以是内联函数, 内联是可以修饰虚函数的, 但是当虚函数表现多态性的时候是不能内联的. (在具体实现时, 到底是否内联, 是由编译器决定的), 如下: 123456789101112131415#include &lt;cstdio&gt;struct Base &#123; virtual ~Base() &#123;&#125; virtual void Foo() &#123; printf("Base::Foo()\n"); &#125;&#125;;struct Derived: Base &#123; virtual void Foo() &#123; printf("Derived::Foo()\n"); &#125;&#125;;Base* b = new Derived; // 非 static 令编译器不能在编译期知道 b 指向那个类型的对像int main() &#123; b-&gt;Foo(); // 不可能内联 b-&gt;Base::Foo(); // 非多态调用，可以内联（但具体是否内联由编译器决定） delete b;&#125; 内联实际上是在建议编译器内联, 而虚函数的多态性需要在运行期起作用, 编译器无法知道运行期具体调用哪个代码, 因此虚函数表现为多态性时, 不可以内联 inline virtual 唯一可以内联的时候是: 编译器知道所调用的对象是哪个类(如 Base::who()), 这只有在编译器具有 实际对象而不是对象的指针或引用时才会发生. 对于常见的主流编译器, 写不写 inline 有什么影响]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShuffleNet]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-ShuffleNet%2F</url>
    <content type="text"><![CDATA[文章: ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices作者: Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun备注: Megvii Inc 摘要我们介绍了一种计算效率极高的 CNN 结构, 名为 ShuffleNet, 它是专门为计算能力非常有限的移动设备设计的. 这个新的网络结构采用了两种新的计算操作: 点态组卷积(pointwise group convolution) 和 通道洗牌(channel shuffle). 实验显示, 效果很好. Introduction我们注意到, 最先进的架构, 如 Xception 和 ResNeXt, 在非常小的网络中, 由于成本较高的密集 1x1 卷积, 使得计算效率变的较低. 因此, 本文提出使用点态组卷积(pointwise group convolution)来降低 1x1 卷积的计算复杂度. 为了克服 group convolution 带来的副作用, 我们提出了一种新的 channel shuffle 操作来帮助信息在特征信道间流动. 基于这两种技术, 我们构建了一个名为 ShuffleNet 的高效结构. Related WorkEfficient Model Designs: GoogLeNet, SqueezeNet, ResNet, SENet, NASNet Group Convolution: AlexNet 首先提供 group conv 的概念, ResNeXt, Xception, MobileNet. Channel Shuffle Operation: Interleaved group convolutions for deep neural networks (paper) Model Acceleration(在 Inference 阶段加速以训练好的模型): Pruning network connections, Channels Reduce, Quantization, Factorization. 利用 FFT 或者其他方法优化卷积计算, 大模型到小模型的知识迁移. ApproachChannel Shuffle for Group Convolutions现代的卷积神经网络通常由相同结构的 building blocks 组成. 其中, Xception 和 ResNeXt 在 building blocks 中引入了高效的深度可分离卷积(Depthwise Separable Conv)和组卷积(Group Conv), 从而在表征能力和计算成本之间取得了很好的平衡. 但是, 我们注意到这两种设计没有完全对 1x1 卷积进行分析, 而实际上该卷积也需要较大的计算量. 例如, 在 ResNeXt 中, 只有 3x3 卷积层配置了 Group Conv, 因此, 对于 ResNeXt 中的每一个残差单元来说, Pointwise Conv 都要占用 93.4% 的乘法加法操作. 在微型网络中, 成本高的 Pointwise Conv 会利用有限的通道数来满足复杂度的约束, 但是这样可能会损害精度. 为了解决这个问题, 一个简单的解决方案是利用通道稀疏连接(channel sparse connections). 通过确保每个卷积只对对应的输入通道进行运算, Group Conv 显著降低了计算成本. 但是, 如果将多个 Group 叠加在一起, 就会产生一个副作用: 来自某个通道的输出只来自于一小部分的输入通道. 图1(a)展示了两个 Group Conv 叠加的情况, 很明显, 某个 Group 的输出至于 Group 内的输入有关, 这种性质会阻塞通道之间的信息流, 降低表征能力. 如果我们允许 Group Conv 获取来自不同 groups 的输入数据, 如图1(b)所示, 那么输入和输出通道将会完全相关. 具体来说, 对于前一个 group layer 生成的 feature map, 我们可以先将每个 group 内部的通道划分成若干个 subgroups, 然后给下一个 group layer 的中每一个 group 提供不同的 subgroups. 这可以利用通道洗牌(channel shuffle)操作高效且优雅的实现, 如图1(c)所示: 假设一个卷积层具有 $g$ 个 groups, 它的输出通道数为 $g\times n$. 我们首先将输出的通道数 reshape 成 $(g, n)$, 然后利用 transposing 进行转置, 最后利用 flatten 将其开展, 并作为下一层的输入. 注意到, 即使两个卷积层的组数不同, 该操作依然有效. 此外, channel shuffle 也是可微的, 这意味着它可以嵌入到网络结构中进行端到端的训练. 信道洗牌操作使得构建具有多组卷积层的更强大的结构成为可能。在下一小节中，我们将介绍一种具有信道洗牌和组卷积的高效网络单元 ShuffleNet Unit利用 channel shuffle 的优势, 我们提出了一种专为小型网络设计的 ShuffleNet unit. 我们从 ResNet 的 bottleneck 的设计原则开始. 首先, 我们将残差分支的 3x3 卷积换成计算效益更高的 Depthwise Conv, 如图2(a)所示. 然后, 我们将第一个 1x1 卷积层换成 Group Conv(Pointwise) 和 Channel Shuffle, 如图2(b)所示, 第二个 Group Conv(Pointwise) 的目的是恢复通道数以匹配 shortcut 连接, 为了简单起见, 我们没有这里使用额外的 Channel Shuffle 操作, 因为这已经可以产生不错的效果了. BN 和 ReLU 会用在每个卷积层之后, 只不过根据 Xception 的建议, 我们没有在 Depthwise Conv 之后使用 ReLU. 对于需要下采样(with stride)的情况, 我们做了两点修改, 如图2(c)所示: 首先, 在 shortcut path 上添加一个 3x3 的 avg pooling; 然后, 用 channel concatenation 操作替换 element-wise addition 操作, 这使得在不增加额外计算成本的情况下, 可以方便的扩大通道尺寸. 得益于 Pointwise Group Conv 和 Channel Shuffle 的结合, ShuffleNet 中的所有组件都可以高效的进行计算. 和 ResNet 与 ResNeXt 相比, 我们的结构在相同的设定下具有更少的复杂度. 例如, 当给定输入尺寸为 $c\times h\times w$, 而 bottleneck 的通道数为 $m$ 时, ResNet unit 需要 $hw(2cm + 9m^2)$ FLOPs, ResNeXt 需要 $hw(2cm + 9m^2/g)$ FLOPs, 而 ShuffleNet 只需要 $hw(2cm/g + 9m)$ FLOPs. 也就说, 当给定计算资源限制后, ShuffleNet 可以使用更大的特征图谱, 这对于小型网络来说非常重要, 因为小型网络通畅没有足够的通道来处理信息. 此外, ShuffleNet 中的 Depthwise Conv 只在 bottleneck 的特征图谱上执行. 虽然深度卷积通常具有非常低的理论复杂度, 但我们发现在低功耗移动设备上很难有效地实现, 这可能是因为与其他密集操作相比, Depthwise Conv 的计算/内存访问率更低. Network Architecture基于 ShuffleNet Units, 我们在表1中给出了整个 ShuffleNet 的网络结构. 该网络主要有一系列的 ShuffleNet units 组成, 并且可以划分为三个阶段. 每个阶段的第一个 building block 的步长为2(stride=2). 每个 Stage 内的其他超参数都相同, 并且当进入下一个 Stage 时, Channels 的输出数量都翻倍. 和 ResNet 类似, 我们设置 bottleneck 的 channels 的数量为最终输出通道数量的 1/4. 我们的目标是提供一个尽可能简单的参考设计, 尽管我们发现更进一步的超参数调优可能会产生更好的结果. 在 ShuffleNet units 中, Group 的数量 $g$ 控制了 Pointwise Conv 的连接稀疏性. 表1研究了不同组数带来的影响, 同时我们会适当调节输出通道数, 以确保总体的计算成本不变. 很明显, 在给定计算资源限制的情况下, 更多的组数可以具有更多的输出通道数, 这样可以对更多的信息编码, 但是由于相应的输入通道有限, 因此这也可能导致单个卷积 filter 的性能下降. 要将网络自定义为所需的复杂性, 我们可以简单地在通道的数量上应用一个比例因子 $s$. 例如, 我们将表1中的网络表示为 “ShuffleNet 1x”, 那么 “ShuffleNet sx” 表示将 ShuffleNet 1x 中的 filters 数量乘以 $s$, 因此总体复杂度大约是 ShuffleNet 1x 的 $s^2$ 倍. Experimentsweight decay: 4e-5.lr: linear-decay learning rate policy.batch size: 1024 Pointwise Group Convolutions: 如表2所示 Channel Shuffle: 如表3所示, 当 group 越大时, Channel Shuffle 带来的效益越高 Comparison with Other Structure Units: 如表4所示, 在小模型上, ShuffleNet 的效果很好. 没有使用 Inception 进行比较, 因为 Inception 包括了太多的超参数, 很难将其模型缩小化. 表6 展示了在达到相同精度时, 不同模型需要的 MFLOPs. Comparison with MobileNets and Other Frameworks: 表5显示了 ShuffleNet 与 MobileNet 之间的性能对比. Generalization Ability: 测试了 ShuffleNet 在目标检测上的通用性, 结果如表7所示. Actual Speedup Evaluation: 表8显示了在 ARM 平台上的实际 Inference 速度. 简述 ShuffleNet 的原理ShuffleNet 从深度卷积模型的计算效率角度出发, 对 ResNet 中的 bottleneck 模块进行改进, 首先利用 Pointwise Group Conv 来替换 ResNet 中计算成本较高 1x1 卷积, 但是 Group Conv 操作本身会阻塞特征图谱通道之间的信息流动, 因此, ShuffleNet 提出使用 Channel Shuffle 操作来缓解这个问题, 在实际使用中 Channel Shuffle 可以利用 reshape + 转置 + flatten 的方法快速实现(为了简单, 只在第一个 1x1 卷积后使用了 Channel Shuffle). 然后, ShuffleNet 用 Depthwise Conv 替换了原本的 3x3 卷积, 进一步降低计算量. 在进行 Downsample 时, 会将 shortcutpath 上添加步长为2的 avg pooling 层, 同时会将残差分支的 Depthwise Conv 的步长置为2. 用改进后的残差模块作为基本单元, ShuffleNet 的网络结构最开始由 3x3 的卷积层和最大池化层组成, 二者的步长均为2, 也就说这里的 Downsample 总步长为 4. 然后是三个不同的 Stage(3,7,3), 每个 Stage 最开始第一个 building block 的步长为2(stride=2). 当进入下一个 Stage 时, Channels 的输出数量都翻倍. 最后是由 GAP+FC+Softmax 组成分类层. ShuffleNet 最主要的特点是可以在较少的计算资源限制下达到更高的精度和计算效率. 举例来说, 当给定输入尺寸为 $c\times h\times w$, 而 bottleneck 的通道数为 $m$ 时, ResNet unit 需要 $hw(2cm + 9m^2)$ FLOPs, ResNeXt 需要 $hw(2cm + 9m^2/g)$ FLOPs, 而 ShuffleNet 只需要 $hw(2cm/g + 9m)$ FLOPs. 也就说, 当给定计算资源限制后, ShuffleNet 可以使用更大的特征图谱, 这对于小型网络来说非常重要, 因为小型网络通畅没有足够的通道来处理信息. 简述 ShuffleNet 和 MobileNet 的区别ShuffleNet 使用的是 Pointwise Group Conv, 而 MobileNet 使用的是 Pointwise Conv.在 3x3 的卷积层上, 二者相同, 都使用的是 Depthwise Conv(不改变通道数).]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习500问》 第二章 机器学习基础]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Book-DL500Questions-ch02-ML%2F</url>
    <content type="text"><![CDATA[本篇博文为个人读书笔记, 更详细的内容请查看《深度学习500问》原版书籍 第二章 机器学习基础2.1 各种常见算法图示 回归算法 基于实例的算法 正则化方法 决策树学习 贝叶斯方法 基于核的算法 聚类算法 关联规则学习 人工神经网络 深度学习 降低维度算法 集成算法 2.2 监督学习, 非监督学习, 半监督学习, 弱监督学习?根据数据类型的不同, 对一个问题的建模有不同的方式. 依据不同的学习方式和输入数据, 机器学习主要分为以下四种学习方式. 监督学习 监督学习是使用已知正确答案的样本来训练网络. 已知数据和其一一对应的标签, 训练一个智能算法, 将输入数据映射到标签的过程. 监督式学习的常见应用场景如分类问题和回归问题 常见算法有逻辑回归(Logistic Regression)和反向传播神经网络(Back Propagation Neural Network) 非监督学习 在非监督式学习中, 数据并不被特别标识, 适用于具有数据集但没有标签的情况. 学习模型是为了推断出数据的一些内在结构. 常见的应用场景包括关联规则的学习以及聚类等. 常见算法包括 Apriori 算法以及 k-Means 算法. 半监督学习 在此学习方式下, 输入数据部分被标记, 部分没有被标记, 这种学习模型可以用来进行预测. 应用场景包括分类和回归, 算法包括一些对常用监督式学习算法的延伸, 通过对已标记数据建模, 在此基础上, 对未标记数据进行预测. 常见算法如图论推理算法(Graph Inference)或者拉普拉斯支持向量机(Laplacian SVM)等. 弱监督学习 弱监督学习可以看做是有多个标记的数据集合, 次集合可以是空集, 单个元素, 或包含多种情况(没有标记, 有一个标记, 和有多个标记)的多个元素. 数据集的标签是不可靠的, 这里的不可靠可以是标记不正确, 多种标记, 标记不充分, 局部标记等. 已知数据和其一一对应的弱标签, 训练一个智能算法, 将输入数据映射到一组更强的标签的过程. 标签的强弱指的是标签蕴含的信息量的多少, 比如相对于分割的标签来说, 分类的标签就是弱标签. 举例, 告诉一张包含气球的图片, 需要得出气球在图片中的位置及气球和背景的分割线, 这就是已知弱标签学习强标签的问题. 在企业数据应用的场景下, 人们最常用的可能就是监督式学习和非监督式学习的模型. 在图像识别等领域, 由于存在大量的非标识的数据和少量的可标识数据, 目前半监督式学习是一个很热的话题. 2.3 监督学习有哪些步骤监督学习是使用已知正确答案的样本来训练网络. 每组训练数据有一个明确的标识或结果, 想象一下, 我们可以训练一个网络, 让其从照片库中(其中包含气球的照片)识别出气球的照片. 以下就是我们在这个假设场景中所要采取的步骤. 数据集的创建和分类: 数据标注, 数据集划分; 训练: 搭建模型, 损失函数, 各种训练 Trick; 验证: 验证当前训练的模型的泛化能力; 测试及应用: 推理结果, 部署应用. 2.4 多实例学习?在机器学习中, 多示例学习(Multiple Instance Learning 简称 MIL)是由监督型学习算法演变出的一种方法, 定义“包”为多个示例的集合, 具有广泛的应用. 学习者不是接收一组单独标记的实例, 而是接收一组带标签的包, 每个包含许多实例. 在多实例二进制分类的简单情况下, 如果包中的所有实例都是否定的, 则可以将包标记为否定. 另一方面, 如果袋子中至少有一个是正面的, 则袋子被标记为阳性. 比如说一段视频由很多张图组成, 假如10000张, 那么我们要判断视频里是否包含某一物体, 比如气球. 单张标注每一帧是否有气球太耗时, 通常人们看一遍说这个视频里是否有气球, 就得到了多示例学习的数据. 10000帧的数据不是每一个都有气球出现, 只要有一帧有气球, 那么我们就认为这个数据包是有气球的. 只有当所有的视频帧都没有气球, 才是没有气球的. 从这里面学习哪一段视频(10000张)是否有气球出现就是多实例学习的问题. 2.5 分类网络和回归的区别?分类任务的输出值是离散的, 而回归任务的输出值是连续的. 2.6 什么是神经网络?神经网络就是按照一定规则将多个神经元连接起来的网络. 不同的神经网络, 具有不同的连接规则.例如全连接(full connected, FC)神经网络, 它的规则包括 有三种层: 输入层, 输出层, 隐藏层. 同一层的神经元之间没有连接. full connected的含义: 第 N 层的每个神经元和第 N-1 层的所有神经元相连, 第 N-1 层神经元的输出就是第 N 层神经元的输入. 每个连接都有一个权值. 神经网络架构下面这张图就是一个神经网络系统, 它由很多层组成. 输入层负责接收信息, 比如一只猫的图片. 输出层是计算机对这个输入信息的判断结果, 它是不是猫. 隐藏层就是对输入信息的传递和加工处理. 2.7 理解局部最优与全局最优一则小故事: 柏拉图有一天问老师苏格拉底什么是爱情? 苏格拉底叫他到麦田走一次, 摘一颗最大的麦穗回来, 不许回头, 只可摘一次. 柏拉图空着手出来了, 他的理由是, 看见不错的, 却不知道是不是最好的, 一次次侥幸, 走到尽头时, 才发现还不如前面的, 于是放弃. 苏格拉底告诉他“这就是爱情. ”这故事让我们明白了一个道理, 因为生命的一些不确定性, 所以全局最优解是很难寻找到的, 或者说根本就不存在, 我们应该设置一些限定条件, 然后在这个范围内寻找最优解, 也就是局部最优解——有所斩获总比空手而归强, 哪怕这种斩获只是一次有趣的经历.柏拉图有一天又问什么是婚姻? 苏格拉底叫他到彬树林走一次,选一棵最好的树做圣诞树, 也是不许回头, 只许选一次. 这次他一身疲惫地拖了一棵看起来直挺, 翠绿, 却有点稀疏的杉树回来, 他的理由是, 有了上回的教训, 好不容易看见一棵看似不错的, 又发现时间, 体力已经快不够用了, 也不管是不是最好的, 就拿回来了. 苏格拉底告诉他: 这就是婚姻. 优化问题一般分为局部最优和全局最优. 局部最优, 就是在函数值空间的一个 有限区域内 寻找最小值; 而全局最优, 是在函数值空间 整个区域 寻找最小值问题. 函数局部最小点是那种它的函数值小于或等于附近点的点. 但是有可能大于较远距离的点. 全局最小点是那种它的函数值小于或等于所有的可行点. 2.8 分类算法2.8.1 常用分类算法的优缺点? 算法 优点 缺点 贝叶斯分类法(Bayes) 1)所需估计的参数少, 对于缺失数据不敏感. 2)有着坚实的数学基础, 以及稳定的分类效率. 1)假设属性之间相互独立, 这往往并不成立. (喜欢吃番茄, 鸡蛋, 却不喜欢吃番茄炒蛋). 2)需要知道先验概率. 3)分类决策存在错误率. 决策树(Decision Tree) 1)不需要任何领域知识或参数假设. 2)适合高维数据. 3)简单易于理解. 4)短时间内处理大量数据, 得到可行且效果较好的结果. 5)能够同时处理数据型和常规性属性. 1)对于各类别样本数量不一致数据, 信息增益偏向于那些具有更多数值的特征. 2)易于过拟合. 3)忽略属性之间的相关性. 4)不支持在线学习. 支持向量机(SVM) 1)可以解决小样本下机器学习的问题. 2)提高泛化性能. 3)可以解决高维, 非线性问题. 超高维文本分类仍受欢迎. 4)避免神经网络结构选择和局部极小的问题. 1)对缺失数据敏感. 2)内存消耗大, 难以解释. 3)运行和调差略烦人. K近邻(KNN) 1)思想简单, 理论成熟, 既可以用来做分类也可以用来做回归; 2)可用于非线性分类; 3)训练时间复杂度为O(n); 4)准确度高, 对数据没有假设, 对outlier不敏感; 1)计算量太大; 2)对于样本分类不均衡的问题, 会产生误判; 3)需要大量的内存; 4)输出的可解释性不强. 逻辑回归(Logistic Regression) 1)速度快. 2)简单易于理解, 直接看到各个特征的权重. 3)能容易地更新模型吸收新的数据. 4)如果想要一个概率框架, 动态调整分类阀值. 特征处理复杂. 需要归一化和较多的特征工程. 神经网络(Neural Network) 1)分类准确率高. 2)并行处理能力强. 3)分布式存储和学习能力强. 4)鲁棒性较强, 不易受噪声影响. 1)需要大量参数(网络拓扑, 阀值, 阈值). 2)结果难以解释. 3)训练时间过长. Adaboosting 1)adaboost是一种有很高精度的分类器. 2)可以使用各种方法构建子分类器, Adaboost算法提供的是框架. 3)当使用简单分类器时, 计算出的结果是可以理解的. 而且弱分类器构造极其简单. 4)简单, 不用做特征筛选. 5)不用担心overfitting. 对outlier比较敏感 2.8.2 正确率能很好的评估分类算法吗?不同算法有不同特点, 在不同数据集上有不同的表现效果, 根据特定的任务选择不同的算法. 如何评价分类算法的好坏, 要做具体任务具体分析. 对于决策树, 主要用正确率去评估, 但是其他算法, 只用正确率能很好的评估吗?答案是否定的.正确率确实是一个很直观很好的评价指标, 但是有时候正确率高并不能完全代表一个算法就好. 比如对某个地区进行地震预测, 地震分类属性分为0不发生地震, 1发生地震. 我们都知道, 不发生的概率是极大的, 对于分类器而言, 如果分类器不加思考, 对每一个测试样例的类别都划分为0, 达到99%的正确率, 但是, 问题来了, 如果真的发生地震时, 这个分类器毫无察觉, 那带来的后果将是巨大的. 很显然, 99%正确率的分类器并不是我们想要的. 出现这种现象的原因主要是数据分布不均衡, 类别为1的数据太少, 错分了类别1但达到了很高的正确率缺忽视了研究者本身最为关注的情况. 2.8.3 分类算法的评估方法?几个常用的术语这里首先介绍几个常见的 模型评价术语, 现在假设我们的分类目标只有两类, 计为正例(positive)和负例(negative)分别是 1) True positives(TP): 被正确地划分为正例的个数, 即实际为正例且被分类器划分为正例的实例数(样本数);2) False positives(FP): 被错误地划分为正例的个数, 即实际为负例但被分类器划分为正例的实例数;3) False negatives(FN):被错误地划分为负例的个数, 即实际为正例但被分类器划分为负例的实例数;4) True negatives(TN): 被正确地划分为负例的个数, 即实际为负例且被分类器划分为负例的实例数. 评价指标1) 正确率(accuracy)正确率是我们最常见的评价指标, accuracy = (TP+TN)/(P+N), 正确率是被分对的样本数在所有样本数中的占比, 通常来说, 正确率越高, 分类器越好.2) 错误率(error rate)错误率则与正确率相反, 描述被分类器错分的比例, error rate = (FP+FN)/(P+N), 对某一个实例来说, 分对与分错是互斥事件, 所以accuracy =1 - error rate.3) 灵敏度(sensitive)sensitive = TP/P, 表示的是所有正例中被分对的比例, 衡量了分类器对正例的识别能力.4) 特效度(specificity)specificity = TN/N, 表示的是所有负例中被分对的比例, 衡量了分类器对负例的识别能力.5) 精度(precision)精度是精确性的度量, 表示被分为正例的示例中实际为正例的比例, precision=TP/(TP+FP).6) 召回率(recall)召回率是覆盖面的度量, 度量有多个正例被分为正例, recall=TP/(TP+FN)=TP/P=sensitive, 可以看到召回率与灵敏度是一样的.7) 其他评价指标计算速度分类器训练和预测需要的时间;鲁棒性处理缺失值和异常值的能力;可扩展性处理大数据集的能力;可解释性分类器的预测标准的可理解性, 像决策树产生的规则就是很容易理解的, 而神经网络的一堆参数就不好理解, 我们只好把它看成一个黑盒子.8) 查准率和查全率反映了分类器分类性能的两个方面. 如果综合考虑查准率与查全率, 可以得到新的评价指标F1测试值, 也称为综合分类率$F1=\frac{2 \times precision \times recall}{precision + recall}$为了综合多个类别的分类情况, 评测系统整体性能, 经常采用的还有微平均F1(micro-averaging)和宏平均F1(macro-averaging )两种指标. 宏平均F1与微平均F1是以两种不同的平均方式求的全局的F1指标. 其中宏平均F1的计算方法先对每个类别单独计算F1值, 再取这些F1值的算术平均值作为全局指标. 而微平均F1的计算方法是先累加计算各个类别的a, b, c, d的值, 再由这些值求出F1值. 由两种平均F1的计算方式不难看出, 宏平均F1平等对待每一个类别, 所以它的值主要受到稀有类别的影响, 而微平均F1平等考虑文档集中的每一个文档, 所以它的值受到常见类别的影响比较大.ROC曲线和PR曲线 References[1] 李航. 统计学习方法[M]. 北京:清华大学出版社,2012. 2.8.4 什么样的分类器是最好的?对某一个任务, 某个具体的分类器不可能同时满足或提高所有上面介绍的指标.如果一个分类器能正确分对所有的实例, 那么各项指标都已经达到最优, 但这样的分类器往往不存在. 比如之前说的地震预测, 既然不能百分百预测地震的发生, 但实际情况中能容忍一定程度的误报. 假设在1000次预测中, 共有5次预测发生了地震, 真实情况中有一次发生了地震, 其他4次则为误报. 正确率由原来的999/1000=99.9下降为996/10000=99.6. 召回率由0/1=0%上升为1/1=100%. 对此解释为, 虽然预测失误了4次, 但真的地震发生前, 分类器能预测对, 没有错过, 这样的分类器实际意义更为重大, 正是我们想要的. 在这种情况下, 在一定正确率前提下, 要求分类器的召回率尽量高. 2.9 逻辑回归2.9.1 理解逻辑回归回归划分 广义线性模型家族里, 依据因变量不同, 可以有如下划分 如果是连续的, 就是多重线性回归; 如果是二项分布, 就是 Logistic 回归(其返回值本身也是连续的, 只不过根据阈值做了二值化处理); 如果是 Poisson 分布, 就是 Poisson 回归; 如果是负二项分布, 就是负二项回归.Logistic 回归的因变量可以是二分类的, 也可以是多分类的, 但是二分类的更为常用, 也更加容易解释. 所以实际中最常用的就是二分类的 Logistic 回归. Logistic 回归的适用性 用于概率预测. 用于可能性预测时, 得到的结果有可比性. 比如根据模型进而预测在不同的自变量情况下, 发生某病或某种情况的概率有多大; 用于分类. 实际上跟预测有些类似, 也是根据模型, 判断某人属于某病或属于某种情况的概率有多大, 也就是看一下这个人有多大的可能性是属于某病. 进行分类时, 仅需要设定一个阈值即可, 可能性高于阈值是一类, 低于阈值是另一类. 寻找危险因素. 寻找某一疾病的危险因素等. 仅能用于线性问题. 只有当目标和特征是线性关系时, 才能用逻辑回归. 在应用逻辑回归时注意两点: 一是当知道模型是非线性时, 不适用逻辑回归; 二是当使用逻辑回归时, 应注意选择和目标为线性关系的特征. 各特征之间不需要满足条件独立假设, 但各个特征的贡献独立计算. 2.9.2 逻辑回归与朴素贝叶斯有什么区别? 逻辑回归是判别模型, 朴素贝叶斯是生成模型, 所以生成和判别的所有区别它们都有. 朴素贝叶斯属于贝叶斯, 逻辑回归是最大似然, 两种概率哲学间的区别. 朴素贝叶斯需要独立假设. 逻辑回归需要求特征参数间是线性的. 2.9.3线性回归与逻辑回归的区别?线性回归的样本的输出, 都是连续值, $ y\in (-\infty ,+\infty )$, 而逻辑回归中$y\in (0,1)$, 只能取0和1.(通过阈值的设定将连续值转化成二值) 对于拟合函数也有本质上的差别线性回归$f(x)=\theta ^{T}x=\theta_{1}x_{1}+\theta_{2}x_{2}+…+\theta_{n}x_{n}$ 逻辑回归$f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)$, 其中, $g(z)=\frac{1}{1+e^{-z}}$ 可以看出, 线性回归的拟合函数, 是对f(x)的输出变量y的拟合, 而逻辑回归的拟合函数是对输出为 1 的样本的概率的拟合. 那么, 为什么要以1类样本的概率进行拟合呢, 为什么可以这样拟合呢? $\theta ^{T}x=0$就相当于是1类和0类的决策边界 当$\theta ^{T}x&gt;0$, 则y&gt;0.5; 若$\theta ^{T}x\rightarrow +\infty $, 则$y \rightarrow 1 $, 即y为1类; 当$\theta ^{T}x&lt;0$, 则y&lt;0.5; 若$\theta ^{T}x\rightarrow -\infty $, 则$y \rightarrow 0 $, 即y为0类; 这个时候就能看出区别来了, 在线性回归中$\theta ^{T}x$为预测值的拟合函数; 而在逻辑回归中$\theta ^{T}x$为决策边界. 线性回归 逻辑回归 目的 预测 分类 $y^{(i)}$ 未知 $(0,1)$ 函数 拟合函数 概率函数 参数计算方式 最小二乘法 极大似然估计 下面具体解释一下 拟合函数和概率函数什么关系呢? 其实就是将拟合函数做了一个逻辑函数的转换, 转换后使得$y^{(i)} \in (0,1)$; 最小二乘和最大似然估计可以相互替代吗? 回答当然是不行了. 我们来看看两者依仗的原理: 最大似然估计是计算使得数据出现的可能性最大的参数, 依仗的自然是 Probability. 而最小二乘是计算误差损失. 2.9.4 Factorization Machines(FM)模型原理TODO: 此小结没仔细看, 待补充 FM旨在解决稀疏数据的特征组合问题,某些特征经过关联之后,就会与 label 之间的相关性就会提高,例如设备 id 与 ip 地址之间的特征交叉就会更好的与 label 之间有相关性. FM为二阶多项式模型 2.10 代价函数2.10.1 为什么需要代价函数? 为了得到逻辑回归模型的训练参数, 需要一个代价函数, 通过训练代价函数来得到参数. 用于找到最优解. 2.10.2 代价函数作用原理在回归问题中, 通过代价函数来求解最优解, 常用的是平方误差代价函数. 有如下假设函数 h(x) = A + Bx假设函数中有$A$和$B$两个参数, 当参数发生变化时, 函数状态也会随着变化. 我们需要尽可能找到最优的 $A$ 和 $B$ 来使上面公式所代表的直线更能代表所有数据. 如何找到最优解呢, 这就需要使用代价函数来求解, 以平方误差代价函数为例, 假设函数.为 $h(x)=\theta_0x$. 平方误差代价函数的主要思想就是将实际数据给出的值与拟合出的线的对应值做差, 求出拟合出的直线与实际的差距. 在实际应用中, 为了避免因个别极端数据产生的影响, 采用类似方差再取二分之一的方式来减小个别数据的影响. 因此, 引出代价函数 J(\theta_0, \theta_1) = \frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2最优解即为代价函数的最小值 $\min J(\theta_0, \theta_1)$. 如果是 1 个参数, 代价函数一般通过二维曲线便可直观看出. 如果是 2 个参数, 代价函数通过三维图像可看出效果, 参数越多, 越复杂. 2.10.3 为什么代价函数要非负?目标函数存在一个下界, 在优化过程当中, 如果优化算法能够使目标函数不断减小, 根据单调有界准则, 这个优化算法就能证明是收敛有效的.只要设计的目标函数有下界, 基本上都可以, 代价函数非负只是为了方便计算. 2.10.4 常见代价函数?二次代价函数(quadratic cost)J = \frac{1}{2n}\sum_x\Vert y(x)-a^L(x)\Vert^2其中, $J$表示代价函数, $x$ 表示样本, $y$ 示实际值, $a$ 表示输出值, $n$ 表示样本的总数. 使用一个样本为例简单说明, 此时二次代价函数为 J = \frac{(y-a)^2}{2}假如使用梯度下降法(Gradient descent)来调整权值参数的大小, 权值 $w$ 和偏置 $b$ 的梯度推导如下: \frac{\delta J}{\delta w}=(a-y)\delta'(z)x\frac{\delta J}{\delta b}=(a-y)\delta'(z)其中, $z$ 表示神经元的输入, $\delta$表示激活函数. 权值 $w$ 和偏置 $b$ 的梯度跟激活函数的梯度成正比, 激活函数的梯度越大, 权值 $w$ 和偏置 $b$ 的大小调整得越快, 训练收敛得就越快. 注神经网络常用的激活函数为sigmoid函数, 该函数的公式为: y = \frac{1}{1+e^{-x}}TODO: 下面的话是什么意思?假设目标是收敛到1.0. 0.82离目标比较远, 梯度比较大, 权值调整比较大. 0.98离目标比较近, 梯度比较小, 权值调整比较小. 调整方案合理. 假如目标是收敛到0. 0.82目标比较近, 梯度比较大, 权值调整比较大. 0.98离目标比较远, 梯度比较小, 权值调整比较小. 调整方案不合理.原因:初始的代价(误差)越大, 导致训练越慢. 交叉熵代价函数(cross-entropy)交叉熵代价函数 J = \frac{1}{n}\sum_x[y\ln a + (1-y)\ln{(1-a)}]其中, $J$ 表示代价函数, $x$ 表示样本, $y$ 表示实际值, $a$ 表示输出值, $n$ 表示样本的总数.权值 $w$ 和偏置 $b$ 的梯度推导如下 \frac{\delta J}{\delta w_j}=\frac{1}{n}\sum_{x}(\delta{(a)}-y)\;, \frac{\delta J}{\delta b}=\frac{1}{n}\sum_{x}(\delta{(z)}-y)当误差越大时, 梯度就越大, 权值$w$和偏置$b$调整就越快, 训练的速度也就越快.二次代价函数适合输出神经元是线性的情况, 交叉熵代价函数适合输出神经元是S型函数的情况. 对数似然代价函数(log-likelihood cost)对数释然函数常用来作为softmax回归的代价函数. 深度学习中普遍的做法是将softmax作为最后一层, 此时常用的代价函数是对数释然代价函数. 对数似然代价函数与softmax的组合和交叉熵与sigmoid函数的组合非常相似. 对数释然代价函数在二分类时可以化简为交叉熵代价函数的形式.在tensorflow中 与sigmoid搭配使用的交叉熵函数 `tf.nn.sigmoid_cross_entropy_with_logits()`. 与softmax搭配使用的交叉熵函数 `tf.nn.softmax_cross_entropy_with_logits()`. 2.10.5 为什么用交叉熵代替二次代价函数 为什么不用二次方代价函数由2.18节可知, 权值$w$和偏置$b$的偏导数为$\frac{\delta J}{\delta w}=(a-y)\delta’(z)x$, $\frac{\delta J}{\delta b}=(a-y)\delta’(z)$, 偏导数受激活函数的导数影响, sigmoid函数导数在输出接近0和1时非常小, 会导致一些实例在刚开始训练时学习得非常慢. 为什么要用交叉熵交叉熵函数权值$w$和偏置$b$的梯度推导为 \frac{\delta J}{\delta w_j}=\frac{1}{n}\sum_{x}(\delta{(a)}-y)\;, \frac{\delta J}{\delta b}=\frac{1}{n}\sum_{x}(\delta{(z)}-y)由以上公式可知, 权重学习的速度受到$\delta{(z)}-y$影响, 更大的误差, 就有更快的学习速度, 避免了二次代价函数方程中因$\delta’{(z)}$导致的学习缓慢的情况. 2.11 损失函数https://www.zhihu.com/question/52398145 2.11.1 什么是损失函数?损失函数(Loss function)又叫做误差函数, 用来衡量算法的运行情况, 估量模型的预测值 与真实值 的不一致程度, 是一个非负实值函数,通常使用 来表示, 损失函数越小, 模型的鲁棒性就越好.损失函数是经验风险函数的核心部分, 也是结构风险函数重要组成部分. 2.11.2 常见的损失函数机器学习通过对算法中的目标函数进行不断求解优化, 得到最终想要的结果. 分类和回归问题中, 通常使用损失函数或代价函数作为目标函数.损失函数用来评价预测值和真实值不一样的程度. 通常损失函数越好, 模型的性能也越好.损失函数可分为经验风险损失函数和结构风险损失函数. 经验风险损失函数指预测结果和实际结果的差别, 结构风险损失函数是在经验风险损失函数上加上正则项.下面介绍常用的损失函数 0-1损失函数如果预测值和目标值相等, 值为0, 如果不相等, 值为1. L(Y, f(x)) = \begin{cases} 1,& Y\ne f(x)\\ 0,& Y = f(x) \end{cases}一般的在实际使用中, 相等的条件过于严格, 可适当放宽条件 L(Y, f(x)) = \begin{cases} 1,& |Y-f(x)|\ge T\\ 0,& |Y-f(x)|< T \end{cases} 绝对值损失函数和0-1损失函数相似, 绝对值损失函数表示为 L(Y, f(x)) = |Y-f(x)|​ 平方损失函数 L(Y, f(x)) = \sum_N{(Y-f(x))}^2这点可从最小二乘法和欧几里得距离角度理解. 最小二乘法的原理是, 最优拟合曲线应该使所有点到回归直线的距离和最小. log对数损失函数 L(Y, P(Y|X)) = -\log{P(Y|X)}常见的逻辑回归使用的就是对数损失函数, 有很多人认为逻辑回归的损失函数式平方损失, 其实不然. 逻辑回归它假设样本服从伯努利分布, 进而求得满足该分布的似然函数, 接着取对数求极值等. 逻辑回归推导出的经验风险函数是最小化负的似然函数, 从损失函数的角度看, 就是log损失函数. 指数损失函数指数损失函数的标准形式为 L(Y, f(x)) = \exp{-yf(x)}例如AdaBoost就是以指数损失函数为损失函数. Hinge损失函数Hinge损失函数的标准形式如下 L(Y) = \max{(0, 1-ty)}其中y是预测值, 范围为(-1,1),t为目标值, 其为-1或1. 在线性支持向量机中, 最优化问题可等价于 \underset{\min}{w,b}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w^2\Vert上式相似于下式 \frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w^2\Vert其中$l(wx_i+by_i)$是Hinge损失函数, $\Vert w^2\Vert$可看做为正则化项. 2.11.3 逻辑回归为什么使用对数损失函数?假设逻辑回归模型TODO假设逻辑回归模型的概率分布是伯努利分布, 其概率质量函数为TODO其似然函数为TODO对数似然函数为TODO对数函数在单个数据点上的定义为TODO则全局样本损失函数为 TODO由此可看出, 对数损失函数与极大似然估计的对数似然函数本质上是相同的. 所以逻辑回归直接采用对数损失函数. 2.11.4 对数损失函数是如何度量损失的?举例 高斯分布中, 我们需要确定均值 和标注差 .如何确定这两个参数? 最大似然估计是比较常用的方法. 最大似然的目标是找到一些参数值, 这些参数值对应的分布可以最大化观测到数据的概率.因为需要计算观测到所有数据的全概率, 即所有观测到的数据点的联合概率. 现考虑如下简化情况 假设观测到每个数据点的概率和其他数据点的概率是独立的. 取自然对数.假设观测到单个数据点TODO的概率为 TODO其联合概率为TODO对上式取自然对数, 可得 TODO根据对数定律, 上式可以化简为 TODO求导 TODO上式左半部分为对数损失函数. 损失函数越小越好, 因此我们令对数损失函数为0, 可得 TODO同理, 可计算TODO. 2.12 梯度下降2.12.1 机器学习中为什么需要梯度下降? 梯度下降是迭代法的一种,可以用于求解最小二乘问题. 在求解机器学习算法的模型参数, 即无约束优化问题时, 主要有梯度下降法(Gradient Descent)和最小二乘法. 在求解损失函数的最小值时, 可以通过梯度下降法来一步步的迭代求解, 得到最小化的损失函数和模型参数值. 如果我们需要求解损失函数的最大值, 可通过梯度上升法来迭代. 梯度下降法和梯度上升法可相互转换. 在机器学习中, 梯度下降法主要有随机梯度下降法和批量梯度下降法. 2.12.2 梯度下降法缺点? 靠近极小值时收敛速度减慢. 直线搜索时可能会产生一些问题. 可能会“之字形”地下降. 梯度概念需注意 梯度是一个向量, 即有方向有大小; 梯度的方向是最大方向导数的方向; 梯度的值是最大方向导数的值. 2.12.3 梯度下降法直观理解?梯度下降法经典图示: 形象化举例 由上图, 假如最开始, 我们在一座大山上的某处位置, 因为到处都是陌生的, 不知道下山的路, 所以只能摸索着根据直觉, 走一步算一步, 在此过程中, 每走到一个位置的时候, 都会求解当前位置的梯度, 沿着梯度的负方向, 也就是当前最陡峭的位置向下走一步, 然后继续求解当前位置梯度, 向这一步所在位置沿着最陡峭最易下山的位置走一步. 不断循环求梯度, 就这样一步步的走下去, 一直走到我们觉得已经到了山脚. 当然这样走下去, 有可能我们不能走到山脚, 而是到了某一个局部的山峰低处.由此, 从上面的解释可以看出, 梯度下降不一定能够找到全局的最优解, 有可能是一个局部最优解. 当然, 如果损失函数是凸函数, 梯度下降法得到的解就一定是全局最优解. 核心思想归纳 初始化参数, 随机选取取值范围内的任意数; 迭代操作 a) 计算当前梯度;b)修改新的变量;c)计算朝最陡的下坡方向走一步;d)判断是否需要终止, 如否, 返回a); 得到全局最优解或者接近全局最优解. 2.12.4 梯度下降法算法描述? 确定优化模型的假设函数及损失函数.举例, 对于线性回归, 假设函数为 TODO其中, TODO分别为模型参数, 每个样本的特征值.对于假设函数, 损失函数为 TODO 相关参数初始化.主要初始化TODO, 算法迭代步长TODO, 终止距离TODO. 初始化时可以根据经验初始化, 即TODO初始化为0, 步长TODO初始化为1. 当前步长记为TODO. 当然, 也可随机初始化. 迭代计算. 1) 计算当前位置时损失函数的梯度, 对TODO, 其梯度表示为TODO 2) 计算当前位置下降的距离. TODO 3) 判断是否终止.确定是否所有TODO梯度下降的距离TODO都小于终止距离TODO, 如果都小于TODO, 则算法终止, 当然的值即为最终结果, 否则进入下一步.4) 更新所有的TODO, 更新后的表达式为TODO5) 更新完毕后转入1). 举例. 以线性回归为例.假设样本是TODO损失函数为TODO在计算中, TODO的偏导数计算如下 TODO令上式 . 4)中TODO的更新表达式为 TODO由此, 可看出, 当前位置的梯度方向由所有样本决定, 上式中TODO的目的是为了便于理解. 2.12.5 如何对梯度下降法进行调优?实际使用梯度下降法时, 各项参数指标不能一步就达到理想状态, 对梯度下降法调优主要体现在以下几个方面 算法迭代步长$\alpha$选择. 在算法参数初始化时, 有时根据经验将步长 初始化为1. 实际取值取决于数据样本. 可以从大到小, 多取一些值, 分别运行算法看迭代效果, 如果损失函数在变小, 则取值有效. 如果取值无效, 说明要增大步长. 但步长太大, 有时会导致迭代速度过快, 错过最优解. 步长太小, 迭代速度慢, 算法运行时间长. 参数的初始值选择. 初始值不同, 获得的最小值也有可能不同, 梯度下降有可能得到的是局部最小值. 如果损失函数是凸函数, 则一定是最优解. 由于有局部最优解的风险, 需要多次用不同初始值运行算法, 关键损失函数的最小值, 选择损失函数最小化的初值. 标准化处理. 由于样本不同, 特征取值范围也不同, 导致迭代速度慢. 为了减少特征取值的影响, 可对特征数据标准化, 使新期望为0, 新方差为1, 可节省算法运行时间. 2.12.7 随机梯度和批量梯度区别?随机梯度下降和批量梯度下降是两种主要梯度下降法, 其目的是增加某些限制来加速运算求解.引入随机梯度下降法与mini-batch梯度下降法是为了应对大数据量的计算而实现一种快速的求解.下面通过介绍两种梯度下降法的求解思路, 对其进行比较.假设函数为TODO损失函数为TODO其中, TODO为样本个数, TODO为参数个数. 1, 批量梯度下降的求解思路如下 a) 得到每个TODO对应的梯度 TODO b) 由于是求最小化风险函数, 所以按每个参数TODO的梯度负方向更新TODO TODO c) 从上式可以注意到, 它得到的虽然是一个全局最优解, 但每迭代一步, 都要用到训练集所有的数据, 如果样本数据 很大, 这种方法迭代速度就很慢.相比而言, 随机梯度下降可避免这种问题. 2, 随机梯度下降的求解思路如下 a) 相比批量梯度下降对应所有的训练样本, 随机梯度下降法中损失函数对应的是训练集中每个样本的粒度.损失函数可以写成如下这种形式, TODO b)对每个参数TODO按梯度方向更新 TODO c) 随机梯度下降是通过每个样本来迭代更新一次.随机梯度下降伴随的一个问题是噪音较批量梯度下降要多, 使得随机梯度下降并不是每次迭代都向着整体最优化方向. 小结 随机梯度下降法, 批量梯度下降法相对来说都比较极端, 简单对比如下 批量梯度下降 a)采用所有数据来梯度下降.b) 批量梯度下降法在样本量很大的时候, 训练速度慢. 随机梯度下降 a) 随机梯度下降用一个样本来梯度下降.b) 训练速度很快.c) 随机梯度下降法仅仅用一个样本决定梯度方向, 导致解有可能不是最优.d) 收敛速度来说, 随机梯度下降法一次迭代一个样本, 导致迭代方向变化很大, 不能很快的收敛到局部最优解. 下面介绍能结合两种方法优点的小批量梯度下降法. 3, 小批量(mini-batch)梯度下降的求解思路如下对于总数为$m$个样本的数据, 根据样本的数据, 选取其中的$n(1&lt; n&lt; m)$个子样本来迭代. 其参数$\theta$按梯度方向更新$\theta_i$公式如下 TODO 2.12.8 各种梯度下降法性能比较下表简单对比随机梯度下降(SGD), 批量梯度下降(BGD), 小批量梯度下降(mini-batch GD), 和online GD的区别, 主要区别在于如何选取训练数据 BGD SGD GD Mini-batch GD Online GD 训练集 固定 固定 固定 实时更新 单次迭代样本数 整个训练集 单个样本 训练集的子集 根据具体算法定 算法复杂度 高 低 一般 低 时效性 低 一般 一般 高 收敛性 稳定 不稳定 较稳定 不稳定 BGD, SGD, Mini-batch GD,前面均已讨论过, 这里介绍一下Online GD. Online GD于mini-batch GD/SGD的区别在于, 所有训练数据只用一次, 然后丢弃. 这样做的优点在于可预测最终模型的变化趋势. Online GD在互联网领域用的较多, 比如搜索广告的点击率(CTR)预估模型, 网民的点击行为会随着时间改变. 用普通的BGD算法(每天更新一次)一方面耗时较长(需要对所有历史数据重新训练); 另一方面, 无法及时反馈用户的点击行为迁移. 而Online GD算法可以实时的依据网民的点击行为进行迁移. 2.13 计算图的导数计算图解?​ 计算图导数计算是反向传播, 利用链式法则和隐式函数求导. ​ 假设TODO在点TODO处偏导连续, TODO是关于TODO的函数, 在TODO点可导, 求TODO在TODO点的导数. 根据链式法则有TODO ​ 为了便于理解, 下面举例说明.假设$f(x)$是关于a,b,c的函数. 链式求导法则如下 \frac{dJ}{du}=\frac{dJ}{dv}\frac{dv}{du},\frac{dJ}{db}=\frac{dJ}{du}\frac{du}{db},\frac{dJ}{da}=\frac{dJ}{du}\frac{du}{da}​链式法则用文字描述:“由两个函数凑起来的复合函数, 其导数等于里边函数代入外边函数的值之导数, 乘以里边函数的导数. 例 f(x)=x^2,g(x)=2x+1则 {f[g(x)]}'=2[g(x)]\times g'(x)=2[2x+1]\times 2=8x+12.14 线性判别分析(LDA)2.14.1 线性判别分析(LDA)思想总结线性判别分析(Linear Discriminant Analysis, LDA)是一种经典的降维方法. 和PCA不考虑样本类别输出的无监督降维技术不同, LDA是一种监督学习的降维技术, 数据集的每个样本有类别输出. LDA分类思想简单总结如下 多维空间中, 数据处理分类问题较为复杂, LDA算法将多维空间中的数据投影到一条直线上, 将d维数据转化成1维数据进行处理. 对于训练数据, 设法将多维数据投影到一条直线上, 同类数据的投影点尽可能接近, 异类数据点尽可能远离. 对数据进行分类时, 将其投影到同样的这条直线上, 再根据投影点的位置来确定样本的类别.如果用一句话概括LDA思想, 即“投影后类内方差最小, 类间方差最大”. 2.14.2 图解LDA核心思想假设有红, 蓝两类数据, 这些数据特征均为二维, 如下图所示. 我们的目标是将这些数据投影到一维, 让每一类相近的数据的投影点尽可能接近, 不同类别数据尽可能远, 即图中红色和蓝色数据中心之间的距离尽可能大. 左图和右图是两种不同的投影方式. 左图思路让不同类别的平均点距离最远的投影方式. 右图思路让同类别的数据挨得最近的投影方式. 从上图直观看出, 右图红色数据和蓝色数据在各自的区域来说相对集中, 根据数据分布直方图也可看出, 所以右图的投影效果好于左图, 左图中间直方图部分有明显交集. 以上例子是基于数据是二维的, 分类后的投影是一条直线. 如果原始数据是多维的, 则投影后的分类面是一低维的超平面. 2.14.3 二类LDA算法原理?输入数据集TODO, 其中样本TODO是n维向量, TODO, TODO降维后的目标维度TODO. 定义 TODO为第TODO类样本个数; TODO为第TODO类样本的集合; TODO为第TODO类样本的均值向量; TODO为第TODO类样本的协方差矩阵. 其中TODO, TODO. 假设投影直线是向量TODO, 对任意样本TODO, 它在直线TODO上的投影为TODO, 两个类别的中心点TODO在直线TODO的投影分别为TODO, TODO. LDA的目标是让两类别的数据中心间的距离TODO尽量大, 与此同时, 希望同类样本投影点的协方差TODO, TODO尽量小, 最小化TODO.定义类内散度矩阵TODO 类间散度矩阵TODO 据上分析, 优化目标为TODO 根据广义瑞利商的性质, 矩阵TODO的最大特征值为TODO的最大值, 矩阵TODO的最大特征值对应的特征向量即为TODO. 2.14.4 LDA算法流程总结?LDA算法降维流程如下 输入数据集TODO, 其中样本TODO是n维向量, TODO, 降维后的目标维度TODO. 输出降维后的数据集TODO. 步骤 计算类内散度矩阵 . 计算类间散度矩阵 . 计算矩阵 . 计算矩阵 的最大的d个特征值. 计算d个特征值对应的d个特征向量, 记投影矩阵为 . 转化样本集的每个样本, 得到新样本 . 输出新样本集 2.14.5 LDA和PCA区别? 异同点 LDA PCA 相同点 1. 两者均可以对数据进行降维; 2. 两者在降维时均使用了矩阵特征分解的思想; 3. 两者都假设数据符合高斯分布; 不同点 有监督的降维方法 无监督的降维方法 降维最多降到k-1维 降维多少没有限制 可以用于降维, 还可以用于分类 只用于降维 选择分类性能最好的投影方向 选择样本点投影具有最大方差的方向 更明确, 更能反映样本间差异 目的较为模糊 2.14.6 LDA优缺点? 优缺点 简要说明 优点 1. 可以使用类别的先验知识; 2. 以标签, 类别衡量差异性的有监督降维方式, 相对于PCA的模糊性, 其目的更明确, 更能反映样本间的差异; 缺点 1. LDA不适合对非高斯分布样本进行降维; 2. LDA降维最多降到k-1维; 3. LDA在样本分类信息依赖方差而不是均值时, 降维效果不好; 4. LDA可能过度拟合数据. 2.15 主成分分析(PCA)2.15.1 主成分分析(PCA)思想总结 PCA就是将高维的数据通过线性变换投影到低维空间上去. 投影思想找出最能够代表原始数据的投影方法. 被PCA降掉的那些维度只能是那些噪声或是冗余的数据. 去冗余去除可以被其他向量代表的线性相关向量, 这部分信息量是多余的. 去噪声, 去除较小特征值对应的特征向量, 特征值的大小反映了变换后在特征向量方向上变换的幅度, 幅度越大, 说明这个方向上的元素差异也越大, 要保留. 对角化矩阵, 寻找极大线性无关组, 保留较大的特征值, 去除较小特征值, 组成一个投影矩阵, 对原始样本矩阵进行投影, 得到降维后的新样本矩阵. 完成PCA的关键是——协方差矩阵.协方差矩阵, 能同时表现不同维度间的相关性以及各个维度上的方差.协方差矩阵度量的是维度与维度之间的关系, 而非样本与样本之间. 之所以对角化, 因为对角化之后非对角上的元素都是0, 达到去噪声的目的. 对角化后的协方差矩阵, 对角线上较小的新方差对应的就是那些该去掉的维度. 所以我们只取那些含有较大能量(特征值)的维度, 其余的就舍掉, 即去冗余. 2.15.2 图解PCA核心思想PCA可解决训练数据中存在数据特征过多或特征累赘的问题. 核心思想是将m维特征映射到n维(n &lt; m), 这n维形成主元, 是重构出来最能代表原始数据的正交特征. 假设数据集是m个n维, $(x^{(1)}, x^{(2)}, \cdots, x^{(m)})$. 如果n=2,需要降维到$n’=1$, 现在想找到某一维度方向代表这两个维度的数据. 下图有$u_1, u_2$两个向量方向, 但是哪个向量才是我们所想要的, 可以更好代表原始数据集的呢? 从图可看出, $u_1$比$u_2$好, 为什么呢? 有以下两个主要评价指标 样本点到这个直线的距离足够近. 样本点在这个直线上的投影能尽可能的分开. 如果我们需要降维的目标维数是其他任意维, 则 样本点到这个超平面的距离足够近. 样本点在这个超平面上的投影能尽可能的分开. 2.15.3 PCA算法推理下面以基于最小投影距离为评价指标推理 假设数据集是m个n维, TODO, 且数据进行了中心化. 经过投影变换得到新坐标为TODO, 其中TODO是标准正交基, 即TODO, TODO. 经过降维后, 新坐标为TODO, 其中TODO是降维后的目标维数. 样本点TODO在新坐标系下的投影为TODO, 其中TODO是TODO在低维坐标系里第j维的坐标. 如果用TODO去恢复TODO, 则得到的恢复数据为TODO, 其中TODO为标准正交基组成的矩阵. 考虑到整个样本集, 样本点到这个超平面的距离足够近, 目标变为最小化TODO. 对此式进行推理, 可得 TODO 在推导过程中, 分别用到了TODO, 矩阵转置公式TODO, TODO, TODO以及矩阵的迹, 最后两步是将代数和转为矩阵形式.由于TODO的每一个向量TODO是标准正交基, TODO是数据集的协方差矩阵, TODO是一个常量. 最小化TODO又可等价于 TODO 利用拉格朗日函数可得到TODO 对TODO求导, 可得TODO, 也即TODO. 是TODO个特征向量组成的矩阵, 为TODO的特征值. TODO即为我们想要的矩阵.对于原始数据, 只需要TODO, 就可把原始数据集降维到最小投影距离的TODO维数据集. 基于最大投影方差的推导, 这里就不再赘述, 有兴趣的同仁可自行查阅资料. 2.15.4 PCA算法流程总结输入TODO维样本集TODO, 目标降维的维数TODO. 输出降维后的新样本集TODO. 主要步骤如下 对所有的样本进行中心化, TODO. 计算样本的协方差矩阵TODO. 对协方差矩阵TODO进行特征值分解. 取出最大的TODO个特征值对应的特征向量TODO. 标准化特征向量, 得到特征向量矩阵TODO. 转化样本集中的每个样本TODO. 得到输出矩阵TODO.注在降维时, 有时不明确目标维数, 而是指定降维到的主成分比重阈值TODO. 假设TODO个特征值为TODO, 则TODO可从TODO得到. 2.15.5 PCA算法主要优缺点 优缺点 简要说明 优点 1. 仅仅需要以方差衡量信息量, 不受数据集以外的因素影响. 2.各主成分之间正交, 可消除原始数据成分间的相互影响的因素. 3. 计算方法简单, 主要运算是特征值分解, 易于实现. 缺点 1.主成分各个特征维度的含义具有一定的模糊性, 不如原始样本特征的解释性强. 2. 方差小的非主成分也可能含有对样本差异的重要信息, 因降维丢弃可能对后续数据处理有影响. 2.15.6 降维的必要性及目的降维的必要性 多重共线性—预测变量之间相互关联. 多重共线性会导致解空间的不稳定, 从而可能导致结果的不连贯. 高维空间本身具有稀疏性. 一维正态分布有68%的值落于正负标准差之间, 而在十维空间上只有0.02%. 过多的变量, 对查找规律造成冗余麻烦. 仅在变量层面上分析可能会忽略变量之间的潜在联系. 例如几个预测变量可能落入仅反映数据某一方面特征的一个组内. 降维的目的 减少预测变量的个数. 确保这些变量是相互独立的. 提供一个框架来解释结果. 关特征, 特别是重要特征更能在数据中明确的显示出来; 如果只有两维或者三维的话, 更便于可视化展示. 数据在低维下更容易处理, 更容易使用. 去除数据噪声. 降低算法运算开销. 2.15.7 KPCA与PCA的区别?应用PCA算法的前提是假设存在一个线性的超平面, 进而投影. 那如果数据不是线性的呢? 该怎么办? 这时候就需要KPCA, 数据集从TODO维映射到线性可分的高维TODO, 然后再从TODO维降维到一个低维度TODO. KPCA用到了核函数思想, 使用了核函数的主成分分析一般称为核主成分分析(Kernelized PCA, 简称KPCA). 假设高维空间数据由TODO维空间的数据通过映射TODO产生. TODO维空间的特征分解为 TODO其映射为TODO 通过在高维空间进行协方差矩阵的特征值分解, 然后用和PCA一样的方法进行降维. 由于KPCA需要核函数的运算, 因此它的计算量要比PCA大很多. 2.16 模型评估2.16.1 模型评估常用方法?一般情况来说, 单一评分标准无法完全评估一个机器学习模型. 只用good和bad偏离真实场景去评估某个模型, 都是一种欠妥的评估方式. 下面介绍常用的分类模型和回归模型评估方法. 分类模型常用评估方法 指标 描述 Scikit-learn函数 Precision 精准度 from sklearn.metrics import precision_score Recall 召回率 from sklearn.metrics import recall_score F1 F1值 from sklearn.metrics import f1_score Confusion Matrix 混淆矩阵 from sklearn.metrics import confusion_matrix ROC ROC曲线 from sklearn.metrics import roc AUC ROC曲线下的面积 from sklearn.metrics import auc precision 查准率 recall 查全率 P-R曲线 查准率为纵轴, 查全率为横轴, 作图 回归模型常用评估方法 指标 描述 Scikit-learn函数 Mean Square Error (MSE, RMSE) 平均方差 from sklearn.metrics import mean_squared_error Absolute Error (MAE, RAE) 绝对误差 from sklearn.metrics import mean_absolute_error, median_absolute_error R-Squared R平方值 from sklearn.metrics import r2_score 2.16.2 机器学习中的Bias, Error和Variance有什么区别和联系?(贡献者黄钦建－华南理工大学) Bias(偏差), Error(误差), 和Variance(方差) 对于Bias Bias衡量模型拟合训练数据的能力(训练数据不一定是整个 training dataset, 而是只用于训练它的那一部分数据, 例如mini-batch). Bias 越小, 拟合能力越高(可能产生overfitting); 反之, 拟合能力越低(可能产生underfitting). 对于Variance Variance衡量模型的泛化的能力. Variance越小, 模型的泛化的能力越高; 反之, 模型的泛化的能力越低. 训练误差大, 测试误差小 → Bias大 训练误差小, 测试误差大→ Variance大 → 降VC维 训练误差大, 测试误差大→ 升VC维 2.16.3 经验误差与泛化误差误差(error)一般地, 我们把学习器的实际预测输出与样本的真是输出之间的差异称为“误差” 经验误差(empirical error)也叫训练误差(training error). 模型在训练集上的误差. 泛化误差(generalization error)模型在新样本集(测试集)上的误差称为“泛化误差”. 2.16.4 图解欠拟合, 过拟合根据不同的坐标方式, 欠拟合与过拟合图解不同. 横轴为训练样本数量, 纵轴为误差 如上图所示, 我们可以直观看出欠拟合和过拟合的区别 模型欠拟合在训练集以及测试集上同时具有较高的误差, 此时模型的偏差较大; 模型过拟合在训练集上具有较低的误差, 在测试集上具有较高的误差, 此时模型的方差较大. 模型正常在训练集以及测试集上, 同时具有相对较低的偏差以及方差. 横轴为模型复杂程度, 纵轴为误差 模型欠拟合模型在点A处, 在训练集以及测试集上同时具有较高的误差, 此时模型的偏差较大. 模型过拟合模型在点C处, 在训练集上具有较低的误差, 在测试集上具有较高的误差, 此时模型的方差较大. 模型正常模型复杂程度控制在点B处为最优. 横轴为正则项系数, 纵轴为误差 模型欠拟合模型在点C处, 在训练集以及测试集上同时具有较高的误差, 此时模型的偏差较大. 模型过拟合模型在点A处, 在训练集上具有较低的误差, 在测试集上具有较高的误差, 此时模型的方差较大. 它通常发生在模型过于复杂的情况下, 如参数过多等, 会使得模型的预测性能变弱, 并且增加数据的波动性. 虽然模型在训练时的效果可以表现的很完美, 基本上记住了数据的全部特点, 但这种模型在未知数据的表现能力会大减折扣, 因为简单的模型泛化能力通常都是很弱的. 模型正常模型复杂程度控制在点B处为最优. 2.16.5 如何解决过拟合与欠拟合?如何解决欠拟合 添加其他特征项. 组合, 泛化, 相关性, 上下文特征, 平台特征等特征是特征添加的重要手段, 有时候特征项不够会导致模型欠拟合. 添加多项式特征. 例如将线性模型添加二次项或三次项使模型泛化能力更强. 例如, FM模型, FFM模型, 其实就是线性模型, 增加了二阶多项式, 保证了模型一定的拟合程度. 可以增加模型的复杂程度. 减小正则化系数. 正则化的目的是用来防止过拟合的, 但是现在模型出现了欠拟合, 则需要减少正则化参数. 如何解决过拟合 重新清洗数据, 数据不纯会导致过拟合, 此类情况需要重新清洗数据. 增加训练样本数量. 降低模型复杂程度. 增大正则项系数. 采用dropout方法, dropout方法, 通俗的讲就是在训练的时候让神经元以一定的概率不工作. early stoping. 减少迭代次数. 增大学习率. 添加噪声数据. 树结构中, 可以对树进行剪枝. 欠拟合和过拟合这些方法, 需要根据实际问题, 实际模型, 进行选择. 2.16.6 交叉验证的主要作用?为了得到更为稳健可靠的模型, 对模型的泛化误差进行评估, 得到模型泛化误差的近似值. 当有多个模型可以选择时, 我们通常选择“泛化误差”最小的模型. 交叉验证的方法有许多种, 但是最常用的是留一交叉验证, k折交叉验证 2.16.7 k折交叉验证? 将含有N个样本的数据集, 分成K份, 每份含有N/K个样本. 选择其中1份作为测试集, 另外K-1份作为训练集, 测试集就有K种情况. 在每种情况中, 用训练集训练模型, 用测试集测试模型, 计算模型的泛化误差. 交叉验证重复K次, 每份验证一次, 平均K次的结果或者使用其它结合方式, 最终得到一个单一估测, 得到模型最终的泛化误差. 将K种情况下, 模型的泛化误差取均值, 得到模型最终的泛化误差.注 一般2&lt;=K&lt;=10. k折交叉验证的优势在于, 同时重复运用随机产生的子样本进行训练和验证, 每次的结果验证一次, 10折交叉验证是最常用的. 训练集中样本数量要足够多, 一般至少大于总样本数的50%. 训练集和测试集必须从完整的数据集中均匀取样. 均匀取样的目的是希望减少训练集, 测试集与原数据集之间的偏差. 当样本数量足够多时, 通过随机取样, 便可以实现均匀取样的效果. 2.16.8 混淆矩阵第一种混淆矩阵: 真实情况T or F 预测为正例1, P 预测为负例0, N 本来label标记为1, 预测结果真为T, 假为F TP(预测为1, 实际为1) FN(预测为0, 实际为1) 本来label标记为0, 预测结果真为T, 假为F FP(预测为1, 实际为0) TN(预测为0, 实际也为0) 第二种混淆矩阵: 预测情况P or N 实际label为1,预测对了为T 实际label为0,预测对了为T 预测为正例1, P TP(预测为1, 实际为1) FP(预测为1, 实际为0) 预测为负例0, N FN(预测为0, 实际为1) TN(预测为0, 实际也为0) 2.16.9 错误率及精度 错误率(Error Rate)分类错误的样本数占样本总数的比例. 精度(accuracy)分类正确的样本数占样本总数的比例. 2.16.10 查准率与查全率将算法预测的结果分成四种情况 正确肯定(True Positive,TP)预测为真, 实际为真 正确否定(True Negative,TN)预测为假, 实际为假 错误肯定(False Positive,FP)预测为真, 实际为假 错误否定(False Negative,FN)预测为假, 实际为真 则 查准率(Precision)=TP/(TP+FP) 理解预测出为阳性的样本中, 正确的有多少. 区别准确率(正确预测出的样本, 包括正确预测为阳性, 阴性, 占总样本比例).例, 在所有我们预测有恶性肿瘤的病人中, 实际上有恶性肿瘤的病人的百分比, 越高越好. 查全率(Recall)=TP/(TP+FN) 理解正确预测为阳性的数量占总样本中阳性数量的比例.例, 在所有实际上有恶性肿瘤的病人中, 成功预测有恶性肿瘤的病人的百分比, 越高越好. 2.16.11 ROC与AUCROC全称是“受试者工作特征”(Receiver Operating Characteristic). ROC曲线的面积就是AUC(Area Under the Curve). AUC用于衡量“二分类问题”机器学习算法性能(泛化能力). ROC曲线, 通过将连续变量设定出多个不同的临界值, 从而计算出一系列真正率和假正率, 再以假正率为纵坐标, 真正率为横坐标绘制成曲线, 曲线下面积越大, 诊断准确性越高. 在ROC曲线上, 最靠近坐标图左上方的点为假正率和真正率均较高的临界值. 对于分类器, 或者说分类算法, 评价指标主要有precision, recall, F-score. 下图是一个ROC曲线的示例. ROC曲线的横坐标为false positive rate(FPR), 纵坐标为true positive rate(TPR). 其中TODO, TODO,下面着重介绍ROC曲线图中的四个点和一条线.第一个点, (0,1), 即FPR=0, TPR=1, 这意味着FN(false negative)=0, 并且FP(false positive)=0. 意味着这是一个完美的分类器, 它将所有的样本都正确分类.第二个点, (1,0), 即FPR=1, TPR=0, 意味着这是一个最糟糕的分类器, 因为它成功避开了所有的正确答案.第三个点, (0,0), 即FPR=TPR=0, 即FP(false positive)=TP(true positive)=0, 可以发现该分类器预测所有的样本都为负样本(negative).第四个点, (1,1), 即FPR=TPR=1, 分类器实际上预测所有的样本都为正样本.经过以上分析, ROC曲线越接近左上角, 该分类器的性能越好. ROC曲线所覆盖的面积称为AUC(Area Under Curve), 可以更直观的判断学习器的性能, AUC越大则性能越好. 2.16.12 如何画ROC曲线?http://blog.csdn.net/zdy0_2004/article/details/44948511下图是一个示例, 图中共有20个测试样本, “Class”一栏表示每个测试样本真正的标签(p表示正样本, n表示负样本), “Score”表示每个测试样本属于正样本的概率. 步骤 1, 假设已经得出一系列样本被划分为正类的概率, 按照大小排序.2, 从高到低, 依次将“Score”值作为阈值threshold, 当测试样本属于正样本的概率大于或等于这个threshold时, 我们认为它为正样本, 否则为负样本. 举例来说, 对于图中的第4个样本, 其“Score”值为0.6, 那么样本1, 2, 3, 4都被认为是正样本, 因为它们的“Score”值都大于等于0.6, 而其他样本则都认为是负样本.3, 每次选取一个不同的threshold, 得到一组FPR和TPR, 即ROC曲线上的一点. 以此共得到20组FPR和TPR的值. 其中FPR和TPR简单理解如下 4, 根据3)中的每个坐标点点, 画图. 2.16.13 如何计算TPR, FPR?1, 分析数据y_true = [0, 0, 1, 1];scores = [0.1, 0.4, 0.35, 0.8];2, 列表样本 预测属于P的概率(score) 真实类别y[0] 0.1 Ny[2] 0.35 Py[1] 0.4 Ny[3] 0.8 P3, 将截断点依次取为score值, 计算TPR和FPR.当截断点为0.1时 说明只要score&gt;=0.1, 它的预测类别就是正例. 因为4个样本的score都大于等于0.1, 所以, 所有样本的预测类别都为P.scores = [0.1, 0.4, 0.35, 0.8];y_true = [0, 0, 1, 1];y_pred = [1, 1, 1, 1];正例与反例信息如下 真实值 预测值​ 正例 反例正例 TP=2 FN=0反例 FP=2 TN=0由此可得 TPR = TP/(TP+FN) = 1;FPR = FP/(TN+FP) = 1; 当截断点为0.35时 scores = [0.1, 0.4, 0.35, 0.8]y_true = [0, 0, 1, 1]y_pred = [0, 1, 1, 1]正例与反例信息如下 真实值 预测值​ 正例 反例正例 TP=2 FN=0反例 FP=1 TN=1由此可得 TPR = TP/(TP+FN) = 1;FPR = FP/(TN+FP) = 0.5; 当截断点为0.4时 scores = [0.1, 0.4, 0.35, 0.8];y_true = [0, 0, 1, 1];y_pred = [0, 1, 0, 1];正例与反例信息如下 真实值 预测值​ 正例 反例正例 TP=1 FN=1反例 FP=1 TN=1由此可得 TPR = TP/(TP+FN) = 0.5;FPR = FP/(TN+FP) = 0.5; 当截断点为0.8时 scores = [0.1, 0.4, 0.35, 0.8];y_true = [0, 0, 1, 1];y_pred = [0, 0, 0, 1];正例与反例信息如下 真实值 预测值​ 正例 反例正例 TP=1 FN=1反例 FP=0 TN=2由此可得 TPR = TP/(TP+FN) = 0.5;FPR = FP/(TN+FP) = 0;4, 根据TPR, FPR值, 以FPR为横轴, TPR为纵轴画图. 2.16.14 如何计算Auc?a.将坐标点按照横着FPR排序b.计算第i个坐标点和第i+1个坐标点的间距 dx;c.获取第i(或者i+1)个坐标点的纵坐标y;d.计算面积微元ds = ydx;e.对面积微元进行累加, 得到AUC. 2.16.15 为什么使用Roc和Auc评价分类器?模型有很多评估方法, 为什么还要使用ROC和AUC呢?因为ROC曲线有个很好的特性当测试集中的正负样本的分布变换的时候, ROC曲线能够保持不变. 在实际的数据集中经常会出现样本类不平衡, 即正负样本比例差距较大, 而且测试数据中的正负样本也可能随着时间变化. 2.16.17 直观理解AUChttp://blog.csdn.net/cherrylvlei/article/details/52958720AUC是ROC右下方的曲线面积. 下图展现了三种AUC的值 AUC是衡量二分类模型优劣的一种评价指标, 表示正例排在负例前面的概率. 其他评价指标有精确度, 准确率, 召回率, 而AUC比这三者更为常用.因为一般在分类模型中, 预测结果都是以概率的形式表现, 如果要计算准确率, 通常都会手动设置一个阈值来将对应的概率转化成类别, 这个阈值也就很大程度上影响了模型准确率的计算.我们不妨举一个极端的例子一个二类分类问题一共10个样本, 其中9个样本为正例, 1个样本为负例, 在全部判正的情况下准确率将高达90%, 而这并不是我们希望的结果, 尤其是在这个负例样本得分还是最高的情况下, 模型的性能本应极差, 从准确率上看却适得其反. 而AUC能很好描述模型整体性能的高低. 这种情况下, 模型的AUC值将等于0(当然, 通过取反可以解决小于50%的情况, 不过这是另一回事了). 2.16.18 代价敏感错误率与代价曲线http://blog.csdn.net/cug_lzt/article/details/78295140 不同的错误会产生不同代价.以二分法为例, 设置代价矩阵如下 当判断正确的时候, 值为0, 不正确的时候, 分别为$Cost_{01}$和$Cost_{10}$ . $Cost_{10}$:表示实际为反例但预测成正例的代价. $Cost_{01}$:表示实际为正例但是预测为反例的代价. 代价敏感错误率 $\frac{样本中由模型得到的错误值与代价乘积之和}{总样本}$ 其数学表达式为 $D^{+}, D^{-}$分别代表样例集 的正例子集和反例子集. 代价曲线 在均等代价时, ROC曲线不能直接反应出模型的期望总体代价, 而代价曲线可以.代价曲线横轴为[0,1]的正例函数代价 $P(+)Cost=\frac{pCost_{01}}{pCost_{01}+(1-p)\times Cost_{10}}$ 其中p是样本为正例的概率. 代价曲线纵轴维[0,1]的归一化代价 $Cost_{norm}=\frac{FNRpCost_{01}+FNR\times (1-p)\times Cost_{10}}{p\times Cost_{01}+(1-p)\times Cost_{10}}$ 其中FPR为假正例率, FNR=1-TPR为假反利率. 注ROC每个点, 对应代价平面上一条线. 例如, ROC上(TPR,FPR),计算出FNR=1-TPR, 在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段, 面积则为该条件下期望的总体代价. 所有线段下界面积, 所有条件下学习器的期望总体代价. 2.16.19 模型有哪些比较检验方法http://wenwen.sogou.com/z/q721171854.htm正确性分析模型稳定性分析, 稳健性分析, 收敛性分析, 变化趋势分析, 极值分析等.有效性分析误差分析, 参数敏感性分析, 模型对比检验等.有用性分析关键数据求解, 极值点, 拐点, 变化趋势分析, 用数据验证动态模拟等.高效性分析时空复杂度分析与现有进行比较等. 2.16.20 偏差与方差http://blog.csdn.net/zhihua_oba/article/details/78684257 方差公式为 S_{N}^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}泛化误差可分解为偏差, 方差与噪声之和, 即generalization error=bias+variance+noise. 噪声描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界, 即刻画了学习问题本身的难度.假定期望噪声为零, 则泛化误差可分解为偏差, 方差之和, 即generalization error=bias+variance. 偏差(bias)描述的是预测值(估计值)的期望与真实值之间的差距. 偏差越大, 越偏离真实数据, 如下图第二行所示. 方差(variance)描述的是预测值的变化范围, 离散程度, 也就是离其期望值的距离. 方差越大, 数据的分布越分散, 模型的稳定程度越差. 如果模型在训练集上拟合效果比较优秀, 但是在测试集上拟合效果比较差劣, 则方差较大, 说明模型的稳定程度较差, 出现这种现象可能是由于模型对训练集过拟合造成的. 如下图右列所示. 简单的总结一下 偏差大, 会造成模型欠拟合;方差大, 会造成模型过拟合. 2.16.21为什么使用标准差?标准差公式为$S_{N}=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}$ 样本标准差公式为$S_{N}=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}$ 与方差相比, 使用标准差来表示数据点的离散程度有3个好处 1, 表示离散程度的数字与样本数据点的数量级一致, 更适合对数据样本形成感性认知. 2, 表示离散程度的数字单位与样本数据的单位一致, 更方便做后续的分析运算. 3, 在样本数据大致符合正态分布的情况下, 标准差具有方便估算的特性66.7%的数据点落在平均值前后1个标准差的范围内, 95%的数据点落在平均值前后2个标准差的范围内, 而99%的数据点将会落在平均值前后3个标准差的范围内. 2.16.22点估计思想点估计用实际样本的一个指标来估计总体的一个指标的一种估计方法. 点估计举例比如说, 我们想要了解中国人的平均身高, 那么在大街上随便找了一个人, 通过测量这个人的身高来估计中国人的平均身高水平; 或者在淘宝上买东西的时候随便一次买到假货就说淘宝上都是假货等; 这些都属于点估计. 点估计主要思想在样本数据中得到一个指标, 通过这个指标来估计总体指标; 比如我们用样本均数来估计总体均数, 样本均数就是我们要找到的指标. 2.16.23 点估计优良性原则?获取样本均数指标相对来说比较简单, 但是并不是总体的所有指标都很容易在样本中得到, 比如说总体的标准差用样本的哪个指标来估计呢? 优良性准则有两大类一类是小样本准则, 即在样本大小固定时的优良性准则; 另一类是大样本准则, 即在样本大小趋于无穷时的优良性准则. 最重要的小样本优良性准则是无偏性及与此相关的一致最小方差无偏计. 样本中用来估计总体的指标要符合以下规则 1.首先必须是无偏统计量.所谓无偏性, 即数学期望等于总体相应的统计量的样本估计量. 2.最小方差准则针对总体样本的无偏估计量不唯一的情况, 需选用其他准则, 例如最小方差准则. 如果一个统计量具有最小方差, 也就是说所有的样本点与此统计量的离差平方和最小, 则这个统计量被称为最小平方无偏估计量.最大概率准则 4, 缺一交叉准则在非参数回归中好像用的是缺一交叉准则 要明白一个原则计算样本的任何分布, 均数, 标准差都是没有任何意义的, 如果样本的这种计算不能反映总体的某种特性. 2.16.24 点估计, 区间估计, 中心极限定理之间的联系?https://www.zhihu.com/question/21871331#answer-4090464点估计是用样本统计量来估计总体参数, 因为样本统计量为数轴上某一点值, 估计的结果也以一个点的数值表示, 所以称为点估计. 区间估计通过从总体中抽取的样本, 根据一定的正确度与精确度的要求, 构造出适当的区间, 以作为总体的分布参数(或参数的函数)的真值所在范围的估计.中心极限定理设从均值为, 方差为;(有限)的任意一个总体中抽取样本量为n的样本, 当n充分大时, 样本均值的抽样分布近似服从均值为, 方差为的正态分布. 三者之间联系 1, 中心极限定理是推断统计的理论基础, 推断统计包括参数估计和假设检验, 其中参数估计包括点估计和区间估计, 所以说, 中心极限定理也是点估计和区间估计的理论基础. 2, 参数估计有两种方法点估计和区间估计, 区间估计包含了点估计. 相同点都是基于一个样本作出; 不同点点估计只提供单一的估计值, 而区间估计基于点估计还提供误差界限, 给出了置信区间, 受置信度的影响. 2.16.25 类别不平衡产生原因?类别不平衡(class-imbalance)是指分类任务中不同类别的训练样例数目差别很大的情况. 产生原因 通常分类学习算法都会假设不同类别的训练样例数目基本相同. 如果不同类别的训练样例数目差别很大, 则会影响学习结果, 测试结果变差. 例如二分类问题中有998个反例, 正例有2个, 那学习方法只需返回一个永远将新样本预测为反例的分类器, 就能达到99.8%的精度; 然而这样的分类器没有价值. 2.16.26 常见的类别不平衡问题解决方法http://blog.csdn.net/u013829973/article/details/77675147 防止类别不平衡对学习造成的影响, 在构建分类模型之前, 需要对分类不平衡性问题进行处理. 主要解决方法有 1, 扩大数据集 增加包含小类样本数据的数据, 更多的数据能得到更多的分布信息. 2, 对大类数据欠采样 减少大类数据样本个数, 使与小样本个数接近.缺点欠采样操作时若随机丢弃大类样本, 可能会丢失重要信息.代表算法EasyEnsemble. 利用集成学习机制, 将大类划分为若干个集合供不同的学习器使用. 相当于对每个学习器都进行了欠采样, 但在全局来看却不会丢失重要信息. 3, 对小类数据过采样 过采样对小类的数据样本进行采样来增加小类的数据样本个数. 代表算法SMOTE和ADASYN. SMOTE通过对训练集中的小类数据进行插值来产生额外的小类样本数据. 新的少数类样本产生的策略对每个少数类样本a, 在a的最近邻中随机选一个样本b, 然后在a, b之间的连线上随机选一点作为新合成的少数类样本.ADASYN根据学习难度的不同, 对不同的少数类别的样本使用加权分布, 对于难以学习的少数类的样本, 产生更多的综合数据. 通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段, 改善了数据分布. 4, 使用新评价指标 如果当前评价指标不适用, 则应寻找其他具有说服力的评价指标. 比如准确度这个评价指标在类别不均衡的分类任务中并不适用, 甚至进行误导. 因此在类别不均衡分类任务中, 需要使用更有说服力的评价指标来对分类器进行评价. 5, 选择新算法 不同的算法适用于不同的任务与数据, 应该使用不同的算法进行比较. 6, 数据代价加权 例如当分类任务是识别小类, 那么可以对分类器的小类样本数据增加权值, 降低大类样本的权值, 从而使得分类器将重点集中在小类样本身上. 7, 转化问题思考角度 例如在分类问题时, 把小类的样本作为异常点, 将问题转化为异常点检测或变化趋势检测问题. 异常点检测即是对那些罕见事件进行识别. 变化趋势检测区别于异常点检测在于其通过检测不寻常的变化趋势来识别. 8, 将问题细化分析 对问题进行分析与挖掘, 将问题划分成多个更小的问题, 看这些小问题是否更容易解决. 2.17 决策树2.17.1 决策树的基本原理决策树是一种分而治之(Divide and Conquer)的决策过程. 一个困难的预测问题, 通过树的分支节点, 被划分成两个或多个较为简单的子集, 从结构上划分为不同的子问题. 将依规则分割数据集的过程不断递归下去(Recursive Partitioning). 随着树的深度不断增加, 分支节点的子集越来越小, 所需要提的问题数也逐渐简化. 当分支节点的深度或者问题的简单程度满足一定的停止规则(Stopping Rule)时, 该分支节点会停止劈分, 此为自上而下的停止阈值(Cutoff Threshold)法; 有些决策树也使用自下而上的剪枝(Pruning)法. 2.17.2 决策树的三要素?一棵决策树的生成过程主要分为以下3个部分: 特征选择从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准, 如何选择特征有着很多不同量化评估标准标准, 从而衍生出不同的决策树算法. 决策树生成根据选择的特征评估标准, 从上至下递归地生成子节点, 直到数据集不可分则停止决策树停止生长. 树结构来说, 递归结构是最容易理解的方式. 剪枝决策树容易过拟合, 一般来需要剪枝, 缩小树结构规模, 缓解过拟合. 剪枝技术有预剪枝和后剪枝两种. 2.17.3 决策树学习基本算法 2.17.4 决策树算法优缺点决策树算法的优点 1, 理解和解释起来简单, 决策树模型易想象. 2, 相比于其他算法需要大量数据集而已, 决策树算法要求的数据集不大. 3, 决策树算法的时间复杂度较小, 为用于训练决策树的数据点的对数. 4, 相比于其他算法智能分析一种类型变量, 决策树算法可处理数字和数据的类别. 5, 能够处理多输出的问题. 6, 对缺失值不敏感. 7, 可以处理不相关特征数据. 8, 效率高, 决策树只需要一次构建, 反复使用, 每一次预测的最大计算次数不超过决策树的深度. 决策树算法的缺点 1, 对连续性的字段比较难预测. 2, 容易出现过拟合. 3, 当类别太多时, 错误可能就会增加的比较快. 4, 信息缺失时处理起来比较困难, 忽略了数据集中属性之间的相关性. 5, 在处理特征关联性比较强的数据时表现得不是太好. 6, 对于各类别样本数量不一致的数据, 在决策树当中,信息增益的结果偏向于那些具有更多数值的特征. 2.17.5熵的概念以及理解熵度量随机变量的不确定性. 定义假设随机变量X的可能取值有$x_{1},x_{2},…,x_{n}$, 对于每一个可能的取值$x_{i}$, 其概率为$P(X=x_{i})=p_{i},i=1,2…,n$. 随机变量的熵为 $H(X)=-\sum_{i=1}^{n}p_{i}log_{2}p_{i}$ 对于样本集合 , 假设样本有k个类别, 每个类别的概率为$\frac{|C_{k}|}{|D|}$,其中 ${|C_{k}|}{|D|}$为类别为k的样本个数,$|D|$为样本总数. 样本集合D的熵为 $H(D)=-\sum_{k=1}^{k}\frac{|C_{k}|}{|D|}log_{2}\frac{|C_{k}|}{|D|}$ 2.17.6 信息增益的理解定义以某特征划分数据集前后的熵的差值.熵可以表示样本集合的不确定性, 熵越大, 样本的不确定性就越大. 因此可以使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏.假设划分前样本集合D的熵为H(D). 使用某个特征A划分数据集D, 计算划分后的数据子集的熵为H(D|A). 则信息增益为 $g(D,A)=H(D)-H(D|A)$ 注在决策树构建的过程中我们总是希望集合往最快到达纯度更高的子集合方向发展, 因此我们总是选择使得信息增益最大的特征来划分当前数据集D. 思想计算所有特征划分数据集D, 得到多个特征划分数据集D的信息增益, 从这些信息增益中选择最大的, 因而当前结点的划分特征便是使信息增益最大的划分所使用的特征. 另外这里提一下信息增益比相关知识 信息增益比=惩罚参数X信息增益. 信息增益比本质在信息增益的基础之上乘上一个惩罚参数. 特征个数较多时, 惩罚参数较小; 特征个数较少时, 惩罚参数较大. 惩罚参数数据集D以特征A作为随机变量的熵的倒数. 2.17.7 剪枝处理的作用及策略?剪枝处理是决策树学习算法用来解决过拟合的一种办法. 在决策树算法中, 为了尽可能正确分类训练样本, 节点划分过程不断重复, 有时候会造成决策树分支过多, 以至于将训练样本集自身特点当作泛化特点, 而导致过拟合. 因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险. 剪枝的基本策略有预剪枝(prepruning)和后剪枝(postprunint). 预剪枝在决策树生成过程中, 在每个节点划分前先估计其划分后的泛化性能, 如果不能提升, 则停止划分, 将当前节点标记为叶结点. 后剪枝生成决策树以后, 再自下而上对非叶结点进行考察, 若将此节点标记为叶结点可以带来泛化性能提升, 则修改之. 2.18 支持向量机2.18.1 什么是支持向量机SVM - Support Vector Machine. 支持向量机, 其含义是通过支持向量运算的分类器. 其中“机”的意思是机器, 可以理解为分类器. 什么是支持向量呢? 在求解的过程中, 会发现只根据部分数据就可以确定分类器, 这些数据称为支持向量. 见下图, 在一个二维环境中, 其中点R, S, G点和其它靠近中间黑线的点可以看作为支持向量, 它们可以决定分类器, 也就是黑线的具体参数. 2.18.2 支持向量机解决的问题?https://www.cnblogs.com/steven-yang/p/5658362.html解决的问题 线性分类 在训练数据中, 每个数据都有n个的属性和一个二类类别标志, 我们可以认为这些数据在一个n维空间里. 我们的目标是找到一个n-1维的超平面(hyperplane), 这个超平面可以将数据分成两部分, 每部分数据都属于同一个类别. 其实这样的超平面有很多, 我们要找到一个最佳的. 因此, 增加一个约束条件这个超平面到每边最近数据点的距离是最大的. 也成为最大间隔超平面(maximum-margin hyperplane). 这个分类器也成为最大间隔分类器(maximum-margin classifier). 支持向量机是一个二类分类器. 非线性分类 SVM的一个优势是支持非线性分类. 它结合使用拉格朗日乘子法和KKT条件, 以及核函数可以产生非线性分类器. 分类器1 - 线性分类器 是一个线性函数, 可以用于线性分类. 一个优势是不需要样本数据. classifier 1:f(x)=xwT+b(1)(1)f(x)=xwT+b ww 和 bb 是训练数据后产生的值. 分类器2 - 非线性分类器 支持线性分类和非线性分类. 需要部分样本数据(支持向量), 也就是$\alpha_i \ne 0$ 的数据. w=∑ni=1αiyixiw=∑i=1nαiyixiclassifier 2: f(x)=∑ni=1αiyiK(xi,x)+bherexi : training data iyi : label value of training data iαi : Lagrange multiplier of training data iK(x1,x2)=exp(−∥x1−x2∥22σ2) : kernel function(2)(2)f(x)=∑i=1nαiyiK(xi,x)+bherexi : training data iyi : label value of training data iαi : Lagrange multiplier of training data iK(x1,x2)=exp(−‖x1−x2‖22σ2) : kernel function αα, σσ 和 bb 是训练数据后产生的值.可以通过调节σσ来匹配维度的大小, σσ越大, 维度越低. 2.18.3 核函数作用?核函数目的把原坐标系里线性不可分的数据用Kernel投影到另一个空间, 尽量使得数据在新的空间里线性可分. 核函数方法的广泛应用,与其特点是分不开的 1)核函数的引入避免了“维数灾难”,大大减小了计算量. 而输入空间的维数n对核函数矩阵无影响, 因此, 核函数方法可以有效处理高维输入. 2)无需知道非线性变换函数Φ的形式和参数. 3)核函数的形式和参数的变化会隐式地改变从输入空间到特征空间的映射, 进而对特征空间的性质产生影响, 最终改变各种核函数方法的性能. 4)核函数方法可以和不同的算法相结合, 形成多种不同的基于核函数技术的方法, 且这两部分的设计可以单独进行, 并可以为不同的应用选择不同的核函数和算法. 2.18.4 对偶问题2.18.5 理解支持向量回归http://blog.csdn.net/liyaohhh/article/details/51077082 2.18.6 理解SVM(核函数)http://blog.csdn.net/Love_wanling/article/details/69390047 2.18.7 常见的核函数有哪些?http://blog.csdn.net/Love_wanling/article/details/69390047 本文将遇到的核函数进行收集整理, 分享给大家.http://blog.csdn.net/wsj998689aa/article/details/47027365 1.Linear Kernel线性核是最简单的核函数, 核函数的数学公式如下 $k(x,y)=xy$ 如果我们将线性核函数应用在KPCA中, 我们会发现, 推导之后和原始PCA算法一模一样, 很多童鞋借此说“kernel is shit！！！”, 这是不对的, 这只是线性核函数偶尔会出现等价的形式罢了. 2.Polynomial Kernel 多项式核实一种非标准核函数, 它非常适合于正交归一化后的数据, 其具体形式如下 $k(x,y)=(ax^{t}y+c)^{d}$ 这个核函数是比较好用的, 就是参数比较多, 但是还算稳定. 3.Gaussian Kernel 这里说一种经典的鲁棒径向基核, 即高斯核函数, 鲁棒径向基核对于数据中的噪音有着较好的抗干扰能力, 其参数决定了函数作用范围, 超过了这个范围, 数据的作用就“基本消失”. 高斯核函数是这一族核函数的优秀代表, 也是必须尝试的核函数, 其数学形式如下 $k(x,y)=exp(-\frac{\left | x-y \right |^{2}}{2\sigma ^{2}})$ 虽然被广泛使用, 但是这个核函数的性能对参数十分敏感, 以至于有一大把的文献专门对这种核函数展开研究, 同样, 高斯核函数也有了很多的变种, 如指数核, 拉普拉斯核等. 4.Exponential Kernel 指数核函数就是高斯核函数的变种, 它仅仅是将向量之间的L2距离调整为L1距离, 这样改动会对参数的依赖性降低, 但是适用范围相对狭窄. 其数学形式如下 $k(x,y)=exp(-\frac{\left | x-y \right |}{2\sigma ^{2}})$ 5.Laplacian Kernel 拉普拉斯核完全等价于指数核, 唯一的区别在于前者对参数的敏感性降低, 也是一种径向基核函数. $k(x,y)=exp(-\frac{\left | x-y \right |}{\sigma })$ 6.ANOVA Kernel ANOVA 核也属于径向基核函数一族, 其适用于多维回归问题, 数学形式如下 $k(x,y)=exp(-\sigma(x^{k}-y^{k})^{2})^{d}$ 7.Sigmoid Kernel Sigmoid 核来源于神经网络, 现在已经大量应用于深度学习, 是当今机器学习的宠儿, 它是S型的, 所以被用作于“激活函数”. 关于这个函数的性质可以说好几篇文献, 大家可以随便找一篇深度学习的文章看看. $k(x,y)=tanh(ax^{t}y+c)$ 8.Rational Quadratic Kernel二次有理核完完全全是作为高斯核的替代品出现, 如果你觉得高斯核函数很耗时, 那么不妨尝试一下这个核函数, 顺便说一下, 这个核函数作用域虽广, 但是对参数十分敏感, 慎用！！！！ $k(x,y)=1-\frac{\left | x-y \right |^{2}}{\left | x-y \right |^{2}+c}$ 2.18.8 软间隔与正则化2.18.9 SVM主要特点及缺点?http://www.elecfans.com/emb/fpga/20171118582139_2.html 3.3.2.1 SVM有如下主要几个特点 (1)非线性映射是SVM方法的理论基础,SVM利用内积核函数代替向高维空间的非线性映射;(2)对特征空间划分的最优超平面是SVM的目标,最大化分类边际的思想是SVM方法的核心;(3)支持向量是SVM的训练结果,在SVM分类决策中起决定作用的是支持向量.(4)SVM 是一种有坚实理论基础的新颖的小样本学习方法. 它基本上不涉及概率测度及大数定律等,因此不同于现有的统计方法. 从本质上看,它避开了从归纳到演绎的传统过程,实现了高效的从训练样本到预报样本的“转导推理”,大大简化了通常的分类和回归等问题.(5)SVM 的最终决策函数只由少数的支持向量所确定,计算的复杂性取决于支持向量的数目,而不是样本空间的维数,这在某种意义上避免了“维数灾难”.(6)少数支持向量决定了最终结果,这不但可以帮助我们抓住关键样本, “剔除”大量冗余样本,而且注定了该方法不但算法简单,而且具有较好的“鲁棒”性. 这种“鲁棒”性主要体现在:①增, 删非支持向量样本对模型没有影响;②支持向量样本集具有一定的鲁棒性;③有些成功的应用中,SVM 方法对核的选取不敏感 3.3.2.2 SVM的两个不足 (1) SVM算法对大规模训练样本难以实施由 于SVM是借助二次规划来求解支持向量, 而求解二次规划将涉及m阶矩阵的计算(m为样本的个数), 当m数目很大时该矩阵的存储和计算将耗费大量的机器内存 和运算时间. 针对以上问题的主要改进有有J.Platt的SMO算法, T.Joachims的SVM, C.J.C.Burges等的PCGC, 张学工的 CSVM以及O.L.Mangasarian等的SOR算法.(2) 用SVM解决多分类问题存在困难经典的支持向量机算法只给出了二类分类的算法, 而在数据挖掘的实际应用中, 一般要解决多类的分类问题. 可以通过多个二类支持向量机的组合来解决. 主要有一对多组合模式, 一对一组合模式和SVM决策树; 再就是通过构造多个分类器的组合来解决. 主要原理是克服SVM固有的缺点, 结合其他算法的优势, 解决多类问题的分类精度. 如与粗集理论结合, 形成一种优势互补的多类问题的组合分类器. 2.19 贝叶斯2.19.1 图解极大似然估计极大似然估计 http://blog.csdn.net/zengxiantao1994/article/details/72787849 极大似然估计的原理, 用一张图片来说明, 如下图所示 总结起来, 最大似然估计的目的就是利用已知的样本结果, 反推最有可能(最大概率)导致这样结果的参数值. 原理极大似然估计是建立在极大似然原理的基础上的一个统计方法, 是概率论在统计学中的应用. 极大似然估计提供了一种给定观察数据来评估模型参数的方法, 即“模型已定, 参数未知”. 通过若干次试验, 观察其结果, 利用试验结果得到某个参数值能够使样本出现的概率为最大, 则称为极大似然估计. 由于样本集中的样本都是独立同分布, 可以只考虑一类样本集D, 来估计参数向量θ. 记已知的样本集为 $D=x_{1},x_{2},…,x_{n}$ 似然函数(linkehood function)联合概率密度函数$P(D|\theta )$称为相对于$x_{1},x_{2},…,x_{n}$的θ的似然函数. $l(\theta )=p(D|\theta ) =p(x_{1},x_{2},…,x_{N}|\theta )=\prod_{i=1}^{N}p(x_{i}|\theta )$ 如果$\hat{\theta}$是参数空间中能使似然函数$l(\theta)$最大的θ值, 则$\hat{\theta}$应该是“最可能”的参数值, 那么$\hat{\theta}$就是θ的极大似然估计量. 它是样本集的函数, 记作 $\hat{\theta}=d(x_{1},x_{2},…,x_{N})=d(D)$ $\hat{\theta}(x_{1},x_{2},…,x_{N})$称为极大似然函数估计值. 2.19.2 朴素贝叶斯分类器和一般的贝叶斯分类器有什么区别?2.19.3 朴素与半朴素贝叶斯分类器2.19.4 贝叶斯网三种典型结构2.19.5 什么是贝叶斯错误率2.19.6 什么是贝叶斯最优错误率2.20 EM算法解决问题及实现流程1.EM算法要解决的问题 我们经常会从样本观察数据中, 找出样本的模型参数. 最常用的方法就是极大化模型分布的对数似然函数. 但是在一些情况下, 我们得到的观察数据有未观察到的隐含数据, 此时我们未知的有隐含数据和模型参数, 因而无法直接用极大化对数似然函数得到模型分布的参数. 怎么办呢? 这就是EM算法可以派上用场的地方了. EM算法解决这个的思路是使用启发式的迭代方法, 既然我们无法直接求出模型分布参数, 那么我们可以先猜想隐含数据(EM算法的E步), 接着基于观察数据和猜测的隐含数据一起来极大化对数似然, 求解我们的模型参数(EM算法的M步). 由于我们之前的隐藏数据是猜测的, 所以此时得到的模型参数一般还不是我们想要的结果. 不过没关系, 我们基于当前得到的模型参数, 继续猜测隐含数据(EM算法的E步), 然后继续极大化对数似然, 求解我们的模型参数(EM算法的M步). 以此类推, 不断的迭代下去, 直到模型分布参数基本无变化, 算法收敛, 找到合适的模型参数. 从上面的描述可以看出, EM算法是迭代求解最大值的算法, 同时算法在每一次迭代时分为两步, E步和M步. 一轮轮迭代更新隐含数据和模型分布参数, 直到收敛, 即得到我们需要的模型参数. 一个最直观了解EM算法思路的是K-Means算法, 见之前写的K-Means聚类算法原理. 在K-Means聚类时, 每个聚类簇的质心是隐含数据. 我们会假设KK个初始化质心, 即EM算法的E步; 然后计算得到每个样本最近的质心, 并把样本聚类到最近的这个质心, 即EM算法的M步. 重复这个E步和M步, 直到质心不再变化为止, 这样就完成了K-Means聚类. 当然, K-Means算法是比较简单的, 实际中的问题往往没有这么简单. 上面对EM算法的描述还很粗糙, 我们需要用数学的语言精准描述. 2.EM算法流程 现在我们总结下EM算法的流程. 输入观察数据x=(x(1),x(2),…x(m))x=(x(1),x(2),…x(m)), 联合分布p(x,z|θ)p(x,z|θ), 条件分布p(z|x,θ)p(z|x,θ), 最大迭代次数JJ. 1) 随机初始化模型参数θθ的初值θ0θ0. 2) for j from 1 to J开始EM算法迭代 a) E步计算联合分布的条件概率期望 Qi(z(i))=P(z(i)|x(i), θj))Qi(z(i))=P(z(i)|x(i), θj))L(θ,θj)=∑i=1m∑z(i)Qi(z(i))logP(x(i), z(i)|θ)L(θ,θj)=∑i=1m∑z(i)Qi(z(i))logP(x(i), z(i)|θ) b) M步极大化L(θ,θj)L(θ,θj),得到θj+1θj+1:θj+1=argmaxθL(θ,θj)θj+1=argmaxθL(θ,θj) c) 如果θj+1θj+1已收敛, 则算法结束. 否则继续回到步骤a)进行E步迭代. 输出模型参数θθ. 2.21 降维和聚类2.21.1 为什么会产生维数灾难?http://blog.csdn.net/chenjianbo88/article/details/52382943 假设地球上猫和狗的数量是无限的. 由于有限的时间和计算能力, 我们仅仅选取了10张照片作为训练样本. 我们的目的是基于这10张照片来训练一个线性分类器, 使得这个线性分类器可以对剩余的猫或狗的照片进行正确分类. 我们从只用一个特征来辨别猫和狗开始 从图2可以看到, 如果仅仅只有一个特征的话, 猫和狗几乎是均匀分布在这条线段上, 很难将10张照片线性分类. 那么, 增加一个特征后的情况会怎么样 增加一个特征后, 我们发现仍然无法找到一条直线将猫和狗分开. 所以, 考虑需要再增加一个特征 此时, 我们终于找到了一个平面将猫和狗分开. 需要注意的是, 只有一个特征时, 假设特征空间是长度为5的线段, 则样本密度是10/5=2. 有两个特征时, 特征空间大小是55=25, 样本密度是10/25=0.4. 有三个特征时, 特征空间大小是55*5=125, 样本密度是10/125=0.08. 如果继续增加特征数量, 样本密度会更加稀疏, 也就更容易找到一个超平面将训练样本分开. 因为随着特征数量趋向于无限大, 样本密度非常稀疏, 训练样本被分错的可能性趋向于零. 当我们将高维空间的分类结果映射到低维空间时, 一个严重的问题出现了 从图5可以看到将三维特征空间映射到二维特征空间后的结果. 尽管在高维特征空间时训练样本线性可分, 但是映射到低维空间后, 结果正好相反. 事实上, 增加特征数量使得高维空间线性可分, 相当于在低维空间内训练一个复杂的非线性分类器. 不过, 这个非线性分类器太过“聪明”, 仅仅学到了一些特例. 如果将其用来辨别那些未曾出现在训练样本中的测试样本时, 通常结果不太理想. 这其实就是我们在机器学习中学过的过拟合问题. 尽管图6所示的只采用2个特征的线性分类器分错了一些训练样本, 准确率似乎没有图4的高, 但是, 采用2个特征的线性分类器的泛化能力比采用3个特征的线性分类器要强. 因为, 采用2个特征的线性分类器学习到的不只是特例, 而是一个整体趋势, 对于那些未曾出现过的样本也可以比较好地辨别开来. 换句话说, 通过减少特征数量, 可以避免出现过拟合问题, 从而避免“维数灾难”. 图7从另一个角度诠释了“维数灾难”. 假设只有一个特征时, 特征的值域是0到1, 每一只猫和狗的特征值都是唯一的. 如果我们希望训练样本覆盖特征值值域的20%, 那么就需要猫和狗总数的20%. 我们增加一个特征后, 为了继续覆盖特征值值域的20%就需要猫和狗总数的45%(0.45^2=0.2). 继续增加一个特征后, 需要猫和狗总数的58%(0.58^3=0.2). 随着特征数量的增加, 为了覆盖特征值值域的20%, 就需要更多的训练样本. 如果没有足够的训练样本, 就可能会出现过拟合问题. 通过上述例子, 我们可以看到特征数量越多, 训练样本就会越稀疏, 分类器的参数估计就会越不准确, 更加容易出现过拟合问题. “维数灾难”的另一个影响是训练样本的稀疏性并不是均匀分布的. 处于中心位置的训练样本比四周的训练样本更加稀疏. 假设有一个二维特征空间, 如图8所示的矩形, 在矩形内部有一个内切的圆形. 由于越接近圆心的样本越稀疏, 因此, 相比于圆形内的样本, 那些位于矩形四角的样本更加难以分类. 那么, 随着特征数量的增加, 圆形的面积会不会变化呢? 这里我们假设超立方体(hypercube)的边长d=1, 那么计算半径为0.5的超球面(hypersphere)的体积(volume)的公式为 $V(d)=\frac{\pi ^{\frac{d}{2}}}{\Gamma (\frac{d}{2}+1)}0.5^{d}$ 从图9可以看出随着特征数量的增加, 超球面的体积逐渐减小直至趋向于零, 然而超立方体的体积却不变. 这个结果有点出乎意料, 但部分说明了分类问题中的“维数灾难”在高维特征空间中, 大多数的训练样本位于超立方体的角落. 图10显示了不同维度下, 样本的分布情况. 在8维特征空间中, 共有2^8=256个角落, 而98%的样本分布在这些角落. 随着维度的不断增加, 公式2将趋向于0, 其中dist_max和dist_min分别表示样本到中心的最大与最小距离. 因此, 在高维特征空间中对于样本距离的度量失去意义. 由于分类器基本都依赖于如Euclidean距离, Manhattan距离等, 所以在特征数量过大时, 分类器的性能就会出现下降. 所以, 我们如何避免“维数灾难”? 图1显示了分类器的性能随着特征个数的变化不断增加, 过了某一个值后, 性能不升反降. 这里的某一个值到底是多少呢? 目前, 还没有方法来确定分类问题中的这个阈值是多少, 这依赖于训练样本的数量, 决策边界的复杂性以及分类器的类型. 理论上, 如果训练样本的数量无限大, 那么就不会存在“维数灾难”, 我们可以采用任意多的特征来训练分类器. 事实上, 训练样本的数量是有限的, 所以不应该采用过多的特征. 此外, 那些需要精确的非线性决策边界的分类器, 比如neural network, knn, decision trees等的泛化能力往往并不是很好, 更容易发生过拟合问题. 因此, 在设计这些分类器时应当慎重考虑特征的数量. 相反, 那些泛化能力较好的分类器, 比如naive Bayesian, linear classifier等, 可以适当增加特征的数量. 如果给定了N个特征, 我们该如何从中选出M个最优的特征? 最简单粗暴的方法是尝试所有特征的组合, 从中挑出M个最优的特征. 事实上, 这是非常花时间的, 或者说不可行的. 其实, 已经有许多特征选择算法(feature selection algorithms)来帮助我们确定特征的数量以及选择特征. 此外, 还有许多特征抽取方法(feature extraction methods), 比如PCA等. 交叉验证(cross-validation)也常常被用于检测与避免过拟合问题. 参考资料 [1] Vincent Spruyt. The Curse of Dimensionality in classification. Computer vision for dummies. 2014. [Link] 2.21.2 怎样避免维数灾难解决维度灾难问题 主成分分析法PCA, 线性判别法LDA 奇异值分解简化数据, 拉普拉斯特征映射 Lassio缩减系数法, 小波分析法, 2.21.3 聚类和降维有什么区别与联系?聚类用于找寻数据内在的分布结构,既可以作为一个单独的过程, 比如异常检测等等. 也可作为分类等其他学习任务的前驱过程. 聚类是标准的无监督学习. 1) 在一些推荐系统中需确定新用户的类型, 但定义“用户类型”却可能不太容易,此时往往可先对原油的用户数据进行聚类,根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型. 2)而降维则是为了缓解维数灾难的一个重要方法, 就是通过某种数学变换将原始高维属性空间转变为一个低维“子空间”. 其基于的假设就是, 虽然人们平时观测到的数据样本虽然是高维的, 但是实际上真正与学习任务相关的是个低维度的分布. 从而通过最主要的几个特征维度就可以实现对数据的描述, 对于后续的分类很有帮助. 比如对于Kaggle上的泰坦尼克号生还问题. 通过给定一个人的许多特征如年龄, 姓名, 性别, 票价等, 来判断其是否能在海难中生还. 这就需要首先进行特征筛选, 从而能够找出主要的特征, 让学习到的模型有更好的泛化性. 聚类和降维都可以作为分类等问题的预处理步骤. 但是他们虽然都能实现对数据的约减. 但是二者适用的对象不同, 聚类针对的是数据点, 而降维则是对于数据的特征. 另外它们着很多种实现方法. 聚类中常用的有K-means, 层次聚类, 基于密度的聚类等; 降维中常用的则PCA, Isomap, LLE等. 2.21.4 四种聚类方法之比较http://www.cnblogs.com/William_Fire/archive/2013/02/09/2909499.html 聚类分析是一种重要的人类行为, 早在孩提时代, 一个人就通过不断改进下意识中的聚类模式来学会如何区分猫狗, 动物植物. 目前在许多领域都得到了广泛的研究和成功的应用, 如用于模式识别, 数据分析, 图像处理, 市场研究, 客户分割, Web文档分类等[1]. 聚类就是按照某个特定标准(如距离准则)把一个数据集分割成不同的类或簇, 使得同一个簇内的数据对象的相似性尽可能大, 同时不在同一个簇中的数据对象的差异性也尽可能地大. 即聚类后同一类的数据尽可能聚集到一起, 不同数据尽量分离. 聚类技术[2]正在蓬勃发展, 对此有贡献的研究领域包括数据挖掘, 统计学, 机器学习, 空间数据库技术, 生物学以及市场营销等. 各种聚类方法也被不断提出和改进, 而不同的方法适合于不同类型的数据, 因此对各种聚类方法, 聚类效果的比较成为值得研究的课题. 1 聚类算法的分类 目前, 有大量的聚类算法[3]. 而对于具体应用, 聚类算法的选择取决于数据的类型, 聚类的目的. 如果聚类分析被用作描述或探查的工具, 可以对同样的数据尝试多种算法, 以发现数据可能揭示的结果.​主要的聚类算法可以划分为如下几类划分方法, 层次方法, 基于密度的方法, 基于网格的方法以及基于模型的方法[4-6]. 每一类中都存在着得到广泛应用的算法, 例如划分方法中的k-means[7]聚类算法, 层次方法中的凝聚型层次聚类算法[8], 基于模型方法中的神经网络[9]聚类算法等.​ 目前,聚类问题的研究不仅仅局限于上述的硬聚类, 即每一个数据只能被归为一类, 模糊聚类[10]也是聚类分析中研究较为广泛的一个分支. 模糊聚类通过隶 属函数来确定每个数据隶属于各个簇的程度, 而不是将一个数据对象硬性地归类到某一簇中. 目前已有很多关于模糊聚类的算法被提出, 如著名的FCM算法等.​ 本文主要对k-means聚类算法, 凝聚型层次聚类算法, 神经网络聚类算法之SOM,以及模糊聚类的FCM算法通过通用测试数据集进行聚类效果的比较和分析. 2 四种常用聚类算法研究 2.1 k-means聚类算法 k-means是划分方法中较经典的聚类算法之一. 由于该算法的效率高, 所以在对大规模数据进行聚类时被广泛应用. 目前, 许多算法均围绕着该算法进行扩展和改进. k-means算法以k为参数, 把n个对象分成k个簇, 使簇内具有较高的相似度, 而簇间的相似度较低. k-means算法的处理过程如下 首先, 随机地 选择k个对象, 每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象, 根据其与各簇中心的距离, 将它赋给最近的簇;然后重新计算每个簇的平均值. 这个过程不断重复, 直到准则函数收敛. 通常, 采用平方误差准则, 其定义如下 $E=\sum_{i=1}^{k}\sum_{p\subset C}|p-m_{i}|^{2}$ 这里E是数据库中所有对象的平方误差的总和, p是空间中的点, mi是簇Ci的平均值[9]. 该目标函数使生成的簇尽可能紧凑独立, 使用的距离度量是欧几里得距离,当然也可以用其他距离度量. k-means聚类算法的算法流程如下 ​ 输入包含n个对象的数据库和簇的数目k;​ 输出k个簇, 使平方误差准则最小.​ 步骤 (1) 任意选择k个对象作为初始的簇中心; (2) repeat; (3) 根据簇中对象的平均值, 将每个对象(重新)赋予最类似的簇; (4) 更新簇的平均值, 即计算每个簇中对象的平均值; (5) until不再发生变化. 2.2 层次聚类算法​ 根据层次分解的顺序是自底向上的还是自上向下的, 层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法. 凝聚型层次聚类的策略是先将每个对象作为一个簇, 然后合并这些原子簇为越来越大的簇, 直到所有对象都在一个簇中, 或者某个终结条件被满足. 绝大多数层次聚类属于凝聚型层次聚类, 它们只是在簇间相似度的定义上有所不同. 四种广泛采用的簇间距离度量方法如下 这里给出采用最小距离的凝聚层次聚类算法流程 (1) 将每个对象看作一类, 计算两两之间的最小距离; (2) 将距离最小的两个类合并成一个新类; (3) 重新计算新类与所有类之间的距离; (4) 重复(2), (3), 直到所有类最后合并成一类. 2.21.5 SOM聚类算法SOM神经网络[11]是由芬兰神经网络专家Kohonen教授提出的, 该算法假设在输入对象中存在一些拓扑结构或顺序, 可以实现从输入空间(n维)到输出平面(2维)的降维映射, 其映射具有拓扑特征保持性质,与实际的大脑处理有很强的理论联系. SOM网络包含输入层和输出层. 输入层对应一个高维的输入向量, 输出层由一系列组织在2维网格上的有序节点构成, 输入节点与输出节点通过权重向量连接. 学习过程中, 找到与之距离最短的输出层单元, 即获胜单元, 对其更新. 同时, 将邻近区域的权值更新, 使输出节点保持输入向量的拓扑特征. 算法流程 (1) 网络初始化, 对输出层每个节点权重赋初值;(2) 将输入样本中随机选取输入向量, 找到与输入向量距离最小的权重向量;(3) 定义获胜单元, 在获胜单元的邻近区域调整权重使其向输入向量靠拢;(4) 提供新样本, 进行训练;(5) 收缩邻域半径, 减小学习率, 重复, 直到小于允许值, 输出聚类结果. 2.21.6 FCM聚类算法1965年美国加州大学柏克莱分校的扎德教授第一次提出了‘集合’的概念. 经过十多年的发展, 模糊集合理论渐渐被应用到各个实际应用方面. 为克服非此即彼的分类缺点, 出现了以模糊集合论为数学基础的聚类分析. 用模糊数学的方法进行聚类分析, 就是模糊聚类分析[12]. FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法. 该聚类算法是传统硬聚类算法的一种改进. 算法流程 (1) 标准化数据矩阵; (2) 建立模糊相似矩阵, 初始化隶属矩阵; (3) 算法开始迭代, 直到目标函数收敛到极小值; (4) 根据迭代结果, 由最后的隶属矩阵确定数据所属的类, 显示最后的聚类结果. 3 四种聚类算法试验 3.1 试验数据 实验中, 选取专门用于测试分类, 聚类算法的国际通用的UCI数据库中的IRIS[13]数据集, IRIS数据集包含150个样本数据, 分别取自三种不同 的莺尾属植物setosa, versicolor和virginica的花朵样本,每个数据含有4个属性, 即萼片长度, 萼片宽度, 花瓣长度, 单位为cm. 在数据集上执行不同的聚类算法, 可以得到不同精度的聚类结果. 3.2 试验结果说明 文中基于前面所述各算法原理及算法流程, 用matlab进行编程运算, 得到表1所示聚类结果. 如表1所示, 对于四种聚类算法, 按三方面进行比较 (1)聚错样本数总的聚错的样本数, 即各类中聚错的样本数的和; (2)运行时间即聚类整个 过程所耗费的时间, 单位为s; (3)平均准确度设原数据集有k个类,用ci表示第i类, ni为ci中样本的个数, mi为聚类正确的个数,则mi/ni为 第i类中的精度, 则平均精度为 $avg=\frac{1}{k}\sum_{i=1}^{k}\frac{m_{i}}{n_{i}}$ 2.22 GBDT和随机森林的区别GBDT和随机森林的相同点 1, 都是由多棵树组成2, 最终的结果都是由多棵树一起决定 GBDT和随机森林的不同点 1, 组成随机森林的树可以是分类树, 也可以是回归树; 而GBDT只由回归树组成2, 组成随机森林的树可以并行生成; 而GBDT只能是串行生成3, 对于最终的输出结果而言, 随机森林采用多数投票等; 而GBDT则是将所有结果累加起来, 或者加权累加起来4, 随机森林对异常值不敏感, GBDT对异常值非常敏感5, 随机森林对训练集一视同仁, GBDT是基于权值的弱分类器的集成6, 随机森林是通过减少模型方差提高性能, GBDT是通过减少模型偏差提高性能 2.23 大数据与深度学习之间的关系大数据通常被定义为“超出常用软件工具捕获, 管理和处理能力”的数据集. 机器学习 关心的问题是如何构建计算机程序使用经验自动改进. 数据挖掘** 是从数据中提取模式的特定算法的应用.在数据挖掘中, 重点在于算法的应用, 而不是算法本身. 机器学习和数据挖掘 之间的关系如下 数据挖掘是一个过程, 在此过程中机器学习算法被用作提取数据集中的潜在有价值模式的工具.大数据与深度学习关系总结如下 深度学习是一种模拟大脑的行为. 可以从所学习对象的机制以及行为等等很多相关联的方面进行学习, 模仿类型行为以及思维. 深度学习对于大数据的发展有帮助. 深度学习对于大数据技术开发的每一个阶段均有帮助, 不管是数据的分析还是挖掘还是建模, 只有深度学习, 这些工作才会有可能一一得到实现. 深度学习转变了解决问题的思维. 很多时候发现问题到解决问题, 走一步看一步不是一个主要的解决问题的方式了, 在深度学习的基础上, 要求我们从开始到最后都要基于哦那个一个目标, 为了需要优化的那个最终目的去进行处理数据以及将数据放入到数据应用平台上去. 大数据的深度学习需要一个框架. 在大数据方面的深度学习都是从基础的角度出发的, 深度学习需要一个框架或者一个系统总而言之, 将你的大数据通过深度分析变为现实这就是深度学习和大数据的最直接关系.]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习500问》 第一章 数学基础]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Book-DL500Questions-ch01-Math%2F</url>
    <content type="text"><![CDATA[本篇博文为个人读书笔记, 更详细的内容请查看《深度学习500问》原版书籍 第一章 数学基础1.1 标量, 向量, 矩阵, 张量之间的联系标量 (scalar)一个标量表示一个单独的数. 向量 (vector)一个向量表示一组数, 通过次序中的索引, 我们可以确定每个单独的数. 矩阵 (matrix)矩阵是具有相同特征和维度的对象的集合, 表现为一张二维数据表. 张量 (tensor)神经网络中的张量和物理学中的张量不是同一个概念, 在神经网络中, 我们所说的张量可以看做是多维数组, 例如在 PyTorch 中我们的张量通常可以中 numpy 的 ndarray 数据结构互相转换 四者之间关系 标量是0阶张量, 向量是一阶张量, 矩阵是二阶张量.(可以这么看) 1.2 张量与矩阵的区别?张量的范围大过矩阵, 对于二阶张量来说, 我们可以把它看做是一个矩阵, 也可以说矩阵是一种特殊的二阶张量 1.3 矩阵和向量相乘结果一个 $m$ 行 $n$ 列的矩阵和 $n$ 行向量相乘, 最后得到就是一个 $m$ 行的向量. 1.4 向量和矩阵的范数归纳向量的范数定义一个向量为: $\vec{a}=[-5, 6, 8, -10]$. 任意一组向量设为$\vec{x}=(x_1,x_2,…,x_N)$. 其不同范数求解如下: $L_1$ 范数: 向量的各个元素的 绝对值 之和, 上述向量 $\vec{a}$ 的 $L_1$ 范数结果就是 29. \Vert\vec{x}\Vert_1=\sum_{i=1}^N\vert{x_i}\vert $L_2$ 范数: 向量的每个元素的平方之和, 最终再开平方根, 上述 $\vec{a}$ 的 $L_2$ 范数结果就是 15. \Vert\vec{x}\Vert_2=\sqrt{\sum_{i=1}^N{\vert{x_i}\vert}^2} $L_p$ 范数: 向量元素绝对值的 $p$ 次方和的 $1/p$ 次幂. L_p=\Vert\vec{x}\Vert_p=\sqrt[p]{\sum_{i=1}^{N}\vert{x_i}\vert^p} 负无穷范数: 向量的所有元素的绝对值中最小的: 上述向量 $\vec{a}$ 的负无穷范数结果就是 5. \Vert\vec{x}\Vert_{-\infty}=\min{\vert{x_i}}\vert 正无穷范数: 向量的所有元素的绝对值中最大的: 上述向量 $\vec{a}$ 的负无穷范数结果就是 10. \Vert\vec{x}\Vert_{+\infty}=\max{|{x_i}|}矩阵的范数 ​定义一个矩阵 $A=[-1, 2, -3; 4, -6, 6]$. 任意矩阵定义为: $A_{m\times n}$, 其元素为 $a_{ij}$. 矩阵的范数定义为 \Vert{A}\Vert_p =\sup_{x\neq 0}\frac{\Vert{Ax}\Vert_p}{\Vert{x}\Vert_p}​当向量取不同范数时(注意这里 1 范数和 $L_1$ 范数的区别, 在深度学习中, 我们一般面对的是张量, 因此只考虑 $L_1$ 等范数), 相应得到了不同的矩阵范数. 矩阵的 1 范数(列范数): 矩阵的每一列上的元素绝对值先求和, 再从中取个最大的(列和最大), 上述矩阵 $A$ 的1范数先得到 $[5,8,9]$, 再取最大的最终结果就是: 9. \Vert A\Vert_1=\max_{1\le j\le}\sum_{i=1}^m|{a_{ij}}| 矩阵的 2 范数: 矩阵$A^TA$的最大特征值开平方根, 上述矩阵$A$的2范数得到的最终结果是: 10.0623. 下式中, $\lambda_{max}(A^T A)$ 为 $A^T A$ 的特征值绝对值的最大值. \Vert A\Vert_2=\sqrt{\lambda_{max}(A^T A)} 矩阵的无穷范数(行范数): 矩阵的每一行上的元素绝对值先求和, 再从中取个最大的(行和最大), 上述矩阵 $A$ 的1范数先得到 $[6; 16]$, 再取最大的最终结果就是: 16. \Vert A\Vert_{\infty}=\max_{1\le i \le n}\sum_{j=1}^n |{a_{ij}}| 矩阵的核范数: 矩阵的奇异值(将矩阵svd分解)之和, 这个范数可以用来低秩表示(因为最小化核范数, 相当于最小化矩阵的秩——低秩), 上述矩阵A最终结果就是: 10.9287. 矩阵的 L0 范数: 矩阵的非 0 元素的个数, 通常用它来表示稀疏, L0 范数越小 0 元素越多, 也就越稀疏, 上述矩阵$A$最终结果就是: 6. 矩阵的 L1 范数: 矩阵中的每个元素绝对值之和, 它是 L0 范数的最优凸近似, 因此它也可以表示稀疏, 上述矩阵 $A$ 最终结果就是: 22. 矩阵的 F 范数: 矩阵的各个元素平方之和再开平方根, 它通常也叫做矩阵的 L2范数, 它的有点在它是一个凸函数, 可以求导求解, 易于计算, 上述矩阵A最终结果就是: 10.0995. \Vert A\Vert_F=\sqrt{(\sum_{i=1}^m\sum_{j=1}^n{|a_{ij}|}^2)} 矩阵的L21范数: 矩阵先以每一列为单位, 求每一列的F范数(也可认为是向量的2范数), 然后再将得到的结果求L1范数(也可认为是向量的1范数), 很容易看出它是介于L1和L2之间的一种范数, 上述矩阵$A$最终结果就是: 17.1559. 矩阵的 Lp 范数 \Vert A\Vert_p=\sqrt[p]{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^p)}在深度学习中, 我们常用的范数是针对张量而言的, 这些范数的计算和矩阵的 L 系范数的计算方式相同. 1.5 如何判断一个矩阵为正定? 顺序主子式全大于0; 存在可逆矩阵 $C$ 使 $C^TC$ 等于该矩阵; 正惯性指数等于 $n$; 合同于单位矩阵 $E$(即: 规范形为 $E$) 标准形中主对角元素全为正; 特征值全为正; 是某基的度量矩阵. 1.6 导数偏导计算导数​导数代表了在 自变量变化趋于无穷小的时候, 函数值的变化与自变量的变化的比值. 几何意义是这个点的 切线. 物理意义是该时刻的 (瞬时)变化率.​注意: 在一元函数中, 只有一个自变量变动, 也就是说只存在一个方向的变化率, 这也就是为什么一元函数没有偏导数的原因. 在物理学中有平均速度和瞬时速度之说. 平均速度为 v=\frac{s}{t}​其中 $v$ 表示平均速度, $s$ 表示路程, $t$ 表示时间. 这个公式可以改写为 \bar{v}=\frac{\Delta s}{\Delta t}=\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}​其中 $\Delta s$ 表示两点之间的距离, 而 $\Delta t$ 表示走过这段距离需要花费的时间. 当 $\Delta t$ 趋向于 0($\Delta t \to 0$)时, 也就是时间变得很短时, 平均速度也就变成了在 $t_0$ 时刻的瞬时速度, 表示成如下形式: v(t_0)=\lim_{\Delta t \to 0}{\bar{v}}=\lim_{\Delta t \to 0}{\frac{\Delta s}{\Delta t}}=\lim_{\Delta t \to 0}{\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}}​实际上, 上式表示的是路程 $s$ 关于时间 $t$ 的函数在 $t=t_0$ 处的导数. 一般的, 这样定义导数: 如果平均变化率的极限存在, 即有 \lim_{\Delta x \to 0}{\frac{\Delta y}{\Delta x}}=\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x)-f(x_0)}{\Delta x}}​则称此极限为函数 $y=f(x)$ 在点 $x_0$ 处的导数. 记作 $f’(x_0)$ 或 $y’\vert_{x=x_0}$ 或 $\frac{dy}{dx}\vert_{x=x_0}$ 或 $\frac{df(x)}{dx}\vert_{x=x_0}$. 通俗地说, 导数就是曲线在某一点切线的斜率. 偏导数​既然谈到偏导数, 那就至少涉及到两个自变量. 以两个自变量 $x, y$ 为例, $z=f(x,y)$, 从导数到偏导数, 也就是从曲线来到了曲面. 曲线上的一点, 其切线只有一条. 但是曲面上的一点, 切线有无数条. 而 偏导数就是指多元函数沿着坐标轴的变化率.​注意: 直观地说, 偏导数也就是函数在某一点上沿坐标轴正方向的的变化率.设函数 $z=f(x,y)$ 在点 $(x_0,y_0)$ 的领域内有定义, 当 $y=y_0$ 时, $z$ 可以看作关于 $x$ 的一元函数 $f(x,y_0)$, 若该一元函数在 $x=x_0$ 处可导, 即有 \lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x,y_0)-f(x_0,y_0)}{\Delta x}}=A​函数的极限 $A$ 存在. 那么称 $A$ 为函数 $z=f(x,y)$ 在点 $(x_0,y_0)$ 处关于自变量 $x$ 的偏导数, 记作 $f_x(x_0,y_0)$ 或 $\frac{\partial z}{\partial x}\vert_{y=y_0}^{x=x_0}$ 或 $\frac{\partial f}{\partial x}\vert_{y=y_0}^{x=x_0}$ 或 $z_x\vert_{y=y_0}^{x=x_0}$. ​偏导数在求解时可以将另外一个变量看做常数, 利用普通的求导方式求解, 比如 $z=3x^2+xy$ 关于 $x$ 的偏导数就为 $z_x=6x+y$, 这个时候 $y$ 相当于 $x$ 的系数.某点 $(x_0,y_0)$ 处的偏导数的几何意义为曲面 $z=f(x,y)$ 与面 $x=x_0$ 或面 $y=y_0$ 的交线在 $y=y_0$ 或 $x=x_0$ 处切线的斜率. 1.7 导数和偏导数有什么区别?​导数和偏导没有本质区别, 如果极限存在, 都是当自变量的变化量趋于0时, 函数值的变化量与自变量变化量比值的极限. 一元函数, 一个 $y$ 对应一个 $x$, 导数只有一个. 二元函数, 一个 $z$ 对应一个 $x$ 和一个 $y$, 有两个导数: 一个是 $z$ 对 $x$ 的导数, 一个是 $z$ 对 $y$ 的导数, 称之为偏导. 当对自身 $z$ 求导时, 则要求同时求对 $x$ 和对 $y$ 的导数 $z’(x,y) = z’(x)z(y)+z(x)z’(y)$. 求偏导时要注意, 对一个变量求导, 则视另一个变量为常数, 只对该变量求导, 从而将偏导的求解转化成了一元函数的求导. 1.8 特征值分解与特征向量 特征值分解可以得到特征值与特征向量; 特征值表示的是这个特征到底有多重要, 而特征向量表示这个特征是什么. 如果说一个向量 $\vec{v}$ 是方阵 $A$ 的特征向量, 将一定可以表示成下面的形式: A \vec{v} = \lambda \vec{v}$\lambda$ 为特征向量 $\vec{v}$ 对应的特征值. 特征值分解是将一个矩阵分解为如下形式:​ A=Q\sum Q^{-1}其中, $Q$ 是这个矩阵 $A$ 的特征向量组成的矩阵, $\sum$ 是一个对角矩阵, 每一个对角线元素就是一个特征值, 里面的特征值是由大到小排列的, 这些特征值所对应的特征向量就是描述这个矩阵变化方向(从主要的变化到次要的变化排列). 也就是说矩阵 $A$ 的信息可以由其特征值和特征向量表示. 1.9 奇异值与特征值有什么关系?TODO: 奇异值这里没搞懂 ​那么奇异值和特征值是怎么对应起来的呢? 我们将一个矩阵$A$的转置乘以$A$, 并对$AA^T$求特征值, 则有下面的形式: (A^TA)V = \lambda V这里$V$就是上面的右奇异向量, 另外还有: \sigma_i = \sqrt{\lambda_i}, u_i=\frac{1}{\sigma_i}A\mu_i这里的 $\sigma$ 就是奇异值, $u$ 就是上面说的左奇异向量. 【证明那个哥们也没给】​奇异值 $\sigma$ 跟特征值类似, 在矩阵 $\sum$ 中也是从大到小排列, 而且 $\sigma$ 的减少特别的快, 在很多情况下, 前 10% 甚至 1% 的奇异值的和就占了全部的奇异值之和的 99% 以上了. 也就是说, 我们也可以用前 $r$($r$ 远小于 $m、n$)个的奇异值来近似描述矩阵, 即部分奇异值分解: A_{m\times n}\approx U_{m \times r}\sum_{r\times r}V_{r \times n}^T右边的三个矩阵相乘的结果将会是一个接近于$A$的矩阵, 在这儿, $r$ 越接近于 $n$, 则相乘的结果越接近于$A$. 1.10 机器学习为什么要使用概率?​事件的概率是衡量该事件发生的可能性的量度. 虽然在一次随机试验中某个事件的发生是带有偶然性的, 但那些可在相同条件下大量重复的随机试验却往往呈现出明显的数量规律.​机器学习除了处理不确定量, 也需处理随机量. 不确定性和随机性可能来自多个方面, 使用概率论来量化不确定性.​概率论在机器学习中扮演着一个 核心角色, 因为机器学习算法的设计通常依赖于 对数据的概率假设. ​ 例如在机器学习(Andrew Ng)的课中, 会有一个朴素贝叶斯假设就是条件独立的一个例子. 该学习算法对内容做出假设, 用来分辨电子邮件是否为垃圾邮件. 假设无论邮件是否为垃圾邮件, 单词 $x$ 出现在邮件中的概率条件独立于单词 $y$. 很明显这个假设是有失一般性的, 因为某些单词几乎总是同时出现. 然而, 最终结果是, 这个简单的假设对结果的影响并不大, 且无论如何都可以让我们快速判别垃圾邮件. 1.11 变量与随机变量有什么区别?随机变量(random variable)​表示随机现象(在一定条件下, 并不总是出现相同结果的现象称为随机现象)中各种结果的实值函数(一切可能的样本点). 例如某一时间内公共汽车站等车乘客人数, 电话交换台在一定时间内收到的呼叫次数等, 都是随机变量的实例.​随机变量与模糊变量的不确定性的本质差别在于, 后者的测定结果仍具有不确定性, 即模糊性. 变量与随机变量的区别:​当变量的取值的概率不是1时,变量就变成了随机变量; 当随机变量取值的概率为1时,随机变量就变成了变量. 比如: 当变量 $x$ 值为 100 的概率为1的话,那么 $x=100$ 就是确定了的,不会再有变化,除非有进一步运算.​ 当变量 $x$ 的值为 100 的概率不为 1, 比如为 50 的概率是 0.5,为 100 的概率是 0.5, 那么这个变量就是会随不同条件而变化的, 是随机变量, 取到 50 或者 100 的概率都是 0.5,即 50%. 1.12 常见概率分布1.13 举例理解条件概率条件概率公式如下: P(A | B) = \frac{P(A\cap B)}{P(B)}​说明: 在同一个样本空间 $\Omega$ 中的事件或者子集 $A$ 与 $B$, 如果随机从 $\Omega$ 中选出的一个元素属于 $B$, 那么下一个随机选择的元素属于 $A$ 的概率就定义为在 $B$ 的前提下 $A$ 的条件概率. ​根据文氏图, 可以很清楚地看到在事件B发生的情况下, 事件A发生的概率就是 $P(A\cap B)$ 除以 $P(B)$. ​举例: 一对夫妻有两个小孩, 已知其中一个是女孩, 则另一个是女孩子的概率是多少? (面试、笔试都碰到过)穷举法: 已知其中一个是女孩, 那么样本空间为男女, 女女, 女男, 则另外一个仍然是女生的概率就是1/3.条件概率法: $P(女|女)=P(女女)/P(女)$,夫妻有两个小孩, 那么它的样本空间为女女, 男女, 女男, 男男, 则$P(女女)$为1/4, $P(女)= 1-P(男男)=3/4$,所以最后$1/3$.这里大家可能会误解, 男女和女男是同一种情况, 但实际上类似姐弟和兄妹是不同情况. 1.14 联合概率与边缘概率的联系和区别?区别:​- 联合概率: 联合概率指类似于 $P(X=a,Y=b)$ 这样, 包含多个条件, 且 所有条件同时成立的概率. 联合概率是指在多元的概率分布中多个随机变量分别满足各自条件的概率.​- 边缘概率: 边缘概率是某个事件发生的概率, 而与其它事件无关. 边缘概率指类似于 $P(X=a)$, $P(Y=b)$ 这样, 仅与单个随机变量有关的概率. 联系:​由联合分布可求边缘分布, 但若只知道边缘分布, 无法保证一定可以求得联合分布. 1.15 条件概率的链式法则​由条件概率的定义, 可直接得出下面的乘法公式:​乘法公式 设 $A, B$ 是两个事件, 并且$P(A) &gt; 0$, 则有 P(AB) = P(B|A)P(A)​推广 P(ABC)=P(C|AB)P(B|A)P(A)​一般地, 用归纳法可证: 若 $P(A_1A_2…A_n)&gt;0$, 则有 P(A_1A_2...A_n)=P(A_n|A_1A_2...A_{n-1})P(A_{n-1}|A_1A_2...A_{n-2})...P(A_2|A_1)P(A_1) =P(A_1)\prod_{i=2}^{n}P(A_i|A_1A_2...A_{i-1})​任何多维随机变量联合概率分布, 都可以分解成只有一个变量的条件概率相乘形式. 1.16 独立性和条件独立性独立性​两个随机变量 $x$ 和 $y$, 概率分布表示成两个因子乘积形式, 一个因子只包含 $x$, 另一个因子只包含 $y$, 两个随机变量相互独立(independent).​条件有时为不独立的事件之间带来独立, 有时也会把本来独立的事件, 因为此条件的存在, 而失去独立性.​举例: $P(XY)=P(X)P(Y)$, 事件 $X$ 和事件 $Y$ 独立. 此时给定 $Z$, 会使得 $P(X,Y|Z) \neq P(X|Z)P(Y|Z)$. ​事件独立时, 联合概率等于边缘概率的乘积. 这是一个非常好的数学性质, 然而不幸的是, 无条件的独立是十分稀少的, 因为大部分情况下, 事件之间都是互相影响的. 条件独立性​给定 $Z$ 的情况下, $X$ 和 $Y$ 条件独立, 当且仅当 X\bot Y|Z \iff P(X,Y|Z) = P(X|Z)P(Y|Z)​$X$ 和 $Y$ 的关系依赖于 $Z$, 而不是直接产生. 举例:定义如下事件:$X$: 明天下雨;$Y$: 今天的地面是湿的;$Z$: 今天下雨;$Z$事件的成立, 对 $X$ 和 $Y$ 均有影响, 然而, 在 $Z$ 事件成立的前提下, 今天的地面情况对明天是否下雨没有影响. 1.17 期望、方差、协方差、相关系数总结期望​在概率论和统计学中, 数学期望(或均值, 亦简称期望)是试验中每次可能结果的概率乘以其结果的总和. 它反映随机变量平均取值的大小. 线性运算: $E(ax+by+c) = aE(x)+bE(y)+c$ ​推广形式: $E(\sum_{k=1}^{n}{a_ix_i+c}) = \sum_{k=1}^{n}{a_iE(x_i)+c}$ 函数期望: 设$f(x)$为$x$的函数, 则$f(x)$的期望为 离散函数: $E(f(x))=\sum_{k=1}^{n}{f(x_k)P(x_k)}$ 连续函数: $E(f(x))=\int_{-\infty}^{+\infty}{f(x)p(x)dx}$ 注意: 函数的期望不等于期望的函数, 即 $E(f(x)) \neq f(E(x))$ 一般情况下, 乘积的期望不等于期望的乘积. 如果 $X$ 和 $Y$ 相互独立, 则 $E(xy)=E(x)E(y)​$. 方差​概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度. 方差是一种特殊的期望. 定义为: Var(x) = E((x-E(x))^2) 方差性质: 1) $Var(x) = E(x^2) -E(x)^2$2) 常数的方差为0;3) 方差不满足线性性质;4) 如果 $X$ 和 $Y$ 相互独立, $Var(ax+by)=a^2Var(x)+b^2Var(y)$ 协方差​协方差是衡量两个变量线性相关性强度及变量尺度. 两个随机变量的协方差定义为: Cov(x,y)=E((x-E(x))(y-E(y)))​方差是一种特殊的协方差. 当 $X=Y$ 时, $Cov(x,y)=Var(x)=Var(y)$. 协方差性质: 1) 独立变量的协方差为0.2) 协方差计算公式: Cov(\sum_{i=1}^{m}{a_ix_i}, \sum_{j=1}^{m}{b_jy_j}) = \sum_{i=1}^{m} \sum_{j=1}^{m}{a_ib_jCov(x_iy_i)} 3)特殊情况: Cov(a+bx, c+dy) = bdCov(x, y)相关系数​相关系数是研究变量之间线性相关程度的量. 两个随机变量的相关系数定义为: Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}} 相关系数的性质:1)有界性. 相关系数的取值范围是 , 可以看成无量纲的协方差.2)值越接近1, 说明两个变量正相关性(线性)越强. 越接近-1, 说明负相关性越强, 当为0时, 表示两个变量没有相关性.]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CUDA By Example》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CUDAByExample%2F</url>
    <content type="text"><![CDATA[WHY CUDA？ WHY NOW？]]></content>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DenseNet (CVPR, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DenseNet-CVPR2017%2F</url>
    <content type="text"><![CDATA[文章: Densely Connected Convolutional Networks作者: Gao Huang, Zhuang Liu, Laurens van der Maaten机构: Cornell University 摘要 简述 DenseNet 的原理在训练特别深层的网络时, 随着深度的增加, 梯度消失的问题会越来越明显, 对此, ResNet 给出了一个很好的解决方案, 那就是在接近输入层的网络中添加一个短接路径到靠近输出层的网络. DenseNet 也延续了这个思路, 与 ResNet 不同的是, 他采用了一个更暴力的方式, 就是将所有网络层都连接起来, 具体来说, 就说每一层的输入会来自于 前面所有层的输出(这些层的特征图谱大小时相同的, 因此可以在 Channel 维度上进行叠加). 如果假设有网络的层数是 $L$, 那么 DenseNet 就会有 $\frac{L(L+1)}{2}$ 个短接路径. 在传统的卷积神经网络中, 通常会利用 Pooling 层或者卷积层来降低特征图谱的大小, 而 DenseNet 的密集连接需要特征图大小保持一致, 因此, 为了解决这个问题, DenseNet 将网络分成了若干个 DenseBlock, DenseBlock 中的网络层都具有相同大小的特征图谱, 因此可以直接使用密集连接的方式进行连接. 在 DenseBlock 中, 每一层网络输出的特征图谱的通道数是通过一个超参数增长率 $k$ 来决定的, 这个 $k$ 可以设定的比较小, 比如32, 虽然每一层的输出图谱通道数较低, 但是每一层的输入是综合前面所有层的输出的, 因此具有特征重用的效果. 另外, 由于深层的网络层输入非常大, 因此 DenseBlock 内部会采用 bottleneck 来减少计算量, 主要是在原来的 $3 \times 3$ 卷积层之前添加 $1\times 1$ 的卷积层, 变成 BN + ReLU + 1x1 Conv + BN + ReLU + 3x3 Conv 的结构(DenseNet-B), $1\times 1$ 卷积会将 $l\times k$ 的通道数降低成 $4\times k$ 的通道数, 从而提升计算效率.对于相邻的具有不同特征图谱大小的 DenseBlock, DenseNet 采用的 Transition Layers 进行连接, 它的结构是 BN + ReLU + 1x1 Conv + 2x2 AvgPooling. 它主要作用是降低特征图谱的尺寸大小, 另外还有一个作用就是压缩模型, 假定 Transition 层的前一个 DenseBlock 得到的特征图谱的数量为 $m$, 它会根据压缩系数 $\theta \in (0, 1]$ 的值来决定输出的特征图谱的数量(通过卷积层), 输出的图谱通道数量为 $\lfloor \theta m \floor$ 当 $\theta = 1$ 时, 相等于没有压缩, 文中使用 $\theta = 0.5$(DenseNet-C). DenseNet 的整体网络结构设计也是遵循的经典的五段式, 其中第一段是有传统 $7\times 7$ 卷积构成的 Stem, 后面四段是层数不同的 DenseBlock-BC, 最后是 GAP+FC+Softmax 的分类层.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
        <tag>网络模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[collections模块-集合型数据结构]]></title>
    <url>%2Fz_post%2FPython-collections%2F</url>
    <content type="text"><![CDATA[collections 是Python的一个集合模块, 它在内置数据结构 (dict, list, set, tuple) 的基础上, 提供了一些额外的集合型数据结构: 类型 说明 备注 deque 双端队列, 可以快速的从头/尾两端添加或删除元素 New in 2.4 defaultdict 带有默认值的字典 New in version 2.5 namedtuple 命名元组, 可以使用名字访问元素 New in version 2.6 Counter 计数器, 用于对某项数据进行计数 New in version 2.7 OrderedDict 有序字典, 按key对字典元素排序 New in version 2.7 ChainMap 合并多个map(dict), 但保持原数据结构 New in version 3.3 UserDict 将字典包装起来使得创建字典的子类更容易 UserList 列表对象的包装器 UserString 字符串对象的包装器 dequedeque 是double-ended queue 的缩写, 即双端队列. List存储数据的优势在于按索引查找元素很快, 但是插入和删除元素就很慢了, 因为List是基于数组实现的. deque 是为了高效插入和删除的双向列表, 适合用于跌列和栈, 而且线程安全, 其原型如下: 1collections.deque([iterable[, maxlen]]) deque 除了list固有的方法外, 还新增了 appendleft / popleft 等方法允许高效的在队列的开头插入或删除元素, 其时间复杂度为 $O(1)$ defaultdictnamedtuplenamedtuple 是继承自 tuple 的子类, 它会创建一个和 tuple 类似的对象, 而且对象拥有可以访问的属性, 注意, 这些属性是只读的, 示例如下: 1234567891011121314151617181920from collections import namedtuple# 定义一个 namedtuple 类型: User 类型, 该类型包含三个属性: name, sex 和 age.User = namedtuple("User", ["name", "sex", "age"])# 创建一个 User 类型的对象 u1u1 = User(name="u1", sex="male", age=1)# 通过 . 访问对象的属性print(u1.name, u1.sex, u1.age) # "u1" "male" 1# 属性一旦确定就是只读的, 不能直接修改u1.age = 2 # 报错: AttributeError: can't set attribute# 如果非要修改, 可以使用 _replace, 这种方法实际上是创建再替换, 而非修改, 不过效果上相同u1 = u1._replace(age=2)# 利用 _asdict() 方法可将 namedtuple 类型转换成 OrderedDict 类型.u1_d = u1._asdict() CounterOrderedDictOrderedDict 是 dict 的一个子类, 支持所有的 dict 方法, 它能够保持 dict 的有序性, 其原型如下: 1collections.OrderedDict([items]) 1234# last = True: LIFO 栈# last = False: FIFO 队列popitem(last=True)move_to_end(key, last=True) OrderedDict 的经典应用, LRU:1234567891011121314151617class LRU(OrderedDict): 'Limit size, evicting the least recently looked-up key when full' def __init__(self, maxsize=128, *args, **kwds): self.maxsize = maxsize super().__init__(*args, **kwds) def __getitem__(self, key): value = super().__getitem__(key) self.move_to_end(key) return value def __setitem__(self, key, value): super().__setitem__(key, value) if len(self) &gt; self.maxsize: oldest = next(iter(self)) del self[oldest]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】基于深度学习的目标检测]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[前言下面对每篇文章及模型的亮点和优势进行了简单总结, 点击标题可以跳转至相关论文解读 (难免存在纰漏或者词不达意的地方, 望谅解) 基于深度学习的目标检测发展轨迹下面是自R-CNN以来有关目标检测的文章，其中，加粗的部分为具有标志性意义的检测模型。 R-CNN (CVPR, 2013) $\longrightarrow$ OverFeat (ICLR, 2014) $\longrightarrow$ MultiBox (CVPR, 2014) $\longrightarrow$ SPPNet (ECCV, 2014) $\longrightarrow$ FastR-CNN (ICCV, 2015) $\longrightarrow$ FasterR-CNN (NIPS, 2015) $\longrightarrow$ OHEM (CVPR, 2016) $\longrightarrow$ YOLOv1 (CVPR, 2016) $\longrightarrow$ SSD (ECCV, 2016) $\longrightarrow$ R-FCN (NIPS, 2016) $\longrightarrow$ DSSD (Arxiv, 2017) $\longrightarrow$ YOLOv2 (CVPR, 2017) $\longrightarrow$ FPN (CVPR, 2017) $\longrightarrow$ Speed-Accuracy TradeOff (CVPR, 2017) $\longrightarrow$ DCN (ICCV, 2017) $\longrightarrow$ Couple Net (ICCV, 2017) $\longrightarrow$ RetinaNet (ICCV, 2017) $\longrightarrow$ Mask R-CNN(ICCV, 2017) $\longrightarrow$ YOLOv3 (Arxiv, 2018) $\longrightarrow$ RefineDet (CVPR, 2018) $\longrightarrow$ Cascade R-CNN (CVPR, 2018) $\longrightarrow$ RFBNet (ECCV, 2018) $\longrightarrow$ Pelee (NIPS, 2018) 主流框架模型对比 模型 特点 性能 Faster R-CNN RPN 精度高, 速度慢 YOLO Darknet, One-Stage 小目标效果不好, 速度很快 SSD MultiBox+Anchor, One-Stage 精度尚可, 速度较快 FPN 特征金字塔 - RetinaNet Focal Loss - Mask R-CNN 实例分割 - Trick NMS Soft NMS (ICCV, 2017) Learning NMS(CVPR, 2018) Softer NMS (Arxiv, 2018) 其他 ResNet (CVPR, 2016) Inception系列V1-V4 FCN (CVPR, 2015) Non Local Group Normalization R-CNN (CVPR, 2014)(1) 利用SS (Selective Search)提取候选区域框:本篇文章利用SS(Selective Search) 算法首先生成大约2000个候选区域框 (2) 将CNN用于目标检测任务:CNN拥有十分强大的特征提取能力, 并且无需人为设计特征算子, 对提取出来的每个候选区域框进行CNN计算, 获取到固定长度的特征向量 (3) 利用SVM分类器对候选框分类:训练SVM分类器, 对候选区域框的特征向量进行分类. (4) 使用回归其精细修正候选框位置 简述 Selective Search 的原理 简述 Bounding Box 的回归方式 Bounding box 回归的时候, 为什么不直接对坐标回归, 而是采用偏移量和缩放度 为什么当 Region Proposals 和 Ground Truth 较接近时, 可以认为是边框回归函数是线性变换 注: 以上几个步骤是独立训练的, 这也是R-CNN后续改进的空间 OverFeat (ICLR, 2014)(1) Multi-Scale Classification:在分类任务上, 虽然训练时采用和AlexNet相同的multi crop方法, 但是在预测阶段没有使用AlexNet的crop投票策略, 而是提出了Multi-Scale Classification方法, 一句话概括就是 对整个图片以不同的尺寸, 并且对每一个location进行模型预测 (2) 利用了全卷积的思想代替全连接降低了滑动窗口的计算代价, 同时支持任意尺寸的图片输入 (3) 可以用同一个模型完成分类, 定位, 检测任务:同一个模型, 只需要用回归层替换分类层, 即可完成目标定位任务, 同时利用了贪心策略来融合最终的定位结果 MultiBox-CVPR2014(1) 将目标边框检测转化为回归问题:将物体检测问题定义为输出多个bounding box的回归问题. 同时每个bounding box会输出关于是否包含目标物体的置信度, 使得模型更加紧凑和高效 (2) 通过损失函数将检测器训练过程整合到神经网络内部:将训练bounding box检测器作为整个网络训练过程的一部分, 也就是说在损失函数中包含了关于bounding box的损失项. 通过联合训练, 不仅利用了神经网络强大的特征表示能力, 而且将检测器的训练集成到了网络中 (3) 无类别监督训练, 使得边框推荐复杂度与类别无关, 易于扩展作者将本文的目标边框检测器在无监督的样本下训练, 由于本方法主要完成的功能就是画框, 并不会输出框中包含的物体类别, 因此训练的时候无需知道样本的类别信息. 这也使得该方法的计算复杂度与类别信息几乎无关, 可以轻易的推广到未知的类别当中. (当然也可以进行相关类别的训练, 对每个类别都训练一个检测器, 模型的总参数会随着类别数线性增加) SPPNet-ECCV2014(1) 提出了一种新的池化方法: 空间金字塔池化SPP: 可以接受任意尺寸的输入图片,并生成固定长度的表征向量 可以进行多尺度的联合训练, 提升模型精度 这种池化方法是比较general的, 可以提升不同模型架构的性能(分类任务) (2) 将SPP用于目标检测, 并且使用了先求卷积特征图谱, 后取区域的的策略(并不是首次提出):大大提升了模型训练和预测的速度(在预测阶段, 比R-CNN快24~102倍, 同时取得了更好的精度). PS:注1: 在特征图谱上使用检测方法不是该文首次提出, 而SPP的贡献在于结合了deep CNN结构强大的特征提取能力和SPP的灵活性, 使得精度和速度同时提高注2: 相比于R-CNN, SPPNet使用了EdgeBoxes( $0.2s/img$ )的方法来进行候选区域推荐, 而不是Selective Search( $1\sim 2s/img$ )注3: SPPNet在ILSVRC2014的目标检测任务上取得第二名, 在图片分类任务上取得第三名 FastR-CNNR-CNN 的效率很低, 低的原因主要是因为需要分别计算每一个 object proposal 的特征, 为此 Fast R-CNN 从共享卷积计算结果的角度出发, 提出了一个新的训练框架, 大幅提升了 R-CNN 检测模型的检测速度, 并且得益于新的损失函数和 RoI Pooling 的反向传播 机制, 使得 Fast R-CNN 的精度也有所提高. 具体来说, Fast R-CNN 网络首先会对整张图片进行计算并获得对应的特征图谱. 然后, 对于给定的每一个 object proposal, 都会通过 RoI Pooling 从特征图谱上提取到固定长度的特征向量, 每一个特征向量都会经过一系列全连接层, 最终被送到两个并行的输出层, 其中一个输出层是由全连接层和 Softmax 组成的分类层, 会预测物体属于每一个类别的可能概率, 另一个输出层是用于计算 bounding box 坐标偏移量的回归层(通过输入为 num_inputs, 输出为 class x 4 的全连接层实现). 同时, 由于 Fast R-CNN 使用了较多的全连接层, 因此原文利用了 SVD 奇异值分解来降低计算量, 提升模型速度. 简述 RoI Pooling 的原理和反向传播公式 简述 SVD 奇异值分解的原理 为什么 RoI Pooling 比 SPP 效果好 其他变动: 用softmax分类器替换了svm分类器 用Smooth L1损失替换了L2损失 在全连接层用SVD奇异值矩阵分解来降低计算成本 在训练SVM的时候不需要额外的硬盘存储特征 Faster R-CNN(NIPS, 2015)Faster R-CNN 的整体结构和 Fast R-CNN 差不多, 主要的区别在于 proposal 阶段的候选框生成方式不同, 在 Fast R-CNN 中, 使用的是 Selective Search 方式生成候选框, Faster R-CNN 则采用了卷积神经网络来生成 proposals, 这个网络就是 RPN 网络. RPN 网络通过 anchor 来生成不同大小的 proposals. 具体来说, 对于 backbone 网络的最后一层卷积层输出的特征图谱, 我们在它的上面添加一个核为 $3\times 3$ 大小的卷积层, 卷积层的卷积操作可以看做是在特征图谱上的滑动窗口, 在每一个滑动窗口处, 我们都会预测 $k$ 个 proposals, 这 $k$ 个 proposals 是根据 $k$ 个预定好的 anchors 获得的, RPN 的学习目标就是学的从 anchor 到 proposals 所需有变换函数. 得到这些 proposals 之后, 根据它们与真实物体的 IoU 大小来确定正负样本, 并按照 1:3 的比例进行采样, 将采样后的 proposals(训练时越 2000 个, 检测时越 300 个) 作为 Fast R-CNN 的输入. 在训练的时候, 可以采用 RPN 和 Fast R-CNN 交替训练的方式来共享卷积层的参数, 具体来说, 我们先对 RPN 进行训练, 使用 ImageNet 预训练的模型进行初始化(对于新添加的层, 使用均值 0 方差 0.01 的高斯分布或者 Xavier 初始化), 并对 RPN 网络的 regioin proposal 任务进行 fine-tuning; 然后我们利用训练好的 RPN 生成的 proposals 来训练 Fast R-CNN 网络, 网络的参数同样是用 ImageNet 预训练的模型进行初始化的, 所以说到这里两个网络之间还不具有参数共享的网络层. 当训练好 Fast R-CNN 以后, 我们用 Fast R-CNN 模型的参数来重新初始化 RPN 网络的参数, 同时要固定住这些来自 Fast R-CNN 网络的共享参数, 然后继续进行 region proposals 任务的 fine-tuning, 并且只对那些独属于 RPN 的网络层进行 fine-tuning. 最后, 同样保持 Fast R-CNN 中的共享层参数不变, 只对独属于 Fast R-CNN 的网络层进行 fine-tuning. 通过这种训练方式, 两个网络可以达到共享参数的目的. RPN 最终推荐的候选区域个数为 $W\times H \times k$ , $W\times H$ 为卷积特征图谱size, $k$ 为anchor boxes的数量. FCN (CVPR, 2015)全连接层本身可以看做是卷积核大小覆盖整个输入图谱的卷积层, 因此FCN 将传统 CNN 中的全连接层全部都转化成一个个的卷积层. 这么做有两个好处, 一个是可以接受任意尺度的图片输入, 另一个是可以通过让卷积网络在更大的输入图片上以滑动的方式一次性得到多个输出, 从而可以加快模型的计算速度. 在进行分割任务时, FCN 会利用最后一层的特征图谱进行像素级别的类别预测, 但是由于最后一层特征图谱的下采样步长较大, 使得图谱中缺少足够的低级语义信息, 因此, 直接在最后一层特征图谱上进行像素类别预测的效果不是特别好. 因此, FCN 利用反卷积对特征图谱进行放大, 反卷积相对于双线性插值来说有一个好处就是可以参数进行学习, 而不是固定不变的. 将多个反卷积层和激活层堆叠起来甚至可以学习到非线性的上采样过程. 然后将上采样以后的图谱和前一层卷积层输出的具有相同尺度的特征图谱进行融合, 这样, 融合后的特征图谱不仅包含了浅层的低级语义信息, 同时还包含了深层的高级语义信息, 这样预测出来的结果会更加精细, 在 FCN 中, 分别在步长为 16 和 步长为 8 的特征图谱进行了分割预测, 结果也显示越精细的特征图谱, 分割的结果也越好. 只不过随着步长的缩短, 获得的提升也慢慢变小了. FCN 是如何降低计算量的? YOLOv1 (CVPR, 2016)YOLOv1 首先将图像分成 $S\times S$ 的格子(cell), 如果一个目标物体的中心落入格子, 那么该格子就负责检测该目标. 每一个格子都会预测 B 个 bbox, 每一个 bbox 包含 5 个值, 分别是坐标和置信度(表示是否包含物体). YOLOv1 的损失函数综合了坐标, 分类标签和分类置信度三部分, 都使用了平方和损失进行计算, 并且通过不同的权重系数平衡了 loss 之间的贡献度. YOLOv1 的缺点: YOLO 的每一个网络只预测两个 boxes 和一套分类概率值(供两个 boxes 共享), 这导致模型对相邻目标的预测准确率下降, 因此, YOLO 对成群的目标识别准确率低 PS:注一: YOLO中采用 $S\times S$ 的网格划分来确定候选框, 这实际上是一种很粗糙的选框方式, 同时也导致了YOLO在面对小目标物以及群落目标物时, 性能较差.(因为YOLOv1的同一个cell无法预测多个目标, 也就是说YOLOv1理论上最多检测出49个物体). YOLOv2 OHEM (CVPR, 2016)提出了一种在线的难样例挖掘算法:作者根据每个RoIs的loss的大小来决定哪些是难样例, 哪些试试简单样例, 通过这种方法, 可以更高效的训练网络, 并且可以使得网络获得更小的训练loss. 同时, OHEM还具有以下两个优点: 消除FastR-CNN系列模型中的一些不必要这参数 , 这些参数大多都是为了解决难样例问题服务的, 在使用OHEM以后, 不仅无需在对这些超参数进行调优, 同时还能获得更好的性能表现. OHEM算法可以与其他多种提升模型精度的trick相结合, 对于大多数模型(R-CNN系列), 在使用了OHEM以后, 都能够获得精度上的提高, 可以看做是一种普适性的提升精度的方法. 注: 在实现OHEM上, 作者为了提升速度和效率, 特意设计了两个RoI网络, 以减少无用的计算. SSD (ECCV, 2016)SSD 是一种 one-stage 检测模型, 它最主要的特点就是使用了多尺度的特征图谱进行预测, 具体来说, SSD 在 VGGNet 之后又添加了五个卷积段, 每个卷积段都是用 $1\times 1$ 和 $3\times 3$ 大小的卷积核组成的, 然后在加上 VGGNet 的 conv4_3 卷积层, 总共可以得到六种不同尺度的特征图谱. 然后对数每一个特征图谱上的每一个 location, 都会有 $k$ 个 default boxes 作为初始的候选框, 不同尺度的特征图谱对应的 $k$ 的大小也不一定相同(4, 6, 6, 6, 4, 4). 也就是说, 对于一个尺度为 $m \times n$ 的特征图谱来说, 它具有的 default box 的个数就是 $m\times n\times k$, 又因为 one-stage 模型会在回归的同时进行分类, 因此, 最终输出结果的形式是一个 $m\times n\times k\times (c + 4)$ 的 tesor, $k$ 就代表了 $k$ 个 default box, $(c+4)$ 代表了每个 box 的分类得分和坐标偏移量. SSD 中如何计算 default box 的大小 (1) 在不同尺度的feature map上进行预测: YOLO的网格划分法精度较低, 但是速度很快, 而Faster的anchor box法, 精度很高, 但是速度很慢, SSD同时考虑了这两种方法的优劣, 提出了在不同层的feature map上面进行anchor box选取的方法, 并在这些不同尺度的feature map上面进行物体类别检测和box检测. (这一点不同于OverFeat和YOLO, 它们只会在同一个feature map上面进行分类预测和box回归). (2) 添加了一些额外的卷积层来进行预测任务:在对不同尺度的feature map进行预测时, SSD使用了额外的层进行预测. 在这些层上的每一个location, 都会产生响应的box (对于特征图谱的每一个像素点, 都会产生一定数量的anchor box), 并对box进行预测和回归 (3) 默认box和宽高比:在每一个feature map的cell里面, 预测默认框相对于cell的偏移量, 同时预测该box属于每个类别的score. 具体来说, 对于每一个cell(location), 都会有 $k$ 个默认box, 对于这 $k$ 个默认box中的每一个box, 都会计算 $c$ 个类别score和4个相对偏移量. 因此, 对于每一个location, 需要有 $(c+4)k$ 个输出, 也就是需要$(c+4)k$ 个卷积核. 又因为特征图谱的大小为 $mn$, 所以最终的输出为 $(c+4)kmn$, 其中 $kmn$ 为box的数量, $(c+4)$ 为每个box带有的值. (4) 使用了数据增广, 难样例挖掘, atrous算法等trick大幅度提升精度和速度这个其实算不上亮点, 只不过作者确实使用这些技术提升性能不少 R-FCN (NIPS, 2016)(1) 利用position sensitive score map将目标位置信息融合进RoI在一般情况下, 分类任务具有平移不变性, 而检测任务却要求对目标的平移做出正确响应. 在Faster R-CNN类的方法中RoI pooling之前都是卷积, 具有平移不变性, 但是一旦经过RoI pooling 之后, 后面的网络结果就不再具备平移不变性了. 因此, 本文提出了position sensitive score map来将目标位置的信息融合进RoI. (2) 让更多的层共享计算对于Faster R-CNN等基于感兴趣区域的检测方法来说, 实际上是 分成了几个subnetwork, 第一个用来在整张图上做比较耗时的conv, 这些操作与region无关, 是计算共享的. 第二个subnetwork是用来产生候选区域(如RPN), 第三个subnetwork是用来分类或者进一步对box进行回归的, 这个subnetwork和region是有关系的, 衔接在这个subnetwork和前两个subnework中间的就是RoI pooling. 本文希望将耗时的卷积都尽量移到前面共享的subnetwork上面去, 因此与FasterR-CNN相比(前91层共享, RoI pooling之后, 后10层不共享)不同, 将ResNet所有的101层都放在的前面共享的subnetwork中, 最后用来进行prediction的卷积只有1层, 大大减少了计算量. Speed-Accuracy TradeOff (CVPR, 2017)本文实现了一个灵活统一的目标检测框架, 并对三个主流的目标检测模型做了详细客观的分析和讨论通过该框架, 本文对目前主流的各个模型(Faster, R-FCN, SSD)影响精确度和速度的各个因素展开了详细的分析和讨论, 以此希望能够帮助从业者在面对真实应用场景时, 能够选择适当的模型来解决问题. 同时, 本文还发现了一些新的trick, 使得可以在保持精度的前提下, 提升模型的速度. DSSD (Arxiv, 2017)(1) 利用反卷积模块向特征图谱中添加更多的上下文信息主要是对SSD的一点改进, SSD使用了不同阶段的卷积特征图谱进行目标检测, 而DSSD受到人体姿态识别任务的启发, 将这些不同阶段的卷积特征图谱通过反卷积模块连接起来, 然后再进行目标检测的预测任务. (2), 预测模块采用Residual模块这个不算是亮点, 不过也是改动之一, 基本来说就说原始的SSD是直接在特征图谱预测结果并计算损失的, 而DSSD在预测之前会先经过一个Residual模块做进一步的特征提取, 然后在进行预测. FPN (CVPR, 2017)提出了多尺度的特征金字塔结构:将最后一层特征图谱进行不断尽快上采样, 并与每一个金字塔阶级的特征图谱进行加法合并操作, 得到新的表征能力更强的不同金字塔层次的特征图谱, 然后将RoI按照尺寸分别映射到这些特征图谱上, 再在每个特征图谱上进行类别和位置预测. 可以直观感受到, 这种多尺度的特征图谱在面对不同尺寸的物体时, 具有更好的鲁棒性, 尤其是在面对小型物体时. 同时, 这种特征金字塔结构是一种通用的特征提取结构, 可以应用到不同的网络框架中, 显著提高(5~8%)模型的召回率(因为提出了更多不同尺度, 不同特征信息的anchor box), 并且可以广泛提高(2~3%)模型的mAP. 思想: 浅层特征负责感知和检测小物体, 但是欠缺足够深度的高级语义信息, 因此将具备深层语义信息的特征层通过反卷积的方式扩大 feature map 的 size, 然后结合浅层和深层的特征图谱来进行预测. YOLOv2 (CVPR, 2017)YOLOv1 对于 bbox 的定位不是很好, 同时在精度上和同类网络还有一定差距, 所以 YOLOv2 对于速度和精度都做了很大的优化, 并且吸收了同类网络的有点, 主要包括以下几点: 提高图片分辨率: 将预训练阶段的输入图片的分辨率扩大到 $448\times 448$, mAP 提升了 4%. 使用 BN: 利用 BN 起到正则化作用, 从而舍弃了 dropout 层, mAP 提升了 2.4% 引入 anchor: 在检测时使用了 $416\times 416$ 的图片大小, YOLOv2模型下采样的总步长是 32, 因此最终得到的特征图大小为 $13\times 13$, 维度控制成奇数, 这样特征图谱恰好有一个中心位置, 对于一些大物体, 它们中心点往往落入图片中心位置, 此时使用特征图的一个中心点来预测这些物体的边界框相对容易些. YOLOv1 上一个 cell 的两个 boxes 共用一套分类概率值, 而 YOLOv2 的每个 anchor box 都会单独预测一套坐标, 一个置信度, 和一套分类概率值. (这和 SSD 类似, 不过 SSD 没有预测置信度, 而是将背景作为一个类进行处理) 用 k-mean 来确定 anchor 的初始形状: 根据训练集的聚类分析结果, 选取 $k$ 个聚类中心作为 anchor 的初始形状设置. Direct location prediction: Faster R-CNN 中的偏移公式是无约束的, 这样预测的边界框就可能落在图片的任何位置, 这导致模型训练时的不稳定性, 需要训练很长时间才能预测出正确的偏移量. 因此, YOLOv2 沿用了 YOLOv1 的方法, 预测的是边界框中心相对于网格单元位置的位置坐标. 综合 anchor + kmean + driect, mAP 提升了 5%. 利用 ResNet 的 identity mapping 获得细粒度的特征图谱: YOLOv2 的输入图片大小为 $416\times 416$, 最终 max pooling 以后得到 $13\times 13$ 大小的特征图谱, 这样的图谱预测大物体相对足够, 但是对于小物体还需要更精细的特征图, 因此 YOLOv2 利用 identity mapping 的思想将前一段的特征图谱 $26\times 26 \times 512$ reshape 成 $13\times 13 \times 2048$ 的特征图谱, 然后与原来的 $13\times 13 \times 1024$ 的特征图谱连接在一起形成 $13\times 13 \times 3072$ 的特征图谱, 然后在此特征图谱上进行预测. 该方法提升 mAP 1%. Multi-Scale Training: 在训练过程中, 每隔一定(10)的 iterations 之后就随机改变输入图片的大小, 图片大小为一系列 32 倍数的值(因为总的 stride 为 32): {320, 352, …, 608}. Darknet-19: YOLOv2 采用了一个新的模型(特征提取器), 包括 19 个卷积层和 5 个 maxpooling 层(卷积层分配为 1,1,3,3,5,5+1). Darknet-19 与 VGG16 模型的设计原则是一致的, 主要采用 $3\times 3$ 卷积和 $2\times 2$ 的 maxpooling 层. Darknet-19 最终采用 global avgpooling 做预测, 并且在 $3\times 3$ 卷积之间利用 $1\times 1$ 卷积来压缩特征图的通道数以降低模型的计算量和参数. YOLO 利用 anchor 会生成 $13\times 13\times 5 = 845$ 个候选区域框, 相比于YOLOv1的98个, 多多了, 所以会大大提高召回率, 但是会降低准确率. 下降的原因, 个人觉得是YOLO在采用anchor box获取候选框的同时, 依然采用YOLOv1的训练方法, YOLOv2的损失函数是一个非常复杂的形式, 导致其在更新参数时很容易顾不过来, 因此其出错的概率也相应提升. YOLOv2的训练包含三个阶段: 预训练(224), finetune(448), 检测模型训练 对样本的处理方式: 和 YOLOv1 相同, 对于训练图片中的 ground truth, 如果其中心落在了某个 cell 内, 那么该 cell 内的 5 个 anchor 就负责预测该物体, 并且最终只有一个边界框会与之匹配, 其他的会被 NMS 掉. 所以 YOLOv2 同样假定每个 cell 至多含有一个 ground truth, 而在实际上基本不会出现多于一个的情况. 与 gt 匹配的 anchor 会计算坐标误差, 置信度误差, 和分类误差, 而其他的边框则只计算置信度误差. YOLO 中一个 gt 只会与一个 anchor 匹配, 这与 Faster R-CNN 和 SSD 有所区别. 损失函数 YOLOv2 的 loss 形式如下: YOLOv3 DCN (ICCV, 2017)Deformable ConvNet 从目标检测任务中物体的几何形变角度发出, 在神经网络中引入了具有学习空间几何形变能力的可形变卷积网络(convolutional neutral networks). 该网络主要由两个模块组成, 分别是 deformable convolution 和 deformable RoI. 对于可形变卷积来说, 通过在每个卷积核的采样点上加一个偏移量来达到更好的采样效果. 对于可形变 RoI pooling 来说, 通过对传统的 RoI bins 添加一个偏移量还使得 RoI pooling 中的窗口具有能够适应几何形变的效果.Deformable ConNet 一个比较好的性质就是它不会对原有检测模型的整体结构进行更改, 也不会增加过多的计算量, 因此可以很容易的添加到现有的检测模型当中, 同时还可以和其他多种提升精度的 trick 叠加使用. Couple Net (ICCV, 2017)在进行区域分类时, 同时使用了全局信息,上下文信息和局部信息综合判断提出了一个新颖的全卷积网络, 并称之为CoupleNet, 它可以在目标检测中结合使用全局和局部信息. 具体来说, CoupleNet会将由RPN网络产生的候选区域送入到coupling module中, 该模块包含两个分支. 第一条分支利用position-sensitive RoI pooling来捕获物体的局部信息, 另一条分支利用RoI pooling对全局上下文信息进行编码. 接着, 我们设计了不同的coupling策略和归一化方法来使用这些不同分支格子的优势. Focal Loss (ICCV, 2017)(1) 分析并指出了One Stage方法精度不高的原因: 极度不平衡的正负样本比例: anchor是一种类似sliding windows的选框方式, 这会使得正负样本的比例接近1000:1, 而且绝大部分负样本都是easy example. 梯度优化过程被easy example过度影响: 这些easy example的loss虽然不高, 但由于数量众多, 最终合起来会对loss有很大的贡献, 从而导致优化的时候过度关注这些easy example, 这样会收敛到一个不够好的结果. (2) 提出了解决正负样本比例和easy example 问题的Focal loss: FL(p_t) = \begin{cases} -(1-p_t)^{\gamma}log(p_t) & 当y=1 \\ -p_t^{\gamma}log(1-p_t) & 当y=0 \end{cases}核心思想很简单, 就是在优化过程中逐渐减低那些easy example的权重, 这样会使得训练优化过程对更有意义的样本有更高的偏置. 所谓easy example指的就是那些预测概率与真实概率十分相近的样本, 这些样本已经被网络很容易切正确的分类了, 所以应该适当减少他们的loss以降低他们对参数更新的影响程度. 以上面的公式为例, 当真实标签为1时, 如果预测概率(假设二分类) $p_t$ 接近于1, 则此样本是easy样本, 因此, 前面的 $(1-p_t)^{\gamma}$ , 就会非常小, 起到了抑制简单样本的作用. 注1: $\gamma$ 的值越大, 则简单样本对于loss的贡献程度越小, 当 $\gamma = 0$ 时, 会退化到普通的交叉熵函数. 注2: 文中在使用 $\gamma$ 参数的情况下, 还是用了另一个参数 $\alpha$ ,如下所示: FL(p_t) = \begin{cases} -\alpha (1-p_t)^{\gamma}log(p_t) & 当y=1 \\ -(1-\alpha) p_t^{\gamma}log(1-p_t) & 当y=0 \end{cases}在经过一系列调参之后, 得到 $\alpha=0.25, \gamma = 2$ 为最优组合. 可以看到, 加在正样本前面的 $\alpha$ 要更小, 个人猜测这是因为使用了Focal Loss之后, 原本在数量上不在优势的前景区域或许在对loss的贡献度上反超了后景区域, 因此, 需要对前景区域赋予更低的权重. (3) 基于Focal Loss设计并实现了RetinaNet PS:注一: 为什么Focal Loss没有用在Two Stage方法上面? 这是因为以R-CNN为代表的一系列Two Stage会在区域候选推荐阶段采用两个问题来降低正负样本比例和easy example问题带来的影响: 采用NMS算法将物体位置候选框降低到一到两千个，更重要的是，这一到两千个可能位置并不是随机选取的，它们移除了大量的易分类负样本（背景框） 采用了biased-minibatch的采样策略, 比如，保证正样本和负样本的比例为1：3进行训练（这其实相当于起到了 $\alpha$ 因子的作用 Mask R-CNN (ICCV,2017)Mask R-CNN 的大体框架还是 Faster R-CNN, 它在 Faster R-CNN 模型中添加了一个与分类和回归分支平行的掩膜预测分支. 掩膜分支(mask branch) 是一个小型的 FCN 网络, 它会作用在每一个 RoI 上, 以像素到像素的方式来预测一个分割掩膜. Mask R-CNN 的掩膜预测分支对于每一个 RoI 的输出维度为 $Km^2$, 也就是每一个类别都会单独输出一个 $m\times m$ 大小的掩膜. 在预测掩膜时非常关键的一点就是要对分类任务和分割任务解耦, 否则对于多分类任务会引起类别之间的竞争, 因此, Mask R-CNN 使用了基于单像素的 sigmoid 二值交叉熵来替换基于单像素的 Softmax 多项式交叉熵. 另外, 在 Faster R-CNN 中使用的 RoI pooling 需要经过两次量化取整(图像坐标到特征图谱坐标, 特征图谱划分固定网格)才能获得固定长度的特征向量. 这种粗糙的量化操作会造成 RoI 和特征向量之间的不对齐, 这对精度要求较高的的分割任务来说有较大影响. 为了克服这个问题, Mask R-CNN 提出了 RoI Align 层来替代 RoI Pooling, RoI Align 的核心思想就是避免在 RoI 边界上或者 bins 中执行任何量化计算. 它在处理每一个 RoI 的时候, 会保持其浮点边界的值而不进行量化操作, 然后将 RoI 划分成的 $k\times k$ 大小的网格, 对于每一个网络, 都会固定四个采样点, 并利用双线性插值法来计算每个采样点的数值, 最后根据这些数值进行池化操作. 除了这些比较重要的点之外, Mask R-CNN 也有一些其他的优化, 比如说更多的 anchor, 更大的 batch size, 更强的 backbone 网络(ResNeXt+FPN)等等. YOLOv3 (Arxiv, 2018)YOLOv3 加入了更多被验证过的有效技术, 使得 YOLO 模型的 mAP 可以与 SSD 系列相媲美, 同时速度依然很快(约为 SSD 的三倍). YOLOv3 的改进主要如下: Bounding Box Prediction: YOLOv3 使用了和 YOLOv2 相同的 bbox 回归策略, 都是预测相对于 cell 左上角的偏移量进行回归. YOLO 中每个 gt box 只会与负责它的 cell 中的一个 anchor box 匹配(IoU 最大), 其他的 anchor box 只会计算 objectness 置信度损失, 而不会计算坐标和分类损失. 类别预测: 由于有的物体可能不止属于一个标签, 如 “人” 和 “女人”. 因此, 为了减少类别之间的对抗性, YOLOv3 没有使用 softmax 计算分类损失, 而是采用了 二值交叉熵 来预测类别(属于某类或其他类). 采用特征金字塔: 使用类似于 FPN 的方法(upsample and top-down)提取到不同尺度的特征图谱(文中使用了3个), 在每个尺度的特征图谱上的都会预测三个boxes, 因此, 每个尺度的特征图谱的输出为: $N\times N \times [3\times (4+1+80)]$. 在确定 anchor 大小时, 利用 kmean 聚类选出 9 个聚类中心, 然后划分成 3 个簇分别赋给 3 个尺度的特征图谱. Darknet-53: 使用了残差模块的思想, 提出了层数为 53 的 Darknet-53 网络 (1, 2, 8, 8, 4). 在 ImageNet 上, Darknet-53 is better than ResNet-101 and 1.5x faster. Darknet-53 has similar performance to ResNet-152 and is 2x faster. 在使用了 anchor 和 multi-scale 之后, YOLOv3 在小物体的检测上有所改善.Focal Loss 对 YOLOv3 不起作用的原因可能是 YOLO 的选框策略和损失函数(objectness+cls)使得 YOLO 在背景样本不均衡问题上影响较小. RefineDet (CVPR, 2018)RefineDet 从 SSD 的 bbox 回归上入手, 分析了相对于 one-stage 方法来说, two-stage 方法精度较高的原因主要有三点: (1) 使用了启发式的规则(正负样本比例控制在 1:3)来处理样本不均衡问题; (2) 具有两个级联的物体边框回归阶段(这样可以使得回归后的 bbox 更加精确); (3) 利用两级特征来描述一个物体, 以 Faster R-CNN 为例, 第一阶段提取的特征是针对于有无物体的二分类问题, 第二阶段则是针对物体具体类别的多分类检测问题.而复杂的结构和流程就意味着效率的牺牲和计算时间的延长, 因此, one-stage 方法的特点就是简化检测流程, 直接在特征图谱进进行分类和回归任务训练. 作者为了提升 one-stage 方法的性能, 结合one-stage方法和two-stage方法各自的优势, 提出了一个新的的检测模型: 该模型主要包含两大模块, 分别是 Anchor Refinement Module(ARM) 和 Object Detection Module(ODM).具体来说, ARM 的作用有两点: (1), 移除 negative anchors 来减少二分类器的搜索空间;(难负样例挖掘, 控制样本不均衡问题) (2), 粗略的调整 anchors 的 locations 和 sizes, 为后续的回归器提供更好地初始 anchors. ODM 的作用是: 将 ARM refine 后的 anchor 作为输入, 进一步的提升 bbox reg 和 multi-class pred 的精度. 在代码具体实现上:RefineDet 的网络框架设计和 SSD 类似, 首先在常规的 SSD 金字塔特征图谱上(即: conv4_3, conv5_3, conv_fc7, conv6_2) 产生预定义的固定数量的 default boxes, 然后每一个特征图都会有两个子网络分支, 分别为 anchor 的回归网络和二分类预测网络. 这一步产生的负样本置信度高于 0.99 的 anchor 不会传入 ODM 阶段. 然后, 将 ARM 阶段得到的特征图谱结合从深层网络反卷积来的特征图谱通过 TCB 单元得到新的特征图谱, 并传入 ODM 中(由两个子网络构成, 分别进行回归和分类任务), 最终输出所有物体类别的 scores 以及相对于 refined anchor box 的唯一(第二次回归). RefineNet 使用了 two-stage 的边框回归过程, 为什么还说它是 one-stage 模型? SNIP (CVPR, 2018) RelationNet (CVPR, 2018) Cascade R-CNN (CVPR, 2018)本文针对检测问题中正负样本区分的 IoU 阈值选择问题提出了一种新的目标检测框架, Cascade R-CNN在 two-stage 的目标检测模型当中, 需要设置 IoU 阈值来区分正样本和负样本, 通常, 阈值选的越高, 正样本的框就与真实框越接近, 但是这样就会使得正样本的数量大大降低, 训练时容易产生过拟合问题, 而如果阈值选的较低, 就会产生大量的假正例样本. 根据经验和实验证明可知, 当输入的 proposals 和真实框的 IoU 的值, 与训练器训练时采用的 IoU 的阈值比较接近的时候, 训练器的性能会比较好, 为此, 作者提出了一种级联式的阈值训练方法, 先在较低的阈值上训练检测器, 得到具体更高 IoU 的候选框输出, 然后在此基础上进行训练, 不断提升 IoU 的阈值, 这样一来, 最终生成的候选框质量会变得更高 (与真实框的 IoU 更大). 作者提出这种框架的启发来自于图1(c), 整体来说, 输入的 proposals 的 IoU 在经过检测器边框回归以后, 其输出的边框与真实框会有更大的 IoU, 因此可以将这个具有更大 IoU 的框作为下一个检测器的输入, 同时调高训练时的 IoU, 进而得到质量更高的框 DetNet (ECCV, 2018) Fitness NMS (ECCV, 2018) STDNet (ECCV, 2018) RFBNet (ECCV, 2018)本文从感受野大小的角度出发, 提出了 RFB 模块, 可以融合多个感受野特征, 进而提升轻量级网络(SSD)的特征表达能力相比于不断增加模型复杂度(深度,宽度)来增强特征的表达能力, 本文通过一种人工设计的机制来增强轻量级模型的特征表达能力, 以期获得一种既快又好的检测模型. Group Normalization (ECCV, 2018)针对BN对batch size的依赖问题, 提出了一种新的通用型归一化方法提出了一个用于替代BN的简单算法, 称之为GN(Group Normalization). GN将输入图谱的通道分成不同的组, 并且计算每一组的mean和variance, 然后将其进行归一化. GN的计算复杂度与batch size 的大小是相互独立的, 并且它的准确度在不同范围内的batch size下仍然是稳定的. 并且在整体表现和不同任务上的效果均强于其他类型的归一化方法(LN,IN等) SoftNMS (ICCV, 2017)提出了一种NMS的变体, 通过利用该变体, 基本上可以提升任何模型的检测准确率作者们提出了一种新式的NMS算法, 并且利用该算法, 可以普遍提高当前现有模型的召回率(尤其是面对重叠程度大的物体), 同时, 由于可以不增加复杂度的情况下直接用该算法替换传统NMS算法, 因此, 在替换SoftNMS时, 无需更改模型的任何参数, 也无需重新训练模型, 就可以达到提升召回率的作用. (对mAP的提升大约为1%左右) Non-local Neural Networks (CVPR, 2018)1) 提出了 non-local operations 来解决 CNN 网络中的 long-range dependencies 问题传统 CNN 的卷积操作由于输出神经元只会与输入图谱上的一部分区域有关系, 因此, 在面对那些 long-range dependencies 的时候, 往往不能捕获到足够的信息来表征数据, 为此, 作者提出了 non-locl operations, 其相当于构造了一个和特征图谱尺寸一样大的卷积核, 从而可以维持更多信息. 2) non-local module 可以作为一种通用的模块应用在各项任务上作者通过实验证明, non-local 的有效性不仅仅局限于某一类特殊任务(如视频分类), 同时还可以轻易的整合到其他现有模型中, 如将其整合到 MaskR-CNN 中, 可以当做是一种 trick 来提供 MaskR-CNN 在目标检测/分割, 姿态识别等任务上的性能表现. SofterNMS (Arxiv, 2018)提出了一种新的边框回归损失函数和NMS算法作者提出了一种 基于KL散度的边框回归损失函数, 可以同时学习到边框的形变量和位置变化量. 最终产生的位置变化量会与位置的精确度有很强的联系, 然后将其使用在本文提出的 新的NMS 算法上, 以此提高准确度. CornerNet (ECCV, 2018)在 CornerNet 中, 我们利用一对关键点(左上角和右下角)来检测物体. 卷积网络会预测两组热图(heatmaps)来表示不同物体类别的 corners locations, 一组用于表示左上角, 一组用于表示右下角. 同时, 网络还会为每个检测到的 corner 预测一个 embedding vector, 其特点是同一个物体的两个角点(corners)的 embeddings vector 之间的距离会非常小. 为了产生更紧密的边界框, 网络还会预测偏移量, 以稍微调整焦点的位置. 得到预测的 heatmaps, embeddings 和 offsets 之后, 我们会使用简单的后处理算法来获取最终的 bboxes. PFPNet (ECCV, 2018) Pelee (NIPS, 2018)本文在 DenseNet 的基础上进行改进, 提出了一个适用于移动设配的轻量级模型(模型大小只有 MobileNet 的 66%). 主要的改进有: 受 Inception 结构启发的 Two-way Dense Layer 受 Inception-V4 启发的 Stem Block 更改了 Bottleneck 结构中的通道数量 移除了 DenseNet 的压缩因子 用传统的后激活方式(conv+bn+relu)替换预激活来加快 inference 速度 另外, 对于目标检测模型, 也在 SSD 的基础上进行有速度优化, 主要有: 不使用 $38\times 38$ 的大特征图谱进行预测 在预测层(head)设计了 Residual Prediction Block 结构. 在 Residual Prediction Block 结构中使用了更小的卷积核($1\times 1$)进行预测. MetaAnchor (NIPS, 2018) SNIPER (NIPS, 2018) M2Det (AAAI, 2019)M2Det 从特征金字塔的构建角度出发, 认为现有的 sota 的特征金字塔的构建方式存在两个缺点, 一是直接简单利用了 backbone 网络固有的金字塔式的特征图谱来构建, 但这些 backbone 实际上是针对分类任务设计的, 因此不足以表示针对目标检测任务的特征. 二是构建的金字塔中每一个尺度的特征仅仅来自于 backbone 中单一层级(level)的特征. 这样一来, 小尺度的特征图谱往往缺少浅层低级的语义信息, 而大尺度的特征图谱又缺少深层的高级语义信息(同尺寸的物体可能本身所需的语义层级不同, 如人和交通灯). 因此, 作者就提出了融合多个层级特征的 MLFPN (multi-level FPN). MLFPN 主要由三个模块组成, 分别是: 特征融合模块(Feature Fusion Module, FFM), 简化的 U-shape 模块(Thinned U-shape Module, TUM), 以及尺度特征聚合模块(Scale-wise Feature Aggregation Module, SFAM). 首先, FFMv1 融合了 backbone 网络中浅层和深层的特征来生成 base feature, 具体来说就是 VGGNet 的 conv4_3 和 conv5_3. 其次, 若干个 TUMs 和 FFMv2 交替连接. 具体的说, 每一个 TUM 都会生成多个不同尺度的 feature maps. FFMv2 融合了 base feature 和前一个 TUM 输出个最大的 feature map. 融合后的 feature maps 会被送到下一个 TUM 中. 最终, SFAM 会通过按照尺度划分的特征连接操作(scale-wise feature concatenation operation)和通道注意力机制(channel-wise attention mechanism)来聚集 multi-level multi-scale features, 形成最终的特征金字塔结构. 最后用两个卷积层在特征金字塔上分别进行回归和分类预测. 可以看出, 整体的流程和 SSD 类似, 不同之处就在于特征金字塔的构建方式. Bag of Freebies (Arxiv, 2019)Fovea: 视野(物体)的中心具有最高的视觉敏感度。 FoveaBox 的整体结构比较简单, 由一个 Backbone 网络和两个分支网络组成, backbone 负责提取特征, 分支网络一个负责像素级别的分类, 另一个在每个像素点上进行 bounding box 的回归预测, 因此, 两个子网络的输出分别是 $W\times H\times K$ 和 $W\times H\times 4$. 同时, FoveaBox 的 backbone 网络上还使用了 FPN 来构建多尺度的特征金字塔, 以此来解决多尺度检测的问题, 参考文献： https://github.com/hoya012/deep_learning_object_detection Deep Learning for Generic Object Detection: A Survey]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>知识点梳理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inception V1 (GoogLeNet)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-InceptionV1%2F</url>
    <content type="text"><![CDATA[文章: Going Deeper with Convolutions作者: Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich备注: Google, Inception V1 核心亮点摘要文章提出了一个深度卷积神经网络结构，并取名为Inception。该模型最主要的特点在于提高了网络内部计算资源的利用率。在保证计算负载不变的前提下，通过人工设计提升了网络的深度和宽度。该模型基于Hebbian原理和多尺度处理的intuition来提高性能。关于该模型的一个实例正是提交在ILSVRC14上的GoogLeNet，一个22层深的深度网络，主要针对分类和检测任务。 介绍简要介绍了深度学习和神经网络技术近年来在图像分类和目标检测任务的发展。文章主要关注针对计算机视觉的高效深度神经网络，取名为Inception，名字来自于NIN。在文章中，“deep”具有两层含义：第一，指代文章新提出的Inception module，第二是指网络的深度。通常情况下，可以将Inception model视作NIN的“逻辑顶点”。 相关工作略 动机和High Level的考虑提高深度卷积网络最直接的方式就是增加它们的size，包括网络的深度（层数）和宽度（每层的神经元个数），这对于高质量的网络结构来说是ok的，尤其是在拥有大量优质数据的情况下。但是，这种方法存在这两个主要的缺点： 更大的size通常意味着更多的参数，这会使得网络更容易过拟合，尤其是在数据标签有限的情况下。由于获得大量优质数据具有一定难度，因此这往往会称为一个主要的瓶颈。 第二个缺点就是更大的size往往需要消耗更多的计算资源 文章认为解决以上问题的一个经济可行的办法是将全连接层置换成稀疏连接结构，甚至是在卷积内。 目前的硬件结构在面对非均匀分布的稀疏数据结构时，计算效率很低。 为此，文章希望找到一个新的结构，可以更高效的处理稀疏矩阵的运算。 文章通过多个实验验证了Inception模型在面对图像分类和检测问题时，可以取得十分好的效果。但是，对于Inception model是否能够成为其他领域任务的指导原则，还尚未有定论，需要更多的验证和实验才能说明。 框架细节Inception模型的一个核心思想在于找到 卷积网络中的最优局部稀疏结构可以在多大程度上被稠密组件近似和覆盖 。需要注意，由于假设了平移不变性，因此本文的模型将从卷积模块中开始建立，本文所需要做的就是找到一个局部最优结构，然后将这些结构在空间上组合起来。 为了避免path-alignment问题，现在滤波器大小设值为1×1,3×3,和5×5。 由于pooling层的重要性，本文才采用了pooling层。 将上面的Inception模块叠加起来，形成一个整体的模型。 但是直接叠加会使得向量维度剧增，因此，通过1×1卷积来控制维度。 当max pooling层的stride为1时，并不会缩小输出的feature map的size，只会影响depth的值。 关于此结构的一个好处在于它可以提高神经元的个数，同时避免网络不受控制的提升计算机复杂度。 GooLeNet(Inception V1) GoogLeNet(也叫做Inception V1)的网络结构图细节如下： GoogLeNet网络结构明细表解析如下： 0、输入 原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。 1、第一层（卷积层） 使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作 2、第二层（卷积层） 使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作 经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作 3a、第三层（Inception 3a层） 分为四个分支，采用不同尺度的卷积核来进行处理 （1）64个1x1的卷积核，然后RuLU，输出28x28x64 （2）96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128 （3）16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32 （4）pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32。将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256 3b、第三层（Inception 3b层） （1）128个1x1的卷积核，然后RuLU，输出28x28x128 （2）128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192 （3）32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96 （4）pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64。 将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480 第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复。 简述一下 GoogLeNet 采用多个卷积核的原因Inception Module这类结构非常看中模型在局部区域的拟合能力。它们认为：一张图像通常具有总体特征和细节特征这两类特征，一般小卷积核能够更好的捕捉一些细节特征，随着深层网络的小卷积不断计算下去，总体特征也会慢慢的被提炼出来，但是这样存在一个问题，那就是在如果只采用小卷积，那么网络结构的前段一般只有细节特征，后段才慢慢有一些总体特征，而我们希望这两方面的特征总是能够一起发挥作用，因此，Inception 模型考虑采用更多不同尺寸的卷积核来提取特征，并把这些特征连接起来，一起送到后面的网络中去计算，使得网络可以获取到更多的特征信息。 Inception 中为什么使用 1×1 卷积层关于Inception Module，有一种很直接的做法就是将1×1,3×3,5×5卷积和3×3 max pooling直接连接起来，如下面的左图所示，但是这样的话就有个问题，那就是计算量增长太快了。 为了解决这个问题，文章在3×3和5×5的卷积之前，3×3max pooling之后使用了1×1卷积，使其输出的feature map的depth降低了，从而达到了降维的效果，抑制的过快增长的计算量。 1×1卷积的作用是什么？1x1卷积的主要目的是为了减少维度，降低计算量. 1×1的卷积核，在一定程度上可以实现全连接层：具体的操作是，输入是224x224x3 的图像，假设经过变换之后最后一层是[7x7x512]的，那么传统的方法应该将其展平成为一个7x7x512长度的一层，然后做全连接层，假设全连接层为4096×1000层的（假设有1000个分类结果）。 那么用1×1卷积核怎么做呢，因为1×1卷积核相当于在不同channel之间做线性变换，所以： 先选择7×7的卷积核，输出层特征层数为4096层，这样得到一个[1×1×4096]层的 然后再选择用1×1卷积核，输出层数为1000层，这样得到一个[1×1×1000]层的 用卷积层代替全连接层的好处这样做其实有非常多的好处，比如上面的例子中输入是224x224x3 的图像，如果此时图像变得更大了，变成384x384大小的了，那么一开始按照32作为步长来进行卷积操作，最后还按照这个网络结构能得到一个[6×6×1000]层的，那么前面那个[6×6]有什么用呢，这个代表每一个位置上，其属于1000个分类结果中的打分，所以这在图像分割等领域等领域有着非常重要的作用【之前一篇论文就是用的这种方法Fully Convolutional Networks for Semantic Segmentation】。 Inception 中为什么使用全局平均池化层最主要的作用就是大大降低了特征图谱的维度, 使得模型的参数量大大减少, 参数量的减少从另一方面来说相对于对网络模型的复杂度做了正则化, 从而在一定程度上可以防止网络模型出现过拟合问题. 为什么使用侧枝为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）。辅助分类器是将中间某一层的输出用作分类，并按一个较小的权重（0.3）加到最终分类结果中，这样相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供了额外的正则化，对于整个网络的训练很有裨益。而在实际测试的时候，这两个额外的softmax会被去掉。也就是说在测试的时候，只会用最后的softmax结果作为分类依据。 当时Inception网络还是太深了，不好训练，因此网络中还加了两个侧枝，通过中间层的feature map，来得到预测结果（有了ResNet的shortcut以后，这种侧枝用的比较少了）。 GoogLeNet 在哪些地方使用了全连接层在两个侧枝使用了卷积+FC+FC+SoftmaxActivation的结构，在最后一层使用了全局平均池化+FC+SoftmaxActivation的结构。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[itertools模块-高效的迭代器操作]]></title>
    <url>%2Fz_post%2FPython-itertools%2F</url>
    <content type="text"><![CDATA[http://funhacks.net/2017/02/13/itertools/#product itertools 模块提供的迭代器函数有以下几种类型: 无限迭代器: 生成一个无限序列, 比如自然数序列: 1, 2, 3, 4, … 有限迭代器: 接受一个或多个序列作为参数, 进行组合, 分组, 过滤等操作 组合生成器: 序列的排列, 组合, 求序列的笛卡尔积等等 无线迭代器优先迭代器组合生成器productproduct 用于求多个可迭代对象的笛卡尔积, 它跟嵌套的 for 循环等价, 其一般使用形式如下:1product(iter1, iter2, ..., iterN, [repeat=1]) 其中, repeat是一个关键字参数, 用于指定重复生成序列的次数]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++创建对象时new与不new的区别]]></title>
    <url>%2Fz_post%2FCpp-%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E6%97%B6new%E4%B8%8E%E4%B8%8Dnew%2F</url>
    <content type="text"><![CDATA[C++在创建对象的时候可以采用两种方式：（例如类名为Test） Test test 或者 Test* pTest = new Test()。这两种方法都可以实例化一个对象，但是这两种方法有很大的区别，区别在于对象内容所在的内存空间不同，众所周知，内存的分配方式有三种（1）从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static 变量。（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束后在将这些局部变量的内存空间回收。在栈上分配内存空间效率很高，但是分配的内存容量有限。（3） 从堆上分配的。程序在运行的时候用 malloc 或 new 申请任意多少的内存，程序员自己负责在何时用 free 或 delete 释放内存。那么当使用Test test给对象分配内存空间的时候，是分配在堆中的还是栈中的呢？ 在不使用new创建对象时，对象的内存空间是在栈中的，其作用范围只是在函数内部，函数执行完成后就会调用析构函数，删除该对象。 而使用new创建对象是创建在堆中的，必须要程序员手动的去管理该对象的内存空间。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown语法]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-MarkDown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[删除线~~markdown~~: markdown 下划线&lt;u&gt;markdown&lt;u&gt;: markdown 引用&gt;: markdown]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[VIM 指令速查及常用技巧]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-VIM%E6%8C%87%E4%BB%A4%E9%80%9F%E6%9F%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/weixin_41278720/article/details/83449518 VIM 常用指令多行编辑: shift+v, 选择多行, shift+A/I, 插入模式进行编辑 fa,i,r,o,A,I,R,O 进入编辑模式h,backspace 左移动 l,space 右移动 j 下移动 k 上移动0 移动到行首$ 移动到行末 1$表示当前行的行尾，2$表示当前行的下一行的行尾b 按照单词向前移动 字首e 按照单词向后移动 字尾w 按照单词向后移至次一个字首H 移动到屏幕最上 非空白字M 移动到屏幕中央 非空白字L 移动到屏幕最下 非空白字G 移动到文档最后一行gg 移动到文档第一行v 进入光标模式，配合移动键选中多行Ctrl+f 向下翻页Ctrl+b 向上翻页u 撤销上一次操作.. 回到上次编辑的位置dw 删除这个单词后面的内容dd 删除光标当前行dG 删除光标后的全部文字d$ 删除本行光标后面的内容d0 删除本行光标前面的内容y 复制当前行，会复制换行符yy 复制当前行的内容yyp 复制当前行到下一行，此复制不会放到剪切板中nyy 复制当前开始的n行 全选（高亮显示）：按esc后，然后ggvG或者ggVG 全部复制：按esc后，然后ggyG 全部删除：按esc后，然后dG 二、复制多行任务：将第9行至第15行的数据，复制到第16行 方法1：（强烈推荐）：9，15 copy 16 或 ：9，15 co 16由此可有：：9，15 move 16 或 :9,15 m 16 将第9行到第15行的文本内容到第16行的后面 ubuntu系统, 默认不支持系统剪切板与vim的交互, 需要先安装一个东西: sudo apt-get install vim-gnome 再set clipboard=unnamed 然后就可以使用ggyG了 选中指定行：方法3：把光标移到第9行 shift + v再把光标移动到第15行 Vim 有12个粘贴板依次编号为：0、1、2、…、9、a、”、+，其中 + 号为系统粘贴板，” 为临时粘贴板。系统剪切板中的内容可在其他程序中使用。上面的复制指令都可以配合剪切板进行操作。kj “nyw 复制当前单词到 n 号剪切板（双引号开始）“np 粘贴 n 号剪切板内容到当前位置后“+Y 复制当前行到系统剪切板“+nY 复制当前行往下 n 行到系统剪切板“+p 粘贴系统剪切板内容到当前位置后 “+yy // 复制当前行到剪切板“+p // 将剪切板内容粘贴到光标后面“ayy // 复制当前行到寄存器 a“ap // 将寄存器 a 中的内容粘贴到光标后面 p,P,. 粘贴ddp 当前行和下一行互换位置J 合并行Ctrl+r 恢复刚才撤销（u）的动作Ctrl+z 暂停并退出ZZ 保存离开xp 交换字符后面的交换到前面~ 更换当前光标位置的大小写，并光标移动到本行右一个位置，直到无法移动 Ctrl+e/y 向下/上滚动Ctrl+b 向上翻页b 按照单词向前移动 字首B 按照单词向前移动 字首 忽略一些标点符号e按照单词向后移动 字尾E 按照单词向后移动 忽略一些标点符号w 按照单词向后移至次一个字首W 按照单词向后移至次一个字首 忽略一些标点符号 H 移动到屏幕最上 非空白字M 移动到屏幕中央 非空白字L 移动到屏幕最下 非空白字 G 移动到文档最后一行gg 移动到文档第一行( 光标到句尾) 光标到局首{ 光标到段落开头} 光标到段落结尾nG 光标下移动到n行的首位n$ 光标移动到n行尾部n+ 光标下移动n行n- 光标上移动n行 zz将当前行移到屏幕中部，zb移到底部,zt 顶部 * 向下查找同样光标的字符# 向上查找同样光标的字符/code 查找 code 一样的内容，向后?code 查找 code 一样的内容，向前n 查找下一处N 查找上一处ma 在光标处做一个名叫a的标记 可用26个标记 (a~z)`a 移动到一个标记ad`a 删除当前位置到标记a之间的内容:marks 查看所有标记 :q 一般退出:q! 退出不保存:wq 保存退出:w filename 另存为 filename:jumps 历史编辑文档记录 ctrl+i，ctrl+o跳转位置, Ctrl+f 向文件尾翻一屏幕Ctrl+b 向文件首翻一屏幕Ctrl+d 向文件尾翻半屏幕Ctrl+u 向文件首翻半屏幕 i 在光标前I 在当前行首a 在光标后A 在当前行尾部o 在当前行下新开一行O 在当前行上新开一行r 替换当前字符R 替换当前行及后面的字符，直到按esc为止s 从当前行开始，以输入的文本替代指定数目的字符S 删除指定数目的行，并以输入的文本替代ncw,nCW 修改指定数目n的字符nCC 修改指定数目n的行 x 删除当前光标字符X 删除光标前字符nxnX dw 删除到下一个单词开头de 删除到本单词末尾dE 删除到本单词末尾包括标点在内db 删除到前一个单词dB 删除到前一个单词包括标点在内 ndw,nDW 删除光标开始及其后 n-1 个worddw 删除这个单词后面的内容dd 删除光标当前行dG 删除光标后的全部文字d$ 删除本行光标后面的内容d0 删除本行光标前面的内容ndd 删除当前行，以及其后的n-1行x 删除一个字符，光标后X 删除一个字符，光标前Ctrl+u 删除输入模式下的输入的文本 :split 创建新窗口Ctrl+w 切换窗口Ctrl-w = 所有窗口一样高Ctrl-w+方向键 多窗口视图切换 :args 列出当前编辑的文件名:next 打开多文件，使用 n(Next) p(revious) N(ext) 切换:file 列出当前打开的所有文件 替換（substitute） :[range]s/pattern/string/[c,e,g,i]]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>VIM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CUDA并行程序设计-GPU编程指南》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CUDA%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1_GPU%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[前言部分——本书编排： 第一章：从宏观上介绍流处理器（streaming processor）的演变历史。 第二章：介绍并行编程的概念，建立基本认识。 第三章：详尽地讲解CUDA设备及与其紧密相关的硬件和架构。 第四章：介绍了如何在Windows、Mac和Linux等不同操作系统上安装和配置CUDA软件开发工具包。 第五章：介绍CUDA线程模型。 第六章：详细讲解了不同类型内存的工作机制。 第七章：详述了如何在若干任务中恰当地协同CPU和GPU。 第八章：介绍如何在应用程序中编写和使用多GPU。 第九章：对CUDA编程中限制性能的主要因素予以讲解。 第十章：介绍了CUDA软件开发工具包的示例和CUDA提供的库文件。 第十一章：关注构建自己的GPU服务器或者GPU集群时的几个问题。 第十二章：检视多数程序员在开发CUDA应用程序时易犯的错误类型。 第一章 超级计算机简史简介``]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[json模块]]></title>
    <url>%2Fz_post%2FPython-json%2F</url>
    <content type="text"><![CDATA[JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式, 易于阅读和编辑. 使用JSON函数之前需要导入json库: import json json.dumps该函数用于将dict类型的数据转换成str, 这是因为我们不能直接将字典类型的数据写入到文件中, 因此需要先将其转换成字符串才能进行写入 函数原型:123json.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding="utf-8", default=None, sort_keys=False, **kw) 示例:123456789101112131415json_dict = &#123; "info": &#123; "contributor": 'xxx', 'year': 2019 &#125;, 'license': 'xxx', 'images': [&#123;&#125;, &#123;&#125;, &#123;&#125;], 'anotations': [&#123;&#125;, &#123;&#125;, &#123;&#125;], 'categories': [&#123;&#125;, &#123;&#125;],&#125;json_str = json.dumps(json_dict)json_save_path = 'test.json'with open(json_save_path, 'w') as json_file: json_file.write(json_str) json.loadsjson.loads()用于将str类型的数据转换成dict, 注意是字符串数据, 而不是文件 json.dumpjson.dump() 用于将 dict 类型的数据之间转换成str并写入到 json 文件中, 例如, 下面两种写入方式是等价的 12345678910json_dict = &#123;'a': 123, 'b': 456&#125;json_save_file = 'save_test.json'# 方式一json_str = json.dumps(json_dict)with open(json_save_file, 'w') as json_file: json_file.write(json_str)# 方式二json.dump(json_dict, open(json_save_file, 'w')) json.load可以解析json文件, 之后可以像使用字典一样进行操作. 假如 json file 内容如下所示:12345678910&#123; &quot;info&quot;: &#123; &quot;contributor&quot;: &apos;xxx&apos;, &apos;year&apos;: 2019 &#125;, &apos;license&apos;: &#123;&#125;, &apos;images&apos;: [&#123;&#125;, &#123;&#125;, &#123;&#125;, ...], &apos;anotations&apos;: [&#123;&#125;, &#123;&#125;, &#123;&#125;, ...], &apos;categories&apos;: [&#123;&#125;, &#123;&#125;, ...],&#125; 12345json_file_path = os.path.abspath('test.json')with open(json_file_path, 'r') as json_file: json_dict = json.load(json_file) print(json_dict.keys()) # 'info', 'license', 'images', 'annotations', 'categories']]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HelloCUDA]]></title>
    <url>%2Fz_post%2FCUDA-CUDA%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0-HelloCUDA%2F</url>
    <content type="text"><![CDATA[1234567891011121314//hellocuda.cu#include &lt;iostream&gt;#include "stdio.h"__global__ void kernel(void)&#123; printf("hello, cvudakernel\n");&#125;int main(void)&#123; kernel&lt;&lt;&lt;1,5&gt;&gt;&gt;(); cudaDeviceReset(); return 0 ;&#125; 在命令行执行12$nvcc hellocuda.cu -o hellocuda$./hellocuda 输出结果：12345hello, cvudakernelhello, cvudakernelhello, cvudakernelhello, cvudakernelhello, cvudakernel]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的构造函数和析构函数]]></title>
    <url>%2Fz_post%2FCpp-%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C++提供了一些特殊的成员函数，它们会在一定条件下自动创建: 默认构造函数 复制/拷贝构造函数 移动构造函数 赋值运算符 移动赋值运算符 地址运算符 带参数的构造函数也可以是默认构造函数, 只要所有参数都有默认值. 但是最终的类只能有一个构造函数, 否则会在调用时产生二义性. 按值传递参数或返回值时, 会产生对象副本, 此时就调用了复制构造函数, 使用引用可以避免频繁调用复制构造函数. 试题: 编写string类的构造函数, 析构函数, 拷贝构造函数和赋值函数. 子类析构时要调用父类的析构函数吗?调用(自动调用, 无需手动调用) 析构函数调用的次序是先调用派生类的析构, 后调用基类的析构, 也就是说在基类的析构函数调用的时候, 派生类的信息已经全部销毁了. 定义一个对象时先调用基类的构造函数, 然后调用派生类的构造函数, 析构的时候恰好相反, 先调用派生类的析构函数, 然后调用基类的析构函数]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中typeid实现原理和使用方法]]></title>
    <url>%2Fz_post%2FCpp-typeid%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[先好好理解一下C++的typeid运算符到底是什么意思，再问“原理是什么”会比较好。先看这里学习typeid是什么意思：typeid operator针对题主给的例子：int i = 1;const char* name = typeid(i).name(); 这里的typeid(i)根本不需要做任何运行时动作，而是纯编译时行为——它使用变量i的静态类型直接就知道这是对int类型做typeid运算，于是可以直接找出int对应的std::type_info对象返回出来。 If expression is not a glvalue expression of polymorphic type, typeid does not evaluate the expression, and the std::type_info object it identifies represents the static type of the expression. Lvalue-to-rvalue, array-to-pointer, or function-to-pointer conversions are not performed.此时的typeid运算符就跟sizeof运算符的大部分情况一样，只需要编译器算出表达式的静态类型就足够了。算出表达式的静态类型是C++编译器的基本功能了，类型检查、类型推导等许多功能都依赖它。而当typeid运算符应用在一个指向多态类型对象的指针上的时候，typeid的实现才需要有运行时行为。If expression is a glvalue expression that identifies an object of a polymorphic type (that is, a class that declares or inherits at least one virtual function), the typeid expression evaluates the expression and then refers to the std::type_info object that represents the dynamic type of the expression. If the glvalue expression is obtained by applying the unary operator to a pointer and the pointer is a null pointer value, an exception of type std::bad_typeid or a type derived from std::bad_typeid is thrown.实际实现的时候，通常是在类的vtable里会有个slot保存着指向该类对应的std::type_info对象的指针。要形象的理解的话，请参考我在另一个回答里画的图：为什么bs虚函数表的地址（int）(&amp;bs)与虚函数地址（int）(int*)(&amp;bs) 不是同一个？ - RednaxelaFX 的回答可以看到Clang++在LP64上用的vtable布局，不禁用RTTI时，在-8偏移量上的slot就是存typeinfo指针的。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logging模块-打印日志信息]]></title>
    <url>%2Fz_post%2FPython-logging%2F</url>
    <content type="text"><![CDATA[简单使用1234567import logginglogging.debug("debug msg")logging.info("info msg")logging.warn("warn msg")logging.error("error msg")logging.critical("critical msg") 默认情况下, logging模块将日志打印到屏幕上, 只有日志级别高于WARNING的日志信息才回输出]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Image-Generation-from-Scene-Graphs]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-Image_Generation_from_Scene_Graphs%2F</url>
    <content type="text"><![CDATA[本篇论文解读的排版主要参见原文的格式，针对原文中的每一个小节进行展开，有的是对原文的一个提炼和简单概括，有的是对原文中一些要点的补充和说明。 摘要&emsp;&emsp;近几年来（至2018），针对某些特定目标（花，鸟等）的图片生成已经取得了令人激动的研究成果，但是当文本描述中包含多个物体和物体之间的关系时，仍然具有一些困难。 为了克服这一点，本文提出了从场景图来生成图片的方法，该方法可以推理出具体的物体和物体之间的关系。 本文的模型使用“图卷积层”（graph convolution）来处理输入的“图”（graph），通过预测物体的bounding boxes和segmentation masks来计算“场景布局”（scene layout），然后利用“级联精细化网络”（cascaded refinement network）将“场景布局”转换成一张图片输出。在训练网络时，通过对抗式的训练一对儿discriminators来确保生成图片的真实感。 本文在Visual Genome和COCO-Stuff数据集是验证了以上模型的有效性，结合高质量的生成图片、消融实验和人工调研的方法证明了本文提出的模型可以生成含有多个物体的复杂图片。 介绍——IntroductionWhat I cannot create，I do not understand —— Richar Feynman &emsp;&emsp;要想让计算机生成图片，就需要令其对图片有更深刻的理解。 &emsp;&emsp;为了达到以上目标，目前在text to image synthesis领域已经有许多的工作成果。这些模型可以在limited domains内产生十分惊人的结果，但是当文本信息变得复杂起来时，其生成出来的图片就不尽人意了。 &emsp;&emsp;句子通常都是由一个单词接一个单词组成的线性结构，但是，一个复杂的句子，其内部携带的信息，通常需要由基于物体的“场景图”在具体表示，“场景图”中包含物体和物体之间的关系。“场景图”作为表征图片和文本的强有力的工具，常常被用于语义图片检测、提高和评价图片描述领域中。也有关于将自然语言或图片转换成“场景图”的研究。 22,1，31,47,32,36，57,58 &emsp;&emsp;本篇文章的主要研究目的是在“场景图”约束条件下，生成带有多个物体和物体之关系的复杂图片。这一任务也带来了许多新的挑战。首先，必须要找到可以处理场景图的输入方法，对此本文使用了“graph convalution network”，它可以沿着“场景图”的“边”将信息传递。处理完“图”以后，还必须建立图结构的输入与二维图片的输出之间的联系。为此 ，本文通过预测图中所有物体的bounding boxes和segmentation masks构建了“场景布局（scene layout）”。得到“布局”以后，就需要生成图片，本文使用了“cascaded refinement network（CRN）”，它可以不断增大空间尺寸，生成图片。 最后，我们必须确保生成的图片具有一定的真实感并且包含多个可辨识的物体，为此我们针对image patches和generated objects训练了一对儿discriminator网络。另外，所有的模型可以进行端到端的联合训练。 &emsp;&emsp;我们在2个数据集上进行了实验：Visual Genome（提供人工标注的场景图）和COCO-stuff（从真实的物体位置生成场景图）。两个数据集的生成结果都证明了本文提出的方法的可以生成包含多个物体并且反映它们之间关系的复杂图片。同时，还进行了综合的消融实验来验证本文提出的模型中每一部分的有效性。 相关工作——Related Work&emsp;&emsp;生成图片模型 Generative Image Models 目前，生成模型主要可分为三类：Generative Adversarial Networks（GANs）、Variational Autoencoders（VAE）和基于像素的似然法autoregressive approaches。 [12,40,24,38,53] &emsp;&emsp;条件图片生成 Conditional Image Synthesis 通过在生成图片时向GAN网络添加条件的方式来控制最终输出图片的结果。由两种不同方法：一是将条件作为附加信息同时送入到generator和discriminator中，二是强制让discriminator去预测图片的label。本文选择后者。 [10,35,37,42,59,41,43,6,9,21,4,5,20,27,28,55,56,22] &emsp;&emsp;场景图 Scene Graph 表现为有向图，它的结点是物体，边是物体之间的关系。场景图多倍用于图片检索、图片描述评价等，有些工作也场景从文本或图片中生成场景图 [1,47,32,36,57,58,26] &emsp;&emsp;针对图的深度学习 Deep Learning on Graphs 有的工作是对图进行embedding学习，类似于word2vec，但这与本文的方法不同，因为本文在进行一次前向计算时，传过来的图都是新的。与本文方法更相关的是Graph Neural Networks，它可以对任意的图进行处理。 [39,51,14,34,11,13,46,8,49,48,7,19,29,54,2,15,25] 方法——Methond&emsp;&emsp;我们的目标是得到一个模型，该模型的输入描述物体和它们之间关系的“场景图”，输出是基于该场景图的图片。主要的挑战和困难有三个方面：一、必须找到可以处理“场景图”输入的方法;二、确保生成的图片可以真实反映出场景图中缩描述的物体;三、确保生成的图片具有真实感。 &emsp;&emsp;如图2所示，本文通过“image generation network f”将场景图转换成图片。该网络的inputs是场景图 $G$ 噪声变量 $z$ ，ouputs是 $\hat I = f(G,z)$ 。 图2 &emsp;&emsp;场景图经过“图卷积网络”后，会得到每个物体的embedding vectors，如图2和图3所示，每一层“图卷积层”都会沿着图的边将信息混合在一起。 图3 &emsp;&emsp;本文利用从图卷积网络中得到的object embedding vectors来预测每个物体的bounding boxes和segmentation masks。将它们结合起来形成一个“场景图 scene layout”，如图2中心所示，场景布局相当于是场景图和图片中间媒介。 &emsp;&emsp;最终将布局送入到CRN中，生成图片，如图2右边所示，CRN中会不断将布局的尺寸放大，指定生成新的图片为止。本文训练的生成器是CRN网络 $f$ 和两个分辨器 $D_{img}$ 和 $D_{obj}$ ，它们可以确保图片的真实感以及图片中物体的可识别力。关于这部分的详细介绍可以查看后文以及附加材料中的内容。 &emsp;&emsp;场景图 Scene Graphs 给定一个物体类别集合 $C$ 和一个关系集合 $R$ 。一个场景图可以用一个元组 $(O,E)$ 表示，其中 $O \subseteq C$ ， $E \subseteq O \times R \times O$ 。在处理的第一阶段，使用学习好的embedding layer将场景图中的结点和边转换成一个dense vector，就像语言模型中的那样。 &emsp;&emsp;图卷积网络 Graph Convolution Network 为了实现端到端的处理，本文需要一个可以对场景图进行处理的神经网络模型，为此，采用了由若干图卷积层构成的图卷积网络。 本文的图卷积网络与传统的卷积网络的工作方式类似：给定一个input graph，它每个结点和边的vecotrs维度为 $D_{in}$ ，然后经过一层图卷积层以后，就会生成一个新的vector，其维度为 $D_{out}$ 。（输出结点的值是关输入结点周围像素的函数）。 具体来说，对于所有的 $o_i \in O , (o_i,r,o_j) \in E$ ，给定输入向量 $v_i,v_r \in R^{D_{in}}$ 都会计算出输出向量 $v_i^{‘} , v_r^{‘} \in R^{D_{out}}$ 。 对于所有的结点和边，都会使用3个函数： $g_s , g_p , g_o$ ，其接受的输入为一个向量的三元组 $(v_i, v_r, v_j)$。&emsp;计算边的输出向量时，直接使用 $v_r^{‘} = g_p(v_i, v_r, v_j)$ 。而更新结点的值时较为复杂，因为结点往往连接了很多条边。对于每条始于 $o_i$ 的结点，都利用 $g_s$ 去计算候选向量（candidate vector），收集到所有的候选向量以后，将其放置于集合 $V_i^s$ 中。用 $g_o$ 以同样的方式处理止于 $o_i$ 的边。公式表示如下： V_i^s = {g_s(v_i, v_r, v_j) : (o_i, r, o_j) \in E}V_i^o = {g_o(v_j, v_r, v_i) : (o_j, r, o_i) \in E}然后再利用公式 $v_i^{‘} = h(V_i^s \cup V_i^o)$ 计算得到物体 $o_i$ 的输出向量 $v_i^{‘}$ （ $h$ 为池化操作）。有关计算的例子可以看图3。在本文中，函数 $g_s , g_p , g_o$ 的实现采用了一个单一网络，该网络会将输入向量连接起来，然后送到一个多层感知机（MLP）当中。pooling 函数 $h$ 会将输入结果进行平均值池化，然后送到MLP当中。 图4 &emsp;&emsp;场景布局 Scene Layout 为了生成图片，本文利用object embedding vectors去计算场景布局，该布局给出了要生成的图片的2D结构。本文利用图4中的object layout network来预测每个物体的bounding boxes和 segmentation masks，进而生成场景布局。 object layout networks接受形状为 $D$ 的embedding vector $v_i$ ，并把它送入到一个 mask regression network中去预测形状为 $M \times M$ 的soft binary mask $\hat m_i$ ，同时也送到一个 box regression network中去预测bounding box $\hat b_i = (x_0, y_0, x_1, y_1)$ 。 我们将 embedding vectors $v_i$ 和 mask $\hat m_i$ 逐个元素相乘，得到一个masked embedding ， 其shape为 $D \times M \times M$ ，然后，再利用双线性插值法结合物体的bounding box得到一个object layout。将所有的object layout相加，最终得到scene layout。在训练阶段，我们使用ground-truth bounding boxes来计算scene layout，在测试阶段我们使用预先预测好的bounding boxes进行计算。 &emsp;&emsp;级联精细化网络 Cascaded Refinement Network 在给定场景布局以后，本文使用CRN来根据场景布局生成图片。一个CRN网络包含了一系列的convolutional refinement modules，modules之间的spatial resolutoin会不断变大（double），最终达到预定义的图片大小。 每个module都以scene layout（downsampling到当前module接受的大小）和前一层module的输出结果。 这两部分输入沿着channel连接在一起,送到2层3×3的卷积层里，然后利用最近邻插值对结果进行upsampling，之后继续传送到下一个module中。第一个module以scene layout和高斯噪声 $z \sim p_z$ 作为输入。把从最后一个module得到的结果再送到两个final convolution layers中去，生成最终的图片。 &emsp;&emsp;分辨器 Discriminators 本文训练了两个分辨器 $D_{img}$ 和 $D_{obj}$ patch-based image discriminators $D_{img}$ ：确保生成图片的overall appearance是realistic的。利用全卷积网络实现。 object discriminator $D_{obj}$ ：确保图片中的每个物体都是recognizable并且realistic的。分别利用辅助分类器 auxiliary classifier和全卷积网络实现。 &emsp;&emsp;训练 Training 本文将generation network $f$ 和 $D_{img} , D_{obj}$ 联合训练。generation network的训练目标是minimize下面的6个损失函数的权重和： $Box \ loss\ \ L_{box} = \sum_{i=1}^n ||b_i - \hat b_i||_1$ ：计算真实box和预测box之间的L1范式 $Mask\ loss\ \ L_{mask}$ ：计算真实mask和预测mask之间基于像素的交叉熵 $Pixel\ loss\ \ L_{pix} = ||I - \hat I||_1$ ：真实图片和生成图片之间的L范式 $Image\ adversarial\ loss\ \ L_{GAN}^{img}$ ：针对 $D_{img}$ 的损失函数 $Object\ adversarial\ loss\ \ L_{GAN}^{obj}$ ：针对 $D_{obj}$ 的损失函数，确保物体的realistic $Auxiliarly\ classifier\ loss\ \ L_{AC}^{obj}$ ：针对 $D_{obj}$的损失函数，确保物体的recognizable &emsp;&emsp;实现细节 Implementation Details 本文对所有的scene graphs都进行了数据增强，并且添加了特殊的图片间的relationships，可以把每个真实物体与图片物体进行连接，确保所有的scene graphs都是连通的。我们使用Adam训练所有的模型，学习率设置为 $10^{-4}$ ， batch size 设置为32, 迭代次数为一百万次，使用单个Tesla P100训练了3天。 对于每一次minibatch，我们首先更新 $f$ ，而后更新 $D_{img}$ 和 $D_{obj}$ 。对于所有的graph convolution 本文使用ReLU作为激活函数，对于CRN和discriminators 使用Leaky ReLU作为激活函数，同时使用了batch normalization技术。 实验&emsp;&emsp;在实验中，我们将证明本文提出的方法可以生成复杂的图片，并且正确反应场景图中的物体和物体之间的关系。 数据集&emsp;&emsp;COCO 使用2017 COCO-Stuff 数据集，该数据集共有80个物体类别，40K的训练集和5K的验证集，所有的图片标注都具有bounding boxes和segmentation masks 。利用这些标注，本文建立了2D平面上的场景图，总共包含6中人工设定的关系：左边，右边，上边，下边，里面，外面。我们忽略了图片中占图片比例小于2%的物体，使用的图片包含3～8个物体。将COCO val分为val和test两部分。最终，我们得到了24972张训练图片，1024张val图片，2048张test图片。 &emsp;&emsp;Visual Genome 本文使用VG 1.4数据集，它包含108077张图片，并且具有标注好的场景图。将其中的80%用作训练集，10%分别用作val和test，本文仅仅使用在训练集中出现次数大于2000次的物体和大于500次的关系，最终，我们得到的训练集具有178种物体和45种关系类型。我们忽略图片中的小物体，并且使用图片中具有3～30个物体和至少一种关系类型的图片，最终我们得到了62565张图片作训练集，5506张val和5088张test，平均每张图片包含10个物体和5种关系类型。由于VG数据集没有提供segmentation masks标注，所以在使用VG数据集时，我们忽略mask loss 。 定性结果——Qualitative Results&emsp;&emsp;由本文提出的模型生成的图片示例如图5,6所示 图5 图6 消融实验&emsp;&emsp;在消融实验中，如表1所示，我们验证了模型每一部分对最终图片质量的重要性和必要性。文本使用 $inception\ score^2$作为衡量生成图片好坏的标准。 表1 表1 我们测试了以下几种不同的消融模型： &emsp;&emsp;无图卷积 no gconv ：去掉图卷积层，因此boxes和masks会直接从原始的object embedding vectors预测而来。 &emsp;&emsp;无关系 no relationships ：使用图卷积层，但是忽视场景图中的所有“边”，即关系信息。 &emsp;&emsp;无分辨器 no discriminators ：去掉分辨器 $D_{img}$ 和 $D_{pix}$ ，依靠像素回归损失函数 $L_{pix}$ 来引导图片的生成。 &emsp;&emsp;去掉一个分辨器 omit one of the Discriminators ：仅去掉其中一个分辨器 &emsp;&emsp;GT Layout ：除了消融实验外，本文还使用了GT layout来代替 $L_{box} 和 $L_{mask}$ 损失函数。 物体定位 Object Localization&emsp;&emsp;除了关注生成图片的质量外，我们还对本文模型预测到的bounding boxes进行了分析。在表2中，我们展示了object的召回率和2种交并比的分值。另一个评价标准就是多样性。 表2 用户调研 User Studies&emsp;&emsp;作者找来了数名志愿者，让他们根据以下两个评价标准对本文模型的生成结果和StackGAN的结果进行评价。 Caption Matching Object Recall]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 手册]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-Git%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[git rebase回到某个提交状态, 删除之前的1git rebase --onto master~3 master 删除 add 的文件如果要删除文件，最好用 git rm file_name，而不应该直接在工作区直接 rm file_name。 如果一个文件已经add到暂存区，还没有 commit，此时如果不想要这个文件了，有两种方法： 1，用版本库内容清空暂存区，git reset HEAD 2，只把特定文件从暂存区删除，git rm —cached xxx 配置用户密码不用每次输入显式配置(不安全)123git config --global user.name "xxxx"git config --global user.email "xxxx@foxmail.com"git config --global credential.helper store 上述指令输完后, 会生成~/.gitconfig文件, 内容如下:12345[user] name = hellozhaozheng email = hellozhaozheng@foxmail.com[credential] helper = store 之后, 再次输入密码, 密码和账号会显式存储在~/.git-credentials文件中.(显式存储, 不安全) 秘钥配置 sshstep 1: 生成公钥123ssh-keygen -t rsa -C &quot;hellozhaozheng@foxmail.com&quot;# Generating public/private rsa key pair...# 三次回车即可生成 ssh key step 2: 查看已生成的公钥12cat ~/.ssh/id_rsa.pub# ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC6eNtGpNGwstc.... step3: 复制已生成的公钥添加到git服务器step4: 使用ssh协议clone远程仓库 or 如果已经用https协议clone到本地了，那么就重新设置远程仓库1git remote set-url origin git@xxx.com:xxx/xxx.git 常用指令初始化当前本地文件夹为仓库 git init 添加文件: 单个: git add readme.md全部: git add -A / git add ./ 提交修改: git commit -m “must write commit” 查看状态: git status 查看日志: git log 版本回退: 回退一个: git reset -hard HRAD^ 回退两个: git reset -hard HARD^^ 回退多个: git reset -hard HEAD~100 首次连接: git remote add origin https//www.github… 提交: git push origin master 更新本地仓库: git fetch origin master 获取 git merge origin/master 合并 如果将别人的仓库拉到了自己的仓库里, 为了push成功: 删除.git相关 git rm rf —cached ./themes/next git add ./themes/next git commit -m “next” git push origin master 子模块: 可以独立提交 从远程库更新本地的单个文件https://stackoverflow.com/questions/3334475/git-how-to-update-checkout-a-single-file-from-remote-origin-master 只显示更改的文件的名字https://segmentfault.com/q/1010000006760132 gitgit checkout misc: 切换分支git stash: 暂存到缓存里, 新建另一个编辑git stash pop: 从缓存理加载出刚刚的分支, 这里可以和chechout结合使用来切换分支同时将刚刚修改的操作添加到当前分支中 若要提交新的commit:先切换分支: git checkout misc再查看状态: git status添加修改: git add .提交: git commit -m “..”推送: git push origin misc查看提交结果: git log —oneline —decorate 更新master到本地分支:1234567891011121314//查询当前远程的版本$ git remote -v//获取最新代码到本地(本地当前分支为[branch]，获取的远端的分支为[origin/branch])$ git fetch origin master [示例1：获取远端的origin/master分支]$ git fetch origin dev [示例2：获取远端的origin/dev分支]//查看版本差异$ git log -p master..origin/master [示例1：查看本地master与远端origin/master的版本差异]$ git log -p dev..origin/dev [示例2：查看本地dev与远端origin/dev的版本差异]//合并最新代码到本地分支$ git merge origin/master [示例1：合并远端分支origin/master到当前分支]$ git merge origin/dev [示例2：合并远端分支origin/dev到当前分支]---------------------git merge orgin vino 解决冲突:git mergetool:diffg RE:diffg LO vimdiff3 忘记切换分支, 提交到了错误的分支: git reset HEAD~1git stashgit checkout target_branchgit stash popgit add .git commit -m “…”git push origin target_branch 比较本地分支和远端分支的区别(先要更新本地的远程分支?)git diff vino origin/vinogit diff vino origin/master 用某一个分支的文件覆盖另一个分支的文件用git checkout branch — filename如： 分支test上有一个文件A，你在test1分支上， 此时如果想用test分支上的A文件替换test1分支上的文件的话，可以使用git checkout test1, 然后git checkout test — A]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch官方教程(六)-FineTuning Torchvision Models]]></title>
    <url>%2Fz_post%2FPyTorch-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B6-FineTuningModels%2F</url>
    <content type="text"><![CDATA[在本篇教程中, 我们将教授你如何 finetune 一个 torchvision models, 这些 models 都已经在 ImageNet 的 1000-class 数据集上进行过预训练. 由于每个模型的结构都不太相同, 因此没有通常的代码模板来适应所有的场景需要. 在这里, 我们将会演示两种类型的迁移学习: finetuning 和 feature extraction. 在 finetuning 中, 我们会从一个预训练好的模型开始, 将该模型的参数应用到新的任务上去, 然后重新训练整个模型. 在 feature extraction 中, 我们同样会从一个预训练好的模型开始, 但是仅仅更新最后的几层网络, 而将之前的网络层参数固定不变. 通常情况下, 这两种迁移学习都包含以下几步: 用预训练模型初始化参数 更改最后的一层或几层神经层, 使其输出适应我们的新数据集 在 optimization 算法中定义我们希望更新的参数 执行训练]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch官方教程(五)-Saving and Loading Models]]></title>
    <url>%2Fz_post%2FPyTorch-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B5-Saving-and-Loading-Models%2F</url>
    <content type="text"><![CDATA[本篇教程提高了大量的用例来说明如何保存和加载PyTorch models. 在介绍细节之前, 需要先熟悉下面的三个函数: torch.save: 保存一个序列化对象(serialized object)到磁盘中. 该函数使用的是Python的pickle工具完成序列化的. Models, tensors, 以及由各种对象所组成的字典数据都可以通过该函数进行保存. torch.load: 使用pickle的解包工具(unpickling facilities)来反序列化 pickled object 到内存中. 该函数同样可以操作设备(device)来加载数据 torch.nn.Module.load_state_dict: 利用非序列结构数据state_dict加载模型的参数字典. What is a state_dict?在PyTorch中, torch.nn.Module 模型中的可更新的参数(weighs and biases)在保存在模型参数中(model.parameters()). 而state_dict是一个典型的python字典数据, 它将每一层和层中的参数tensor相互关联起来. 注意到, 只有那些具有可更新参数的层才会被保存在模型的state_dict数据结构中. 优化器对象(Optimizer object-torch.optim)同样也可以拥有state_dict数据结构, 它包含了优化器的相关状态信息(超参数等). 下面看一个state_dict的简单例子. 调用时, 要使用 .state_dict() 来获得字典结构` 123456789101112131415161718192021222324252627282930313233343536# Define modelclass TheModelClass(nn.Module): def __init__(self): super(TheModelClass, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # 个人建议最好将relu也写在__init__函数内, 否则无法通过模型获知到底使用了什么激活函数(只有通过forward函数才能知道) x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x# Initialize modelmodel = TheModelClass()# Initialize optimizeroptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)# Print model's state_dictprint("Model's state_dict:")for param_tensor in model.state_dict(): print(param_tensor, "\t", model.state_dict()[param_tensor].size())# Print optimizer's state_dictprint("Optimizer's state_dict:")for var_name in optimizer.state_dict(): print(var_name, "\t", optimizer.state_dict()[var_name]) Saving &amp; Loading Model for InferenceSave/Load state_dict(Recommended)Save:1torch.save(model.state_dict(), PATH) Load:123model = TheModelClass(*args, **kwargs)model.load_state_dict(torch.load(PATH))model.eval() 当为inference阶段保存模型时, 仅仅保存训练好的模型的可更新参数即可. 利用torch.save()函数来保存模型的state_dict可以在之后恢复模型时提供极大的灵活性, 这也是我们推荐使用该方法来保存模型的原因. 模型的保存文件通常以.pt或者.pth结尾 请牢记在执行inference逻辑之前使用了model.eval()来将当前的模式转换成测试模式, 不然的话dropout层和BN层可能会产生一些不一致的测试结果. 请注意, load_state_dict()函数接受的参数是一个字典对象, 而不是模型文件的保存路径. 这意味着你必须先将模型文件解序列成字典以后, 才能将其传给load_state_dict()函数 Save/Load Entire ModelSave:1torch.save(model, PATH) Load:123# Model class must be defined somewheremodel = torch.load(PATH)model.eval() 这段保存/加载的流程使用了最直观的语法以及最少的代码. 以这种方式保存模型时将会用pickle模块把 整个 模型序列化保存. 这种方法的坏处是序列化的数据会和特定的classes绑定, 以及模型保存时固定的目录结构(这句话啥意思?). 造成这种结果的原因在于pickle没有保存模型本身, 而是保存了一个包含类的文件的路径. 因此, 这样的代码会在之后应用到其他工程时以各种方式造成程序崩溃. Saving &amp; Loading a General Checkpoint for Inference and/or Resuming TrainingSave:123456torch.save(&#123;"epoch":epoch, "model_state_dict":model.state_dict(), "optimizer_state_dict":optimizer.state_dict(), "loss": loss, ... &#125;, PATH) Load:123456789101112model = TheModelClass(*args, **kwargs)optimizer = TheOptimizerClass(*args, **kwargs)checkpoint = torch.load(PATH)model.load_state_dict(checkpoint["model_state_dict"])optimizer.load_state_dict(checkpoint["optimizer_state_dict"])epoch = checkpoint["epoch"]loss = checkpoint["loss"]model.eval()# --or--model.train() 当保存一个通用的 checkpoint 文件时, 我们不仅仅需要保存模型的 state_dict 信息, 还需要保存一些其他信息. 为此, 我们需要将这些信息组织成字典的形式, 然后利用 torch.save() 函数进行保存. 通常情况下, 在PyTorch中, 这些checkpoints文件使用 .tar 文件后缀. 在加载模型时, 首先要记得初始化模型, 然后利用 torch.load() 函数来你所需要的各项数据. Saving Multiple Models in One FileSave:1234567torch.save(&#123; "modelA_state_dict": modelA.state_dict(), "modelB_state_dict": modelB.state_dict(), "optimizerA_state_dict": optimizerA.state_dict(), "optimizerB_state_dict": optimizerB.state_dict(), ... &#125;, PATH) Load:12345678910111213141516modelA = TheModelAClass(*args, **kwargs)modelB = TheModelBClass(*args, **kwargs)optimizerA = TheOptimizerAClass(*args, **kwargs)optimizerB = TheOptimizerBClass(*args, **kwargs)checkpoint = torch.load(PATH)modelA.load_state_dict(checkpoint["modelA_state_dict"])modelB.load_state_dict(checkpoint["modelB_state_dict"])optimizerA.load_state_dict(checkpoint["optimizerA_state_dict"])optimizerB.load_state_dict(checkpoint["optimizerB_state_dict"])modelA.eval()modelB.eval()# - or -modelA.train()modelB.train() 当需要保存多个不同的模型时(如RNN, CNN), 可以用同样的方式将这些模型的 state_dict 信息保存起来, 并将它们组织成字典的形式, 然后利用torch.save()将他们序列化保存起来, 通常情况下文件以.tar后缀命名. Warmstarting Model Using Parameters from a Different ModelSave:1torch.save(modelA.state_dict(), PATH) Load:12modelB = ThemodelBClass(*args, **kwargs)modelB.load_state_dict(torch.load(PATH), strict=False) Partially loading a model 或者 loading a partial model 在迁移学习或者训练一个复杂模型时是很常见的, 即使只是用很小一部分参数, 也可以起到训练过程的热启动效果, 进而可以帮助模型更快的收敛.不论何时, 当你需要从 partial state_dict 中加载模型时, 都需要将参数 strict 设置为 False. Saving &amp; Loading Model Across DevicesSave on GPU, Load on CPUSave:1torch.save(model.state_dict(), PATH) Load:123device = torch.device("cpu")model = TheModelClass(*args, **kwargs)model.load_state_dict(torch.load(PATH, map_location=device)) 通过 torch.load() 函数的 map_location 参数来指定将模型的 state_dict 加载到哪个设备上. Save on GPU, Load on GPUSave:1torch.save(model.state_dict(), PATH) Load:1234device = torch.device("cuda:0")model = TheModelClass(*args, **kwargs)model.load_state_dict(torch.load(PATH))model.to(device) 使用 .to 来将模型中的参数tensor转移到GPU设备上, 需要注意的是, 在进行训练或者预测之间, 还需要调用 tensor 的 .to() 方法来将 tensor 也转移到 GPU 设备上, 另外, 注意, mytensor.to(device) 实际上是在 GPU 中创建了 mytensor 的副本, 而并没有改变 mytensor 的值, 因此, 需要写成这样的形式来是的 mytensor 的值改变: my_tensor = my_tensor.to(torch.device(&quot;cuda&quot;)) Save on CPU, Load on GPUSave:1torch.save(model.state_dict(), PATH) Load:1234device = torch.device("cuda")model = TheModelClass(*args, **kwargs)model.load_state_dict(torch.load(PATH, map_location="cuda:0"))model.to(device) 由于模型是在CPU上存储的, 因此在模型加载时, 需要设置 torch.load() 函数的 map_location 参数为 cuda:0. 然后, 还需要调用 model 的 .to(device) 方法来将model的参数 tensor 全部转移到 GPU 上去, 另外别忘了将数据也要转移到 GPU 上去, my_tensor = my_tensor.to(torch.device(&quot;cuda&quot;)). Saving torch.nn.DataParallel ModelsSave:1torch.save(model.module.state_dict(), PATH) Load:1# Load to whatever device you want]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络的复杂度分析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[https://zhuanlan.zhihu.com/p/31575074 https://zhuanlan.zhihu.com/p/31575074 https://blog.csdn.net/dcrmg/article/details/79652521 https://blog.csdn.net/laolu1573/article/details/79196160 时间复杂度时间复杂度即模型的浮点数运算次数, 可用 FLOPs (FLoating-point OPerations) 来衡量. 单个卷积层的时间复杂度Time \sim O(M^2 K^2 C_{in} C_{out}) $M$ : 每个卷积核输出的特征图谱的边长 $K$ : 每个卷积核的边长 $C_{in}$ : 每个卷积核的输入通道数 $C_{out}$ : 本卷积层具有的卷积核个数, 也即输出通道数 注一: 为了简化表达式, 这里假设输入和输出的特征图谱都是正方形注二: 同样为了简化表达式, 这里省略了偏置项. 网络整体的时间复杂度Time \sim O \Big(\sum_{l=1}^D M^2K^2C_{l-1}C_l \Big) $D$ : 神经网络具有的卷积层层数, 也就是网络的深度 $l$ : 神经网络的第l层卷积层 $C_l$ : 神经网络第l层卷积层的输出通道数, 也就是该层的卷积核个数 示例: 用Numpy实现简单二维卷积: 1234567891011121314def conv2d(img, kernel): height, width, in_channels = img.shape kernel_height, kernel_width, in_channels, out_channels = kernel.shape out_height = height - kernel_height + 1 out_width = width - kernel_width + 1 feature_maps = np.zeros(shape=(out_height, out_width, out_channels)) for oc in range(out_channels): # Iterate out_channels (# of kernels) for h in range(out_height): # Iterate out_height for w in range(out_width): # Iterate out_width for ic in range(in_channels): # Iterate in_channels patch = img[h: h + kernel_height, w: w + kernel_width, ic] feature_maps[h, w, oc] += np.sum(patch * kernel[:, :, ic, oc]) return feature_maps 空间复杂度空间复杂度 (访存量) 包含两部分: 总参数量 + 各层的输出特征图谱 参数复杂度: 模型所有带参数的层的参数总量: $O(K^2C_{l-1}C_{l})$ 特征图谱复杂度: 实时运行过程的每层计算出的图谱大小: $O(M^2C_l)$ Space \sim O\Big( \sum_{l=1}^D K_l^2 C_{l-1} C_l + \sum_{l=1}^D M^2 C_l \Big)注意, 上面的参数复杂度没有带偏置项, 因为这只是计算复杂度, 而不是精确的参数个数. 复杂度对模型的影响复杂度的优化1×1 卷积降维同时优化时间复杂度和空间复杂度 用两个 3×3 卷积 (18个参数) 替代 5×5卷积 (25个参数) 使用 N×1 和 1×N 卷积级联替代 $N×N$ 卷积.]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>深度学习</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch官方教程(四)-Transfer_Learning_Tutorial]]></title>
    <url>%2Fz_post%2FPyTorch-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B4-Transfer-Learning-Tutorial%2F</url>
    <content type="text"><![CDATA[通常情况下, 我们不会从头训练整个神经网络, 更常用的做法是先让模型在一个非常大的数据集上进行预训练, 然后将预训练模型的权重作为当前任务的初始化参数, 或者作为固定的特征提取器来使用. 既通常我们需要面对的是下面两种情形: Finetuning the convnet: 在一个已经训练好的模型上面进行二次训练 ConvNet as fixed feature extractor: 此时, 我们会将整个网络模型的权重参数固定, 并且将最后一层全连接层替换为我们希望的网络层. 此时, 相当于是将前面的整个网络当做是一个特征提取器使用. Load Data我们将会使用torch.utils.data包来载入数据. 我们接下来需要解决的问题是训练一个模型来分类蚂蚁和蜜蜂. 我们总共拥有120张训练图片, 具有75张验证图片. 12345678910111213141516171819202122232425data_transforms = &#123; "train": transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), # 注意转换成tensor后, 像素会变成[0,1]之间的浮点数 transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) ]), "val": transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) ])&#125;data_dir = "hymenoptera_data"# from torchvision import datasetsimage_datasets = &#123;x:datasets.ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x]) for x in ["train", "val"]&#125;dataloaders = &#123;x:torch.utils.data.DataLoader(image_datasets[x]), batch_size=4, shuffle=True, num_workers=4) for x in ["train", "val"]&#125;dataset_sizes = &#123;x:len(image_datasets[x]) for x in ["train", "val"]&#125;class_names = image_datasets["train"].classesdevice = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") Visualize a few images1234567891011121314def imshow(inp, title=None): inp = inp.numpy().transpose((1,2,0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) plt.imshow(inp) if title is not None: plt.title(title) plt.pause(0.001) # pause a bit so that plots are updatedinputs, class_ids = next(iter(dataloaders["train"])) # 获取一个batchout = torchvision.utils.make_grid(inputs)imshow(out, title=[class_names[x] for x in class_ids]) Training the model接下来, 让我们定义一个简单的函数来训练模型, 我们会利用LR scheduler对象torch.optim.lr_scheduler设置lr scheduler, 并且保存最好的模型. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def train_model(model, criterion, optimizer, scheduler, num_epochs=25): since = time.time() best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(num_epochs): print(epoch) for phase in ["train", "val"]: if phase == "train": model.train() else: model.eval() running_loss = 0.0 running_corrects = 0 for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) labels = labels.to(device) optimizer.zero_grad() # forward with torch.set_grad_enabled(phase == "train"): outputs = model(inputs) _, preds = torch.max(outputs,1) # preds代表最大值的坐标, 相当于获取了最大值对应的类别 loss = criterion(outputs, labels) if phase = "train": # 只有处于train模式时, 来更新权重 loss.backward() optimizer.step() # 统计状态 running_loss += loss.item() * inputs.size(0) running_corrects += torch.sum(preds==labels.data) epoch_loss = running_loss / dataset_sizes[phase] epoch_acc = running_corrects.double() / dataset_sizes[phase] print(phase, epoch_loss, epoch_acc) if phase == "val" and epoch_acc &gt; best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) time_elapsed = time.time() - since print(time_elapsed) print(best_acc) # load best model weights model.load_state_dic(best_model_wts) return model Visualizing the model predictions下面的代码用于显示预测结果 12345678910111213141516171819202122232425def visualize_model(model, num_images=6): was_training = model.training model.eval() images_so_far = 0 fig = plt.figure() with torch.no_grad(): # 不计算梯度 for i, (inputs, labels) in enumerate(dataloaders["val"]): inputs = inputs.to(device) labels = labels.to(device) outputs = model(inputs) _, preds = torch.max(outputs,1) for j in range(inputs.size()[0]): # 或者batch size images_so_far += 1 ax = plt.subplot(num_images//2, 2, images_so_far) ax.axis("off") ax.set_title(class_names[preds[j]]) imshow(inputs.cpu().data[j]) # 由于imshow不能作用在gpu的数据上, 因此需要先将其移动到cpu上. if images_so_far == num_images: model.train(mode = was_training) return model.train(mode=was_training) FineTuning the convnet加载预训练模型, 并重置最后一层全连接层 123456789101112# from torchvisioin import modelsmodel_ft = models.resnet18(pretrained=True)num_ftrs = model_ft.fc.in_featuresmodel_ft = model_ft.to(device)criterion = nn.CrossEntropyLoss()# 这里是让所有的参数都进行更新迭代optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) Train and evaluate调用刚刚定义的训练函数对模型进行训练123model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)visualize_model(model_ft) Convnet as Fixed Feature Extractor假设我们需要将除了最后一层的其它层网络的参数固定(freeze), 为此, 我们需要将这些参数的requires_grad属性设置为False. 123456789101112131415model_conv = torchvision.models.resnet18(pretrained=True)for param in model_conv.parameters(): param.requires_grad = False# 将最后一层fc层重新指向一个新的Module, 其内部参数的requires_grad属性默认为Truenum_ftrs = model_conv.fc.in_featuresmodel_conv.fc = nn.Linear(num_ftrs,2)model_conv = model.to(device)criterion = nn.CrossEntropyLoss()optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1) Train and evaluate12model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_eopch=25)visualize_model(model_conv)]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种树结构知识点总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E5%90%84%E7%A7%8D%E6%A0%91%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[注: 本文的对各个概念的定义不一定采用常用的标准定义, 原因有二: 常用的定义描述在百度百科上即可查到 更多的是想通过自己的理解, 用简短的几个关键词语或句子, 来点明核心要点 二叉树基本概念和性质二叉树的定义: 二叉树中的每个节点至多有2棵子树, 并且子树有左右之分, 其次序不能任意颠倒。 二叉树的性质: 对于非空二叉树: $N_0 = N_2 +1$ 在于非空二叉树, 第k层上的节点数不超过: $2^{k-1}$ 高为h的二叉树, 总节点数不超过: $2^h-1$ 具有N个节点的完全二叉树, 其高度为: $\lceil log_2(N+1) \rceil$ 或 $\lfloor log_2{N} \rfloor +1$ 对于完全二叉树, 如果各个节点按照顺序存储(从 1 开始), 则节点之间编号具有一定关系: 节点 $i$ 的父节点为 $\lfloor \frac{i}{2} \rfloor (i&gt;1)$ $i$的左右子树分别为: $2i$ 和 $2i+1$ （如果$2i/2i+1 \geq N$, 则无左/右子树 给定N个节点, 能够成$h(N)$ 种不同的二叉树: $h(N)=…$ 设有$i$个枝点, $I$为所有枝点的道路长度总和, $J$为叶的道路长度总和$J=I+2i$ 注意: 二叉树不是度为2的树。 度为2的树至少要有3个节点, 而二叉树可以为空;度为2的树的左右子树是相对而言的, 当只有一个孩子时, 就无须分左右 满二叉树与完全二叉树满二叉树: 除叶子节点外的所有节点均有两个子节点 完全二叉树: 最后一个不满的“满二叉树”, 最后一层所有节点集中在左边 二叉树的遍历先根遍历: 根节点、左子树、右子树递归实现12345void preOrder(Tree t)&#123; visit(t-&gt;value); //访问根节点 if (t-&gt;left) preOrder(t-&gt;left); //访问左孩子 if (t-&gt;right) preOrder(t-&gt;right); //访问右孩子&#125; 非递归实现对于任一节点, 其可看做是根节点, 因此直接访问, 访问后, 若其左孩子不为空, 则按相同规则访问其左子树, 当访问完左子树之后, 再访问其右子树: 对于任一节点P: 访问节点P, 并将P入栈 如果P的左孩子不为空, 则令P = P-&gt;left, 并转向第一步。若为空, 则将P出栈, 并令P = P-&gt;right, 然后转向第一步。 直到P为nullptr并且栈为空时, 结束循环 123456789101112131415vector&lt;TreeNode*&gt; preOrder;if(pRoot == nullptr) return preOrder;stack&lt;TreeNode*&gt; s_node;TreeNode* P = pRoot;while(!s_node.empty() || P!=nullptr)&#123; while(P!=nullptr)&#123; preOrder.push_back(P); // visit P s_node.push(P); P = P-&gt;left; &#125; if(!s_node.empty())&#123; P = s_node.top(); s_node.pop(); P = P-&gt;right; // go to right child &#125;&#125; 中根遍历: 左子树、根节点、右子树递归1234567void in_order(TreeNode* pRoot)&#123; if(pRoot != nullptr)&#123; in_order(pRoot-&gt;left); visit(pRoot); in_order(pRoot-&gt;right); &#125;&#125; 非递归对于任一节点, 优先查看其左孩子, 而左孩子节点又可以看作是一个根节点, 则继续优先查看其左孩子, 直到遇到左孩子节点为空的根节点才进行访问。然后再转向查看其右孩子, 右孩子可看作是一个根节点, 继续按上面的规则循环: 对于任一节点P: 若其左孩子不为空, 则就P入栈并将P的左孩子置为当前的P, 然后继续查看当前P的左孩子, 直到为空； 经过上一步后, P指向了空的左孩子, 因此取栈顶元素并进行出栈操作, 同时访问该栈顶节点, 然后将P置为栈顶节点的右孩子（无需判断右孩子是否为空, 若为空则下一次循环会自动继续取栈顶） 知道P为nullptr并且栈为空时循环结束 1234567891011121314vector&lt;TreeNode*&gt; inOrder;if(pRoot == nullptr) return inOrder;stack&lt;TreeNode*&gt; stack_node;TreeNode* P = pRoot;while(!stack_node.empty() || P !=nullptr)&#123; while(P!=nullptr)&#123; stack_node.push(P); P = P-&gt;left; &#125; if(!stack_node.empty())&#123; P = stack_node.top(); stack_node.pop(); inOrder.push_back(P); // visit P P = P-&gt;right;&#125; 后根遍历: 左子树、右子树、根节点递归1234567void in_order(TreeNode* pRoot)&#123; if(pRoot != nullptr)&#123; in_order(pRoot-&gt;left); in_order(pRoot-&gt;right); visit(pRoot); &#125;&#125; 非递归后序遍历的非递归实现是最难的一种。因为在后序遍历中, 要保证左孩子和右孩子都已被访问, 并且左孩子在右孩子之间访问, 最后才能访问根节点。有两种思路: 思路一:思路二:二叉排序树（Binary Sort Tree, BST）基本概念和性质定义: 也叫二叉查找树或有序二叉树。当树不为空时, 该树具有如下性质: 左子树上的所有节点值, 均小于其根节点的值 右子树上的所有节点值, 均大于其根节点的值 左、右子树也分别为二叉排序树 没有键值相等的节点 性质: 对二叉排序树进行中根遍历, 即可得到一串有序数列（从小到大） 时间复杂度: 插入与查找的复杂度均为$O(logn)$, 但在最坏情况下为$O(n)$（原因在于树不一定是平衡的） 平衡二叉树AVL树, 名字来源于其发明者 Adelson-Velsky 和 Landis 红黑树B+树字典树基本概念Trie 树, 又称字典树, 单词查找树或前缀树, 是一种用于快速检索字符串的多叉树结构, 如英文字母的字典树是一个26叉树, 数字的字典树是一个10叉树.字典树可以利用字符串的公共前缀来节约空间, 如下图所示. 当然, 如果字符串列表中存在大量没有公共前缀的字符串, 则字典树会变得非常消耗内存. 字典树的基本性质可以概括为以下三点: 除根节点以外, 每个节点都只包含一个字符(根节点不包含字符) 当前节点的所表示的字符串, 就是将从根节点到当前节点的路径上的字符连接起来的字符串. 每个节点的所有子节点包含的字符各不相同 基本实现http://dongxicheng.org/structure/trietree/ 高级实现]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib模块-数据绘图]]></title>
    <url>%2Fz_post%2FPython-matplotlib%2F</url>
    <content type="text"><![CDATA[基础知识Matplotlib是一个Python 2D绘图库，可以在各种平台上以各种硬拷贝格式和交互式环境生成出版质量数据。Matplotlib可用于Python脚本，Python和IPython shell，jupyter笔记本，Web应用程序服务器和四个图形用户界面工具。 matplotlib画板一般由以下部分组成 创建了subplot后, 如果发出绘图指令，matplotlib这时就会在你最后一个用过的subplot中（没有则创建）绘制. 12345678910111213141516171819202122232425import matplotlib.pyplot as pltimport numpy as np# 多个figurex = np.linspace(-1, 1, 50)y1 = 2*x + 1y2 = 2**x + 1# 使用figure()函数重新申请一个figure对象# 注意，每次调用figure的时候都会重新申请一个figure对象plt.figure()# 第一个是横坐标的值，第二个是纵坐标的值plt.plot(x, y1)# 第一个参数表示的是编号，第二个表示的是图表的长宽plt.figure(num = 3, figsize=(8, 5))# 当我们需要在画板中绘制两条线的时候，可以使用下面的方法：plt.plot(x, y2)plt.plot(x, y1, color='red', # 线颜色 linewidth=1.0, # 线宽 linestyle='--' # 线样式 )plt.show() # 会将所有的figure对象显示出来, 这里有2个 用matplotlib显示图片12345678910from PIL import Imageimport matplotlib.pyplot as plt # plt 用于显示图片img = Image.open(image_file_path)plt.figure("Image")plt.title("title")plt.axis("on") # 默认就是onplt.imshow(img)plt.show() 显示多张图片:1234567891011121314151617# plt.subplot(nrows, ncols, index, **kwargs), 行, 列, 编号, 从1开始, 直接行x列img = cv2.imread('cat.jpg')img = img[:, :, ::-1]plt.subplot(2, 2, 1)plt.title('origin')plt.imshow(img)plt.subplot(2, 2, 2)plt.title('origin')plt.imshow(img)plt.subplot(2, 2, 3)plt.title('origin')plt.imshow(img)plt.subplot(2, 2, 4)plt.title('origin')plt.imshow(img) 2D图表风格散点图12matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None,alpha=None, linewidths=None, verts=None, edgecolors=None, hold=None, data=None, ** kwargs) 参数说明: x/y: 一维向量, 且长度相等 s: 标记大小, 以平方磅为单位的标记面积，指定为下列形式之一： 数值标量 ： 以相同的大小绘制所有标记。 行或列向量 ： 使每个标记具有不同的大小。x、y 和 sz 中的相应元素确定每个标记的位置和面积。sz 的长度必须等于 x 和 y 的长度。 [] ： 使用 36 平方磅的默认面积 c: 标记颜色, 指定为下列形式之一: RGB 三元数或颜色名称 - 使用相同的颜色绘制所有标记。 由 RGB 三元数组成的三列矩阵 - 对每个标记使用不同的颜色。矩阵的每行为对应标记指定一种 RGB 三元数颜色。行数必须等于 x 和 y 的长度。 向量 - 对每个标记使用不同的颜色，并以线性方式将 c 中的值映射到当前颜色图中的颜色。c 的长度必须等于 x 和 y 的长度。要更改坐标区的颜色图，请使用 colormap 函数 marker: 标记样式 linewidths: 线宽 颜色种类 样式种类 直方图 hist12matplotlib.pyplot.hist(x, bins=10, range=None, normed=False, weights=None, cumulative=False, bottom=None, histtype=u'bar', align=u'mid', orientation=u'vertical', rwidth=None, log=False, color=None, label=None, stacked=False, hold=None, **kwargs) 参数说明: x: 横轴对应的数据 bins: 指定条状图的条形个数 range: 横轴的范围, 默认为数据最小和最大的值作为范围 normed: 默认为False, 纵轴表示频数, 如果置为True, 则纵轴表示频率 rwidth: 条状图柱子与柱子之间的距离, 默认为0 饼状图 pie]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch官方教程(三)-Learning PyTorch with Examples]]></title>
    <url>%2Fz_post%2FPyTorch-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B3-Learning-PyTorch-with-Examples%2F</url>
    <content type="text"><![CDATA[TensorsWarm-up: numpy对于numpy来说, 它对计算图, 深度学习, 梯度等等概念几乎是不知道的, 但是, 如果我们了解简单神经网络的具体结构, 那么我们就可以很轻易的用numpy来实现这个简单网络, 对此, 我们通常需要自己来实现前向计算和反向计算的逻辑, 下面我们来实现一个具有两层隐藏层的简单网络: 12345678910111213141516171819202122232425262728293031323334353637import numpy as np# N 为batch size, D_in 为输入维度# H 为隐藏层的维度, D_out 为输出的维度N, D_in, H, D_out = 64, 1000, 100, 10# 创建随机的输入和输出数据x = np.random.randn(N, D_in) # N × D_in 的矩阵y = np.random.randn(N, D_out) # N × D_out 的矩阵# 对两个隐藏层w1,w2进行初始化w1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)# 设置学习率learning_rate = 1e-6for t in range(500): # 前向传播: 计算预测结果 y_pred h = x.dot(w1) # x维度为64 × 1000, w1维度为 1000 × 100, 计算完以后, h维度为 64 × 100 h_relu = np.maximum(h,0) y = h_relu.dot(w2) # h_relu维度为 64×100, w2维度为100×10, y的维度为64×10 # 计算损失 loss = np.square(y_pred - y).sum() print(t, loss) # 反向传播根据loss更新w1和w2的值 grad_y_pred = 2.0*(y_pred - y) # 对y_pred求导 grad_w2 = h_relu.T.dot(grad_y_pred) # 对w2求导, 微分矩阵应该与w2的size相同 grad_h_relu = grad_y_pred.dot(w2.T) # 对h_relu求导 grad_h = grad_h_relu.copy() grad_h[h &lt; 0] = grad_h_relu # 经过relu, 将小于0的梯度归0 grad_w1 = x.T.dot(grad_h) # Update weights w1 = w1 - learning_rate * grad_w1 w2 = w2 - learning_rate * grad_w2 在执行上述代码以后, w1和w2的值会是的预测出来的pred_y与y之间的平方损失越来越小. PyTorch: Tensors用PyTorch实现一个简单的神经网络在神经网络的实现中, 较麻烦的是梯度的计算过程, 下面利用PyTorch的自动求导来实现一个简单的神经网络(两层隐藏层) 1234567891011121314151617181920212223242526272829303132333435363738import torchdtype = torch.floatdevice = torch.device("cpu")# N为batch size, D_in为input dimension# H为hidden dimension, D_out为output dimensionN, D_in, H, D_out = 64, 1000, 100, 10# 创建输入和输出的Tensors# requires_grad的值默认为False 指明无需计算x和y的梯度x = torch.randn(N, D_in, device=device, dtype=dtype)y = torch.randn(N, D_in, device=device, dtype=dtype)# 初始化两个隐藏层的参数, 注意要将requires_grad的值设置为Truew1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)learning_rate = 1e-6for t in range(500): ## torch.mm / torch.Tensor.mm : matrix multiplication h = x.mm(w1) h_relu = h.clamp(min=0) y_pred = h_relu.mm(w2) loss = (y_pred - y).pow(2).sum().item() print(t, loss) # BackProp grad_y_pred = 2*(y_pred - y) grad_w2 = h_relu.t().mm(grad_y_pred) grad_h_relu = grad_y_pred.mm(w2.t()) grad_h = grad_h_relu.clone() grad_h[h&lt;0] = 0 # 将grad_h_relu中小于0的都置为0, 即为relu的反向传播公式(因为小于0的梯度为0, 大于0的梯度为1) grad_w1 = x.t().mm(grad_h) w1 -= lr * grad_w1 w2 -= lr * grad_w2 Autograd自定义一个具有自动求导功能的PyTorch函数上面的例子是使用手动的方式求梯度的, 当模型参数变多时, 这样的方式显然很不方便. 不过, 借助PyTorch的autograd模块, 可以方便的求取任意参数的导数.在使用PyTorch的自动推导模块autograd时, 前向传播过程会被定义成一个计算图, 图中的节点是Tensors, 图中的边是一些函数, 用于根据 input Tensors 来生成 output Tensors. 比如当 x 是一个Tensor, 并且拥有属性x.requires_grad=True, 那么x.grad就是另一个Tensor, 它持有loss相对于x的梯度. 1234567891011121314151617181920212223242526272829303132333435363738import torchdtype = torch.floatdevice = torch.device("cpu")# N为batch size, D_in为input dimension# H为hidden dimension, D_out为output dimensionN, D_in, H, D_out = 64, 1000, 100, 10# 创建输入和输出的Tensors# requires_grad的值默认为False 指明无需计算x和y的梯度x = torch.randn(N, D_in, device=device, dtype=dtype)y = torch.randn(N, D_in, device=device, dtype=dtype)# 初始化两个隐藏层的参数, 注意要将requires_grad的值设置为Truew1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)learning_rate = 1e-6for t in range(500): # 定义前向计算过程, mm为两个矩阵相乘, clamp可以将数据限定在某一范围内, 实现relu的功能 y_pre = x.mm(w1).clamp(min=0).mm(w2) # 计算loss, loss.item()可以得到loss的矢量值 loss = (y_pred - y).pow(2).sum() print(t, loss.item()) # 只需要调用一条语句, 即可计算出所有requires_grad设置为True的参数的梯度, 可以通过w1或者w2的grad属性来访问各自的梯度. loss.backward() # 所有的ops, 如conv, relu等的backward方法已经在PyTorch内部实现 # 手动更新参数(面对大型网络时, 可以通过调用torch.optim.SGD来自动更新) # 将参数放在 torch.no_grad() 管理环境当中, 这是因为我们无需对grad进行跟踪, 因此, 也需要在更新完参数以后, 将grad重新置为0 , 以便下一次更新 with torch.no_grad(): w1 -= learning_rate*w1.grad w2 -= learning_rate*w2.grad # 为了避免当前求取的梯度的值累加到下一次迭代当中, 调用zero_原地清空grad. 对于nn.Module, 可以调用`zero_grad`来清空所有Module中的参数的梯度. w1.grad.zero_() w2.grad.zero_() Defining new autograd functions在PyTorch中, 每一个具有自动求导功能的operator都由两个作用在Tensors上的函数实现, 分别是用于计算输出的 前向函数 , 以及用于计算梯度的 反向函数. 因此, 我们在可以在PyTorch中通过继承父类torch.autograd.Function, 并实现其中的forward 和 backward 函数来定义自己的自定义autograd functions 1234567891011121314151617181920212223import torchclass MyReLU(torch.autograd.Function): @staticmethod # 将该方法变成静态方法, 使得不用实例化也可以调用, 当前实例化也可以调用 def forward(ctx, input): # ctx 是一个上下文管理器, 它可以利用`ctx.save_for_backward`把任何需要在backward用到的对象都存储起来 ctx.save_for_backward(input) return input.clamp(min=0) @staticmethod def backward(ctx, grad_output): # grad_output 为从下游传回来的梯度 input, = ctx.saved_tensors grad_input = grad_output.clone() grad_input[input&gt;0] = 0 return grad_input# 使用方法: 使用.apply方法来应用自定义的opsy_pred = MyReLU.apply(x.mm(w1)).mm(w2)# 为了方便, 也可以先对MyReLU重命名, 然后调用更简洁的别名relu = MyReLU.applyy_pred = relu(x.mm(w1)).mm(w2) Static GraphsPyTorch采用动态计算图, 而TensorFlow采用静态计算图 静态计算图: 只对计算图定义一次, 而后会多次执行这个计算图.好处: 可以预先对计算图进行优化, 融合一些计算图上的操作, 并且方便在分布式多GPU或多机的训练中优化模型 动态计算图: 每执行一次都会重新定义一张计算图. 控制流就像Python一样, 更容易被人接受, 可以方便的使用for, if等语句来动态的定义计算图, 并且调试起来较为方便. nn Modulenn对于大型网络模型来说, 直接使用autograd有些太过底层(too low-level). 为此在搭建神经网络时, 我们经常会将计算放置到 layers上 , 这些 layers 中的可学习参数会在训练中就行更新. 在TF中, Keras, TF-Slim等提高了封装性更高的高层API, 在PyTorch中, nn 包可以提供这些功能. 在nn包中, 定义了一系列的 Modules , 可以类比为神经网络中的不同层. 一个 Module 会接受一组 input Tensors, 并计算出对应的 output Tensors, 同时会持有一些内部状态(如可学习的权重参数). 在nn包中还定义了一系列有用的 loss functins 可供使用. 下面尝试用 nn 包来实现上面的两层网络: 123456789101112131415161718192021222324252627282930importN, D_in, H, D_out = 64, 1000, 100, 10x = torch.randn(N,D_in)y = torch.randn(N,D_out)# 由于当前的两层网络是序列的, 因此可以使用 torch.nn.Sequential 来定义一个Module, 该 Module 中包含了一些其它的 Modules (如Linear, ReLU等),# Sequential Module会序列化的执行这些 Modules, 并且自动计算其output和grads.# 注意因为是序列化执行的, 因此无需自定义 forward. 这是与 nn.Module 的区别之一.model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out))loss_fn = torch.nn.MESLoss(reduction="sum")lr = 1e04for t in range(500): y_pred = model(x) loss = loss_fn(y_pred, y) print(t, loss.item()) # 在获取梯度前, 先清空梯度缓存 model.zero_grad() loss.backward() with torch.no_grad(): for param in model.parameters(): param -= lr * param.grad optim可以看到, 上面在更新参数时, 我们仍采取的是手动更新的方式, 对于简单的优化算法来说, 这并不是什么难事, 但是如果我们希望使用更加复杂的优化算法如AdaGrad, Adam时, 采用 optim 包提供的高层API可以方便的使用这些优化算法.12345678optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)for t in range(500): y_pred = model(x) loss = loss_fn(y_pred, y) optimizer.zero_grad() # 已经将待优化参数model.parameters()传给优化器了 loss.backward() optimizer.step() # 执行一次参数优化操作(是不是很简单?) Custom nn Modules有时候, 我们需要定义一些相比于序列化模型更加复杂的模型, 此时, 我们可以通过继承nn.Module,同时定义forward前向计算函数来自定义一个 Module. 下面我们就用这种方式来自定义一个具有两层网络的 Module.12345678910111213141516171819202122232425262728class TwoLayerNet(torch.nn.Module): def __init__(self, D_in, H, D_out): # 通常我们将具有参数的层写在__init__函数中, 将不具有参数的ops写在forward中 self.linear1 = torch.nn.Linear(D_in, H) self.linear2 = torch.nn.Linear(H, D_out) def forward(self, input): h_relu = self.linear1(input).clamp(min=0) y_pred = self.linear2(h_relu) return y_predN, D_in, H, D_out = 64, 1000, 100, 10x = torch.randn(N, D_in)y = torch.randn(N, D_out)model = TwoLayerNet(D_in, H, D_out)loss_fn = torch.nn.MSELoss(reduction="sum")optim = torch.optim.SGD(model.parameters(), lr=1e-4)for t in range(500): y_pred = model(x) loss = loss_fn(y_pred, y) optim.zero_grad() loss.backward() optim.step() Control Flow + Weight Sharing为了更好的演示动态图和权重共享的特点, 我们会在下面实现一个非常奇怪的模型: 一个全连接的ReLU网络, 中间会随机的使用1~4层隐藏层, 并且重复利用相同的权重来计算最深层的隐藏层输出. 在PyTorch中, 我们可以通过for循环来实现这种动态模型, 并且通过重复调用同一个Module就可以很容易使用多层之间的参数共享, 如下所示:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import randomimport torchclass DynamicNet(torch.nn.Module): def __init__(self, D_in, H, D_out): # 实现三个 nn.Linear 实例, 意味着在模型中只有 三个 nn.Linear 的参数 super(DynamicNet, self).__init__() self.input_linear = torch.nn.Linear(D_in, H) self.middle_linear = torch.nn.Linear(H, H) self.output_linear = torch.nn.Linear(H, D_out) def forward(self, x): """ 在PyTorch中, 我们可以通过for循环来随机的选择中间层的层数, 使得每一次 执行forward函数时, 都具有不同的中间层层数. 而这些中间层都来自于同一个Module实例, 因而具有共享的权重参数. """ h_relu = self.input_linear(x).clamp(min=0) for _ in range(random.randint(0,3)): h_relu = self.middle_linear(h_relu).clamp(min=0) y_pred = self.output_linear(h_relu) return y_pred;# N is batch size; D_in is input dimension;# H is hidden dimension; D_out is output dimension.N, D_in, H, D_out = 64, 1000, 100, 10# Create random Tensors to hold inputs and outputsx = torch.randn(N, D_in)y = torch.randn(N, D_out)# Construct our model by instantiating the class defined abovemodel = DynamicNet(D_in, H, D_out)# Construct our loss function and an Optimizer. Training this strange model with# vanilla stochastic gradient descent is tough, so we use momentumcriterion = torch.nn.MSELoss(reduction='sum')optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)for t in range(500): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x) # Compute and print loss loss = criterion(y_pred, y) print(t, loss.item()) # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step()]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乱七八糟]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F%2F</url>
    <content type="text"><![CDATA[mac Finder 顶部显示路径1defaults write com.apple.finder _FXShowPosixPathInTitle -bool TRUE 还原:1defaults delete com.apple.finder _FXShowPosixPathInTitle 关闭所有窗口, 重新打开即可1killall Finder https://jingyan.baidu.com/article/380abd0a12007b1d91192c5e.html ubuntu 输入法失效点击 fcitx 没有反应, 尝试重新安装 123sudo apt remove fcitx*#rm -rf ~/.config/fcitxsudo apt install fcitx gcc/g++ 降级升级【链接】ubuntu16.04LTS降级安装gcc4.8https://www.cnblogs.com/in4ight/p/6626708.html Jupyter报错: ImportError: cannot import name &#39;create_prompt_application&#39; 原因:https://github.com/jupyter/jupyter_console/issues/158 解决方案1pip install 'prompt-toolkit==1.0.15' 无法挂载 D 盘 (windows 未完全关闭导致)Unable to access “WinD”123456Error mounting /dev/sda6 at /media/ubuntu/Media Center: Command-line `mount -t &quot;ntfs&quot; -o &quot;uhelper=udisks2,nodev,nosuid,uid=1000,gid=1000,dmask=0077,fmask=0177&quot; &quot;/dev/sda6&quot; &quot;/media/rolindroy/Media Center&quot;&apos; exited with non-zero exit status 14: The disk contains an unclean file system (0, 0).Metadata kept in Windows cache, refused to mount.Failed to mount &apos;/dev/sda6&apos;: Operation not permittedThe NTFS partition is in an unsafe state. Please resume and shutdownWindows fully (no hibernation or fast restarting), or mount the volumeread-only with the &apos;ro&apos; mount option https://askubuntu.com/questions/462381/cant-mount-ntfs-drive-the-disk-contains-an-unclean-file-system 谷歌浏览器不能手势双击有可能是没有打开这项功能, 需要在触控板设置里看一下 如果打开了, 那就是某个插件与手势可能有冲突, 目前已知的有 Mouse什么的 (鼠标手势插件) 如何在英文版 Chrome 登录印象笔记剪藏插件？Chrome 商店上的最新版 https://chrome.google.com/webstore/detail/evernote-web-clipper/pioclpoplcdbaefihamjohnefbikjilc 已经可以切换到国内的印象笔记，方法是在选项界面用键盘输入一遍 上上下下左右左右BA ，不用考虑大小写，代码里就是判断的就是 ↑ ↑ ↓ ↓ ← → ← → B A。然后会出个新Tab: Developer Options 勾选上模拟简体中文，再点击“Save and reload clipper”后，就可以登录印象笔记了。（评论中有人遇到仍然不能登录的情况，此时请在上图的“Override Service URL”下方填写 app.yinxiang.com ，然后再“Save”试试。） windows 将 ctrl 和 caps clock 键互换创建文件caps_ctrl.reg, 输入如下内容:123Windows Registry Editor Version 5.00[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Keyboard Layout]&quot;Scancode Map&quot;=hex:00,00,00,00,00,00,00,00,03,00,00,00,1D,00,3A,00,3A,00,1D,00,00,00,00,00 双击运行, 然后查看是否修改完成 若成功修改, 重启即可. 双系统 windows 方法 ubuntu 文件下载 ext2explore工具 地址：https://sourceforge.net/projects/ext2read/files/latest/download 更改windows分区导致出现 grub error: unknown filesystem12345678910111213141516lsset#以(hd0,msdos1)为例，分别输入：set root=hd0,msdos1set prefix=(hd0,msdos1)/boot/grub# 检查是否正确, 如果出现unknown filesystem则错误, 如果没有返回则正确insmod normal# 输入 normal, 引导界面正确呈现normal# 选择ubuntu，进入之后启动终端，输入如下命令sudo update-grubsudo grub-install /dev/sda 修复引导Boot Repair Ubuntu 无损扩容1。先在windows里面划分出一个未分配的空间2。用linux live creater或者其他linux livecd制作软件 制作带有ubuntu镜像的u盘3。在bios里面用u盘启动ubuntu（选择 try ubuntu without installing）4。在u盘启动的ubuntu里打开GParted5。在GParted中，将未分配的空间移动到你想要合并的分区的附近（遇到swap要swapoff，遇到/ /home等要进行unmount，不过貌似u盘启动的ubuntu默认就是unmunt的）6。提交移动/调整大小操作，根据操作涉及的空间大小需要等待一段时间7。操作完成后，重启机器，无损扩容完成！ Ubuntu 互换 ctrl 和 caps 键位即刻生效1setxkbmap -option "ctrl:swapcaps" 重启生效12# 在/etc/default/keyboard文件中添加XKBOPTIONS="ctrl:nocaps" pip 安装速度慢Linux系统pip、conda等包管理程序下载速度慢的主要原因是默认的下载镜像源是国外的，而解决方法是修改镜像源到国内即可，具体如下： pip目前可用源：http://pypi.douban.com/ 豆瓣http://pypi.hustunique.com/ 华中理工大学http://pypi.sdutlinux.org/ 山东理工大学http://pypi.mirrors.ustc.edu.cn/ 中国科学技术大学http://mirrors.aliyun.com/pypi/simple/ 阿里云https://pypi.tuna.tsinghua.edu.cn/simple/ 清华大学 1.临时使用：可以使用pip时添加参数 -i[url]，如： 1pip install -i http://pypi.douban.com/simple/ gevent 2.永久生效：修改~/.pip/pip.conf，修改index-url至相应源（如果没有该文件或文件夹，就先在home下创建.pip文件夹，再在.pip文件夹里面创建.pip.conf文件）123[global]index-url = http://mirrors.aliyun.com/pypi/simpletrusted-host = mirrors.aliyun.com #对应阿里云的host，其他的可以自己查一下，也可以不写这一句 conda可用源清华https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/中科大http://mirrors.ustc.edu.cn/anaconda/pkgs/free/ 1$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 然后可以输入下面的指令查看当前的源：1$ conda config --show 或者修改成.condarc文件，在文件中输入下面的指令。 1234channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - defaultsshow_channel_urls: true 更换 apt 源备份系统自带源1mv /etc/apt/sources.list /etc/apt/sources.list.bak 修改/etc/apt/sources.list文件1/etc/apt/sources.list 阿里源: https://opsx.alibaba.com/mirror 若更新了源以后仍然不好使, 尝试删除sources.list.d(将其重命名) 若 apt-get update时卡在 waiting for headers, 则删除下面的文件123# rm /var/lib/apt/lists/*rm /var/lib/apt/lists/partial/*apt-get update pyenv 安装速度慢尝试离线安装, 先下载对应包, 存储到 ~/.pyenv/cache 文件夹中, 然后尝试安装指令. 注意事项: cache 文件夹如果是自己创建的, 那么一定要注意修改权限, 用sudo创建 文件夹名字要保持一致, 例如自己下载的是, xxx.sh, 但是 pyenv 在安装时会安装 xxx.sh.sh, 这里只要将名字修改一致即可 自己使用pyenv install 时, 最好加上 sudo. atom 安装插件慢方法一: 翻墙 方法二: 利用 git 克隆到本地安装 先进入插件安装的目录1cd /Users/zerozone/.atom/packages 将需要的仓库 clone 下来，再npm install123git clone git@github.com:Glavin001/atom-beautify.gitcd atom-beautifynpm install 最后重启下 atom 就可以看到插件安装成功 opencv python2.7 缺少文件1python2.7 from .cv2 import *ImportError: libSM.so.6: cannot open shared object file: No such file or directory 方法一: 升级到python3 方法二: 安装指定版本的opencv-python(其他版本貌似对应的是python3):1pip install opencv-python==3.2.0.8 pickle 在编码解码时遇到的 python2 和 python3 不兼容的问题https://stackoverflow.com/questions/11305790/pickle-incompatibility-of-numpy-arrays-between-python-2-and-3 解决方法: 在python2下执行 使用lattin1encoding(亲测可行): 12345678910import pickleimport numpy as nppkl_path = &apos;/home/zerozone/Works/GAN/StackGAN-v2-python3/data/birds/test/char-CNN-RNN-embeddings.pickle&apos;with open(pkl_path, &apos;rb&apos;) as f: embeddings = pickle.load(f, encoding=&apos;latin1&apos;) embeddings = np.array(embeddings) # embedding_shape = [embeddings.shape[-1]] print(&apos;embeddings: &apos;, embeddings.shape)]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 系统下安装 NVIDIA 驱动]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-Ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%89%E8%A3%85NVIDIA%E9%A9%B1%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[安装步骤卸载所有安装的nvidia驱动(可选)如果之前没安装过nvidia驱动，可以不执行此步骤.123sudo service lightdm stop # 卸载之前应该先停止 lightdmsudo /usr/bin/nvidia-uninstallsudo apt-get --purge remove &quot;nvidia-*&quot; 卸载完以后，重启。 禁用nouveau驱动和相关的驱动包用编辑器打开blacklist.conf配置文件1sudo gedit /etc/modprobe.d/blacklist.conf 在文件的最后一行加入下面的命令，屏蔽有影响的驱动包12345blacklist rivafbblacklist vga16fbblacklist nouveaublacklist nvidiafbblacklist rivatv 测试是否禁用成功1lsmod | grep nouveau 如果有输出则代表nouveau正在加载。修改blacklist-nouveau.conf(若没有则创建)1sudo gedit /etc/modprobe.d/blacklist-nouveau.conf 文件中输入以下内容并保存:12blacklist nouveauoptions nouveau modeset=0 之后更新1sudo update-initramfs -u 重启1sudo reboot 再次查看1lsmod | grep nouveau 没有输出即为禁用成功，重启后很明显可以发现终端命令中打字体变大了 一定要禁用之后才能安装, 否则会报错, 错误内容在最后面的整理部分 安装显卡驱动安装需要的依赖123456sudo apt updatesudo apt install dkms build-essential linux-headers-generic# 32 位库兼容性支持相关文件sudo apt-get install lib32ncurses5sudo apt-get install lib32z1 安装驱动包Ctrl+Alt+F1 进入命令提示符界面然后，输入对应的username和passwd进入命令行.最后，使用下面的指令 关闭图形界面 1sudo service lightdm stop 更改执行权限, 进行安装, 不要忘了后面的选项12345sudo chmod 755 NVIDIA-Linux-x86_64-384.111.run #修改权限（否则没有访问权限，无法进行指令安装）sudo ./NVIDIA-Linux-x86_64-384.111.run –no-x-check –no-nouveau-check –no-opengl-files #安装驱动#–no-x-check 关闭X服务#–no-nouveau-check 禁用nouveau#–no-opengl-files 不安装OpenGL文件 安装过程中遇到 kernel-module, 选 yes, 32-兼容, 选 yes. 安装完成后, 更新重启12sudo update-initramfs -usudo reboot 判断显卡驱动是否安装成功1nvidia-smi #输入指令查看显卡信息 遇到问题错误1.1the distribution-provided pre-install script failed! 这个问题源自nvidia驱动安装包自身的问题，这里我们可以直接点击yes或者continue继续安装错误2.12345678ERROR: Unable to load the kernel module &apos;nvidia.ko&apos;. This happens mostfrequently when this kernel module was built against the wrong orimproperly configured kernel sources, with a version of gcc that differsfrom the one used to build the target kernel, or if a driver such asrivafb/nvidiafb is present and prevents the NVIDIA kernel module fromobtaining ownership of the NVIDIA graphics device(s), or NVIDIA GPUinstalled in this system is not supported by this NVIDIA Linux graphicsdriver release. 遇到此问题, 要么是安装本身不匹配或者破损, 要么没有完全禁用nouveau, 根据上面的安装方式禁用即可. 错误3.检测到系统已经安装了其他版本的nvidia驱动驱动没卸载干净，可以使用sudo apt-get --purge remove nvidia-*命令，卸载所有的nvidia驱动，也可以点继续，这样在安装过程中会自动卸载旧驱动 错误4.在安装的最后一步，没有提示安装成功，而是显示1Error：Unable to load the &apos;nvidia-drm&apos; kernel module . 出现这个问题最有可能的原因是你安装的Ubuntu是UEFI模式启动的，但是在BIOS中却打开了Security BOOT选项. 正确做法是 禁用该选项 错误5.安装过程中有可能会弹出X.org异常警告，以我的经验来说你可以无视该警告继续安装，这样并不会有什么问题1`pkg-config` utility and the X.Org SDK/development package for your distribution and reinstall the driver. 错误6. 就是安装完以后仍不能nvidia-smi，解决办法是去boot里将secureboot 设置成disable，这步操作完nvidia-smi就有结果了 错误7: 循环登录主要表现为在登录界面输入密码后依然跳转回登陆界面，无限循环，这是在使用.run文件安装时遇到的问题，这里有一个亲测有效的解决方案： 当输入安装指令时，不要简单地输入 sudo ./NVIDIA-Linux-x86_64-384.111.run，而是输入：123456sudo ./NVIDIA-Linux-x86_64-384.111.run -no-x-check -no-nouveau-check -no-opengl-files-no-x-check：安装驱动时关闭X服务-no-nouveau-check：安装驱动时禁用nouveau-no-opengl-files：只安装驱动文件，不安装OpenGL文件 这样再reboot，就不会出现循环登录的问题。 其他问题: http://www.cnblogs.com/matthewli/p/6715553.html]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PyTorch官方教程(二)-DataLoadingAndProcessing]]></title>
    <url>%2Fz_post%2FPyTorch-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B2-Data-Loading-and-Processing%2F</url>
    <content type="text"><![CDATA[对于一个新的机器/深度学习任务, 大量的时间都会花费在数据准备上. PyTorch提供了多种辅助工具来帮助用户更方便的处理和加载数据. 本示例主要会用到以下两个包: scikit-image: 用于读取和处理图片 pandas: 用于解析csv文件 导入下面的包123456789101112131415from __future__ import print_function, divisionimport osimport torchimport pandas as pdfrom skimage import io, transformimport numpy as npimport matplotlib.pyplot as pltfrom torch.utils.data import Dataset, DataLoaderfrom torchvision import transforms, utils# Ignore warningsimport warningswarnings.filterwarnings("ignore")plt.ion() # interactive mode 本示例使用的是人脸姿态的数据集, 数据集的标注信息是由68个landmark点组成的, csv文件的格式如下所示:123image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y0805personali01.jpg,27,83,27,98, ... 84,1341084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312 利用如下代码可以快速的读取CSV文件里面的标注信息, 并且将其转换成 (N,2) 的数组形式, 其中, N 为 landmarks 点的个数12345678910landmarks_frame = pd.read_csv('faces/face_landmarks.csv')n = 65img_name = landmarks_frame.iloc[n, 0]landmarks = landmarks_frame.iloc[n, 1:].as_matrix()landmarks = landmarks.astype('float').reshape(-1, 2)print('Image name: &#123;&#125;'.format(img_name))print('Landmarks shape: &#123;&#125;'.format(landmarks.shape))print('First 4 Landmarks: &#123;&#125;'.format(landmarks[:4])) 利用下面的函数可以将图像和标注文件中的点显示出来, 方便观察:12345678910def show_landmarks(image, landmarks): """Show image with landmarks""" plt.imshow(image) plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r') plt.pause(0.001) # pause a bit so that plots are updatedplt.figure()show_landmarks(io.imread(os.path.join('faces/', img_name)), landmarks)plt.show() Dataset classtorch.utils.data.Dataset实际上是一个用来表示数据集的虚类, 我们可以通过集成该类来定义我们自己的数据集, 在继承时, 需要重写以下方法: __len__: 让自定义数据集支持通过len(dataset)来返回dataset的size __getitem__: 让自定义数据集支持通过下标dataset[i]来获取第 $i$ 个数据样本. 接下来, 尝试创建人脸姿态的自定义数据集. 我们将会在__init__函数中读取csv文件, 但是会将读取图片的逻辑代码写在__getitem__方法中. 这么做有助于提高内存使用效率, 因为我们并不需要所有的图片同时存储在内存中, 只需要在用到的时候将指定数量的图片加载到内存中即可. 我们的数据集样本将会是字典形式: {&#39;image&#39;: image, &#39;landmarks&#39;:landmarks}. 我们的数据集将会接受一个可选参数transform, 以便可以将任何需要的图片处理操作应用在数据样本上. 使用transform会使得代码看起来异常整洁干净.123456789101112131415161718192021222324class FaceLandmarksDataset(Dataset): def __init__(self, csv_file, root_dir, transform=None): # 参数: # csv_file(string): csv标签文件的路径 # root_dir(string): 所有图片的文件夹路径 # transform(callable, optioinal): 可选的变换操作 self.landmarks_frame = pd.read_csv(csv_file) self.root_dir = root_dir self.transform = transform def __len__(self): return len(self.landmarks_frame) def __getitem__(self, idx): img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0]) image = io.imread(img_name) landmarks = self.landmarks.astype("float").reshape(-1,2) sample = &#123;"image": image, "landmarks":landmarks&#125; if self.transform: sample = self.transform(sample) return sample 接下来, 让我们对这个类进行初始化1234567891011121314face_dataset = FaceLandmarksDataset(csv_file="faces/face_.csv", root_dir="faces/")fig = plt.figure()for i in range(len(face_dataset)): sample = face_dataset[i] print(i, sample["image"].shape, sample["landmarks"]) ax = plt.subplot(1,4,i+1) plt.tight_layout() ax.set_title("Sample") ax.axis("off") show_landmarks(**sample) if i==3: plt.show() break Transforms尝试以下三种常见的转换操作: Rescale: 改变图片的尺寸大小 RandomCrop: 对图片进行随机剪裁(数据增广技术) ToTensor: 将numpy图片转换成tensor数据 我们将会把这些操作写成可供调用的类, 而不仅仅是一个简单的函数, 这样做的主要好处是不用每次都传递transform的相关参数. 为了实现可调用的类, 我们需要实现类的 __call__ 方法, 并且根据需要实现 __init__ 方法. 我们可以像下面这样使用这些类:12tsfm = Transform(params)transformed_sample = tsfm(sample) 具体实现如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class Rescale(object): def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) self.output_size = output_size def __call__(self, sample): image, landmarks = sample["image"], sample["landmarks"] h, w = image.shape[:2] if isinstance(self.output_size, int): if h&gt;w: new_h, new_w = self.output_size*h/w, self.out_size else: new_h, new_w = self.output_size, self.output_size*w/h else: new_h, new_w = self.output_size new_h, new_w = int(new_h), int(new_w) img = transform.resize(image, (new_h, new_w)) landmarks = landmarks*[new_w/w, new_h/h] return &#123;"image":img, "landmarks": landmarks&#125;class RandomCrop(object): """Crop randomly the image in a sample. Args: output_size (tuple or int): Desired output size. If int, square crop is made. """ def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) if isinstance(output_size, int): self.output_size = (output_size, output_size) else: assert len(output_size) == 2 self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] new_h, new_w = self.output_size top = np.random.randint(0, h - new_h) left = np.random.randint(0, w - new_w) image = image[top: top + new_h, left: left + new_w] landmarks = landmarks - [left, top] return &#123;'image': image, 'landmarks': landmarks&#125;class ToTensor(object): """Convert ndarrays in sample to Tensors.""" def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] # swap color axis because # numpy image: H x W x C # torch image: C X H X W image = image.transpose((2, 0, 1)) return &#123;'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)&#125; Compose transforms接下来, 需要将定义好的转换操作应用到具体的样本上, 我们首先将特定的操作组合在一起, 然后利用torchvision.transforms.Compose方法直接将操作应用到对应的图片上.1234567891011121314151617scale = Rescale(256)crop = RandomCrop(128)composed = transforms.Compose([Rescale(256), RandomCrop(224)])# Apply each of the above transforms on sample.fig = plt.figure()sample = face_dataset[65]for i, tsfrm in enumerate([scale, crop, composed]): transformed_sample = tsfrm(sample) ax = plt.subplot(1, 3, i + 1) plt.tight_layout() ax.set_title(type(tsfrm).__name__) show_landmarks(**transformed_sample)plt.show() Iterating through the dataset总结一下对数据采样的过程: 从文件中读取一张图片 将transforms应用到图片上 由于transforms是随机应用的, 因此起到了一定的增广效果. 可以利用 for i in range循环操作来对整个数据集进行transforms12345678910transformed_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',root_dir='faces/', transform=transforms.Compose([Rescale(256),RandomCrop(224),ToTensor()]))for i in range(len(transformed_dataset)): sample = transformed_dataset[i] print(i, sample['image'].size(), sample['landmarks'].size()) if i == 3: break Afterword: torchvision123456789101112131415import torchfrom torchvision import transforms, datasetsdata_transform = transforms.Compose([ transforms.RandomSizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train', transform=data_transform)dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset, batch_size=4, shuffle=True, num_workers=4)]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种网络层]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%90%84%E7%A7%8D%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[全连接层 全连接层底层是如何实现的转换成矩阵和相乘的乘法, 然后利用 CUBLAS 或者 OpenBLAS 进行运算. 卷积层 简述 1x1 卷积层的作用 卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用 卷积层底层是如何实现的一种比较方便也是比较偷懒的卷积层实现方法都是将图片或者特征图谱利用 im2col 方法展开成矩阵, 将卷积操作变成普通的矩阵乘法, 然后利用 cuBLAS 或者 OpenBLAS 的库函数进行计算. 具体来说, 对于任意的输入图谱, 根据卷积核的大小在特征图谱上获得一个 patch, 将这个 patch 里面的元素拿出来变成矩阵的一列, 按照卷积操作, 取出所有的 path 组成一个新的矩阵. 然后将卷积核展开成一个矩阵, 矩阵的每一行都是卷积核中的元素, 总共的行数和输出图谱的通道数相关. 这样, 卷积的计算操作就变成了普通的矩阵乘法. 这里可以看出, 对于卷积核大于 1 的卷积层来说, 我们需要按照卷积核的大小对图谱重新进行排列. 但是, 当卷积核大小为 1 时, 我们就无需排列, 直接将其展开即可. 这也解释了 MobileNet 中提到的 $1\times 1$ 卷积在实现上执行速度很快的原因. im2col+GEMM 的卷积实现方法有一个很明显的问题就是, 会存储大量的冗余元素, 使得内存消耗比较大. 当然, 随着新的算法出现, 卷积层对3*3的卷积核有专门的算法. 其他计算卷积的方法: FFT: 大卷积核时使用, 时域卷积等于频域相乘, 因此可以将问题转化成简单的乘法问题. cuFFT Winograd: 据说在 GPU 上效率更高, 貌似是针对 $2\times2$ 和 $3\times 3$ 的卷积核专门使用的? NNPACK: FFT 和 Winograd 方法的结合 MEC(17年): 一种内存利用率高且速度较快的卷积计算方法, http://cn.arxiv.org/pdf/1706.06873v1. 主要改进了 im2col+GEMM 的策略, 目的主要是减少内存消耗的同时顺便提升速度. 由于同样可以利用现有的矩阵运算库, 因此算法的实现难度并不大. CNN 基础之卷积及其矩阵加速 http://shuokay.com/2016/06/08/convolution Winograd 方法快速计算卷积 http://shuokay.com/2018/02/21/winograd/ https://blog.csdn.net/antkillerfarm/article/details/78829889 https://blog.csdn.net/xiaoxiaowenqiang/article/details/82050354 BLAS 接受, 矩阵乘法优化 https://www.leiphone.com/news/201704/Puevv3ZWxn0heoEv.html im2col 讲解: https://blog.csdn.net/Mrhiuser/article/details/52672824 简述矩阵乘法的优化方法BLAS: Basic Linear Algebra Subprograms. 分为三级: BLAS 1级: 向量与向量之间的点乘或者乘加运算, 元素运算; BLAS 2级: 向量与矩阵的运算, 矩阵变形; BLAS 3级: 矩阵与矩阵的运算; 反卷积层池化层]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch官方教程(一)-A 60 Minute Blitz]]></title>
    <url>%2Fz_post%2FPyTorch-%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B1-60MinuteBlitz%2F</url>
    <content type="text"><![CDATA[What is PyTorch?一个基于Python的科学计算包, 设计目的有两点: numpy在GPUs实现上的替代品 具有高度灵活性和速度的深度学习研究平台 TensorsTensors可以理解成是Numpy中的ndarrays, 只不过Tensors支持GPU加速计算. 12345678910x = torch.empty(5,3)print(x) # 输出 5×3 的未初始化的矩阵, 矩阵元素未初始化, 所以可能是浮点类型的任何职x = torch.rand(5,3)x = torch.zeros(5,4,dtype=torch.long)x = torch.tensor([5.5, 3]) # 直接用常数来初始化一个Tensorx.size() # Tensor的size OperationsPyTorch支持多种语法实现相同的操作. 加法:12345678910111213141516171819202122232425x = torch.rand(5,3)y = torch.rand(5,3)z1 = x + yz2 = torch.add(x,y)z3 = torch.empty(5,3)torch.add(x,y,out=z3)# in-placey.add_(x) # _ 代表原地加法 也就是 y = y+x# 可以想numpy数组一样使用tensor:print(x[:,-1])# Resizing, 利用torch.view来对tensor执行reshape/resize操作x = torch.randn(4, 4)y = x.view(16)z = x.view(-1,8) # -1代表自动推断维度print(x.size(), y.size(), z.size()) # torch.Size([4,4]) torch.Size([16]) torch.Size([2,8])# item()可以获得只有一个元素的tensor的值x = torch.randn(1)print(x.item()) Tensor与Numpy Array从tensor转换成numpy数组: 1234a = torch.ones(5)print(type(a)) # &lt;class 'torch.Tensor'&gt;b = a.numpy()print(type(b)) # &lt;class 'numpy.ndarray'&gt; 注意, 此时a和b共享内存, 即a和b指向的都是同一个数据, 也就是说, 如果改变a的值, 那么b的值也会随之改变!!12print(a.add_(1)) # tensor([2., 2., 2., 2., 2])print(b) # [2., 2., 2., 2., 2] 从numpy数组转换成tensor 12a = np.ones(5)b = torch.from_numpy(a) 同样, a和b是共享内存的 所有位于CPU上的Tensor (除了CharTensor) 都支持转换成对应的numpy数组并且再转换回来. CUDA TensorsTensors可以利用.to方法移动到任何设备上去123456if torch.cuda.is_avaiable(): device = torch.device("cuda") # 创建了一个cuda device对象 y = torch.ones_like(x, device=device) # 直接从GPU上创建tensor x = x.to(device) # 将x移到gpu上, 也可以直接用字符串指明: x = x.to("cuda") z = x+y z.to("cpu", torch.double) Neural Networks可以利用torch.nn包来创建神经网络, nn依靠autograd来定义模型并且对其计算微分. 从nn.Module类派生的子类中会包含模型的layers, 子类的成员函数forward(input)会返回模型的运行结果. 经典的训练神经网络的过程包含以下步骤: 定义具有一些可学习参数(权重)的神经网络 在数据集上创建迭代器 将数据送入到网络中处理 计算loss 对参数进行反向求导 更新参数: $weight = weight - lr*gradient$ 定义一个简单的网络12345678910111213141516171819202122232425262728293031323334353637import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_featuresnet = Net()print(net) 输出如下1234567Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True)) 当定义好模型的forward()函数以后, backward()函数就会自动利用autograd机制定义, 无需认为定义. 可以通过net.parameters()函数来获取模型中可学习的参数 123params = net.parameter() # params的类型为 &lt;class 'Iterator'&gt;print(len(list(params))) # 具有可学习参数的层数print(list(params)[0].size()) # conv1 的参数 根据网络结构接受的输入, 想网络中传输数据并获取计算结果123input = torch.randn(1,1,32,32) # 四个维度分别为 (N,C,H,W)out = net(input) # 自动调用forward函数进行计算并返回结果print(out) #tensor([[ 0.1246, -0.0511, 0.0235, 0.1766, -0.0359, -0.0334, 0.1161, 0.0534, 0.0282, -0.0202]], grad_fn=&lt;ThAddmmBackward&gt;) 下面的代码可以清空梯度缓存并计算所有需要求导的参数的梯度12net.zero_grad()out.backward(torch.randn(1,10)) # 正如前面所说, 当定义了forward函数以后, 就会自动定义backward函数, 因此可以直接使用 需要注意的是, 整个torch.nn包只支持mini-batches, 所以对于单个样本, 也需要显示指明batch size=1, 即input第一个维度的值为1 也可以对单个样本使用input.unsqueeze(0)来添加一个假的batch dimension. Loss Function一个损失函数往往接收的是一对儿数据 (output, target). 然后根据相应规则计算output和target之间相差多远, 如下所示: 1234567output = net(input)target = torch.randn(10)target = target.view(1,-1) # 令target和output的shape相同.criterion = nn.MSELoss()loss = criterion(output, target)print(loss) # tensor(1.3638, grad_fn=&lt;MseLossBackward&gt;) 利用.grad_fn属性, 可以看到关于loss的计算图:12345print(loss.grad_fn) # 返回MseLossBackward对象#input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d# -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear# -&gt; MSELoss# -&gt; loss 因此, 当调用loss.backward()时, 就会计算出所有(requires_grad=True的)参数关于loss的梯度, 并且这些参数都将具有.grad属性来获得计算好的梯度 BackProp再利用loss.backward()计算梯度之前, 需要先清空已经存在的梯度缓存(因为PyTorch是基于动态图的, 每迭代一次就会留下计算缓存, 到一下次循环时需要手动清楚缓存), 如果不清除的话, 梯度就换累加(注意不是覆盖). 123456net.zero_grad() # 清楚缓存print(net.conv1.bias.grad) # tensor([0., 0., 0., 0., 0., 0.])loss.backward()print(net.conv1.bias.grad) # tensor([ 0.0181, -0.0048, -0.0229, -0.0138, -0.0088, -0.0107]) Update The Weights最简单的更新方法是按照权重的更新公式:123learning_rate = 0.001for f in net.parameters(): f.data.sub_(learning_rate*f.grad.data) 当希望使用一些不同的更新方法如SGD, Adam等时, 可以利用torch.optim包来实现, 如下所示:12345678import torch.optim as optimoptimizer = optim.SGD(net.parameters(), lr=0.01) # 创建优化器optimizer.zero_grad() # 清空缓存output = net(input)loss = criterion(output, target)loss.backward() # 计算梯度optimizer.step() # 执行一次更新 Train A ClassifierWhat About Data?通常情况下, 在处理数据的时候可以使用标准的Python包(opencv, skimage等), 并将其载入成Numpy数组的形式, 然后可以很方便的将其转换成torch.*Tensor数据. 对于图像数据来说, PyTorch提供了torchvision包, 它包含许多常见数据集(Imagenet, CIFAR10, MNIST等等)的加载器, 同时还包含其他一些针对图片的数据转换(data transformers)函数. 对于CIFAR10来说, 它的数据集中图片尺寸为 3×32×32, 总共具有10个不同的类别. 下面就来看一下如何训练一个分类器将这10个类别进行分类. Training An Image Classifier接下来主要包括以下步骤: 使用torchvision加载并归一化CIFAR10的训练数据集和测试数据集. 定义一个卷积神经网络 定义损失函数 在traing data上训练网络 在test datauh测试网络 Loading and normalizing CIFAR10: 导入相关的包123import torchimport torchvisionimport torchvision.transforms as transforms torchvision的输出类型是 PILImage. 我们需要将其转换成 Tensors, 并对其进行归一化, 使其数值处于 [-1, 1] 之间.123456789101112131415# 将多个transforms链接(chained)起来transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') 利用下面的代码可以查看CIFAR10中的训练图片样本:1234567891011121314151617181920import matplotlib.pyplot as pltimport numpy as np# functions to show an imagedef imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0)))# get some random training imagesdataiter = iter(trainloader)images, labels = dataiter.next()# show imagesimshow(torchvision.utils.make_grid(images))# print labelsprint(' '.join('%5s' % classes[labels[j]] for j in range(4))) 定义卷积神经网络:123456789101112131415161718192021222324import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Model): def __init__(self): super(self, Net).__init__ self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) # 两个max pooling的参数是一样的, 所以定义一个就行, 可以重复使用 self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, input): x = self.pool(F.relu(self.conv1(input))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16*5*5) # 第一个维度为batch size x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) output = self.fc3(x) return outputnet = Net() Define a Loss function and optimizer: 损失函数使用交叉熵, 优化器使用带动量的SGD123import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 训练网络: 训练网络的时候, 我们需要简单的在数据迭代器上进行循环操作就可以, 只需要注意不断想网络中送入新的数据即可.123456789101112131415161718192021222324for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0print('Finished Training') Test the network on the test data 在测试集上获取模型的准确率, 只需要利用outputs = net(images)即可获得预测的类别概率, 取最大者为预测的类别结果. 123456789101112correct = 0total = 0with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item()print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total)) 利用下面的代码可以看到每个类别的准确率: 1234567891011121314151617class_correct = list(0. for i in range(10))class_total = list(0. for i in range(10))with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1for i in range(10): print('Accuracy of %5s : %2d %%' % ( classes[i], 100 * class_correct[i] / class_total[i])) Training on GPU上面的代码是在CPU上训练的, 那么如何利用PyTorch在GPU上进行训练呢? 实际上, 只需要将模型转移到GPU上即可. 首先定义一个device对象:12device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")print(device) # 输出 cdua:0 接下来, 利用.to()方法将模型转移到GPU上面(同时所有的参数和梯度缓存也会转移到GPU上)1net.to(device) # 也可以直接写成 net.to(device), 但是这样会缺少了设备检查, 不够健壮 接下来, 再向模型投喂数据之前, 就需要先将数据转移到GPU上1inputs, labels = inputs.to(device), labels.to(device) 其余代码均与上面的训练代码相同. Training on multiple GPUs//TODO]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lmdb模块-键值型数据库]]></title>
    <url>%2Fz_post%2FPython-lmdb%2F</url>
    <content type="text"><![CDATA[LMDB 数据库和常用的 SQLite, MySQL 等关系型数据库不同, 它是一种非关系型数据库, 以键值对的方式进行存储(更像是字典), 其中 “键” 和 “值” 的类型都是字符串类型. 由于 LMDB 数据集的读取效率较高, 因此追求轻量级和速度的 Caffe2 选用这种数据库作为其常用的数据读取形式. 常用使用方式: import lmdb: 导入 LMDB 包 env = imdb.open(): 打开环境 txn = env.begin(): 建立事物 txn.put(key, value): 进行插入和修改 txn.delete(key): 进行删除 txn.get(key): 进行查询 txn.cursor(): 进行遍历 txn.commit(): 提交更改 https://blog.csdn.net/u010472607/article/details/76855509https://zhuanlan.zhihu.com/p/23485774]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Training ImageNet in 1 Hour]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-TrainingImageNetIn1Hour%2F</url>
    <content type="text"><![CDATA[文章: Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour作者: Priya Goyal Piotr Dollar Ross Girshick Pieter Noordhuis, Lukasz Wesolowski Aapo Kyrola Andrew Tulloch Yangqing Jia Kaiming He备注: Facebook AI Research (FAIR)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[time和datetime模块-时间与日期]]></title>
    <url>%2Fz_post%2FPython-time-datetime%2F</url>
    <content type="text"><![CDATA[Python中的日期和时间Python程序能用很多方式处理日期和时间, 转换日期格式是一个常见的功能. Python提供了 time 和 calendar模块可以用来格式化日期和时间. 时间间隔是以秒为单位的浮点小数. 每个时间戳都以自1970年1月1日午夜(历元)经过了多长时间来表示. time.time()用于获取当前的时间戳, 单位为秒1234import timeticks = time.time()print(ticks) # 1540387897.1916292 时间戳单位最适于做日期运算, 但是1970年之前的日期就无法以此表示了. 太遥远的日期也不行, UNIX和Windows只支持到2038年. 时间元组]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Latex语法]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-Latex%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/qq_17528659/article/details/82152530 符号(很全):https://blog.csdn.net/caiandyong/article/details/53351737任意\forall: $\forall$存在\exists: $\exists$ \Sigma: $\Sigma$ \sim$$:$\sim$ `$$output = \left\{ \begin{aligned} 0, \quad if \sum_i w_i x_i \le threshold \\ 1, \quad if \sum_i w_i x_i > threshold \end{aligned} \right.$$`: $$output = \left\{ \begin{aligned} 0, \quad if \sum_i w_i x_i \le threshold \\ 1, \quad if \sum_i w_i x_i > threshold \end{aligned} \right.尖括号\langle \rangle: $\langle \rangle$ 乘法点乘\cdot : $\cdot$\odot : $\odot$ \cdot: $\cdot$\cdots: $\cdots$ 竖线\Vert: $\Vert$\vert: $\vert$ 开根\sqrt[3]{n}: $\sqrt[3]{n}$\sqrt[p]{n}: $\sqrt[p]{n}$ 无穷\infty: $\infty$+\infty: $+\infty$-\infty: $-\infty$ 矩阵1234567891011121314151617$$\begin&#123;matrix&#125; 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9\end&#123;matrix&#125; \tag&#123;1&#125;$$$$\begin&#123;bmatrix&#125; 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9\end&#123;bmatrix&#125; \tag&#123;2&#125;$$$$\begin&#123;pmatrix&#125; 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9\end&#123;pmatrix&#125; \tag&#123;3&#125;$$ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{matrix} \tag{1}\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix} \tag{2}\begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{pmatrix} \tag{3}bot\bot: $\bot$ 当且仅当\iff: $\iff$ 实数集 R\mathbb{R}: $\mathbb{R}$ 花体 l\ell: $\ell$, 这不是花体, 只是为了避免混淆字母 l 和数字 1, 也只有这一个字母可以加 \el, 其他字母无效. 平均\bar{v}: $\bar{v}$ 顶部\widetilde k: $\widetilde k$\overline k: $\overline k$\hat k: $\hat k$\widehat k: $\widehat k$ delta\delta: $\delta$\Delta: $\Delta$ 集合\cap: $\cap$\bigcap: $\bigcap$\Omega: $\Omega$ 箭头\to: $\to$ 样式 指令 样式 指令 样式 指令 样式 指令 样式 指令 样式 指令 $\uparrow$ \uparrow $\Uparrow$ \Uparrow $\downarrow$ \downarrow $\Downarrow$ \Downarrow $\leftarrow$ \leftarrow $\Leftarrow$ \Leftarrow 样式 指令 样式 指令 样式 指令 样式 指令 $\uparrow$ \uparrow $\Uparrow$ \Uparrow $\downarrow$ \downarrow $\Downarrow$ \Downarrow \rightarrow \Rightarrow \updownarrow \Updownarrow \leftrightarrow\Leftrightarrow长箭头表示(其实就是在上述表示前加一个long/Long即可) 符号 符号 MarkDown MarkDown\longleftarrow\Longleftarrow \longrightarrow\Longrightarrow\longleftrightarrow\Longleftrightarrow更多的箭头符号 符号 符号 MarkDown MarkDown\twoheadrightarrow\rightarrowtail\looparrowright\curvearrowright\circlearrowright\Rsh\multimap \leftrightsquigarrow \rightsquigarrow \leadsto \nearrow \searrow \swarrow \nwarrow \nleftarrow \nrightarrow \nLeftarrow \nRightarrow \nleftrightarrow \nLeftrightarrow \dashrightarrow\dashleftarrow \leftleftarrows \leftrightarrows \Lleftarrow \twoheadleftarrow \leftarrowtail \looparrowleft \curvearrowleft \circlearrowleft \Lsh \mapsto \hookleftarrow \hookrightarrow\upharpoonright \upharpoonleft\downharpoonright\downharpoonleft \leftharpoonup\rightharpoonup\leftharpoondown \rightharpoondown \upuparrows \downdownarrows \rightrightarrows \rightleftarrows \rightrightarrows \rightleftarrows \rightleftharpoons\leftrightharpoons]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Caffe2 教程-CIFAR 10]]></title>
    <url>%2Fz_post%2FCaffe2-%E6%95%99%E7%A8%8B-CIFAR10%2F</url>
    <content type="text"><![CDATA[前言本示例主要包含以下几个主要部分: 下载 Cifar10 数据集 将 Images 写入 lmdbs 定义并且训练 model 保存训练好的 model 加载训练好的 model 在 testing imdb 上面执行 inference 继续训练以提高 test accuracy 测试 retrained model 项目地址: https://github.com/caffe2/tutorials 导入必要的包123456789101112131415161718192021222324252627from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionfrom __future__ import unicode_literals%matplotlib inlinefrom matplotlib import pyplot as pltimport numpy as npimport osimport lmdbimport shutilfrom imageio import imreadimport caffe2.python.predictor.predictor_exporter as pefrom caffe2.proto import caffe2_pb2from caffe2.python.predictor import mobile_exporterfrom caffe2.python import( brew, core, model_helper, net_drawer, optimizer, visualize, workspace)# 设置全局初始化信息 , 如果需要看到更加详细的初始化信息, 需要将caffe2_log_level参数设置为 1core.GlobalInit(['caffe2', '--caffe2_log_level=0']) 下载并解压数据集1234567891011121314151617181920212223242526272829303132333435363738import requestsimport tarfile# 设置下载路径相关变量# data_folder为data下载并解压的地方, 这个路径需要根据你自己的电脑环境设置data_folder = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10' )# root_folder为checkpoints文件和.pb模型定义文件存放的地方root_folder = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_files', 'tutorial_cifar10' )url = "http://pjreddie.com/media/files/cifar.tgz" # url to datafilename = url.split("/")[-1] # download file namedownload_path = os.path.join(data_folder, filename) # path to extract data toif not os.path.isdir(data_folder): os.makedirs(data_folder)# 如果data不存在, 就下载并解压之if not os.path.exists(download_path.strip('.tgz')): # Download data r = requests.get(url, stream=True) print("Downloading... &#123;&#125; to &#123;&#125;".format(url, download_path)) open(download_path, 'wb').write(r.content) print("Finished downloading...") # Unpack images from tgz file print('Extracting images from tarball...') tar = tarfile.open(download_path, 'r') for item in tar: tar.extract(item, data_folder) print("Completed download and extraction!")else: print("Image directory already exists. Moving on...") 接下来看一看数据集中的一些示例:12345678910111213import globfrom skimage import io# Grab 5 image paths from training set to displaysample_imgs = glob.glob(os.path.join(data_folder, "cifar", "train") + '/*.png')[:5]# Plot imagesf, ax = plt.subplots(1, 5, figsize=(10,10))plt.tight_layout()for i in range(5): ax[i].set_title(sample_imgs[i].split("_")[-1].split(".")[0]) ax[i].axis('off') ax[i].imshow(io.imread(sample_imgs[i]).astype(np.uint8)) 创建 LMDBs 数据结构现在我们已经拥有了数据, 接下来需要写入LMDBs用于训练, 验证和测试. 为了根据每个类别来分离图片, 下面将会使用到一个经常在caffe框架中使用的技术, 创建label files. 具体来说, label files就是将每个.png图片对应到它的类别上面去:/path/to/im1.png 7/path/to/im2.png 3/path/to/im3.png 5/path/to/im4.png 0… 根据不同的数据集, 创建labels的方式有些许区别 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# Paths to train and test directoriestraining_dir_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'cifar', 'train' )testing_dir_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'cifar', 'test' )# Paths to label filestraining_labels_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'training_dictionary.txt' )validation_labels_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'validation_dictionary.txt' )testing_labels_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'testing_dictionary.txt' )# Paths to LMDBstraining_lmdb_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'training_lmdb' )validation_lmdb_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'validation_lmdb' )testing_lmdb_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'testing_lmdb' )# Path to labels.txtlabels_path = os.path.join( os.path.expanduser('~'), 'caffe2_notebooks', 'tutorial_data', 'cifar10', 'cifar', 'labels.txt' )# Open label file handlerlabels_handler = open(labels_path, "r")# Create classes dictionary to map string labels to integer labelsclasses = &#123;&#125;i = 0lines = labels_handler.readlines()for line in sorted(lines): line = line.rstrip() classes[line] = i i += 1labels_handler.close()print("classes:", classes) 输出如下: 1234classes: &#123; &apos;automobile&apos;: 1, &apos;airplane&apos;: 0, &apos;truck&apos;: 9, &apos;ship&apos;: 8, &apos;dog&apos;: 5, &apos;horse&apos;: 7, &apos;cat&apos;: 3, &apos;frog&apos;: 6, &apos;deer&apos;: 4, &apos;bird&apos;: 2&#125; 既然现在我们已经拥有了从类别字符串名到数字的映射关系, 我们就可以创建用于训练, 验证和推演的标签文件了. 我们会将数据分成以下三个部分: training: 44000 images (73%) validation: 6000 images (10%) testing: 10000 image (17%) 注意到我们的验证数据集仅仅只是训练数据集的一个子集, 我们这么做是为了查看我们当前的模型在面对没有见过的数据集时的表现怎么样. 为了得到分布相对均匀的训练集合验证集, 我们首先读取所有的图片(路径), 将其随机打乱, 然后拆分成数据集和验证集. 代码如下: 12345678910111213141516171819202122232425262728293031from random import shuffle# Open file handlerstraining_labels_handler = open(training_labels_path, "w")validation_labels_handler = open(validation_labels_path, "w")testing_labels_handler = open(testing_labels_path, "w")# 创建 training, validation, testing 的标签文件i = 0validation_count = 6000# 将所有的训练集的图片路径读取到imgs中, 以字符串列表的形式存储imgs = glob.glob(training_dir_path+"/*.png")shuffle(imgs) # 打乱文件路径for img in imgs: if i &lt; validation_count: # img的形式为 path/train/31205_frog.png validation_labels_handler.write(img + ' ' + str(classes[img.split('_')[-1].split('.')[0]]) + '\n') else: training_labels_handler.write(img + ' ' + str(classes[img.split('_')[0].split('.')[0]]) + '\n') i += 1print("Finished writing training and validation label files")# 根据 test image 的信息存储 test labels 到文件中for img in glob.glob(testing_dir_path+'/*.png'): # 获取所有 test 图片的文件路径 testing_labels_handler.write(img + ' ' + str(classes[img.split('_')[-1].split('.')[0]]) + '\n')print("Finished writing testing label files")# Close file handlerstraining_labels_handler.close()validation_labels_handler.close()testing_labels_handler.close() 现在, 我们已经可以开始用这些创建好的标签文件来构建我们的 LMDBs 数据集了. 下面的代码采纳自 Caffe2 的 lmdb_create_example.py 脚本. 请注意在将数据送入 LMDB 之前, 首先要将图片的颜色通道从 RGB 变成 BGR, 并且要将图片矩阵从 HWC 变成 CHW. 另外, Caffe2 接受的输入格式为 NCHW, 这里的 N 代表 batch-size. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758def write_lmdb(labels_file_path, lmdb_path): labels_handler = open(labels_file_path, "r") print("&gt;&gt;&gt;Write database...") LMDB_MAP_SIZE = 1 &lt;&lt; 40 # 设置 lmdb 的size print("LMDB_MAP_SIZE", LMDB_MAP_SIZE) env = lmdb.open(lmdb_path, map_size=LMDB_MAP_SIZE) # &lt;class 'Environment'&gt; with env.begin(write=True) as txn: count = 0 for line in labels_handler.readlines(): line = line.rstrip() # 去除最后的回车 im_path = line.split()[0] im_label = int(line.split()[1]) # from imageio import imread, 读取图片 img_data = imread(im_path).astype(np.float32) # 将 RGB 转换成 BGR 格式 img_data = img_data[:, :, (2,1,0)] # 将 HWC 转换成 CHW 格式 img_data = np.transpose(img_data, (2,0,1)) tensor_protos = caffe2_pb2.TensorProtos() # 创建 TensorProtos img_tensor = tensor_protos.protos.add() # 获取 TensorProto img_tensor.dims.extend(img_data.shape) # 将img_tensor.dims从[]扩展成[3,32,32] img_tensor.data_type = 1 # 将类型置为 float flatten_img = img_data.reshape(np.prod(img_data.shape)) # 将 img_data 的维度变成 32×32×3 = 3072 维(单维度) img_tensor.float_data.extend(flatten_img) # 将 flatten_img 填入 img_tensor(初始时为空) label_tensor = tensor_protos.protos.add() # 获取一个新的 TensorProto label_tensor.data_type = 2 # 置为 int 类型 label_tensor.int32_data.append(im_label) # 将 label(int类型, 表示标签编号) 添加到 label_tensor 中. txn.put( # 第一个参数为 key, 第二个为 value '&#123;&#125;'.format(count).encode('ascii'), tensor_protos.SerializeToString() ) if ((count % 1000 == 0)): print("Inserted &#123;&#125; rows".format(count)) count = count + 1 print("Inserted &#123;&#125; rows".format(count)) print("\nLMDB saved at " + lmdb_path + "\n\n") labels_path.close()# 调用上面定义好的 LMDBs 写入函数if not os.path.exists(training_lmdb_path): print("Writing training LMDB") write_lmdb(training_labels_path, training_lmdb_path)else: print(training_lmdb_path, "already exists!")if not os.path.exists(validation_lmdb_path): print("Writing validation LMDB") write_lmdb(validation_labels_path, validation_lmdb_path)else: print(validation_lmdb_path, "already exists!")if not os.path.exists(testing_lmdb_path): print("Writing testing LMDB") write_lmdb(testing_labels_path, testing_lmdb_path)else: print(testing_lmdb_path, "already exists!") 定义 CNN 模型既然我们已经将数据存储成了 LMDBs 的格式, 那么是时候建立相应的网络模型了! 首先, 设置一些路径变量, 定义数据集的具体参数, 同时定义训练参数. 12345678910111213141516# caffe2 的 init 网络 和 predict 网络的位置init_net_out = 'cifar10_init_net.pb'predict_net_out = 'cifar10_predict_net.pb'# 数据集相关参数image_width = 32image_height = 32image_channels = 3num_classes = 10# 网络训练参数training_iters = 2000training_net_batch_size = 100validation_images = 6000validation_interval = 100 # 每经过100次训练迭代, 就会进行一次验证迭代.checkpoint_iters = 1000 # 每经过1000次迭代, 就会输出一次 checkpoint db 创建相应的目录, 然后将该目录设置为工作目录. 123456# root_folder = /home/zerozone/caffe2_notebooks/tutorial_files/tutorial_cifar10if not os.path.isdir(root_folder): os.makedirs(root_folder) ## 将根目录设置为工作目录workspace.ResetWorkspace(root_folder) AddInput() 数据输入层下面的任务是利用 helper functions 来模块化我们的代码, 最终使其构成相应的网络模型. 我们将会使用 ModelHelper 类来定义和表示我们的模型, 同时会包含相应的参数信息. 我们将利用 brew 模块来向我们的模型中添加相应的网络层.需要注意的是, 调用上面的代码并不会使模型执行任何实际上的计算, 相反的, 我们是在搭建一个计算操作的图结构(graph of operators), 这个图最终指明了当数据传入时, 网络应该进行哪些 forward 和 backward 计算.第一个 helper function 是AddInput, 它向我们的网络添加了输入(数据)层. 注意到, 图片已经存储到了我们的 LMDBs 数据结构中, 因此在将其送入网络模型之前, 还需要一些简单的预处理操作. 第一, 我们先从 LMDB 中读取 raw image data 和 labels, 它们的类型都是 uint8([0,255] pixel values). 接着我们将数据转换成浮点类型, 同时将图片的像素值放缩到 [0,1] 之间, 使其在训练时可以更快收敛. 最后, 我们会调用model.StopGradient(data, data)来组织在 backward 过程中计算关于数据的梯度(因为我们只需要关于参数的梯度). 最后, 是一些关于引号中的名称含义: “data_unint8” 和 “label” 代表着与 DB 输入数据相关的 blobs 的名字 如果名字是 input blob, 则代表当 operator 运行时的 blob_name 如果名字是 output blob, 则代表是某个 operator 创建的 blob 的名字. 1234567891011121314151617def AddInput(model, batch_size, db, db_dtype): # 加载数据 data_uint8, label = brew.db_input( model, # ModelHelper 实例 blobs_out=["data_uint8", "label"], batch_size=batch_size, db=db, db_type=db_type, ) # 将数据转换成 float data = model.Cast(data_uint8, "data", to=core.DataType.FLOAT) # 将 data 从 [0, 255] 放缩到 [0,1] data = model.Scale(data, data, scale=float(1./256)) # 避免计算数据的梯度 data = model.StopGradient(data, data) return data, label 根据后文的调用语句:12345data, label = AddInput( train_model_zz, batch_size=training_net_batch_size, # 100 db=training_lmdb_path, # /home/zerozone/caffe2_notebooks/tutorial_data/cifar10/training_lmdb db_type="lmdb") 调用后, 模型中会增加四个新的 op(原本模型中的 op 为 0 个), 如下所示:1234567891011121314151617181920212223242526272829303132333435363738name: &quot;train_net&quot;op &#123; input: &quot;dbreader_/home/zerozone/caffe2_notebooks/tutorial_data/cifar10/training_lmdb&quot; output: &quot;data_uint8&quot; output: &quot;label&quot; name: &quot;&quot; type: &quot;TensorProtosDBInput&quot; arg &#123; name: &quot;batch_size&quot; i: 100 &#125;&#125;op &#123; input: &quot;data_uint8&quot; output: &quot;data&quot; name: &quot;&quot; type: &quot;Cast&quot; arg &#123; name: &quot;to&quot; i: 1 &#125;&#125;op &#123; input: &quot;data&quot; output: &quot;data&quot; name: &quot;&quot; type: &quot;Scale&quot; arg &#123; name: &quot;scale&quot; f: 0.00390625 &#125;&#125;op &#123; input: &quot;data&quot; output: &quot;data&quot; name: &quot;&quot; type: &quot;StopGradient&quot;&#125; Add_Original_CIFAR10_Model() 模型核心处理好输入层以后, 接下来实现 CNN 模型的定义. 本教程使用的网络模型拥有三层卷积层和池化层, 并且使用 ReLU 激活函数. 我们将会使用 update_dims 函数来帮助我们根据卷积层和池化层造成的维度的降低程度. 维度会以下列公式为依据发生变化: height_{out}=\frac{height_{in}-kernel+2*pad}{stride}+1width_{out}=\frac{width_{in}-kernel+2*pad}{stride}+1尽管使用 update_dims 函数不是必须的, 但我们发现这是一种避免手动计算维度变化的很不错的策略选择, 尤其是在决定全连接层的参数的时候. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 辅助计算维度变化的函数def update_dims(height, width, kernel, stride, pad): new_height = ((height - kernel + 2*pad)//stride) + 1 new_width = ((width - kernel + 2*pad)//stride) + 1 return new_height, new_widthdef Add_Original_CIFAR10_Model(model, data, num_classes, image_height, image_width, image_channels): # 第一层卷积层 conv1 = brew.conv( model, data, 'conv1', dim_in=image_channels, dim_out=32, kernel=5, stride=1, pad=2 ) h,w = update_dims(height=image_height, width=image_width, kernel=5, stride=1, pad=2) # 第一层池化层 pool1 = brew.max_pool(model, conv1, "pool1", kernel=2, stride=2) h,w = update_dims(height=h, width=w, kernel=3, stride=2, pad=0) # 第一层激活层 relu1 = brew.relu(model, pool1, "relu1") # 第二层 conv2 = brew.conv( model, relu1, "conv2", dim_in=32, dim_out=32, kernel=5, stride=1, pad=2 ) h,w = update_dims(height=h, width=w, kernel=5, stride=2, pad=2) relu2 = brew.relu(model, conv2, "relu2") pool2 = brew.average_pool(model, relu2, "pool2", kernel=3, stride=2) h,w = update_dims(height=h, width=w, kernel=3, stride=2, pad=0) # 第三次 conv3 = brew.conv( model, pool2, "conv3", dim_in=32, dim_out=64, kernel=5, stride=1, pad=2 ) h,w = update_dims(height=h, width=w, kernel=5, stride=1, pad=2) relu3 = brew.relu(model, conv3, "relu3") pool3 = brew.average_pool(model, relu3, "pool3", kernel=3, stride=2) h,w = update_dims(height=h, width=w, kernel=3, stride=2, pad=0) # 全连接层, 通过动态维护w,h变量, 省去了手动计算的麻烦 fc1 = brew.fc(model, pool3, "fc1", dim_in=64*h*w, dim_out=64) fc2 = brew.fc(model, fc1, "fc2", dim_in=64, dim_out=num_classes) # Softmax 网络层, 将输出转换成概率 softmax = brew.softmax(model, fc2, "softmax") return softmax 后文在调用该函数时的代码如下所示:1234softmax = Add_Original_CIFAR10_Model( train_model, data, num_classes image_height, image_width, image_channels) 由于此处涉及的 op 过多, 并且大部分都是重复的, 因此这里我们仅仅贴出网络中 conv1, pool1, relu1 的 op, 其他网络层的 op 类似.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667op &#123; input: &quot;data&quot; input: &quot;conv1_w&quot; input: &quot;conv1_b&quot; output: &quot;conv1&quot; name: &quot;&quot; type: &quot;Conv&quot; arg &#123; name: &quot;exhaustive_search&quot; i: 0 &#125; arg &#123; name: &quot;stride&quot; i: 1 &#125; arg &#123; name: &quot;order&quot; s: &quot;NCHW&quot; &#125; arg &#123; name: &quot;pad&quot; i: 2 &#125; arg &#123; name: &quot;kernel&quot; i: 5 &#125; engine: &quot;CUDNN&quot;&#125;op &#123; input: &quot;conv1&quot; output: &quot;pool1&quot; name: &quot;&quot; type: &quot;MaxPool&quot; arg &#123; name: &quot;kernel&quot; i: 3 &#125; arg &#123; name: &quot;cudnn_exhaustive_search&quot; i: 0 &#125; arg &#123; name: &quot;stride&quot; i: 2 &#125; arg &#123; name: &quot;order&quot; s: &quot;NCHW&quot; &#125; engine: &quot;CUDNN&quot;&#125;op &#123; input: &quot;pool1&quot; output: &quot;relu1&quot; name: &quot;&quot; type: &quot;Relu&quot; arg &#123; name: &quot;cudnn_exhaustive_search&quot; i: 0 &#125; arg &#123; name: &quot;order&quot; s: &quot;NCHW&quot; &#125; engine: &quot;CUDNN&quot;&#125; AddTrainingOperators() 损失函数及优化器我们的下一个辅助函数是 AddTrainingOperators(). 这个函数将会被我们的训练模型所调用, 用于添加相应的损失函数和优化机制. 我们将会在模型的 softmax 输出和图片的真实标签上使用平均交叉熵来计算模型的损失. 然后我们会添加一个计算损失函数梯度的 operators 到模型中. 最终, 我们会使用 Caffe2 中 optimizer 类的 build_sgd 函数作为我们的优化函数. 123456789101112def AddTrainingOperators(model, softmax, label): xent = model.LabelCrossEntropy([softmax, label], 'xent') # 计算 loss 的期望值 loss = model.AveragedLoss(xent, "loss") # from caffe2.python import optimizer optimizer.build_sgd( model, base_learning_rate=0.01, policy="fixed", momentum=0.9, weight_decay=0.004 ) 后文的调用语句如下:1AddTrainingOperators(train_model, softmax, label) 此处涉及到的 op 也非常的多, 主要包含了计算之前每一个操作的梯度, 这里我们也只简单的列出一些 op 作为示例: 1234567891011121314151617181920212223op &#123; input: &quot;fc1&quot; input: &quot;fc2_w&quot; input: &quot;fc2_grad&quot; output: &quot;fc2_w_grad&quot; output: &quot;fc2_b_grad&quot; output: &quot;fc1_grad&quot; name: &quot;&quot; type: &quot;FCGradient&quot; arg &#123; name: &quot;use_cudnn&quot; i: 1 &#125; arg &#123; name: &quot;cudnn_exhaustive_search&quot; i: 0 &#125; arg &#123; name: &quot;order&quot; s: &quot;NCHW&quot; &#125; is_gradient_op: true&#125; AddAccuracy() 模型准确率下面的函数用于计算我们当前模型的 top-1 准确率. 12345def AddAccuracy(model, softmax, label): # blobs_in 为 [softmax, label] # blobs_out 为 "accuracy" accuracy = brew.accuracy(model, [softmax, label], "accuracy") return accuracy 后文的调用语句如下:1AddAccuracy(val_model, softmax, label) 本函数增加了一个新的 op, 如下所示:1234567op &#123; input: "softmax" input: "label" output: "accuracy" name: "" type: "Accuracy"&#125; 检查点下面的函数会在每经过一定次数的迭代之后输出一个 checkpoint db. 一个 checkpoint 本质上来说是模型在训练过程中的一种保存成文件的模型状态. checkpoint 在快速加载训练好或者训练中的模型时非常有用, 并且它们能够在长时间的模型训练的过程中提高有力的安全保障. Caffe2 的 checkpoint 文件类似于 Caffe 的定期输出的 .caffemodel 文件. 我们利用 brew 和 iter operator 来跟踪迭代次数, 并把它们保存成 LMDBs 的形式.在使用 checkpoints 的时候, 你必须时刻注意在训练过程是否将之前同名检查点给覆盖掉. 如果你尝试覆盖一个 checkpoint db, 那么将会产生报错. 为了解决这种情况, 我们将会把 checkpoints 以一种唯一的命名字典保存在我们的 root_folder 下面. 这个字典的名字会基于当前的系统时间戳, 以避免出现重复. 12345678910111213141516import datetime# 在 root_folder 目录下创建唯一的命名字典unique_timestamp = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))checkpoint_dir = os.path.join(root_folder. unique_timestamp)os.makedirs(checkpoint_dir)print("Checkpoint output location: ", checkpoint_dir)# 将 checkpoint 添加到给定的模型当中def AddCheckpoints(train_model, checkpoint_iters, db_type): # 注意这里第一个参数是train_model, 原始教程里写错了, 会导致运行出错 ITER = brew.iter(train_model, "iter") train_model.Checkpoint( [ITER] + train_model.params, [], db=os.path.join(unique_timestamp, "cifar10_checkpoint_%05d.lmdb"), dy_type="lmdb", every=checkpoint_iters ) 利用 ModelHelper 初始化模型现在既然我们已经创建了必要的辅助函数, 那么是时候初始化模型, 同时使用相应的函数来定义模型的计算图(operator graphs). 请记住此时我们还没有执行模型. 首先, 定义 train model: 用 ModelHelper class 初始化模型 利用 AddInput() 函数添加数据输入层 添加 Cifar10 模型, 该模型返回一个 softmax blob 利用 AddTrainingOperators() 函数添加 training operators, 此处需要使用第三步中的 softmax blob 利用 AddCheckpoints() 函数添加定时的 checkpoints. 下面, 我们来定义 validation model, 该模型在结构上与 training model 是相同的, 但是其数据来源于另一个 LMDB 文件, 并且使用了不同的 batch size. 具体定义如下: 利用 ModelHelper class 对模型进行初始化(需要将参数 init_params 设置为 False); 利用 AddInput() 函数添加数据输入层; 添加 Cifar10 模型, 该模型返回一个 softmax blob; 利用 AddAccuracy() 函数添加 accuracy layer, 此处需要使用第三步中的 softmax blob; 最后, 我们定义 deploy model 如下: 利用 ModelHelper class 初始化模型(需令 init_params=False); 添加 Cifar10 模型, 以 “data” 作为模型输入 input blob. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051arg_scope = &#123;"order": "NCHW"&#125; # 字典, 在 ModelHelper 中, arg_scope["order"] 的默认值即为 "NCHW", 因此该语句可省略# TRAINING MODEL# 利用 ModelHelper class 初始化 training modeltrain_model = model_helper.ModelHelper(name="train_net", arg_scope=arg_scope)# 从 lmdb 文件添加数据输入层data, label = AddInput( train_model, batch_size=training_net_batch_szie, db=training_lmdb_path, db_type="lmdb")# 添加模型核心定义, 将返回的值保存在 'softmax' 变量中softmax = Add_Original_CIFAR10_Model( train_model, data, num_classes, image_height, image_width, image_channels)# 利用上面返回的 softmax 添加 training operatorsAddTrainingOperators(train_model, softmax, label)# 添加 periodic checkpoint 输出到模型中AddCheckpoints(train_model, checkpoint_iters, db_type="lmdb")# VALIDATION MODEL# 利用 ModelHelper class 初始化 val modelval_model = model_helper.ModelHelper( name="val_net", arg_scope=arg_scope, init_params=False)# 从 validation_lmdb 文件添加数据输入层data, label = AddInput( val_model, batch_size=validation_images, db=validation_lmbd_path, db_type="lmdb")# 添加模型定义, 并将返回值存储在 'softmax' 变量中softmax = Add_Original_CIFAR10_Model( val_model, data, num_classes, image_height, image_width, image_channels)# 添加 accuracy operatorAddAccuracy(val_model, softmax, label)# DEPLOY MODEL# 利用 ModelHelper class 初始化 deploy modeldeploy_model = model_helper.ModelHelper( name="deploy_net", arg_scope=arg_scope, init_params=False)# 添加模型定义, 输入数据为 "data"Add_Original_CIFAR10_Model( deploy_model, "data", num_classes, image_height, image_width, image_channels)print("Training, Validation, and Deploy models all defined") 开始训练最后, 既然我们已经拥有了模型, 并且定义了相应的 operator graphs, 那么就应该开始真正意义上的执行 training process 了. Under the hood, 我们已经定义将我们的模型以 operator graphs 的形式定义, 并且序列化成了 protobuf 格式. 最后一步就是要将这些 protobufs 送入 Caffe2 的 C++ 后端, 以便建立模型并执行它. 还记得 ModelHelper 模型对象拥有的两个网络吗: param_init_net: 包含参数和初始数据 net: 包含定义好的网络结构(operator graph) 以上的两个网络都需要执行, 并且我们必须先执行 param_init_net 网络, 注意, 该网络只需要被执行一次, 因此我们利用 workspace.RunNetOnce() 函数来执行, 这个函数会经过一个实例化, 运行, 然后销毁网络的过程. 如果我们需要多次运行某个网络, 就像我们需要多次运行 training nets 和 validation nets 一样, 那么我们必须先利用 workspace.CreateNet() 手动创建网络, 然后利用多次调用 workspace.RunNet() 的方式达到多次运行网络的目的, 从这里我们也就可以看出 RunNetOnce 和 RunNet 之间的区别了, 简单来说, 前者会在执行之前自动创建网络, 而后者只能运行已经创建好的网络, 也正是因为这样, 后者的执行速度要比前者快.当我们利用 workspace.RunNet() 执行 train_model 以后, 这会在一个 batch 的数据上执行 forward 和 backward 过程, 而在执行 val_model 时, 只会执行 forward 过程(同时会计算准确率). 1234567891011121314151617181920212223242526272829303132333435import math# 初始化并创建 training networkworkspace.RunNetOnce(train_model.param_init_net)workspace.CreateNet(train_model.net, overwrite=True) # overwrite 参数代表是否允许覆盖checkpoint文件# 初始化并创建 validation networkworkspace.RunNetOnce(val_model.param_init_net)workspace.CreateNet(val_model.net, overwrite=True)# 创建 Placeholder, 用于跟踪 loss 和 validation accuracyloss = np.zeros(int(math.ceil(training_iters/validation_interval))) # shape = (2000/100,) = (20,)val_accuracy = np.zeros(int(math.ceil(training_iters/validation_interval))) # shape = (20,)val_count = 0iteration_list = np.zeros(int(math.ceil(training_iters/validation_interval))) # shape = (20,)# 现在, 开始运行网络 (forward &amp; backward padd)for i in range(training_iters): workspace.RunNet(train_model.net) # 每经过 validation_interval 次迭代就执行一次 validation net if (i % validation_interval == 0): print("Training iter:", i) # 获取当前 workspace 内的名为 "loss" 的 blob loss[val_count] = workspace.FetchBlob("loss") # 记录一次 loss # 注意, 在 Caffe2 中, 同一个 workspace 的参数会被所有当前 workspace 内的模型所共享, # 也就是说, 虽然看起来 train_net 和 val_net 是分别利用 ModelHelper 定义的, # 但是, 当他们在workspace中获取参数的值时(通过名字, 如"loss"), 会获得相同的值, # 因此, 这里可以直接运行 val_net 来计算 train_net 训练的准确率. workspace.RunNet(val_model.net) val_accuracy[val_count] = workspace.FetchBlob("accuracy") print("Loss:", str(loss[val_count])) print("Validation accuracy:", str(val_accuracy[val_count])+"\n") iteration_list[val_count] = i # 记录当前迭代次数 val_count += 1 下面的代码用于将训练过程中的 accuracy 和 loss 绘制出来, 以方便我们观察和分析. 12345plt.title("Training loss vs. Validation Accuracy")plt.plot(iteration_list, loss, 'b')plt.plot(iteration_list, val_accuracy, 'r')plt.xlabel("Training iteration")plt.legend(('Loss', 'Validation Accuracy'), loc='upper right') 保存训练好的模型当我们在 workspace 中训练好模型的参数以后, 我们就可以利用 mobile_exporter 来导出部署模型. 在 Caffe2 中, 预训练的模型通常情况下会存储成两个单独的 protobuf(.pb) 文件(inti_net 和 predict_net). 模型也可以被存储为 db 格式, 但是最好存储成 pb 格式, 因为这种格式在社区中更流行. 为了保持一致性, 我们将这些参数保存在相同的 checkpoints 的唯一目录下. 1234567891011121314151617181920# 初始化并创建 deploy 网络workspace.RunNetOnce(deploy_model.param_init_net)workspace.CreateNet(deploy_model.net, overwrite=True)# 利用 mobile_exporter 的 Export 函数来获取 init_net 和 predict_netinit_net, predict_net = mobile_exporter.Export( workspace, deploy_model.net, deploy_model.params))# 定义 output files 的路径full_init_net_out = os.path.join(checkpoint_dir, init_net_out)full_predict_net_out = os.path.join(checkpoint_dir, predict_net_out)# 将两个网络写入文件with open(full_init_net_out, 'wb') as f: f.write(init_net.SerializeToString())with open(full_predict_net_out, 'wb') as f: f.write(predict_net.SerializeToString())print("Model saved as " + full_init_net_out + " and " + full_predict_net_out) 利用训练好的模型进行推演在保存好模型以后, 我们试着来使用这个模型进行推演, 首先定义一些路径相关变量, 方便我们加载特定的模型.12345678910111213141516171819202122# Train lmdb, 定义训练集的 lmdb路径TRAIN_LMDB = os.path.join(os.path.expanduser('~'),"caffe2_notebooks/tutorial_data/cifar10/training_lmdb")# Test lmdb, 定义验证集的 lmdb 路径TEST_LMDB = os.path.join(os.path.expanduser('~'),"caffe2_notebooks/tutorial_data/cifar10/testing_lmdb")# 提起保存好的 protobuf 文件.part1_runs_path = os.path.join(os.path.expanduser('~'), "caffe2_notebooks", "tutorial_files", "tutorial_cifar10")# runs 为一个列表, 列表的长度跟路径中 checkpoint 的个数有关, 按日期排序, 日期大的在后面runs = sorted(glob.glob(part1_runs_path + "/*"))# Init netINIT_NET = os.path.join(runs[-1], "cifar10_init_net.pb")# Predict netPREDICT_NET = os.path.join(runs[-1], "cifar10_predict_net.pb")# Make sure they all existif (not os.path.exists(TRAIN_LMDB)) or (not os.path.exists(TEST_LMDB)) or (not os.path.exists(INIT_NET)) or (not os.path.exists(PREDICT_NET)): print("ERROR: input not found!")else: print("Success, you may continue!") 构建 Testing model 12345678# 利用 ModelHelper 创建 testing modelarg_scope = &#123;"order": "NCHW"&#125;test_model = model_helper.ModelHelper( name="test_model", arg_scope=arg_scope, init_params=False)# 添加 data layer, 注意使用 TEST_LMDBdata, _ = AddInputLayer(test_model, 1, TEST_LMDB, 'lmdb') # batch size 为 1 下面我们使用保存好的模型参数来填充(populate) Model Helper. 想要构建用于 testing 的模型, 我们不需要在 model helper 重新创建 params, 同样也不需要添加 gradient operators, 因为我们仅仅执行 forward pass. 我们只需要利用 predict_net.pb 和 init_net.pb 文件中的参数填充 testing model 的 .net 和 .param_init_net 成员即可. 为此, 我们需要从 pb 文件中创建 caffe2_pb 对象, 然后再利用 caffe2_pb 对象创建 Net 对象, 接着将 net 对象 添加(append) 到 .net 和 .param_init 成员中即可. 请注意, 这里的添加操作非常重要, 如果没有执行 append, 我们将会抹去刚刚添加的输入层. 会想上面的程序, 保存好的模型需要一个名为 “data” 输入, 同时会产生一个名为 “softmax” 的输出. Conveniently(but not accidentally), 输入层函数(AddInputLayer())会从 lmdb 中读取数据, 并且将读取到的信息以 “data” 命名的 blob 存入 workspace 当中. 同样重要的是要记住我们添加到模型中的每个保存的网络中包含着什么. predict_net 包含着模型的结构, 包括 forward pass 的相关 ops. 而 init_net 包含着 predict_net 中的 ops 所需的参数的权重信息. 举例来说, 如果在 predict_net 中存在一个名为 fc1 的 op, 那么 init_net 就会包含这个全连接层的权重矩阵和偏置项 (fc1_w) 和 (fc1_b).当我们 append 网络以后, 我们添加了一个 accuracy 层到模型中, 它是利用网络输出的 softmax 以及数据的真实标签来计算 accuracy 的. 最终, 我们可以利用 workspace.FetchBlob() 来手动的获取指定 blob 的值.12345678910111213141516# 用 init net 来填充(populate) model helper 对象, 用于给模型提供权重参数init_net_proto = caffe2_pb2.NetDef()with open(INIT_NET, "rb") as f: init_net_proto.ParseFromString(f.read())test_model.param_init_net = test_model.param_init_net.AppendNet( core.Net(init_net_proto))# 用 predict net 来添加模型的 net, 用于定义模型的结构predict_net_proto = caffe2_pb2.NetDef()with open(PREDICT_NET, "rb") as f: predict_net_proto.ParseFromString(f.read())test_model.net = test_model.net.AppendNet(core.Net(predict_net_proto))# 添加 accuracy, 三个参数分别为: model, blobs_in, blobs_outaccuracy = brew.accuracy(test_model, ['softmax', 'label'], 'accuracy') 接下来, 我们来运行 testing model 以查看结果. 123456789101112131415161718192021# 先利用 init_net 初始化 test_model, 然后再创建该模型workspace.RunNetOnce(test_model.param_init_net)workspace.RunNet(test.net, overwrite=True)# Stat keeperavg_accuracy = 0.0# 运行网络的总次数, 因为我们的测试数据集总共有 10000 张图片, 并且模型 batch 为 1, 故设置为 10000test_iters = 10000# Main testing loopfor i in range(test_iters): workspace.RunNet(test_model.net) acc = workspace.FetchBlob('accuracy') avg_accuracy += acc if (i % 500 == 0) and (i &gt; 0): print("Iter:&#123;&#125;, Current Accuracy: &#123;&#125;".format(i, avg_accuracy/float(i)))# 输出相关信息print("*************************")print("Final Test Accuracy: ", avg_accuracy/float(test_iters)) 输出结果如下: 123456789101112131415161718192021Iter: 500, Current Accuracy: 0.654Iter: 1000, Current Accuracy: 0.663Iter: 1500, Current Accuracy: 0.640666666667Iter: 2000, Current Accuracy: 0.643Iter: 2500, Current Accuracy: 0.6356Iter: 3000, Current Accuracy: 0.639333333333Iter: 3500, Current Accuracy: 0.639142857143Iter: 4000, Current Accuracy: 0.63625Iter: 4500, Current Accuracy: 0.636444444444Iter: 5000, Current Accuracy: 0.6352Iter: 5500, Current Accuracy: 0.638181818182Iter: 6000, Current Accuracy: 0.638666666667Iter: 6500, Current Accuracy: 0.638461538462Iter: 7000, Current Accuracy: 0.636428571429Iter: 7500, Current Accuracy: 0.634533333333Iter: 8000, Current Accuracy: 0.63475Iter: 8500, Current Accuracy: 0.633058823529Iter: 9000, Current Accuracy: 0.632111111111Iter: 9500, Current Accuracy: 0.632421052632*********************************************Final Test Accuracy: 0.6321 利用 checkpoint 对模型进行再训练从上面的结果我们可以看出, 我们模型在精度上虽然比随机猜测要高一些, 但是如果能够进行更多次迭代的训练, 模型的精度应该还会进一步提高, 为此, 我们需要进行以下步骤: 创建一个新的 model helper 指定训练数据集和 training imdb 利用 Add_Original_CIFAR10_Model() 重新定义模型的结构. 从之前保存的 init_net.pb 文件中获取相应的参数权重 继续训练 下面我们新创建了一个 model helper 对象用于训练, 请注意要将 init_params 参数设置为 False. 这一点非常重要, 因为我们不希望 brew 自动初始化参数, 而是从文件中加载权重(也就是我们自己来设置这些参数的值). 一旦我们创建了 model helper, 我们将会添加 input layer 并将其指向 training lmdb. 12345678910111213141516171819202122# 定义训练的迭代次数training_iters = 3000# 清空当前的工作空间(主要是清空之前的 testing stage 产生的信息)workspace.ResetWorkspace()# 创建一个新的 modelarg_scope = &#123;"order": "NCHW"&#125;train_model = model_helper.ModelHelper( name="cifar10_train", arg_scope=arg_scope, init_params=False)# 向模型中添加 data layerdata, _ = AddInputLayer(train_model, 100, TRAIN_LMDB, 'lmdb')softmax = Add_Original_CIFAR10_Model(train_model, data, 10, 32, 32, 3)# 用之前保存的文件来填充 model 对象的 param_init_net 成员init_net_proto = caffe2_pb2.NetDef()with open(INIT_NET, "rb") as f: init_net_proto.ParseFromString(f.read())tmp_init_net = core.Net(init_net_proto)train_model.param_init_net = train_model.param_init_net.AppendNet(tmp_init_net) 下面的代码指定了损失函数和优化器, 和之前的代码没什么不同.12345678910111213141516# 向模型中添加 training operatorsxent = train_model.LabelCrossEntropy([softmax, 'label'], 'xent')# 计算 lossloss = train_model.AveragedLoss(xent, "loss")# 根据模型的精度accuracy = brew.accuracy(train_model, [softmax, "label"], "accuracy")# 添加计算梯度的 opstrain_model.AddGradientOperators([loss])# 指定优化算法optimizer.build_ssd( train_model, base_learning_rate=0.01, policy="fixed", momentum=0.9, weight_decay=0.004) 注意:我们可以利用 GetOptimizationParamInfo() 函数来获得会被优化函数优化的参数. 如果你希望以不同的方式训练你的模型, 而模型看起来并没有被正确训练, 那么检查一下这个函数的返回值. 如果返回值为空, 那么就说明定义的网络没有训练任何东西! 这就是我们在 Add_Original_CIFAR10_Model() 函数中利用 brew 来创建网络层的原因之一, 因为 brew 会自动帮我们创建网络层所需的参数. 而如果我们已经在 Model Helper 中 append .net, 那么就会返回空, 意味着没有任何参数被优化. 在工作区中, 当你 append 一个 net 以后, 你需要利用 create_param() 手动的创建 params. 12for param in train_model.GetOptimizationParamInfo(): print("Param to be optimized: ", param) 正常情况下, 应该输出如下:12345678910Param to be optimized: conv3_bParam to be optimized: fc2_wParam to be optimized: fc1_bParam to be optimized: conv1_bParam to be optimized: conv2_bParam to be optimized: conv3_wParam to be optimized: fc2_bParam to be optimized: fc1_wParam to be optimized: conv2_wParam to be optimized: conv1_w 定义好模型以后, 输入下面的代码开始训练: 1234567891011# 初始化并创建 train model 的网络workspace.RunNetOnce(train_model.param_init_net)workspace.CreateNet(train_model.net, overwrite=True)# Run the training loopfor i in range(training_iters): workspace.RunNet(train_model.net) acc = workspace.FetchBlob('accuracy') loss = workspace.FetchBlob('loss') if i % 100 == 0: print("Iter: &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;".format(i, loss, acc)) 正常情况下, 输出如下: 123456789101112131415161718192021222324252627282930Iter: 0, Loss: 1.02017736435, Accuracy: 0.629999995232Iter: 100, Loss: 1.03627979755, Accuracy: 0.639999985695Iter: 200, Loss: 1.01044285297, Accuracy: 0.649999976158Iter: 300, Loss: 1.11098098755, Accuracy: 0.569999992847Iter: 400, Loss: 0.857563138008, Accuracy: 0.660000026226Iter: 500, Loss: 0.947329521179, Accuracy: 0.689999997616Iter: 600, Loss: 1.03314650059, Accuracy: 0.660000026226Iter: 700, Loss: 0.916410207748, Accuracy: 0.72000002861Iter: 800, Loss: 0.780662596226, Accuracy: 0.730000019073Iter: 900, Loss: 0.84335398674, Accuracy: 0.709999978542Iter: 1000, Loss: 0.813905596733, Accuracy: 0.740000009537Iter: 1100, Loss: 0.696036875248, Accuracy: 0.730000019073Iter: 1200, Loss: 0.901836633682, Accuracy: 0.680000007153Iter: 1300, Loss: 0.892839670181, Accuracy: 0.649999976158Iter: 1400, Loss: 0.832642018795, Accuracy: 0.72000002861Iter: 1500, Loss: 0.771974146366, Accuracy: 0.72000002861Iter: 1600, Loss: 0.926190078259, Accuracy: 0.699999988079Iter: 1700, Loss: 0.884124755859, Accuracy: 0.680000007153Iter: 1800, Loss: 0.891266524792, Accuracy: 0.660000026226Iter: 1900, Loss: 0.633636891842, Accuracy: 0.75Iter: 2000, Loss: 0.643068671227, Accuracy: 0.77999997139Iter: 2100, Loss: 0.827954411507, Accuracy: 0.740000009537Iter: 2200, Loss: 0.845260441303, Accuracy: 0.689999997616Iter: 2300, Loss: 0.806422412395, Accuracy: 0.689999997616Iter: 2400, Loss: 0.742512345314, Accuracy: 0.740000009537Iter: 2500, Loss: 0.785759627819, Accuracy: 0.759999990463Iter: 2600, Loss: 0.530824780464, Accuracy: 0.790000021458Iter: 2700, Loss: 0.726455926895, Accuracy: 0.709999978542Iter: 2800, Loss: 0.945818066597, Accuracy: 0.670000016689Iter: 2900, Loss: 0.67063999176, Accuracy: 0.810000002384 利用 Retrained 模型进行推演1234567891011121314151617181920212223242526272829303132333435363738394041arg_scope = &#123;"order": "NCHW"&#125;# 构建模型test_model = model_helper.ModelHelper( name="test_model", arg_scope=arg_scope, init_params=False)# 将输入层指向 test lmdbdata, _ = AddInputLayer(test_model, 1, TEST_LMDB, 'lmdb')# 创建模型结构softmax = Add_Original_CIFAR10_Model(test_model, data, 10, 32, 32, 3)accuracy = brew.accuracy(test_model, ['softmax', 'label'], 'accuracy')# Prime the net (准备网络)workspace.RunNetOnce(test_model.param_init_net)workspace.CreateNet(test_model.net, overwrite=True)# CIFAR10 的混合矩阵cmat = np.zeros((10, 10))# Stat keepersavg_accuracy = 0.0test_iters = 10000# Main testing loopfor i in range(test_iters): workspace.RunNet(test_model.net) acc = workspace.FetchBlob('accuracy') avg_accuracy += acc if (i % 500 == 0) and (i &gt; 0): print("Iter: &#123;&#125;, Current Accuracy: &#123;&#125;".format(i, avg_accuracy/float(i))) # 获取 top-1 预测结果 results = workspace.FetchBlob('softmax')[0] label = workspace.FetchBlob('label')[0] max_index, max_value = max(enumerate(results), key=operator.itemgetter(1)) # 更新混合矩阵 cmat[label, max_index] += 1# Report final testing resultsprint("***************************")print("Final Test Accuracy: ", avg_accuracy/float(test_iters)) 正常情况下, 输出如下 123456789101112131415161718192021Iter: 500, Current Accuracy: 0.712Iter: 1000, Current Accuracy: 0.721Iter: 1500, Current Accuracy: 0.718Iter: 2000, Current Accuracy: 0.713Iter: 2500, Current Accuracy: 0.71Iter: 3000, Current Accuracy: 0.716Iter: 3500, Current Accuracy: 0.72Iter: 4000, Current Accuracy: 0.71675Iter: 4500, Current Accuracy: 0.719555555556Iter: 5000, Current Accuracy: 0.7194Iter: 5500, Current Accuracy: 0.720363636364Iter: 6000, Current Accuracy: 0.721166666667Iter: 6500, Current Accuracy: 0.720461538462Iter: 7000, Current Accuracy: 0.719571428571Iter: 7500, Current Accuracy: 0.7188Iter: 8000, Current Accuracy: 0.7185Iter: 8500, Current Accuracy: 0.718235294118Iter: 9000, Current Accuracy: 0.718Iter: 9500, Current Accuracy: 0.717157894737*********************************************Final Test Accuracy: 0.7169 查看结果1234567891011121314151617# Plot confusion matrixfig = plt.figure(figsize=(10,10))plt.tight_layout()ax = fig.add_subplot(111)res = ax.imshow(cmat, cmap=plt.cm.rainbow,interpolation='nearest')width, height = cmat.shapefor x in xrange(width): for y in xrange(height): ax.annotate(str(cmat[x,y]), xy=(y, x),horizontalalignment='center',verticalalignment='center')classes = ['Airplane','Automobile','Bird','Cat','Deer','Dog','Frog','Horse','Ship','Truck']plt.xticks(range(width), classes, rotation=0)plt.yticks(range(height), classes, rotation=0)ax.set_xlabel('Predicted Class')ax.set_ylabel('True Class')plt.title('CIFAR-10 Confusion Matrix')plt.show() 输出如下:]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Caffe2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch 踩坑]]></title>
    <url>%2Fz_post%2FPyTorch-%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[模型与参数的类型不符Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same TensorIterator expected type torch.cuda.FloatTensor but got torch.FloatTensor 要么需要在每一处新建立的tensor上将其手动移动到 cuda 或者 cpu 上, 要么利用下面的语句设置默认设备和类型12if torch.cuda.is_available(): torch.set_default_tensor_type('torch.cuda.FloatTensor') https://www.zhihu.com/question/67209417/answer/250909765 reshape 和 view 的不同view 只能作用在连续的内存空间上. 并且不会对 tensor 进行复制. 当它作用在非连续内存空间的 tensor 上时, 会产生报错.reshape 可以作用在任何空间上, 并且会在需要的时候创建 tenosr 的副本. module ‘torchvision.datasets’ has no attribute ‘VOCDetection’这是因为 VOCDetection 还没有添加到最新的 release 版本的导致的错误, 我们可以通过源码的方式重新安装 torchvision. 方法如下: 首先查看当前虚拟环境的 torchvision 的安装位置:12345import torchvision as tvprint(tv.__file__)# /home/zerozone/.pyenv/versions/a3py3.5/lib/python3.5/site-packages/torchvision/__init__.py 然后进入上面的文件夹, 删除旧的 torchvision123cd /home/zerozone/.pyenv/versions/a3py3.5/lib/python3.5/site-packages/rm -rf torchvision* 然后下载最新版本的 torchvision 并安装(注意不要更换安装路径) 123git clone https://github.com/pytorch/vision.gitpython setup.py install 最后查看新安装的 torchvision 中是否包含 VOCDetection: 123&gt;&gt;&gt; import torchvision as tv&gt;&gt;&gt; print(dir(tv.datasets))# ['CIFAR10', 'CIFAR100', 'CocoCaptions', 'CocoDetection', 'DatasetFolder', 'EMNIST', 'FakeData', 'FashionMNIST', 'Flickr30k', 'Flickr8k', 'ImageFolder', 'LSUN', 'LSUNClass', 'MNIST', 'Omniglot', 'PhotoTour', 'SBU', 'SEMEION', 'STL10', 'SVHN', 'VOCDetection', 'VOCSegmentation', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'cifar', 'coco', 'fakedata', 'flickr', 'folder', 'lsun', 'mnist', 'omniglot', 'phototour', 'sbu', 'semeion', 'stl10', 'svhn', 'utils', 'voc'] 可以看到, 新包含了 &#39;VOCDetection&#39;, &#39;VOCSegmentation&#39;, &#39;voc&#39; 等名称, 说明安装成功, 此时可以正常使用 VOCDetection 了. CUDA driver version is insufficient for CUDA runtime version考虑可能是 cuda 或者 显卡驱动的版本不匹配, 也可能是 PyTorch 的版本过低导致的, 建议提升 PyTorch 版本至最新的稳定版. Differences between .data and .detach【链接】PyTorch中tensor.detach()和tensor.data的区别https://blog.csdn.net/DreamHome_S/article/details/85259533 https://github.com/pytorch/pytorch/issues/6990 detach 的作用: https://blog.csdn.net/qq_39709535/article/details/80804003 Variable 在 PyTorch 1.0 中如何替换将 PyTorch 模型转换成 Caffe 模型https://github.com/longcw/pytorch2caffe DataLoader挂起:当num_worker参数大于1时, 会出现一些奇怪的现象, 表现为无法迭代(挂起, 死锁), 进而无法使用上面的进度条模块. https://github.com/pytorch/pytorch/issues/1355(仍然没有完全解决) 现在这种情况多出现在用户手动终止程序后, 再次启动程序时发生, 目前的解决方法是要在dataloader处使用异常捕获, 来避免进程之间的资源死锁 RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 37 and 1 in dimension 1在 pytorch 中, dataloader 会自动将 datasets 中的数据组织成 tensor 的形式, 因此, 这就要求 batch 中的每一项元素的 shape 都要相同. 但是在目标检测中, 每一张图片所具有的 box 的数量是不同的, 因此, 需要自己实现collate_fn来构建 mini-batch 中每一个 samples. 如下所示(ssd代码):12345678910111213141516171819def detection_collate(batch): &quot;&quot;&quot;Custom collate fn for dealing with batches of images that have a different number of associated object annotations (bounding boxes). Arguments: batch: (tuple) A tuple of tensor images and lists of annotations Return: A tuple containing: 1) (tensor) batch of images stacked on their 0 dim 2) (list of tensors) annotations for a given image are stacked on 0 dim &quot;&quot;&quot; targets = [] imgs = [] for sample in batch: imgs.append(sample[0]) targets.append(torch.FloatTensor(sample[1])) return torch.stack(imgs, 0), targets]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[StackGAN---ICCV2017]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-StackGAN-ICCV2017%2F</url>
    <content type="text"><![CDATA[本篇论文解读的排版主要参见原文的格式，针对原文中的每一个小节进行展开，有的是对原文的一个提炼和简单概括，有的是对原文中没有详细介绍的技术的补充和说明。 摘要&emsp;&emsp;要想从给定的文字描述中生成一幅高质量的图片，是一件十分具有挑战性的事情。而现有的方法（截止至2017年）生成的图片，虽然可以表现出文字中的一些关键信息，但是它们都缺少了很多局部细节。这篇文章提出了一个“堆叠式的生成式对抗神经网络——Stacked Generative Adversarial Networks（StackGAN）”。它可以在根据给定的文本信息，生成像素为256×256的高质量图片。具体的做法是利用“分治”的思想，将一个复杂的问题分解成更易解决的多个小问题。这篇文章将生成图片的过程分为了2个阶段： Stage-1：根据给定的文本信息，生成64×64大小的图片草图，着重于描绘图片中主要目标的轮廓和颜色 Stage-2：结合64×64的图片草图和文本信息，生成256×256的更高质量的图片，这个过程不仅修正了第一阶段中的错误信息，同时还反映了的图片中更多的细节。 &emsp;&emsp;另外，为了提高训练时的稳定性和生成图片的多样性，本文还提出了一种新颖的“条件数据增强技术”，可以确保训练过程的平缓（ 不懂 ） 介绍&emsp;&emsp;作者简要介绍了有关“图像生成”和“GAN”的研究现状和存在的困难，然后阐述了本文的3点主要贡献： 提出了一个“堆叠式的生成式对抗神经网络——StackGAN”。该网络是第一个能够生成256×256图片大小的神经网络模型 提出了一个新颖的“条件数据增强技术”。以此来稳定网络训练过程，同时提高了生成图片的多样性 大量的实验和高质量的实验结果表明本文设计的模型框架是有效的，这对以后的研究和发展具有一定的帮助作用 相关工作 VAE PixelRNN energy-based GAN $S^2$-GAN … 堆叠的生成式对抗神经网络——StackGAN&emsp;&emsp;为了生成高质量的图片，本文提出了一个简单但是十分有效的网络模型，它将生成过程分成了两个阶段： Stage-1：根据给定的文本信息，生成64×64大小的图片草图，着重于描绘图片中主要目标的轮廓和颜色 Stage-2：结合64×64的图片草图和文本信息，生成256×256的更高质量的图片，这个过程不仅修正了第一阶段中的错误信息，同时还反映了的图片中更多的细节。 正文之前——Preliminaries&emsp;&emsp;作者在这里简单介绍了GAN和Conditional GAN的核心原理。 GAN：由两个“子模型”组成，这两个“子模型”不断交替训练，它们的训练目标恰好相反，仿佛实在彼此对抗一般。生成模型G的目标是习得能够代表真实数据分布 $p_{data}$ 的生成概率分布 $p_g$ ，而分辨模型D的目标则是要习得能够准确分辨出 $p_{data}$ 和 $p_g$ 的二分类器。它们之间的关系就像是一场“two-player min-max game”一样，其目标方程可以如下表示： \min_G \max_D V(D,G) = E_{x\sim p_{data}}[logD(x)] + E_{z\sim p_z}[log(1-D(G(z)))] Conditional GAN：是GAN的一种扩展，它令生成器和分辨器均接受一个条件向量 $c$ ，分别写成 $G(z,c)$ 和 $D(x,c)$ ，如此一来，生成器就可以根据不同的条件 $c$ 来限定生成的图片。（ $c$ 通常为图片标签或者图片描述） 条件增强技术——Conditioning Augmentation&emsp;&emsp;如图1所示，文本描述信息 $t$ 首先会通过一个编码器进行编码，生成一个text embedding: $\phi_t$ 。 在之前的工作中，会将text embedding非线性的传送到生成器当中去。但是，由于text embedding通常维度很高（100以上），所以当我们的数据十分有限时，text embedding表现出不连续，稀疏等特点，这对训练生成器来说是不利的。为了缓和这个问题，本文不再将text embedding直接送入的生成器中进行训练，而是随机的从一个独立高斯分布 $N(\mu(\phi_t), \Sigma(\phi_t))$ 当中进行采样，生成新的变量 $\hat{c}$ 。利用该技术，可以从一小部分数据中生成更多的训练数据（pairs）。 &emsp;&emsp;另外，为了更进一步的增强训练时的平滑性，同时为了抑制过拟合，本文还在目标函数中增加了下面的正则惩罚项(KL离散度——KL divergence)： D_{KL}(N(\mu(\phi_t), \Sigma(\phi_t)) || N(0,I))（引入随机性变量 $\hat z$ 的原因，可以考虑是因为同样的特别描述往往可以对应到不同的图片） Stage-1 GAN&emsp;&emsp;通过预训练好的编码器对给定的图片描述进行编码，生成text embedding: $\phi_t$ 。利用Conditioning Augmentation技术根据 $\phi_t$ 对 $N(\mu_0(\phi_t),\Sigma_0(\phi_t))$ 采样得到 $\hat c_0$ 。 最后，利用 $\hat c_0$ 和随机向量 $z$ 进行第一阶段的生成，得到 $G(z,\hat c_0)$ 。 在Stage-1的训练阶段，模型通过交替训练以下2个目标函数来分别优化生成器和分辨器： 生成器， $min(L_{G_0})$ ：L_{G_0} = E_{z\sim p_z,t\sim p_{data}}[log\bigl(1-D_0(G_0(z,\hat c_0), \phi_t)\bigr)] + \lambda D_{KL}\bigl( N(\mu_0 (\phi_t), \Sigma_0(\phi_t)) || N(0,I_0) \bigr) 分辨器， $max(L_{D_0})$ ， $D(I,\phi_t)$ 代表图片 $I$ 在 $\phi_t$ 条件下是真实图片的概率：L_{D_0} =E_{(I_0,t)\sim p_{data}} [logD_0(I_0,\phi_t)] + E_{z\sim p_z,t\sim p_{data}}[log \bigl(1-D_0(G_0(z,\hat c_0), \phi_t) \bigr)] 上面公式中： $I_0$ ：来自真实分布 $p_{data}$ 的图片 $t$ ：来自真实分布 $p_{data}$ 的图片描述 $\phi_t$ ：t经过预训练好的编码器编码后得到的text embedding $z$ ：噪声，从 $p_z$ 分布中随机采样而来（本文用的是高斯分布） $\lambda$ ：惩罚项的权重，本文采用 $\lambda = 1$ $N(\mu_0 (\phi_t), \Sigma_0(\phi_t))$ ：用于生成 $\hat c_0$ 的高斯分布，其期望值和方差都是通过神经网络学习出来的 模型架构 ： &emsp;&emsp;对于生成器 $G_0$ 来说，要想得到文本条件变量 $\hat c_0$ ，首先要将text embedding $\phi_t$ 送到一个全连接层中以此来生成 $\mu_0$ 和 $\sigma_0$ （ $\sigma_0$ 是 $\Sigma_0$ 对角线上的值），得到高斯分布 $N(\mu(\phi_t),\Sigma(\phi_t))$ 。然后从高斯分布中采样得到文本条件变量 $\hat c_0 = \mu_0 + \sigma_0 \cdot \epsilon$ ， $\hat c_0$ 的维度为 $N_g$ 。 这里，“ $\cdot$ ”代表点乘，$\epsilon \sim N(0,I)$ 。之后，将 $\hat c_0$ 和噪声向量 $z$ 连接起来，它们经过一些列“升维块”（upsampling block）之后，会生成大小为 $W_0 \times H_0$ 的图片。 &emsp;&emsp;对与分辨器 $D_0$ 来说，首先利用全连接层将 $\phi_t$ 压缩到 $N_d$ 维，然后，将其在空间上进行复制，形成一个 $M_d \times M_d \times N_d$ 的张量。 同时，将图片送到一系列“降维块”（downsampling block）中，使其具有 $M_d \times M_d \times N_{filter}$ 的空间结构，然后将图片的tensor和文本的tensor沿着channel的维度连接的一起，然后将其送到 $1 \times 1$ 的卷积层当中，联合学习图片和文本之间的关系特征。最后，将特征传送到输出为一个节点的全连接层，得到当前图片与文本属于真实数据的概率。 Stage-2 GAN&emsp;&emsp;从Stage-1 GAN中得到的低分辨率图像通常会缺少一些局部细节，有时候还会造成主要目标物不同程度的形变。另一方面，有些存在于文本中的重要信息，也可能被忽视。 因此，本文的Stage-2 GAN在Stage-1的基础上进行构建。它将Stage-1返回的低分辨率图片和图片描述的text embedding作为GAN的条件，使之返回的结果不仅能修正Stage-1中的错误信息，同时还可以补充在Stage-1中没有捕捉到的信息。 &emsp;&emsp;当选取Stage-1低分辨率结果 $s_0 = G_0(z,\hat c_0)$ 和 高斯变量 $\hat c$ 作为GAN的条件时，生成器和分辨器的目标函数如下所示： 生成器， $min(L_G)$ ：L_G = E_{z\sim p_z,t\sim p_{data}}[log\bigl(1-D(G(s_0,\hat c), \phi_t)\bigr)] + \lambda D_{KL}\bigl( N(\mu (\phi_t), \Sigma(\phi_t)) || N(0,I) \bigr) 分辨器， $max(L_D)$ ， $D(I,\phi_t)$ 代表图片 $I$ 在 $\phi_t$ 条件下是真实图片的概率：L_D =E_{(I,t)\sim p_{data}} [logD(I,\phi_t)] + E_{z\sim p_z,t\sim p_{data}}[log \bigl(1-D(G(s_0,\hat c), \phi_t) \bigr)] &emsp;&emsp;与第一阶段的GAN不同的是，在Stage-2中，本文提出了一个假设，那就是作为Stage-1条件之一的随机变量 $z$ ，可以确保Stage-1的生成结果具有多样性。在这样的假设下，本文在Stage-2阶段并不使用 $z$ 作为条件，而是采用Stage-1的生成结果 $s_0$ 作为条件。 高斯条件变量 $\hat c$ 和 $\hat c_0$ 分别作为Stage-2和Stage-1阶段的CA（Contioning Augmentation），它们共享同一个text embedding—— $\phi_t$ ， $\phi_t$ 由同一个预训练的编码器生成。 但是，Stage-1和Stage-2的CA会通过不同的全连接层，因此，它们生成的关于 $\phi_t$ 的均值和方差不同。 通过这种方式，Stage-2可以学习到被Stage-1所忽略的一些有用的信息。 模型架构： &emsp;&emsp;对于生成器，本文利用残差模块（residual blocks）将Stage-2的生成器设计成一个“编码-解码网络”（encoder-decoder network）。 首先，根据给定的text embedding $\phi_t$ 生成维度为 $N_g$ 的文本条件向量 $\hat c$ ，然后对其进行复制，使之形成形状为 $M_g \times M_g \times N_g$ 的张量。 同时，将Stage-1的结果 $s_0$ 送到若干个“降维模块”（downsampling block）中，直至其size变为 $M_g \times M_t$ 为止。然后将文本特征和图片特征沿着channels连接到一起，并将其送到若干个“残差模块”中去，目的是为了学习到图片和文本交织在一起的多模态表征。最终，通过一系列的“升维模块”（upsampling block），也就是解码器（decoder），生成size为 $W \times H$ 的高分辨率图片。 &emsp;&emsp;对于分辨器，它的结构与Stage-1中的结构相似，只不过由于接受的图片size变大了，所以需要更多的“降维模块”（downsampling block）。为了让分辨器更好的学到图片和文本之间的联系，本文采用了matching-aware discriminator，而非vanilla discriminator，具体可以参考才论文中的参考文献部分。 在训练阶段，正反例构成如下： 正例：真实的图片和与之对应的文本描述 反例：1、真实的图片和不相匹配的文本描述&emsp; 2、生成器生成的图片和与之对应的文本描述 实现细节&emsp;&emsp;“升维模块”由 $3 \times 3 stride 1$ 的卷积层后接最近邻upsampling组成。除了最后的卷积层外，其他卷积层都使用了Batch Normalization和ReLU激活函数。 “残差模块”由 $3 \times 3 stride 1$ 的卷积层、Batch Normalization和ReLU激活函数组成。 在 $128 \times 128$ 的StackGAN模型中，使用了2个“残差模块”，而在 $256 \times 256$ 的StackGAN模型中，使用了4个“残差模块”。 “降维模块”由 $4 \times 4 stride 2$ 的卷积层、Batch Normalization（除第一层）和LeakyReLU组成。&emsp;&emsp;默认情况下，$N_g = 128$ , $N_z = 100$, $M_g = 16$, $M_d = 4$, $N_d = 128$, $W_0 = H_0 = 64$ , $W = H = 256$ 。在训练时，首先固定Stage-2 ，同时迭代训练Stage-1 GAN的 $D_0$ 和 $G_0$ 600 epochs。然后再固定Stage-1 ，同时迭代训练Stage-2 GAN的 $G$ 和 $D$ 600epochs。所有的网络训练时都使用ADAM优化算法，batch size为64,初始的学习率为0.0002 ，学习率每经过100epochs都会衰减成原来值的一半。 实验&emsp;&emsp;为了验证上面提出的模型和方法的有效性，本文进行了大量的高质量实验。本文采用的对照方法是目前（2017）最有效的两个图片生成方法：GAN-INT-CLS和GAWWN 。 测试这两个方法时使用的代码来自于各自的作者。 除此以外，文本还设计了多个baseline models来验证模型整体的设计和每个部分对模型的重要程度。对于第一个baseline，本文直接训练Stage-1 GAN来生成64×64和256×256大小的图片，来探究本文提出的stack结构和CA技术是否对最终结果有帮助。然后修改本文的StackGAN，令其分别生成128×128和256×256大小的图片，来验证在生成更大的图片时，本文的模型是否可以生成取得更好的图片质量。另外，我们还验证了是否有必要在每个Stage都将图片描述作为约束条件之一。 数据集和评价标准&emsp;&emsp;CUB数据集包含200种鸟类，共11788张图片。由于该数据集中80%的鸟的大小与图片大小的比例小于0.5,因此我们需要对其进行剪裁预处理，确保所有的图片中鸟占总大小的比例在0.75以上。Oxford-102数据集包含102种花类，共8189张图片。为了证实本文方法的有效性，同时还对一个更具挑战性的数据集——MS COCO数据集进行了实验， MS COCO数据集中的图片具有不同的背景，同时每张图片会有多个不同的物体， 它具有80k张图片作为训练集，40k张图片作为作为验证集。 COCO中的每张图片具有5条描述，CUB和Oxford-102中的每张图片具有10条描述。 &emsp;&emsp; 评价标准： 目前，关于图片生成还没有很适合的权威的评价标准，在这里，本文采用的是最近比较流行的“inception score”来对生成图片的质量进行评价，公式如下： I = exp(E_x D_{KL}( p(y|x) || p(y)))其中， $x$ 代表生成的图片， $y$ 代表Inception model预测的图片标签。该评价公式背后包含的隐层含义是： 好的模型应该能生成多种多样并且有意义的图片 。因此，边缘分布 $p(y)$ 和条件分布 $p(y|x)$ 之间的KL散度应该越大越好。对于MC COCO数据集，本文直接使用预训练好的模型进行评价，而对于CUB和Oxfor-102数据集，本文先对其进行fine-tune迁移学习，训练出不同的模型，然后，再分别进行评价。评价时，对每个模型都需要大量的样本参与（随机挑选30k以上个生成模型产生的样本）。 &emsp;&emsp;尽管inception score可以表现出类似于人的对“高质量图片”的感知能力，但是它却不能准确反应出生成的图片和图片描述信息之间的相关联系。因此，本文还进行人工评价。本文随机选取了CUB和Oxfor-102测试集中的50条图片描述信息，从MS COCO测试集中随机选取了4k条图片描述。 对于每条描述信息，对应的生成模型都会产生5张图片， 然后让10个用户通过不同的方法对这些图片进行排序。最后用平均排序结果作为最终的人工评价。 定性/定量结果——Quantitative and qualitative results&emsp;&emsp;本文在3个数据集上与现有的两种stage of art方法进行比较，inception scores和平均人工排序结果如下表所示。可以看出，本文的Stack GAN方法在三个数据集上全都取得了最好的结果。 &emsp;&emsp;从下面的图中，也可以看出本文提出的方法，可以生成更加生动的图片，同时生成的图片也具有多样性，而非单纯的“记忆”了训练集中的数据。 成分分析——Component analysis&emsp;&emsp;在本小节中，我们会利用baseline mdoels来分析StackGAN每个成分的作用。下表展示了不同baseline models的inception socres StackGAN的设计： 如表中前四行所示，如果令Stage-1 GAN直接生成256×256的图片，inception scores会大大下降，并且在不使用CA的情况下，甚至无法生成合理的具有含义的图片。即使在使用CA的情况下可以生成含有一定意义的图片，它的图片质量也远不如Stack GAN生成的图片质量，详情如下图所示。这说明了本文提出了Stack结构是有效的。 另外，当把生成图片的分辨率降到128×128以后，inception socres的值从3.70降到了3.35。需要注意的是，inception model接受的图片大小为299×299,所以它在计算inception scores之前，会先将所有输入图片放缩到规定大小后再送入网络进行计算。因此，如果本文的模型仅仅是将128×128的图片放大到256×256，那么，最终计算出的inception scores就不会产生差异（多个线性放缩的叠加会退化成一个放缩计算），这就说明了本文的模型在生成256×256的图片时，相较于128×128的图片，确确实实生成了更多有效的信息。对于256×256的Stack GAN来说，如果仅仅只在Stage-1使用图片描述作为约束条件，inception scores的值会从3.70降到3.45，这说明将Stage-2阶段确实可以捕捉到Stage-1所忽略的文本信息，从而有助于生成高质量的图片。 条件增强——Conditioning Augmentation： 本文同时还探究了CA技术的有效性，在不使用CA技术时，inception scores的值明显下降，并且，在训练时还容易崩溃，导致生成的图片难以识别。而在使用CA时，不仅能提成inception scores的值，还能生成更加多样的鸟（如姿态、脸的朝向等）。 语句嵌入插值——Sentence embedding interpolation： 为了更进一步的证明我们的模型可以学习到更加光滑的潜在的数据信息，本文通过对text embedding线性插值的方式来进行验证。首先固定住噪声变量 $z$ ，这样一来生成的图片仅受图片text embedding约束的影响。下图中第一行的图片使用的text embedding是由我们自己可以制作的句子生成的，这些句子仅仅包含一些简单的颜色描述。结果显示，生成的图片可以根据不同的text embedding生成与之对应的鸟，可以反映出text embedding中描述的颜色，同时还能保持合理的外形。第二行展示了一些更加复杂句子生成的图片，这些句子包含更多的描述信息，用这些句子生成的图片中的鸟，它们的主要颜色会从红色慢慢变成蓝色，而翅膀的颜色会从黑色慢慢的变成棕色。 总结&emsp;&emsp;在本篇文章中，作者提出了一个Stack GAN模型框架，同时结合CA技术，来生成具有照片真实度的图片。 该模型将text-to-image synthesis任务变成了一个“草图——细化”的过程。 Stage-1 GAN主要负责输出图片的“草图”，它侧重于输出图片的基本颜色搭配和主要目标的轮廓信息。 Stage-2 会修正Stage-1中的一些错误，同时很会再次根据图片描述来补充Stage-1中遗漏的信息，从而生成更高质量的图片。 大量的实验表明，本文提出的方法是有效的。 同时，与现有的最领先的方法进行比较后，本文的模型可以生成更高分辨率的图片，同时包含更多的信息和细节。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe2 教程-Models and Datasets]]></title>
    <url>%2Fz_post%2FCaffe2-%E6%95%99%E7%A8%8B-ModelsAndDatasets%2F</url>
    <content type="text"><![CDATA[Models vs Datasets]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>Caffe2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe2 教程-Brewing Models]]></title>
    <url>%2Fz_post%2FCaffe2-%E6%95%99%E7%A8%8B-BrewingModels%2F</url>
    <content type="text"><![CDATA[Brew 简介brew 是 Caffe2 里面的一个新的 API, 该 API 和过去的 CNNModelHelper 的作用是相似的, 但是由于 Caffe2 现在不仅仅支持 CNN, 因此将 CNNModelHelper 替换为 ModelHelper 显得更加合理. brew 封装了 ModelHelper , 是的搭建模型更加简单. Model Building and Brew’s Helper Functions在本小节中, 我们将会介绍一个由 helper functions 组成的轻量级的集合, 这些函数可以帮助我们更轻易的搭建模型. 下面我们会先介绍关于 Ops 和 Helper Functions 的相关概念. 接下来我们将会展示如何使用 brew 以及引入 brew 的动机. Concepts: Ops vs Helper Functions在介绍 brew 之前, 我们首先应该回顾一下 Caffe2 中的一些常规概念, 以及在一个神经网络中, 一个网络层是如何表示的. 在 Caffe2 中, 深度学习框架是建立在 operators 之上的. 通常这些 operators 使用 C++ 实现, 同时 Caffe2 会提供封装了 C++ 代码的 Python API. 在 Caffe2 中, operators 的命名方式采用驼峰风格, 而对应的 helper functions 则采用相似的小写名称. Ops通常我们将 operators 缩写为 Op, 将一系列 operators 的集合缩写为 Ops. 例如, 一个 FC Op 代表了一个 Fully-Connected operator. 下面的代码创建了一个 FC 网络层. 1model.net.FC([blob_in, weights, bias], blob_out) 下面的代码创建了一个 Copy Op: 1model.net.Copy(blob_in, blob_out) 也可以省略.net, 含义等价, 如下所示:1model.Copy(blob_in, blob_out) ModelHelper 包含了29个最常用的 Ops. 其持有的 Ops 是 Caffe2 中400+ Ops 的一个子集 Helper Functions如果使用单一的 operators 来创建网络或模型, 则在参数初始化的时候会非常麻烦, 并且还需要自己选择 device/engine (这也是为什么 Caffe2 很快!). 利用, 创建一个 FC 层的时候, 我们需要自己写代码来准备 weights 和 bias, 然后将其送入到 Op 中, 如下所示: 12345678910111213141516171819# This is the longer, manual way:model = model_helper.ModelHelper(name="train")# 初始化权重weight = model.param_init_net.XavierFill( [], blob_out + '_w', shape=[dim_out, dim_in], **kwargs, # 指定 weights 的GPU位置)# 初始化偏置bias = model.param_init_net.ConstantFill( [], blob_out + '_b', shape=[dim_out, ], **kwargs,)# 接着创建 FCmodel.net.FC([blob_in, weights, bias], blob_out, **kwargs) 可以看出, 上面的代码十分麻烦, 因此, 我们可以利用 Caffe2 helper functions 来帮助我们. helper function 会自动处理参数的初始化, operator 的定义, 以及 engine 的选择. Caffe2 中默认的 helper functions 采用的是 Python PEP8 的命名规范. 例如, 它会使用 fc 来实现 FC Op. 下面的代码和上面的代码相同, 可以明显看出更加简洁: 1fcLayer = fc(model, blob_in, blob_out, **kwargs) brew既然我们已经了解的 Ops 和 Helper Functions, 下面就来介绍一下如何利用 brew 更简单的搭建模型. brew 更像是一个智能的集合, 你可以利用它调用所有的 Caffe2 helper functions, 如下所示, 调用了一个 fc 辅助函数. 12from caffe2.python import brewbrew.fc(model, blob_in, blob_out, ...) 当模型变的复杂度, brew 就会显得十分有用, 下面的代码定义了一个经典的 LeNet. 123456789def AddLeNetModel(model, data): conv1 = brew.conv(model, data, "conv1", 1, 20, 5) pool1 = brew.max_pool(model, conv1, "pool1", kernel=2, stride=2) conv2 = brew.conv(model, pool1, "conv2", 20, 50, 5) pool2 = brew.max_pool(model, conv2, "pool2", kernel=2, stride=2) fc3 = brew.fc(model, pool2, "fc3", 50*4*4, 500) fc3 = brew.relu(model, fc3, fc3) pred = brew.fc(model, fc3, "pred", 500, 10) softmax = brew.softmax(model, pred, "softmax") 上面的代码使用 brew 来定义网络, 代码变的十分整洁. arg_scopearg_scope 更像是一种语法糖, 它可以让你在当前上下文环境中设置默认的 helper function 的参数. 举个例子, 如果你想要在 ResNet-150 的训练脚本中尝试使用不同的权重初始化, 你首先会想到这么做: 123456# 改变所有的 weight_init 参数brew.conv(model, ..., weight_init=("XavierFill", &#123;&#125;), ...)...# 重复150次...brew.conv(model, ..., weight_init=("XavierFill", &#123;&#125;), ...) 而如果使用 arg_scope, 我们只需要更改一处地方即可:1234with brew.arg_scope([brew.conv], weight_init=("XavierFill", &#123;&#125;)): brew.conv(model, ...) # 这里不用指定 weight_init 参数 brew.conv(model, ...) ... 自定义 Helper Function如果你经常使用 brew, 而某个你希望的 Op 没有默认的实现, 那么你可以自定义使用一个 helper function.创建自定义的 new_helper_function, 首先利用 brew.Register 进行注册, 然后就可以使用 brew.new_helper_function 进行调用, 如下所示: 12345def my_super_layer(model, blob_in, blob_out, **kwargs): #...balabalabrew.Register(my_super_layer)brew.my_super_layer(model, blob_in, blob_out) Caffe2 Default Helper Functions下面是 Caffe2 中默认的29个最常用的 Ops, 点击这里可以查看详细信息. 引入 brew 的动机.长话短说: Caffe2 的开发者希望将模型的创建过程和模型的存储分离开. 在开发者的想法中, ModelHelper 类应该只包含网络的定义和网络参数信息. 而 brew 会包含用于创建网络的初始化参数的函数.旧版的 CNNModelHelper 同时包含模型存储和模型搭建, 与之相比, ModelHelper + brew 的模型创建方式更加模块化且易于扩展. 并且避免了命名方面造成的疑惑(因为 Caffe2 不仅仅有CNN, 还有 RNN 和 MLP 等). 关于 brew 的一个详细示例https://github.com/pytorch/pytorch/blob/master/caffe2/python/brew_test.py]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>Caffe2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe2 教程-Intro Tutorial]]></title>
    <url>%2Fz_post%2FCaffe2-%E6%95%99%E7%A8%8B-IntroTutorial%2F</url>
    <content type="text"><![CDATA[本篇教程主要介绍一些 Caffe2 里面基础概念, 以便帮助理解 Caffe2 模型的设计思路和基本原理. 在 Caffe2 中, 对于任意一个 operator, 我们不仅仅需要提供 input, 同时还需要提供 weights 和 bias.(这是与 Caffe 的不同点之一) Blobs and Workspace, Tensors在 Caffe2 中, 数组的组织形式是 blobs. 一个 blobs 可以看做是内存当前一块带有名字的数据. 绝大多数 blobs 都包含一个 tensor, 在 Python 中, 会被转换成 numpy 数组来表示. 而 workspace 会存储所有的 blobs, 下面的代码展示了如何将 blobs 添加到 workspace 中, 以及如何再次获取它们. workspace 会在你开始使用的时候对自身进行初始化. 1234567891011from caffe2.python import workspace, model_helperimport numpy as np# Create random tensor of three dimensionsx = np.random.rand(4, 3, 2)print(x)print(x.shape)workspace.FeedBlob("my_x", x)x2 = workspace.FetchBlob("my_x")print(x2) Nets and Operators在 Caffe2 中, 基本模型的抽象形式为 net. 一个 net 可以看成是一个图, 其中节点为各种 operators, 这些 operators 会接受一系列 blobs 作为输入, 然后会输出一个或多个 blobs.在下面的代码块中, 我们将会创建一个简单的模型, 它包含以下三个部分: 一个全连接层(FC) 一个使用了 Softmax 的 Sigmoid 激活函数 交叉熵损失函数 我们利用 ModelHelper 来帮助创建模型, 它会创建以下两个互相联系的 nets: 一个执行参数初始化(ref.init_net) 一个执行训练逻辑(ref.exec_net) 1234567891011121314151617# Create the input datadata = np.random.rand(16, 100).astype(np.float32)# Create labels for the data as integers [0, 9].label = (np.random.rand(16) * 10).astype(np.int32)workspace.FeedBlob("data", data)workspace.FeedBlob("label", label)# Create model using a model helperm = model_helper.ModelHelper(name="my first net")weight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])bias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])fc_1 = m.net.FC(["data", "fc_w", "fc_b"], "fc1")pred = m.net.Sigmoid(fc_1, "pred")softmax, loss = m.net.SoftmaxWithLoss([pred, "label"], ["softmax", "loss"]) 上面的代码首先在内存中创建了数据和标签的 blobs. 数据的第一维代表 batch size, 即16. 许多 Caffe2 的 operators 都可以利用 ModelHelper 直接获取, 因此我们用它创建了一系列 operators, 包括: FC, Sigmoid 和 SoftmaxWithLoss.ModelHelper 会创建两个 nets: m.param_init_net 用于初始化指定的参数, 只需要执行一次即可. m.net 用于执行训练逻辑, 该过程对用户透明, 且是自动运行的.网络的定义存储在一个 protobuf 结构当中(Google’s Protocal Buffer), 可以通过下面的方式来进行检查网络 1print(m.net.Proto()) 输出如下: 123456789101112131415161718192021222324252627name: &quot;my first net&quot;op &#123; input: &quot;data&quot; input: &quot;fc_w&quot; input: &quot;fc_b&quot; output: &quot;fc1&quot; name: &quot;&quot; type: &quot;FC&quot;&#125;op &#123; input: &quot;fc1&quot; output: &quot;pred&quot; name: &quot;&quot; type: &quot;Sigmoid&quot;&#125;op &#123; input: &quot;pred&quot; input: &quot;label&quot; output: &quot;softmax&quot; output: &quot;loss&quot; name: &quot;&quot; type: &quot;SoftmaxWithLoss&quot;&#125;external_input: &quot;data&quot;external_input: &quot;fc_w&quot;external_input: &quot;fc_b&quot;external_input: &quot;label&quot; 通过下面的代码可以查看参数初始化网络 1print(m.param_init_net.Proto()) 输出如下: 1234567891011121314151617181920name: &quot;my first net_init&quot;op &#123; output: &quot;fc_w&quot; name: &quot;&quot; type: &quot;XavierFill&quot; arg &#123; name: &quot;shape&quot; ints: 10 ints: 100 &#125;&#125;op &#123; output: &quot;fc_b&quot; name: &quot;&quot; type: &quot;ConstantFill&quot; arg &#123; name: &quot;shape&quot; ints: 10 &#125;&#125; 可以看到有两个 operators, 它们会分别对 FC 的权重和偏置参数进行初始化. Executing现在, 既然我们已经定义好了用于网络训练的 operators, 那么就可以利用下面的代码来训练我们的简单模型.首先, 调用一次参数初始化网络: 1workspace.RunNetOnce(m.param_init_net) 注意, 通常情况下, 上面的代码会将 param_init_net 的 protobuffer 结构传送给 C++ 运行时以供执行. 接下来, 创建真正用于训练的网络 1workspace.CreateNet(m.net) 我们只需要创建该网络一次, 然后可以多次执行它 123456789workspace.CreateNet(m.net, overwrite=True) # 这里需要将 overwrite 设置为 True, 官方教程没有设值, 运行时会出现RuntimeError# Run 100 × 10 iterationsfor _ in range(100): data = np.random.rand(16, 100).astype(np.float32) label = (np.random.rand(16)*10).astype(np.int32) workspace.FeedBlob("data", data) workspace.FeedBlob("label", label) workspace.RunNet(m.name, num_iter=10) #Run net 10 times 注意, 因为我们已经在 workspace 中定义过 net 了, 因此, 我们只需要传送 m.name 给 RunNet 函数即可, 而无需再次定义网络.在训练迭代完成后, 可以通过 Fetch 来查看计算的结果 12print(workspace.Fetch("softmax"))print(workspace.Fetch("loss")) Backward pass上面的网络仅仅包含 foward pass, 因此它不会学到任何东西, 我们可以通过在每一个 operator 中添加一个梯度计算操作来实现 backward pass. 我们需要在调用 RunNetOnce() 之前在网络中插入下面的 operator: 1m.AddGradientOperators([loss]) 接着可以看看新的网络的结构 1print(m.net.Proto()) 输出如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566name: &quot;my first net&quot;op &#123; input: &quot;data&quot; input: &quot;fc_w&quot; input: &quot;fc_b&quot; output: &quot;fc1&quot; name: &quot;&quot; type: &quot;FC&quot;&#125;op &#123; input: &quot;fc1&quot; output: &quot;pred&quot; name: &quot;&quot; type: &quot;Sigmoid&quot;&#125;op &#123; input: &quot;pred&quot; input: &quot;label&quot; output: &quot;softmax&quot; output: &quot;loss&quot; name: &quot;&quot; type: &quot;SoftmaxWithLoss&quot;&#125;op &#123; input: &quot;loss&quot; output: &quot;loss_autogen_grad&quot; name: &quot;&quot; type: &quot;ConstantFill&quot; arg &#123; name: &quot;value&quot; f: 1.0 &#125;&#125;op &#123; input: &quot;pred&quot; input: &quot;label&quot; input: &quot;softmax&quot; input: &quot;loss_autogen_grad&quot; output: &quot;pred_grad&quot; name: &quot;&quot; type: &quot;SoftmaxWithLossGradient&quot; is_gradient_op: true&#125;op &#123; input: &quot;pred&quot; input: &quot;pred_grad&quot; output: &quot;fc1_grad&quot; name: &quot;&quot; type: &quot;SigmoidGradient&quot; is_gradient_op: true&#125;op &#123; input: &quot;data&quot; input: &quot;fc_w&quot; input: &quot;fc1_grad&quot; output: &quot;fc_w_grad&quot; output: &quot;fc_b_grad&quot; output: &quot;data_grad&quot; name: &quot;&quot; type: &quot;FCGradient&quot; is_gradient_op: true&#125;external_input: &quot;data&quot;external_input: &quot;fc_w&quot;external_input: &quot;fc_b&quot;external_input: &quot;label&quot; 可以看到, 网络中增加了4个新的 operators, 其输入为 backward 的计算结果, 输入为相应参数的梯度.]]></content>
      <categories>
        <category>Caffe2</category>
      </categories>
      <tags>
        <tag>Caffe2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客相关问题及解决方案汇总]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-hexo%E5%8D%9A%E5%AE%A2%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[需要安装的插件1234npm install hexo-generator-searchdb --save # 站内搜索npm install hexo-generator-index-pin-top --save # 置顶npm install hexo-blog-encrypt --save # 文章加密npm install hexo-renderer-kramed --save # 数学公式 图片自适应, 点击放大fancybox 数学公式渲染异常https://www.once4623.site/2017/10/03/2017-10-04--Use-MathJax-In-Hexo-Next/ hexo 实现置顶功能https://blog.csdn.net/qwerty200696/article/details/79010629 hexo 站内搜索https://www.jianshu.com/p/519b45730824 https://blog.csdn.net/ksws0292756/article/details/82714984 一直处于加载状态首先看是不是有哪些文件的title命名方式有问题, 已知的问题有: 不能有包含半角的冒号(全角可以), 这个可以用hexo g得知, 如果有问题, 则hexo g会报错 数学公式中用星号代表乘号. 方法一: hexo clean + hexo g 重新生成search.xml文件 方法二: 更新searchdb插件: npm install hexo-generator-searchdb --save 方法三: 文章太多时, 尝试将_comfig.yml中Local Search下的limits设置的更高一些 方法四: 查看 search.xml 文件: 根据报错信息确定哪一篇文章有问题. 有时候, 报错的行数并不是真的问题所在, 需要不断用排除法才能确定具体的行数, 并且, 有可能该行本身并无错误, 而只有重新敲一遍之后才能正常搜索. https://www.itfanr.cc/2017/11/24/resolve-hexo-blog-search-exception/ 如果public/search.xml文件报错(用谷歌浏览器打开), 则根据错误进行排查., 通过 “更多工具-&gt;开发者工具”, 确定是哪一篇文章出错, 然后将其修正, 具体步骤如下 用chrome浏览器打开atom.xml 一般会提示和上述相同错误，并提示Bytes: 0x10 0xEF 0xBC 0x8C 用 atom 或者任意一款拥有正则匹配搜索功能的编辑器打开atom.xml 用正则匹配模式搜索\x10字符,留意搜索的结果, 并在source/_posts路径中找到*.md文章源文件, 用正则匹配替换掉搜索到的所有\x10字符为空. 可能存在多个文件有特殊字符。(修改完成后记得保存) 刷新chrome中的atom.xml此时应该已经不会报错了.(无需重新hexo g, 只需刷新页面即可) 显示更新时间https://www.itfanr.cc/2017/12/06/hexo-blog-optimization/ 默认的更新时间是最后的修改时间, 也可以手动添加 updated 参数强制设置更新时间. 修改完成后, 需要重新启动 hexo server 才能正确显示. 如果显示的是英文: post.updated, 则需要在 languages/zh-CNs 文件中的 post 选项下添加 updated: 更新于 文章加密【链接】MikeCoder/hexo-blog-encrypthttps://github.com/MikeCoder/hexo-blog-encrypt/blob/master/ReadMe.zh.md]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[thread和threading模块-多线程处理]]></title>
    <url>%2Fz_post%2FPython-thread%E5%92%8Cthreading%2F</url>
    <content type="text"><![CDATA[Python的标准库提供了两个多线程模块: thread 和 threading. 其中, thread 是低级模块, threading 是高级模块, 对thread进行了封装, 大多数情况下, 我们只需要使用threading这个高级模块. python中使用线程有两种方式: 函数或者用类来包装线程对象]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shutil模块-shell命令行指令]]></title>
    <url>%2Fz_post%2FPython-shutil%2F</url>
    <content type="text"><![CDATA[1234567shutil.copyfile("old","new") # 复制文件，都只能是文件shutil.copytree("old","new") # 复制文件夹，都只能是目录，且new必须不存在shutil.copy("old","new") # 复制文件/文件夹，复制 old 为 new（new是文件，若不存在，即新建），复制 old 为至 new 文件夹（文件夹已存在）shutil.move("old","new") # 移动文件/文件夹至 new 文件夹中]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tqdm模块-进度条]]></title>
    <url>%2Fz_post%2FPython-tqdm%2F</url>
    <content type="text"><![CDATA[12345from tqdm import tqdmimport timefor i in tqdm(range(1000)): time.sleep(0.01) 效果如下:137%|█████████ | 370/1000 [00:03&lt;00:06, 98.89it/s] 只要是可迭代的对象都可以使用 tqdm, 例如 PyTorch 的 DataLoader 对象: 12for inputs, labels in tqdm(dataloader): # ... 输出形式和上面相同 tqdm 不能单行显示的问题原因: 有些 IDE 不支持回车(CR), 导致每次新的进度条不能覆盖旧的进度条, 出现原因的问题也可能是手动终止进程导致 tqdm 没有完全退出导致的, 应使用 t.close() 使其正确关闭: 12345678try: with tqdm(...) as t: for i in t: ...except KeyboardInterrupt: t.close() raiset.close() progressbar12345678910111213import timefrom progressbar import *widgets = ['bar name:', Percentage(), ' ', Bar('#'), ' ', Timer(), ' ', EAT(), ' ', FileTransferSpeed()]pbar = ProgressBar(widgets=widgets)try: for i in pbar(range(1000)): time.sleep(0.01)except KeyboardInterrupt: pbar.finish() raisepbar.finish()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch 手册]]></title>
    <url>%2Fz_post%2FPyTorch-%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[PyTorch主要提供以下两大特色: 支持强力GPU加速的Tensor计算能力 基于tape的具有自动微分求导能力的深度神经网络框架 PyTorch 主要包含以下组成要素: 组成要素 描述说明 torch 一个类似于numpy的tensor哭, 提供强力的GPU支持 torch.autograd 一个基于tape的具有自动微分求导能力的库, 可以支持几乎所有的tesnor operatioin torch.nn 一个神经网络库, 与autograd深度整合, 可以提供最大限度的灵活性 torch.multiprocessing Python的多线程处理, 可以提供torch Tensors之间的内存共享, 对于加载数据和Hogwild training来说十分有用 torch.utils 一些功能类和函数, 如DataLoader, Trainer等等 torch.legacy(.nn/.optim) 为了兼容性而存在的一些代码和实现 Pytorch通常可以作为以下用途使用: 为了使用GPUs性能的numpy替代品 可以提供强大灵活力和速度优势的深度学习平台. torchbackends.cudnn1torch.backends.cudnn.benchmark = True 上述设置可以让内置的cudnn的auto-tuner自动寻找最合适当前配置的搞笑算法, 来达到优化运行效率的目标, 在使用时, 应该遵循以下两个准则: 如果网络的输入数据维度或类型上变化不大, 则该设置可以增加运行效率 如果网络的输入数据在每次的iteration中都变化的话, 会导致cudnn每次都寻找一遍最优配置, 这样反而 会降低 运行效率. torch.cat()1torch.cat(seq, dim=0, out=None) # 返回连接后的tensor 将给定的 tensor 序列 seq 按照维度连接起来. 默认维度为0, 说明会将其在第 0 个维度上进行拼接.(最后的结果是第 0 维度增大, 例如三个2行3列的 tensor 按照第0维度拼接, 最后得到的 tensor 维度为6行3列) clamp()/clamp_()1torch.clamp(input, min, max, out=None) -&gt; Tensor 将input里面元素全部划分到[min,max]区间内, 小于min的置为min, 大于max的置为max. 如果不指定min或者max,则认为无下界或上界 其他调用形式:1torch.Tensor(min, max) # 调用tensor为input, 返回值为out device()1device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") gather()1torch.gather(input, dim, index, out=None) -&gt; Tensor 沿着dim指定的轴按着index指定的值重新组合成一个新的tensor. 123out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 即假设input是一个 n 维的tensor, 其 size 为 $(x_0, x_1, …, x_{i-1}, x_i, x_{i+1},…, x_{n-1})$, 若dim=i, 则 index 必须也是一个 n 维的tensor, 其 size 为 $(x_0, x_1, …, x_{i-1}, y, x_{i+1},…, x_{n-1})$, 其中 $y\geq 1$, 而返回的 tensor out 的 size 和 index 的 size 相同.一句来说 gather 的作用就是, 在指定的维度上筛选给给定下标index指示的值, 其他值舍弃. 一个例子说明:scores是一个计算出来的分数，类型为[torch.FloatTensor of size 5x1000]而y_var是正确分数的索引，类型为[torch.LongTensor of size 5]容易知道，这里有1000个类别，有5个输入图像，每个图像得出的分数中只有一个是正确的，正确的索引就在y_var中，这里要做的是将正确分数根据索引标号提取出来。12scores = model(X_var) # 分数scores = scores.gather(1, y_var.view(-1, 1)).squeeze() #进行提取 提取后的scores格式也为[torch.FloatTensor of size 5]这里讲一下变化过程：1、首先要知道之前的scores的size为[5,1000]，而y_var的size为[5]，scores为2维，y_var为1维不匹配，所以先用view将其展开为[5,1]的size，这样维数n就与scroes匹配了。2、接下来进行gather，gather函数中第一个参数为1，意思是在第二维进行汇聚，也就是说通过y_var中的五个值来在scroes中第二维的5个1000中进行一一挑选，挑选出来后的size也为[5,1]，然后再通过squeeze将那个一维去掉，最后结果为[5]. Tensor形式:1torch.Tensor.gather(dim, index) -&gt; Tensor torch.ge()torch.gt()1torch.gt(input, other, out=None) # -&gt; Tensor 根据 input 和 other 的值返回一个二值 tensor, 如果满足大于条件则为1, 不满足则为0.other 可以是能够转换成 input size 的tensor, 也可以是一个 float 标量. torch.index_select()1torch.index_select(input, dim, index, out=None) # -&gt; Tensor 返回在 dim 维度上的 index 指明的下标组成的 tensor.返回的 tensor 的维度的数量和 input 是相同的, 但是第 dim 维度的 size 会和 index size大小相同. 其他维度的 size 保持不变. torch.le()1torch.le(input, other, out=None) # -&gt;Tensor 按元素计算 $input \leq other$. max()123torch.max(input) # 返回一个Tensor, 代表所有元素中的最大值torch.max(input,dim,keepdim=False,out=None) # 返回一个元组:(Tensor, LongTensor) 第二种形式会返回一个元组, 元组内元素类型为: (Tensor, LongTensor), 其中, 前者代表对应 dim 上 reduce 后的最大值, 后者代表最大值在维度 dim 中对应的下标.如果keepdim=True, 则输出的 tensor 的 size 会和输入的相同, 只不过对应 dim 维度上的size为1. 否则, 对应 dim 维度会被 squeeze/reduce, 使得输出的维度比输入的维度少1.12345678&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[-1.2360, -0.2942, -0.1222, 0.8475], [ 1.1949, -1.1127, -2.2379, -0.6702], [ 1.5717, -0.9207, 0.1297, -1.8768], [-0.6172, 1.0036, -0.6060, -0.2432]])&gt;&gt;&gt; torch.max(a, 1)(tensor([ 0.8475, 1.1949, 1.5717, 1.0036]), tensor([ 3, 0, 0, 1])) mm()注意, 没有torch.mm_版本1torch.mm(mat1, mat2, out=None) # 返回值为Tensor, 也可以使用out记录返回值 两矩阵相乘, 矩阵的size需要满足乘法规则 其他调用形式:1torch.Tensor(mat2) # 调用者为mat1 norm()返回输入tensor的p-norm标量1torch.norm(input, p=2) # 返回一个标量tensor numel()1torch.numel(input) #返回一个int值 返回 inpput tensor 中的元素的总个数12a = torch.randn(1,2,3,4,5)print(torch.numel(a)) # 120 ones()randn()标准正太分布随机基础, 传入参数为维度信息 torch.sort()1torch.sort(input, dim=None, descending=False, out=None) # 返回 (Tensor, LongTensor) 如果没有给定维度 dim, 则会默认选择最后一个维度. sum()1234torch.sum(input, dtype=None) # 返回求和后的Tensor(只有一个元素)torch.sum(input, dim, keepdim=False, dtype=None) # 返回在dim上reduce的sum和, 如果dim包含多个维度, 则都进行reduce求和.# reduce这个词很形象, 因为返回的Tensor的维度刚好没有了dim指示的那些维度 其他形式:1torch.Tensor.sum() torch.t()1torch.t(input) # 返回转置后的Tensor 其他形式:1torch.Tensor.t() unsqueeze()在指定维度上插入一个 singleton 维度(一般用于将单一数据处理用 batch 的形式)1torch.unsqueeze(input, dim, out=None) # -&gt; Tensor 返回的tensor与input tensor 共享数据 dim 的取值范围在 [-input.dim()-1, input.dim()+1] 之间, 如果为负值, 则相当于 dim = dim + input.dim() + 1. zeros()torch.cudatorch.cuda.empty_cache()释放所有未使用的 GPU 内存, 使用这些内存可以被其他 GPU 应用使用, 并且可以被 nvidia-smi 查到. empty_cache() 并不会强制提升供 PyTorch 使用的显卡内存的大小, 查看Memory management torch.Tensortorch.Tensor 是默认类型 torch.FloatTensor 的别名, 使用 torch.Tenosr 的构造函数创建 tensor 变量时, 传入的是维度信息(注意与 torch.tensor() 的区别):12t = torch.Tensor(2,3,4) # 里面的数值未初始化, 是随机的print(t.size()) # torch.Size([2,3,4]) torch.LongTesnor 使用方法相似, 只不过数据类型是长整型. troch.tensor()创建tensor1torch.tensor(data, dtype=None, device=None, requires_grad=False) 可以利用torch.tensor从python的list数据或者其他序列数据中创建tensor对象12torch.tensor([[1,-1],[1,-1]])torch.tensor(np.array([[1,2,3],[4,5,6]])) 注意, torch.tensor()函数总是会对数据进行复制操作, 因此, 如果你仅仅是想将数据的requires_grad标志改变, 那么就应该使用required_grad_()或者detach()函数来避免复制. 同时, 对numpy数组使用torch.as_tensor()将其转换成tensor而无需复制 torch.Tensor.cpu()12torch.Tensor.cpu()z = x.cpu() 将tensor移动到cpu上, 注意返回值z是cpu上的数据, tensorx本身的device属性不变 torch.Tensor.cuda()12torch.Tensor.cuda()z = x.cuda() torch.Tensor.dim()1torch.Tensor.dim() -&gt; int 返回 tensor 的维度的个数. torch.Tensor.max()1torch.Tensor.max(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor) 详情见 torch.max() torch.Tensor.numel()1torch.Tensor.numel() 详见 torch.numel() torch.Tensor.to()1torch.Tensor.to(*args, *kwargs) 返回一个转移后的tensor, 而自身维持不变1234t = torch.randn(2,3)t.to(torch.float64)t.to(device)t.to("cuda:0") 将tensor移动到gpu上, 注意返回值z是gpu上的数据, tensorx本身的device属性不变 torch.Tensor.numpy()tensor与numpy数组的转换 123torch.Tensor.numpy() # 返回tensor对应的numpy数组torch.from_numpy(ndarray) # 将numpy数组ndarray转换成对应的tensor并返回. torch.Tensor 实际上是 torch.FloatFensor 的别名 torch.Tensor.permute()重新排列tensor的维度1torch.Tensor.permute(*dims) # 返回一个重新排列维度后的 tensor torch.Tensor.unsqueeze()详细可见torch.unsqueeze torch.Tensor.expand()1torch.Tensor.expand(*sizes) # 返回 tensor 将 tensor 中的 singleton 维度扩展到一个更大的 size.参数 -1 意味着不改变原始的维度新增的维度的元素被被添加到前头, size不能设置为-1.expand 并没有申请新的内存, 而仅仅是在当前已经存在的 tensor 上面创建了新的视图(view), 使得 singleton 维度被扩展成了一个更大的尺寸.Any dimension of size 1 can be expanded to an arbitrary value without new memory.1234x = torch.tensor([1],[2],[3])print(x.size()) # torch.Size([3,1])print(x.expand(3,4)) # torch.Size([3,4]) # 将维度为1的扩展到任意尺寸print(x.expand(-1,4)) # torch.Size([3,4]) # -1 代表不改变维度 注意, 只能对 singleton 的维度进行扩展, 如果强行对其他维度扩展, 则会报错. torch.Tensor.expand_as()1torch.Tensor.expand_as(other) # 返回 tensor 将当前 tensor 扩展到和 other 一样的size.self.expand_as(other) 与 self.expand(other.size()) 等价. torch.Tensor.index_fill_()1torch.Tensor.index_fill_(dim, index, val) # 返回tensor 在给定的维度 dim 上, 用 val 将该维度上的 index 坐标的值填充.1234567x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)index = torch.tensor([0, 2])x.index_fill_(1, index, -1)print(x)#tensor([[-1., 2., -1.],# [-1., 5., -1.],# [-1., 8., -1.]]) torch.Tensor.contiguous()返回一个连续的tensor, 数据内容不变1torch.Tensor.contiguous() # 如果tensor本身就是连续的, 那么就会返回tensor本身 这里的 contiguous 指的是内存上的连续, 由于在 PyTorch 中, view 只能用在 contiguous 的 tensor 上面, 而如果在 view 之前使用了 transpose, permute等操作后, 就需要使用 contiguous 来返回一个 contiguous tensor. 在 PyTorch 0.4 版本以后, 增加了 torch.reshape(), 这与 numpy.reshape() 的功能类似, 它大致相当于 tensor.contiguous().view() ? torch.Tensor.item()当Tensor中只包含一个元素时, 可以利用该函数返回这个元素的标量 torch.Tensor.tolist()可以将Tensor转换成列表 torch.Tensor.zero_()1torch.Tensor.zero_() 将当前的 tensor 变量全部置为0(原地) torch.autogradset_grad_enabled()1class torch.autograd.set_grad_enabled(mode) 用来控制梯度计算的开关(依据bool类型参数mode决定), 可以当做上下文管理器使用, 也可以当做函数使用1234567891011# 当做上下文管理器with torch.set_grad_enabled(is_train): # 注意, 这里省略了autograd loss.backward() optimizer.step()# 当做函数使用w1 = torch.Tensor([1], requires=True)torch.set_grad_enabled(True)print(w1.requires_grad) # Truetorch.set_grad_enabled(False)print(w1.requires_grad) # False no_grad()1class torch.autograd.no_grad 用于禁用梯度计算的上下文管理器.在测试阶段, 当你确信你不会调用Tensor.backward()时,禁用梯度计算十分有用. 这会降低计算使用内存消耗.123456x = torch.tensor([1.0], requires_grad=True)with torch.no_grad(): # 省略了autograd print(x.requires_grad) # True, 虽然为True, 但在该上下文中, 会无视掉requires_grad参数, 一律做False处理 y = x*2 print(y.requires_grad) # False, 在当前上下文产生的tensor的requires_grad属性为Falseprint(x.requires_grad) # True torch.autograd.Function1class torch.autograd.Function 为可微分的 ops 记录 operation history, 同时定义计算公式. 每一个作用在 tensor 上的 operatin 都会创建一个新的 function 对象, 它会执行计算过程并记录相关信息. 这些信息可以从一个由 functions 组成的有向图中获得. 当 backward() 方法被调用时, 就会利用这些信息在 function 上进行反向传播, 并将梯度传给下一个 Funtion.通常情况下, 当用于需要自定义可自动求导的 ops 时, 可以实现一个 Function 的子类.123456789101112# Exampleclass Exp(Function): @staticmethod def forward(ctx, i): result = i.exp() ctx.save_for_backward(result) @staticmethod def backward(ctx, grad_output): result, = ctx.saved_tensors return grad_output*result static forward(ctx, *args, kwargs):**定义前向计算的逻辑. static backward(ctx, *grad_outputs):定义反向传导的逻辑, 如果确定不会使用到反向传播, 则可以不实现该函数. torch.nnModule1class torch.nn.Module 所有神经网络Module的基类, 自定义的模型也应该是它的子类.Modules可以包含其他Module(如Linear, Conv2d等等). parameters()12for param in model.parameters(): print(param.data, param.size()) state_dict:1torch.nn.Module.state_dict(destination=None,prefix="",keep_vars=False) 以字典形式返回整个module的状态 train1torch.nn.Module.train(mode=True) 将module的模式设置为train, 这只对部分module有效, 如Dropout, BatchNorm等, 详细请查看官网.返回值: torch.nn.Module training1torch.nn.Module.training # 属性, 返回一个bool值, 指示当前的模式是否为train eval1torch.nn.Module.eval() # 注意, 和train不同, eval为无参函数 将module的mode设置为evaluation, 同样, 只对部分module起效. Linear1torch.nn.Linear(in_features, out_features, bias=True) 全连接层的实现. 输入的shape为 $(N, …, in_features)$, 输出的shape为 $(N,…, out_features)$, 可以看出, 除了最后一维不同外, 其他维度都相同. (通常在使用Linear之前, 会将输入变成二维的矩阵, 其中第一维为batch size, 第二维为特征向量). in_features 和 out_features 可以当做属性用.来获取. Conv2d1class torch.nn.Conv2的(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) in_channels(int): out_channels(int): kernel_size(intortuple): stride(intortuple, optional): MaxPool2dSoftmax()1class torch.nn.Softmax(dim=None) dim指明了需要进行 softmax 的维度, 在这个维度上的值, 加起来和为1. ReLU1torch.nn.ReLU(inplace=False) 输入输出的shape是相同的, 执行relu函数 torch.nn.Sequential1class torch.nn.Sequential(*args) torch.nn.MSELoss1class torch.nn.MSELoss(size_average=None, reduce=None, reduction="elementwise_mean") size_average(bool, optional): 弃用(见reduction参数). 默认情况下, loss会计算在每个样本上的平均误差. 如果将size_average置为False, 则计算平方误差总和. 当reduce参数为False时, 忽视该参数 reduce(bool, optional): 弃用(见reduction参数). reduce参数顾名思义, 就是是否让MSELoss函数返回值的维度减少, 默认为True, 即会将任意维度的输入计算loss后, 返回一个标量(平均or总和取决于size_average), 如果为False, 则说明返回值维度不应该发生变化, 故而返回值就是对每个元素单独进行平方损失计算. 12345678910y = torch.tensor([1,2,3,4], dtype=torch.float)pred_y = torch.tensor([1,1,1,1], dtype=torch.float)loss_fn1 = torch.nn.MSELoss()loss1 = loss_fn1(y, pred_y)loss_fn2 = torch.nn.MSELoss(size_average=False)loss2 = loss_fn2(y, pred_y)loss_fn3 = torch.nn.MSELoss(reduce=False)loss3 = loss_fn3(y, pred_y)print(loss1,loss2,loss3)# tensor(3.5000) tensor(14.) tensor([0., 1., 4., 9.]) reduction(string, optional): 用字符串来替代上面两个参数的作用: “elementwise_mean”(默认) | “sum” | “none” (不进行reduce). torch.nn.functionalconv1d()conv2d()relu()1torch.nn.functional.relu(input, inplace=True) # 返回 一个 Tenosr relu_()1torch.nn.functional.relu_(input) # relu() 的原地版本 torch.optimlr_schedulerStepLR1class torch.optim.lr_schedulr.StepLR(optimizer,step_size,gamma=0.1,last_epoch=-1) 每经过step_size次epoch之后, lr就会衰减gamma倍(new_lr=lr×gamma), 初始的lr来自于optimizer中的lr参数.12345# Observe that all parameters are being optimizedoptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)# Decay LR by a factor of 0.1 every 7 epochsexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) ExponentialLR1class torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma,last_epoch=-1) CosineAnnealingLR12345```## Adam```pyclass torch.optim.Adam(params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False) conv2dtorch.utils.dataDataLoader1class torch.utils.data.DataLoader(dataset,batch_size=1,shuffle=False,sampler=None,batch_sampler=None,num_workers=0,collate_fn=&lt;function default_collate&gt;,pin_memory=False,drop_last=False,timeout=0,worker_init_fn=None) 数据加载器, 将数据集和采样器结合起来, 并且提供单/多线程的迭代器. dataset(utils.data.Dataset): batch_size(int,optional): batch中的样本个数 shuffle(bool,optional) num_worker(int,optional): 加载数据的线程个数, 0意味着只有一个主线程. 方法: __iter__(self): 可以当做迭代器使用, 如inputs,class_ids=next(iter(dataloaders)), 其中, input的shape为 $(N, C, H, W)$, class_ids的shape为 $(N)$. __len__(self): 返回数据集的类别数目 torchvisiontorchvision.utilsmake_grid1torchvision.utils.make_grid(tensor,nrow=8,padding=2,normalize=False,range=None,scale_each=False,pad_value=0) 制作一个关于image的grid, 返回值依然是一个tensor, 只不过尺度变成了3D, 相当于把多个图片拼接在一起了, 直接通过plt.imshow(grid)即可输出网格化以后的图片. tensor(Tensor/list): 4D的 mini-batch Tensor, Shape为 $(N×C×H×W)$, 或者是同维度的list. torchvision.transformstorchvision.transforms.Compose1234567class torchvision.transforms.Compose(transforms)# 使用trans.Compose([ transforms.CenterCrop(10), transforms.ToTensor(),]) 将多个transforms操作组合起来, 注意参数是列表形式 Transforms on PIL Image123# cv2 image to PIL Image# skimage to PIL Image 注意, 以下操作作用在PIL Image上的 CenterCrop1class torchvision.transform.CenterCrop(size) size参数表示输出的图谱的大小, 如果只传入了一个数字, 则该数字既表示高度, 又表示宽度. Resize1class torchvision.transforms.Resize(size, interpolation=2) size: 期望的输出size. interpolation: 插值方法, 默认为双线性插值 ToTensor1class torchvision.transforms.ToTensor 将一个PIL Image或者numpy.ndarray (H×W×C,[0, 255])转换成torch.FloatTensor (C×H×W, [0.0, 1.0]). RandomHorizontalFlip1transforms.RandomHorizontalFlip(p=0.5) 在给定概率下对PIL Image随机执行水平翻转操作 RandomResizedCrop1torch.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333), interpolation=2) 对PIL Image随机执行剪裁操作(按照scale和ratio的区间剪裁), 然后将剪裁后的图片放缩都期望的尺寸(默认插值为双线性插值) size: 期望得到的尺寸 scale: 剪裁的面积比例(相对于原始图) ratio: 剪裁的宽高比 interpolation: 默认为:PIL.Image.BILINEAR Transforms on torch.*Tensor注意, 以下操作是作用在tensor上的 Normalize1class torchvision.transforms.Normalize(mean, std) 将图片tensor按照均值mean和标准差std进行归一化, 对于n个channels, 有 mean=(M1, …, Mn), std=(S1,…,Sn).注意, 这个归一化操作是原地进行的 torchvision.datasetsImageFolder1class torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=&lt;function default_loader&gt;) 一个一般化的数据加载器, 主要针对如下数据排列格式:1234567root/dog/x.pngroot/dog/y.pngroot/dog/z.png...root/cat/123.pngroot/cat/nsdf3.pngroot/cat/asd932_.png root: 根目录路径 transform(callable,optional): 对图片要做的变换操作 target_transform(callable,optional): 对target要做的变换操作 loader: 用于加载给定路径图片的函数 属性: classes(list): 返回类别的名字列表 class_names class_to_idx(dict): 以字典的形式返回(class_name, class_index) imgs(list): 返回元组列表: (image path, class_index) 方法: getitem(index): 根据index返回(sample,target)元组. 可以使用 len(imagefolder) 返回类别数量 sort()1sort(dim=None, descending=False) # 默认为升序, 返回(Tensor, LongTensor) 详见 torch.sort() torch.distributedtorch.distributed.reduce()inspect 模块1234inspect.signature() # 查看函数签名, python3.6以上inspect.getargspec() # 查看函数签名, python3.6以上inspect.getsource() # 获取模型的codeinspect.getabsfile() # 获取模块的路径 un normalizehttps://github.com/pytorch/vision/issues/528 123456mean = torch.tensor([1, 2, 3], dtype=torch.float32)std = torch.tensor([2, 2, 2], dtype=torch.float32)normalize = T.Normalize(mean.tolist(), std.tolist())unnormalize = T.Normalize((-mean / std).tolist(), (1.0 / std).tolist())]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requests模块-HTTP客户端库]]></title>
    <url>%2Fz_post%2FPython-requests%2F</url>
    <content type="text"><![CDATA[requests 是一个很实用的Python HTTP客户端库, 在编写爬虫和测试服务器响应数据时会经常用到, 可以说, requests 完全满足如今网络的需求. get请求1r = requests.get("http://httpbin.org/get")]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入理解TensorFlow架构设计与实现原理》]]></title>
    <url>%2Fz_post%2FTensorFlow-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3TF%2F</url>
    <content type="text"><![CDATA[第一章 TensorFlow系统概述人工智能和深度学习的热潮将Tensoflow推向了很高的地位，本章主要是作为引子，来对TF进行一个概述 1.1 简介1.1.1 产生背景近年来深度学习在图像、视觉和语音领域的突破，促使了各种深度学习框架的诞生 1.1.2 独特价值TF能在众多开源框架中杀出重围，除了Google的背书以外，还少不了以下独特价值： 运算性能强劲：TF1.0利用线性代数编译器XLA全方位的提升了计算性能，XLA帮助TF在CPU、GPU、TPU、嵌入式设备等平台上更快速的运行机器学习模型的训练与推理任务。同时，还提供了大量针对不同软硬件环境的优化配置参数 框架设计通用：TF既提供高层封装API（如Slim、Keras、TF Layers等），又提供底层原生API 支持生产环境部署 语言借口丰富：支持python、C、C++、java、Go等 端云协同计算：支持同时在云侧和端侧运行（移动设备等终端） 1.1.3 版本变迁迭代更新非常快，慢慢走向成熟 1.1.4 与其他主流深度学习框架对比起初，TF的内存消耗和计算速度一直是短板。但是，随着XLA和RDMA等特性的发布，TF的性能在绝大多数情况下都不输于其他深度学习框架。 TF的灵活性导致了学习成本也相应较高，API过于丰富。（不过，可以使用Keras、TF Layers来解决此问题） 1.2 设计目标TF的设计目标并非局限一套深度学习库，Google希望其成为一套面向多种应用场景和编程范式、支持异构计算平台、具备优异性能与可伸缩性的通用人工智能引擎。 1.2.1 灵活通用的深度学习库TF的灵活性主要体现在以下几个方面： 算子定义：粒度更细，数量更多 编程范式：支持声明式编程，将模型的定义和执行解耦 runtime框架 多语言支持 1.2.2 端云结合的人工智能引擎TF对云计算场景的支持是其竞争力的基础，主要体现在以下方面： 提供多种标准化的安装包、构建脚本和容器化封装，支持在不同Linux发行版以及Windows Server等服务器上部署 支持对接多种常见的公有云和私有云服务 兼容若干种常见的高性能计算与通信硬件 灵活的runtime框架设计，既提供标准且易用的PS-worker分布式模式，也允许用户自由开发针对特定环境需求的分布式框架 TF在端侧方面也毫不逊色，主要体现在以下几个方面 推理（预测）态代码能够运行于多种主流的终端平台 通过XLA AOT（ahead of time）编译技术及其他软硬件解耦设计，简化对接 提供量化参数和低精度代数等算法层机制 提供模型与框架一体化的精简版runtime平台 1.2.3 高性能的基础平台软件TF的高性能设计体现在它对高端和专用硬件的深入支持。 1.3 基本架构1.3.1 工作形态TF采用了库模式，其工作形态是有用户编写主程序代码，调用Python或其他语言函数库提供的借口以实现计算逻辑。 1.3.2 组件结构结构示意图可查看书上p13 构成TF的主体使其运行时核心库。 对于普通的python应用层开发者而言，这个核心库就是值通过pip命令等方式安装TF之后，部署到site-packages或类似目录中的动态链接库文件。 生成这个库的C++源代码大致分为3个层次：分布式运行时、公共运行时和算子核函数。其中，公共运行时实现了数据流图计算的基本逻辑，分布式运行时在此基础上实现了数据流图的跨进程协同计算逻辑，算子核函数则包含图上具体操作节点的算法实现代码。 第二章 TensorFlow环境准备2.1 安装可查看官方文档 有一点需要注意：为了保证软件对操作系统和硬件平台的通用性，Google官方发布的TensorFlow whl包没有使用过多的编译优化选项，如 XLA、AVX、SSE等，如果想要打开这些编译优化选项来提升TF的计算性能，那么必须使用源代码编译安装的方式。 2.2 依赖项2.2.1 Bazel软件构建工具Bazel是Google开源的一套软件构建工具，功能定位与CMake、GNU Autotools和Apache Ant等类型，但具有一些独特的优势，如下所示： 多语言支持：C++、Java、Python等 高级构建语言 多平台支持 可重现性 可伸缩性 Bazel使用工作空间、包和目标三层抽象组织待构建的对象 工作空间（workspce）： 包（package）： 目标（target）： 2.2.2 Protocal Buffers 数据结构序列化工具2.2.3 Eigen线性代数计算库2.2.4 CUDA统一计算设备架构CUDA是NVIDIA公司退出的一种用于并行计算的软硬件架构，发布于2007年。该架构以通用计算图形处理器（GPGPU）作为主要的硬件平台，提供一组用于编写和执行通用计算任务的开发库与运行时环境。 CUDA作为软件依赖项提及时，往往指的是CUDA架构中的软件组件，即NVIDIA驱动程序和CUDA Toolkit。除了基本的CUDA开发库和编译器外，CUDA工具包还包括cuBLAS、cuFFT、cuSOLVER、cuDNN等高级算法库，以及IDE、调试器、可视化分析器等开发工具，其中部分组件需要独立安装。 在CUDA架构中，不同层次的软件组件均为开发者提供编程接口，以适应不同类型软件的开发需求： NVIDIA驱动层的开发接口（即cu开头的函数，也称为CUDA Driver API）较为底层，暴露了GPU的若干内部实现抽象。这种接口能够对GPU的运行时行为进行细粒度控制，有助于提升程序的运行时效率，但缺点在于开发过程烦琐。一般的GPU应用程序不会直接使用这一层接口，然而TF内部的GPU计算引擎——StreamExecutor为了追求性能，选择使用这一层接口实现GPU任务调度和内存管理等功能 CUDA开发库的API（即以cuda开头的函数，也称为CUDA Runtime API）是CUDA架构中使用最为广泛的接口，功能涵盖GPU设备管理，内存管理，时间管理以及图形处理相关的逻辑。 cuBLAS、cuDNN等高级算法库：提供了面向通用计算（如线性代数）或领域专用计算（如神经网络）需求的高层次接口。在这个层次，GPU设备的很多技术细节已被屏蔽，开发者可以专注于算法逻辑的设计与实现。TF面向NVIDIA GPU的计算类操作大多基于cuBLAS和cuDNN接口实现。 对于TF而言，CUDA工具包是不受Bazel管理的外部依赖项，因此，用户如果想要使用NVIDIA GPU加速深度学习时，需要事先安装带有NVIDIA驱动程序的CUDA工具包即cuDNN库 2.3 源代码结构2.3.1 根目录TF源码的组织复合Bazel构建工具要求的规范。其根目录是一个Bazel项目的工作空间。 2.3.2 tensorflow目录TF项目的源码主体位于tensorflow目录，该目录下的源文件几乎实现了TF的全部功能，同时体现了TF的整体模块布局。 2.3.3 tensorflow/core 目录TF核心运行时库的源代码位于tensorflow/core目录 2.3.4 tensorflow/python 目录TF Python API的源码位于tensorflow/python目录 2.3.5 安装目录pip命令会将TF运行时所需的Python文件、动态链接库以及必要的依赖项复制到当前Python环境的site-packages或dist-packages目录中，其中TF软件本身的的运行时代码会被部署到tensorflow子目录，这一目录具有与源码tensorflow目录相似的组织结构。二者的不同点在于以下几点： 安装目录中只包含每个模块的Python语言接口文件，不再包含C++源码。所有使用到的C++源码已被编译到了python子目录下的动态链接库文件中（在Linux下为_pywrap_tensorflow_internal.so）。如果某个模块未提供Python API，那么相应的子目录不会在安装目录中出现 安装目录中的python/ops子目录比同名的源代码子目录增加了一系列名称有gen_开头的Python接口文件。这些文件是TensorFLow编译脚本自动创建的，旨在为C++核心库的一部分数据流图操作提供Python编程接口 安装目录比源代码目录多出一个include子目录。这个目录包含了TensorFLow本身以及Protocol Buffers、Eigen等依赖库的C++头文件，允许用户通过编程方式使用核心库的功能。 第三章 TensorFlow基础概念3.1 编程范式：数据流图TF采用了更适合描述深度神经网络模型的声明式编程范式，并以数据流图作为核心抽象。 优势（相比更广泛的命令式编程范式）： 代码可读性强 支持引用透明 提供预编译优化能力 3.1.1 声明式编程与命令式编程二者的最大区别在于：前者强调“做什么”， 后者强调“怎么做”。 声明式编程：结构化、抽象化，用户不必纠结每个步骤的具体实现，而是通过下定义的方式描述期望达到的状态。声明式编程比较接近人的思考模式；程序中的变量代表数学符号或抽象函数，而不是一块内存地址，程序的最终输出仅依赖于用户的输入数据，计算过程不受内部和外部状态影响。 命令式编程：过程化、具体化、用户告诉机器怎么做，机器按照用户的指示一步步执行命令，并转换到最终的停止状态。命令式编程起源于对汇编语言和机器指令的进一步抽象，本身带有明显的硬件结构特征。它通过修改存储器的值、产生副作用的方式实现计算。这里的副作用是值对外部环境产生的附加影响。 编程是一种输入到输出的转换机制，这两种范式提供了截然不同的解决方案： 声明式编程：程序是一个数学模型，输入是自变量，输出是因变量，用户设计和组合一系列函数，通过表达式变换实现计算。 命令式编程：程序是一个有穷自动机，输入是起始状态，输出是结束状态，用户设计一系列指令，通过指令的执行完成状态转换。 适用范围： 声明式编程：DL、AI 命令式编程：交互式UI、OS 3.1.2 声明式编程在DL应用上的优势 代码可读性强 &emsp;&emsp;以目标为导向，更接近于数学公式或人类的思维方式 支持引用透明 &emsp;&emsp;引用透明是指：如果一个函数的语义同他出现在程序中的上下文无关，则称它是引用透明的。关于引用透明的一个推论是：函数的调用语句可以被它的返回值取代，而不影响程序语义。因此，用户可以选择执行任意的模块组合（子图），以得到不同模型结构的输出结果。 提供预编译优化能力 &emsp;&emsp;TF需要实现编译得到完整的数据流图，然后根据用户选择的子图、输入数据进行计算。因此，声明式编程能够实现多种预编译优化，包括无依赖逻辑并行化、无效逻辑移除、公共逻辑提取、细粒度操作融合等。 3.1.3 TensorFlow数据流图的基本概念TF的数据流图是一个 有向无环图 。 图中的节点代表各类操作（opertion），具体包括数学运算、数据填充、结果输出和变量读写等操作，每个节点上的操作都需要分配到具体的物理设备（CPU、GPU）上执行。 图中的有向边描述了节点间的输入、输出关系（也就是各个操作的输入和输出），边上流动（flow）着代表高位数据的张量。 1.节点前向图中的节点统一称为操作，它们根据功能可以分为以下3类： 数学函数或表达式 存储模型参数的变量（variable） 占位符（placeholder） 后向图中的节点同样分为三类： 梯度值 更新模型参数的操作 更新后的模型参数 2.有向边数据流图中的有向边用于定义操作之间的关系，它们分为两类：一类用来传输数据，绝大部分流动着的张量的变都是此类，简称数据边；另一类用来定义控制依赖，通过设定节点的前置依赖决定相关节点的执行顺序，简称控制边。 3.执行原理声明式编程的特点决定了在深度神经网络模型的数据流图上，各个节点的执行顺序并不完全依赖于代码中定义的顺序，而是与节点之间的逻辑关系以及运行时库的实现机制相关。 抛开运行时库内部的复杂实现，数据流图上节点的执行顺序参考了拓扑排序的设计思想，其过程可以简述为以下4个步骤： 以节点名称作为关键字、入度作为值，创建一张散列表，并将次数据流图上的所有节点放入散列表中。 为此数据流图创建一个可执行节点队列，将散列表中入度为0的节点加入到该队列，并从散列表中删除这些节点 依次执行该队列中的每一个节点，执行成功后将此节点输出指向的节点的入度值减1，更新散列表中对应节点的入度值 重复步骤2和步骤3，直到可执行节点队列变为空 3.2 数据载体：张量TF提供Tensor和SparseTensor两种张量抽象，分别表示稠密数据和系数数据。后者旨在减少高维稀疏数据的内存占用。 3.2.1 张量：Tensor与数学和物理学中的张量不同，在NumPy或TF中，通常使用多维数组的形式描述一个张量，数组的维数表示对应张量的阶数。张量的阶数决定了其描述的数据所在高维空间的维数，在此基础上，定义每一阶的长度可以唯一确定一个张量的形状。 TF中的张量形状用python中的列表表示，列表中的每个值依次表示张量各阶的长度（如图片的张量：[128,128,3]）。 TF的张量在逻辑定义上是数据载体，但在物理实现时是一个句柄，它存储张量的元信息以及指向张量数据的内存缓冲区指针。这样设计是为了实现 内存复用。在某些前置操作（生产者）的输出值被输入到多个后置操作（消费者）的情况下，无须重复存储输出值。 1.创建一般情况下，用户不需要使用Tensor类的构造方法直接创建张量，而是通过操作间接创建张量，如constant和add操作等： 1234567import tensorflow as tfa = tf.constant(1.0)b = tf.constant(1.0)c = tf.add(a,b)print([a,b,c])//output: [&lt;tf.Tensor....&gt;,&lt;...&gt;,&lt;...&gt;] 没有执行会话，所以不会输出值，而是输出abc的类型 2.求解3.成员方法Tensor具有eval，get_shape等成员方法 4.操作TF为Tensor提供了abs,add,reduce_mean等大量操作 5.典型用例见书p44 3.2.2 稀疏张量：SparseTensorTF提供了专门用于处理高维稀疏数据的SparseTensor类。该类以键值对的形式表示高维稀疏数据，包含indices、values和dense_shape三个属性。 1.创建在TF中创建稀疏张量时，一般可以直接用SparseTensor类的构造方法，如下：123import tensorflow as tfsp = tf.SparseTensor(indices=[[0,2],[1,3]], values=[1,2],dense_shape=[3,4]) 2.操作TF为稀疏张量提供了一些专门的操作，方便用户处理。 3.典型用例见书p46 模型载体：操作TF中每个节点均对应一个具体的操作。因此，操作是模型功能的实际载体，数据流图主要有以下三种节点： 计算节点：对应的是无状态的计算或控制操作，主要负责算法逻辑表达式或流程控制 存储节点：对应的是有状态的变量操作，通常用来存储模型参数 数据节点：对应的是特殊的占位符操作，用于描述待输入数据的属性 3.3.1 计算节点：OperationOperation类定义在tensorflow/python/framework/ops.py文件中，提供了获取操作的名称、类型、输入张量、输出张量等基本属性的方法。 对于无状态节点，其输出有输入张量和节点操作共同决定 3.3.2 存储节点：Variable存储节点作为数据流图中的有状态节点，其主要作用是在多次执行相同数据流图时存储特定的参数，如深度学习或机器学习的模型参数。 对于有状态的节点，其输出除了跟输入张量和节点操作有关之外，还会受到节点内部保存的状态值的影响。 1.变量TF中的存储节点抽象是Variable类 2.变量操作每个变量对应的变量操作对象在变量初始化时构造，变量支持两种初始化方式： 初始值。根据用户输入或采用缺省值初始化 VariableDef。使用Protocol Buffers定义的变量完成初始化 3.read节点通过解释read节点的实现原理，加深对于变量、变量操作和变量值的理解。 3.3.3 数据节点：Placeholder数据流图本身是一个具有计算拓扑和内部结构的“壳”。在用户向数据流图填充数据前，图中并没有真正执行任何计算。当数据流图执行时，TF会向数据节点填充（feed）用户提供的、复合定义的数据。 TF的数据节点有占位符操作（placeholder Operation）实现，其对应的操作函数是tf.placeholder。针对稀疏数据，TensorFlow也提供了稀疏占位符操作（sparse placeholder operatin），其操作函数是tf.sparse_placeholde。 3.4 运行环境：会话]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Linux命令行与Shell脚本编程大全》]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-Book-Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Eshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[报错module 'tensorflow' has no attribute 'FIFOQueue']]></title>
    <url>%2Fz_post%2FTensorFlow-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-no_attribute_FIFOQueue%2F</url>
    <content type="text"><![CDATA[报错原因可能是因为当前路径下存在有与tensorlfow官方库相冲突的文件名，解决办法有2个。 1、更改掉有冲突性质的名字这里如果你回忆一下在创建了哪个文件以后产生报错，然后将那个文件的名字更改一下就行了。以我自己为例，我这里创建了一个queue.py的文件，然后运行时就报这个错误了，并且不只是这个文件，在当前路径下的其他py文件也不能正常运行，但是如果换一个文件夹路径，运行其他文件夹下的py文件是没有问题的。所以这里我把queue.py改名成了q.py（其他名字也行），然后在运行，就不会报错了 2、tensorlfow本身问题如果你不管在什么路径下运行任何还有tensorflow代码的文件，都会报错的话，建议使用指令重装TF： 123pip3 uninstall tensorflow-gpu#卸载pip3 install --upgrade tensorflow-gpu #安装]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 踩坑记录]]></title>
    <url>%2Fz_post%2FPython-%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[name ‘xrange’ is not defined在 Python2 中, xrange 和 range 的功能想不多, 不同的是 xrange 生成的是一个生成器, 而 range 生成的是一个 list 对象, 在要生成很大的数字序列时, xrange 的性能更好些 在 Python3 中, 取消了 range 函数, 而把 xrange 函数重命名为了 range 函数, 因此, 可以使用xrange = range来令python3兼容python2 plt.title: ‘str’ object is not callable在交互式对话框中(如 jupyter notebook), 如果之前输入了 plt.title = &quot;image&quot;, 那么 plt.title 就不再是一个函数了, 所以会报错. 解决方法是重启 kernel no module named ‘torch.utils.data.DataLoader’导入时, import 是针对文件而言的, 如果想要导入文件中的某个对象或类, 需要使用 from... import ... 语法, 如下所示: 123import torch.utils.data as data # data.pyfrom torch.utils.data import DataLoader # class DataLoader takes 0 positional arguments but 1 was given在类中的函数, 会自动传递self参数, 因此在定义函数的时候不要忘了加上该参数, 否则会在调用时显示参数数量不匹配的错误. python 的赋值运算符python 对于基本类型的数据, 使用=不会对原来的变量造成影响, 拷贝后的变量无关联:12345a = 10b = ab = 20print(a) # 10print(b) # 20 python 对于对象类型的数据, 使用=是浅拷贝, 拷贝后的对象指向同一个实例:12345678910class A(object): def __init__(self, item): super(A, self).__init__() self.item = itema = A(10)b = ab.item = 20print(a.item) # 20print(b.item) # 20 TypeError: list indices must be integers or slices, not tuple列表类型的数据无法进行超过一维以上的划分, 如下所示:12a[:5] # 正确a[:, :5] # 报错 因此, 在因此二维以上的操作时, 应该现将其转换成numpy数组, 在进行划分, 如下所示:12a = np.array(a)a[:, :5] # 正确 TypeError: Cannot cast ufunc subtract output from dtype(‘int64’) to dtype(‘uint8’) with casting rule ‘same_kind’在进行强制类型转换时, 不能向上转, 只能向下转 detach() 和 data 的区别https://blog.csdn.net/dss_dssssd/article/details/83818181 tensor.data和tensor.detach()的功能都是获取和tensor相同的数据, 并且当对获取到的值进行修改时, 原来的tensor也会被修改. 它们之间的区别在于data并不会将修改记录到tensor的加入到历史中, 而.detach()会将修改记录到历史中, 这样, 当在进行反向传播时, 如果通过.detach()对原始数据进行了修改, 程序就会报错, 而data不会提示任何错误, 这样存在很大的风险, 具体看下面代码示例. torch.data123456789101112&gt;&gt;&gt; a = torch.tensor([1,2,3.], requires_grad =True)&gt;&gt;&gt; out = a.sigmoid()&gt;&gt;&gt; c = out.data&gt;&gt;&gt; c.zero_()tensor([ 0., 0., 0.])&gt;&gt;&gt; out # out的数值被c.zero_()修改tensor([ 0., 0., 0.])&gt;&gt;&gt; out.sum().backward() # 反向传播&gt;&gt;&gt; a.grad # 这个结果很严重的错误，因为out已经改变了, 但是程序没有报错, 存在隐患tensor([ 0., 0., 0.]) torch.detach()12345678910111213&gt;&gt;&gt; a = torch.tensor([1,2,3.], requires_grad =True)&gt;&gt;&gt; out = a.sigmoid()&gt;&gt;&gt; c = out.detach()&gt;&gt;&gt; c.zero_()tensor([ 0., 0., 0.])&gt;&gt;&gt; out # out的值被c.zero_()修改 !!tensor([ 0., 0., 0.])# 编译错误, 避免了安全隐患&gt;&gt;&gt; out.sum().backward() # 需要原来out得值，但是已经被c.zero_()覆盖了，结果报错RuntimeError: one of the variables needed for gradientcomputation has been modified by an]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习与深度学习数学基础知识]]></title>
    <url>%2Fz_post%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Beta 分布Beta 分布可以看做是一个概率的概率分布, 当 参数为 $\alpha, \beta$ 的 Beta 分布的众数是 $\frac{\alpha - 1}{\alpha + \beta - 2}$, 期望是 $\frac {\alpha} {\alpha + \beta}$, 方差是 $\frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$.]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Queue模块-队列]]></title>
    <url>%2Fz_post%2FPython-Queue%2F</url>
    <content type="text"><![CDATA[Queue 是Python标准库中的线程安全的队列 (FIFO) 实现, 提供了一个适用于多线程变成的先进先出的数据结构, 主要用于在生产者和消费者线程之间的信息传递 Queue-基本FIFO队列1class Queue.Queue(maxsize=0) Queue.Queue 提供了一个基本的FIFO容器, maxsize 指明了队列中能存放的数据个数的上线. 一旦达到上限, 就会导致队列阻塞, 指责队列中的数据被消费掉. 如果将 maxsize 的值设置为小于或者等于 0, 则队列的大小没有限制. ```pyimport]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习与计算机视觉》]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NumPy模块-线性代数计算库]]></title>
    <url>%2Fz_post%2FPython-numpy%2F</url>
    <content type="text"><![CDATA[numpy基础知识ndarray 对象ndarray对象的属性表示一个 n 维数组, 描述相同类型的元素集合, 基于0的索引访问 创建 ndarray 1numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0) object: 可以返回一个数组或任何(嵌套)序列的对象。 dtype: 数据类型对象 copy: 对象是否被复制 order: C 安行, F 按列, 或者默认(A) subok: 默认情况下，返回的数组被强制为基类数组。 如果为true，则返回子类 ndmin: 指定返回数组的最小维数。 123456789101112131415# 最小维度 import numpy as npa = np.array([[1,2,3], [1,2,4]], dtype= float ,ndmin = 2)print(a)print(a.shape)print(a.dtype)print(a.ndim)print(a.size)#output:[[ 1. 2. 3.] [ 1. 2. 4.]](2, 3)float6426 numpy.array 中的 object 传入参数必须是同一结构的, 否则将进行自动类型转换, 如果指定了 dtype 参数, 则以该参数类型为准(规则与C++类似) ndarray对象的方法ndarray.ptp(axis=None, out=None) ndarray.clip()ndarray.all()ndarray.any()ndarray.swapaxes(axis1, axis2) numpy支持的数据类型 数据类型对象 dtypedtype是一个对象, 这个对象所属类的名字叫做 “数据类型” dtype 通常用于结构化数据类型: 123import numpy as npdt = np.dtype([('age',np.int8)]) print(dt) #输出如下： [('age', 'i1')] numpy基本操作根据下标组成新的数组123a = np.asarray([1,2,3,4,5,6,7,8,9])c = a[[2,3,4]]print(c) # [3,4,5] 比较运算符12345678910111213141516171819a = np.array([[1,2,3], [1,2,4]], dtype= float ,ndmin = 2)# 可以对ndarray中的值依次进行比较运算符, 返回bool数组print(a == 3)#out[[False False True] [False False False]]#out print(a &lt; 3) #out[[ True True False] [ True True False]]#out# 可以根据bool数组对ndarray中的值进行筛选, 返回1维数组print(a[ a&lt;3 ])#out[1. 2. 1. 2.]#out 向量运算矩阵运算矩阵运算主要注意的是axis参数的选择, axis参数的作用是, 沿着axis参数进行运算, 即运算后, 其他维度不变, axis指定的维度消失(所以维度会减1) numpy常用函数ndarray对象的创建np.array该函数会返回一个ndarray对象(注意numpy中不存在array这种数据对象类型). np.ndarray该函数也会返回一个ndarray对象, 但是不推荐使用(为啥?), np.ndarray是一个底层的方法, 会被其他多维数组创建方法所调用 np.zeros()生成默认元素为 0. (注意是float64类型)的ndarray 12345np.zeros ((3,4))array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]]) np.ones()生成默认元素为 1. (注意是float64类型)的ndarray 12345z = np.ones ((3,4))array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) np.arange()指定范围和数值间的间隔生成 array，注意范围包左不包右 1234l = np.arange(0,10,2) # 这里与python中的range不同的是, 必须指定第一个元素, 其次, 这里步长可以为小数, python的则不行[0 2 4 6 8] np.randomnp.random.random:12345random, 生成0~1的随机小数,默认类型为float64, 还有其他更多类型的randomnp.random.random((2,3))array([[ 0.86166627, 0.37756207, 0.94265883], [ 0.9768257 , 0.96915312, 0.33495431]]) np.random.randn: 从标准正态分布中随机输出1numpy.random.randn(d1,d2,...,dn) # d1,d2,...,dn为维度 np.random.rand: 生成[0,1)之间的随机数据1numpy.random.rand(d1,d2,...,dn) # d1,d2,...,dn为维度 ndarray.reshape()可以对ndarray的维度重新进行调整 123456arr = np.arange(15).reshape(3, 5)arrarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) 数组拼接np.append()np.append(arr, values, axis=None)参数: arr 返回: np.concatenate()统计类数值np.median()1numpy.median(a, axis=None, out=None, overwrite_input=False, keepdims=False) 沿着指定的轴计算中位数参数: a: 类似数组的变量. 不一定非要是ndarray类型, 只要是任何可以转换成ndarray类型的数据变量都可以 np.mean()1numpy.mean(a, axis=None, dtype=None, out=None, keepdims=&lt;no value&gt;) 返回沿着指定轴的算数平均值参数: a: 类似数组的变量. dtype: 数据类型, 可选参数. 对于整数输入来说, 默认返回值为float64, 对于其他floating输入来说, 返回值类型与输入类型保持一致. np.round()np.newaxisnp.stack()函数原型为 stack(arrays, axis=0), 其中, arrays 既可以是列表, 也可以是数组. 其作用是沿着指定的维度(axis)将数组(如果是列表, 就先将列表转化成numpy数组)中的元素 “堆叠” 起来, 代码示例如下: 首先, 对于列表或者元组, 是 np.stack 会首先将这些列表和元组转化成 numpy 数组, 也可以看做是对将列表作为参数传入到 np.asarray() 中, 例如, 下面的两种写法是等价的: 123456a = [[1,2,3], [4,5,6]]b = [[1,2,3], [4,5,6]]# 下面两语句是等价的c = np.stack((a,b), axis=0)c = np.stack(np.asarray((a,b)), axis=0) 即使 a 和 b 本身就是 numpy 数组, 也可以使用 np.asarray(), 如下所示:12345a = np.array([1,2,3])b = np.array([2,3,4])# 下面两种方式等价c = np.stack((a,b), axis=0)c = np.stack(np.asarray((a,b)), axis=0) 下面我们来看看其他更多的情况 12345678910111213141516171819202122232425262728import numpy as np# 创建一个二维数组 aa = np.asarray([[1,2,3],[4,5,6]])print(a) # [[1 2 3] [4 5 6]]print(a.shape) # (2, 3), 故 a 具有两个维度, 其中, 第一个维度的size为2, 第二个维度的size为3# 在a的第一个维度上, 具有两个元素, 分别为 [1 2 3] 和 [4 5 6]print(a[0]) # [1 2 3]print(a[1]) # [4 5 6]# 在a的第二个维度上, 具有三个元素, 分别为:print(a[0][0]) # 1print(a[0][1]) # 2print(a[0][2]) # 3print(a[1][0]) # 4print(a[1][1]) # 5print(a[1][2]) # 6# 我们按照定义, 沿着第一个维度(axis=0)将元素堆叠起来, 也就是将元素 [1 2 3] 和 [4 5 6] 堆叠起来, 为:a_0 = np.stack(a, axis=0)print(a_0) # [[1 2 3] [4 5 6]]print(a_0.shape) # (2, 3)# 沿着axis=1 将元素堆叠起来a_1 = np.stack(a, axis=1)print(a_1) # [[1 4] [2 5] [3 6]]print(a_1.shape) # (3, 2) 我们发现, a 的值没有发生变化, 实际上就是这样, 因为我们沿着第一维(0轴), 就是相当于 将数组其他维保持不变, 只将0轴堆叠, 也就是将: a[0], a[1], a[2],... 堆叠起来 , 就形成了一个新的数组 a_0 = [a[0] a[1] a[2] ... ], 仔细观察, 这实际上就是 a. 当 axis=1 时, 我们需要保持其他轴不变, 只将 axis=1 轴上的元素堆叠起来, 也就是要分别将 a[0][0], a[1][0], a[0][1], a[1][1], 以及 a[0][2], a[1][2] 堆叠起来. 下面我们再看一个例子来总结 axis 参数的作用123456789101112a=[[1],[2],[3]]b=[[1],[2],[3]]c=[[1],[2],[3]]d=[[1],[2],[3]]s1 = np.stack((a,b,c,d), axis=0)s2 = np.stack((a,b,c,d), axis=1)s3 = np.stack((a,b,c,d), axis=2)print(s1.shape) # (4, 3, 1)print(s2.shape) # (3, 4, 1)print(s3.shape) # (3, 1, 4) 可以看出, 经过 np.stack(array, axis=n) 操作后, 新的数组的 shape 值会使得原来第一维的大小移动到 axis 指定的维度, 而其他维的大小会相应移动, 但是相对位置不变知道了维度的变化后, 对于 “堆叠” 的理解就会变得容易得多, 具体来说, 令 n=np.asarray((a,b,c,d)): 对于 axis=0, 我们堆叠的是: n[0], n[1], n[2], a[3]; 每个 n[i] 的维度都是 3×1, 故而最终的维度为 4×3×1 对于 axis=1, 我们堆叠的是: n[0][i], n[1][i], a[2][i], a[3][i] for i in range(3); 每个元素的维度均为 对于 axis=2, 我们堆叠的是: n[0][..][i], n[1][..][i], n[2][..][i], n3[..][i] for i in range(1), 式中的 [..] 范围为 0~2, 姑第一维的维度就是 3, 后面的两个维度就是 1×4 (因为i只有0这一种情况) np.hstack()np.vstack()直接用一个较复杂的情况来说明 vstack() 对维度的影响: 12345678910a=[[[1],[2],[3]],[[1],[2],[3]]] # shape: (2, 3, 1)b=[[[1],[2],[3]],[[1],[2],[3]]]c=[[[1],[2],[3]],[[1],[2],[3]]]d=[[[1],[2],[3]],[[1],[2],[3]]]vs_a = np.vstack(np.array(a)) # shape of a: (2, 3, 1)print(vs_a.shape) # (6, 1)vs = np.vstack((a, b, c, d))print(vs.shape) # (8, 3, 1) 根据维度的变化, 我们很容易知道 vstack() 的作用实际上就是将前两维的元素合成一维, 可以简单理解成一种平铺展开的方式, 如下所示1234a= np.array([[[1],[2],[3]],[[1],[2],[3]]])print(a.shape) # (2, 3, 1)print(np.vstack(a)) # (6, 1)# [[1] [2] [3] [1] [2] [3]] 但是注意, 如果传入的数组本身只有两维, 那么就不会将这两维合并, 如下所示: 123a = np.array([[1,2,3],[1,2,3]]) # (2, 3)print(a.shape)print(np.vstack(a)) # (2, 3) [[1 2 3] [1 2 3]] https://blog.csdn.net/csdn15698845876/article/details/73380803 np.prod()乘积 np.newaxisnp.newaxis 在使用上和功能上等价于 None, 使用示例如下: 12x = np.arange(3) # x = array([0 1 2])x = x[:, np.newaxis] # x = array([[0], [1], [2]]) pad() 填充https://blog.csdn.net/qq_29592167/article/details/81043640]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[random模块-生成随机数]]></title>
    <url>%2Fz_post%2FPython-random%2F</url>
    <content type="text"><![CDATA[random.random()random.uniform()random.randint()random.randrange()random.choice()random.shuffle()参数: 返回值:无返回值, 原地操作 备注:random.shuffle的函数原型如下所示1random.shuffle(x[, random]) 该函数用于将一个列表中的元素打乱, 如:123p = ["Python", "is", "powerful"]random.shuffle(p)print(p) # 输出: ["Python", "powerful", "is"]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github源码：DenseCap]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DenseCap%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本篇博文是对论文DenseCap的源码实现，作者是斯坦福的Justin Johnson项目地址：https://cs.stanford.edu/people/karpathy/densecap/源码地址：https://github.com/jcjohnson/densecap论文地址：http://arxiv.org/abs/1511.07571 注意事项：源码是15年写的，所以使用的是比较老版本的cuda和cudnn（8.0 v5.1），并且作者也没有在继续更新代码了，所以如果你想成功运行起来的话，尽量不要用太高版本的cuda，否则可能会出现文件丢失错误（libcudnn (R5) not found in library path.） 安装安装以下依赖： 123456$luarocks install torch$luarocks install nn$luarocks install image$luarocks install lua-cjson$luarocks install https://raw.githubusercontent.com/qassemoquab/stnbhwd/master/stnbhwd-scm-1$.rockspec$luarocks install https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/torch-rnn-scm-1.rockspec （可选）安装GPU相关依赖（如果你不使用GPU跑代码，可以不装这里） 123$luarocks install cutorch$luarocks install cunn$luarocks install cudnn 下载预训练模型在命令行中键入下面的指令，运行脚本下载预训练模型（注意，下面的脚本文件在github上的项目代码里，所以你要先把github上的源代码下载下来，然后进入到项目目录里面）1$sh scripts/download_pretrained_model.sh 用图片来测试模型源码中自带了一张大象的图片，你可以用下面的指令来对大象图片进行测试，如果你想测试自己的图片，把图片放到项目中的imgs文件里，然后修改指令后面的图片名称为你自己图片的名称就可1$th run_model.lua -input_image imgs/elephant.jpg 如果你没有GPU，记得要加上-gpu -1指令来告诉模型在cpu上指令（CPU上的指令速度较慢，我自己的执行情况是：GTX980Ti：0.3s 酷睿i5/7：5～10min） 以上指令会生成vis/data文件夹，这就是模型的运行结果，可以用下面的方式查看结果， 12$cd vis$python -m SimpleHTTPServer 8181（或者python -m http.server 8181) 然后，在浏览器中打开http://localhost:8181/view_results.html. 当然，如果你想一次运行数张图片，可以使用下面的指令，该指令会将指定路径下的图片全部执行1$th run_model.lua -input_dir /path/to/my/image/folder 问题：我遇到了以下问题，这里列出我自己的解决方法，如果你还遇到了其他不同的问题，可以留言，我会尽快答复你 问题1：cutorch问题提示找不到cutorch，或者其他什么相关的错误 解决办法：重新安装cutorch1$luarocks install cutorch 不幸的是，这个解决方法对我并没有用，我最后发现是因为代码运行的cutorch版本是5.1，而由于此时我安装了高版本的cuda（9），所以在使用上面的指令安装时，安装的是cutorch 5.2，所以提示找不多5.1的cutorch，最后，我重新换回了的cuda8.0，并重新安装cutorch，解决了问题，切换cuda版本的方法可以看这里：https://blog.csdn.net/ksws0292756/article/details/80120561 问题2：libcudd.5.so.5 找不到主要原因还是cuda和cudnn的版本问题，我切换了cuda和cudnn的相关版本，换到cuda8.0和cudnn_v5.1以后， 解决了问题]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tarfile和zipfile模块-压缩解压tar归档文件]]></title>
    <url>%2Fz_post%2FPython-tarfile-zipfile%2F</url>
    <content type="text"><![CDATA[tarfiletarfile是Python自带的用于方便读取tar归档文件的模块. zipfile与tarfile对应的是zipfile模块, 用于处理zip压缩.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习轻松学》]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Book-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[第七章 网络结构7.1 关于网络结构，我们更关心什么模型结构的关注点有以下几个： 模型的总深度：代表了模型潜在的学习能力和模型的复杂度。 模型的参数总量：同样代表了模型的学习能力和复杂的复杂度。 模型前向计算所需的内存量：模型的大小 7.2 网络结构的演化7.2.1 VGG哲学AlexNet：采用类7*7的卷积核 VGGNet：用3个3×3个卷积核代替了7×7的卷积核，效果差不多，但是参数量降低了。同时增加了非线性层，过去一个卷积层加一个非线性，现在替换成了三个卷积核加三个非线性。另外，在VGG中，卷积层的操作不会改变输入数据的维度，通常会通过padding来维持输出的大小。而只通过pooling层来改变输出的大小。 提问： 卷积的时候为什么要进行padding？ 回答：对于一些通过卷积减小维度的模型来说，对于不同的输入尺度，卷积后的输出维度各不一样，所以模型不容易适配更多的场景，而如果只用pooling层改变场长宽维度，整体模型的维度计算就方便了许多。 7.2.2 GooLeNet：丰富模型层的内部结构NIN网络和Inception Module这类结构非常看中模型在局部区域的拟合能力。它们认为：一张图像通常具有总体特征和细节特征这两类特征，一般小卷积核能够更好的捕捉一些细节特征，随着深层网络的小卷积不断计算下去，总体特征也会慢慢的被提炼出来，但是这样存在一个问题，那就是在如果只采用小卷积，那么网络结构的前段一般只有细节特征，后段才慢慢有一些总体特征，而我们希望这两方面的特征总是能够一起发挥作用，因此，上面的两种模型考虑采用更多不同尺寸的卷积核来提取特征，并把这些特征连接起来，一起送到后面的网络中去计算，使得网络可以获取到更多的特征信息。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-PIL]]></title>
    <url>%2Fz_post%2FPython-PIL%2F</url>
    <content type="text"><![CDATA[导入1from PIL import Image 读取1img = Image.open(filepath) 显示1img.show() 与 numpy 数组的互相转换PIL Image 转 numpy 数组 1img_to_array = np.array(img) numpy 数组转 PIL Image (注意要确保数组内的值符合 PIL 的要求)1array_to_img = Image.fromarray(img_to_array) PIL 与 cv2 格式互相转换PIL.Image读入的图片数据类型不是 numpy 数组, 它的size属性为 (w, h), 利用np.array转换成 numpy 数组后, 它的通道顺序为 (r, g, b) 1234567891011from PIL import Imageimport numpy as np# PIL to cv2pil_img = Image.open(img_path)print(pil_img.size) # (w, h)np_img = np.array(pil_img)cv2_img = np_img[:, :, ::-1] # 交换通道# cv2 to PILpil_img = Image.fromarray(cv2_img[:, :, ::-1])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Faster R-CNN (NIPS, 2015)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FasterR-CNN-NIPS2015%2F</url>
    <content type="text"><![CDATA[文章: Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks作者: Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun 背景介绍核心亮点摘要在本文中, 我们提出了一个候选区域框推荐网络(Region Proposal Network, RPN), 该网络可以与检测模型的网络共享图片的卷积计算结果. PRN 是一个可以在每一个位置上同时预测物体边界(object bounds)以及前后景置信度(objectness scores)的全卷积网络. RPN 可以通过端到端(Faster R-CNN 由 RPN 和 Fast R-CNN 组成)的训练来生成高质量的候选框区域, 而这些区域可以提供给 Fast R-CNN 网络来进行目标检测任务. 更进一步地, 本文通过共享卷积特征的方法将 RPN 和 Fast R-CNN 网络融合成了一个单独的网络(RPN 的作用类似于一种注意了机制, 即告诉 Fast R-CNN 应该对哪里进行检测). 当使用深度卷积网络 VGG-16 时, 我们的检测模型可以在 GPU 上达到 5fps 的检测帧率, 同时在 VOC 2007, 2012 和 MS COCO 数据集上达到了 state-of-the-art 的精确度. 介绍Fast R-CNN 目标检测模型取得了很大的成功, 但是它使用的候选区域框仍然是通过 Selective Search 或者 EdgeBoxes 算法来获得的, 这种方式是在 CPU 上运行的, 相对来说比较慢. 因此, 一个明显的思路就是利用 GPU 来加速候选区域框的生成. 在本文中, 我们提出了一个新的深度网络模型, 可以代替 Selective Search 算法来为 Fast R-CNN 提供候选区域框, 并且与 Fast R-CNN 通过共享卷积计算结果, RPN 可以节省大量的计算成本.我们观察到, 用于检测目标的卷积特征图谱, 同样可以用来生成候选区域框, 因此, 我们在 backbone 卷积网络之上额外添加一些卷积层来构成 RPN 网络, RPN 网络和 Fast R-CNN 网络的分类器和回归器是并列关系. 注意, RPN 网络和 Fast R-CNN 网络各自可以进行端到端的训练, 但是 Faster R-CNN 网络并非是端到端的, 它需要结合 RPN 和 Fast R-CNN 网络才可以工作* 如图1(a)和(b)所示, 目前主流的候选框生成算法都是通过 “图片金字塔” 或者 “过滤器金字塔” 来生成候选框的, 而 RPN 网络通过引入一种新颖的 “anchor” boxes 来达到生成不同尺寸和比例的候选框. 为了融合 RPNs 和 Fast R-CNN 物体检测模型, 我们提出了交替 fine-tuning 候选框生成任务和目标检测任务的训练策略, 在训练其中一个网络时, 将另一个网络固定. Related WorkObject Proposals: Selective Search, EdgeBoxes. Deep Networks for Object Detection: R-CNN, OverFeat, MultiBox Faster R-CNN本文将提升的模型命名为 Faster R-CNN, 它主要由两部分组成. 其一是用于生成候选区域框的深度全卷积网络, 其二是 Fast R-CNN 检测模型. 整体的检测系统是一个统一的目标检测网络, 如图2所示. Region Proposals NetworksRPN 网络会将一张任意尺寸的图片作为输入, 同时会输出一系列的矩形候选框, 每一个候选框都带有一个前后景置信度(objectness score). 因为我们希望 RPN 网络和 Fast R-CNN 网络能够共享卷积计算结果, 因此我们假设两个网络中的卷积层是共享的. 在我们的实验中, 我们研究分析了 ZF Net(拥有5个可共享的卷积层)和 VGG-16 Net(拥有13层可共享的卷积层).为了生成候选区域框, 我们在最后一层共享卷积层的特征图谱上添加了一个小型的网络. 这个小型网络会接受 $n\times n$ 大小的特征图谱上的窗格. 每一个滑动的窗口都可以映射到更低维度的特征(256-d for ZF, 512-d for VGG, with ReLU, following). 这个特征会被送入到两个并行的全连接层: 一个边框回归层(reg)和一个分类层(cls). 本文中我们使用 $n=3$, 注意到在输入图片上的有效感受野非常大(171 and 228 pixels for ZF and VGG, respectively). 这个小型网络在图3中的左侧单独展示. 请注意, 因为 mini-network 是以滑动窗口的形式进行工作的, 因此两个全连接层可以在所有位置上共享. 上面的小型网络可以很自然的用一个 $n\times n$ 的卷积层后接两个并行的 $1\times 1$ 的卷积层(for reg and cls, respectively)实现 实际上, RPN网络由两部分构成: 一个卷积层, 一对全连接层分别输出分类结果(cls layer)以及坐标回归结果(reg layer). 利用了一个卷积核大小为 $n\times n$ 的卷积层, 后接两个 $1\times 1$ 的卷积层(分别用于回归和分类)实现. 我们以 ZF model(具有5层卷积层) 为例对RPN网络进行讲解, ZF model的最后一层卷积层Conv5具有256个卷积核, 也就是说它生成的特征图谱的shape为 $W\times H\times 256$, RPN网络的第一层可以认为是一个卷积层, 卷积核的尺寸为 $n\times n$ (文中使用的是 3×3), 卷积核的个数为 256 (维持通道数不变). 利用该层的卷积层对 Conv5 的特征图谱操作, 最终生成的特征图谱大小仍然为 $W\times H\times 256$ (只不过此时,图谱中的每个点都会与原图谱中的 $k\times k$ 个点相关联). 对于这个图谱中的每个点, 我们认为它是一个 anchor, 可以将它看做是一个元素个数为256的1维向量 (因为通道数为256).然后, 对于每一个anchor, 都会分配 $k$ 个anchor boxes. 每个anchor box都要分前景后景, 也就是分是否包含物体, 同时, 每一个anchor box还要输出预测物体相对于anchor的偏移坐标量. 训练的时候会选择128个postive anchor boxes 和128个negative anchor boxes. Anchors在每一个 sliding-window 的 location 上, 我们会同时预测多个 region proposals, 每个 location 上可以预测的 proposals 的最大数量为 $k$. 因此 reg layer 将会有 $4k$ 个输出, 表示 $k$ 个 box 的坐标, 同时 cls layer 将会有 $2k$ 个 scores, 用来估计每个 proposal 中是否含有物体的概率(为简单起见, cls layer 使用二分类的 softmax layer 实现, 也可以选择用 logistic regression 实现). $k$ 个 proposals 的具体参数是和 $k$ 参考框有关的, 我们称这些参考框为 anchors. anchor 处于滑动窗口的中心位置, 并且会带有一个放缩比例(scale)和宽高比(aspect ratio), 如图3左侧所示. 在默认情况下, 我们使用3个 scales 和3个 aspect ratios, 这样, 每个 sliding position 总共会生成9个anchors. 因此, 对于一张 $W\times H$ 大小的特征图谱, 总共会生成 $WHk$ 个 anchors. Translation-Invariant Anchors本文方法的一个重要性质就是它具有 平移不变性(translation invariant), 不论是在 anchors 方面还是在根据 anchors 计算 proposals 方面都具有此特性. 无论物体被移动到图片中的哪里, 我们的方法都可以生成与之对应的相同的 proposals.这种平移不变性还可以降低模型的大小. MultiBox 的全连接层维度为 $(4+1)\times 800$, 而我们的维度为 $(4+2)\times 9$. 最终, 我们输出层的参数量为 $512\times (4+2)\times 9 = 2.8 \times 10^4$ (for VGG-16), 比 MultiBox 的参数量低了两个数量级 $1536 \times (4+1) \times 800 = 6.1\times 10^6$. 如果考虑到 feature projection layers, 我们的 proposal layers 仍然具有更少的参数量, 因此, 理论上我们的模型在训练过程中发生过度拟合的风险更低. Multi-Scale Anchors as Regression References anchors 的设计提出了一种新的解决目标多尺度问题的方法. 如图1所示, 目前有两中主流的多尺度目标预测方法. 第一种方法是基于 image/feature pyramid, 如 DPM 和基于 CNN (SPPNet, Fast R-CNN, Overfeat)的方法. 图片会被放缩到不同的尺度, feature map 会根据特定尺度进行计算(如图1(a)所示). 这种方法很有用, 但是很耗时. 第二种方法是在 feature map 上使用多尺度的 sliding windows. 举例来说, 就是对于不同的尺度, 我们会使用不同的 filter sizes 来分别进行训练, 这也可以看做是 pyramid of filters (如图1(b)所示).第二种方法经常会结合第一种方法使用.与上面两种方法相比, 我们的基于 anchor 的方法是建立在 pyramid of anchors 之上的, 这种方法的成本收益较高. 我们方法的分类器和回归器都和多尺度(scales, aspect ratios)的 anchor boxes 相关. 它仅仅依赖于单一尺度的图片和特征图谱, 同时也只是用单一大小的 filters (sliding windows on the feature map). 我们在表8中展示了我们的模型在解决多尺度问题上的有效性.由于这种多尺度解决方案是建立在 anchors 之上的, 因此我们可以简单的使用卷积层来计算单一尺度的图片, 正如 Fast R-CNN 中的一样. 这种多尺度 anchors 的设计对于共享特征(sharing features without extra cost for addressing scales)来说是非常关键的一点. 综上, RPN网络做的事情就是，如果一个Region的 $p\geq 0.5$ ，则认为这个Region中可能是80个类别中的某一类，具体是哪一类现在还不清楚。到此为止，Network只需要把这些可能含有物体的区域选取出来就可以了，这些被选取出来的Region又叫做ROI （Region of Interests），即感兴趣的区域。当然了，RPN 同时也会在 feature map 上框定这些ROI感兴趣区域的大致位置，即输出Bounding-box。 好的，到此为止，RPN网络的工作就完成了，即我们现在得到的有：在输入RPN网络的 feature map 上，所有可能包含80类物体的Region区域的信息，其他Region（非常多）我们可以直接不考虑了（不用输入后续网络）。接下来的工作就很简单了，假设输入RPN网络的feature map大小为 $64\times 64$，那么我们提取的ROI的尺寸一定小于 $64 \times 64$ ，因为原始图像某一块的物体在feature map上也以同样的比例存在。我们只需要把这些Region从feature map上抠出来，由于每个Region的尺寸可能不一样，因为原始图像上物体大小不一样，所以我们需要将这些抠出来的Region想办法resize到相同的尺寸，这一步方法很多（Pooling或者Interpolation，一般采用Pooling，因为反向传播时求导方便）。假设这些抠出来的ROI Region被我们resize到了 $14\times 14$ 或者 $7\times 7$，那我们接下来将这些Region输入普通的分类网络，即第一张Faster R-CNN的结构图中最上面的部分，即可得到整个网络最终的输出classification，这里的class（车、人、狗。。）才真正对应了COCO数据集80类中的具体类别。同时，由于我们之前RPN确定的box\region坐标比较粗略，即大概框出了感兴趣的区域，所以这里我们再来一次精确的微调，根据每个box中的具体内容微微调整一下这个box的坐标，即输出第一张图中右上方的Bounding-box regression。我们网络输出的两个Bounding-box regression，都是输出的坐标偏移量，也就是在初始锚点的基础上做的偏移修正和缩放，并非输出一个原图上的绝对坐标。 Region Proposal有什么作用？1、COCO数据集上总共只有80类物体，如果不进行Region Proposal，即网络最后的classification是对所有anchor框定的Region进行识别分类，会严重拖累网络的分类性能，难以收敛。原因在于，存在过多的不包含任何有用的类别（80类之外的，例如各种各样的天空、草地、水泥墙、玻璃反射等等）的Region输入分类网络，而这些无用的Region占了所有Region的很大比例。换句话说，这些Region数量庞大，却并不能为softmax分类器带来有用的性能提升（因为无论怎么预测，其类别都是背景，对于主体的80类没有贡献）。2、大量无用的Region都需要单独进入分类网络，而分类网络由几层卷积层和最后一层全连接层组成，参数众多，十分耗费计算时间，Faster R-CNN本来就不能做到实时，这下更慢了 损失函数为了训练 RPNs, 我们给每个 anchor 都赋予了一个 binary class label. 我们会给两种类型的 anchors 赋予正样本标签: (1), 和真实框具有最大交并比(不一定大于0.7)的 anchor/anchors; (2), 和某一个真实框的交并比大于0.7. 注意, 一个真实框可以被赋值给多个 anchors. 通常情况下, 第二种情况就已经足够用来决定正样本了, 我们利用第一种情况的原因是在某些极端情况下有可能第二种情况找不到正样本. 如果某一个 anchor 和所有的真实框的交并比都低于0.3, 那么我们就对其赋予负样本标签. 剩下就不是正样本也不是负样本的 anchors 不参与训练过程.通过以上的定义, 我们可以根据 Fast R-CNN 中的多任务损失函数确定训练函数如下: L(\{p_i\}, \{t_i\}) = \frac{1}{N_{cls}} \sum_i L_{cls}(p_i, p_i^* ) + \lambda \frac{1}{N_{reg}} \sum_i p_i^* L_{reg}(t_i, t_i^* )上式中, $i$ 代表 mini-batch 中 anchor 的下标, $p_i$ 代表预测 anchor $i$ 是一个物体的可能性大小. 如果 anchor 是正样本, 则真实标签 $p^*_i$ 为1, 反之, 如果是负样本, 则为0. $t_i$ 是一个 vector, 用来表示参数化以后的边框坐标, $t^*_i$ 是正样本 anchor 对应的真实框的参数化坐标. 分类损失函数 $L_{cls}$ 是一个二分类 log 损失. 对于回归损失, 我们使用 $L_{reg}(t_i, t^*_i) = R(t_i - t^*_i)$, 这里 $R$ 代表 robust loss function(smooth L1). $p^*_i L_{reg}$ 代表回归损失仅仅会被正样本的 anchor 所激活.$N_{cls}$ 和 $N_{reg}$ 是两个归一项, 同时 $lambda$ 会调节每一项的权重. 在本文的发行版代码中, $N_{cls}$ 设定为 mini-batch 的大小(256), $N_{reg}$ 设定为 anchor locations 的大小(约2400). 同时 $lambda$ 默认为10, 这样, $cls$ 和 $reg$ 所占的比重大致相等. 我们在表9中给出了 $lambda$ 值在很大范围内对结果的影响并不敏感(这是比较好的, 说明我们不需要过度调整该超参的值). 同时, 我们发现归一化也不是必须的, 可以被简化. 训练 RPNs RPN 可以利用反向传播和 SGD 进行端到端的训练(注意这里是指 RPN, 而不是 Faster R-CNN). 我们依照 “image-centric” 的简单策略来训练网络. 每一个 mini-batch 都从一张单一的图片中得到, 其中包含了许多正样本和负样本. 我们可以对所有的 anchors 进行训练, 但是这样就会导致预测结果偏向于负样本, 因为负样本的数量占据绝对地位. 因此, 我们选择从 一张图片 中随机的挑选 256 个 anchors 来组成一个 mini-batch, 其中 正负样本的比例为 1:1, 如果图片中的正样本数量不足128, 那么就用负样本补足. 对于新添加的所有网络层, 我们都是用均值方差为(0, 0.01)的高斯分布来初始化, 其它层使用在 ImageNet 上预训练后的权重进行初始化. RPN 和 Fast R-CNN共享卷积参数到目前为止我们已经讨论过如何训练网络来进行 region proposal generation, 但是还没有考虑如何让 region-bases object detection CNN 来使用这些 proposals. 对于目标检测网络, 我们使用 Fast R-CNN 进行预测. 接下来我们将会介绍由 RPN 和 Fast 组成的参数共享的统一网络的算法训练流程.如果 RPN 和 Fast R-CNN 单独训练的话, 那么就会以不同的方式改变他们的卷积层参数. 因此, 我们需要提出一种新的训练策略使得可以在这两个网络之间的参数共享. 为了使RPN和FastRCNN共享卷积参数, 我们讨论了三种不同的训练策略: Alternating training: 先训练RPN, 然后用 RPN 产生的候选区域来训练Fast RCNN, 之后, FastRCNN 更新参数以后, 继续用来训练RPN, 这个过程是迭代进行的. 该策略是本篇 paper 中所有实验使用的训练方法 Approximate joint training: 在该策略中, RPN 网络和 Fast R-CNN 网络在训练阶段会被合并到一个网络中去(如图2所示). 每一次 SGD 迭代中, 前向计算过程都会产生 region proposals, 这些 proposals 在训练 Fast R-CNN detector 时被看做是固定的, 预计算好的. 在反向传播过程中, 会将 RPN loss 和 Fast R-CNN 的损失结合计算. 这种策略实现起来很容易, 但是这种策略忽略了对于 proposals boxes 坐标的导数, 因此这只是一种粗略的联合训练方式. 在我们的实验中, 我们发现这种方法可以取得与策略一接近的结果, 但是可以 令训练时间降低25%~50%. 该策略被包含在我们发布的Python版本的发行版代码中. Non-approximate joint training: 正如上面讨论的, RPN 预测的 bounding boxes 的坐标同样与输入数据之间存在联系. 在 Fast R-CNN 的 RoI pooling Layer 中会接受卷积特征, 同时也会将预测的 bounding boxes 作为输入, 因此理论上来说, 一个有效的优化器(backpropagation solver)应该包含相对于 box coordinate 的梯度. 因此, 我们需要 RoI pooling layer 相对于 box coordinates 是可导的. 这是一个 nontrivial 的问题, 并且它的解决方案在 RoI warping Layer (何恺明的另一篇paper, Instance-aware semantic segmentation via multi-task network cascades)给出, 但是这一部分超出了本论文想说明的事情, 故不做详细描述. 4-Step Alternating Training在本篇文章中, 我们采用了一种实用的四步训练算法通过 alternating optimization 来学习共享的特征. 第一步, 我们按照前文提到的训练 RPN 的方法对其进行训练. 这个网络使用 ImageNet 预训练的模型进行初始化并且端到端的对 region proposal 任务进行 fine-tune. 第二步, 我们使用第一步生成的 proposals 来训练一个单独的 Fast R-CNN 网络. 这个检测网络同样也是用 ImageNet 预训练的模型进行初始化. 到这里为止, 这两个网络还没有共享卷积层. 第三步, 我们使用检测网络来对 RPN 网络的训练过程进行初始化, 但是此时 我们固定住共享的卷积层, 仅仅 fine-tuning 属于 RPN 独有的那些网络层. 到这里, 两个网络已经共享的卷积层的参数. 第四步, 同样固定住共享的卷积层, 仅仅 fine-tuning 属于 Fast R-CNN 独有的网络层. 这样一来, 两个网络都共享了同样的卷积层, 并且组成一个统一的网络. 类似的交替训练可以用于更多的迭代. Implementation Details训练和预测 RPN 和 detection networks 都是在单一的图片尺寸下进行的. 我们将图片进行放缩, 使其较短边长度为 $s = 600$ pixels. Multi-scale feature extraction(图片金字塔)也许可以提升精度, 但是无法保证检测速度. 在放缩后的图片上, ZFNet 和 VGG net 到最后一层卷积层的总共的 stride 为 16. 这样大的步长依然可以取得较好的效果, 如果使用较小的 stride, 也许精度更高.对于 anchors, 我们使用三种 scales: $128^2$, $256^2$, $512^2$, 和三种 aspect ratios: 1:1, 1:2, 2:1. 这种设定并非是精心设计的, 我们的实验证明了我们方法在很大范围都有效. 表1给出了 ZF Net 学习到的每个 anchor 的平均 proposal size. 那些超出图片边界的 anchor 需要特别处理, 在训练阶段, 我们忽略了所有越界的 anchors, 因此它们不会参与训练. 对于一张经典的 $1000\times 600$ 大小的图片来说, 总共将会有大约 20000($60\times 40 \times 9$) 的 anchors, 忽略掉越界的 anchors 以后, 大约有 6000 个 anchors 可以参与训练. 如果越界的 anchors 没有被忽略, 它们将会带来大量的, 难以纠正的错误项, 这会使得训练过程难以收敛. 而在预测阶段, 我们会将全卷积的 RPN 应用到整张图片中, 这也许会产生越界的 proposal boxes, 但是我们会对其进行剪裁处理, 而不是忽略.有一些 RPN proposals 之间会有很高的 overlap. 为了减少冗余, 我们会对 proposal regions 采用基于 scores 的 NMS 算法, 最终会留下大约 2000 个proposal regions. 在 NMS 之后, 我们将会使用 top-N proposal regions 进行 detection. Experiments 如果anchor box有两个物体重叠了? 怎么处理????]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基本概念]]></title>
    <url>%2Fz_post%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[PR 曲线Accuracy: $ACC = \frac{TP+TN}{FP+FN+TP+TN}$Precision: $PRE = \frac{TP}{TP+FP}$TPR(召回率): $TPR = \frac{TP}{TP+FN}$FPR(误诊率): $FPR = \frac{FP}{FP+TN}$ PR 曲线刻画了查准率和查全率(召回率)之间的关系. 查准率指的是在所有预测为正例的数据中, 预测正确的数据所占的比例, 查全率是指预测正确的数据在所有正例的比例. 查准率和查全率一般来说是一对矛盾的度量, 当查准率高时, 查全率往往偏低, 查全率高时, 查准率往往偏低. 在很多情况下, 我们可以根据学习器的预测结果对样例进行排序, 排在前面的是学习器认为最可能是正例的样本, 排在后面的是学习器认为最不可能是正例的样本, 按此顺序逐个把样本作为正例进行预测, 则每次可以计算当前的查全率和查准率, 以查准率为 y 轴, 以查全率为 x 轴, 就可以得到相应的 PR 曲线. 如果一个学习器的 PR 曲线被另一个学习器的 PR 曲线完全包住, 则可断言后者的性能优于前者, 当不能完全包住时, 我们可以根据曲线下方的面积大小来进行比较, 面积大的性能好, 但更常用的是利用 平衡点(全准率 = 查全率) 进行比较, 平衡点的值越大, 则认为学习器的性能越好. ROC 曲线ROC: Receiver Operating Characteristic (相关操作特征曲线) 召回率(TPR)作 $y$ 轴, 误诊率(FPR)作 $x$ 轴. 在 ROC 曲线上, 最完美的点是 $(0, 1)$ 点, 该点代表学习器的误诊率为 0, 召回率为 100%. 一个完全随机的预测会得到一条从左下到右上的对角线(也叫误识别率线), 该对角线上的任意一点对应的 ACC 都是 50%(召回率和误诊率相同).]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2和Python3的兼容问题]]></title>
    <url>%2Fz_post%2FPython-Python2%E5%92%8CPython3%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在看社区里面开源的深度学习或者python项目时, 经常会看到诸如__future__或者six.moves 这种名字很奇怪的包, 实际上, 这些包都是为了实现python2与python3的兼容性而设置的, 在python社区里, 很多公司或者个人为了只维护一套代码, 一般都会写同时兼容Python2/3的代码. futurepython3 出来的时候, python的设计者们当然也考虑过代码之间的兼容问题, 许多为兼容性设计的功能可以通过 __future__ 这个包来导入, 较常用的例如: 1234567891011from __future__ import print_function# 让python2可以使用python3的print函数, 同时禁用python2的print语句from __future__ import unicode_literal# 像python3一样, 字符串字面量的类型为文本( 文本是python2中的unicode, python中的str), 而不是字节( python2中的str, python3中的bytes)from __future__ import absolute_import#from __future__ import division# 让python2像python3一样, int/int = float, int // int = int 上面四条语句导入以后, python2中的很多语法就和python3差不多了 six由于 python2/3 之间还有很多别的差异, 因此只用 __future__ 是不够的. 用 six 这个 第三方模块 可以解决这个问题. 例如, Python2 和 Python3 中字符串类型名字不同, six可以把它们变成统一的第三种形式: six.text_type , six.binary_type]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《TensorFlow实战》]]></title>
    <url>%2Fz_post%2FTensorFlow-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-TF%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RCNN(CVPR, 2014)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-R-CNN-CVPR2014%2F</url>
    <content type="text"><![CDATA[文章: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation作者: Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik 训练流程 SS 提取出候选区域框; 根据候选区域框与真实框的交并比决定正负样本标签(此时不关心框内物体的类别); 送入到CNN中提取特征; 将提取到的特征送入到 SVM 分类器中进行分类, 每一个类别都单独训练了一个 SVM 分类器; 对每一个框进行边框回归, 学习特征图谱候选区域框到真实框的转换, 调整框的位置. 检测流程 SS 提取出候选区域框; 送入到CNN中提取特征; 对于每一个类别的 SVM, 计算这些框的得分, 并在每一个类别上使用 NMS 算法, 最终根据每一个框在不同类别上的得分决定框预测类别; 根据类别和得分情况输出检测结果. Region ProposalsSelective Search.基本思路如下: 使用一个分割手段, 将图像分割成小区域 查看现有小区域, 合并可能性最高的两个区域, 重复直到整张图像合并成一个区域位置. 优先合并以下区域: 颜色(颜色直方图)相近的 纹理(梯度直方图)相近的 合并后总面积小的 合并后, 总面积在其BBox中所占比例大的 输出所有存在过的区域, 即所谓的候选区域 Feature Extraction: AlexNet (5层卷积, 2层FC, 最终特征向量的维度为 4096). 输入图片大小: $227\times 227$. 正负样本划分: 与 gt-box 的 IoU 大于 0.5 的认为是正样本, 反之认为是负样本. 训练时, mini-batch 中正样本采样数为32(over all classes), 负样本的采样数为 96. 负样本数量多是因为在真实情况下, 背景的区域数量远大于物体数量. 分类器: 为每个类别训练了一个 SVM. AppendixA. Object proposal transformations**图片大小归一化. B. Positive vs. negative examples and softmax**在 fine-tuning CNN 时和训练 SVM 时采用的正负样本的定义是不同的 find-tuning: 根据候选框与真实框的交并比决定, 无视框的类别, 我们只在乎前景和后景的区别 SVM: 当训练某一个类别的 SVM 时, 只认为与当前类别的真实框的交并比大于一定阈值的为正样本, 其他的均为负样本. 为什么要使用 SVM 而不用更加方便的 Softmax 分类器? 作者尝试过但是 mAP 从 54.2% 降到了 50.9% 下降的原因是多因素造成的, 比如对正负样本的定义, 再比如在训练 Softmax 时使用的负样本是随机采样的, 而训练 SVM 时的负样本更像是 “hard negatives” 的子集, 导致训练精度更高等等. 后续的 Fast RCNN 使用 Softmax 也达到了和 SVM 差不多的准确率, 训练过程更加简单. C. Bounding-box regression在利用 SVM 对每个候选框预测完得分以后, 我们会用一个 class-specific bounding-box regressor 来对候选框的位置进行调整.输入为 $N$ 个训练数据对: $\{(P^i, G^i)\}_{i=1,…,N}$, 其中, $P^i = (P^i_x, P^i_y, P^i_w, P^i_h)$ 代表预测框的中心坐标和宽高(后面为了简洁, 会在不必要的时候省略上标 $i$). 真实框的记法也相同: $G = (G_x, G_y, G_w, G_h)$. 注意, 这里的 $P$ 代表的是特征图谱上的候选框, 它与真实框之间存在一个转换关系. 为了让神经网络更加方便的学习, 我们让网络直接学习这 4 个特定的转换函数: $d_x(P), d_y(P), d_w(P), d_h(P)$, 我们可以通过这四个函数通过下面的公式将 $P$ 转换成真实框 $\hat G$ 的值. 假设我们具有一个特征图谱上的候选区域框, 用 $P=(P_x, P_y, P_w, P_h)$ 表示, 它对应的真实框用 $G=(G_x, G_y, G_w, G_h)$ 表示, 那么, 我们的目标是希望回归器能够学习到一个从 $P$ 到 $G$ 的转化(transformation), 如下所示, $\hat G$ 就是我们经过转换后得到的预测框在原始图片上的坐标和宽高. \hat G_x = P_w d_x(P) + P_x\hat G_y = P_h d_y(P) + P_y\hat G_w = P_w exp(d_w(P))\hat G_h = P_h exp(d_h(P))上式中的 $d_x(P), d_y(P), d_w(P), d_h(P)$ 就是我们要学习的参数, 因此我们有 $d_*(P) = w^T_* \Phi_5(P)$, 这里的 $w_*$ 就是神经网络中的可学习参数. 我们通过优化下面的最小二乘目标函数(ridge regression)来学习参数: w_* = \arg\min_{\hat w_*} \sum^N_i (t^i_* - \hat w^T_* \Phi_5(P^i))^2 + \lambda \|\hat w_* \|^2那么我们的学习目标就是使得这些参数可以满足 $\hat G = G$, 也就是说, 我们的学习目标就是令参数 $d_x(P), d_y(P), d_w(P), d_h(P)$ 无限近似于下面的 $(t_x, t_y, t_w, t_h)$: t_x = (G_x - P_x) / P_wt_y = (G_y - P_y) / P_ht_w = log(G_w / P_w)t_h = log(G_h / P_h) 以上图举例来说, 红色的框 $P$ 代表的是原始的 proposal, 绿色的框 $G$ 代表的是真实的 Ground Truth, 我们的目标时寻找一种函数关系使得 $P$ 经过映射后可以得到一个更接近 $G$ 的回归窗口 $\hat G$. 也就是说, 边框回归的目的既是：给定一个 box 坐标 $(P_x,P_y,P_w,P_h)$, 我们要寻找一种映射关系 $f$, 使得 $f(P) = \hat G$, 其中, $\hat G \approx G$. 简述 Selective Search 的原理首先, 首先利用分割算法(Graph-Based Image Segmentation, 2004, IJCV, 贪心)得到一些初始化的区域, 然后计算每个相邻区域的相似性, 相似性的计算依赖于颜色相似性和纹理相似性, 同时给较小的区域赋予更多的权重, 也就是优先合并小区域(否则大区域有可能会不断吞并周围区域, 使得多尺度之应用了在局部区域, 而不是在每个位置都具有多尺度), 接着找出相似性最大的区域, 将它们合并, 并计算新合并的区域与其他相邻区域的相似性, 重复这个过程, 直到所有的区域被合并完为止. 简述 Bounding Box 的回归方式在 R-CNN 的边框回归中, 我们不是直接学习真实框的坐标, 而是学习从 Proposals 到 真实框的一个偏移变换函数, 具体来说, 对于中心点, 需要学习的是 proposal 和 真实框相对位移, 这个位移会用 proposal 的宽和高进行归一化, 对于宽和高, 需要学习的是真实框相对于 proposal 的 log 缩放度. t_x = (G_x - P_x) / P_wt_y = (G_y - P_y) / P_ht_w = log(G_w / P_w)t_h = log(G_h / P_h) Bounding box 回归的时候, 为什么不直接对坐标回归, 而是采用偏移量和缩放度最主要是为了获得对物体的尺度不变性和唯一不变性, 一般来说, 对于大物体和小物体, 在没用使用归一化时, 对于相同的偏移量, 大物体可能只偏移了一点, 而小物体可能会偏移很多. 具体来说, 对于两个不同尺度但是完全一样的物体, 我们得到的特征应该是相似的, 因此, 我们最终学习出来的结果也应该是相似的, 但是如果采用直接学习坐标的方式, 那么由于此时大物体和小物体虽然在相对位移上是相同的, 但是绝对位移和坐标值是不同的, 因此, 我们最终学习出来的结果就会不一样, 这就相当于给了一个函数相同的输入, 但是却得到了不同的结果, 这样就很难让网络学习. 边框回归(BoundingBoxRegression)详解https://blog.csdn.net/zijin0802034/article/details/77685438 为什么当 Region Proposals 和 Ground Truth 较接近时的 IoU 较大时, 可以认为是边框回归函数是线性变换?当输入的 Proposal 与 Ground Truth 相差较小时(RCNN 设置的是 IoU&gt;0.6)， 可以认为这种变换是一种线性变换， 那么我们就可以用线性回归来建模对窗口进行微调， 否则会导致训练的回归模型不 work (当 Proposal跟 GT 离得较远，就是复杂的非线性问题了，此时用线性回归建模显然不合理). 对于这一段的话解释如下: 首先, Log 函数肯定不满足线性函数的定义, 但是根据极限的相关定义, 我们如下面的等式成立: lim_{x\rightarrow0}log(1+x) = x根据上面的公式, 我们可以对公式 $t_w$ 作如下推导: $$t_w = log(G_w / P_w) = log(\frac{G_w + P_w - P_w}{P_w}) = log(1 + \frac{G_w - P_w}{P_w})$ 从上式我们可以看出, 当 $G_w - P_w = 0$ 的时候, 回归函数 $t_w$ 可以看做是线性函数. 这里还有一点疑问: 从公式来说, $t_x$ 和 $t_y$ 本身就已经是线性函数, 而 $t_w$ 和 $t_h$ 只需要 Proposals 和 Ground Truth 的宽高相似即可满足线性回归条件. 那么为什么必须要 IoU 较大才可以? 不是只要宽高相似就可以吗? 边框回归(BoundingBoxRegression)详解https://blog.csdn.net/zijin0802034/article/details/77685438]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fast R-CNN (ICCV, 2015)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-FastR-CNN-ICCV2015%2F</url>
    <content type="text"><![CDATA[文章: Fast R-CNN作者: Ross Girshick 核心亮点摘要本篇文章提出了一个用于解决目标检测问题的 Fast Region-based Convolutional Network (Fast R-CNN). Fast R-CNN 是基于之前的 R-CNN 提出的. 相比于之前的工作, Fast R-CNN 利用一些新颖的方法来提升训练和推演时的速度, 同时还提高了模型的准确率. 使用 VGG16 的 Fast R-CNN 在训练时的速度是 R-CNN 的9倍, 是 SPP-Net 的3倍, 在推演时的速度是 R-CNN 的213倍, 是 SPP-Net 的10多倍. 介绍R-CNN 是近年来较为成功的目标检测模型之一, 但是, 它却存在着一些明显的缺点: 训练过程是分阶段的(Training is a multi-stage pipeline): 在物体候选框上训练 CNN 网络, 然后再在 ConvNet features 上面训练 SVMs 分类器, 最后在训练一个边框回归器来对候选框的位置修正 Training is expensive in space and time: 对于 SVM 和 bounding-box 回归器训练来说, 我们需要分别计算每个候选框的 feature maps, 这造成了大量的重复计算, 会消耗掉大量的存储空间. 目标检测速度太慢(Object detection is slow): 在推演阶段, 也会对图片上的每个候选框分别计算其 feature maps, 大量重复计算是的网络模型的计算效率很低. 从上面的分析可以看出, R-CNN 速度慢的原因在于它需要在每个候选区域框上进行卷积计算, 这会造成大量的重复计算. SPP Net 通过共享卷积计算图谱的方式提高了 R-CNN 的速度. 但是 SPP Net 同样也具有很多缺点: 训练过程是分阶段的(Training is a multi-stage pipeline): 训练的 pipeline 和 R-CNN 差不多, 都是多阶段的 无法 Fine-Tuning 金字塔池化层之前的卷积层: 由于 SPPNet 提出的 fine-tuning 算法不能更新 spatial pyramid pooling 层之前的卷积层, 这使得它的准确率有待提高. (不能更新的原因是 SPPNet 的 mini-batch 选择策略和 R-CNN 是相同的, 这使得计算的复杂度很高, 详细解释可看下文). 本文主要的贡献点有以下几点: 更高的检测准确率(mAP) 整个训练过程更加统一(利用多目标损失函数) 训练时可以对所有网络层参数进行更新(相比于SPPNet) 无需在硬盘上额外存储 feature.(相比于 R-CNN, 因为共享卷积计算结果, 使得feature的体积大大降低) Fast R-CNN architecture and training 如图1所示为 Fast R-CNN 的结构. Fast R-CNN 网络的输入是一张图片和一系列的物体候选框. 网络首先会对整张图片进行卷积计算来得到卷积特征图谱(conv feature map). 然后, 对于每一个物体候选框, 都会通过 RoI pooling 层从卷积特征图谱上提取固定长度的 feature vector. 将这些还有物体区域特征的 feature vector 送入一系列的全连接层, 最终会分别送到两个不同的分支, 一个用于生成类别的置信度, 另一个用于计算每个物体边框区域的坐标. RoI Pooling LayerRoI Pooling Layer 使用 max pooling 来将 任意尺寸 的有效感兴趣区域中的特征转换成一个具有 固定尺寸 $H\times W (e.g., 7\times 7)$的较小的 feature map, 这里的 $H$ 和 $W$ 是超参数. 在本文中, 一个 RoI(感兴趣区域)就是 feature map 上面的一个矩形窗口. 每一个 RoI 都通过四元组 $(r,c,h,w)$ 来表示(top-left corner, and its height and width). RoI Pooling的前向传播过程如下: 对于任意给定尺寸为 $h\times w$ 的feature map的 RoI 窗口, 将其划分成 $W\times H$ 的网格大小(上图中的示例为 $W\times H= 3\times 3$ ), 这样, 每一个网格 cell 中的尺寸大约为 $h/H \times w/W$, 然后我们在网格 cell 中执行max pooling操作. 和标准的 max pooling 相同, RoI pooling 在卷积图谱上的各个通道之间是独立计算的. 这样, 对于任意size的输入, 都可以获得固定长度的输出. 可以看出, RoI layer 实际上是 spatial pyramid pooling layer 中的一个特例, 即只有一个 pyramid level. (但是相比于金字塔池化, RoI 池化可以确定固定大小的 pooling 窗口, 这使得我们可以更新池化层之前的网络层参数, 进而提高准确率) 利用预训练网络初始化参数本文使用了三种不同的在 ImageNet 上预训练的网络结构, 每一种都具有5层池化层, 以及5~13层的卷积层. 在利用预训练模型初始化 Fast R-CNN 网络时, 网络结构会发生以下变化: 首先用 RoI pooling 替代网络的最后一层 max pooling. 需要设置超参数 $H$ 和 $W$ (e.g. $H=W=7$ for VGG16) 网络的最后两层全连接层和 softmax 层会被两个并列的网络层替代, 即分类层(fc, K+1softmax)和 bounding-box 回归层 网络的输入除了接收图片外, 还要接收每张图片中含有的一系列 RoIs(特征图谱上的感兴趣区域). Fine-tuning for detectionFast R-CNN 的一个重要特性就是可以对模型中的所有参数进行更新. 首先, 我们来说明一下为什么 SPPNet 不能更新 spatial pyramid pooling layer 之间的网络权重.最根本的原因是当每一个 RoI 训练样本来自于不同的图片时, 在 SPP layer 上进行反向传播时的效率非常低(highly inefficient), 而这恰恰是 R-CNN 和 SPPnet 网络的训练方式(即从不同图片获取 RoI). 这种低效性源自于每一个 RoI 都可能具有非常大的感受野(receptive field), 通常会覆盖整个输入图片(often spanning the entire input image). 因此前向传播时必须处理整个感受野, 因此训练时的输入会非常大(通常回事整张图片).本文提出了一个更加高效的训练方式, 它可以在训练阶段有效利用特征共享的优势. 在 Fast R-CNN 中, SGD 的 mini-batches 是分层次采样的(sampled hierarchically), 首先会采样出 N 个图片, 然后会在每张图片中采样 R/N 个 RoIs. 关键性的一点是, 从同一张图片中得到的 RoIs 会在前向传播和反向传播的过程中共享卷积计算结果和内存. 如果我们令 N 很小, 就可以降低 mini-batch 的计算复杂度. 例如, 我们令 $N=2, R=128$, 此时的训练策略就会比使用 128 张不同的图片(R-CNN 和 SPPNet 的训练策略)计算速度快 64 倍.这种加速策略的一点顾虑就是由于同一张图片中的不同 RoIs 之间是有关联性的, 因此这会降低模型训练的收敛速度, 但是, 通过实验表明, 这种顾虑并不会在实际使用中出现, 并且我们利用 $N=2, R=128$ 的参数设置取得了更快的收敛效果(比 R-CNN 的收敛迭代次数少).除了使用层次采样外, Fast R-CNN 还使用了流水线式的训练过程(streamlined training process), 通过联合训练 softmax 分类器和 bounding box 回归器, FastRCNN 可以更加统一的进行训练(多目标联合训练).接下来我们会对以上这些关键部分进行详细介绍 Multi-task lossFast R-CNN 网络拥有两个并列的输出层. 第一个输出层是离散的概率分布预测层(per RoI, over K+1 categories), $p=(p_0, …, p_K)$. 第二个输出层用于回归预测 bounding-box 的坐标偏移量, $t^k = (t_x^k, t_y^k, t_w^k, t_h^k)$, 每一个物体都具有 $k$ 个边框预测结果, 对应着 $K$ 个物体类别.每一个训练样本 RoI 都会用真实类别标签 $u$ 和真实 bounding-box 回归目标 $v$ 标记. 我们会在每一个标记好的 RoI 样本上计算联合任务损失函数 $L$ 如下所示: L(p, u, t_u, v) = L_{cls}(p,u) + \lambda [u \geq 1] L_{loc}(t^u, v) \tag 1上式中, $L_{cls}(p,u) = - log p_u$, 即对于真实类别 $u$ 的 log 损失.$L_{loc}$ 被定义为相对于真实类别 $u$ 的边框回归损失, 即不计算其他类别的边框损失, 也不计算背景的边框损失. 对于 bounding-box 归回, 我们使用下面的损失: L_{loc}(t^u, v) = \sum_{i\in {x,y,w,h}} smooth_{L_1}(t_i^u - v_i) \tag 2上式中, smooth L1 损失被定义为: smooth_{L_1}(x) = \begin{cases} 0.5x^2 && |x|]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mask R-CNN (ICCV, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-MaskR-CNN-ICCV2017%2F</url>
    <content type="text"><![CDATA[文章: MaskRCNN作者: Kaiming He, Georgia Gkioxari, Piotr Dollar, Ross Girshick备注: FAIR, ICCV best paper 核心亮点1) 提出了一个简单,灵活,通用的实例分割模型框架MaskRCNN 在 FasterRCNN 的基础上进行改进, 在模型的head部分引入了一个新的mask预测分支, 在训练阶段, 该分支会与其他分支并行执行, 在测试阶段, 虽然不是并行执行, 但是利用 NMS 减少了需要计算的候选框个数, 因此 MaskRCNN 模型整体增加的额外开销较小. 2) 提出了RoI Align来解决 RoI 与 pooling 后的特征图谱之间的不对齐问题Fast/FasterRCNN 原始的 RoIPool 操作在进行池化时, 会进行两次粗糙的量化操作, 这使得池化后的特征图谱与 RoI 中的信息不能很好的对齐, 对于像素级任务实例分割来说, 这种非对齐会使得模型性能大大降低, 因此 MaskRCNN 提出用基于双线性插值法的 RoI Align 代替 RoI Pool, 以此来解决非对齐问题. 摘要本文提出了一个简单, 灵活, 通用的目标实例分割框架. 本文的方法可以有效的检测图片中的物体, 同时为每个实例生成一个高质量的掩膜, 我们将其称为 Mask RCNN, 它是从 Faster RCNN扩展而来的, 添加了一个新的分支来并行预测物体掩膜. MaskRCNN可以轻易的进行训练, 并且相对于FasterRCNN只增加了很少的开销, 可以在5fps下运行. 不仅如此, MaskRCNN可以轻易的泛化到其他任务中, 如人体姿态识别. 本文的模型在COCO的三个系列任务都, 都取得了最好的效果. 背景介绍本文意在提出一种通用的实例分割模型框架-MarkRCNN, 该模型扩展自FasterRCNN, 在FasterRCNN模型中的每一个RoI上, 添加一个与检测分支平行运行的掩膜预测分支, 如图1所示. 掩膜分支(mask branch) 是一个小型的FCN网络, 它应用在每一个RoI上, 以pixel-to-pixel的方式来预测一个分割掩膜. Mask RCNN易于实现, 且增加的额外开销很小, 并且具有很大的灵活性, 是一个通用的实例分割模型框架. 在FasterRCNN中使用的RoI pooling是一种针对目标检测任务的粗糙的pooling方法, 会造成一定程度上的不对齐结果, 为了克服这一点, 本文提出了RoIAlign, 用于保留准确的空间位置, RoIAlign可以将掩膜的精确度才提高10%~50%. 另外, 本文发现, 将二值掩膜预测和类别预测任务分开独立进行是非常重要的一步, 因此, 我们为每一个类别都会单独进行mask预测, 避免了不同类别之间的冲突. 这一点与FCN不同, FCN会对一个像素点进行多类别的分类.我们的模型在GPU上的运行速度大约为200ms/frame, 在8-GPU的单机上训练时, 需要1到2天的时间. Faster RCNN简单回顾一下Faster RCNN, 它包含两个阶段, 第一个阶段, 是RPN结构, 用于生成候选框集合. 第二个阶段, 本质上就是一个Fast RCNN, 利用RoI pooling从RoI中提出固定尺寸的特征, 然后进行分类任务和边框回归任务. 这两个阶段使用的特征图谱是共享的, 都来自backbone网络. Mask RCNNMask RCNN在概念上来说非常简单: FasterRCNN对于每个候选框来说都有两个输出分支, 一个class label和一个bounding-box offset, 对此在MaskRCNN中我们添加了第三个分支用于输出掩膜. 虽然这是一个看起来很自然的想法, 但是额外增加的掩膜分支和class, box分支并不相同, 它需要物体更加精确的空间位置. 因此, 我们还引入了一个在MaskRCNN中非常关键的元素:RoIAlign, 用于进行像素对其. 来弥补FasterRCNN RoI pooling的粗糙映射造成的位置偏移问题.Mask R-CNN 使用了与 Faster R-CNN相同的two-stage结构, 第一阶段使用了相同的RPN网络, 第二阶段, 在执行class分类和box回归任务的 同时(并行), MaskRCNN会为每一个RoI生成一个二值掩膜. 这一点与许多现有系统不同, 这些系统都是在mask预测结果的基础上进行分类任务的. 我们的灵感来自于Fast RCNN中class任务和box任务的并行执行(这种并行执行方式很大程度上简化了原始的 R-CNN 的 multi-stage pipeline).Formally, 在训练阶段, 我们在每一个采样的RoI上定义一个multi-task loss如: $L = L_{cls}+L_{box}+L_{mask}$. 前两个loss和Fast RCNN相同, 第三个分支对于每一个RoI的输出维度为 $Km^2$, 代表这分辨率 $m\times m$ 下的 $K$ 个二值掩膜, 每一个掩膜对应了一个类别(共 $K$ 个类别). 为此, 我们使用了 per-pixed sigmoid, 并且将 $L_{mask}$ 定义为平均二值交叉熵(average binary cross-entropy loss). 对于一个与真实类别 $k$ 相关联的RoI, $L_{mask}$ 只在第 $k$ 个mask上有定义(其他mask不计入loss).我们对 $L_{mask}$ 的定义使得网络模型可以为每个class生成mask, 避免了不同类别之间的竞争冲突. 并且利用分类分支的结果标签来选择对应的mask进行计算. 这样做可以使得mask预测任务和class预测任务 decouple, 这与许多现有应用FCNs进行实例分割任务的模型不同, 这些模型通常会使用一个 per-pixel softmax 和一个 multinomial cross-entropy loss(多分类), 在这种模型中, 掩膜通常会引起类别之间的竞争. 而在本文的模型中, 使用的是 per-pixel sigmoid 和一个 binary loss (二分类). 我们将会通过实验来展示这将对于呈现出好的实例分割结果来说十分关键! Mask Representation一个mask代表了一个物体的空间布局(spatial layout). 因此, 和 class labels 或者 box offsets 不可避免的要通过 FC layer 降到较小维度输出不同, 提取mask的空间结构时可以很自然的通过像素到像素(卷积层正好提供了这种相关关系)的方式解决.具体来说, 我们使用FCN从每个RoI中预测出一个 $m\times m$ 的mask. 这使得mask分支中的每一层都维护着 $m\times m$ 的物体空间布局矩阵, 而不用将其转换成低纬度的向量形式(缺少空间信息). 和之前的工作(依赖于fc层预测mask)不同的是, 本文的全卷积表征需要的参数更少, 同时通过实验证明, 更加精确. 这种 pixel to pixel 的机制需要我们的RoI feature (通常都是些很小的特征图谱)能够较好与真实物体对齐, 保持明确的逐像素间的对应关系. 为此, 本文提出了 RoIAlign 来代替 RoiPool.(这个替换很重要) RoIAlignRoIPool可以从每个RoI中提取到一个较小的固定的feature map(如, 7×7). RoIPool首先会将浮点型的 RoI (因为 RoI 是模型预测出来的 bounding box 的坐标, 不是严格个 feature map 的整数像素点对应的) 离散量化 到 feature map 的像素粒度上, 然后量化后的 RoI (整数) 又会细分到 RoIPool 的各个 bin 中去(这又是一次量化), 最终的 feature values 是通过每个 bin 整合信息得到的(通常为 max pooling). 例如, 首先, 第一次量化会在 (x / 16) 上以四舍五入的方式(rounding)进行, 这里, 16 是特征图谱相对于原图片的步长, 然后, 同样的, 量化又会在划分到 bins 中时被执行(因为不可能总是刚好整数划分). 这些量化操作(两次)会引入 RoI 和提取到的特征之间的 misalignments, 这种misalignments对于分类任务来说或许影响不大, 但是对于predicting pixel-accurate mask任务来说就会造成很大的负面影响. 为了解决这个问题, 我们提出了RoIAlign层, 移除了RoIPool粗糙的量化计算, 将提取到的的 features 与输入的RoI对齐. RoIAlign的原理很简单: 避免在 RoI 边界上或者 bins 中执行任何量化计算(即, 我们使用 $x/16$, 而不是 $[x/16]$). 我们利用双线性插值法来计算每个 RoI bin 中各个位置上具体的像素值, 并且对计算结果整合(max或者average). 具体计算细节如图3所示. 我们注意到, 在不使用任何量化计算以后, 计算结果对于具体的采样点位置和采样数量的多少都不再那么敏感了. 在4.2节中可以看到 RoIAlign 会带来很大的提升. 同时我们还与 RoIWarp 操作进行了比较. 和 RoIAlign 不同, RoIWarp 忽视了 alignment 问题, 并且同样采用了想 RoIPool 一样的量化 RoI 的操作. 因此, 即使 RoIWarp 也采用了二线性插值法的 resampling 操作, 它的表现在实验中也没有取得很大的提升, 这也正说明了 alignment 的关键性作用. RoI Pooling存在两次量化过程: 将候选框边界量化为整数坐标值 将量化后的边界区域分割成 $k\times k$ 个bins, 并对每一个单元的边界量化 可以看出, 上面的量化操作是一种很粗糙的Pooling方式, 由于feature map可以看做是对原图特征的高度概括信息, 所以feature map上的细微差别映射回原图时, 往往会导致产生很大的像素位移差. 故此, 提出了RoI Align的解决思路: 取消量化操作, 使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值, 从而将整个特征聚集过程转换为一个连续的操作. 其具体流程如下: 遍历每一个候选区域, 保持浮点数边界不做量化 将候选区域分割成 $k\times k$ 个bins, 每个bins的边界也不做量化 在每个bins中计算固定四个采样点的位置, 使用双线性插值的方法计算出这四个位置的值, 然后进行最大化操作. 如下图所示. 网络结构(Network Architecture)为了说明本文方法的通用性, 我们利用多个模型结构初始化Mask RCNN. For clarity, 我们做出以下区分: 1) 用于提取整个图片特征的卷积结构称为 backbone, 2) 用于执行bounding-box recognition(cls,reg)任务和 mask prediction 任务的部分称为 network head, 它会被分别应用在每一个 RoI 上面.我们将基于网络深度特性的命名方法来表示 backbone network(主干网络). 我们测试了 50和101层的 ResNet, ResNeXt 网络. 原始的 FasterRCNN 在使用ReNets时, 利用的是第4段卷积块的最后一层卷积层的输出, 我们称为 C4. 这个backbone, 我们将其记为 ResNet-50-C4 , 它是很多模型中的一个常用的选择.我们同时还使用了另一个更有效backbone: Feature Pyramid Network(FPN). FPN 使用了一种 top-down 的横向连接结构, 使得可以从单一的图片输入建立起网络内部的特征金字塔结构(in-network feature pyramid). 用 FPN 当做 backbone 的 Faster R-CNN 根据 RoI 的尺寸从特征金字塔的不同层级中提取 RoIs features, 但是其他的流程基本和普通 ResNet 相同. 使用 ResNet-FPN 作为 backbone 用于特征提取的 Mask R-CNN 可以获得极大的性能提升(both acc and speed).对于 network head, 我们几乎是按照之前的 Faster R-CNN 的框架设计的, 我们在其基础上添加了一个全卷积的mask prediction 分支. Specifically, 我们对现有的 ResNet 和 FPN 的论文中 Faster R-CNN 的 box heads 进行扩展. 具体细节如图4所示. ResNet-C4 的 head 包含 ResNet 的第5个卷积块(即 9层的res5, 计算密集型). 对于FPN来说, 它的backbone就已经包含了res5, 因此可以允许有 filters 更少的有效头部(efficient head).我们注意到本文的mask分支具有一个很简单的结构. 其他更加复杂设计也许可以更进一步的提升性能, 这将会在以后的工作的进一步讨论, 并非本文的焦点. 实现细节(Implementation Details)我们使用Faster RCNN原文提供的超参数.(无需调参也说明了MaskRCNN的鲁棒性很高) Training:和FastRCNN一样, 如果RoI与真实框的IOU大于0.5, 就会被认为是正样本, 否则认为是负样本(这里与FasterRCNN不同). $L_{mask}$ 只会计算正样本上的掩膜损失. mask target 是 RoI 和 真实mask之间的交集(注意不是直接根据真实mask计算损失). 我们使用 image-cengric (FastRCNN), 图片会被resized成scale(shorter edge) 为800 像素. minibatch为 2 img/GPU, 每个img含有N个sampled RoIs. 正负样本比例为 1:3. 对于 C4 backbone来说, N为 64, 对于FPN来说, N为512.(因为FPN效率更高, 所以可以在一张图片上计算更多的RoIs). 在8PGUs上训练(即有效minibatch为16). lr为0.02, 每120k 迭代(iteration)会缩小10倍. weight decay为0.0001, momentum为0.9. 在使用ResNeXt时, one img/GPU, lr初始为0.02, 其他相同.RPN的anchor具有 5 scales 和 3 aspect ratios. 为了方便进行消融实验, RPN是被单独训练的, 并且没有与Mask RCNN共享了卷积特征(可共享, 只是为了方便没有共享). 对于本文中的每一项, RPN和MaskRCNN都具有相同的backbones. Inference:在预测阶段, proposal的数量为 300 for C4 backbone, 1000 for FPN. 我们会在这些 proposals 上面进行 box prediction branch, 然后使用NMS选择了最高score的100个boxes, 并对这100个 boxes 应用 mask branch, 虽然这里和训练时采用的并行计算不同, 但是它仍然可以加速预测速度, 同时能够提高精度(因为只使用了更少但是更精确的100个box). mask branch 可以对每个RoI预测出 $K$ 个masks, 但是我们只会使用第 $k$ 个mask, 这里的小写 $k$ 代表着物体的预测分支上确定的类别(注意不一定是真实类别). 我们会将 $m\times m$ 的浮点类型的mask放缩到RoI的尺寸大小, 然后依据一个阈值(0.5)对mask的像素值进行二值化操作. 注意到, 由于我们只对top 100 的 score box执行mask branch , 因此在模型预测时, MaskRCNN相比于FasterRCNN, 只增加了很小的开销.(增加了20%) 实验: 实例分割(Instance Segmentation)使用了 COCO 数据集, 采用 AP(averaged over IoU thresholds) 评价标准, $\text{AP}_{50}$, $\text{AP}_{75}$, $\text{AP}_{S}$, $\text{AP}_{M}$, $\text{AP}_{L}$. 如表1所示, MarkRCNN 的性能超过 COCO2015 和 COCO2016的实例分割冠军 MNC 和 FCIS.(并且 MaskRCNN 没有使用 multi-scale train/test, horizontal flip test, OHEM 等 trick, 言外之意 MaskRCNN 的性能可以进一步利用这些 trick 提高) Table2 显示了对 MaskRCNN 的消融实验分析结果. 表3 显示了 MaskRCNN 与当前的 state of art 的目标检测方法在 COCO 数据集上的表现. MaskRCNN for Human Pose Estimation: 附录A: Experiments on Cityscapes 附录B: Enhanced Results on COCO下表显示了 MarkRCNN 被各种 trick 增益后的性能表现]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
        <tag>实例分割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[os模块-系统操作]]></title>
    <url>%2Fz_post%2FPython-os%2F</url>
    <content type="text"><![CDATA[https://docs.python.org/3/library/os.path.html os.path.isabs(…) # 判断是否绝对路径 os.path.exists(…) # 判断是否真实存在 os.path.isdir(…) # 判断是否是个目录 os.path.isfile(…) # 判断是否是个文件 os.path.split(…) # 分隔目录和文件名/文件夹名 os.path.splitdrive(…) # 分隔盘符(windows系统) os.path.splitext(…) # 分隔文件和扩展名 os.walk() 方法用于通过在目录树中游走输出在目录中的文件名，向上或者向下。 os.mkdir(path[, mode])创建一个目标, 参数可以是相对或者绝对路径, mode的模式默认为0777,如果目录有多级, 则创建最后一级. 如果最后一级目录的上级有不存在的或者目录已经存在, 则会抛出一个OSError os.makedirs(path[, mode])创建 递归 的目录树, 参数可以是相对或者绝对路径, mode的默认模式也是0777.如果子目录已经存在, 则创建失败, 会抛出一个OSError的异常 os.path.expanduser(‘~’)可以返回~的真实路径, 如 /home/zerozone.]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[skimage模块-图像处理]]></title>
    <url>%2Fz_post%2FPython-skimage%2F</url>
    <content type="text"><![CDATA[比opencv的速度要慢很多, 但是使用起来更加简单, 真的对速度要求很高的话, 一般都会C++和opecv使用. 所以一般情况下, 首先看skimage能否实现, 不行的话再转用opencv 123import skimagefrom skimage import io # IO is a submodule. Submodules need to be imported from the parent module explicitly.img = io.imread("1.jpg")]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv模块-计算机视觉算法库]]></title>
    <url>%2Fz_post%2FPython-opencv%2F</url>
    <content type="text"><![CDATA[opencv 基础知识cv2.imread读入的图片, 其shape为(h, w, c), 颜色通道顺序为(b, g, r) 常用颜色读取图片1img = cv2.imread(img_path) 保存图片1cv2.imwrite(save_path, img) 文本(startX, startY) 为左上角坐标1cv2.putText(img, "text test", (startX, startY), cv2.FONT_HERSHEY_SIMPLEX, font_size, (B,G,R), thickness) 画框(x,y) 为左上角坐标(x+h,y+w) 为右下角坐标1cv2.rectangle(img,(x,y), (x+h,y+w), (0,255,0), thickness) waitKey()12345keypress = cv2.waitKey(200) # 200为当前图片的显示持续时间if keypress == ord('c') # keypress为按键的整数形式, 所以需要用ord将字符类型转换if cv2.waitKey(200) == 27: # Decimal 27 = Esc opencv与numpyopencv的基础类型为numpy.ndarray, 因此可以直接使用 ndarray 的一些属性的方法 1234import cv2img = cv2.imread('./test.jpg')print(type(img)) # &lt;class 'numpy.ndarray'&gt;print(img.shape) # (500, 1069, 3) (高, 宽, 通道) 利用 cv2.merge 方法将 numpy.ndarray 数据转换成opencv的图片数据: 12345678910# 图片的分辨率为300*200(宽*高)，这里b, g, r设为随机值，注意dtype属性b = np.random.randint(0, 255, (200, 300), dtype=np.uint8)g = np.random.randint(0, 255, (200, 300), dtype=np.uint8)r = np.random.randint(0, 255, (200, 300), dtype=np.uint8)# 合并通道，形成图片img = cv2.merge([b, g, r]) # opencv的通道是b在最前,r在最后# 显示图片cv2.imshow('test', img)cv2.waitKey(0)cv2.destroyWindow('test') 通道的拆分与合并拆分: cv2.split合并: cv2.merge 123456789101112# 图片的分辨率为800*200(宽*高)，这里b, g, r设为随机值，注意dtype属性b = np.random.randint(0, 255, (200, 800), dtype=np.uint8)g = np.random.randint(0, 255, (200, 800), dtype=np.uint8)r = np.random.randint(0, 255, (200, 800), dtype=np.uint8)# 合并通道，形成图片img = cv2.merge([b, g, r]) # opencv的通道是b在最前,r在最后# 显示图片cv2.imshow('test', img)cv2.waitKey(0)cv2.destroyWindow('test')# 拆分通道, 每个通道都变成了单通道数组[blue, green, red] = cv2.split(img) 将 BGR 转换成 RGB 通道顺序12345# 方法一:rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)# 方法二:rgb_img = img[:, :, [2, 1, 0]]rgb_img = img[:, :, ::-1] PIL 与 cv2 格式互相转换PIL.Image读入的图片数据类型不是 numpy 数组, 它的size属性为 (w, h), 利用np.array转换成 numpy 数组后, 它的通道顺序为 (r, g, b) 1234567891011from PIL import Imageimport numpy as np# PIL to cv2pil_img = Image.open(img_path)print(pil_img.size) # (w, h)np_img = np.array(pil_img)cv2_img = np_img[:, :, ::-1] # 交换通道# cv2 to PILpil_img = Image.fromarray(cv2_img[:, :, ::-1]) 用matplotlib显示图像1234b,g,r=cv2.split(img)img2=cv2.merge([r,g,b])plt.imshow(img2)plt.show() 截取子图12# 已知子图左上角坐标 (x1, y1), 右下角坐标(x2, y2)crop_img = img[y1:y2, x1:x2, :] opencv 核心图像算法cv2123456789101112131415161718import cv2image_path = './test.jpg'src_image = cv2.imread(image_path) # 读取图片size = src_image.shape # 获取图片的尺寸, 返回一个元组: (height, width, depth)copy_image = src_image.copy() # 复制图片cv2.imwrite('./dst_test.jpg', copy_image) # 保存图片cv2.imshow('image', src_image) # 显示图片# 利用下标访问指定像素for x in range(src_image.shape[0]): # 以行为主, 行数=图片height for y in range(src_image.shape[1]): # 列数 = 图片width src_image[x,y] = (255,0,255) # (blue, green, red) 值越高表示对应颜色越显著, 全0为黑, 全255为白]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十二章～第十三章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter12_13%2F</url>
    <content type="text"><![CDATA[第一章 ~ 第八章第九章 ~ 第十一章第十二章 类和动态内存分配动态内存和类复习示例和静态成员 所有的对象都共用一个静态成员副本。 不能在类声明中初始化静态成员变量 ，这是因为声明描述了如何分配内存，但并不分配内存。p428 对于静态类成员，可以在类声明之外使用单独的语句来进行初始化，这是因为静态类成员是单独存储的，而不是对象的组成部分。注意下面的初始化语句，指出了类型，并使用了作用域运算符，但没有使用关键字static。p428 1int StringBad::num_strings = 0; 在构造函数中使用new来分配内存时，必须在相应的析构函数中使用delete来释放内存。如果使用new[]来分配内存，则应使用delete[]来释放内存。p429 特殊成员函数 C++提供了一些特殊的成员函数，它们会在一定条件下自动创建。p432 默认构造函数，如果没有定义构造函数; 默认析构函数，如果没有定义; 复制构造函数，如果没有定义; 赋值运算符，如果没有定义; 地址运算符，如果没有定义。 C++11提供了另外两种特殊成员函数：移动构造函数和移动赋值运算符。这将在第十八章讨论。 其中，隐式地址运算符返回调用对象的地址（即this指针的值），这与我们的初衷一致。主要引起问题的是复制构造函数和赋值运算符。p432 复制构造函数 用于将一个对象复制到 新创键 的对象中。也就是说，它用于初始化过程中，而不是常规的复制过程中。类的复制构造函数原型通常如下：Class_name(const Class_name&amp;); p433 何时调用复制构造函数：每当程序产生了对象副本时，都将使用复制构造函数，如用赋值语句初始化，函数按值传递等。具体地说，当函数按值传递对象或者函数按值返回对象时，都将使用复制构造函数。因此，进行传递时，多用引用，可以减少调用复制构造函数的时间和存储新对象的空间。 默认复制构造函数的功能：默认的复制构造函数逐个复制非静态成员，复制的是成员的值（按值复制，浅复制），如果成员本身就是类对象，则将使用这个类的复制构造函数来复制成员对象。静态函数不受影响，因为它们属于整个类。 复制构造函数容易引起的问题 如果常规构造函数中设置了一个静态变量用于计录创建对象的个数，那么就应在复制构造函数中显示写出该逻辑，否则会导致计数结果不准确。p434 由于隐式复制构造函数是按值进行复制的。在这成员变量中含有指针时是十分危险的，因为这样依赖两个对象中的成员指针就会指向同一块内存，如果其中一个对象被释放后，其指针指向的内存块可能会导致不确定的错误。另外，程序有可能会因为两次释放同一块内存而导致程序终止。具体的错误取决于系统和相关实现。p435 深度复制。深度复制可解决上述的问题。复制时应当复制指针指向内容的副本，并将副本的地址赋给新的对象，这样一来，两个对象就是完全独立的。必须自定义复制构造函数的原因就在于，一些类成员是使用new初始化的、指向数据的指针，而不是数据本身。p435 警告: 如果类中包含了使用 new 初始化的指针成员, 应当自定义一个复制构造函数, 以复制指向的数据, 而不是指针, 这被称为 深度复制. 复制的另一种形式(成员复制或浅复制)只是复制指针的值. 因此, 浅复制仅仅复制指针本身的值, 而不会深入”挖掘”以复制指针指向的结构. 赋值运算符容易引起的问题 赋值运算符的完整函数原型如下：Class_name &amp; Class_name::operator = (const Class_name&amp;);。它接受并返回一个指向类对象的引用。 赋值运算符的功能以及何时使用：将已有的对象赋给另一个对象时，将使用重载的复制运算符。（注意，初始化赋值时，不会调用赋值运算符重载，而是调用复制构造函数）。p436 赋值的问题：主要是由于浅复制造成的数据问题，由于赋值时是按值赋值的，导致指针变量会指向相同的地址。解决的方法是提供赋值运算符（进行深度复制）的定义，其实现与复制构造函数相似，但也有一些差别。p436 由于目标对象是已经存在的对象，所以它可能引用了以前分配的数据，因此函数应使用delete[]来释放这些数据。 函数应当避免将对象赋给自身，否则，给对象重新赋值前，释放内存操作就已经删除了对象内容。这一点可以通过程序逻辑实现：if(this == &amp;s) return *this; 函数应返回一个指向调用对象的引用。通过返回一个对象，函数可以想常规赋值操作那样，连续进行赋值。 改进后的新String类 下面两种方式分配的内存量相同，区别在于前者与类析构函数兼容，而后者不兼容。p438 12str = new char[1]; //与析构函数中的delete []str; 兼容str = new char; C++11空指针： 在C++98中，字面值0有两个含义：可以表示数字值零，也可以表示空指针，这使得阅读程序的人和编译器难以区分。有些程序员使用(void *) 0来标识空指针(空指针本身的内部表示可能不是零), 还有些程序员使用NULL, 这是一个表示空指针的 C 语言宏定义. C++11提供了更好的解决方案，引入新关键字nullptr，用于表示空指针。原来的表示依然合法，但建议使用nullptr。 p438 静态成员函数： 不能通过对象调用静态成员函数，也不能使用this指针。如果静态成员函数是在公有部分声明，则可以使用类名和作用域解析符来调用它。 其次，由于静态成员函数不与特定的对象相关联，因此只能使用静态数据成员，不能访问其他成员数据。p441 较早的get(char *, int)版本在读取空行后，字符串中第一个字符将是一个空字符。较新的C++标准则会返回false。p446 在构造函数中使用new时应注意的事项 使用new初始化对象的指针成员时，必须注意下面几项：p446 如果在构造函数中使用new来初始化指针成员，则应在析构函数中使用delete。 new和delete必须相互兼容。new对应于delete，new[]对应于delete[]。 如果有多个构造函数，则必须以相同的方式使用new，要么都带中括号，要么都不带。因为只有一个析构函数，所有的构造函数都必须与它兼容。然而，可以在一个构造函数中使用new初始化指针，而在另一个构造函数中将指针初始化为空（0或C++11中的nullptr），这是因为delete（无论是否带[]）可以用于空指针。 应定义一个复制构造函数，通过深度复制将一个对象初始化为另一个对象。它应分配足够的空间来存储复制的数据，并复制数据，而不仅仅是数据的地址。另外，还应该更新所有受影响的静态类成员。 应定义一个赋值运算符，通过深度复制将一个对象赋值给另一个对象。它应该检查自我赋值的情况，释放成员指针以前指向的内存，复制数据而不仅仅是数据的地址，并返回一个指向调用对象的引用。 有关返回对象的说明返回指向const对象的引用 返回的对象应该是函数参数传递进来的对象，并且是const的，所以需要返回const引用。p449 返回指向非const对象的引用 返回的对象应该是函数参数传递进来的对象，但是由于参数不是const的，所以返回非const（当然也可以返回const）。常见的两种情况是重载赋值运算符以及重载与count一起使用的&lt;&lt;运算符。p449 返回对象 如果返回的对象是被调用函数中的局部变量，则不应该按引用方式返回它，因为在调用函数执行完毕时，局部对象将调用其析构函数。p450 返回const对象 返回const对象，该对象将不能作为右值，此时可以避免一些不必要的错误。p450 使用指向对象的指针 利用new创建一个对象并令指针指向它，该对象会被分配到堆内存中，直到使用delete为止，该对象一直存在。p453 1String * favorite = new String; 使用对象指针时，需要注意几点：p454 使用常规表示法来声明指向对象的指针：String * glamour; 可以将指针初始化为指向已有的对象：String * second = &amp;string_first; 想要将创建一个新的对象，可以使用new来初始化指针：String * glamour = new String 可以通过间接访问运算符-&gt;来调用类的方法。 可以通过解除引用运算符（ * ）来活得对象。 定位new运算符： 定位new运算符可以在分配内存时指定内存的位置：Sting * p1 = new (buffer) String; 。但是在使用时要注意以下几点：p457 确保定义不同的对象时，二者使用的内存地址是不同的，且内存单元之间没有重叠 delete可以与常规new运算符配合使用，但不能与定位new运算符配合使用。有时需要通过显示调用析构函数来释放对象的内存。 对于使用定位new运算符创建的对象，应以与创建顺序相反的顺序进行删除。原因在于，晚创建的对象可能依赖于早创建的对象。另外，仅当所有对象（定位new创建的）都被销毁后，才能释放用于存储这些对象的缓冲区。 复习各种技术 p459 初始化列表 如果Classy是一个类，而mem1、mem2和mem3都是这个类的数据成员，则类构造函数可以使用如下的语法来初始化数据成员。该语法需要注意以下几点：p464 这种格式只能由于构造函数; 必须用这种格式来初始化非静态const数据成员（C++11之前）; 必须用这种格式来初始化引用数据成员。123Classy:Classy(int n, int m) :mem1(n), mem2(0), mem3(n*m+2)&#123; ...&#125; 第十三章 类继承13.1 一个简单的基类 从一个类派生出另一个类时,原始类称为基类,继承类称为派生类。p481 13.1.1 派生一个类 使用公有派生，基类的公有成员将成为派生类的公有成员。基类的私有部分只能通过基类的公有和 保护 方法访问。 class A : public B //A继承自B，且是公有继承 p483 13.1.2 构造函数：访问权限的考虑创建派生类对象时，程序首先会创建基类对象，这意味着 基类对象应该在程序进入派生类构造函数之前被创建 。C++使用成员初始化列表语法来完成这种工作。 派生类构造函数必须调用基类的构造函数，利用成员初始化列表语法来显式调用基类构造函数，如果没有显式调用，那么就会调用默认的基类构造函数。p48412345678910derived::derived(type1 x, type2 y) : base(x,y)&#123; //显式调用基类B的构造函数 ...&#125;derived::derived(type1 x, type2 y)&#123; //该代码与下面的等效 ...&#125;derived::derived(type1 x, type2 y) : base()&#123; ...&#125; 有关派生类构造函数的要点如下： 首先创建基类对象（在进入派生类构造函数之前就被创建） 派生类构造函数应通过 成员初始化列表 将基类信息传递给基类构造函数 派生类构造函数应初始化派生类新增的数据成员 释放对象的顺序与创建对象的顺序相反，即首先执行派生类的析构函数，然后自动调用基类的析构函数。p485 如果没有在成员初始化列表中提供基类构造函数，程序将使用默认的基类构造函数，成员初始化列表只能用于构造函数。p486 派生类与基类之间的特殊关系 当基类的方法不是私有的（可以是公有或保护），派生类可以使用基类的方法。p488 基类指针/引用可以在不进行显式类型转换的情况下指向/引用派生类对象（反之不行）。但是只能调用基类方法。p488 继承：is-a关系 公有继承是最常用的方式（另外还有私有和保护继承），它建立一种is-a-kind-of（是一种）的关系，术语简称is-a。is-a关系的派生类对象也是一种基类对象，凡是可以对基类执行的操作，都可以对派生类执行。p489 多态公有继承 实现多态公有继承的方式有以下两种：p490 在派生类中重新定义基类的方法 使用虚方法（关键字virtual只用与类声明的方法原型中，不用于方法定义） 如果要在派生类中重新定义基类的方法，通常应将基类方法声明为虚的。这样，程序将根据对象类型而不是引用或指针的类型来选择方法版本。为基类声明一个虚析构函数也是一种惯例。p493 在派生类方法中，标准技术是使用作用域解析符来调用基类方法。p496 静态联编和动态联编 将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编（binding）。在编译过程中进行联编被称为静态联编（static binding），又称为早期联编（early binding）。但是有时候，无法在编译时确定使用哪个函数块（如虚函数），所以，编译器必须生成能够在程序运行时选择正确的虚方法的代码，这被成为动态联编（dynamic binding），又称为晚期联编（late binding）。p502 指针和引用类型的兼容性 将派生类引用或指针转换为基类引用或指针被称为向上强制转换（upcasting）。如果不使用显式类型转换，则向下强制转换是不允许的。p502 隐式向上强制转换使基类指针或引用可以指向基类对象或派生类对象，因此需要动态联编。C++使用虚成员函数来满足这种需求。p503 虚成员函数和动态联编 编译器对非虚方法使用静态联编，对虚方法使用动态联编。因为虚方法是根据对象类型来选择的，而对象类型只有在运行时才能确定。非虚方法则是根据引用或指针的类型来选择方法，它们可以在编译时确定。p503 为什么有两种联编类型以及为什么默认为静态联编： 动态联编的好处是可以重新定义类方法，但是在运行阶段跟踪对象类型会产生一定的开销，这使得动态联编没有静态联编效率高，这也是选择静态联编为默认方式的原因。p503 虚函数的工作原理： C++规定了虚函数的行为，但将实现方法留给了编译器作者。通常，编译器处理虚函数的方法是，给每个对象添加一个隐藏成员。隐藏成员中保存了一个指向函数地址数组的指针。这种数组成为虚函数表（virtual function table，vtbl）。虚函数表中存储了为类对象进行声明的虚函数的地址。 派生类对象将包含一个指向独立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址;如果没有重新定义虚函数，则保存函数原始版本的地址。调用虚函数时，程序将查看存储在对象中的vtbl地址，然后转向相应的函数地址表。p504 根据工作原理可以得出，使用虚函数时，在内存和执行速度方面有一定的成本（虽然非虚函数效率高，但不具备动态联编功能），包括：p505 每个对象都将增大，增大量为存储地址的空间; 对于每个类，编译器都将创建一个虚函数地址表（数组）; 对于每个函数调用，都需要执行一项额外的操作，即到表中查找地址。 有关虚函数注意事项 虚函数的一些要点：p505 在基类方法的声明中使用关键字virtual可使该方法在基类以及所有的派生类（包括儿子的儿子）中是虚的。 如果使用指向对象的引用或指针来调用虚方法，程序将使用为对象类型定义的方法，而不使用为引用或指针类型定义的方法。这称为动态联编或晚期联编。这种行为非常重要，因为这样基类指针或引用可以指向派生类对象。 构造函数不能是虚函数。创建派生类对象时，将调用派生类的构造函数，而不是基类的构造函数，然后，派生类的构造函数会使用基类的构造函数，这种顺序不同于继承机制。因此，派生类不急成基类的构造函数。p505 除非类不是基类，否则应该将析构函数声明为虚函数。p505 友元不能是虚函数，因为友元不是类成员，而只有成员才能是虚函数。p505 如果派生类没有重新定义函数，将使用该函数的基类版本。如果派生类位于派生链中，则将使用最新的虚函数版本。p506 重新定义继承的方法并不是重载，而是将基类的方法隐藏，也可以看作是重写。由此，得出两条经验规则：第一，如果重新定义继承的方法，应确保与原来的原型完全相同，但如果返回类型是基类引用或指针，则可以修改为指向派生类的引用或指针。第二，如果基类声明被重载了，则应在派生类中重新定义所在的基类版本。如果只定义类部分版本，则其他版本将被隐藏。另外，如果不需要修改，则新定义直接调用基类版本即可，如void derived::show() { const(base::show()); } 访问控制：protected 对于外部世界来说，保护成员的行为与私有成员相似，但对于派生类来说，保护成员的行为与公有成员相似。p507 对于数据成员最好采用私有访问控制，同时通过基类方法使派生类能够访问基类数据。对于成员函数来说，保护访问控制很有用，它让派生类能够访问公众不能使用的内部函数。 抽象基类 从多个类中抽象出它们的共性，将这些共性放在一个抽象基类（abstract base class，ABC）中，然后再从该ABC派生出这些类。ABC中有些方法不能直接实现，C++通过纯虚函数（pure virtual function）提供未实现的函数。纯虚函数声明的结尾处为=0，如下所示： 1virtual double Area() const = 0; // a pure virtual function 当类声明中包含纯虚函数时，则不能创建该类的对象，而只能作为基类使用。要成为真正的ABC，必须至少包含一个纯虚函数，原型声明中的=0是虚函数成为纯虚函数，一般纯虚函数没有定义，但C++允许纯虚函数有定义，即可以把所有派生类的某个共同操作作为纯虚函数的定义，然后在派生类重写该纯虚函数时调用。p509 13.7 继承和动态内存分配如果基类使用动态内存分配，并重新定义赋值和复制构造函数，那么将怎么影响派生类的实现呢？有以下几种情况： 13.7.1 派生类不使用new 如果基类使用了动态内存分配，而派生类未使用，那么就不需要为派生类定义显式析构函数、赋值和复制构造函数。 p516 13.7.2 派生类使用new 如果派生类使用了new，就必须为派生类定义显示析构函数、赋值和复制构造函数。p517 13.8 类设计回顾13.8.1 编译器生成的成员函数 默认构造函数 &emsp;&emsp;如果没有定义任何构造函数，编译器将定义默认构造函数。 复制构造函数&emsp;&emsp;如果程序没有使用（显式或隐式）复制构造函数，编译器将提供原型，但不提供函数定义。 复制运算符&emsp;&emsp;默认的赋值运算符用于处理同类对象之间的赋值。不要将赋值与初始化混淆了。如果语句创建新的对象，则是用初始化。如果语句修改已有对象的值，则是赋值。 13.8.2 其他的类方法 构造函数 构造函数不同于其他类方法，因为它创建新的对象，而其他类方法只是被现有的对象调用。这是构造函数不被继承的原因之一，继承意味着派生类对象可以使用基类的方法，然而，构造函数在完成其工作之前，对象并不存在。 析构函数 一定要定义显式析构函数来世放类构造函数使用new分配的所有内存，并完成类对象所需的任何特殊的清理工作。对于基类，即使它不需要析构函数，也应提供一个虚析构函数。 转换 使用一个参数就可以调用的构造函数定义了从参数类型到类类型的转换。 按值传递对象引用传递 返回对象和返回引用 有些类方法返回对象，有些返回引用，返回对象涉及生成返回对象的临时副本。优先返回引用，但函数不能返回在函数中创建的临时对象的引用。 使用const可以是用const来确保方法不修改参数。 注意，如果函数将参数声明为指向const的引用或指针，则不能将该参数传递给另一个函数，除非后者也确保了参数不会被修改。 13.8.3 公有继承的考虑因素 is-a关系 要遵循is-a关系。如果派生类不是一个特殊的基类，则不用使用公有派生。 什么不能被继承 构造函数是不能继承的，也就是说，创建派生类对象时，必须调用派生类的构造函数。 C++11新增了一种能够继承构造函数的机制，但默认是不能继承构造函数。 析构函数也是不能继承的。 赋值运算符是不能继承的。 赋值运算符 私有成员与保护成员 虚方法 析构函数 友元函数]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DenseCap---CVPR2016]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DenseCap%2F</url>
    <content type="text"><![CDATA[本篇论文解读的排版主要参见原文的格式，针对原文中的每一个小节进行展开，有的是对原文的一个提炼和简单概括，有的是对原文中涉及但是又没有详细介绍的技术的补充和说明。原文连接：https://cs.stanford.edu/people/karpathy/densecap/作者个人主页：https://cs.stanford.edu/people/jcjohns/PS：本篇博文不是对原文的简单翻译，论文中每一处涉及到的知识点以及论文中没有提及的技术细节，本文都会做一定的补充说明，如果还有什么看不懂的地方的话，可以留言一起讨论，我会尽量在24小时内回复。 (正文所有图片中的ksws0292756水印是我的CSDN博客) 这里输入题注 摘要&emsp;&emsp;这篇文章的主要工作是对图像的dense captioning。所谓dense captioning，就是要描述的对象不再是一幅简单的图片，而是要将图片中的许多局部细节都都用自然语言描述出来。这篇文章所做的工作可以说是object detection和image captioning的一般化，即当描述的语言是一个单词的时候，就可以看作是object detection，当描述的对象是整幅图片的时候，就成了普通的image captioning。这篇文章的主要贡献在于提出了一个Fully Convolutional Localization Network（FCLN）网络结构，该网络结构可以进行端到端式的训练，无需额外的候选区域生成模型（以及整合到网络内部），只需要进行一轮优化和前馈计算就可以得到输出结果。网络模型有三部分组成：卷积网络（Convolutional Network）、密集定位层（dense localization layer） 和RNN语言模型。 介绍&emsp;&emsp;本小节主要介绍了dense cationing任务的定义，以及相对应的object detection和image caotioning方面的研究。大家可以自己看一下原文 相关工作&emsp;&emsp;这里只给出重要的2篇论文（作者主要是在这两篇论文的几处上进行模型构建的），其他的可以参见原文 Faster R-CNNhttp://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networksDeep Visual-Semantic Alignments for Generating Image Descriptionshttps://cs.stanford.edu/people/karpathy/deepimagesent/ 模型总览目标：设计一个可以标定出感兴趣区域并且用自然语言描述其中内容的网络框架模型挑战与难点：在兼顾高效性和有效性的前提下，开发出一个可以支持端到端训练并且只需一次优化的模型 模型框架 卷积网络（Convalutional Network）&emsp;&emsp;作者采用了基于VGG-16的网络结构，包含13层卷积核为3×3的卷积层和4层池化核为2×2的最大池化层（原本的VGG是5层池化层，这里作者做了一些小改动，改为4层），因此，对于大小为$3×W×H$的图片，经过卷积网络后，输出结果是$C×W’×H’$的特征图谱，这里$C=512$，$W’=\lfloor\frac{W}{16}\rfloor$，$H’=\lfloor\frac{H}{16}\rfloor$，该特征图谱就是下一层Fully Convolutional Localization Layer的输入。 全卷积定位层（Fully Convolutional Localization Layer）输入和输出 输入 : 来自卷积网络的特征图谱$C×W’×H’$（size任意） 输出 : 输出B个候选区域的表征向量（定长），每个特征向量都包含下面三个关键信息： 候选区域的坐标：输出形式是一个$B×4$的矩阵，每行代表一个候选区域的坐标 候选区域的置信分数：一个长度为$B$的一维列向量，向量内每个元素都给出了候选区域的得分。得分越高说明越可能是真实区域 候选区域的特征：输出形式为$B×C×X×Y$的特征集合，这里B代表区域个数，$X×Y$表示特征图谱的大小（注意，这里的size已经是固定的），$C$代表特征的维度 &emsp;&emsp;这里额外说明一下，在CNN阶段我们不需要指定输入图片的大小（传统CNN分类任务由于FC全连接层的限制，使得输入图片的大小是固定的），因为这里我们关心的是图片的特征，而卷积层和池化层根本不care输出尺寸的多少，它们只负责拿到前一层的特征图谱（feature map）。&emsp;&emsp;但是为什么这里的输出必须是定长的向量呢？主要是因为后面RNN模型的制约，由于RNN模型接受的数据必须的定长的，所以在全卷积定位层（FCL）阶段的最后一步，我们需要使用双线性插值的方法来使输出成为定长的特征向量。 卷积锚点（Convolutional Anchors）&emsp;&emsp;这里的工作主要参考自Faster R-CNN。主要思想是借助一系列具有平移不变性的锚点（anchors）来预测候选区域的位置和大小，具体做法如下：&emsp;&emsp;对于大小为$W’×H’$的特征图谱来说，将图谱中的每一个像素点都做为一个锚点（anchor）（锚点数量为$W’×H’$个），将该点反向映射会原始图像$W*H$中，然后基于该锚点，画出不同宽高比和大小的若干个“锚箱”（anchor box）。下图所示是3个具有相同大小但是不同宽高比的锚箱示例（分别为1:1，1:2，2:1）。 &emsp;&emsp;如果采用Faster R-CNN的设置，即每个锚点对应3个不同的size取值（$128^2，256^2，512^2$）和3个不同的宽高比取值（1:1，1:2，2:1），因此，每个锚点对应的锚箱数量为$k=9$，在本文中采用的是$k=12$，具体对应多少个size和宽高比文中并没有给出。对于这$k$个锚箱，定位层（localization layer）会通过回归模型来预测相应的置信分数（score）和位置信息（scalars）。具体的计算过程是将特征图片作为输入，经过一个卷积核为$3×3$的卷积层（filter个数为256)，然后再经过一个卷积核为$1×1$卷积层（filter个数为$5k$，这里$k$代表anchor box的数量）,所以这一层的最终输出是$5k×W’×H’$的张量，包含了所有锚点对应的置信分数和位置信息。 边界回归（Box Regression）&emsp;&emsp;边界回归主要是对刚刚预测的候选区域的一次精修，进行边界回归的原因主要是当前的候选区域可能与真实区域并不是特别匹配，如下图所示： &emsp;&emsp;图中，绿色框代表真实区域，红色框代表目前的候选区域，我们可以看到，候选区域虽然可以判断出区域内存在物体（飞机），但是它的定位并不是很准取，这时候就可以利用box regression来对边框进行微调。核心思想是利用线性回归得到关于边框的四个位移参数$（t_x,t_y,t_w,t_h）$，然后通过下面的式子对候选区域的中点$（x,y）$和size$（w，h）$进行更新 x=x_a+t_xw_a$$$$ y=y_a+t_yh_a$$$$ w=w_aexp(t_w) $$$$h=h_aexp(h_w)有关box regression的详细讲解可以参考这篇论文：https://blog.csdn.net/zijin0802034/article/details/77685438（PS：这篇论文的讲解是基于R-CNN的，其中的符号表示与本文有些出入，如$t_x,t_y$在R-CNN中代表的是真实区域的中心坐标，看的时候注意一下各个符号都表达了什么，不要搞混了） 区域采样&emsp;&emsp;以图像大小为$W=720，H=540$，锚箱（anchor box）数量为$k=12$的情况为例，得到的候选区域的个数应该为$\lfloor\frac{720}{16}\rfloor×\lfloor\frac{540}{16}\rfloor×12=17820$（文章中写的是17280，我感觉应该是写错了）。为了降低成本，我们只取这些候选区域的子集来参与训练过程和测试过程，具体选取原则如下： 在训练阶段: 采用Faster R-CNN的方法，采集一个大小为$B=256$的minibatch来进行训练，在这$B$个候选区域中，有至多$B/2$个正样本，其余均为负样本。采集时，如果所有的候选区域中（这里为17280个）正样本的数量不足$B/2$个，那么就由负样本补充，所以，最终的minibatch中正样本的数量$B_P\le B/2$，而负样本的数量$B_N=B-B_P$。正样本和负样本的定义如下： 正样本：候选区域与一个或多个真实区域的面积相交部分大于70% 负样本： 候选区域与所有真实区域的面积相交部分小于30% 在测试阶段: 基于每个候选区域的置信分数，采用非极大抑制选取$B=300$个置信分数最高的候选区域 &emsp;&emsp;非极大抑制：这里的抑制就是忽略的意思，非极大抑制的意思就是忽略那些与具有最高score值的候选区域的相交面积大于设定阈值的其他候选区域。这样做的目的主要是为了减少重叠区域的输出，从而更精细化的定位目标位置。 &emsp;&emsp;经过以上操作，最终我们可以得到关于这B个候选区域的位置坐标和置信分数，表示为B×4和B×1的张量，这就是定位层（localization layer）的输出。 双线性插值（Bilinear Interpolaion） &emsp;&emsp;在经过采样后，我们得到的各个候选区域是具有不同大小和宽高比的矩形框。为了与全连接层（主要进行识别分类）和RNN语言模型的进行建立连接，我们必须将候选区域提取成固定大小的特征表示向量。对于这一问题，Faster R-CNN提出了感兴趣区域池化层（RoI pooling layer），具体方法是大小为$W’×H’$的卷积特征图谱进行划分，得到具有$X×Y$个小网格的网格图，然后根据最大池化的原理，将小网格内的像素最大值作为代表该网格的特征像素，最终可以得到定长为$X×Y$的特征向量。划分示意图如下所示。 &emsp;&emsp;RoI pooling layer需要两个输入：卷积特征图谱和候选区域坐标。但是在应用梯度下降时，该方法只能对特征图谱采用反向传播（BP）算法，而不能对候选区域坐标使用BP算法，为了克服这个缺点，在本文中，作者采用了双线性插值。&emsp;&emsp;具体来说，就是对于任意的特征图谱$U（C×W’×H’）$和候选区域，我们要将其放缩成大小为$（C×X×Y）$的特征图谱$V$，放缩过程按照如下步骤进行： 计算$V$到 $U$的反向投影坐标值，例如对于特征图谱$V$中的任意一点坐标$(x_{i,j}^V,y_{i,j}^V)$，投影到$U$中的坐标值为x_{i,j}=x_{i,j}^V*\frac{W'}{X}，y_{i,j}=y_{i,j}^V*\frac{H'}{Y}很容易看出，这里$x_{i,j}和y_{i,j}$的值均为浮点数，然而图像的像素坐标在计算机中必须为整数，所以这里坐标$(x_{i,j},y_{i,j})$对应的像素点是虚拟像素点，并不是$U$中实际存在的点。 按照双线性插值法，得到$U$中$(x_{i,j}^U,y_{i,j}^U)$坐标点的像素值，该像素值就是$V$中对应点的像素值$V_{c,i,j}$，计算公式如下V_{c,i,j}=\sum_{i'=1}^{W’}\sum_{j'=1}^{H'}U_{c,j',j'}k(i'-x_{i,j})k(j'-y_{i,j})，其中 ，k(d)=max(0,1-|d|) 利用上面的方法，计算$V$中所有像素点的坐标值，得到$C×X×Y$的特征图谱 &emsp;&emsp;对于上面的步骤可能理解起来不太直观，下面我们利用一个例子来帮助理解，我们假定源图谱U的大小为4×4，目的图谱V的大小为3×3，如下图所示 如果我们想要知道V中某点的坐标值，以V的中心点为例，我们先计算出V反向投影到U的坐标值$(x_{i,j},y_{i,j})$ x_{i,j}=1*\frac{4}{3}=1.333，y_{i,j}=1*\frac{4}{3}=1.333然后，利用上面的公式计算$V_{c,i,j}$的值 V_{c,i,j}=95*0.667*0.667+32*0.667*0.333+156*0.333*0.667+84*0.333*0.333=93.336\approx 93 最终，对于$B$个候选区域，我们会得到形式为$B×C×X×Y$的一个张量，这就是localization layer的最终输出。 识别网络（Recognition Network）&emsp;&emsp;识别网络以一个全连接的神经网络，它接受的是来自定位层的候选区域的特征矩阵（定长）。将每个候选区域的特征拉伸成一个一维列向量，令其经过两层全连接层，每次都使用ReLU激活函数和Dropout优化原则。最终，对于每一个候选区域，都会生成一个长度为$D=4096$的一维向量。&emsp;&emsp;将所有的正样本的存储起来，形成一个$B×D$形状的矩阵，将该矩阵传送到RNN语言模型中。另外，我们允许识别网络对候选区域的置信分数和位置信息进行二次精修，从而生成每个候选区域最终的置信分数和位置信息，这一次的精修与之前的box regression基本是一样的，只不过是针对这个长度$D$的向量又进行了一次box regression而已（在R-CNN论文中已经指出，理论上是可以通过迭代使用box regression来不断让候选区域无限逼近真实区域的，不过实现表明，对最终的结果提升并不大）。 RNN语言模型（RNN Language Model）&emsp;&emsp;将图片的特征图谱输入到RNN语言模型当中，从而获得基于图片内容的自然语言序列。基本方法是将识别网络的输出结果进行编码（每一个候选区域到对应一个编码），记为$x_{-1}=CNN（I）$，然后将该区域对应的真实描述$s_1,…,s_T$也进行编码，记为$x_1,…x_T$，这里，$x_i$就是对应的$s_i$的向量编码。于是，我们就得到了长度为T+2的单词向量序列$x_{-1},x_0,x_1,…,x_T$，其中$x_{-1}$代表这候选区域的图像信息，$x_0$是特殊的开始标志，$x_1,…x_T$代表每一个单词的向量编码，将这T+2长度的向量序列feed到RNN中，训练出一个预测模型。接着，在预测阶段，训练好的RNN语言模型的 输入是$x_{-1}$和$x_0$ （START token），然后根据公式$h_t,y_t=f(h_{t-1},x_t)$分别计算出隐藏状态$h_0$和单词向量$y_0$。这里，$y_t$是一个长度为$|V|+1$的向量，$V$代表词库的size，多出来的1是一个特殊的END标志，根据$y_0$预测出第一个word，然后将该word再作为下一层LSTM网络（RNN中的语言模型网络）的输入，预测出第二个word，一直 递归 的重复这个过程，直到输出的word是END标志为止。该预测过程可以用下面的公式和两张示意图表示。 x_{-1}=CNN(I)$$$$x_t=W_eS_t，t\in \{ 0...N-1 \} $$$$p_{t+1}=LSTM(x_t)，t\in \{ 0...N-1\}&emsp;&emsp;上式中，$x_{-1}$代表$CNN$生成的$D$维图像特征向量，并且它将作为整个$RNN$语言模型的初始输入，$S_t$代表RNN模型生成的一个个单词（word），其中$S_0$是一个特殊的开始标志，$p_{t+1}$代表第$t+1$个单词在整个单词表中的分布率，它是$p(S_{t+1}|I,S_0,…,S_t)$的简写形式，之后，选取$p_t$概率最大的元素作为句子中第$t$个单词的输出，如果概率最大的元素对应的是$END$标识符，则句子生成结束，迭代终止。 有关RNN模型生成图片描述的详细介绍可以参考下面两篇论文：Show and Tell: A Neural Image Caption Generatorhttps://arxiv.org/abs/1411.4555Deep Visual-Semantic Alignments for Generating Image Descriptionshttps://arxiv.org/abs/1412.2306 损失函数（Loss function）&emsp;&emsp;这篇文章训练时的损失函数有五个，如下图所示，首先是lacalization layer定位层的边框位置回归和置信分数两处损失函数，前者使用smooth L1 loss，后者使用binary logistic loss。损失函数的数学定义可以参考Fast R-CNN和Faster R-CNN里面的损失函数。&emsp;&emsp;接下来是Recognition Network的两处损失函数，该层和localization layer一样，也是边框位置和置信分数两个损失函数，最后是语言模型的损失函数，采用的取交叉熵（cross-entropy）损失函数。&emsp;&emsp;作者利用bathch size和sequence length对所有的损失函数都进行了归一化。经过不断测试，作者发现将后续区域边框的初始权重设为0.1，将图片描述的置信权重设为1.0，是比较高效率的初始化设置。文中并没有对损失函数给出详细定义，通过查阅相关论文后，得到了各个损失函数的详细定义如下： 置信度损失函数（binary logistic loss） : l(w,b)=-\sum_{i=1}^{m}lnP(y_i|x_i;w,b)$$$$P(y=1|x)=\frac{e^{w^Tx+b}}{1+e^{w^Tx+b}}$$$$P(y=0|x)=\frac{1}{1+e^{w^Tx+b}}这里，$w$为矩阵，$b$为向量，$x_i$是输入的图像区域的特征图谱，$y_i$为期望的真实输出（is or not object） 边框位置回归损失函数（smooth L1 loss）: L_{loc}(t^u,v)=\sum_{i\in \{x,y,w,h\}}smooth_{L_1}(t_i^u-v_i) smooth_{L_1}(x)=\begin{cases} 0.5x^2& \text{if |x|]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy和tensorflow中的关于参数axis的辅助理解方法]]></title>
    <url>%2Fz_post%2FPython-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-numpy%E5%92%8Ctensorflow%E4%B8%AD%E7%9A%84%E5%85%B3%E4%BA%8E%E5%8F%82%E6%95%B0axis%E7%9A%84%E8%BE%85%E5%8A%A9%E7%90%86%E8%A7%A3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一句话总结：固定除axis之外的其他维度，在axis指定的维度上进行函数操作，轴的计数按shape的形状从左往右为0轴，1轴，2轴…（详解请看下面的推导） 首先声明：axis的默认值不是0，这一点我发现很多博客文章都搞错了。所以一定要知道，axis的默认值不是0，0代表0轴，而默认值是将整个shape拉伸成一个一维向量，在整个向量上求解过 axis的默认值不是0当给axis赋值为0时，和采取默认值时的表现是完全不同的，从下面的代码就可以看出。 1234567891011121314&gt;&gt;&gt; z #大小为2×3×4的数组array([[[ 2, 3, 4, 8], [ 3, 1, 4, 1], [ 6, 3, 2, 6]], [[10, 2, 45, 2], [ 2, 4, 5, 10], [22, 4, 4, 1]]])&gt;&gt;&gt; np.sum(z,axis=0) # axis=0array([[12, 5, 49, 10], [ 5, 5, 9, 11], [28, 7, 6, 7]])&gt;&gt;&gt; np.sum(z) #axis不指定，取默认值154 理解axis参数的作用刚开始学习numpy和tensorflow的朋友经常遇到类似下面这样的一些函数： 123456789101112#pythonx=[[1,2],[5,1]]x=np.array(x)z1=np.max(x,axis=0)z2=np.max(x,axis=1)#tensorflowx=tf.constant([[1.,2.],[5.,2.]]) x=tf.shape(x) z1=tf.reduce_max(x,axis=0)#沿axis=0操作 z2=tf.reduce_max(x,axis=1)#沿axis=1操作 类似的还有argmax，sum等等函数，它们都含有一个名为axis的参数，那这个参数到底是什么意思呢？一句话总结就是：沿着axis指定的轴进行相应的函数操作 直接看这句话可能看不懂，下面用一个最简单的例子来说明一下。 123456789101112import numpy as np#首先，创建一个2×3维的numpy的array数组x=[[2,3,4],[1,2,5]]x=np.array(x)#然后，计算不同参数下np.max的输出print(np.max(x))# 5print(np.max(x,0))# [2,3,5]print(np.max(x,1))# [4,5] 可以看到，如果不知道axis，那么默认就是取得整个数组的最大值，这相当于把多维数组展开成一维，然后找到这个一维数组里的最大值。而当axis=0时，直观上来看就是取得每一列的最大值，源数组总共为2行3列，所以最终的输出包含3个元素。当axis=1时，就相当与是取每一行的最大值。 上面的理解方式在二维数组还比较直观，但是如果数组达到3维4维甚至更高维时，就不能简单的从行列角度出发去理解了，这时应该考虑从“轴”的角度来看。首先，明确一点，“轴”是从外向里的，也就是说，最外层的是0轴，往内一次是1轴，2轴… 。 具体可以看下面的例子： 12345678910&gt;&gt;&gt; zarray([[[ 2, 3, 4, 8], [ 3, 1, 4, 1], [ 6, 3, 2, 6]], [[10, 2, 45, 2], [ 2, 4, 5, 10], [22, 4, 4, 1]]])&gt;&gt;&gt; z.shape(2, 3, 4) 可以看到，这是一个2×3×4的三位数组，其中0轴对应第一维（2），1轴对应第二维（3），2轴对应第三维（4）。当我们指定了函数按某一轴来计算时，函数的输出数组的shape就是去掉当前轴的shape，如下所示。 123456&gt;&gt;&gt; np.max(z,axis=0).shape(3, 4)&gt;&gt;&gt; np.max(z,axis=1).shape(2, 4)&gt;&gt;&gt; np.max(z,axis=2).shape(2, 3) 而对于输出数组的每一个元素output[i][j]的值，实际上就是z[i][...][j]集合中的最大值，如下面的代码所示。其中当axis=0时，输出数组output的shape为3×4，其中output.[2][3]的值，实际上就是z[0][2][3],z[1][2][3]的最大值，也就是（6，1）中的最大值，即为output.[2][3]=6。 再如axis=1时，输出数组output的shape为2×4，其中output.[1][2]的值，实际上就是z[1][0][2],z[1][1][2],z[1][2][2]中的最大值，也就是（45，5，4）中的最大值，即为output.[1][2]=45]。 12345678910&gt;&gt;&gt; np.max(z,axis=0)array([[10, 3, 45, 8], [ 3, 4, 5, 10], [22, 4, 4, 6]])&gt;&gt;&gt; np.max(z,axis=1)array([[ 6, 3, 4, 8], [22, 4, 45, 10]])&gt;&gt;&gt; np.max(z,axis=2)array([[ 8, 4, 6], [45, 10, 22]]) 数学公式总结用形式化的数学语言总结上面的过程就是：对于大小为[i,j,k]的输入数组z，假设axis=0，那么输出矩阵output的大小就为[j,k]，并且output的每一个元素的计算方式如下： x^{y^z}=(1+{\rm e}^x)^{-2xy^w}output[j,k]=\max_{i}(z[i,j,k])如果axis=1，那么输出矩阵output的大小就为[i,k]，并且output的每一个元素的计算方式如下： output[i,k]=\max_{j}(z[i,j,k])对于4维，5维甚至无限维的情况，计算方法是一样的，你不妨自己推导一下，如果有任何问题，欢迎可以在评论中留言。 另外，对于其他的sum，argmax等等函数中的计算方法也是一样的，只需要把函数max换成对应的函数即可，如下所示： sum： output[j,k]=\sum_{i}(z[i,j,k])argmax: output[j,k]=argmax_{i}(z[i,j,k])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 手册]]></title>
    <url>%2Fz_post%2FPython-%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[字符串固定字数, 不足的空格补齐12345str.ljust(10) # 左对齐 字符串长10位rjust，ljust和center三个方法来给字符串补全空格rjust，向右对其，在左边补空格ljust，向左对其，在右边补空格center，让字符串居中，在左右补空格 排序sorted: 返回一个新的 listlist.sort(): 改变 list 自身的值reverse 参数: 默认为 False, 升序, True 时变为降序 列表循环删除列表元素常见错误: 直接删除, 或者正序删除 正确做法: 使用 pop, 倒序删除 12for i in range(len(list)): list.pop() 使用切片, 遍历拷贝列表, 操作原始列表, 用 remove 删除, remove 会操作首个遇到的匹配元素, 相等元素删除, 删除哪个都一样 12345for x in enumerate(a[::]): a.remove(x)for x in enumerate(a[::-1]): a.remove(x) 遍历列表:123456789101112131415161718192021222324252627zz_list = ['a', 'b', 'c', 'd']for index in list: print(index) # 0 # 1 # 2 # 3for index in range(len(list)): print(index) # 0 # 1 # 2 # 3for index, val in enumerate(list): print(index, val) # 0 a # 1 b # 2 c # 3 d# 设置遍历的开始序号, val的输出不变for i, val in enumerate(list, 2): print(index, val) # 2 a # 3 b # 4 c # 5 d append() 方法追加单个元素 extend() 方法extend()函数用于在列表末尾一次性追加另一个序列中的多个值(用新列表扩展原来的列表).该方法没有返回值, 会直接在已经存在的列表中添加新的列表内容, extend和+=的作用差不多12345a= [[1,2,3],[4,5,6]]b= [['a','b','c'],['d','e','f']]a.extend(b)print(a)# [[1, 2, 3], [4, 5, 6], ['a', 'b', 'c'], ['d', 'e', 'f']] 序列切片(双冒号)Python序列切片地址可以写为 [开始(包含) : 结束(不包含) : 步长]. 当开始省略的时候, 默认从第0项开始, 当结尾省略的时候, 默认到数组最后, 当步长省略的时候, 默认为1. 步长可以为负数, 代表从右向左取数.123456a = range(10) # a = [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9]a[0:9:1] # [0, 1, 2, 3, 4, 5, 6, 7, 8] 包含开始下标, 不包含结束下标a[1::2] # [1, 3, 5, 7, 9]a[::3] # [0, 3, 6, 9]a[::-1] # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]a[::-2] # [9, 7, 5, 3, 1] update() 方法1dict.update(dict2) 将 dict2 中的键值更新到 dict 中, 对于存在的则覆盖原值, 对于不存在的则添加新的键值. 字典遍历字典:1zz_dict = &#123;'x': 1, 'y':2, 'z':3&#125; 遍历keys: 123456789# 输出均为: x y zfor key in zz_dict: print(key)for key in zz_dict.iterkeys(): print(key)for key in zz_dict.keys(): print(key) 遍历values: 123456# 输出均为 1 2 3for value in zz_dict.itervalues(): print(value)for value in zz_dict.values(): print(value) 遍历keys和values 123456# 输出为: x corresponds to 1 (其余两个也一样)for key, value in zz_dict.iteritems(): # python3 没有iteritems print(key, "corresponds to", value)for key, value in zz_dict.items(): print(key, "corresponds to", value) 字符串判断字符串是否为字母或者数字str.isalnum() 字母或数字str.isalpha() 字母str.isdigit() 数字str.isspace() 空白符, \t, \n, \r isdigit() 和 isnumeric() 的区别123456789101112131415161718192021222324num = "1" #unicodenum.isdigit() # Truenum.isdecimal() # Truenum.isnumeric() # Truenum = "1" # 全角num.isdigit() # Truenum.isdecimal() # Truenum.isnumeric() # Truenum = b"1" # bytenum.isdigit() # Truenum.isdecimal() # AttributeError 'bytes' object has no attribute 'isdecimal'num.isnumeric() # AttributeError 'bytes' object has no attribute 'isnumeric'num = "IV" # 罗马数字num.isdigit() # Truenum.isdecimal() # Falsenum.isnumeric() # Truenum = "四" # 汉字num.isdigit() # Falsenum.isdecimal() # Falsenum.isnumeric() # True ===================isdigit()True: Unicode数字，byte数字（单字节），全角数字（双字节），罗马数字False: 汉字数字Error: 无 isdecimal()True: Unicode数字，，全角数字（双字节）False: 罗马数字，汉字数字Error: byte数字（单字节） isnumeric()True: Unicode数字，全角数字（双字节），罗马数字，汉字数字False: 无Error: byte数字（单字节） str.rstrip()参数:chars: 指定删除的字符(默认为空格或换行符) 返回值:返回删除指定字符后的新字符串 备注:删除字符串末尾的指定字符(默认为空格或换行符) 1str.rstrip([chars]) str.strip()参数: 返回值: 备注:1str.strip([chars]) str.split()参数: 返回值: 备注:默认以空格进行分词 文件reduce() 函数reduce() 函数会对参数序列中元素进行累积 函数将一个数据集合(列表, 元组等) 中的所有数据进行以下操作: 用传给reduce中的函数function(有两个参数)先对集合中的第1,2个元素进行操作, 得到的结果再与第三个数据用function函数运算, 最后得到一个结果 语法: 1reduce(function, iterable[, initializer]) zip() 函数zip() 函数用于将可迭代的对象作为参数, 将对象中对应的元素打包成一个个 元组 ,然后返回有这些元组组成的 对象. ( 相比于python2中返回列表的方式, 这样做的好处是节约了不少的内存 )可以用list()转换或者dict()转换将对象转换成相应的数据类型如果各个迭代器的元素个数不一致, 则返回列表长度与最短的对象相同, 多出来的部分会被舍弃, 利用*号操作符, 可以将元组解压成列表. 123456789101112131415161718192021a = [1,2,3]b = [4,5,6]c = ['a','b','c','d','e','f']zip_ab = zip(a,b)print(zip_ab) # &lt;zip object at 0x104605348&gt;print(dict(zip_ab)) # &#123;1: 4, 2: 5, 3: 6&#125;# !!!注意, 一旦将zip_ab转换成dict以后, zip_ab内部就为空了!! 例如, 再次调用上面的语句:print(dict(zip_ab)) # &#123;&#125;# 但是zip_ab对象本身不会消失, 地址仍然不变print(zip_ab) # &lt;zip object at 0x104605348&gt;zip_abc = zip(a,b,c) # 注意, 三个元素的zip是不能转换成dict类型的print(zip_abc) # &lt;zip object at 0x1046054c8&gt;print(list(zip_abc)) # [(1, 4, 'a'), (2, 5, 'b'), (3, 6, 'c')]zip_abc = zip(a,b,c)z_a, z_b, z_c = zip(*zip_abc) # 利用zip(*)可以将zip对象重新解压, 返回类型是元组print(z_a) # (1,2,3)print(z_b) # (4,5,6)print(z_c) # ('a','b','c') getattr() 函数getattr()函数用于返回一个对象的属性值, 语法如下1getattr(object, name[, default]) 参数: object: 对象 name: 字符串, 对象属性 default: 默认返回值, 如果不提供该参数, 在没有对应属性时, 将触发Attributerror @propertyhttp://python.jobbole.com/80955/ dir() 函数可以查看某个类的所有方法和属性 1members = [attr for attr in dir(classA)] 下划线 _var: 在一个模块中以单下划线开头的变量和函数会被默认当做内部函数, 在使用from a_module import * 导入时, 这部分变量和函数不会被导入. 不过如果使用import a_module导入模块时, 仍然可以用a_module._var的形式访问该变量或函数 var_: 有时候, 一个变量的最适合的名称已经被另一个关键字所占用. 在这种情况下, 可以在名称的末尾附加一个下划线来解决冲突. __var: 双下划线前缀会导致Python解释器重写属性名称, 以避免子类中的命名冲突. 举例来说, 如果在class Test中有一个成员__x, 那么当利用内置函数dir(Test)来查看类的属性时, 会发现__x被解释器重命名为_Test__x. 双下划线的名称修饰同样也适用于方法名称. __var__: 双下划线开头和结尾的是一些 Python 的特殊对象, 如类成员的 __init__, __del__, __name__, __call__ 等. Python 官方推荐永远不要讲这样的命名方式应用于自己的变量或函数. 有一种说法是说双下划线建议为类的私有成员, 但是 PEP8 当前的官方版本中并没有明说. _: 有时候我们会用一个独立的下划线作为一个名字, 这通常是用来指示某个变量时临时的或者无关紧要的. 类的特殊方法call()在 Python 中, 函数实际上也是一个对象: 123f = absprint(f.__name__) # 'abs'print(f(-123)) # 123 从上面可以看出, 函数是一个对象, 当它赋给另一个变量时, 该变量也是一个函数对象, 可以起到与原函数相同的效果. 在 Python 中, 一个类实例也可以变成一个可调用对象, 只需要实现一个特殊方法 __call__() 即可. 下面我们举例把 Person 类变成一个可调用对象: 123456789class Person(object): def __init__(self, name, gender): self.name = name self.gender = gender def __call__(self, friend): print("name:", self.name) print("friend:", friend) 接下来我们就可以将 Person 类的实例对象当做一个函数来使用, 如下所示: 1234p = Person('Bob', 'male')p('Tim')# name: Bob# friend: Tim getitem()凡是在类中定义了 __getitem__() 方法, 那么它的实例对象就是可以通过 [] 操作符来访问指定的成员或进行特定的行为, 大多数情况下会将该方法实现成通过索引来方法元素的形式. 1234567class DataBase(object): def __init__(self): super(DataBase, self).__init__() self.vals = [1,2,3,4,5] def __getitem__(self, key): return self.vals[key] setitem()使得可以通过 A[3] = 4, B[&quot;a&quot;] = 5 等方式来对类中的元素进行赋值 file()查看模块的路径 len()使得类对象可以使用 Python 的内建方法 len(), 返回你自定义的数值. 123456789101112131415class DictDemo: def __init__(self,key,value): self.dict = &#123;&#125; self.dict[key] = value def __getitem__(self,key): return self.dict[key] def __setitem__(self,key,value): self.dict[key] = value def __len__(self): return len(self.dict)dictDemo = DictDemo('key0','value0')print(dictDemo['key0']) #value0dictDemo['key1'] = 'value1'print(dictDemo['key1']) #value1print(len(dictDemo)) #2 repr()1234567891011121314151617181920212223242526272829303132333435363738class Test(object): def __init__(self, value='hello, world!'): self.data = value&gt;&gt;&gt; t = Test()&gt;&gt;&gt; t&lt;__main__.Test at 0x7fa91c307190&gt;&gt;&gt;&gt; print t&lt;__main__.Test object at 0x7fa91c307190&gt;# 看到了么？上面打印类对象并不是很友好，显示的是对象的内存地址# 下面我们重构下该类的__repr__以及__str__，看看它们俩有啥区别# 重构__repr__class TestRepr(Test): def __repr__(self): return 'TestRepr(%s)' % self.data&gt;&gt;&gt; tr = TestRepr()&gt;&gt;&gt; trTestRepr(hello, world!)&gt;&gt;&gt; print trTestRepr(hello, world!)# 重构__repr__方法后，不管直接输出对象还是通过print打印的信息都按我们__repr__方法中定义的格式进行显示了# 重构__str__calss TestStr(Test): def __str__(self): return '[Value: %s]' % self.data&gt;&gt;&gt; ts = TestStr()&gt;&gt;&gt; ts&lt;__main__.TestStr at 0x7fa91c314e50&gt;&gt;&gt;&gt; print ts[Value: hello, world!]# 你会发现，直接输出对象ts时并没有按我们__str__方法中定义的格式进行输出，而用print输出的信息却改变了 str()参见 __repr__() 代码示例 星号 *用于计算*: 乘法**: 乘幂 用于函数参数单星号: 将所有参数以 元组(tuple) 的形式导入123456def foo(param1, *param2): print(param1) print(param2)foo(1,2,3,4,5)# 1# (2,3,4,5) 双星号: 将所有参数以 字典 的形式导入123456def bar(param1, **param2): print(param1) print(param2)bar(1, a=2, b=3)# 1# &#123;'a': 2, 'b': 3&#125; 当然这两个用法可以同时出现在一个函数中:12345678910def fun(a, b=10, *args, **kwargs): print(a) print(b) print(args) print(kwargs)fun(1,2,3,4,e=5,f=6)# 1# 2# (3,4)# &#123;'e': 5, 'f': 6&#125; globals() 函数该函数会以字典类型返回当前位置的全部全局变量 stripe()readlines()lambda 函数https://www.cnblogs.com/evening/archive/2012/03/29/2423554.html 3.6新功能 f stringhttps://imliyan.com/blogs/article/Python3.6%E6%96%B0%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%AF%AD%E6%B3%95/ 包的导入机制模块和包的定义模块(module): 用来从逻辑上组织 Python 代码(变量, 函数, 类), 通常是一个.py文件.包(package): 定义了一个由模块和子包组成的 Python 应用程序执行环境, 本质上就是一个有层次的文件目录结果(必须带有一个__init__.py文件) import 的搜索路径 在当前目录下搜索 在环境变量PYTHONPATH中指定的路径列表中搜索 在 Python 安装路径的lib库中搜索 Python 所有加载的模型信息都存放在sys.modules结构中, 当import一个模块时, 会按如下步骤来进行: 如果import A, 检查sys.modules中是否已经有A, 如果有则不加载, 如果没有则为A创建module对象, 并加载A; 如果是from A import B, 先为A创建module对象, 再解析A(此时会加载并执行A中的所有代码), 从中寻找B并填充到A的__dict__中. 在导入模块的时候, 模块所在文件夹会自动生成一个__pycache__/module_name.cpython-35.pyc的文件. import module_name的本质是将module_name.py中的全部代码加载到内存中, 并将其赋值给与模块同名的变量, 这个变量的类型是class&lt;module&gt;.from module_name import name的本质是将指定的变量或者方法导入到当前的文件中import package_name的本质是执行该包下的__init__.py文件, 在执行文件后, 会在package_name目录下生成一个__pycache__/__init__cpython-35.pyc文件.from package_name import *的本质是导入__init__.py文件中的__all__列表(eg. __all__ = [&#39;L2Norm&#39;, &#39;MultiBoxLoss&#39;]). 相对导入和绝对导入绝对导入:12import A.Bfrom A import B 相对导入:12from . import B # . 代表当前路径from ..A import B # .. 代表上层路径, ... 代表上上层路径. 在没有明确指定包结构的情况下, Python 是根据__name__来决定一个模块在包中的结构的, 如果是__main__, 则它本身就是顶层模块, 没有包结构, 如果是A.B.C结构, 则A是顶层模块. Python 的导入方式的不同具有不同的规则: 如果是绝对导入, 一个模块只能导入自身的子模块或者和它的顶层模块同级别的模块及其子模块. 如果是相对导入, 一个模块必须有包结构且只能导入它的顶层模块内部的模块. 如果一个模块被直接运行, 则它自己为顶层模块, 不存在层次结构, 所以也找不到上层(..)的相对路径 Python2.x 默认为相对路径导入, 而 Python3.x 默认为绝对路径导入, 这样可以避免导入的子包覆盖掉标准库模块. 通常, 在 Python2.x 中, 我们利用下面的语句来使其导入规则遵循 Python3.x1from __future__ import absolute_import absolute_import的意思并不是将所有的导入都视为绝对导入, 而是指禁用隐式相对导入(implicit relative import), 关于隐式的显示的具体区别, 可以看下面的例子, 假设有如下的包结构:1234567891011121314thing└── __init__.py├── books│ ├── __init__.py│ ├── adventure.py│ ├── history.py│ ├── horror.py│ └── lovestory.py├── furniture│ ├── __init__.py│ ├── armchair.py│ ├── bench.py│ ├── screen.py│ └── stool.py 那么如果想在stool.py中导入bench模块, 则有如下几种方式:123import bench # 隐式相对导入from . import bench # 显式相对导入from furniture import bench # 绝对导入 隐式相对导入没有告诉解释器相对于谁进行导入, 默认相对于当前模块; 而显式相对导入则明确告诉了解释器相对于谁来导入. 以上导入方式的第三种是官方推荐的, 第一种是官方强烈不推荐的, Python3 中第一种导入方式只能用于导入sys.path中的模块. 注意, 还有相对导入的模块不能被直接运行, 会提示如下错误:1234Traceback (most recent call last): File "test.py", line 8, in &lt;module&gt; from .ssd import SSDModuleNotFoundError: No module named '__main__.ssd'; '__main__' is not a package 另外存在一种情况就是: 假如有两个模块a.py和b.py放在同一个目录下, 则可以直接在a.py中使用import b来导入模块b. 这是为什么呢? 我们上面说了在 Python3.x 中不能使用这种隐式相对导入, 但是这里却可以成功导入, 这是因为此时我们是直接运行a.py, 所以a.py和b.py的目录没有被当做一个包来处理, 因此不涉及相对导入和绝对导入的概念. 因此相对导入和绝对导入仅仅是针对于包而言的. 综合距离存在目录结构如下所示:123456789101112dirRoot└── __init__.py├── file1.py├── file2.py├── dirA│ ├── __init__.py│ ├── a1.py│ └── a2.py├── dirB│ ├── __init__.py│ ├── b1.py│ └── b2.py 直接运行a1.py, 并希望导入a2模块:1234# a1.pyimport a2 # 正确, 此时并未将 dirA 当做包来处理, a1.py 和 a2.py 相当于两个独立的模块from a2 import func_a2 # 正确from .a2 import func_a2 # 错误, 当进行相对导入时, 不能直接运行 直接运行file1.py, 并希望导入a1模块, 同时a1模块中需要导入a2模块:12345678910# file1.pyfrom dirA import a1a1.func_a1() # a1.py 中的函数a1.func_a2() # a1.py 中导入了 a2.py 的函数, 可以直接使用# a1.pyimport a2 # 错误, 此时由于 dirA 中有 __init__.py 文件, 因此会将 dirA 当做包来处理,# 由于 Python3.x 不允许使用隐式的相对导入, 因此该语句非法from a2 import func_a2 # 错误, 原因同上from .a2 import func_a2 # 正确, 当进行相对导入时, 需要使用显式的相对导入 直接运行file1.py, 并希望导入a1模块, 同时a1模块中需要导入dirB/b1模块(跨文件夹导入):12345678910# file1.pyfrom dirA import a1a1.func_a1() # a1.py 中的函数a1.func_a2() # a2.py 中的函数a1.func_b1() # b1.py 中的函数# a1.pyfrom .a2 import func_a2 # 推荐使用绝对导入 from dirA.a1 import func_a2from dirB import b1 # 由于运行的是 file1.py 文件, 因此顶层目录是 dirRootfrom dirB.b1 import func_b1 # 所以可以直接使用 dirB 包 直接运行a1.py, 并希望跨目录的导入dirB/b1模块. 由于这种跨目录的导入超越了顶层路径的限制, 因此必须使用sys.path.append()方法来额外添加搜索路径, 否则无法正常导123456# a1.pyimport syssys.path.append("../") # 将 dirA 的上一次目录添加到搜索路径中from dirB import b1 # 正确, 注意必须先添加 path, 然后再导入from dirB.b1 import func_b1 # 正确from .a2 import func_a2 # 这里是错误的, 当直接执行 a1.py 时, a1.py 中不能包含显式相对导入 获取 python 版本:1print(sys.version_info) 获取包的安装位置1print(cv2) 解析 xml 文件导入:12345import sysif sys.version_info[0] == 2: import xml.etree.cElementTree as ETelse: import xml.etree.ElementTree as ET 解析:1xmlfile = ET.parse(xmlfile_path) 123456789101112root = xmlfile.getroot() # 获取根节点root.tag # 标签root.attrib # 属性字典for child in root: # 迭代访问子节点 print(child.tag, child.attrib)# 可以通过索引访问嵌套节点的内容root[0][1].textElement.findall() #Element.find() # python 中 == 和 is 的区别== 只用于判断值是否相等is 用于判断两个对象是否为同一个实例https://www.cnblogs.com/CheeseZH/p/5260560.html 小整数对象池: Python 为了优化速度，使用了小整数对象池，避免为整数频繁申请和销毁内存空间。而Python 对小整数的定义是 [-5, 257)，只有数字在-5到256之间它们的id才会相等，超过了这个范围就不行了，同样的道理，字符串对象也有一个类似的缓冲池，超过区间范围内自然不会相等了]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《TensorFlow实战Google深度学习框架》]]></title>
    <url>%2Fz_post%2FTensorFLow-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-TF%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第九章～第十一章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter9_11%2F</url>
    <content type="text"><![CDATA[第一章 预备知识第二章 开始学习C++第三章 处理数据第四章 复合类型第五章 循环和关系表达式第六章 分支语句和逻辑运算符第七章 函数——C++的编程模块第八章 函数探幽第九章 内存模型和名称空间单独编译 头文件中常包含的内容： （不能将函数定义放在头文件中，容易出现重定义错误） p301 函数原型 使用#define或const定义的符号常量 结构声明 （结构声明不创建变量，只是告诉编译器如果创建该结构变量） 类声明 模板声明 内联函数 在同一个文件中只能将同一个头文件包含一次，利用下述C/C++技术可以避免多次包含同一个头文件。p302 1234#ifndef COORDIN_H_#define COORDIN_H_...#endif 多个库的链接： 不同的编译器可能会为同一个函数生成不同的修饰名称（取决于编译器设计人员），名称的不同将使链接器无法将一个编译器生成的函数调用与另一个编译器生成的函数定义匹配。在链接编译模块时，请确保所有对象文件或库都是由同一个编译器生成的。（如果有源代码，通常可以用自己的编译器重新编译源代码来消除链接错误）。p304 存储持续性、作用域和链接性 C++使用三种（在C++11中是四种）不同的方案来存储数据，这些方案的区别就在于数据保留在内存中的时间：p304 自动存储持续性 静态存储持续性 线程存储持续性（C++11） 动态存储持续性 作用域和链接 作用域（scope）描述了名称在文件（翻译单元）的多大范围可见。链接性（linkage）描述了名称如何在不同单元间共享。 自动变量的名称没有链接性，因为它们不能共享。p305 全局作用域是名称空间作用域的特例。 p305 自动存储持续性 C++11中的auto： 在C++11中，auto关键字用于自动类型推断。但在C语言和以前的C++版本中，auto用于显式的指出变量为自动存储（实际中很少很使用，因为默认就是自动存储类型）。在C++11中，这种用法不再合法。p307 函数及其中的变量存放于“栈”中——这是专门流出来的一段内存，栈的长度由具体的实现决定。p308 寄存器变量：在C++11中，关键字register的作用只是显示地指出变量是自动的。鉴于它只能用于原本就是自动的变量，使用它的唯一原因是，指出程序员想使用一个自动变量。保留该关键字的原因是避免使用了该关键字的现有代码非法。p309 静态持续变量 和C语言一样，C++也为 静态 存储持续性变量提供了3种链接性，这三种链接性都在整个程序执行期间存在，与自动变量相比，它们的寿命更长。p309 外部链接性（可在其他文件中访问） 内部链接性（只能在当前文件中访问） 无链接性（只能在当前函数或代码块中访问，与自动变量不同的是，就算不在函数中，变量也存在，只是不能访问） 由于静态变量的数目在程序运行期间是不变的，因此程序不需要使用特殊的装置（如栈）来管理它们。编译器将分配固定的内存块来存储所有的静态变量，这些变量在整个程序执行期间一直存在。另外，如果没有显式地初始化静态变量，编译器将把它设置为0。在默认情况下，静态 数组和结构将每个元素或成员的所有位都设置为0。p309 创建三种链接性的静态持续变量：p309 外部链接性：必须在代码块的外面声明 内部链接性：必须在代码块的外面声明，并使用static限定符 无链接性：必须在代码块内部声明，并使用static限定符123456789int global = 1000; //静态持续变量，外部链接性，作用域为整个文件static int one_file = 50; //静态持续变量，内部链接性，作用域为整个文件int main()&#123; ...&#125;void funct1(int n)&#123; static int count = 0; //静态持续变量，无链接性，作用域为局部 int llama = 0;&#125; 五种变量存储方式：p310 自动 寄存器 静态，无链接 静态，外部链接 静态，内部链接 关键字重载： 关键字的含义取决于上下文，static用于局部声明，以指出变量是无链接性的静态变量时，表示的是存储持续性。而用于代码块外的声明时，static表示内部链接性，因为位于代码块外的变量已经是静态持续性了。p310 静态变量的初始化： 静态变量有三种初始化方式：零初始化（变量设为零）、常量表达式初始化和动态初始化。 零初始化和常量表达式初始化被统称为静态初始化，这意味着在编译器处理文件时初始化变量，动态初始化意味着变量将在编译后初始化。p310 静态变量的初始化过程： 首先，所有静态变量都被零初始化，而不管程序员是否显式地初始化了它。接下来，如果使用常量表达式初始化了变量，且编译器仅根据文件内容（包括被包含的头文件）就可计算表达式，编译器将执行常量表达式初始化。必要时，编译器将执行简单计算。最后，剩下的变量将被动态初始化。 常量表达式并非只能是使用字面常量的算术表达式。（sizeof运算符也可以）p310 链接性为外部的变量通常简称为外部变量，也称全局变量，它们的存储持续性为静态，作用域为整个文件。p310 静态持续性、外部链接性 单定义规则（One Definition Rule，ODR）： 变量只能定义一次。为满足这种需求，C++提供了两种变量声明：p311 定义声明（简称定义）：为变量分配存储空间。 引用声明（简称声明）：不给变量分配存储空间，引用已有的变量。使用关键字extern12double up; //定义声明exterm int blem; //blem在别处定义 如果要在多个文件中使用外部变量，只需在一个文件中包含该变量的定义（单定义规则），但在使用该变量的其他所有文件中，都必须使用关键字extern声明它。p311 1234567//file01.cppextern int cats = 20; // 由于初始化，所以这里是定义而非声明int dogs = 22; //定义//即使去掉file01.cpp文件中的extern也无妨，效果相同。//file02.cppextern int cats; //使用extern且无初始化，说明使用的是其他文件的catsextern int dogs; //同上 静态持续性、内部链接性 将作用域为整个文件的变量声明为静态外部变量（内部链接性），就不必担心其名称与其他文件中的外部变量发生冲突123456789101112131415//file1int errors = 20;//file2int errors = 5;int main()&#123; cout&lt;&lt;errors; //报错，errors与file1中的外部变量重定义 ...&#125;//解决方法：file2static int errors = 5;int main()&#123; cout&lt;&lt;errors; // 输出5&#125; 静态存储持续性、无链接性 局部静态变量：虽然该变量只在该代码块中可用，但它在该代码块不处于活动状态时仍然存在。因此在两次函数调用之间，静态局部变量的值将 保持不变 。另外，如果初始化了静态局部变量，则程序 只在启动时进行一次初始化 。以后再调用函数时，将不会被再次初始化。p315 说明符和限定符 存储说明符（storage class specifier）：p317 auto（在C++11中不再是说明符） register static extern thread_local（C++11新增的） mutable：即使结构（或类）变量为const，其某个成员也可以被修改 cv-限定符（cv-qualifer）：p317 const：内存被初始化后，程序便不能再对它进行修改 volatile：即使程序代码没有对内存单元进行修改，其值也可能发生变化 在默认情况下全局变量的链接性为外部，但const全局变量的链接性为内部。因此，将一组常量放在头文件中，其他引用该头文件的文件都相当于自己定义了私有的常量，这就是能够将常量定义放在头文件中而不会重定义的原因。p318 如果处于某种原因，程序员希望某个常量的链接性为外部的，则可以使用extern关键字来覆盖默认的内部链接性，extern const int states = 50;，在这种情况下，必须在所有使用该常量的文件中使用extern关键字来声明它。p318 函数和链接性 C++不允许在一个函数中定义另一个函数，因此所有函数的存储持续性都自动为静态，即在整个程序执行期间都一直存在。p318 在默认情况下，函数的链接性为外部。即可以在文件间共享，使用extern来指出函数实在另一个文件中定义的（可选）。p318 可以使用关键字static将函数的链接性设置为内部，使之只能在一个文件中使用，必须同时在原型和函数定义中使用该关键字。p318 内联函数不受单定义规则的约束，这允许程序员能够将内联函数的定义放在头文件中。但是C++要求同一个函数的所有内联定义都必须相同。 p319 C++查找函数顺序：静态（在本文件中找）——外部（在所有的程序文件中找）——在库函数中找。因此如果定义了一个与库函数同名的函数，编译器优先使用程序员定义的版本（C++不推荐这样做）。p319 语言链接性 不同的语言采用了不同的链接性，为了解决这种问题，需要特别指定函数采用的链接性（默认为C++链接性）。p319 存储方案和动态分配 前面介绍的分配内存的5种方案（线程内存除外），它们不适用于C++运算符new分配的内存，这种内存被称为动态内存。动态内存由运算符new和delete控制，而不是由作用域和链接性规则控制。 p320 使用new运算符初始化： 1234567891011//如果要为内置的标量类型分配存储空间并初始化，可在类型名后面加上括号和初始值int *pi = new int(6);double *pd = new double(99.99);//如果要初始化常规结构或数组，需要用大括号的列表初始化，这要求编译器支持C++11.struct where &#123;double x; double y; double z;&#125;;where *one = new where&#123;2.5, 5.3, 6.2&#125;;int *ar = new int [4]&#123;2,4,6,8&#125;;//列表初始化也可以用于单值变量int *pin = new int&#123;6&#125;;double *pdo = new doubel&#123;99.99&#125;; new失败时，在最初的10年中，C++在这种情况下让new返回空指针，但现在将引发异常std::bad_alloc。p320 运算符new和new[]分别调用函数1和2，同样delete和delete[]调用3和4。p320 123456789101112void * operator new(std::size_t);void * operator new[](std::size_t);void * operator delete(void *);void * operator delete[](void *);//std::size_t是一个typedef，对应于合适的整型int *pi = new int;//该式会被转换为下式int *pi = new(sizeof(int));int *pa = new int[40];//同样，转换为下式int *pa = new(40*sizeof(int));delete pi;//同样，转换为下式delete(pi); 定位new运算符。p321 名称空间传统的C++名称空间 一些基本术语：p324 声名区域：变量可以进行声明的区域。对于全局变量，其声明区域为所在的文件，对于局部变量，其声明区域为所在的代码块。 潜在作用域：变量的潜在作用域从声明点开始，到其声明区域的结尾。因此潜在作用域比声名区域小。 作用域：变量对程序而言可见的范围。变量并非在其潜在作用域内的任何位置都可见，如被另一个嵌套声明区域中的同名变量隐藏。作用域小于潜在作用域。 新的名称空间特性 一个名称空间中的名称不会和另一个名称空间的相同名称发生冲突，利用新的关键字namespace可以创建名称空间：p325 12345678910111213141516171819202122namespce Jack&#123; double pail; void fetch();&#125;namespace Jill&#123; double fetch; int pal;&#125;//名称空间是开放的，可以重复使用namespace来将名称添加到名称空间中namespace Jack&#123; char * goose(const char*); //将goose添加到Jack名称空间（已有pail和fetch）&#125;//可以在另一个文件中使用namespce为函数原型写出定义namespace Jack&#123; void fetch()&#123; ... &#125;&#125;//使用作用域解析运算符来使用名称空间Jack::pail = 12.35;Jill::pal = 1;Jack::fetch(); 名称空间可以是全局的，也可以位于另一个名称空间中，但不能位于代码块中。保持，在默认情况下，在名称空间中声明的名称的链接性是外部的（除非使用了const）。p326 using声明和using编译指令： p326 using声明：using Jack::fetch 使特定的标识符可用（可以用在代码块中）。 using编译指令：using namespace Jack 使整个名称空间可用（可以用在代码块中，放在代码块中时，虽然它只在该代码块中可见，但是其作用域不是布局的）。p328 使用using编译指令和使用多个using声明是不一样的。假设名称空间和声明区域定义了相同的名称。如果试图使用using声明将名称空间的名称导入该声明区域，则这两个名称会发生冲突，从而出错。如果使用using编译指令将该名称空间的名称导入该声明区域，则局部版本将隐藏名称空间版本。p328 推荐使用using声明而不是using编译指令，因为前者更安全。在引入的名称有相同局部名称时，前者会发出错误提示，后者只会隐藏名称空间版本而不进行提示。p329 名称空间可以嵌套：1234567891011121314151617181920namespce elements&#123; namespce fire&#123; int flame; &#125; using Jill::fetch; using namepace Jack; float water;&#125;using namespace elements;using namespace elements::fire;//访问Jill::fetch，由于在elements中声明了Jill::fetch，所以以下两种名称空间都可用Jill::fetch;elements::fetch;using namespace elements;//这条编译指令与下面两条编译指令等价using namespace elements;using namespace Jack;namespace ele = elements; //给elements创建别名 名称空间示例名称空间及其用途 指导原则：p334 使用在已命名的名称空间中声明的变量，而不是使用外部全局变量。 使用在已命名的名称空间中声明的变量，而不是使用静态全局变量。 如果开发了一个函数库或类库，将其放在一个名称空间中。 仅将编译指令using作为一种将旧代码转换为使用名称空间的权益之计。 不要在头文件中使用using编译指令。首先，这样做掩盖了要让哪些名称可用，另外，包含头文件的顺序可能影响程序的行为。 导入名称时，首选使用作用域解析运算符或using声明的办法。 对于using声明，首选将其作用域设置为局部而不是全局。 第十章 对象和类过程性编程和面向对象编程 面向对象变成（OOP），首先从用户的角度考虑对象——描述对象所需的数据以及描述用户与数据交互所需的操作。p341 抽象和类类型是什么 指定基本类型完成了三项工作：p342 决定数据对象需要的内存数量 决定如何解释内存中的位（long与float位数相同，但含义不同） 决定可使用数据对象执行的操作或方法 10.2.2 C++中的类 类规范由两个部分组成：p342 类声明：以数据成员的方式描述数据部分，以成员函数（方法）的方式描述公有接口——提供了类的蓝图。 类方法定义：描述如何实现类成员函数——提供了类的实现细节。 类对象成员访问类型默认为私有private。结构体成员访问类型默认为公有public。p345 类和结构的区别： 实际上，在C++中，对结构进行了扩展，使之具有与类相同的特性。它们之间唯一的区别是，结构的默认访问类型是public，而类的默认访问类型是private。C++程序员通常使用类来实现类描述，而把结构限制为只表示纯碎的数据对象。（看上去类可以完美替代结构体，事实上也是这样，C++保留结构体的主要原因是为了向C兼容）。 实现类成员函数 定义成员函数时，使用作用域解析符（::）来标识函数所属的类。类方法可以直接访问类的组件（private和public均可，并且无需使用作用域解析符）。 p345 1234//无需使用public，因为在声明函数原型时已经指明了访问类型void Stock::update(double price)&#123; ...&#125; 内联方法： 方法定义位于类声明处的函数都将自动成为内联函数。类声明常常将短小的成员函数作为内联函数。内联函数的特殊规则要求在每个使用它们的文件中都对其进行定义，因此通常将内联定义放在定义类的头文件中。p347 12345678class Stock&#123; private: int shares; double share_val; void set_tot() &#123;total_val = shares*share_val;&#125; //自动成为内联函数 public: ...&#125; 类的每个新对象都有自己的存储空间，用于存储其内部变量和类成员。但是同一个类的所有对象共享同一组类方法，即每种方法只有一个副本。p348 使用类 要创建类对象，可以像基本类型一样声明类对象Stock kate，joe; //声明了2个对象kate和joe，也可以使用new为类对象分配存储空间。p349 修改实现 利用setf()控制输出格式，并将修改限定在实现文件中，以免影响程序的其他方面。p351 类的构造函数和析构函数声明和定义构造函数 构造函数没有返回类型。并且，构造函数的形参名称不能与类成员变量的形参名称完全相同，一种常见做法是在数据成员中使用m_前缀，或者用this指针this-&gt;company = company。p3531234567891011class Stock&#123; private: string m_company; ... public: Stock(const string &amp;company);更&#125;Stock::Stock(const string &amp;company)&#123; m_company = company;&#125; 使用构造函数 C++提供了两种使用构造函数来初始化对象的方式。p35412Stock garment = Stock(&quot;Furry&quot;); //显示调用构造函数Stock garment(&quot;Furry&quot;); //隐式调用构造函数，二者等价 默认构造函数 当且进党没有定义任何构造函数时，编译器会提供一个默认构造函数，它不接受任何参数，也不做任何操作。它可以使得下述语句正常运行：p354 1Stock cat; //隐式地调用了默认构造函数 如果为类定义了构造函数，程序员就必须为它显式提供默认构造函数，除非不使用无参数的对象声明Stock cat;，否则会报错。定义默认构造函数的方式有两种：p354 12Stock(const string &amp; company = &quot;default_company&quot;); //为所有参数提供默认值Stock(); //函数重载定义无参数的构造函数 隐式地调用默认构造函数时，不要使用圆括号：p355 1234Stock first(&quot;Furry&quot;); //隐式调用非默认构造函数Stock second(); //这是一条声明语句，指出second()是一个返回Stock对象的函数Stock third; //隐式调用默认构造参数Stock third = Stock(); //显式调用默认构造参数 接受一个参数的构造函数（或者其它的参数提供了默认值）允许使用赋值语法将对象初始化为一个值。p362 1Classname object = value; 带参数的构造函数也可以是默认的构造函数，只要所有参数都有默认值。但是只能有一个默认构造参数，也就是说，一旦所有参数都提供了默认值，就不能再声明无参数的构造函数，否则会产生二义性错误。 p433 析构函数 如果程序员没有提供析构函数，编译器将隐式的声明一个析构函数，析构函数没有返回类型，也没有参数，在声明时，需要在类型前加上波浪号：p355 1234567class Stock&#123; public: ~Stock(); //声明 &#125;Stock::~Stock()&#123; //定义&#125; 编译器调用析构函数的时机：p356 静态存储类对象：在程序结束时自动被调用 自动存储类对象：在程序执行完代码块时自动被调用 new创建的对象：当使用delete来释放对象内存时自动被调用 构造函数的另一种用法——赋值。语句1为初始化语句，语句2为赋值语句，构造函数会创建一个 临时 的对象，然后将该对象的值赋给已经存在的对象stock1，之后编译器会自动调用析构函数 删除该临时对象 。p361 123Stock stock1 = Stock(&quot;test1&quot;);stock1 = Stock(&quot;test2&quot;);//如果既可以通过初始化，也可以通过赋值来设置对象的值，则应采用初始化方式，通常这种方式的效率更高。 可以使用C++11的列表初始化方式来作用于类，前提是提供了相应的构造函数。p361 12Stock hot_tip = &#123;&quot;Plus&quot; ,100, 45.0&#125;;Stock jock&#123;&quot;Sport&quot;&#125;; 以上两个声明中，用大括号括起的列表与下面的构造函数匹配：1Stock::Stock(const std::string&amp; co, long n =0, double pr = 0.0); 另外，C++11还提供了名为std::initialize_list的类，可将其用作函数参数或方法参数的类型。这个类可表示任意长度的列表，只要所有的列表项的类型都相同或可转换为相同的类型。（在16章介绍）。 C++的成员函数如果不修改调用对象，则应将其声明为const，将const关键字放在函数的括号后面。（放在前面就变成了返回类型为const double了）p36212345678class Stock&#123; public: double show() const; //const成员函数声明&#125;double Stock::show() const&#123; //const成员函数定义&#125; this指针 this指针指向用来调用成员函数的对象（this被作为隐藏参数传递给方法）。一定要注意this是一个指向对象的指针，所以在使用时要按照指针的方式。p36412this-&gt;shares; //用间接成员运算符-&gt;引用对象的成员return *this; //返回this指向的对象 对象数组 利用对象数组可以创建同一个类的多个对象。p368 123456Stock mystuff[4]; //调用默认构造函数Stock stocks[4]=&#123; //为每个元素调用指定的构造函数 Stock(&quot;NanoSmar&quot;); Stock(); //显示调用默认构造函数 //stocks[2]和stock[3]未指明构造函数，将调用默认构成函数&#125; 初始化对象数组的方案是，首先使用默认构造函数创建数组元素，然后花括号中的构造函数将创建临时对象，然后将临时对象的内容复制到相应的元素中。因此，要创建类对象数组，则这个类必须有默认构造函数。p369 类作用域 C++类引入了一种新的作用域：类作用域。在类中定义的名称（如类数据成员名和类成员函数名）的作用域都为整个类，作用域为整个类的名称只在该类中是已知的，在类外是不可知的。要调用公有成员函数，必须通过对象访问。同样，在定义成员函数时，必须使用作用域解析符。 作用域为类的常量 直接在类中声明const常量是非法的，因为声明类只是描述了对象的形式，并没有创建对象。因此，在创建对象前，将没有用于储存值的空间。p371 实现“类的常量”的两种方式： 方式1：使用枚举，在类中声明一个枚举，用枚举为 整型常量 提供作用域为整个类的符号名称。 方式2：使用static，这将创建一个常量，该常量将于其他静态变量存储在一起，而不是存储在对象中。该常量被所有的类对象共享。123456class Bakery&#123; private: const int Months = 12; //非法，无法编译 enum &#123;Months = 12&#125;; //未提供枚举名，这种方式声明枚举并不会创建类数据成员，Months只是一个符号名称，在编译时，将用12来替换它。 static const int Months = 12; //C++98中，不能存储double常量，C++11消除了这种限制&#125; 作用域内枚举 传统的枚举如果两个枚举定义中的枚举量名称相同，则会发生冲突，C++利用类作用域的方法消除了这种冲突。p372 123456789//传统枚举量，产生冲突enum egg &#123;Small, Medium, Large, Jumbo&#125;;enum t_shirt &#123;Small, Medium, Large, Xlarge&#125;;//类作用域，不冲突。 也可以利用关键字struct代替class。enum class egg &#123;Small, Medium, Large, Jumbo&#125;;enum class t_shirt &#123;Small, Medium, Large, Xlarge&#125;;//使用时用枚举名和作用域解析符来限定枚举量：egg choice = egg::Large;t_shirt t_choice = t_shirt::Large; C++11还提高了作用域内枚举的类型安全，在有些情况下，常规枚举将自动转换为整型，如将其赋给int变量或用于比较表达式时，但作用域内枚举不能隐式地转换为整型。p372 枚举有某种底层整型类型表示，在C++98中，如何选择取决于实现，因此包含枚举的结构的长度可能随系统而异。对于作用域内枚举，C++11消除了这种依赖性。默认情况下，C++11作用域内枚举的底层类型为int。而常规枚举的底层类型依然随实现而异。另外，C++11提供了指定底层类型的语法。p3721enum class :short pizza &#123;Small,Medium,Large,XLarge&#125;; //:short将底层类型指定为short 抽象数据类型 类很适合描述ADT。公有成员函数接口提供了ADT描述的服务，类的私有部分和类方法的代码提供了实现，这些实现对类的客户隐藏。p373 第十一章 使用类运算符重载 要重载运算符，需使用被成为运算符函数的特殊函数形式。op必须是有效的C++运算符，不能虚构一个新的符号。p381123456789101112operatorop(argument-list)&#123;&#125;Stock::operator+(...)&#123;&#125;Stock::operator*(...)&#123;&#125;//当编译器发现了运算符的操作数是对应的对象是，会自动替换运算符为重载函数stock3 = stock1 + stock2; //左侧的操作数为调用对象，右侧为重载函数的参数stock3 = stock1.operator+(stock2); //用operaotr+重载函数替换“+” 计算时间：一个运算符重载示例添加加法运算符 对于连加或连乘，需要函数返回的是正确的对象类型。p38712t4 = t1 + t2 + t3;t4 = t1.operator+(t2.opertor+(t3)); //当operator+返回的函数类型复合其参数列表要求时，合法。 重载限制 重载的运算符不必是成员函数，但必须至少有一个操作数是用户定义的类型，这是为了防止用户为标准类型重载运算符。p387 使用运算符时不能违反运算符原来的语法规则，如双目不能重载成单目，同时，重载不会修改运算符的优先级。p387 不能创建新的运算符。p387 不能重载下面的运算符： p387 “sizeof”运算符 “.”成员运算符 “.* ”成员指针运算符 “::” 作用域解析运算符 “? :” 三目条件运算符 “typeid” 一个RTTI运算符 “const_cast” 强制类型转换运算符 “dynamic_cast” 强制类型转换运算符 “reinterpret_cast” 强制类型转换运算符。 “static_cast” 强制类型转换运算符 大多数运算符都可以通过成员或非成员函数进行重载，但下面 的运算符只能通过成员函数进行重载： p387 “=” 赋值运算符 “()” 函数调用运算符 “[]” 下标运算符 “-&gt;” 通过指针访问类成员的运算符 友元 除了private，public和protect控制的类访问权限外，C++提供了另外一种形式的方式权限：友元。通过让函数成为类的友元，可以赋予该函数与类的成员函数相同的访问权限。友元有3种： p391 友元函数 友元类 友元成员函数 创建友元函数 创建友元的第一步是将其原型 放在类声明中 ，并在原型声明前加上关键字friend：p391 123friend Time operator*(double m, const Time &amp; t);//可以解决2.85*time的乘法重载的问题，2.85不是Time对象，因此无法调用成员重载函数，需要借助友元非成员函数实现。//该声明意味着：1、虽然该函数是在类声明中声明的，但它不是成员函数，因此不能使用成员运算符来调用; 2、虽然该函数不是成员函数，但它与成员函数的访问权限相同。 编写友元函数的定义。因为它不是成员函数，所以无需使用类名::限定符，另外，定义时不要在函数头使用关键字friend。p392 常用的友元：重载&lt;&lt;运算符 cout是一个ostream对象，对于每种基本类型ostream类声明中都包含了相应的重载的operator&lt;&lt;()定义。因此，对于不同的基本类型，&lt;&lt;运算符在cout对象中可以表现出不同行为。p392 &lt;&lt;的第一种重载版本 如果直接通过类声明来重载operator&lt;&lt;()函数，那么在使用时就会像这样，time&lt;&lt;cout;，其中，time是Time类的实例，而cout是Time类重载函数的参数，为了看起来不那么迷惑，利用友元函数，使其第一个参数为ostream对象，这样一来，就可以使用cout&lt;&lt;time的形式（运算符左侧操作数是第一个参数）。p393 123456void operator&lt;&lt;(ostream &amp;os, const Time &amp;t)&#123; os&lt;&lt;t.hours&lt;&lt;t.minutes; //os是cout的引用，别名，省去了拷贝副本的时间&#125;cout&lt;&lt;time1; //等价于下式operator&lt;&lt;(cout,time1); &lt;&lt;的第二种重载版本 上面的重载方法有一些问题，那就是无法使用cout&lt;&lt;time1&lt;&lt;time2&lt;&lt;endl;这样的形式，解决方法如下：p394 1234ostream &amp; operator&lt;&lt;(ostream &amp; os, const Time &amp; t)&#123; os&lt;&lt;t.hours&lt;&lt;t.minutes; return os; //返回os的引用，以便实现连续使用&lt;&lt;的操作。&#125; 重载运算符：作为成员函数还是非成员函数 成员函数和非成员函数的实现方法二者均可，但不能都实现，否则会产生二义性错误。p398 再谈重载：一个矢量类 一个应用了运算符重载和友元设计的例子——矢量类。p398 类的自动转换和强制类型转换 只有一个参数的构造函数可以作为转换函数。如果使用关键字explicit限定了这种构造函数，则它只能用于显示转换，否则也可以用于隐式转换。p413 转换函数 转进行从对象到基本类型的转换，必须使用特殊的C++运算符——转换函数operator typeName()。创建转换函数时，需要注意以下几点：p415 转换函数必须是类方法 转换函数不能指定返回类型 转换函数不能有参数12345678operator double() const; //转换为double类型的函数原型。Stonewt::operator double() const&#123; // 转换函数的定义 return pounds;&#125;double d = stonewt; //隐式调用转换函数double d = double(stonewt); //显式调用转换函数 在进行类型转换时，一定要注意是否有二义性，如果有，编译器将产生错误。p418 提供执行自动、隐式的转换函数存在的问题是，在用户不希望进行转换时，转换函数也可能进行转换。消除这种隐患的方式是在转换函数原型前加上关键字explicit。（C++98不能将explicit用于转换函数，C++11可以）。另一种方法是使用功能相同的非转换函数，在进行转换时显式调用该函数即可。p419 总之，C++为类提供了下面的类型转换：p419 只有一个参数的类构造函数用于将类型与该参数相同的值转换为类类型。在构造函数声明中使用explicit可防止隐式转换。 被称为转换函数的特殊类成员运算符函数，用于将类对象转换为其他类型。没有返回类型、没有参数，名为operator typeName()。 将加法等二元运算符定义为友元可以让程序更容易适应自动类型转换。因为这会可以自动将对象类型转换成基本类型，或者将基本类型转换为对象类型进行运算。p420 将double变量与对象相加，由两种选择。一种是借助类型转换，另一种是在重载函数中显式接受double参数而不进行类型转换。 前者定义简单，但需要类型转换，增加了内存和时间开销。后面定义麻烦，需要写更多逻辑，但运行速度快。p421]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 软件配置]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-Ubuntu%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[快捷键在 nautilus 中: ctrl+l: 显示可复制的路径 esc(焦点在路径上): 复原 terminal: ctrl+q: 退出tab ctrl+t: new tab alt+1/2: prev/next tab always on top: https://www.maketecheasier.com/keyboard-shortcut-for-always-on-top-ubuntu/ 字体主题font: ubuntu Mono Regular 20DraculaBackgound color(#282a36) + Linux console(Palette) PDF 阅读器foxitReader Atomtheme: One-Light(UI)+Dracula(Editor)autocomplete-pathsmarkdown-preview-plussync-settings Personal Access Token: Gist ID: Gist Description: Last Backup Hash:12sync-settings:backupsync-settings:restore vim-mode-plus 自动换行: settings-&gt;editor-&gt;soft wrap vimctrlP: 杀手级插件, 可以快速打开最近访问的文件 与系统剪切板交互首先确认当前的 vim 支持系统剪切板:12vim --version | grep "clip"# +clipboard +xterm_clipboard 如果前面是减号说明不支持 原生的 vim 一般默认关闭剪切板支持, 要获得支持, 安装vim-gtk或者vim-gnome:1sudo apt install vim-gtk 在 windows &amp; OS X 中, 只有一个 clipboard, 所以*和+没有区别, 在其他系统中, 区别如下*寄存器: 使用 PRIMARY, 高亮区域+寄存器: 使用 CLIPBOARD, 复制区域 以下键位映射, 可以使得赋值粘贴更加方便(貌似不好用?)1234noremap &lt;Leader&gt;y "*ynoremap &lt;Leader&gt;p "*pnoremap &lt;Leader&gt;Y "+ynoremap &lt;Leader&gt;P "+p 显式指定默认使用的寄存器(亲测可行)12set clipboard = unnamed # *set clipboard = unnamedplus # +, 这样一来, y 和 p 指令都会默认使用 + 寄存器 其他系统的没有+clipboardDebian &amp; Ubuntu: Install vim-gtk or vim-gnome.Fedora: install vim-X11, and run vimx instead of vim (more info).Arch Linux: install gvim (this will enable +clipboard for normal vim as well). You could also use xclip, xcopy, or xsel to copy text to the clipboard; see the following questions for solutions oh-my-zshtheme: yszsh-autosuggestionzsh-syntax-highlightingautojump Chromedocker安装 nvidia-docker, 添加 keyhttps://nvidia.github.io/nvidia-docker/apt安装12sudo apt-get install -y nvidia-docker2sudo pkill -SIGHUP dockerd Guake TerminalDracula EverNoteFoxit ReaderTeamViewerSogouinputVMware WorkstationGpartedVCLWine Tim2019年wineQQ最完美解决方案https://www.lulinux.com/archives/1319 https://github.com/wszqkzqk/deepin-wine-ubuntu 截屏ubuntu 自带软件: screenshot如果没有可以用指令安装: sudo apt install -y gnome-screenshot然后在 “系统设置-&gt;键盘-&gt;快捷键-&gt;自定义快捷键” 中添加如下快捷键: 名称: ScreenShot 命令: gnome-screenshot -a 接着点击新添加的快捷键, 为其设置快捷键: Ctrl-Alt-A]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SqueezeNet (ICLR, 2017)]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SqueezeNet%2F</url>
    <content type="text"><![CDATA[文章: SqueezeNet: AlexNet-Level Accuracy With 50x Fewer Parameters And &lt; 0.5 Mb Model Size作者:备注: UC Berkeley, Stanford University 摘要在相同精度下, 小模型至少具有三点好处: (1) 在分布式训练时需要较少的服务器间的通信; (2) 导入到嵌入式设备上时需要更少的带宽; (3) 更适合部署到其他硬件上. 为了能够提供这些优势, 我们提出了一个小型的 CNN 框架, 名为 SqueezeNet. SqueezeNet 可以达到 AlexNet 的精度, 但是只需要 1/50 的参数量. 另外, 结合一些模型压缩技术, 我们可以将 SqueezeNet 压缩到不足 0.5Mb. Introduction and Motivation在给定精度小, 小模型具有三点好处: More efficient distributed training Less overhead when exporting new models to clients Feasible FPGA and embedded deployment 为了获得以上好处, 我们提出了 SqueezeNet. 此外, 我们还尝试了一种更有规律的方法来搜索 CNN 网络结构的设计空间. Related WorkModel Compression: SVD, Network Pruning, Deep Compression, EIE. CNN MicroArchitecture: 1x1, 3x3, 1x3, 3x3. CNN MacroArchitecture: Inception, ResNet Neural Network Design Space Exploration: Automated Search SqueezeNet: Preserving Accuracy With Few Parameters首先介绍模型的整体架构, 然后介绍 Fire module, 最后介绍如果构建 SqueezeNet. Architectural Design Strategies为了找到精度相当但是参数更少的模型, 我们采用了下面三种策略来设计 CNN 网络结构 Replace 3x3 filters with 1x1 filters. 1x1 的卷积核参数量比 3x3 卷积核的参数量少9倍, 因此优先选择; Decrease the number of input channels to 3x3 filters. 由于 3x3 卷积核参数量和输入通道输入通道数有关, 因此, 我们优先减少 3x3 卷积核的输入通道数. 我们利用 squeeze layers 来完成减少通道数的任务. Downsample late in the network so that convolution layers have large activation maps. 每一个卷积层输出的特征图谱的尺寸通过两方面因素控制: (1) 输入图片的尺寸; (2) CNN 中的 downsample 网络层. 通常, downsample 可以通过 conv 和 pooling 来实现. 如果浅层的网络具有较大的下采样步长, 那么大多数网络层的特征图谱的尺寸都会比较小, 反之, 则比较大. 我们的 Intuition 是, 在其他条件相同的情况下, 较大的特征图谱(利用 delayed downsampling 实现)可以具有更高的分类精度. 上面的前两条是在试图保持准确性的同时, 明智的减少 CNN 中的参数量, 第三条是在有限的资源条件下, 尽可能的提升检测的精度. The Fire Module我们定义了 Fire Modules 作为组成 SqueezeNet 的基本 Block. 它包括: 一个 squeeze conv 层(由 1x1 卷积层组成), 一个 expand 层(由 1x1 和 3x3 卷积层组成), Fire Modules 的结构如图1所示. 我们在 Fire Modules 中展示了三个可以调节的维度(超参数): $s_{1x1}, e_{1x1}, e_{3x3}$. 其中, $s_{1x1}$ 代表了 squeeze layer 中的 filters 的数量, $e_{1x1}$ 代表了 expand layer 中 1x1 filters 的数量, $e_{3x3}$ 代表了 expand layer 中 3x3 filters 的数量. 当我们使用 Fire Modules 时, 我们令 $s_{1x1}$ 小于 $(e_{1x1} + e_{3x3})$, 这样一来 squeeze layers 可以起到降低通道维度的作用. The SqueezeNet Architecture SqueezeNet 的结构如图2所示, 他的第一层是传统的卷积层, 之后由 8 个 Fire Modules 组成, conv10 也是传统的卷积层, 最后是由 GAP 和 Softmax 组成的分类层. 从网络的开始到结束, 我们会逐渐增加每个 Fire Module 模块的过滤器数量. SqueezeNet 会在 conv1, fire4, fire8, conv10 之后添加 max-pooling 层来进行下采样. 最终完整的 SqueezeNet 结构如表1所示. 其他的 SqueezeNet 细节如下所示: Padding: 为了使 1x1 和 3x3 滤波器的输出激活具有相同的高度和宽度, 我们在扩展模块的 3x3 滤波器的输入数据中添加了一个填充为零的1像素边框. ReLU Dropout: 在 fire9 使用, 0.5. 没有使用 FC 层 lr: 初始值为 0.04, 之后不断衰减 Caffe框架本身并不支持包含多个滤波器分辨率(例如 1x1 和 3x3 组成的 expand layer)的卷积层. 因此, 实际上我们是用了两个独立的卷积层来实现 expand layer. 我们将两个卷积层的输出结果在 channel 维度上连接起来, 这在数值上和 expand layer 是等价的. Evaluation of SqueezeNet表2显示了不同的模型压缩方法对于 AlexNet 的压缩效果, 以及 SqueezeNet 的效果表现(Deep Compression 貌似很有用). CNN MicroArchitecture Design Space ExplorationSqueezeNet 虽然已经达到了我们的预期目标, 但是还有许多未被探索的设计, 下面, 我们将分两部分进行介绍: MicroArchitecture(网络层的模块设计) 和 MacroArchitecture(顶层的整体架构设计).请注意, 我们这里的目标不是在每个实验中都最大化精度, 而是理解 CNN 架构选择对模型大小和精度的影响. 定义了各种超参数来决定模型的大小(通过改变通道数实现): $base_e = 128, incr_e = 128, pct_{3x3} = 0.5, freq = 2, SR = 0.5$. SR 对模型大小和精度的影响如图3(a)所示, 3x3 卷积核数量占比的多少对模型大小和精度的影响如图3(b)所示. CNN MacroArchitecture Design Space Exploration受到 ResNet 的启发, 我们对比了三种不同模型(结构如图2所示): 原始的 SqueezeNet 使用了简单的短接通路的 SqueezeNet 使用了复杂的短接通路的 SqueezeNet simple bypass: 在 Fire Modules 3, 5, 7, 9 之间添加了 bypass 连接, 令这些模型学习输入输出之间的残差. complex bypass: 当输入和输出的特征图谱的通道数不同时, 不能使用 simple bypass 连接, 因此, 我们利用 1x1 卷积核来实现 complex bypass 连接. 三种模型的精度和模型大小如表3所示. 简述 SqueezeNet 的原理SqueezeNet 定义了 Fire Modules 作为其基本的组成部件, Fire Modules 由 squeeze layer 和 expand layer 组成, 其中是通过 1x1 的卷积层实现的, 后者是通过 1x1 和 3x3 的卷积层实现的(这两层的输入都是 sequeeze layer, 输出会将二者在通道维度叠加). SqueezeNet 的第一层是传统的 7x7 卷积层, 之后由 8 个 Fire Modules 组成, conv10 也是传统的 1x1 卷积层, 最后是由 GAP 和 Softmax 组成的分类层. SqueezeNet 会在 conv1(自身也是下采样), fire4, fire8, conv10 之后添加 max-pooling 层来进行下采样(总步长为 32). 同时, SqueezeNet 受到 ResNet 的启发, 可以在 Fire Modules 3, 5, 7, 9 的输入和输出之间添加 bypass 连接, 令这些模型学习输入输出之间的残差(可以获得更高的精度). 对于通道数不同的其他 Modules, 可以通过 1x1 卷积层来建立 complex bypass).]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>网络结构</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未来工作计划]]></title>
    <url>%2Fz_post%2F%E5%85%B6%E4%BB%96-ToDoList%2F</url>
    <content type="text"><![CDATA[本篇文章因为某些原因被暂时加密, 如果希望继续浏览请输入正确的密码 Incorrect Password! No content to display! U2FsdGVkX1+5+9Y0UVI8xGWq9q57W7sA3oxmUuz99iG2+VkzOVELZCKJA44gmNjKDZ4QrMgQ4SddyKrHk6YwS6pOo0olV7DoyRBRSqvqwmPIcEIMt7aQ+3WE7/IP/WTGwgrTqWBI5SnZpDpiI8XrVsctGOvg/KTzGv04ZIFrysN7ex/PFTROTxhUgl+Tw4P97nN068HKG3+OE0rdaEXybjiC2KJB1qI4w44fZ1rXUGNLExsG9x3RLfW/Q0ddjvRi6pbI6R5R0Wyq+UTVb5YeDmJl4nGE0P1gM8ahVB259nIGvPttpc1kYivES3lewLUknD1EIjiP+qmyn/ccycxfHVcK+KINsh6zksuagGinWPvkuP6jnedJj3YKrD4hWTbLCPe5kavupyAyqdRORF6QrcXlS+jWgRlDN/WZewvmJmB41FSM14ewehVqsoas1eX99rkW/CEDaa0+WV71KJ6+fxef+R4kv3/pHeSl8LPbjW6SRsda99hjZhcQIrUTSj+S5JKltbslxvV8SuTtr8j5iq6s0fC0ZFTQaBDKUnn6oAxVP94uUcUqNhiK/h097UkYBT0+nZZVIFduni9owVT/6Tdh2Gh4oGuY7ycrgcS3AuFs0BOl3yda1T0v2g5/pZjG4qZD2wTVz9F6m6eg4te/zMQEAN3208a8vM39cN3hs7dwq1lis1cJVt8Va8QSBoKcwerzMbsKaMRpwBRZ7kiu4Xq2LKfhkDR9KIyVswduMN+3+yFCq7YC3C7wM8iJjxgJ+oOs75fNZ0JlVAey3MhWl2m436TizPqZB8ymfzM2XhJ6hbFtbPGimwsT3w9Pexxr18SaDg9hLOjRv2Zb1VakUpqwJn7PHP1Bd1XTVBhK6ZJ36NCPVb8z+gOBPizbuM5fPPIJ0k6TW33J/h1+jisy0MaecMZO0vzziMzJmGCyAQm73WL68REmXGtpnL1hjHpaz6b/YCAdURhugaTkjrxhpKUa+To1zapaBzCBnlau2fIfecdLUeSlXo2o3RcwYZwtrUCVav0e5qeBTFSy/0F2YibXOpChKJYaaSCysebfV1LSPKY/CYD4lXsVqJEi5C+xyMC6exJUQRi2HidGRdxa6yFhN8M4s+jtZ7EvtNO8QEi77PWnFSpTmMUmG1mezQ+xi8reRr/FKvLdgWYRHqzDM1WZlbZMX8xyvfBwaQCp0qVkvR++3ERJzht3NgG5USh5S+umdJTuyyt1iWVTXbVBX73ToSo63PrATYS7I+I8VwJNPPztJ5HTibjXLYgoVeurVRP0uIqjwiKDK3dUupOHJa6Mxza0cW1HBa6AY2yDiOQjQ3sj3NyAYjObAn98/RoKZ2xjZKhN6DmHfeNDCqcGWx+vXT0nv9776R7g1RkxFdiLCtErTxjUtZj6tB6iqtF+N6O4Kg0rQB3k2eEeTc8pKRW1FnpW+3I5pbtIv8AsFkF6p4dE+EtNIDSgmrIDWh0hfEsIFfKfK/orvVleEBdiHis67o/kgbqwdzMk0aIFIaURv62RmWVZP45y3bdyziLUTbBR0YKf1pwcfwMEfcODc09fL/fmKDhLBwD9mTUsW7obowAEffdPQxWEBRlYVGr0sVfww987Y58f4rPQ8glH3QsxTzeytw6u6YdvY/AVMFZNW9SlC4AMj2fM83H+fc6pXG/gF1qY0+W8rfaVoLYx13EXesfHxBilC2Jed7c42Oc+A/ZoghaKuN7Iqqm88ovZ7h6t5NaJqfO+DTzs9dQJiVDqpYr3m4/geLqzVu43CokRLpB/hO1l26kNhlBPJZLKu1nnpstPlaH+nOVb/ToVHIyGXoG9t9o0FNijw/P73dlPLnLr5UCwf2ARVSzWyeto06XAcbrup2U8wS1bGrPZqmSEMTi8USGSeEhMLusNg4PRLXwNToNY84KEVs4q9LnQz9QPH5qiVxaP2T5BO8R8UbGl7w4OUD8Z03PlZ0/YpVLj+Vn1hr3aVSrW7JLVyGj4G1ziI36q/oDOZmN2N2xoXuK4zt/GXwUy6APYgdWWzWHoTU5M8Kc9a4qTL4Ko9Cer8uauy6AkRJlXtNpeT/TaLukItcZkD4hCKCOffJB7+RBhMR5d6z2KnGGmeb9gjsSSY4KdtRWQ7dzoeduC9uZ+e/cU5E6bfatJTkZ/zA++jBS1huhhndZsDaA4aasUS+cpd6Pxo8+vX3jpPgUle3P+QWkgB/FgtkxFWaGP2sIJo0d4J5TkJD4qksGeME53QRp+h9imf0JsjItlqe6YvCn5GO8wUb41z3F7bgSAB4L35JK6Nv5aNGTSOsG+YIpiGis6OeXLRC7zPAlSlqvjZRJap1UiA3pkZqqy3rNygnRVSD/H16CgRSL3C4GSC+aSUMCQNXATDVvxgXKsiJ5btG3bAVTlhCd7s+N5KtVlW8TvDjNQqWR+ZDGe09nAOxyKB2GRUo0CN5vuoiQypVTJkgaP3A3BNZJpUN4Lwb+ZIAFI2fca70SBAtQmvy39QMxBTh6HB7/HhaZdCMgTa/HofLDy/ho1+xQH+fxnqpzxy98AUIHYblXlwSkqLlxXvlOV0+actli2p8mtICV7gRpFgD2vk9RdFNeeLOTjYEDhuwGYueIDrnCRTCel1CiDAcldM7JYN6AckYXXT+BfBNwgwmx7wVx6Bn+Y8Km+XtFoj+za2Qq2FARZ3uLqXZmWKI0dodTXmwec/ircy5DYempRNQdaeEBkVVv4BjPVLdhLppvcdDFVM2hks6dYz2EP1QPiZs4Ml6vX1QscuSizwhbRrGUwLXHepQ1ufsBobkzKEhYbjbgYX1U0UHpRkbjF/mIyV0n4OcI3eYU0JyCMkFTQVE3Gjtv9qQ9OWr3Yl5NAtG6Js14N9QM2bUHo1I5UpdQ9seozOFSFfWEyAphjnStIlKOLo/mHxrlYp3f4ooI/IOsetKo3alaXzco9PFwPEE/gnEkVcgikvxqC3f9hzVfiwzO0cyEXsBEA2a8UuE290NAu9x7FQHOwMtVMOb3A8yuvboWLlKfXF5hg5VE1qF4lMO6VeWA9RaJlZBU2hJ1MtSqV1l5LDn/Lhf9wH0tzG6e9siyRXuFohIBxHrTYuLBnxKbUaO7En4ggD6Qe+Ne54/TjOYN8vZROPgWox2q/osfCSoVqV8+oBB4mKdlf+AdaCtjVcbTt5Kp97WC4xo5Th2LoItFTEbbJxSN1URNeMIXaVEZaP+npi0TY6DqdRlmnsTLnRJTqvT8yV+RQu0QTHVYlpnDSMWHRkCdHeDJyONocTS4HyGl8itNqaR7BiazfFW6ClS51iFr8b0P6tSHN17bmdQDgYWPrn9eC6aZkUhnSYBkiPxHA5BcK6I/bIlBNofttQgQgxQwG/4H9r2nISKRJAPqGBjyZXyYpF/jXqOhC/WcIZFyETYYKGG4VXqPgUM/RUANzJTYQ2hqHRQigC/G8x5VDNdvoG84ckcx2SrcSQPI2DLFoE1mz4TxVfnYrRO+d5ZyPG8svmAEqaYJpqSbd1CNK+8rih8SEHfPd8TdbL7asqEh4QrT3S0hSG5f2XAWV8Fcr8rvTgfjoOJ/xjq0tp9xTaAv1evYQPcezYr18woorS5KKr/iW7MSo3miFd+kImBo8w9hgKkUAOK/wEsk78oG2ZvUeZ2LvFMvgIH04E/R+GhIoZcPFJK+CrtPNN8jgL50vvLfsCzb8xDBZW4ON0VkYqI0S8WPBCGilluTZQne22Fux9y7bA23kuqJ2lS+NIDa2i7iBkndck3E9Snx9K2JUE3GO/VLqCTggrg562s6q/y9v1+8G5gZ1gLco7iZAHT6Sb1YxVRf8/BCG6Q+NrQ4cpEWTHBuOjmtheGl1lnG+0eY50Y60AXwh00nx77g06jX98c6q3fH/NIQyugNjczWXucUaz/rhr/IZVwhxlKRIVNe55yXx9Ksb5eOWsU0qSVjUzwrNEACnEw2sYlPE/QKZ/WwoY7rnWCGQYuWez8ZFr7zvTnJf3mWs2KYfNhmmbAsYfIpFAYwA883U0UOXUzZk1/eVir+UR8x+JaPoa0SvuC/M98RKkSnTfP/V523mGwfgUJmOosC8XeQWyp+WzgadKYgdF6ROb4IaXvUeQmV5aZRZ940S86m/mglR2iMY62c+w/lR4+lwxZdh0UxaCGAKYOC8poaZX+v4DeMkmngpGQV0MT116V4UbEHnSlWLsMoVZlMz1dddQJY7pd9acbCzyU39kkprc3iKNJixfWe28tZVpQDJYQLT5NX4S0+J1Z9JdLCTXdPZ7yHMxolE9rQlqU2qJfo3l98H70smhvq9nN91LaLm/6Ppz8D59P01K6cSsvD95g8aoG4Ay01HbPliP1dgB36k7vV6jjpwAeR9ylPAVY5vE3ygISOVf18lFfKmRROOvB1fEjbOfcNZd5aHxRvW/zSNnb5tKYSDxQHwOW30dmIJIqSfC+IRC1pMraT5CUk/Q1Q3oe498MRfzga3TD+PUyLnVG5yi929xd9nYY2Uqj2cEhjuPd6QdpEqH1uUz1f36zLHIlcRRu+FA9FyBbIWKXgBammMILe1fTfJJqyoUHgvgwV85CAOeN81+NisHRu/6eCzTU49E2l174jx3yfM5uraHX8u0pG2edmIrSM04qyJjvwIncOhunWrXRlc4bm9GApfjA40OqF6Ezbi36oVOhfC+hDw9lA+TvEUcJnHE3R8EjS93He9P9CxxTy/cT71P8xlp9v7jCx19a9T9/sMzQzZ1WDfS1XcPPptCCMOb6cDKHegIqmkNJQW9//I9AJ99aUGGX7SlVZ4JLtcK2EDov0XWQqmM4nZkbMqJE8orJ8pI5+9F4udxXyAoPNf4sia9eGF7G9GQJG8NBJdyrBHARtD2t+IW0IbV6wGJsTscp36etyXApK+mEDk7VMfoN8H2WCZkz1u3c5jqBYe2QiobKxRFbuY8A5cSR3CjxarsU5ZOFtfDHHjnY33HTKi/Zt0+NTMH9fPi6RrZNPDpg081HnpIP4tYv1OYjElYzAfzkHnGXxUzEin2+wDp+W+cnhutUWKHivJeR4aJi9xnmpBwpdO3g6N3tyTAjJnFBY+OHO4ELNUWSg7wwYgxpsl1wfcQ8MjMpQW1r0aI44lOBKDLS5eWeGGdQbtNd3sLOaDWS8y0rJkxI/oswfvtwK5Zzj/CyFgSopmMBYXgj7WGZrd1Bj8E1sXTLDE7Y47a37RLyB9LBImlGUYLqTNX3v2ZgTL/VGVLokueLYpwLy8szIIr1R59KwAruBsWOLU3CXvpe5WPVG6N/ZjgycgMvgW7P9JxpT76lOgvKuND9IPVf6s2ALQ/Xgd0vd1QTyN+BNbXmv/wVAN2PbMPygEB5P8dxxHNesYnmCNYCMZWHxkof7eq6eLs0shCeVrF/Gdzi+oEpoZggG4I5umpj23x9iOD8lm6EKkTqtK7NJu8cUbeHLgOEsJUzGDeITBc0BrwPMQR0Va/n65dt5r3vSZr7ia6epVtqkc8DnFncPmk+j7nB524rTZ1M94AcAHZq0Cz/mIge73CkGErFKBfh7gFnMx2Ryra+57Y+lJRc8BzlOfNDn9NDVT3kaaidG9DETHA8AAfIkyp17gLmOjZd4+I6aBtBwvVScEkXxRJIv3vMwMXwcuQPMuU9Yv+zA+Ei62Rk60l5CFBLeC7WeRADjxz4eT3a4Z76/b6LLIEFLE65mxVilY/8Zk9VpLtGtGIwscQrRQS6g6uEAWBzIcJc2Or09CnomOQuT5FPqe0+EiceSS3k/AzgeTQyOxTDbW2yWY8YSCaPc0g8YrHijoTJ2JShkBIBrMJuRRusNAJVQyn9Q6hImWonyR8FTk15faRdX5BqNxlDM4VJcTBoUUqFa5iNIR7qe9gXowTDLFnj5hYcP2wtkPLmpB/VPRO5yKqcqfDEzMwiBhDVW6CvFlFoueWb0jwDxZ7D/yVN0jvzg836S9nA2iPiHAWimb4+fqgeVlWBOttvdhDZ6rbmYW3EzRisz+WbbK/myVD9CND1OJrcKuU3W5WlBOYwW4rWTr0mnafjWod/s2FTmti9k60lSbulVir3N4QExirN0/nkRBznUAkECeS7ix4bJH7LT7N+5gMo8RiPJyciQp9K1XVHulTf7noVfZcPfz8vOCE4KRYHPwgGqxYdOuznLnVPV/XwO3xscFneDeDvxIzpefFb6dKE4oyJJ47VJsClCnIk6q0IfxIgbFrCjr74H3LcJmT5P1vD5I998YW038Gim/kE5bZVjuHVSPdYgqF4jp8tZM6V89JjFI2MWfpcdN1Yh4ICpvdVdEnTiphhtjQ7o0BnfI6zaevdOQth2HJ30DijLzfrIQhrrjHZDRQgaLwctDxS3bG1m9BJdgWHfe0A2wjeiWPKsUelO10JXJT9DAFbSnnhelBNYZOnBvk97Ig3G280e22kamDQlhPit0de/ruCyg5jHp8iIk22x71hVHfWpU5kD4qIApqEBy2Cqdfjd5GAvfFrNzxmAMt7VL7R1oj+Wk3Q1kuYAaqhYEyVVEnWr4+cHC+DzTjcw5KWP4GV3vV/xA85QG+1W5Xv+IKwc0wib6Vh0mPvm+BcXYDrdunfkse9emduIBh1vpWrEvo5+fTF4ANA23hBmmCg6WiH6RmzZEdIJEDjs16fZjS1MIr9z3YYJTb6Luqjy/Ac5VWfb2O3mYGeQAgCBcQHu8wbq4DyXSHukzIkKcVHfn9wkm0MH7FHU+rTq5xTxuvsfkUk0Y1qGbsGCwKoRSd8z3B9awONaYEGZtKl+mB/uQWqdLlHrGpW+fYGS5BjTdPlQ5r2SiQJCHNu0q18a4/gsTq3mc8+Yt1bFGG0pSSLYRjSwQwDX18+OL/2nEuTkN37C8s5oefD9GmIZ/t0TBHuueYpJQskXQnavdAM6G4gXKplHwpiFpQvybS6yhv9LOdzYgqUYrFl0k1U2Yk/WTn/RgDTL1f4sUMJ/cCkGYKXHA3Hl4DNkmHTDVaPspYRNdZ8xx7iAvBoeBGOYM0x2CpEL8A7KmKDtE9StZQXuoOXEusdwl5HaLERXl5F2kcU5FQ6mkf7SHOGu2ahP3peG2UoaJKPn4OvUUGjdJAYRIrlBcERoHHuJpeMqQmJMtMigwnj2Rw0ji4R8Glrm5Y8Q9Mb4iNZBmJoE4lE/eI3xSVlXS0BzPgRGPfMXktj721PFHgL93AZcoXo+xTVdzfoX0TOMMkrEiV8g/Chh4STlHfz7Yb6kcjrfHjBhNiFJ8G+mD5whTcaxK7tjnuQOFX+WPkwfDadho8xBeQBFKLyhvoxiM6awppy9sFllx9FHRBYIzYYhOfKwQbGGJNMfJr5OWL1p1R1TxTKqJZ7hMQg0vPqPe1vgyxyvj6R4s4MG/152di91lIp0GMx9MwsIwJKBOx1Xj/XcwCvIPHdj4VbzcFAzvR0GS68Box67ahGtvqbWxYQ3VdEyv0E24/oqPXbSJEKMtEpxsj0WpuX8w6AlSuWbHquuNF1g2GIJLjWyfs+X91gEDIYp0sE0xBfvvjQU926kiV72w1M1BTZEc8wS9xmzYKOtdHEogVm+nZTvwx8iNnDZ/IF9grO4mzA2pvaRP0x+sE4TLiT4qpLOlXClAxMSew2ADqCOAt78hmsTZ/kjc1FWfwVtSoon0CjeamWW1XEQFKa8MNILZl0KmsbyBlCn2g8BUjJRcKN8i+4xm3pOsnK74mpRz9Cz0W8g1O2n8i6J5xNgK9nRl+NnNRDKrbiO3NG2kzmU9i5BHqq/YPa+TYvOoht3PMK077uCb4XK/daxZsuhIOOqU4ogwXQhPOuopHzOa5M5dKmkwYpFvN+GSdzkGUojrYt+Ses/tg6vheFkT4Qz36In2aJvChqhDeUYPQOX7Oha3QF8Vdkt69abc5MRVlLHRtrXWoNHkfMghd3cCzS5NLLHM41lQve3znxBQ2VTqopfWrxBVicIzoCJvW/Y/tq6g5H6K9MpXaV2jleo9m3h479EX3vneMdh8sok3gAkDl53AizcnOXgh/2jjHrCygzkyH+KfWXZU+Q9rt0j/nBL4ndGbZ6CCuoCBfkYkpuSOCDURIpMp66YDRTqJGBYOsvqi/vBKFhQP527MXE6fCul+Jxgc27UocbMgYP1nhq+FEwPOD+hCle9TmYD7+8Zeqifp2u5HZmNhmwWBhVWGhFzziAGKI4uL6TykWl9tFTqTawcEF0GhgIMd8XTFWW/Vb4VVCxjHDoM08y76uXZEhyqLb/HqXSIJfOhsIMknuUn2XqTqHvDtxuDroKYtTNtYDqxq4gf/Y/ZOUaQjio/TqnoZ3p+pnBKe1+4CaDScv5fB4aXg3jMyPNzPTdlVxU1GM24UiAGOg1UGThgzOpJq2R56uocLUTuq3rXBzwh0p9OEvHbsT1pNqRALhVilRtMDrYPzC5wijB7xcl6PbmwfTcTp65g+ihgu8LamrtYriHnNFzPfDnVtp+corBeyReVpCiTA6WlP1y26nSBvtCNliPpMeBQoNyEZfuXJHqco0iBi4osl4XBzsV07q2T85AmCgEmJ+ZPXlzPkxrVLu/yRmuhrxPyUtcih7SX3/i2PSlAQXakQxPgvUMLVgRPVJIrg7PaToUO0vH5Jg0yJJBHCcbswmeIgd6qw9I0PccsvL0me9QDlLvQxbnFSK2zPgtR893tZm3gTLeEh/nBr5H8JdFdjcwPg085m8/SMuwdVqRwL089sWa3G/StjWnpBxunQqiwCTExTMh6b2xUKBmVhd5PDYeKaUSY3mly9r+OyYNnBLjf0R0byeIeEz20hAGpPkWqAbxK6/F3P+D916IuB7G2SL3C/dmM6m6r+PJFNHV29kV4cER12+WmmKYewtG0jssm8yLa3muknK49qZQQuwLWkeiu40GdOHtGAM3AOR4UUPfaVsS+Q6rdPVY9BoKhXNHxXKnkx52J2WT2PJ1kt6TvaVt9y4Q3v/9tH2/4WDihNYUzDytp0NaenJoZGNQ4ALTf5v1R7siFUFTpnc+rVUXffxk0dnnDeEptdfooGoNlQtzff4PxZJYnia6cENuArfIAA0/ZVquEChYQjh6Vpa/VsKDSU3wykI80WUnhM0zbaUno4k4cSrIF9gIVk/0YXDyjXBkjReBOz2ruGcOj30S2YZUAlWW2fg3aRLRofcfKrPFdysTAWzemkZT1LgHMEfZatRGWRe81cAFtIe0PBcxwofPQWS0z0xtxdIA3ruGULLEOgGiloI3YqXI/MjsS2dbbXhyrmWfmdC08vx4cw08f+slA0OIWYxlYhDml6gWH9ifJxieE7iex89CWfBVTFdTu9mQ7I5H6kSqQXkeX0tPWB5wageazBETvaz6ayTlhGbJ4NfbN4SlnG7SNrxUWg2QK+fppBRjlmf2pbgWieyl5niKCkbZ+zFALik58ETY1WQMemIYPM8TzAlIdBVyMtbPezuqDegMcprNv61G6qEIyH2tQJxdaZUoRyDHPNkehjKay/1h+t30/W3ChqxrHe3SBVQ2M9WLSLkzGabSCEG7aLs8temc+3tfgpBSRM8AOAHz7Swas2XfJyptzNTjjt3b+bGqOJxajpEXlr3JhWsyChXIIyJllhX2r/tM24XVlTXXa/ii8mTXNldTT+v9PTxpydmry0d5OCUsTtPzv1gWSrvmuOXD4PaE91NGqRLvy9R+6yBZDFuHs6KRmSwuZwxmRDK07vGzwXkpB8YOcm7AdskJ+YnGQgquq73lo0If6UTJqRv136nuFxLnow80xWaUXpq7Qf+rYXtrcbb6Wyx6t1SszUdnkW/EO04QnDJNLE8K6SiHcBWe/AQT6RYDMpMuIaECm45IqqvPXp6wyxEjWgukInwfkxD57yo+t8k6ASaXeTLYOLpGubk97JoMOilau1abCneFQHfSSQPdwonoYrt2BUUqvH5oMxBVqygqngqlDyczmaNeHy2N1vKXSsecaNKVVkhMvLmSQl19eSXkPQP6ng8uHtcCHqeal+wiu0CIvl21C83jruJAAaK8EkcakwQOpQFHK3CrDEUYgWpr1CIbpc7VtxGTtcd1BNWT1AH9HwKUSRxcXdnuBFo8OFCwnbZ4VSu1ber5UDwd6+WAt+46ZKl07RmGlO534s2wj0FcDyj6WkccNL3AyDCrqEeLnkYbS+Pj/TkfCGaTS0ygR/qwM29l0+uckWbe40swTdENSCKLmQ6AKRBXT724ARIixLLzCYmf9RTrRm4kRy7/pElgkyXLICkw0aXkfGbGsrFzqmAFqJuV5lx1L1LUDfjIyF+pxat9ZFzRQ/swaC4XC4AdqYmapYFc8BeQb02rDSGlFdBhTAB5B258zy+EL+oVDtFNNMJnJczD99IjNoRjERqqAxjiVWa4/Tlfrevr+LlMTU8B0YlV8D9ryzYUSymTeR+lsadv47zp3ztcJy47axQM8D012ytetBOs5Us2xlTpFh8jSs3tH3FKsip72rE3ZPJbNtAsx0UUQls2PSq2qJZQLC0b5WH13tQk9oW8/TQhksF0wQIgB9P8dzhJLTOb7JiEj6hjmWRtpvScLjaWeAuGGtHHTieZ3UZbfzuqTRV2/KHNEZ0vz5DLObZme6ESOaGjoUm4z4I/wyNn1bAzOnIMu5BMdASsSwz0vnmhNuzimYci7HSom6SAOp4U5wjnKTDTNd/TEiZfbMa44E5/mHmPCW+oXFqmNjbjQyzZcUlzHZaud+fbyidAtoCDt3ZpvrGhIOrn/mIJ8SSFVFzP6/1rrGhcAIbFW7Gv8TdEv0boBpxLNil9MXYkeODQIkHp8wTTayISolMFm79AbaVgCNkQ65rm5kI/bSnmIykemjAunrEplw8OEybQJghgbHm12HF24GYCXowACSwqoIyz2OxRFvTTPy1BZdmO1Co3TxSMZlmhgOVRqTjo0H3frPbdTv0xV7iF8SjblHpQg8AManbAngoZ7inJC1GwjgvyxZg0q+FHuU5jLK/F15Ik6JLX55QHCTG9jPTySQd+TqXUiX8m5ThyD+kYbM6keNwm3eKcyQD6SVPz37hrKkeJAst4ZSU6DvrhnJ99kuoCgxjUhXlXs5HV5FaTsq+gtqcnNzGVXkEz/CsL88AMLnKKEGrO5WCN2OV3JDuyrFpD5i561+BOGkajYoEwL/nA9d+wg4oNcpooDeAhsDndWHR5+h2S/VfiA2o4OizvHElbhH1L94oUmZrfS1pKbTuO2fGSSWTWdQtjm1IACdU41lieK5n8151vKVunZxJVft97OW0FigDrP8cM6dlxjWAZJOGDycvJh7rqAPQft/Hc6NwOM+WCvEHoHhmeRXpy+ZysS4jHgdxMKiObFODa5hb9IbcRRjt6LjI9G6kPqVUFmI3fV9HQgkMVjvhOSOgQOIX0tBNbcJigUlvWhYBBH4jxLADktzFrTv1yigYjX95SlCxeLdYIXIYDt6vnFHuxB8bwtrxK/sl3upbJQIrxecfhQt0K+JNfB9mtUnyQT0bQjhbMGXn+/kf0X5QbIqGY3ttE5vdUCHYziwlnhQmwyK9IS2Jy+Rp9Rs9jBqY7bBRO6lVDx6u59Lr+pQkl1sxEoLvK6V68ku61QzYFSufIjBjX1/Z2Cf46Oe8Hkl012d0o2oGKGsij708HaoO1RA0AM9H1cEw0fzjEjz0m5WpJn9sCG9q4AFBxFmhDCEqD6pkLVy4Jr/7UTExja/BhArG3A+JrRq8lGzVEfvWAebn/5wdSlTXJUPvfW+AcFy6jAJx/u8jV5gTLHQwh/4JT5gB896MO1ursYL71BDR7W8h59kM5b/JoG0TuVEVDtfUgjuUPxST64SEynRwWhb2qIW88qmhIs5XwXu19GKqlpk08OmWCjEOjSRn1kNgovlnNhtYDBhjiF5qjZt9cMOBXX891bLX8L/x1c2MmCHK5eWmOu2D8QDHyx0TNYliQeI9UNtkLOzBDF97eYEBX1BP0pAVW6ektBIiD90/Cpzil8Krr6aDMBQMshy3J7E3g1w2w0v54sQqaiNGwuTCnmE6giReE2qCTXomnCrcqdwTqcxsqxiKaD9QDpPaCAazzbVAWus0L7uqH3UPOx9qlbJbXrHysYapiNBgfuz0/QY1ojMJF6Jr6EOC75omLC4Z7gZcNH+tobB44QR5MFXCVm+WCc6BqGqR8Pmavst1kNE6kVO8ASIr+RTctIgzzhBIFW4poCQpSMeVJ3N8nD4zvKgPDHqeSel/Cb9ELaIy8KaO6LE9WqOO5ubJxWZZNL63Hq64W7eMAOKJCG6H6bgkxF3DcrH+rjLYH7B0yi4ng4l71rdDayAXlW1Nj4ugBVidrTcR1Mu0OrNt9SeFhOfOZcWyy9cvm2CaglqgrkG3l166g/NQHToi9ysF/IuMUsZ7o9wKyBRxOfwboSsXyAjx7OVu+ECfILM196IFt2IHNOIpglB1uWhWz02s0ey/1hC8uioJoxEiNEcHTU56L1p49kT8iQLrmZBY0g83/IbXKMjMzdaaAs+pjszpqTKH6+XGuHJwSiWYlOpbF/HI3eEvA2MUXtGIZDxQzPxkICdi1Gby5/3gwPKm1+FZPzQJr1uIlQ0YPonKm5iFuQw6e3PjdWOpBdy9CyRHg8Aog8eUtV2Wj/agAVY8yjGpAaKjLukDYyvsuCoMpo23MaWXmB/QMM7LIUNnzgja+cdjB41KvqAXOj+nAt8o6mw60EtjcxuUpF07vHgXkKzTghpJEnp8kksjdOECEhI1QROOowcc1oiQ5UF7Le1zWS3XyVqXBFLYlCaY10PP3avIQZn1TwUZBNRy5uR1FigDVYTpsGUW+q1Kwx/OJSrZ69ahr9waXbgIq/VbJ9utFq8aVKIYb1TrY80zrjdPL6pN3n2Or/siqqqrdavNOgb0xIWi2lQ3yR/jXUj7tuWhyDLnlWE0mV03u15MVwz0xj5bF54Fb+OEFOoJJVjYZCENOIndJvp8JebBCqOWm6HVeh9HI4OA3kjw2K+2CFlVBuINsa1S+aA9lbWUQSPWBYBIDF6H/PPMDiaFEFres5gt62oxIXF9J5Oj7Bq3wcQs7q0E4D3lLhle7Em2qDySyzRIc9l9YFqcpmei7ign4eAHojjpmQim2hiFL0ycmFRl4N4MUYw7DTPORrwlSZsIu88VLs5QsHCYkT7FfAH1rdpT8P5VrWBsP28i8NWDkTp9rBrMbDCx5F3w69U2ZdvjjyB+dpi5nIOUnqlzYp9hUdsdGcMB48vOyPgrmCKvLyStTbgUe20MyIQkvTLsW5c1RpwNKtNAVk9yQ6X0OsUT0WnPdfCf34HYfqmCYUW2p/DyOhqGP17YrY/xBFy7dAg47us9O7cC5gvx2IDyVZyR81YwLCDn2tiZqnphBRlAXlm2QnpgCdRotyrYNkE4vdC3VLqnlwgz3K62m7NUKCbvw/A/JlU77IxObV/dlELwzZuq4GLemXhUCHRaOlXXt+cHCBnz2YLU9gTiBCWKmlLykISLIQao83Tl/wnKZ4YH8qPAhDcaLoOePFp+p4T241h39WIM7sd2Pc+2ytLmCKkx0WcWF9mgnkSDyjyUktLjUazr8e/ZPBoVKSQRKW1pOMdKIu5cEyzgeLZl9128Vvy8MvpVQyv5NgfoZ345Rc5kFaUq0FoHtjmZVVoLgrH2GZsgob3rpfKbbgNQLBUsDQhbeiEZL0Vf74RZF+8QLKZNkPQFjOkppwh/mfW+ecbWlTZMBV9YACQ1Yycpev/vx2vmPj6hTHWW1O2b7cYQI8mMfEyOOA67tl2SDKEEUcoTSUJJR3ZtBVaCeTq0XtAnXxHyCCHXEUSb9YSclpg1rYeXx/H6233XFWY5KU2ERtXQUDQpdhng0lnMZW5v4+BiIFRc5uT+2VtFrc32r4u/OfStJkgiCr8Dy6P9WeQNLFt0HiL+wtUzJRmifmrYm80v6LPpR00p4iBiqBs1gqBecS67PSLa71NhCix2PdYYcOyHUuKF9UU5isLv44Sf6xTKxpflrs6zGQYH2YN2wwsNsey8A7e0NNbkKmRTWI2vcKkfAhLzJuoVa68ZuUWHQcxubKOg7CwYSU99v2Z/+3pdJZ3j+bwd4an/sPblN5i7P/sGS32KqB7nJiaAWKMf92VH+22tfLIEi1yzS7tn8XoLPPOYnSBCsnL5YaAI3G+TY9f17W3JHQWTLSmP+XVmYqfdPoWCSzJi5e0ID5NdDSkupSEgs+oiNSpHJvqoTNJ6l8v6QknTFoj6qfUItFc38DIX1BNYaDleFhi/5Ps+qgMtqMo5yQJo1lDsi5I+x5lzmHtnUsRAzb46s7by04D05ws7LqNXWzT3zjfryacMa7wLsRcZjbKCsBPs0j5t9tF2Mfl1w/vKCQSpc/UaREAvu2mYetWTm85JJAA+L8pBkcA58yi7SB7AvKVTx8qMOrghxlptZSZ82tvbYimDyon2/wc9MkCOK7P+Yd72QcFifit0BVLSD61iKHusHn6VQYwtBZ6xmmZoxbCHiUTOqSGSDY2D+DOT8to/t63cdHYwcxH5nPJi+hlu1NfGMhxJOLTcVFR3bGQpfuaPKFWU5vWpIOzK5EAk4N5w5BW6vY3oyIdvsLvgpVGDR8P0vZj6BmBvD0+d6ovVFzR15IVy/KhjsTGIV3j7RYTRGo7FNQBh8qVMGCiaEmWtkRdf4JVs8ZwBnopSmKES4QhejbjOmmJpruTBdVI4aIzquuDQikiN2JHwD4G+A5wMs8zn5B055vQEwxAKLYsHUuTTFuzm5ygF/5f/p+IEbobeH6P2naWzuaAcHLCMoW4cM+wt8lp6Y9QFNZvbsph+VeHn9IkowOYBNwAD2U=]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第一章～第八章]]></title>
    <url>%2Fz_post%2FCpp-Book-CppPrimerPlusChapter1_8%2F</url>
    <content type="text"><![CDATA[第一章 预备知识C++简介 C++融合了三种不同的变成方式：1、C语言代表的过程性语言 2、带有类的面向对象语言 3、C++模板支持的泛型编程 C++简史20世纪70年代早期，贝尔实验室的Dennis Ritchie开发了C语言。 20世纪80年代，贝尔实验室的Bjarne Stroustrup开发了C++语言。 可移植性和标准C++98 C++11 程序创建的技巧编译和链接 第二章 开始学习C++进入C++输入输出：C++能在使用printf()、scanf()和其他所有标准的C输入输出函数，只需要包含常规的C语言的stdio.h文件即可 main函数： main函数是被操作系统调用的，他是程序与操作系统之间的接口。p14 int main( void ) 在括号中用void明确指出，函数不接受任何参数，在CPP中，让括号空着与使用void完全等效。但是在C中，让括号空着意味着对于是否接受参数保持沉默。p15 许多程序员喜欢使用下面的函数头，并省略返回语句：void main()。这在逻辑上是可以理解的，大部分系统也适用，但由于它不是当前标准的内容，因此在有些系统上不能工作。新的标准中对这一点作出了让步，如果编译器到达main()函数末尾时没有遇到返回语句，则自动添加return 0语句 （只对main函数有效，对其他函数不会隐含return 0）。p15 （疑问：在测试的时候报错说main函数必须是int返回类型？同时，非main函数也可以不写明return语句，但是返回的值是6295680？？） 有一些非标准函数，他们使用_tmain() 形式，这种情况下，有一个隐藏的main（）调用它，但是常规的独立程序都需要main()。p15 头文件名，名称空间： 新标准的CPP不适用头文件的.h扩展名，而利用命名空间机制。 新的cout，cin为了避免产生函数名冲突，需要使用std::cout，std::cin来使用 如果使用using namespace std； 则表示std名称空间中的所要名称都可用，但这是一个隐患，推荐使用using std::cout的方式（为了方便，大多会使用using namespace std） p33：using namespace std可以放在main中，表示只有main可以访问其命名空间，也可以放在iostream下面，表示文件中的所有函数都能访问 使用cout进行输出： cout是一个预定义的对象，是某个类的特定实例，&lt;&lt;符号表示它将后面的字符串发送给cout：cout&lt;&lt;string 从概念上看，输出是一个流，即从程序流出的一系列字符。cout对象表示这种流，其属性定义在iostream文件中，&lt;&lt;是cout对象的一个属性，它表示将其右侧的信息插入到流中，该符号与按位左移运算符实际上是重载关系 打印的时候，cout会将整数形式的数字自动转换成字符串形式，注意整数25与字符串25有天壤之别 endl确保程序继续运行前刷新输出？控制符：诸如endl等对于cout来说有特殊含义的符号（manipulator）传统Cpp不能把回车放在字符串中间，但是C++11新增的原始字符串可以包含回车 C++语句其他C++语句 cin.get（） 一般需要两条，一条用于接受多余的换行，有一条用于让程序暂停。cin使用&gt;&gt;运算符才输入流中抽取字符。p24 函数 C++函数和C一样，不允许嵌套定义。p30 main不是关键字，因为它不是语言的组成部分，可以做关键字，但最好别这样，会引起其他错误。cout也不是关键字，而是一个对象名，所以可以在不适用cout的程序中，将cout用作变量名。p31 第三章 处理数据简单变量变量名，符号类型： CPP命名规则：以两个下划线或下划线和大写字母打头的名称被保留给实现（编译器及其使用的资源）。p38 CPP的字节位数根据字符集的大小而定，对于基本字符集ASCII和EBCDIC来说，一字节为8为，而对于国际编程Unicode来说，一字节可能为16为或32位，int在老式机器中一般为16位，而在现在多为32位。p39 预编译指令#define是c遗留下来的，cpp中多用const关键字p42。 cpp中有一种c没有的初始化赋值语法：int a（42）。C++11具有新的初始化方式。p42 常数后缀，ul，lu，uL，LU等等都可以，均表示unsigned long常量。在cpp中，对十进制整数采用的长度规则，与16进制和8进制略有不同。p47 通用字符名，以/u开头 Unicode与ISO 10646。p52 char默认情况下既不是无符号，也不是有符号。 wcha_t 与 underlying（底层类型） cin和cout将输入和输出看做是char流，因此不适合用来处理wchar_t类型，以l或L为前缀应用wcin和wcout。cpp11新增的char16_t char32_t分别以u和U为前缀。p53 const限定符 p54：const比#define更好，1.它可以明确指定类型，2.cpp的作用于规则将定义限制在特定的函数或头文件中，3.const可用于复杂类型，如数组和结构体 浮点数C++算术运算符 求模运算符只能用于整形。p59 对于float类型，11.17+50.25=61.419998 具体愿意是float的精度限制所导致的（将操作数转化成二进制即可理解）。p60 数值类型转换，对于精度丢失的情况，最终结果会根据系统的不同而不同。p63 c++11中的{}初始化赋值法不允许narrowing缩窄，即只能小赋给大，不能大赋给小（但是const可以，只要能hold住要赋的值即可）。p64整型提升：c++在计算表达式时自动将bool char unsigned char signed char short转换为int。如果shot比int短，则unsigned short类型将被转化为int，如果长度相同，则unsigned short将被转化为unsigned int，以此确保在对unsigned short进行提升时不会损失数据。wchar_t被提升为下列类型中第一个宽度足够的类型：int，unsigned int，long，unsigned long。更多转化规则可以查看校验表p64 强制类型转化通用格式：（typeName）value；typeName（value）第一种格式来自C语法，第二种是纯粹C++语法。p65 c++11中新增了auto类型声明的用法，让编译器根据初始值的类型推断变量的类型。主要用于复杂类型。p66 第四章 复合类型数组 c++中数组的arraySize只能是常量，const，或常量表达式，不能是变量。p71 字符串 c++11初始化数组时，可以省略等号。c++标准模板库（STL）提供了一种数组替代品模板类vector，c++11新增了模板类array。p74 ‘s’表示83 “s”表示的是某块内存的地址。 cout会默认自动拼接两段字符串，并且可以不在同一行。p75 c++使用空白（空格，制表，换行）来确定字符串的结束位置。为了读取空白可以采用cin的成员函数面向行的输入：cin.getline（）和cin.get（）。二者以换行为结束，前者会舍弃换行符，后者会将其保留在输入队列中（注意是输入队列，这相当于输入缓冲区，下面读取函数有可能会读到这个换行符）。二者的返回值为cin对象，可以继续调用函数。getline（）使用起来更简单方便，但get（）更能检查出错误。另外要注意二者读取空行时的区别。p78 string类 string对象和字符数组之间的主要区别是string对象可以声明为简单变量，类设计让程序能够自动处理string的大小。p83 原始字符串 raw。p87 结构 p89：C++允许在声明结构变量时省略关键字struct。但是C不允许 p92：c++的结构特性比C更多。 位字段，共用体（长度为其最大成员长度） 共用体枚举 对于枚举变量，只有赋值运算符，枚举创建的是符号常量，可以代替const。枚举量的值可以重复。p96 指针：*运算符称为间接值（indirect value）或解除引用（dereferencing）。p101：不管是指向何种类型的指针，其指针变量本身的长度是一定的。p9917.10.19 指针和自由存储空间 C++利用new关键字代替了malloc（）来分配内存：int* p=new int; 用指针和new进行的内存分配是在程序运行时进行的（只有运行时，指针才知道它指向的是哪一块地址）。p102 delete关键字只能释放new的内存，不能用于一般变量，同时，不可以重复释放，否则结果未知。 不能用sizeof运算符确定动态数组包含的字节数。p104 指针、数组和指针算术 指向数组的指针和数组名基本等价，区别是：1，指针值可以变，而数组名的值不能变。2，sizeof用在数组名上返回数组长度，用在指针上放回指针的长度。注意short tell[10]; 中tell与&amp;tell的关系。p109 cout打印字符数组的关键不在于变量是一个数组名，而在于它是一个char的地址！在cout和多数c++表达式中，char数组名，char指针和双引号下的字符串常量都被解释为字符串第一个字符的地址。p109 第五章 循环和关系表达式for循环while循环do while循环基于范围的for循环（C++11) c++11新增了一种基于范围的for循环，它简化了一种常见的循环任务：对数组或容器类的循环for（int x：arr）和for（int &amp;x：arr），前者不可以改变x的值，后者可以。5.5节详解cin.get（）函数。p152 循环和文本输入 cin在获取用户输入的字符时，将忽略空格和换行符，并且，发送给cin的输入会被缓冲，只有在用户按下回车键后，他输入的内容才会被发送给程序，为了读取空格和换行符，可以利用cin.get（char）进行补救，char的函数声明是引用，所以，可以改变char的值。p154 第六章 分支语句和逻辑运算符if语句逻辑表达式字符函数库cctype?:运算符switch语句 p181 ：c++的switch语句中必须是整数表达式，一般为int或char或枚举 break和continue语句读取数字的循环简单文件输入/输出 打开已经存在的文件，接受输出时，默认将它的长度截断为零，文件原来的内容会丢失。p194 函数exit（）的原型是在头文件cstdlib中定义的，在该头文件中，还定义了一个用于操作系统通信的参数值EXIT_FAILURE。p195 windows系统中的文本文件每行都已回车字符和换行符两个字符结尾，在通常情况下，C++在读取文件时将这两个字符转换为换行符，并在写入文件时执行相反的转换。有些文本编辑器不会自动在文件的最后一行加上换行符，因此，需要手动按下回车键再保存文件。p196 第七章 函数——C++的编程模块复习函数的基本知识 在C++中不能将数组作为函数返回值 （但是可以将数组作为结构或这对象的组成部分返回）。p204 函数定义必须提供标识符，而函数原型不要求，有类型列表就足够了：void cheers（int），通常，在原型的参数列表中，可以包括变量名，也可以不包括。原型中的变量名相当于占位符，因此不必与函数定义中的变量名相同。但是，好的变量名可以帮助理解程序功能，所以一般建议加上。p206 C++与接受可变参数的C函数交互时可能用到：void say（…）的形式。p206 通常，函数原型会自动将被传递的参数强制转换为期望的类型。（但函数重载可以导致二义性，因此不允许某些自动强制类型转换） 函数参数和按值传递 C++通常按值传递参数，这会让函数在自身的作用域内保持实参的副本，这种方式在一定程度上可以确保数据的完整性和安全性。 函数和数组 在C++中，当且仅当用于函数头或函数原型中，int *arr和int arr[]的含义才是相同的。在其他的环境下，二者的含义并不同，前者代表指向int类型的指针，后者代表数组名。p213 以下程序说明了数组函数一些有趣的地方，首先，cookies和arr指向同一个地址，但sizeof cookies的值是32，而sizeof arr的值是4。sizeof cookies是整个数组的长度，sizeof arr只是指针变量的长度。这也是必须显示传递数组长度，而不能在函数中使用sizeof arr的原因，因为指针本身并没有指出数组的长度。p215 12int cookies[size]=&#123;1,2,3,4,5,6,7,8&#125;;int *arr = cookies 由为防止函数中无意中修改数组的内容，可以在声明形参的时候使用关键字const，但应注意，这并不是意味着原始数组必须是常量而只意味着不能在函数中修改数组中的值。（对于普通变量来说，由于C++默认按值传递的特性，这种保护会自动实现）p217 使用数组区间（range）的函数 ：对于处理数组的函数，必须将数组的数据种类、起始位置和元素个数传递给它，传统的方法是传递数组名和数组个数n。另一种方法是传递两个指针，分别标识数组的开头和结尾，即数组区间。STL方法使用“超尾”的概念来指定区间，即end指针的是最后一个元素后面的指针。p220 指针和const： 情况1，pt指向一个const int，因此不能使用pt来修改这个值，但是这并不意味着age是一个常量，而只是说对于pt来说这是一个常量，我们依然可以直接通过age来修改age的值，但不能通过pt来修改它。同时，我们可以修改pt的值，即pt可以重新指向另一个地址。 情况2，finger只能指向age，但是允许使用finger来修改age。简而言之，finger和ps都是const，而*finger和ps不是。 情况3，stick只能指向age，并且不能通过stick修改age的值。p2211234int age=30；const int *pt=&amp;age；int *const finger=&amp;age;const int * const stick=&amp;age； 函数和二维数组 数组作参数的函数，必须牢记，数组名被视为地址，因此，相应的形参是一个指针，正确的函数原型如下所示，二者含义完全相同，后者可读性更强。注意，前者的括号是必不可少的，式子3代表的是指针数组，而不是指向二维数组的指针。123int sum (int (*arr)[4])int sum (int arr[][4])int *arr[4] 函数和C-风格字符串 C-风格字符串与常规char数组之间的区别：字符串有内置的结束字符’\0’。p225 空字符’\0’值等于0，因此可以直接用于while（）里的循环判定。p227 函数无法返回一个字符串，但是可以返回字符串的地址。p227 函数和结构 在涉及到函数时，结构变量的行为更接近与基本的单值变量，默认情况下是按值传递的，函数将使用原始结构的副本。当结构非常大时，这会增加内存要求，因此更推荐使用指针来传递结构体。指针传递时使用间接成员运算符’-&gt;’访问，值传递时使用成员运算符’.’访问。p228 当程序在输入循环以后还需要进行输入时，可以使用 cin.clear() 重置输入。p233 函数和string对象 虽然C-风格字符串和string对象的用途几乎相同，但与char数组相比，string对象更像是一个单一变量，可以将string直接复制，也可以直接在函数中传递。 函数和array对象 在C++中，类对象是基于结构的，因此结构变成方面的考虑因素也适用于类，所以可以按值将对象传递给函数。p236 array模板并非只能存储基本类型数据，它还可以存储类对象。p237 递归 C++函数允许自己调用自己（然而，与C语言不同，C++不允许main()调用自己） 函数指针 与数据项类似，函数也有地址，函数名即为函数的地址，它是存储其机器语言代码的内存的开始地址。p241 使用场景：要在当前函数中使用不同的算法来实现灵活的功能，可以将算法的函数地址作为参数进行传递，这就是函数指针。p241 注意以下代码的区别。p242 123int think ();process(think); //传递了函数的地址，process函数能够在其内部调用think函数thought(think()); //传递了函数的返回值 声明函数指针，最简单的方法就是，先写出该函数的原型，然后用(*pf)替换函数名即可，如下所示,pf即为函数指针。注意，括号的优先级比星号高，所以这里括号不可少。p242 1234double pam(int,double);double (*pf)(int,double); //pf是一个指针，指向doubel （int，double）类型的函数double *pf(int,double); //pf是一个函数，返回double *类型的数据pf = pam; //正确声明函数指针后，便可以将相应的函数赋给它 在使用函数指针时，下面两种方法等价！这很神奇！前者的好处是强调当前正在使用函数指针，后者的好处是使用起来很方便。至于为什么会这样，主要是因为有两种流派的声音，C++对这两种流派进行了折衷，认为二者都正确。p243 12345678double pam(int);double (*pf)(int);pf = pam;double y;y = pam(5);//下面两种方法等价y = (*pf)(5);y = pf(5); C++11的自动类型推断功能在函数指针声明并初始化时十分方便，以下两种声明初始化方式等价。p245 123const double *f1(const double ar[], int n);const bouble *(*pf)(const double ar[], int n) = f1;auto pf = f1; 函数指针数组,[]的优先级高级星号，所以先指明了这是一个包含3个元素的数组，声明的其他部分指出了元素的类型。所以pa是一个包含三个指针的数组，每个指针都指向一个函数，该函数返回指向double类型的指针。p245 1234567const double *(*pa[3])(const double *,int) = &#123;f1,f2,f3&#125;;auto pb = &#123;f1,f2,f3&#125; //非法！ auto只能用于单值初始化，不能用于初始化列表。auto pb=pa //但可以利用声明好的pa数组，来声明同样类型的数组。//使用时，想使用数组一样即可const double *px = pa[0](av,3);const double *py = (*pb[0])(av,3); //前面的括号必不可少 下面的声明，表示pd首先是一个指针，它指向一个包含三个元素的数组，数组中的元素是函数指针。这里pd其实就是指向pa的地址，pa是上面声明的函数指针数组的名字，也就是函数指针数组的首地址。p245 123456const double* (*(*pd)[3])(const double*,int) = &amp;pa;//调用方法，用``(*pd)``代替``pa``即可(*pd)[i](av,3); //返回指针(*(*pd)[i])(av,3); //与上面等价， 返回指针*(*pd)[i](av,3); //注意如果不带括号，先返回指针，然和用星号得到指针指向的值*(*(*pd)[i])(av,3) //与上一条等价，先返回指针，然和用星号得到指针指向的值 函数指针的声明有时候会很长，此时可使用auto（C++11）或typedef来对代码进行简化，方便编程。p248 12345678910//下面两条语句等价，前者使用方便，缺点就是无法直观看出pc的类型，后续程序可能会不小心产生类型赋值错误auto pc = &amp;pa;const double* (*(*pd)[3])(const double*,int) = &amp;pa;// 可以用typedef简化声明typedef double real; //正常声明变量，前面加上typedef，即可用后者代替前者typedef const double* (*p_fun)(const double*, int);p_fun pa[3] = &#123;f1,f2,f3&#125;;p_fun (*pa)[3] = &amp;pa; 第八章 函数探幽C++内联函数 常规函数与内敛函数之间的主要区别在于C++编译器如何将它们组合到程序中。 传统函数在被调用后，会立即存储该指令的内存地址，并将函数参数复制到堆栈，跳到函数起点的内存单元，然后执行函数的机器代码，之后再跳回到地址被保存的指令处。 来回跳跃并记录跳跃位置需要一定的开销。p253 内联函数的编译代码与其他程序的代码“内联”起来了，即编译器会使用相应的函数代码来替换函数调用（这就省去了来回跳跃的时间开销和内存开销）。 内联函数无需跳跃时间，因此加快了运行速度，但同时增加了存储内联函数的内存开销，如果程序在10个不同的地方调用同一个内联函数，就需要存储10个副本。 当函数的代码执行时间很短（函数很小），则内联调用可以省去调用时间。但是由于这个过程相当快，因此尽管接伸了该调用过程的大部分时间，但节省的时间绝对值并不大，除非该函数被经常调用。p253 使用内联时，在函数声明或定义前加上关键字inline。通常的做法是省略原型，将整个定义放在原型处，并加上内联关键字。p254 1inline double square(double x) &#123; return x*x&#125; inline工具是C++新增的特性，原始的C语言使用#define来实现内联（文本替换）p255 引用变量 引用变量，是 已定义的变量的别名 ，他的主要作用是用作函数的形参，如此一来，函数将使用原始数据，而不是其副本。 &amp;符号在变量前（右值）是代表“取地址”，在类型附近时（左值）代表“引用” 引用和指针的区别（引用看上去很像伪装的指针 “&amp;rodents=prats”）： 123int rats = 101;int &amp; rodents = rats; //rodents是rats的别名，二者指向同一块内存地址int * prats = &amp;rats; //prats指向rats的内存地址 引用在声明的同时必须进行初始化（做函数参数时，在函数调用时使用实参初始化），而不能像指针那样，先声明，在赋值 。引用更接近const指针，必须在创建时进行初始化，一旦与某个变量关联起来，就将一直效忠于它。p256123456789int rats = 101;int &amp; rodents = rats;int * const pr = &amp;rats; //上式是该式的伪装表示int bunnies = 50;rodents = bunnies; //试图将rodents变成bunnies的别名cout&lt;&lt;rodents&lt;&lt;endl; //输出50,和rodents值一样count&lt;&lt;rats&lt;&lt;endl; //但同时rats的值也变成了50cout&lt;&lt;&amp;rodents&lt;&lt;endl;cout&lt;&lt;&amp;bunnies&lt;&lt;endl; //二者的内存地址并不相同 const double &amp;ra用作函数参数时，在函数内不能修改ra的值（会报错），这在行为上与按值传递类似，但是当ra内存占用比较大时（结构或对象），就会很省内存（按值传递会生成副本，内存消耗大）。p261 对于基本类型，使用按值传递兼容性更好，因为按值传递可以自动强制类型转换，而const引用的限制更严格，因为它是别名，所以不能将表达式赋给引用。p261 12//现代C++中会报错，但早期C++只会警告，会创建一个临时变量，并将其初始化为x+3.0的值double &amp; ra = x + 1.0; 临时变量、引用参数和const： 当前，如果实参与引用参数不匹配，仅当引用参数为const引用时，C++将生成临时变量。创建临时变量的两种情况：p262 实参的类型正确，但不是左值。（字面常量，表达式） 实参的类型不正确，但可以转换为正确的类型。（int转double） 左值：左值参数是可以被引用的数据对象，例如，变量、数组元素、结构成员、引用和接触引用的指针都是左值。 非左值：字面常量（用引号扩起的字符串除外，它们由其地址表示）和包含多项的表达式。 （C语言中，左值最初指的是可出现在赋值语句左边的实体，引入const关键字后，const变量，虽然一般不出现在左边，但是可以通过地址访问它们） 非const引用无法生成临时变量，这是因为如果接受引用参数的函数的意图是修改作为参数传递的变量，临时变量将无法实现修改，所以现在的C++标准禁止创建临时变量（老的编译器只会发出警告”Warning: Temporary used for parameter ‘ra’ in call to refcube(double &amp;)”，遇到这种警告，一定要排除）。p263 将引用参数声明为const引用的理由有三个： p263 使用const可以避免无意中修改数据的变成错误; 使用const使函数能够处理cnost和非const实参，否则只能接受非const数据; 使用const引用能使函数能够正确生成并使用临时变量。 C++11新增了另一种引用—— 右值引用（rvalue reference） 。这种引用可指向右值，是使用&amp;&amp;声明的。新增右值引用的主要目的是，让库设计人员能够提供有些操作的更有效实现，实例见18章。&amp;声明的叫左值引用。：p263 123double &amp;&amp; rref = std::sqrt(36.00); // not allowed for double &amp;double j = 15.0;double &amp;&amp; jref = 2.0*j + 15.6; //not allowed for double &amp; 返回引用与传统返回机制的区别： 传统返回机制是按值传递函数参数类似，计算关键字return后面的表达式，并将结果返回给调用参数。而返回引用是返回return后面的变量的别名，并不会生成新的副本。p267 返回引用需要注意的问题： 最重要的是要避免返回函数终止时不再存在的内存单元的引用。（同样，也应避免返回指向临时变量的指针）。如下面的情况：p267 123456const double &amp; clone(double &amp; dref)&#123; double newguy; newguy = dref; return newguy; //返回newguy的引用，但是newguy在函数结束时会释放内存,会报错 return dref; //返回dref的引用，可行&#125; 前者可以编译，后者不可以。因为前者是指针，指向x，而后者是变量，是独立于x的副本。指针和副本都会在函数结束时释放，但是x并不会释放。p268 1234567891011#include &lt;iostream&gt;using namespace std;const int &amp; clone(int &amp; x)&#123; //可以编译 int *y = &amp;x; return *y;&#125;const int &amp; clone(int &amp; x)&#123; //不可以编译 int y = x; return y;&#125; 将C-风格字符串用作string对象引用参数，形参类型为const string &amp;时，实参类型可以为char*, const char*, string等（“abc”类型为const char*）。原因如下：p270 string类定义了一种char*到string的转换功能，这使得可以使用C-风格字符串来初始化string对象 const引用形参具有创建临时变量的属性。因此，当类型不符合时，会创建临时变量 对象、继承和引用： 除了可以使用父类的方法外，继承的另一个特征是，基类引用可以指向派生类对象，而无需进行强制类型转换。这种特征的实际结果是，可以定义一个接受基类引用作为参数的函数，调用该函数时，可以将基类对象作为实参，也可以将派生类对象作为实参。p271 使用引用参数两个主要原因： p274 程序员能够修改调用函数中的数据对象; 通过传递引用而不是整个数据对象，可以提高程序的运行速度。 指导原则： p274 对于使用传递的值而不作修改的函数 如果数据对象很小，如内置数据类型或小型结构，则按值传递; 如果数据对象是数组，则使用指针，因为这是唯一的选择，并将指针声明为指向const的指针; 如果数据对象是较大的结构，则是用const指针或const引用，以提高程序的效率。这样可以节省复制结构所需的时间和空间; 如果数据对象是类对象，则是用const引用。传递类对象参数的标准方式是按引用传递。 对于修改调用函数中的数据的函数 如果数据对象是内置数据类型，则是用指针; 如果数据对象是数组，则只能使用指针; 如果数据对象是结构，则使用引用或指针; 如果数据对象是类，则使用引用。 默认参数 对于带参数列表的函数，必须从右向左添加默认值。（即带默认值的参数的右边所有参数都要有默认值）。p275 12int harpo(int n, int m=4, int j=5); //validint chico(int n, int m=6, int j); //invalid 实参按从左到右的顺序一次被赋给相应的形参，而不能跳过任何参数。（这点与python不同） p275 123beeps = harpo(2); //same as harpo(2,4,5)beeps = harpo(1,8); //same as harpo(1,8,5)beeps = harpo(3, ,8); /invalid 函数重载 “多态”指的是函数有多种形式，“重载”指的是可以有多个同名的函数。二者指的是一回事 。p276 函数重载的关键是函数的参数列表——函数特征标（function signature）。如果两个函数的参数数目和类型相同，同时参数的排列顺序也相同，则它们的特征标相同，而 参数变量名是无关紧要的 。p277 编译器在检查函数特征标时，将把 类型引用和类型本身视为同一个特征标 。如以下两个看起来不同的特征标是不能共存的(它们都接受同一个参数x，会使得程序具有二义性)：p277 12double cube(double x);double cube(double &amp;x); 函数重载只看特征标是否相同，不关心函数返回类型。p278 当传入参数类型可以被强制转换时，将调用最匹配的版本：p278 123456void staff(double &amp; rs); // matches modifiable lvaluevoid staff(const double &amp; rcs); //matches rvalue, const lvaluevoid stove(double &amp; r1); // matches modifiable lvaluevoid stove(const double &amp; r2); //matches const lvaluevoid stove(double &amp;&amp; r3); //matches rvalue 名称修饰： C++通过名称修饰（name decoration）或名称矫正（name mangling）来区分重载函数，它会根据函数原型中指定的形参类型对每个函数名进行加密。p289 函数模板 函数模板是通用的函数描述，它们使用泛型来定义函数。模板并不创建任何函数，而只是告诉编译器如何定义函数。在标准C++98添加关键字typename之前，C++使用关键字class来创建模板。p281 12345678//如果需要多个将同一种算法用于不同类型的函数，可以使用模板template &lt;typename AnyType&gt; //注意没有分号;void Swap(AnyType &amp;a, AnyType &amp;b)&#123; //可以交换多种类型 AnyType temp; temp = a; a = b; b = temp;&#125; 函数模板不能缩短可执行程序。对于以不同类型多次调用模板的程序来说，最终仍然会生成多个独立的函数定义，就像以手工方式定义一样。 最终的代码不包含任何模板，而只包含了为程序生成的实际函数。p283 重载的模板： 被重载的模板的函数特征标必须不同：p283 1234template &lt;typename T&gt;void Swap(T &amp;a, T &amp;b);template &lt;typename T&gt;void Swap(T *a, T *b, int n); 显式具体化： （具体机制随着C++的演变而不断变化，下面是ISO/ANSI C++标准）p286 对于给定的函数名，可以有非模板函数、模板函数和显式具体化模板函数以及它们的重载版本。 显式具体化的原型和定义应以template&lt;&gt;打头，并通过名称来指出类型。 具体化优先于常规模板，而非模板函数优先于具体化和常规模板。12345struct job&#123;...&#125;;void Swap(job &amp;, job &amp;); //非模板函数template &lt;typename T&gt;void Swap(T &amp;, T &amp;); //模板函数template &lt;&gt; void Swap&lt;job&gt;(job &amp;, job &amp;); //显式具体化 实例化和具体化： 在代码中包含函数模板本身并不会生成函数定义，它只是一个用于生成函数定义的方案。编译器使用模板为特定类型生成函数定义时，得到的是模板实例（instantiation）。也就是说，模板并非函数定义，模板实例才是函数定义。p288 隐式实例化和显式实例化： p288 隐式(implicit)：通过函数调用导致编译器生成模板实例（大多数情况下都是隐式） 显示(explicit)：直接命令编译器创建特定的实例，方法如下：1template void Swap&lt;int&gt;(int, int); //explicit instantiation 显式实例化和显式具体化的区别： p288 显式实例化：使用Swap()模板来生成int类型的函数定义 1template void Swap&lt;int&gt;(int, int); //explicit instantiation 显式具体化(explicit specialization)：不要使用Swap()模板来生成函数定义，而应使用专门为int类型显式定义的函数定义。这些原型必须有自己的函数定义。 12template &lt;&gt; void Swap&lt;int&gt;(int &amp;, int &amp;);template &lt;&gt; void Swap(int &amp;, int &amp;); //这两句声明等价，任选其一 警告： 试图在同一个文件（或转换单元）中使用同一种类型的显式实例化和显式具体化将出错。 隐式实例化、显式实例化和显式具体化统称为具体化（specialization）。 它们的相同之处在于，它们表示的都是使用具体类型的函数定义，而不是通用描述。p289 重载解析（overloading resolution）： 对于函数重载、函数模板和函数模板重载，C++需要（且有）一个定义良好的策略，来决定为函数调用使用哪一个函数定义，尤其是有多个参数时。该策略大概过程如下：p289 第一步：创建候选函数列表。其中包含与被调用函数的名称相同的函数和模板函数。 第二步：使用候选函数列表创建可行函数列表。这些都是参数数目正确的函数，为此有一个隐式转换序列，其中包括实参类型与相应的形参类型完全匹配的情况。 第三步：确定是否有最佳的可行函数。如果有，则使用它，否则该函数调用出错。 匹配顺序： p290 完全匹配，但常规函数优先于模板。 提升转换（如，char和shorts自动转换为int，float自动转换为double）。 标准转换（如，int转换为char，long转换为double）。 用户自定义的转换（如，类声明中定义的转换）。 完全匹配与最佳匹配 完全匹配不等于最佳匹配，通常，有两个函数完全匹配是一种错误，但这一规则有两个例外。即有时候，即使两个函数都完全匹配，仍可完成重载解析。p290 指向非const数据的指针和引用，优先与非const指针和引用参数匹配。 下面两个式子都是完全匹配，但程序会选择前者，而不是报错： 1234567891011void recycle(blot &amp;); //#1void recycle(const blot &amp;); //#2struct blot &#123;int a; char b[10];&#125;;blot ink = &#123;25,&quot;spots&quot;&#125;;recycle(ink); //选择#1，因为ink没有被声明为const//然而，const和非const之间的区别只适用于指针和引用指向的数据//即，如果是如下定义，则将出现二义性错误void recycle(blot);void recycle(const blot); 两个完全匹配的函数，一个是非模板函数，另一个不是。此时，非模板函数将优先于模板函数（包括显式具体化）。如果两个完全匹配的函数都是模板函数，则较具体的模板函数优先。 C++98新增的特性—— 部分排序规则（partial ordering rules） 可以找出最具体的模板。 8.5小节涵盖的知识点很多，并且由于篇幅原因，没有详细展开，需要多看。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习》]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Book-%E8%8A%B1%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[第一章 引言第二章 线性代数2.1 标量, 向量, 矩阵和张量 标量(scalar): 一个单独的数字 向量(vector): 一般默认是列向量, 为一列数字 矩阵(matrix): 多个列向量组成, 可看做是二维数组 张量(tensor): 超过两维的数组 2.2 矩阵和向量相乘2.3 单位矩阵和逆矩阵2.4 线性相关性和生成子空间范数]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
</search>
