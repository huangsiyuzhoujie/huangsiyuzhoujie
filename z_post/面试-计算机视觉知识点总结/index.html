<!DOCTYPE html>













<html class="theme-next gemini" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">

<meta name="google-site-verification" content="jgw73iXouBAJcOuff0yi9vdSNDecBSOUXacsHJszpmo" />
<meta name="baidu-site-verification" content="xyf9WD2vvl" />











<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/apple-icon-57x57.png?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_body":"slideDownIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。 使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。 使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。 总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维">
<meta name="keywords" content="知识点梳理,计算机视觉">
<meta property="og:type" content="article">
<meta property="og:title" content="【置顶】计算机视觉知识点总结">
<meta property="og:url" content="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/index.html">
<meta property="og:site_name" content="从零开始的BLOG">
<meta property="og:description" content="神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。 使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。 使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。 总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1fww4hqied3j21kw0esjwt.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1g0ixnfk7w4j20o408q3yr.jpg">
<meta property="og:image" content="https://wx4.sinaimg.cn/large/d7b90c85ly1fxmo2fpvavj21650u079w.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g5nupi5fj21c80u0doq.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g6on0w08j21hc0u0b29.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6orzjmmj21hc0u0b29.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6ox6512j21hc0u0e81.jpg">
<meta property="og:image" content="https://wx3.sinaimg.cn/large/d7b90c85ly1fxc7ewvfr1j20u00wn0y7.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1fxc7gghlzjj21xt0l1n26.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1fxsf9g1udsj21q00s3152.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1fx1toyw0xkj20kc0a5wkw.jpg">
<meta property="og:image" content="https://wx3.sinaimg.cn/large/d7b90c85ly1g1hbfdtyvcj21dg0m6ta3.jpg">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/nvidia-smi.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/bottle.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/RooflineModel.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/RooflineModel2.png?x-oss-process=style/blog_img">
<meta property="og:image" content="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/Batch-Normalization深入解析">
<meta property="og:updated_time" content="2019-07-18T02:38:37.501Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="【置顶】计算机视觉知识点总结">
<meta name="twitter:description" content="神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。 使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。 使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。 总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维">
<meta name="twitter:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1fww4hqied3j21kw0esjwt.jpg">






  <link rel="canonical" href="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>【置顶】计算机视觉知识点总结 | 从零开始的BLOG</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?21a4899cc63d3c11a3d90ac58074a19c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">从零开始的BLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">与其感慨路难行，不如马上出发</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档<span class="badge">263</span></a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-计算机视觉">
    <a href="/categories/计算机视觉/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tripadvisor"></i> <br />计算机视觉</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-深度学习">
    <a href="/categories/深度学习/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-drupal"></i> <br />深度学习</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-caffe2">
    <a href="/categories/Caffe2/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-coffee"></i> <br />Caffe2</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-pytorch">
    <a href="/categories/PyTorch/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-free-code-camp"></i> <br />PyTorch</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-c++">
    <a href="/categories/Cpp/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-codiepie"></i> <br />C++</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-python">
    <a href="/categories/Python/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-product-hunt"></i> <br />Python</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-项目">
    <a href="/categories/项目/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-connectdevelop"></i> <br />项目</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-cuda">
    <a href="/categories/CUDA/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-braille"></i> <br />CUDA</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-其他">
    <a href="/categories/其他/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />其他</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签<span class="badge">40</span></a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于我</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />站内搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="站内搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    
  
  
  
    
      
    
    <a href="https://github.com/hellozhaozheng" class="github-corner" target="_blank" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#222; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg>
    
      </a>
    



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZeroZone">
      <meta itemprop="description" content="并不是什么厉害的地方<br>只是一个安静的学习角落">
      <meta itemprop="image" content="/images/avatar_zz.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="从零开始的BLOG">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">【置顶】计算机视觉知识点总结
              
            
          </h1>
        

        <div class="post-meta">
	
	     <i class="fa fa-thumb-tack"></i>
	    <font style="color:#999">置顶</font>
	    <span class="post-meta-divider">|</span>
	
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-10-23 20:32:39" itemprop="dateCreated datePublished" datetime="2018-10-23T20:32:39+08:00">2018-10-23</time>
            

            
          </span>

	  
  	    <span class="post-updated">
    		&nbsp; | &nbsp; 更新于
    		<time itemprop="dateUpdated" datetime="2019-07-18T10:38:37+08:00" content="2019-07-18">
      		  2019-07-18
    		</time>
  	  </span>
	  

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/面试/" itemprop="url" rel="index"><span itemprop="name">面试</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon"
            >
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">17k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">15 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。</p>
<p>使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。</p>
<p>使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。</p>
<h1 id="总目录篇"><a href="#总目录篇" class="headerlink" title="总目录篇"></a>总目录篇</h1><p><strong>机器学习:</strong> <a href="#逻辑回归">逻辑回归</a>, <a href="#支持向量机">支持向量机</a>, <a href="#决策树">决策树</a>, <a href="#降维">降维</a>, <a href="#聚类">聚类</a></p>
<p><strong>深度学习:</strong> <a href="#优化方法">优化方法</a>, <a href="#初始化方法">初始化方法</a>, <a href="#损失函数">损失函数</a>, <a href="#激活函数">激活函数</a>, <a href="#正则化">正则化</a>, <a href="#归一化">归一化</a>, <a href="#感受野">感受野</a>, <a href="#全连接层">全连接层</a>, <a href="#卷积层">卷积层</a>, <a href="#反卷积层">反卷积层</a>, <a href="#池化层">池化层</a>, <a href="#训练问题">训练问题</a></p>
<p><strong>网络结构:</strong> <a href="#AlexNet">AlexNet</a>, <a href="#VGGNet">VGGNet</a>, <a href="#InceptionV1">InceptionV1</a>, <a href="#InceptionV2">InceptionV2</a>, <a href="#InceptionV3">InceptionV3</a>, <a href="#InceptionV4">InceptionV4</a>, <a href="#Xception">Xception</a>, <a href="#ResNet">ResNet</a>, <a href="#ResNeXt">ResNeXt</a>, <a href="#DenseNet">DenseNet</a>, <a href="#SqueezeNet">SqueezeNet</a>, <a href="#MobileNet">MobileNet</a>, <a href="#MobileNetV2">MobileNetV2</a>, <a href="#ShuffleNet">ShuffleNet</a>, <a href="#ShuffleNetV2">ShuffleNetV2</a>, <a href="#SENetV2">SENet</a>,</p>
<p><strong>目标检测:</strong> <a href="#NMS">NMS</a></p>
<p><strong>图像处理:</strong> <a href="#图像放缩">图像放缩</a></p>
<p><strong>数学基础:</strong> <a href="#概率分布">概率分布</a>, 矩阵乘法优化</p>
<p><strong>常见问题:</strong></p>
<ul>
<li><a href="#目前的 SOTA 目标检测模型">目前的 SOTA 目标检测模型</a></li>
<li><a href="#SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别">SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</a></li>
<li><a href="#常用的训练 Trick">常用的训练 Trick</a></li>
<li><a href="#有哪些数据增广方法? 怎么实现的?">有哪些数据增广方法? 怎么实现的?</a></li>
<li><a href="#PyTorch 和 TensorFlow 的区别">PyTorch 和 TensorFlow 的区别</a></li>
<li><a href="#目标检测领域还有哪些可以继续改进或者优化的地方">目标检测领域还有哪些可以继续改进或者优化的地方</a></li>
</ul>
<h1 id="机器学习篇"><a href="#机器学习篇" class="headerlink" title="机器学习篇"></a>机器学习篇</h1><p>各种机器学习算法的应用场景分别是什么(比如朴素贝叶斯、决策树、K 近邻、SVM、逻辑回归最大熵模型)<br><a href="https://www.zhihu.com/question/26726794/answer/151282052" target="_blank" rel="noopener">https://www.zhihu.com/question/26726794/answer/151282052</a></p>
<p><span id="基本概念"></span></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>PR 曲线</li>
<li>ROC 曲线</li>
</ul>
<p><span id="逻辑回归"></span></p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p><a href="../机器学习-逻辑回归">逻辑回归与线性回归</a></p>
<ul>
<li><a href="../机器学习-逻辑回归/#逻辑回归和线性回归的定义">逻辑回归和线性回归的定义</a></li>
<li><a href="../机器学习-逻辑回归/#逻辑回归与线性回归的联系和区别">逻辑回归和线性回归的联系和区别</a></li>
<li><a href="../机器学习-逻辑回归/#对于一个二分类问题">对于一个二分类问题, 如果数据集中存在一些离异值, 在不清洗数据的情况下, 选择逻辑回归还是 SVM? 为什么?</a></li>
<li><a href="../机器学习-逻辑回归/#逻辑回归和 SVM 的区别是什么">逻辑回归与 SVM 的区别是什么? 哪个是参数模型? 分别适合在什么情况下使用?</a></li>
</ul>
<p><span id="支持向量机"></span></p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p><a href="../机器学习-SVM深入解析">SVM深入解析</a></p>
<ul>
<li><a href="../机器学习-SVM深入解析/#简述 SVM 的基本概念和原理">简述 SVM 的基本概念和原理</a></li>
<li><a href="../机器学习-SVM深入解析/#SVM 推导过程">SVM 推导过程</a></li>
<li><a href="../机器学习-SVM深入解析/#SVM 如何解决线性不可分问题">SVM 如何解决线性不可分问题</a></li>
<li><a href="../机器学习-SVM深入解析/#为什么SVM的分类结果仅依赖于支持向量?">为什么SVM的分类结果仅依赖于支持向量?</a></li>
<li><a href="../机器学习-SVM深入解析/#如何选取核函数">如何选取核函数</a></li>
<li><a href="../机器学习-SVM深入解析/#为什么说高斯核函数将原始特征空间映射成了无限维空间?">为什么说高斯核函数将原始特征空间映射成了无限维空间?</a></li>
<li><a href="../机器学习-SVM深入解析/#核函数中不同参数的影响">核函数中不同参数的影响</a></li>
<li><a href="../机器学习-SVM深入解析/#既然深度学习技术性能表现已经全面超越 SVM, SVM 还有存在的必要吗?">既然深度学习技术性能表现以及全面超越 SVM, SVM 还有存在的必要吗?</a></li>
</ul>
<p><span id="决策树"></span></p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p><span id="降维"></span></p>
<h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><p><span id="聚类"></span></p>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><ul>
<li><a href="../机器学习-聚类分析/#简单介绍常用的聚类方法">简单介绍常用的聚类方法</a></li>
</ul>
<h1 id="深度学习篇"><a href="#深度学习篇" class="headerlink" title="深度学习篇"></a>深度学习篇</h1><p><span id="优化方法"></span></p>
<h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2><p><strong>梯度下降:</strong> SGD, Momentum, Nesterov, Adagrad, Adadelta, RMSprop, Adam, Adamax<br><strong>牛顿法:</strong><br><strong>拟牛顿法:</strong><br><strong>共轭梯度法:</strong></p>
<ul>
<li><a href="../深度学习-各种优化方法整理总结/#简述各种优化方法的概念及其优缺点">简述各种优化方法的概念及其优缺点</a></li>
<li><a href="../深度学习-各种优化方法整理总结/#简述 Adam 中使用的指数加权滑动平均法">简述 Adam 中使用的指数加权滑动平均法</a></li>
<li><p><a href="../深度学习-各种优化方法整理总结/#各种优化方法的源码实现">各种优化方法的源码实现</a></p>
</li>
<li><p>各个优化算法的形式, 优点和缺点</p>
</li>
<li>Adam 无法收敛?: <a href="https://www.jiqizhixin.com/articles/2017-12-06" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-12-06</a></li>
<li>SGD 的参数设置</li>
</ul>
<p><a href="https://www.cnblogs.com/happylion/p/4172632.html" target="_blank" rel="noopener">https://www.cnblogs.com/happylion/p/4172632.html</a></p>
<p><a href="https://www.cnblogs.com/shixiangwan/p/7532830.html" target="_blank" rel="noopener">https://www.cnblogs.com/shixiangwan/p/7532830.html</a></p>
<p><a href="https://www.cnblogs.com/hlongch/p/5734105.html" target="_blank" rel="noopener">https://www.cnblogs.com/hlongch/p/5734105.html</a></p>
<p><a href="https://www.baidu.com/link?url=8EyCqGYnldJzHuqBBGagV9juEA_nhCYvRElM2Tw0lBdewSmc0qshAy_AHAEegO-wT3vLsrcY1xSDdyLOmL09Ltm_UICAFX_C02QdkkSCcWW&amp;wd=&amp;eqid=ce9adcb10004685c000000035b5d4fb6" target="_blank" rel="noopener">https://www.baidu.com/link?url=8EyCqGYnldJzHuqBBGagV9juEA_nhCYvRElM2Tw0lBdewSmc0qshAy_AHAEegO-wT3vLsrcY1xSDdyLOmL09Ltm_UICAFX_C02QdkkSCcWW&amp;wd=&amp;eqid=ce9adcb10004685c000000035b5d4fb6</a></p>
<p><a href="../深度学习-各种优化方法整理总结">各种优化方法整理总结</a></p>
<p><a href="https://mp.weixin.qq.com/s/lh4jTYJroq6AKb2fYsP-GQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/lh4jTYJroq6AKb2fYsP-GQ</a></p>
<p><span id="初始化方法"></span></p>
<h2 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h2><p>constant, uniform, gaussian, xavier, msra(kaiming), bilinear</p>
<ul>
<li>各个初始化方法的形式,</li>
<li>神经网络训练时是否可以将全部参数初始化为 0?</li>
</ul>
<p><a href="../深度学习-各种初始化方法深入分析">深度学习-各种初始化方法深入分析</a></p>
<p><span id="损失函数"></span></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>绝对值损失(L1), 平方损失(L2), Binary 交叉熵, Softmax 交叉熵</p>
<p><a href="../深度学习-各种损失函数深入解析">深度学习-各种损失函数深入解析</a></p>
<ul>
<li>写出多层感知机的平方误差和交叉熵误差损失函数</li>
<li>推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式</li>
</ul>
<p><span id="激活函数"></span></p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>Sigmoid, Tanh, ReLU, Leaky ReLU, PReLU, RReLU, ELU, Maxout</p>
<ul>
<li>写出常用的激活函数的公式及其导数形式</li>
<li>简单画出常用激活函数的图像</li>
<li>为什么需要激活函数?</li>
<li>各个激活函数的优缺点和适用场景</li>
<li>Sigmoid 激活函数和 Softmax 激活函数的区别</li>
<li>什么情况下 ReLU 的神经元会死亡? 为什么? 如何解决?</li>
<li>激活函数的使用原则</li>
</ul>
<p><a href="../深度学习-各种激活函数深入解析">深度学习-各种激活函数深入解析</a></p>
<p><span id="正则化"></span></p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>L1, L2</p>
<p><a href="../深度学习-正则化方法深入解析">深度学习-正则化方法深入解析</a></p>
<ul>
<li>L1 正则和 L2 正则的特点是什么? 各有什么优势?</li>
<li>L1 和 L2 的区别有哪些?</li>
<li>L1正则化使模型参数稀疏的原理是什么?</li>
<li>为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验?</li>
<li>为什么权重矩阵稀疏可以防止过拟合?</li>
<li>为何权重参数 $w$ 减小就可以防止过拟合?</li>
<li>L0 范式和 L1 范式都能实现稀疏, 为什么不选择用 L0 而要用 L1?</li>
<li>为什么说 L2 范式可以优化计算?</li>
<li>正则项前面的系数一般怎么设置?</li>
</ul>
<p><span id="归一化"></span></p>
<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1fww4hqied3j21kw0esjwt.jpg" alt="图2"></div></p>
<ul>
<li>Batch Normalization<ul>
<li><a href="../深度学习-Batch-Normalization深入解析/#为什么要进行归一化">为什么要进行归一化</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#简述 BN 的原理">简述 BN 的原理</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 解决了什么问题">BN 解决了什么问题</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#使用 BN 有什么好处">使用 BN 有什么好处</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 层通常处于网络中的什么位置">BN 层通常处于网络中的什么位置</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 中 batch 的大小对网络性能有什么影响">BN 中 batch 的大小对网络性能有什么影响</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 中线性偏移的参数个数怎么计算的">BN 中线性偏移的参数个数怎么计算的</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 中使用的均值和方差是如何求得的">BN 中的使用的均值和方差是如何求得的</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#在多卡训练使用 BN 时, 需要注意什么问题">在多卡训练使用 BN 时, 需要注意什么问题</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#使用 BN 时, 前一层的卷积网络需不需要偏置项, 为什么">使用 BN 时, 前一层的卷积网络需不需要偏置项, 为什么</a></li>
</ul>
</li>
<li>Group Normalization<ul>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#简述 GN 的原理">简述 GN 的原理</a></li>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#为什么 GN 效果好">为什么 GN 效果好</a></li>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#简述 BN, LN, IN, GN 的区别">简述 BN, LN, IN, GN 的区别</a></li>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#GN 中线性偏移的参数个数怎么计算的">GN 中线性偏移的参数个数怎么计算的</a></li>
</ul>
</li>
<li>Layer Normalization</li>
<li>Instance Normalization</li>
<li>Switchable Normalization</li>
</ul>
<p><span id="感受野"></span></p>
<h2 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h2><ul>
<li>感受野的作用</li>
<li>理论感受野和有效感受野的区别? <a href="https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw</a></li>
<li>目标检测中的 anchor 的设置和感受野的大小之间有什么关系? <a href="https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw</a></li>
</ul>
<p><span id="全连接层"></span></p>
<h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><ul>
<li>全连接层的作用是什么? <a href="https://www.zhihu.com/question/41037974" target="_blank" rel="noopener">https://www.zhihu.com/question/41037974</a></li>
<li>为什么要将全连接层转化为卷积层? <a href="https://www.cnblogs.com/liuzhan709/p/9356960.html" target="_blank" rel="noopener">https://www.cnblogs.com/liuzhan709/p/9356960.html</a></li>
<li>请推导全连接层的反向传播算法. <a href="https://zhuanlan.zhihu.com/p/39195266" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/39195266</a></li>
</ul>
<p><span id="卷积层"></span></p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积层的作用?</p>
<ul>
<li><a href="../深度学习-各种网络层/#简述 1x1 卷积层的作用">简述 1x1 卷积层的作用</a></li>
<li><a href="../深度学习-各种网络层/#卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用">卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用</a></li>
<li><a href="../深度学习-各种网络层/#卷积层底层是如何实现的">卷积层底层是如何实现的</a></li>
<li><a href="../深度学习-各种网络层/#简述矩阵乘法的优化方法">简述矩阵乘法的优化方法</a></li>
</ul>
<p><strong>卷积操作通常由 GEMM 实现</strong>, 但是需要在内存进行名为 im2col 的初始重新排序, 以便将其映射到 GEMM 当中.</p>
<p>卷积核的大小如何确定?<br>卷积核的大小决定了该卷积核在上一层特征图谱上的感受野大小，在确定卷积核的大小时有以下原则（并非通用性原则，实际设计时需要结合具体情况决定）：在网络的起始层，选用较大的卷积核（7×7），这样可以使得卷积核“看到”更多的原图特征；在网络中中间层，可以用两个3×3大小的卷积层来代替一个5×5大小的卷积层，这样做可以在保持感受野大小不变的情况下降低参数个数，减少模型复杂度；通常使用奇数大小的卷积核，原因有二，一是可以更加方便的进行padding，二是奇数核相对于偶数核，具有天然的中心点，并且对边沿、对线条更加敏感，可以更有效的提取边沿信息</p>
<p><span id="反卷积层"></span></p>
<h2 id="反卷积层"><a href="#反卷积层" class="headerlink" title="反卷积层"></a>反卷积层</h2><p>反卷积与上采样.</p>
<ul>
<li>反卷积和双线性插值的区别, 各自的优势</li>
</ul>
<p><span id="池化层"></span></p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层的作用?</p>
<ul>
<li>平均池化和最大池化有什么异同?</li>
<li>为什么用全局平均池化替换全连接层?</li>
</ul>
<p>讲一下pooling的作用， 为什么max pooling要更常用？哪些情况下，average pooling比max pooling更合适？</p>
<p>个人理解: 最大池化层会保留核内的最大响应值, 也可以理解成是最显著的特征, 然后利用这些最显著的特征去预测, 从直觉上来说会取得较好的效果, 就像是人眼一样, 我们往往只通过一些很明显的特征就可以判断出一个物体的种类, 最大池化多多少少也有这一层含义.<br>而 mean pooling 是平均核内的所有特征, 这样做有一点不好的地方就是, 显著的响应值会被周围的不显著响应值所影响, 因此, 最终可能会得到一个不高不低的值. 举一个例子, 比如两处不同的位置进行 mean pooling, 一处的最大值是100, 然后经过mean pooling 之后, 它的输出值变成了 20, 而另一处的最大值是50, 然后经过mean pooling 之后它的输出值也是20, 这样, 对于不同的特征, 我们却得到了重复的结果, 这实际上是一种信息冗余, 也可以认为是一种特征丢失, 因此, 在使用中, maxpooling 更常用.</p>
<p>什么时候mean pooling 更好用? 通常在整个网络的最后, 我们会使用 gap 来整合整体的特征, 此时, 因为特征图谱已经是经过高度提取抽象后的, 所以, 我们不能只关注那些最大的值, 图谱上的每一个值所对应的特征我们都需要综合考虑, 因此, 我们通常会用 gap 来得到固定长度的特征向量, 进行最大的分类预测.</p>
<p>池化层的作用:<br>降低优化难度和参数个数：池化层可以降低特征图谱的维度，从而降低网络整体的复杂度，不仅可以加速计算，也能起到一定的防止过拟合的作用<br>增大感受野：当没有pooling时，一个3×3，步长为1的卷积，那么输出的一个像素的感受野就是3<em>3的区域，再加一个stride=1的3</em>3卷积，则感受野为5*5。当使用pooling后，很明显感受野迅速增大，这就是pooling的一大用处。感受野的增加对于模型的能力的提升是必要的，正所谓“一叶障目则不见泰山也”<br>平移不变性：pooling层只会关注核内的值，而不会关注该值的位置，因此，当目标位置发生移动时，pooling层也可以得到相同的结果，所以pooling层在一定程度上可以增加CNN网络的平移不变性</p>
<p><span id="训练问题"></span></p>
<h2 id="训练问题"><a href="#训练问题" class="headerlink" title="训练问题"></a>训练问题</h2><p><a href="../深度学习-训练问题">训练过程中遇到的问题及解决方案</a></p>
<ul>
<li><a href="../深度学习-训练问题/#在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题?">在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题?</a></li>
<li><a href="../深度学习-训练问题/#如何解决数据不均衡问题?">如何解决数据不均衡问题?</a></li>
<li><a href="../深度学习-训练问题/#训练不收敛的具体表现是什么? 可能的原因是什么? 如何解决?">训练不收敛的具体表现是什么? 可能的原因是什么? 如何解决?</a></li>
<li><a href="../深度学习-训练问题/#训练过程中出现 Nan 值是什么原因? 如何解决?">训练过程中出现 Nan 值是什么原因? 如何解决?</a></li>
<li><a href="../深度学习-训练问题/#过拟合是什么? 如何处理过拟合?">过拟合是什么? 如何处理过拟合?</a></li>
<li><a href="../深度学习-训练问题/#欠拟合是什么? 如何处理欠拟合?">欠拟合是什么? 如何处理欠拟合?</a></li>
<li><a href="../深度学习-训练问题/#Dropout 的实现方式在训练阶段和测试阶段有什么不同? 如何保持训练和测试阶段的一致性?">Dropout 的实现方式在训练阶段和测试阶段有什么不同? 如何保持训练和测试阶段的一致性?</a></li>
<li><a href="../深度学习-训练问题/#Dropout 为什么可以起到防止过拟合的作用?">Dropout 为什么可以起到防止过拟合的作用?</a></li>
<li><a href="../深度学习-训练问题/#如何选取 Batch Size 的值? 显存中通常会存储哪些东西?">如何选取 Batch Size 的值? 显存中通常会存储哪些东西?</a></li>
</ul>
<h1 id="网络结构篇"><a href="#网络结构篇" class="headerlink" title="网络结构篇"></a>网络结构篇</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">模型</th>
<th style="text-align:center">层数</th>
<th style="text-align:center">特点</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">Top-1 Acc</th>
<th style="text-align:center">Top-5 Acc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AlexNet</td>
<td style="text-align:center">8</td>
<td style="text-align:center"></td>
<td style="text-align:center">6000w+</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">VGGNet</td>
<td style="text-align:center">19</td>
<td style="text-align:center"></td>
<td style="text-align:center">1亿3000w+</td>
<td style="text-align:center">71.1</td>
<td style="text-align:center">89.8</td>
</tr>
<tr>
<td style="text-align:center">InceptionV1 (GoogLeNet)</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">69.8</td>
<td style="text-align:center">89.6</td>
</tr>
<tr>
<td style="text-align:center">InceptionV2</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">73.9</td>
<td style="text-align:center">91.8</td>
</tr>
<tr>
<td style="text-align:center">InceptionV3</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center">2000w+</td>
<td style="text-align:center">78.0</td>
<td style="text-align:center">93.9</td>
</tr>
<tr>
<td style="text-align:center">InceptionV4</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">80.2</td>
<td style="text-align:center">95.2</td>
</tr>
<tr>
<td style="text-align:center">ResNet</td>
<td style="text-align:center">152</td>
<td style="text-align:center"></td>
<td style="text-align:center">200w</td>
<td style="text-align:center">76.8</td>
<td style="text-align:center">93.2</td>
</tr>
<tr>
<td style="text-align:center">InceptionResNet</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">80.4</td>
<td style="text-align:center">95.3</td>
</tr>
<tr>
<td style="text-align:center">ResNeXt</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<p><span id="AlexNet"></span></p>
<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1g0ixnfk7w4j20o408q3yr.jpg" alt=""></div></p>
<p>AlexNet 的网络结构相对来说比较简单, 它包括 5 层卷积层, 3 层最大池化层, 以及 3 层全连接层. 池化层被分别放置在 conv1, conv2, 和 conv5 的后面. 虽然 AlexNet 结构简单, 但是由于全连接层的存在, 使得 AlexNet 的参数量较大, 大约有 6000w 个参数.</p>
<p><span id="VGGNet"></span></p>
<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h2><p><div style="width: 550px; margin: auto"><img src="https://wx4.sinaimg.cn/large/d7b90c85ly1fxmo2fpvavj21650u079w.jpg" alt=""></div></p>
<p>VGGNet 的网络结构延续了 AlexNet 的设计思想. 将卷积层分成 5 段, 每一段之间通过池化层分隔开, 后面同样跟了 3 层全连接层, 同时他用多个小卷积核替换了 AlexNet 中的大卷积核, 可以在减少参数量的同时提高感受野的范围, 并且通过统建更深层的网络, 使得提取到的特征图谱的表征能力更强. VGGNet 比较常用的结构有 VGG16 和 VGG19. 二者的区别在于前者每个卷积段的卷积层数量是(2, 2, 3, 3, 3), 后者每个卷积段中的卷积层数量是(2, 2, 4, 4, 4).</p>
<p><span id="InceptionV1"></span></p>
<h2 id="InceptionV1"><a href="#InceptionV1" class="headerlink" title="InceptionV1"></a><a href="../计算机视觉-InceptionV1">InceptionV1</a></h2><p>GoogLeNet 模型的核心思想是 <strong>卷积神经网络中的最优局部稀疏结构可以被现有的组件逼近和覆盖, 因此, 只要找到这个局部最优结构, 并在网络结构中重复使用它, 就可以进一步提升神经网络的拟合能力.</strong> 于是, InceptionV1 跳出了传统卷积神经网络的简单堆叠结构, 首次提出了 Inception 模块. Inception 模块综合了 1x1, 3x3, 5x5 这三种不同尺度的卷积核进行特征提取, 同时, 考虑到池化层的重要作用, 还综合了 3x3 大小的最大池化层. 并且, 还在 3x3 和 5x5 的卷积层之前, 以及池化层之后, 使用了 1x1 的卷积层来降低特征维度, 从而减少计算量. 以 Inception 模块为基本单元就可以构建出 IncetionV1 模型, 构建时仍然遵循了 5 个卷积段的段落形式, 段之间通过最大池化层分隔, 具体来说, 前两段使用的是传统的卷积层, 其中第一段是单层的 7x7 大小的卷积层, 第二段是两层较小尺寸的卷积层(1x1, 3x3), 后三段卷积段都是由 Inception 模块组成, 每一段使用的 Inception 模块数量分别为 2, 5, 2. 最后的分类层由全局平均池化层, 全连接层, Softmax 激活层组成. 另外, 由于网络结构较深, 因此, 为了防止梯度消失, InceptionV1 分别在 4a 和 4d 的 Inception 模块上添加了辅助侧枝分类器, 该分类器由一层平均池化层, 一层 1x1 卷积层, 两层全连接层和 Softmax 激活层组成.</p>
<ul>
<li><a href="../计算机视觉-InceptionV1/#简述一下 GoogLeNet 采用多个卷积核的原因">简述一下 GoogLeNet 采用多个卷积核的原因</a></li>
<li><a href="../计算机视觉-InceptionV1/#Inception 中为什么使用 1×1 卷积层">Inception 中为什么使用 1×1 卷积层</a></li>
<li><a href="../计算机视觉-InceptionV1/#Inception 中为什么使用全局平均池化层">Inception 中为什么使用全局平均池化层</a></li>
<li><a href="../计算机视觉-InceptionV1/#为什么使用侧枝">为什么使用侧枝</a></li>
<li><a href="../计算机视觉-InceptionV1/#GoogLeNet 在哪些地方使用了全连接层">GoogLeNet 在哪些地方使用了全连接层</a></li>
</ul>
<p><span id="InceptionV3"></span></p>
<h2 id="InceptionV3"><a href="#InceptionV3" class="headerlink" title="InceptionV3"></a><a href="../计算机视觉-InceptionV3">InceptionV3</a></h2><h3 id="简述-InceptionV2-相比于-GoogLeNet-有什么区别"><a href="#简述-InceptionV2-相比于-GoogLeNet-有什么区别" class="headerlink" title="简述 InceptionV2 相比于 GoogLeNet 有什么区别"></a>简述 InceptionV2 相比于 GoogLeNet 有什么区别</h3><p>InceptionV2 改进的主要有两点. 一方面加入了 BN 层, 减少了 Internal Covariate Shift 问题(内部网络层的数据分布发生变化), 另一方面参考了 VGGNet 用两个 $3\times 3$ 的卷积核替代了原来 Inception 模块中的 $5\times 5$ 卷积核, 可以在降低参数量的同时加速计算.</p>
<h3 id="简述-InceptionV3-相比于-GoogLeNet-有什么区别"><a href="#简述-InceptionV3-相比于-GoogLeNet-有什么区别" class="headerlink" title="简述 InceptionV3 相比于 GoogLeNet 有什么区别"></a>简述 InceptionV3 相比于 GoogLeNet 有什么区别</h3><p>InceptionV3 最重要的改进是分解(Factorization), 这样做的好处是既可以加速计算(多余的算力可以用来加深网络), 有可以将一个卷积层拆分成多个卷积层, 进一步加深网络深度, 增加神经网络的非线性拟合能力, 还有值得注意的地方是网络输入从 $224\times 224$ 变成了 $299\times 299$, 更加精细设计了 $35\times 35$, $17\times 17$, $8\times 8$ 特征图谱上的 Inception 模块.<br>具体来说, 首先将第一个卷积段的 $7\times 7$ 大小的卷积核分解成了 3 个 $3\times 3$ 大小的卷积核. 在第二个卷积段也由 3 个 $3\times 3$ 大小的卷积核组成. 第三个卷积段使用了 3 个 Inception 模块, 同时将模块中的 $5\times 5$ 卷积分解成了两个 $3\times 3$ 大小的卷积. 在第四个卷积段中, 使用了 5 个分解程度更高的 Inception 模块, 具体来说, 是将 $n\times n$ 大小的卷积核分解成 $1\times n$ 和 $n\times 1$ 大小的卷积核, 在论文中, 对于 $17\times 17$ 大小的特征图谱, 使用了 $n = 7$ 的卷积分解形式. 在第五个卷积段中, 面对 $8\times 8$ 大小的特征图谱, 使用了两个设计更加精细的 Inception 模块. 它将 $3\times 3$ 大小的卷积层分解成 $1\times 3$ 和 $3\times 1$ 的卷积层, 这两个卷积层不是之前的串联关系, 而是并联关系.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g5nupi5fj21c80u0doq.jpg" alt="Inception"></div></p>
<ul>
<li><a href="..//#Inception 模块的设计和使用原则是什么">Inception 模块的设计和使用原则是什么</a></li>
</ul>
<p><span id="InceptionV4"></span></p>
<h2 id="InceptionV4-and-Inception-ResNet"><a href="#InceptionV4-and-Inception-ResNet" class="headerlink" title="InceptionV4 and Inception ResNet"></a><a href="../计算机视觉-InceptionV4-InceptionResNet">InceptionV4 and Inception ResNet</a></h2><p><strong>Inception 系列的缺点:</strong> 模块过于复杂, 人工设计的痕迹太重了.</p>
<h3 id="简述-InceptionV4-做了哪些改进"><a href="#简述-InceptionV4-做了哪些改进" class="headerlink" title="简述 InceptionV4 做了哪些改进"></a>简述 InceptionV4 做了哪些改进</h3><p>InceptionV4 使用了更复杂的结构重新设计了 Inception 模型中的每一个模块. 包括 Stem 模块, 三种不同的 Inception 模块以及两种不同的 Reduction 模块. 每一个模块的具体参数设置均不太一样, 但是整体来说都遵循的卷积分解和空间聚合的思想.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g6on0w08j21hc0u0b29.jpg" alt="InceptionV4"></div></p>
<h3 id="简述-Inception-Resnet-v1-做了哪些改进"><a href="#简述-Inception-Resnet-v1-做了哪些改进" class="headerlink" title="简述 Inception-Resnet-v1 做了哪些改进"></a>简述 Inception-Resnet-v1 做了哪些改进</h3><p>Inception ResNet v1 网络主要被用来与 Inception v3 模型性能进行比较, 因此它所用的 Inception 子网络的计算相对常规模块有所减少, 这是为了保证使得它的整体计算和内存消耗与 Inception v3 近似, 如此才能保证公平性. 具体来说, Inception ResNet v1 网络主要讲 ResNet 中的残差思想用到了 Inception 模块当中, 对于每一种不太的 Inception 模块, 都添加了一个短接连接来发挥残差模型的优势.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6orzjmmj21hc0u0b29.jpg" alt="InceptionResNetV1"></div></p>
<h3 id="简述-Inception-ResNet-v2-做了哪些改进"><a href="#简述-Inception-ResNet-v2-做了哪些改进" class="headerlink" title="简述 Inception-ResNet-v2 做了哪些改进"></a>简述 Inception-ResNet-v2 做了哪些改进</h3><p>Inception ResNet v2 主要被设计来探索残差模块用于 Inception 网络时所尽可能带来的性能提升. 因此它是论文给出的最终性能最高的网络设计方案, 它和 Inception ResNet v1 的不同主要有两点, 第一是使用了 InceptionV4 中的更复杂的 Stem 结构, 第二是对于每一个 Inception 模块, 其空间聚合的维度都有所提升. 其模型结构如下所示:</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6ox6512j21hc0u0e81.jpg" alt="InceptionResNetV2"></div></p>
<p><span id="Xception"></span></p>
<h2 id="Xception"><a href="#Xception" class="headerlink" title="Xception"></a><a href="">Xception</a></h2><p><span id="ResNet"></span></p>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a><a href="../计算机视觉-ResNet-CVPR2016">ResNet</a></h2><ul>
<li><a href="../计算机视觉-ResNet-CVPR2016/#简述 ResNet 的原理">简述 ResNet 的原理</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#ResNet 中可以使用哪些短接方式">ResNet 中可以使用哪些短接方式</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#如何理解所谓的残差比原始目标更容易优化">如何理解所谓的残差 $F(x)$ 比原始目标 $H(x)$ 更容易优化</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5">为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#ResNet 到底解决了一个什么问题">ResNet 到底解决了一个什么问题</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#ResNet 残差模块中激活层应该如何放置">ResNet 残差模块中激活层应该如何放置</a></li>
</ul>
<p><span id="ResNeXt"></span></p>
<h2 id="ResNeXt"><a href="#ResNeXt" class="headerlink" title="ResNeXt"></a><a href="../计算机视觉-ResNeXt-CVPR2017">ResNeXt</a></h2><ul>
<li><a href="../计算机视觉-ResNeXt-CVPR2017/#ResNeXt 在 ResNet 上做了哪些改进">ResNeXt 在 ResNet 上做了哪些改进</a></li>
</ul>
<p><div style="width: 550px; margin: auto"><img src="https://wx3.sinaimg.cn/large/d7b90c85ly1fxc7ewvfr1j20u00wn0y7.jpg" alt=""></div></p>
<p><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1fxc7gghlzjj21xt0l1n26.jpg" alt=""></div></p>
<p><span id="DenseNet"></span></p>
<h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a><a href="">DenseNet</a></h2><ul>
<li><a href="../计算机视觉-DenseNet-CVPR2017/#简述 DenseNet 的原理">简述 DenseNet 的原理</a></li>
</ul>
<p><span id="SqueezeNet"></span></p>
<h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a><a href="">SqueezeNet</a></h2><ul>
<li><a href="../计算机视觉-SqueezeNet/#简述 SqueezeNet 的原理">简述 SqueezeNet 的原理</a></li>
</ul>
<p><span id="MobileNet"></span></p>
<h2 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a><a href="../计算机视觉-MobileNet">MobileNet</a></h2><ul>
<li><a href="../计算机视觉-MobileNet/#简述 MobileNet 的原理">简述 MobileNet 的原理</a></li>
</ul>
<p><span id="MobileNetV2"></span></p>
<h2 id="MobileNetV2"><a href="#MobileNetV2" class="headerlink" title="MobileNetV2"></a><a href="">MobileNetV2</a></h2><ul>
<li><a href="../计算机视觉-MobileNetV2/#MobileNetV2 做了哪些改进">MobileNetV2 做了哪些改进</a></li>
</ul>
<p><span id="ShuffleNet"></span></p>
<h2 id="ShuffleNet"><a href="#ShuffleNet" class="headerlink" title="ShuffleNet"></a><a href="../计算机视觉-ShuffleNet">ShuffleNet</a></h2><ul>
<li><a href="../计算机视觉-ShuffleNet/#简述 ShuffleNet 的原理">简述 ShuffleNet 的原理</a></li>
<li><a href="../计算机视觉-ShuffleNet/简述 ShuffleNet 和 MobileNet 的区别">简述 ShuffleNet 和 MobileNet 的区别</a></li>
</ul>
<p><span id="ShuffleNetV2"></span></p>
<h2 id="ShuffleNetV2"><a href="#ShuffleNetV2" class="headerlink" title="ShuffleNetV2"></a><a href="">ShuffleNetV2</a></h2><ul>
<li><a href="..//#ShuffleNetV2 做了哪些改进">ShuffleNetV2 做了哪些改进</a></li>
</ul>
<p><span id="SENet"></span></p>
<h2 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a><a href="">SENet</a></h2><ul>
<li><a href="..//#简述 SENet 的原理">简述 SENet 的原理</a></li>
</ul>
<h1 id="目标检测篇"><a href="#目标检测篇" class="headerlink" title="目标检测篇"></a>目标检测篇</h1><p><span id="NMS"></span></p>
<h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h2><h3 id="简述-NMS-的原理"><a href="#简述-NMS-的原理" class="headerlink" title="简述 NMS 的原理"></a><a href="../计算机视觉-NMS-Implementation/#简述 NMS 的原理">简述 NMS 的原理</a></h3><p>非极大值抑制(Non-Maximum Suppression, NMS), 顾名思义就是抑制那些不是极大值的元素, 可以理解为局部最大值搜索. 对于目标检测来说, 非极大值抑制的含义就是对于重叠度较高的一部分同类候选框来说, 去掉那些置信度较低的框, 只保留置信度最大的那一个进行后面的流程, 这里的重叠度高低与否是通过 NMS 阈值来判断的.</p>
<p>计算两个边框 IoU 的公式如下所示:</p>
<script type="math/tex; mode=display">x1 = \max (box1_{x1}, box2_{x1}), y1 = \max (box1_{y1}, box2_{y1})</script><script type="math/tex; mode=display">x2 = \min (box1_{x2}, box2_{x2}), y2 = \min (box1_{y2}, box2_{y2})</script><script type="math/tex; mode=display">intersection = (x2 - x1 + 1) \times (y2 - y1 + 1)</script><script type="math/tex; mode=display">IoU = \frac{intersection}{area1+area2-intersection}</script><p><span id="NMS 算法源码实现"></span></p>
<h3 id="NMS-算法源码实现"><a href="#NMS-算法源码实现" class="headerlink" title="NMS 算法源码实现"></a><a href="../计算机视觉-NMS-Implementation/#NMS 算法源码实现">NMS 算法源码实现</a></h3><p><strong>算法逻辑:</strong><br>输入: $n$ 行 $4$ 列的候选框数组, 以及对应的 $n$ 行 $1$ 列的置信度数组.<br>输出: $m$ 行 $4$ 列的候选框数组, 以及对应的 $m$ 行 $1$ 列的置信度数组, $m$ 对应的是去重后的候选框数量<br>算法流程:</p>
<ol>
<li>计算 $n$ 个候选框的面积大小</li>
<li>对置信度进行排序, 获取排序后的下标序号, 即采用<code>argsort</code></li>
<li>将当前置信度最大的框加入返回值列表中</li>
<li>获取当前置信度最大的候选框与其他任意候选框的相交面积</li>
<li>利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除.</li>
<li>对剩余的框重复以上过程</li>
</ol>
<p><strong>Python 实现:</strong><br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span><span class="params">(bounding_boxes, confidence_score, threshold)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(bounding_boxes) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> [], []</span><br><span class="line">    bboxes = np.array(bounding_boxes)</span><br><span class="line">    score = np.array(confidence_score)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 n 个候选框的面积大小</span></span><br><span class="line">    x1 = bboxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = bboxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = bboxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = bboxes[:, <span class="number">3</span>]</span><br><span class="line">    areas =(x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对置信度进行排序, 获取排序后的下标序号, argsort 默认从小到大排序</span></span><br><span class="line">    order = np.argsort(score)</span><br><span class="line"></span><br><span class="line">    picked_boxes = [] <span class="comment"># 返回值</span></span><br><span class="line">    picked_score = [] <span class="comment"># 返回值</span></span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 将当前置信度最大的框加入返回值列表中</span></span><br><span class="line">        index = order[<span class="number">-1</span>]</span><br><span class="line">        picked_boxes.append(bounding_boxes[index])</span><br><span class="line">        picked_score.append(confidence_score[index])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前置信度最大的候选框与其他任意候选框的相交面积</span></span><br><span class="line">        x11 = np.maximum(x1[index], x1[order[:<span class="number">-1</span>]])</span><br><span class="line">        y11 = np.maximum(y1[index], y1[order[:<span class="number">-1</span>]])</span><br><span class="line">        x22 = np.minimum(x2[index], x2[order[:<span class="number">-1</span>]])</span><br><span class="line">        y22 = np.minimum(y2[index], y2[order[:<span class="number">-1</span>]])</span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, x22 - x11 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, y22 - y11 + <span class="number">1</span>)</span><br><span class="line">        intersection = w * h</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除</span></span><br><span class="line">        ratio = intersection / (areas[index] + areas[order[:<span class="number">-1</span>]] - intersection)</span><br><span class="line">        left = np.where(ratio &lt; threshold)</span><br><span class="line">        order = order[left]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> picked_boxes, picked_score</span><br></pre></td></tr></table></figure></p>
<p><strong>C++ 实现</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Bbox</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> x1;</span><br><span class="line">    <span class="keyword">int</span> y1;</span><br><span class="line">    <span class="keyword">int</span> x2;</span><br><span class="line">    <span class="keyword">int</span> y2;</span><br><span class="line">    <span class="keyword">float</span> score;</span><br><span class="line">    Bbox(<span class="keyword">int</span> x1_, <span class="keyword">int</span> y1_, <span class="keyword">int</span> x2_, <span class="keyword">int</span> y2_, <span class="keyword">float</span> s):</span><br><span class="line">	x1(x1_), y1(y1_), x2(x2_), y2(y2_), score(s) &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">iou</span><span class="params">(Bbox box1, Bbox box2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> area1 = (box1.x2 - box1.x1 + <span class="number">1</span>) * (box1.y2 - box1.y1 + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">float</span> area2 = (box2.x2 - box2.x1 + <span class="number">1</span>) * (box2.y2 - box2.y1 + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> x11 = <span class="built_in">std</span>::max(box1.x1, box2.x1);</span><br><span class="line">    <span class="keyword">int</span> y11 = <span class="built_in">std</span>::max(box1.y1, box2.y1);</span><br><span class="line">    <span class="keyword">int</span> x22 = <span class="built_in">std</span>::min(box1.x2, box2.x2);</span><br><span class="line">    <span class="keyword">int</span> y22 = <span class="built_in">std</span>::min(box1.y2, box2.y2);</span><br><span class="line">    <span class="keyword">float</span> intersection = (x22 - x11 + <span class="number">1</span>) * (y22 - y11 + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> intersection / (area1 + area2 - intersection);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Bbox&gt; nms(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Bbox&gt; &amp;vecBbox, <span class="keyword">float</span> threshold) &#123;</span><br><span class="line">    <span class="keyword">auto</span> cmpScore = [](Bbox box1, Bbox box2) &#123;</span><br><span class="line">	<span class="keyword">return</span> box1.score &lt; box2.score; <span class="comment">// 升序排列, 令score最大的box在vector末端</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">std</span>::sort(vecBbox.begin(), vecBbox.end(), cmpScore);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Bbox&gt; pickedBbox;</span><br><span class="line">    <span class="keyword">while</span> (vecBbox.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        pickedBbox.emplace_back(vecBbox.back());</span><br><span class="line">        vecBbox.pop_back();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; vecBbox.size(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (iou(pickedBbox.back(), vecBbox[i]) &gt;= threshold) &#123;</span><br><span class="line">                vecBbox.erase(vecBbox.begin() + i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> pickedBbox;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>CUDA 实现:</strong></p>
<h3 id="简述-Soft-NMS-的原理"><a href="#简述-Soft-NMS-的原理" class="headerlink" title="简述 Soft-NMS 的原理"></a><a href="../计算机视觉-NMS-Implementation/#简述 Soft-NMS 的原理及算法实现">简述 Soft-NMS 的原理</a></h3><p>在 Soft-NMS 中, 对于那些重叠度大于一定阈值的 box, 我们并不将其删除, 而仅仅只是根据重叠程度来降低那些 box 的 socre, 这样一来, 这些 box 仍旧处于 box 列表中, 只是 socre 的值变低了. 具体来说, 如果 box 的重叠程度高, 那么 score 的值就会变得很低, 如果重叠程度小, 那么 box 的 score 值就只会降低一点, Soft-NMS 算法伪代码如下图所示:</p>
<h3 id="Soft-NMS-算法源码实现"><a href="#Soft-NMS-算法源码实现" class="headerlink" title="Soft-NMS 算法源码实现"></a><a href="../计算机视觉-NMS-Implementation/#Soft-NMS 算法源码实现">Soft-NMS 算法源码实现</a></h3><p><strong>算法逻辑:</strong><br>输入:</p>
<ul>
<li>bboxes: 坐标矩阵, 每个边框表示为 [x1, y1, x2, y2]</li>
<li>scores: 每个 box 对应的分数, 在 Soft-NMS 中, scores 会发生变化(<strong>对外部变量也有影响</strong>)</li>
<li>iou_thresh:   交并比的最低阈值</li>
<li>sigma2: 使用 gaussian 函数的方差, sigma2 代表 $\sigma^2$</li>
<li>score_thresh: 最终分数的最低阈值</li>
<li>method: 使用的惩罚方法, 1 代表线性惩罚, 2 代表高斯惩罚, 其他情况代表默认的 NMS</li>
</ul>
<p>返回值: 最终留下的 boxes 的 index, 同时, scores 值也已经被改变.<br>算法流程:</p>
<ol>
<li>在 bboxes 之后添加对于的下标[0, 1, 2…], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标</li>
<li>计算每个 box 自身的面积</li>
<li><strong>对于每一个下标 $i$</strong>, 找出 i 后面的最大 score 及其下标, 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大.</li>
<li>计算 IoU</li>
<li>根据用户选定的方法更新 scores 的值</li>
<li>以上过程循环 $N$ 次后($N$ 为总边框的数量), 将最终得分大于最低阈值的下标返回, 根据下标获取最终存留的 Boxes, <strong>注意, 此时, 外部 scores 的值已经完成更新, 无需借助下标来获取.</strong></li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_nms</span><span class="params">(bboxes, scores, iou_thresh=<span class="number">0.3</span>, sigma2=<span class="number">0.5</span>, score_thresh=<span class="number">0.001</span>, method=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 在 bboxes 之后添加对于的下标[0, 1, 2...], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标</span></span><br><span class="line">    N = bboxes.shape[<span class="number">0</span>] <span class="comment"># 总的 box 的数量</span></span><br><span class="line">    indexes = np.array([np.arange(N)])  <span class="comment"># 下标: 0, 1, 2, ..., n-1</span></span><br><span class="line">    bboxes = np.concatenate((bboxes, indexes.T), axis=<span class="number">1</span>) <span class="comment"># concatenate 之后, bboxes 的操作不会对外部变量产生影响</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个 box 的面积</span></span><br><span class="line">    x1 = bboxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = bboxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = bboxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = bboxes[:, <span class="number">3</span>]</span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="comment"># 找出 i 后面的最大 score 及其下标</span></span><br><span class="line">        pos = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i != N<span class="number">-1</span>:</span><br><span class="line">            maxscore = np.max(scores[pos:], axis=<span class="number">0</span>)</span><br><span class="line">            maxpos = np.argmax(scores[pos:], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            maxscore = scores[<span class="number">-1</span>]</span><br><span class="line">            maxpos = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大</span></span><br><span class="line">        <span class="keyword">if</span> scores[i] &lt; maxscore:</span><br><span class="line">            bboxes[[i, maxpos + i + <span class="number">1</span>]] = bboxes[[maxpos + i + <span class="number">1</span>, i]]</span><br><span class="line">            scores[[i, maxpos + i + <span class="number">1</span>]] = scores[[maxpos + i + <span class="number">1</span>, i]]</span><br><span class="line">            areas[[i, maxpos + i + <span class="number">1</span>]] = areas[[maxpos + i + <span class="number">1</span>, i]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># IoU calculate</span></span><br><span class="line">        xx1 = np.maximum(bboxes[i, <span class="number">0</span>], bboxes[pos:, <span class="number">0</span>])</span><br><span class="line">        yy1 = np.maximum(bboxes[i, <span class="number">1</span>], bboxes[pos:, <span class="number">1</span>])</span><br><span class="line">        xx2 = np.minimum(bboxes[i, <span class="number">2</span>], bboxes[pos:, <span class="number">2</span>])</span><br><span class="line">        yy2 = np.minimum(bboxes[i, <span class="number">3</span>], bboxes[pos:, <span class="number">3</span>])</span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        intersection = w * h</span><br><span class="line">        iou = intersection / (areas[i] + areas[pos:] - intersection)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Three methods: 1.linear 2.gaussian 3.original NMS</span></span><br><span class="line">        <span class="keyword">if</span> method == <span class="number">1</span>:  <span class="comment"># linear</span></span><br><span class="line">            weight = np.ones(iou.shape)</span><br><span class="line">            weight[iou &gt; iou_thresh] = weight[iou &gt; iou_thresh] - iou[iou &gt; iou_thresh]</span><br><span class="line">        <span class="keyword">elif</span> method == <span class="number">2</span>:  <span class="comment"># gaussian</span></span><br><span class="line">            weight = np.exp(-(iou * iou) / sigma2)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># original NMS</span></span><br><span class="line">            weight = np.ones(iou.shape)</span><br><span class="line">            weight[iou &gt; iou_thresh] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        scores[pos:] = weight * scores[pos:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># select the boxes and keep the corresponding indexes</span></span><br><span class="line">    inds = bboxes[:, <span class="number">4</span>][scores &gt; score_thresh]</span><br><span class="line">    keep = inds.astype(int)</span><br><span class="line">    <span class="keyword">return</span> keep</span><br><span class="line"></span><br><span class="line"><span class="comment"># boxes and scores</span></span><br><span class="line">boxes = np.array([[<span class="number">200</span>, <span class="number">200</span>, <span class="number">400</span>, <span class="number">400</span>], [<span class="number">220</span>, <span class="number">220</span>, <span class="number">420</span>, <span class="number">420</span>],</span><br><span class="line">                  [<span class="number">240</span>, <span class="number">200</span>, <span class="number">440</span>, <span class="number">400</span>], [<span class="number">200</span>, <span class="number">240</span>, <span class="number">400</span>, <span class="number">440</span>],</span><br><span class="line">                  [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]], dtype=np.float32)</span><br><span class="line">boxscores = np.array([<span class="number">0.9</span>, <span class="number">0.8</span>, <span class="number">0.7</span>, <span class="number">0.6</span>, <span class="number">0.5</span>], dtype=np.float32)</span><br><span class="line">index = soft_nms(boxes, boxscores, method=<span class="number">2</span>)</span><br><span class="line">print(index) <span class="comment"># 按照 scores 的排序指明了对应的 box 的下标</span></span><br><span class="line">print(boxes[index])</span><br><span class="line">print(boxscores) <span class="comment"># 注意, scores 不需要用 index 获取, scores 已经是更新过的排序 scores</span></span><br></pre></td></tr></table></figure>
<h3 id="介绍一下其他的-NMS-算法"><a href="#介绍一下其他的-NMS-算法" class="headerlink" title="介绍一下其他的 NMS 算法"></a><a href="../计算机视觉-NMS-Implementation/#介绍一下其他的 NMS 算法">介绍一下其他的 NMS 算法</a></h3><ul>
<li><a href="../计算机视觉-NMS-Implementation/#简述 NMS 的原理">简述 NMS 的原理</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#NMS 算法源码实现">NMS 算法源码实现</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#简述 Soft-NMS 的原理及算法实现">简述 Soft-NMS 的原理</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#Soft-NMS 算法源码实现">Soft-NMS 算法源码实现</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#介绍一下其他的 NMS 算法">介绍一下其他的 NMS 算法</a></li>
</ul>
<p><span id="R-CNN"></span></p>
<h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a><a href="../计算机视觉-R-CNN-CVPR2014">R-CNN</a></h2><ul>
<li>Selective Search</li>
<li>AlexNet</li>
<li>SVM</li>
<li>Bounding Box Regression</li>
</ul>
<script type="math/tex; mode=display">t_x = (G_x - P_x) / P_w, t_y = (G_y - P_y) / P_h</script><script type="math/tex; mode=display">t_w = log(G_w / P_w), t_h = log(G_h / P_h)</script><p><span id="Fast R-CNN"></span></p>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a><a href="../计算机视觉-FastR-CNN-ICCV2015">Fast R-CNN</a></h2><p><strong>R-CNN 缺点</strong>:</p>
<ul>
<li>训练过程是分阶段的(Training is a multi-stage pipeline)</li>
<li>Training is expensive in space and time</li>
<li>目标检测速度太慢(Object detection is slow)</li>
</ul>
<p><strong>SPPNet 缺点</strong>:</p>
<ul>
<li>训练过程是分阶段的(Training is a multi-stage pipeline)</li>
<li>无法 Fine-Tuning 金字塔池化层之前的卷积层</li>
</ul>
<p><strong>Fast R-CNN 贡献</strong>:</p>
<ul>
<li>更高的检测准确率(mAP)</li>
<li>整个训练过程更加统一(利用多目标损失函数)</li>
<li>训练时可以对所有网络层参数进行更新(相比于SPPNet)</li>
<li>无需在硬盘上额外存储 feature.(相比于 R-CNN, 因为共享卷积计算结果, 使得feature的体积大大降低)</li>
</ul>
<p><strong>要点</strong>:</p>
<ul>
<li>Multi-task loss: 下式中, $L_{cls}(p,u) = - log p_u$, 即对于真实类别 $u$ 的 log 损失.<script type="math/tex; mode=display">L(p, u, t_u, v) = L_{cls}(p,u) + \lambda [u \geq 1] L_{loc}(t^u, v) \tag 1</script><script type="math/tex; mode=display">L_{loc}(t^u, v) = \sum_{i\in {x,y,w,h}} smooth_{L_1}(t_i^u - v_i) \tag 2</script><script type="math/tex; mode=display">smooth_{L_1}(x) = \begin{cases} 0.5x^2 && |x|<1 \\ |x| - 0.5 && otherwise \end{cases} \tag 3</script></li>
<li>Mini-batch Sampling</li>
<li>RoI Pooling Layer</li>
<li><a href="../深度学习-奇异值分解">Truncated SVD 截断式奇异矩阵分解</a></li>
</ul>
<p><span id="Faster R-CNN"></span></p>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a><a href="../计算机视觉-FasterR-CNN-NIPS2015">Faster R-CNN</a></h2><ul>
<li>RPN (Region Proposals Networks)<br><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1fxsf9g1udsj21q00s3152.jpg" alt="图2"></div></li>
<li>损失函数<script type="math/tex; mode=display">L(\{p_i\}, \{t_i\}) = \frac{1}{N_{cls}} \sum_i L_{cls}(p_i, p_i^* ) + \lambda \frac{1}{N_{reg}} \sum_i p_i^* L_{reg}(t_i, t_i^* )</script></li>
<li>RPN 与 Fast R-CNN 共享卷积参数<ul>
<li>Alternating training(交叉训练)</li>
<li>Approximate joint training(近似联合训练)</li>
<li>Non-approximate joint training(非近似联合训练)</li>
</ul>
</li>
</ul>
<p><strong>问题:</strong></p>
<p>(1). 为什么 Fast 和 Faster R-CNN 没有采用像 multi-scale testing (image pyramids)?</p>
<ul>
<li>FPN: 但是, 在 image pyramids 的每一层上提取特征具有很明显的缺点, 那就是会使得 Inference time 显著提升. 更进一步的, 会使得在 image pyramid 上训练端到端的深层网络变的不可行, 也因此, 我们仅仅在测试阶段才会使用 image pyramids, 这会在训练和测试阶段之间产生不一致问题. <strong>基于以上原因, Fast 和 Faster R-CNN 选择在默认设置下不使用 featurized image pyramids</strong></li>
</ul>
<h2 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a><a href="../计算机视觉-MaskR-CNN-ICCV2017">Mask R-CNN</a></h2><ul>
<li>基于 Faster R-CNN 的基本结构, 替换 backbone 为 ResNet-50/101-C4 和 ResNet-50/101-FPN, ResNeXt-101-FPN.</li>
<li>除了边框回归和目标分类两个分支外, 新添加了一个全卷积的 Mask Prediction 网络, 该分支在每一个 RoI 上的输出维度为 $K\times m^2$, 代表 $K$ 个类别的二值掩膜.</li>
<li>在计算 mask 的损失时, 使用的是 sigmoid 的二分类损失, 而不是多分类的 softmax 损失, 这减少了类别之前的竞争, 使得可以生成更好的分割结果.</li>
<li>RoIAlign 消除了 RoI Pooling 中的两次量化操作, 使得最终提取到的特征可以 RoI 尽可能的对齐. 从而大幅提升在实例分割任务上的性能表现.</li>
</ul>
<p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1fx1toyw0xkj20kc0a5wkw.jpg" alt="图1"></div></p>
<h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a><a href="../计算机视觉-FPN-CVPR2017">FPN</a></h2><h2 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a><a href="../">FCN</a></h2><h2 id="RFCN"><a href="#RFCN" class="headerlink" title="RFCN"></a><a href="../">RFCN</a></h2><h2 id="Deformable-CNN"><a href="#Deformable-CNN" class="headerlink" title="Deformable CNN"></a><a href="../">Deformable CNN</a></h2><h2 id="Cascade-R-CNN"><a href="#Cascade-R-CNN" class="headerlink" title="Cascade R-CNN"></a><a href="../">Cascade R-CNN</a></h2><h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><p>【链接】目标检测|SSD原理与实现<br><a href="https://zhuanlan.zhihu.com/p/33544892" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33544892</a></p>
<p><strong>问题:</strong></p>
<ul>
<li>为什么SSD不直接使用浅层的特征图谱, 而非要额外增加卷积层, 这样不是增加模型的复杂度了吗?</li>
<li>SSD 使用了哪些数据增广方法?</li>
</ul>
<h2 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h2><p><a href="http://caffecn.cn/?/question/1842" target="_blank" rel="noopener">http://caffecn.cn/?/question/1842</a></p>
<h2 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h2><p>YOLOv2(也叫做 YOLO9000)</p>
<h2 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h2><h2 id="FocalLoss"><a href="#FocalLoss" class="headerlink" title="FocalLoss"></a><a href="../计算机视觉-FocalLoss-ICCV2017">FocalLoss</a></h2><p>FocalLoss</p>
<h2 id="SNIP"><a href="#SNIP" class="headerlink" title="SNIP"></a><a href="../">SNIP</a></h2><h2 id="SNIPER"><a href="#SNIPER" class="headerlink" title="SNIPER"></a><a href="../">SNIPER</a></h2><h2 id="TridentNet"><a href="#TridentNet" class="headerlink" title="TridentNet"></a><a href="../">TridentNet</a></h2><h2 id="DenseBox"><a href="#DenseBox" class="headerlink" title="DenseBox"></a><a href="../">DenseBox</a></h2><h2 id="CornerNet"><a href="#CornerNet" class="headerlink" title="CornerNet"></a><a href="../">CornerNet</a></h2><h2 id="FSAF"><a href="#FSAF" class="headerlink" title="FSAF"></a><a href="../">FSAF</a></h2><h2 id="FoveaBox"><a href="#FoveaBox" class="headerlink" title="FoveaBox"></a><a href="../">FoveaBox</a></h2><h2 id="FCOS"><a href="#FCOS" class="headerlink" title="FCOS"></a><a href="../">FCOS</a></h2><h2 id="ExtremeNet"><a href="#ExtremeNet" class="headerlink" title="ExtremeNet"></a><a href="../">ExtremeNet</a></h2><h2 id="CenterNet"><a href="#CenterNet" class="headerlink" title="CenterNet"></a><a href="../">CenterNet</a></h2><h2 id="CenterNet-Objects-as-Points"><a href="#CenterNet-Objects-as-Points" class="headerlink" title="CenterNet(Objects as Points)"></a><a href="../">CenterNet(Objects as Points)</a></h2><h2 id="CornerNet-Lite"><a href="#CornerNet-Lite" class="headerlink" title="CornerNet-Lite"></a><a href="../">CornerNet-Lite</a></h2><h2 id="TridentNet-1"><a href="#TridentNet-1" class="headerlink" title="TridentNet"></a><a href="../">TridentNet</a></h2><h2 id="HTC"><a href="#HTC" class="headerlink" title="HTC"></a><a href="../">HTC</a></h2><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>RefineDet, SNIP, SNIPPER, Fitness NMS, RFBNet, M2Det, TridentNet, HTC, NAS-FPN(为开源)</p>
<p>Guided Anchoring<br>Libra R-CNN<br>Hybrid Task Cascade</p>
<h1 id="图像处理篇"><a href="#图像处理篇" class="headerlink" title="图像处理篇"></a>图像处理篇</h1><p>4.1 图像特征提取的算法有哪些，各自优缺点、适用范围<br><a href="https://blog.csdn.net/xiongchao99/article/details/78776629" target="_blank" rel="noopener">https://blog.csdn.net/xiongchao99/article/details/78776629</a></p>
<p><span id="图像放缩"></span></p>
<h2 id="图像放缩"><a href="#图像放缩" class="headerlink" title="图像放缩"></a>图像放缩</h2><p><strong>双线性插值</strong><br>双线性插值本质上就是在两个方向上做线性插值.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx3.sinaimg.cn/large/d7b90c85ly1g1hbfdtyvcj21dg0m6ta3.jpg" alt="双线性插值"></div></p>
<p>假如我们想得到未知函数 $f$ 在点 $P = (x, y)$ 的值, <strong>在图像中, 这个 $f$ 代表的就是某个像素点的像素值.</strong> 当我们已知点 $P$ 周围四个点的值以后, 我们可以首先在 $x$ 方向上进行线性插值, 得到:</p>
<script type="math/tex; mode=display">f(R_1) \approx \frac{x_2 - x}{x_2 - x_1} f(Q_{11}) + \frac{x - x1}{x_2 - x_1}f(Q_{21})</script><script type="math/tex; mode=display">f(R_2) \approx \frac{x_2 - x}{x_2 - x_1} f(Q_{12}) + \frac{x - x_1}{x_2 - x_1} f(Q_{22})</script><p>然后在 $y$ 方向上进行线性插值, 得到:</p>
<script type="math/tex; mode=display">f(P) \approx \frac{y_2 - y}{y_2 - y_1} f(R_1) + \frac{y - y_1}{y_2 - y_1}f(R_2)</script><p><span id="边缘检测算法"></span></p>
<h2 id="边缘检测算法"><a href="#边缘检测算法" class="headerlink" title="边缘检测算法"></a>边缘检测算法</h2><p><a href="https://www.jianshu.com/p/2334bee37de5" target="_blank" rel="noopener">https://www.jianshu.com/p/2334bee37de5</a></p>
<p><a href="https://blog.csdn.net/KYJL888/article/details/78253053" target="_blank" rel="noopener">https://blog.csdn.net/KYJL888/article/details/78253053</a></p>
<p>Roberts算子<br>Sobel算子<br>Prewit算子<br>Canny算子</p>
<p><span id="霍夫变换"></span></p>
<h2 id="霍夫变换"><a href="#霍夫变换" class="headerlink" title="霍夫变换"></a>霍夫变换</h2><p><a href="https://www.cnblogs.com/AndyJee/p/3805594.html" target="_blank" rel="noopener">https://www.cnblogs.com/AndyJee/p/3805594.html</a></p>
<p><a href="https://blog.csdn.net/m0_37264397/article/details/72729423" target="_blank" rel="noopener">https://blog.csdn.net/m0_37264397/article/details/72729423</a></p>
<p><span id="滤波器"></span></p>
<h2 id="图像保边滤波器"><a href="#图像保边滤波器" class="headerlink" title="图像保边滤波器"></a>图像保边滤波器</h2><p><a href="https://blog.csdn.net/Trent1985/article/details/80509232" target="_blank" rel="noopener">https://blog.csdn.net/Trent1985/article/details/80509232</a></p>
<p><a href="https://blog.csdn.net/eejieyang/article/details/52333112" target="_blank" rel="noopener">https://blog.csdn.net/eejieyang/article/details/52333112</a></p>
<p><a href="https://blog.csdn.net/LG1259156776/article/details/51816875" target="_blank" rel="noopener">https://blog.csdn.net/LG1259156776/article/details/51816875</a></p>
<p><a href="https://blog.csdn.net/u012968002/article/details/44463229" target="_blank" rel="noopener">https://blog.csdn.net/u012968002/article/details/44463229</a></p>
<h2 id="图像平移"><a href="#图像平移" class="headerlink" title="图像平移"></a>图像平移</h2><p><a href="https://blog.csdn.net/qq_25867649/article/details/52131252" target="_blank" rel="noopener">https://blog.csdn.net/qq_25867649/article/details/52131252</a></p>
<p><a href="https://blog.csdn.net/linqianbi/article/details/78593203" target="_blank" rel="noopener">https://blog.csdn.net/linqianbi/article/details/78593203</a></p>
<h2 id="图像开操作、闭操作"><a href="#图像开操作、闭操作" class="headerlink" title="图像开操作、闭操作"></a>图像开操作、闭操作</h2><p><a href="https://blog.csdn.net/learning_tortosie/article/details/80030201" target="_blank" rel="noopener">https://blog.csdn.net/learning_tortosie/article/details/80030201</a></p>
<p><a href="https://blog.csdn.net/water_93/article/details/50859193" target="_blank" rel="noopener">https://blog.csdn.net/water_93/article/details/50859193</a></p>
<p><a href="https://www.cnblogs.com/daxiongblog/p/6289551.html" target="_blank" rel="noopener">https://www.cnblogs.com/daxiongblog/p/6289551.html</a></p>
<h2 id="图像旋转"><a href="#图像旋转" class="headerlink" title="图像旋转"></a>图像旋转</h2><p><a href="https://www.cnblogs.com/hustlx/p/5245226.html" target="_blank" rel="noopener">https://www.cnblogs.com/hustlx/p/5245226.html</a></p>
<p><a href="https://blog.csdn.net/ccblogger/article/details/72918354" target="_blank" rel="noopener">https://blog.csdn.net/ccblogger/article/details/72918354</a></p>
<h2 id="图像重建质量评价指标"><a href="#图像重建质量评价指标" class="headerlink" title="图像重建质量评价指标"></a>图像重建质量评价指标</h2><p><a href="https://blog.csdn.net/smallstones/article/details/42198049" target="_blank" rel="noopener">https://blog.csdn.net/smallstones/article/details/42198049</a></p>
<h2 id="光流法"><a href="#光流法" class="headerlink" title="光流法"></a>光流法</h2><p><a href="https://blog.csdn.net/longlovefilm/article/details/79824723" target="_blank" rel="noopener">https://blog.csdn.net/longlovefilm/article/details/79824723</a></p>
<p><a href="https://www.xuebuyuan.com/3203656.html" target="_blank" rel="noopener">https://www.xuebuyuan.com/3203656.html</a></p>
<h2 id="图像去噪的方法"><a href="#图像去噪的方法" class="headerlink" title="图像去噪的方法"></a>图像去噪的方法</h2><p><a href="https://blog.csdn.net/eric_e/article/details/79504444" target="_blank" rel="noopener">https://blog.csdn.net/eric_e/article/details/79504444</a></p>
<h2 id="度量图像patch相似度的方法"><a href="#度量图像patch相似度的方法" class="headerlink" title="度量图像patch相似度的方法"></a>度量图像patch相似度的方法</h2><p><a href="https://blog.csdn.net/lg1259156776/article/details/47037583/" target="_blank" rel="noopener">https://blog.csdn.net/lg1259156776/article/details/47037583/</a></p>
<p><a href="https://blog.csdn.net/zchang81/article/details/73275155/" target="_blank" rel="noopener">https://blog.csdn.net/zchang81/article/details/73275155/</a></p>
<p><a href="https://blog.csdn.net/yangyangyang20092010/article/details/8472257" target="_blank" rel="noopener">https://blog.csdn.net/yangyangyang20092010/article/details/8472257</a></p>
<h2 id="传统图像处理CDC做过吗？"><a href="#传统图像处理CDC做过吗？" class="headerlink" title="传统图像处理CDC做过吗？"></a>传统图像处理CDC做过吗？</h2><h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><h2 id="图像融合算法有哪些？"><a href="#图像融合算法有哪些？" class="headerlink" title="图像融合算法有哪些？"></a>图像融合算法有哪些？</h2><h2 id="图像增强算法有哪些"><a href="#图像增强算法有哪些" class="headerlink" title="图像增强算法有哪些"></a>图像增强算法有哪些</h2><h2 id="图像滤波方法"><a href="#图像滤波方法" class="headerlink" title="图像滤波方法"></a>图像滤波方法</h2><h2 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h2><p><a href="https://www.cnblogs.com/hustlx/p/5245461.html" target="_blank" rel="noopener">https://www.cnblogs.com/hustlx/p/5245461.html</a></p>
<p><a href="https://www.cnblogs.com/tianyalu/p/5687782.html" target="_blank" rel="noopener">https://www.cnblogs.com/tianyalu/p/5687782.html</a></p>
<h1 id="算法实现篇"><a href="#算法实现篇" class="headerlink" title="算法实现篇"></a>算法实现篇</h1><h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h2><h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h2><h2 id="NMS-1"><a href="#NMS-1" class="headerlink" title="NMS"></a>NMS</h2><h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><h1 id="数学基础篇"><a href="#数学基础篇" class="headerlink" title="数学基础篇"></a>数学基础篇</h1><p><span id="概率分布"></span></p>
<h2 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h2><p><a href="../机器学习-数学基础/#Beta 分布">Beta 分布</a></p>
<p>5.1 概率分布<br>5.2 期望、方差、协方差、相关系数<br>5.3 假设检验<br><a href="https://support.minitab.com/zh-cn/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/what-is-a-hypothesis-test/" target="_blank" rel="noopener">https://support.minitab.com/zh-cn/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/what-is-a-hypothesis-test/</a></p>
<p><a href="https://blog.csdn.net/pipisorry/article/details/51182843" target="_blank" rel="noopener">https://blog.csdn.net/pipisorry/article/details/51182843</a></p>
<p><a href="https://blog.csdn.net/YtdxYHZ/article/details/51780310" target="_blank" rel="noopener">https://blog.csdn.net/YtdxYHZ/article/details/51780310</a></p>
<p>5.4 54张牌，分3组，大王小王同在一组的概率<br>分成3份 总的分法 M=(C54，18)(C36，18)(C18，18)</p>
<p>大小王在同一份N=(C3，1)(C52，16)(C36，18)x(C18，18) P=N /M=17/53 。</p>
<p>5.5 最大似然估计、贝叶斯估计<br><a href="https://blog.csdn.net/bitcarmanlee/article/details/52201858" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/52201858</a></p>
<p><a href="https://www.cnblogs.com/zjh225901/p/7495505.html" target="_blank" rel="noopener">https://www.cnblogs.com/zjh225901/p/7495505.html</a></p>
<p><a href="https://blog.csdn.net/feilong_csdn/article/details/61633180" target="_blank" rel="noopener">https://blog.csdn.net/feilong_csdn/article/details/61633180</a></p>
<p>5.6<br><a href="https://www.nowcoder.com/questionTerminal/836b01b7809248b7b6e9c30495d4680e?from=14pdf" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/836b01b7809248b7b6e9c30495d4680e?from=14pdf</a></p>
<p>假设一段公路上，1小时内有汽车经过的概率为96%，那么，30分钟内有汽车经过的概率为?</p>
<p>48%<br>52%<br>80%<br>96%</p>
<p>一小时有车的概率 = 1 - 一小时没车的概率 = 1 - 两个半小时都没车的概率 = 1 - （1 - 半小时有车的概率）^2<br>1-(1-x)^2=0.96<br>x = 0.8</p>
<p>5.7 三门问题<br>三个宝箱里有一个宝箱里有宝物，两个是空的，你选了一个，主持人打开剩下2个中的一个发现没有宝物，问你换不换</p>
<p>假设A无，B无，C有，<br>选A，则主持人只会开B，1/3概率；<br>选B，则主持人只会开A，1/3概率；<br>选C，则主持人会开A\B，1/3概率；</p>
<p>可见，不换只有1/3的概率中，换的话，有2/3的概率中；</p>
<p>5.8 概率题：抛一个骰子，直到集齐六面，问抛骰子的期望次数。<br>5.9 概率题：抛色子连续n次正面向上的期望次数。<br>5.10 一个人向北走了一公里，向东走了一公里，又向南走了一公里，最后回到了最开始的起点，为什么？<br>南极点，刚好一个等边三角形；</p>
<p>或者是一个一圈距离刚好是1公里的那个地方。向北走之后，达到那个地方，饶了一圈回到这个地方，再向南走回去。</p>
<p><a href="https://blog.csdn.net/Turinglife/article/details/7358061" target="_blank" rel="noopener">https://blog.csdn.net/Turinglife/article/details/7358061</a></p>
<p>从逻辑上来讲，题目从好像缺少了一次向西的过程，才可以回到原地。有没有可能向东1公里还在原地，答案是肯定的，如果有一个纬度，绕其一圈恰好是1公里即可实现，所以这样的点有无穷多个，只要找到那个纬度即可。</p>
<p>5.11 一个四位数abcd，满足abcd <em> 4 = dcba，求这个数<br>a9没有进位，且为四位数，a只能为1<br>d9个位数为1，d只能是9<br>b9后为个位数（9加任何数进位），这个数只能是1或0，排除1，b=0<br>c9+8的尾数为0，则c</em>9个位数为2，c=8</p>
<p>a4没有进位，说明a=1或2，但是d4的个位是a，不可能a=1，所以a=2;</p>
<p>d=a4=8;而且没有进位，说明b4+它的可能进位不超过10；</p>
<p>如果b=0：则c*4的个位需要是7，不存在，不符；</p>
<p>如果b=1：则c*4的个位需要是8，存c=2不符合，c=7符合，所以为2178；</p>
<p>如果b=2:则c*4的个位需要是9，不符；</p>
<p>5.12 概率题：一个家庭有两个孩子，已知其中一个是女孩，求另一个也是女孩的概率<br>(1/21/2)/(1-1/21/2)<br>=(1/4)/(3/4)<br>=1/3</p>
<p>5.13 16个球队中随机选2个，在大量选取后，越强的队越容易被选中<br>5.14 有一个3L、一个5L的桶，请量出4L的水<br>5L桶装满水，倒入3L桶；此时5L中有2L水，3L桶中有3L水；</p>
<p>3L桶全部倒走，将5L桶的2L水道入3L桶中，此时5L桶中没有水，3L桶中有2L水；</p>
<p>将5L桶倒满水，然后向3L桶中倒水，此时3L桶水已满，5L桶中还剩4L水。</p>
<p>5.15 把1~9这9个数填入九格宫里,使每一横、竖、斜相等。<br><a href="https://zhidao.baidu.com/question/329122415632328485.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/329122415632328485.html</a></p>
<p>5.16 一个圆上随机三个点组成锐角三角形的概率<br>一个圆周上,随机点三个点,这三个点在同一个半圆上的概率是多少?<br>三个点在同一个半圆时,形成的三角形为直角或钝角三形（自己想为什么）.<br>不在同一个半圆时,为锐角三角形.<br>三点在同一半圆的概率是3/4,所以你这题的答案为1/4.</p>
<p>设在圆上任取的3点是A、B、C。圆心为 O<br>先假定A、B的位置，设弦AB的圆心角为∠α，且∠α属于[0，π].那么满足锐角三角形的C点就要在AO延长线与BO延长线间，所以C点的取值范围只有圆心为α的弧，即概率为：α/（2π）<br>对任意A、B的位置，C点的概率为对α/（2π）从[0，π]积分，结果是 π/4</p>
<p>关于为什么C点就要在AO延长线与BO延长线间，因为C点如果不在这之间，则ABC三点就会处于同一个半圆中。而处于同一个半圆中的三个点构成直角或者钝角三角形。</p>
<h2 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h2><h1 id="常见问题篇"><a href="#常见问题篇" class="headerlink" title="常见问题篇"></a>常见问题篇</h1><p><a href="../面试-计算机视觉常见问题详细解答">面试-计算机视觉常见问题详细解答</a></p>
<ul>
<li>目前的 SOTA 目标检测模型</li>
<li>SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</li>
<li>常用的训练 Trick</li>
<li>有哪些数据增广方法? 怎么实现的?</li>
<li>FCN 是如何降低计算量的?</li>
</ul>
<p><span id="目前的 SOTA 目标检测模型"></span></p>
<h2 id="目前的-SOTA-目标检测模型"><a href="#目前的-SOTA-目标检测模型" class="headerlink" title="目前的 SOTA 目标检测模型"></a>目前的 SOTA 目标检测模型</h2><p>比较经典的, 比如 R-CNN 系列, YOLO, 以及 SSD 等属于比较具有代表性的一些模型. 在此基础上, 从 17 年开始, 又有很多新的模型出现, 按照不同的关注角度来分, 大致有这么几类.<br>首先是对卷积网络的特征金字塔的构建和生成进行优化和改进的模型, 比如 FPN 和 M2Det 等.<br>其次是从感受野的角度进行优化的模型, 比如 Deformable ConvNet, RFBNet.<br>还有从 bounding box 回归角度进行优化的 RefineDet.<br>然后还有从损失函数及样本不均衡角度进行优化, 使用 Focal Loss 的 RetinaNet等.</p>
<ul>
<li>在 feature map 的多尺度金字塔特征上进行优化: SSD, FPN, PFPNet, M2Det</li>
<li>在 bbox 回归上进行优化: RefineDet</li>
<li>然后也可以在感受野上进行优化: DCN, RFBNet</li>
<li>以另一种角度来选取 bbox: CornerNet</li>
<li>在 anchor 的生成上进行优化: CornerNet, MetaAnchor</li>
<li>对 NMS 和 IoU 上进行优化: Soft-NMS, Sofer-NMS, Fitness NMS, Relation Network, IoUNet, Cascade R-CNN</li>
<li>在 backbone 网络上优化: DetNet</li>
<li>在损失函数和样本不均衡上进行优化: Focal Loss, Gradient Harmonized(梯度均衡)</li>
<li>针对移动端设备: Pelee</li>
<li>多尺度问题: SNIP, SNIPER</li>
<li>小目标检测: STDNet, Augmentation for small od.</li>
<li>超大目标检测: HKRM</li>
</ul>
<p>FPN,<br>RefineDet, RFBNet<br>STDN</p>
<p><span id="SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别"></span></p>
<h2 id="SSD-FPN-RefineDet-PFPNet-STDN-M2Det-等特征金字塔的区别"><a href="#SSD-FPN-RefineDet-PFPNet-STDN-M2Det-等特征金字塔的区别" class="headerlink" title="SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别"></a>SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</h2><p>SSD 是通过使用 backbone(VGG16) 的最后两个卷积段的特征图谱和 4 个额外卷积层特征图谱来构建特征金字塔的.<br>FPN 是通过融合深层和浅层的特征图谱来构建特征金字塔. 主要做法是将最后一层特征图谱进行不断的上采样得到 top-down 结构的特征图谱, 然后与原始的 down-top 结构的特征图谱相结合, 从而得到新的表征能力更强的特征金字塔结构.<br>M2Det 主要是从现在特征金字塔的一些缺点出发进行优化, 它认为, 现有金字塔结构中每一个尺度的特征仅仅来自于 backbone 中单一层级(level)的特征. 这样一来, 小尺度的特征图谱往往缺少浅层低级的语义信息, 而大尺度的特征图谱又缺少深层的高级语义信息. 因此, 作者就提出了融合多个层级特征的 Multi-Level FPN (MLFPN). 从而可以让小尺寸的特征图谱上包含有更多的低级语义信息, 让大尺寸的特征图谱包含更多的高级语义信息.</p>
<p><span id="常用的训练 Trick"></span></p>
<h2 id="常用的训练-Trick"><a href="#常用的训练-Trick" class="headerlink" title="常用的训练 Trick"></a>常用的训练 Trick</h2><p><span id="有哪些数据增广方法? 怎么实现的?"></span></p>
<h2 id="有哪些数据增广方法-怎么实现的"><a href="#有哪些数据增广方法-怎么实现的" class="headerlink" title="有哪些数据增广方法? 怎么实现的?"></a>有哪些数据增广方法? 怎么实现的?</h2><ul>
<li>颜色变换(Convert Color): BGR 与 HSV 格式随机切换. HSV 模型的三维表示是从 RGB 立方体以旧换新儿来的, 设想从 RGB 沿立方体对角线的白色顶点向黑色顶点观察, 就可以看到立方体的六边形外形. 六边形边界表示色彩, 水平轴表示纯度, 明度沿垂直测量.</li>
<li>随机对比度和亮度: 像素最大最小值的差值影响对比度, 像素的整体大小影响亮度, 通过公式 $g(i, j) = a\times f(i,j) + b$ 控制, $a$ 影响的是对比度, $b$ 影响的图像的亮度.</li>
<li>随机饱和度(Random Saturation): 先将图片转换成 HSV 格式, 然后对 S 通道乘以一个随机值</li>
<li>随机色度(Random Hue): 先将图片转换成 HSV 格式, 然后对 H 通过进行修改</li>
<li>随机交换通道, 增加噪声</li>
</ul>
<h2 id="FCN-是如何降低计算量的"><a href="#FCN-是如何降低计算量的" class="headerlink" title="FCN 是如何降低计算量的?"></a>FCN 是如何降低计算量的?</h2><p>面对 $384\times 384$ 的图像, 让含全连接层的初始卷积神经网络以 32 像素的步长独立对图像中的 $224\times 224$ 块进行多次评价, 其效果和使用全卷积网络进行一次评价时相同的. 后者通过权值共享起到了加速计算的作用.</p>
<p><span id="简单说一下 PyTorch 和 TensorFlow 的区别"></span></p>
<h2 id="PyTorch-和-TensorFlow-的区别"><a href="#PyTorch-和-TensorFlow-的区别" class="headerlink" title="PyTorch 和 TensorFlow 的区别"></a>PyTorch 和 TensorFlow 的区别</h2><p>两个框架虽然都是在张量上运行, 并且将模型都看做是一个有向非循环图(DAG), 但是二者对于图的定义不同. TensorFlow 是基于静态计算图, 因此是先定义再运行, 一次定义多次运行, 而 PyTorch 是基于动态计算图的, 是在运行过程中被定义的, 在运行的时候进行构建, 可以多次构建多次运行.<br>动态图的还有一个好处就是比较容易调试, 在 PyTorch 中, 代码报错的地方, 往往就是代码错写的地方, 而静态图需要先根据代码生成 Graph 对象, 然后在 session.run() 时报错, 但是这种报错几乎很难直接找到代码中对应的出错段落.</p>
<p>链接】Variable和Tensor合并后，PyTorch的代码要怎么改<br><a href="https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/80105285" target="_blank" rel="noopener">https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/80105285</a></p>
<p><span id="你觉得目标检测领域还有哪些可以继续改进或者优化的地方"></span></p>
<h2 id="目标检测领域还有哪些可以继续改进或者优化的地方"><a href="#目标检测领域还有哪些可以继续改进或者优化的地方" class="headerlink" title="目标检测领域还有哪些可以继续改进或者优化的地方"></a>目标检测领域还有哪些可以继续改进或者优化的地方</h2><ol>
<li><p>首先是精确度和速度的考量, 相对于精度较高的 Faster RCNN, RFCN 相关系列模型来说, 个人觉得速度更快的 YOLO 系列和 SSD 系列的模型在实际场景应用中会更加实用, 近年来的主要代表有 RefineDet, RFBNet 等都是基于 SSD 模型的研究.</p>
</li>
<li><p>其次是目标的选框步骤, 从最开始的 Region Based , Anchor Based 到现在的基于角点, 甚至基于 segmentation, 包括 semantic segmentation 和 instance segmentation. 今年比较有代表性的就是 CornerNet. 就目前来说, 目标的选框方法很多还是基于 RPN 的 anchor 思想, 所以, 未来的研究中, 新的更好的目标选框方法依旧是研究的一个重要方向.</p>
</li>
<li><p>多尺度问题(尺度变换问题), 目标常见的三种思路, 采用专门设计的尺度变换模块, STDN: Scale-Transferrable Object Detection.</p>
</li>
</ol>
<h2 id="one-stage目标检测算法中-浅层特征图检测小目标，为什么不同时也检测大目标？"><a href="#one-stage目标检测算法中-浅层特征图检测小目标，为什么不同时也检测大目标？" class="headerlink" title="one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？"></a>one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？</h2><p>浅层感受野较小, 并且语义信息比较低级<br>深层感受野较大, 包含更多高级语义信息</p>
<p>【链接】onestage目标检测算法中,浅层特征图检测小目<br><a href="https://www.zhihu.com/question/305729744/answer/555781620" target="_blank" rel="noopener">https://www.zhihu.com/question/305729744/answer/555781620</a></p>
<p><span id="GPU 两个重要指标之间的关系"></span></p>
<h2 id="GPU-两个重要指标之间的关系"><a href="#GPU-两个重要指标之间的关系" class="headerlink" title="GPU 两个重要指标之间的关系"></a>GPU 两个重要指标之间的关系</h2><p>科普帖,深度学习中GPU和显存分析: <a href="https://zhuanlan.zhihu.com/p/31558973" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31558973</a></p>
<p><div style="width: 600px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/nvidia-smi.jpg?x-oss-process=style/blog_img" alt="%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2Fnvidia-smi.jpg"></div></p>
<p>上图是<code>nvidia-smi</code>命令的输出, 其中最重要的两个指标:</p>
<ul>
<li>显存占用</li>
<li>GPU 利用率</li>
</ul>
<p>显存占用和GPU利用率是两个不一样的东西，显卡是由GPU计算单元和显存等组成的，显存和GPU的关系有点类似于内存和CPU的关系。</p>
<p>显存可以看成是空间，类似于内存</p>
<ul>
<li>显存用于存放模型，数据</li>
<li>显存越大，所能运行的网络也就越大<br>GPU计算单元类似于CPU中的核，用来进行数值计算。衡量计算量的单位是flop: the number of floating-point multiplication-adds，浮点数先乘后加算一个flop。计算能力越强大，速度越快。衡量计算能力的单位是flops: 每秒能执行的flop数量</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>*<span class="number">2</span> + <span class="number">3</span>  <span class="comment"># 2 flop</span></span><br><span class="line"><span class="number">1</span>*<span class="number">2</span> + <span class="number">3</span>*<span class="number">4</span> + <span class="number">4</span>*<span class="number">5</span> <span class="comment"># 5 flop</span></span><br></pre></td></tr></table></figure>
<p><span id="GPU 及其显存占用"></span></p>
<h2 id="神经网络显存占用"><a href="#神经网络显存占用" class="headerlink" title="神经网络显存占用"></a>神经网络显存占用</h2><p>神经网络模型占用显存的部分包括:</p>
<ul>
<li>模型的输入</li>
<li>模型中间网络层的输出</li>
<li>模型参数</li>
<li>模型参数的梯度</li>
<li>优化器动量</li>
</ul>
<p>首先, 要确定运算过程中使用的数据类型, 常用的数据类型有: int8, int16, float16, float32 等. <strong>通常, 在训练时, 我们为了更高的精度需要使用 float32 的数据类型, 而在预测时, 我们为了压缩模型的大小会选用 float16 的数据类型(预测时几乎不会带来精度损失)</strong>.<br>距离来说, 一个 $(32, 3, 256, 256)$ 的 tensor, 如果使用的是 float32 的数据类型, 那么它的显存占用约为 <strong>24M</strong>, 而如果使用的是 float16 的数据类型, 那么它的显存占用约为 <strong>12M</strong>.</p>
<p>下面来逐一分析:</p>
<ol>
<li><strong>模型的输入:</strong> 一般就是图片的分辨率大小, 另外需要注意的时, 一般不需要计算模型输入(图片)的梯度.</li>
<li><strong>模型中间网络层的输出:</strong> 这部分显存主要是指每个网络层输出的 feature map, 它的形状和模型的具体结构有关, 越大越厚的 feature map 占用的显存越多.</li>
<li><strong>模型参数:</strong> 只有有参数的层, 才会占用显存, 这些网络层一般包括卷积层, 全连接层, BN 层等等. 其它的不包括参数的层如激活层, 池化层, Dropout 层等均不占用显存. 在 PyTorch 中, 当执行完<code>model=MyModel().cuda()</code>之后就会占用相应的显存, 占用的显存大小基本与下面计算的差不多(会稍大一些, 因为还存在一些其它的开销):<ul>
<li>Linear(M-&gt;N): $M\times N$</li>
<li>Conv2d(Cin, Cout, K): $C_{in} \times C_{out} \times K\times K$</li>
<li>BatchNorm(N): $2N$</li>
<li>Embedding(N, W): $N\times W$</li>
</ul>
</li>
<li><strong>模型参数的梯度:</strong> 在训练的时候, 由于需要进行反向传播的原因, 我们还需要保存每个参数对应的梯度, 这部分的显存占用和参数占用的显存大小一致. 通常来说, 神经网络的每一层输入输出都需要保存下来, 用来进行反向传播. 但是在某些特殊情况下, 我们可以不保存输入. 比如 ReLU, 在 PyTorch 中, 使用<code>nn.ReLU(inplace=True)</code>能将激活函数的输出直接覆盖保存于模型的输入之中, 节省不少内存(此时的反向传播:$y = relu(x) -&gt; dx = dy.copy(); dx[y&lt;=0]=0$).</li>
<li><strong>优化器的动量:</strong> 不同的优化器需要的信息量不同, 对于普通的 SGD 来说, 仅仅需要参数的梯度就足够了, 因此 <strong>总显存(参数+梯度+动量)</strong> 占用为参数显存的 <strong>两倍</strong>, 但是对于 Momentum-SGD, 不仅需要梯度, 还需要动量, 因此总显存占用为参数显存的 <strong>三倍</strong>, 对于 Adam 优化器, 需要更多的动量信息, 总显存占用为参数显存的 <strong>四倍</strong>.</li>
</ol>
<p>在深度学习神经网络的显存占用中, 我们可以得到: <strong><script type="math/tex">显存占用 = 模型显存占用 + batchsize \times 每个样本的显存占用</script></strong>. 可以看出, 显存并不是简单的和 batch_size 成正比, 尤其是在模型自身比较大的情况下.</p>
<p><span id="节省显存的方法"></span></p>
<h2 id="节省显存的方法"><a href="#节省显存的方法" class="headerlink" title="节省显存的方法"></a>节省显存的方法</h2><ul>
<li>降低 batch_size</li>
<li>进行下采样, 降低 feature map 的大小</li>
<li>减少全连接层</li>
<li>将激活层设置成<code>inplace=True</code></li>
<li>使用字节数更少的数据类型(float8, float16等)</li>
</ul>
<p>显存计算, PyTorch 显存跟踪: <a href="https://www.cnblogs.com/kk17/p/10262688.html" target="_blank" rel="noopener">https://www.cnblogs.com/kk17/p/10262688.html</a><br><a href="https://oldpan.me/archives/how-to-calculate-gpu-memory" target="_blank" rel="noopener">https://oldpan.me/archives/how-to-calculate-gpu-memory</a></p>
<p><span id="各个网络层的参数量"></span></p>
<h2 id="各个网络层的参数量"><a href="#各个网络层的参数量" class="headerlink" title="各个网络层的参数量"></a>各个网络层的参数量</h2><p>同时计算 weight 和 bias</p>
<ul>
<li>Linear (M-&gt;N): $(1+M)\times N$</li>
<li>Conv2d (Cin, Cout, Kw, Kh): $C_{out}\times (C_{in} \times K_w\times K_h + 1)$</li>
<li>BatchNorm (N): $2N$</li>
<li>Embedding (N, W): $N\times W$</li>
</ul>
<p><span id="如何计算 FLOPs"></span></p>
<h2 id="如何计算-FLOPs-和-MAC"><a href="#如何计算-FLOPs-和-MAC" class="headerlink" title="如何计算 FLOPs 和 MAC"></a>如何计算 FLOPs 和 MAC</h2><p>FLOPs: Floating point operations, 通常是指运算中乘法和加法的总次数. Paper 里比较流行的单位是 GFLOPs, 即 $10^9$ FLOPs<br>FLOPS: Floating Point Operations Per Second, 代表算力<br>MAC: 只统计乘法, 因此 FLOPs 通常是 MAC 的两倍, 这是因为在编码的时候, 芯片内部会用 MAC 指令进行乘加计算, 对应一个乘法和一个加法, 所以 FLOPs 通常是 MAC 的两倍.</p>
<ol>
<li><strong>矩阵乘法:</strong> $M\times N$ 和 $N\times P$ 的两矩阵相乘, 最终输出的矩阵形状为 $M\times P$, 计算 $M\times P$ 上一个元素需要 $N$ 次乘法, 以及 $N-1$ 次加法, 因此, 矩阵乘法所需的总的 FLOPs 为:<script type="math/tex; mode=display">(N + N - 1) \times M \times P</script></li>
<li><strong>卷积层:</strong> ($C_{in}, C_{out}, K_w, K_h, W_{out}, H_{out}$)(输入输出通道数, 卷积核尺寸, 输出特征图谱尺寸): 首先计算得到 output feature map 上一个像素的值需要的 FLOPs 为 $C_{in}\cdot K_w \cdot K_h$ 次乘法, 以及 $C_{in}\cdot K_w \cdot K_h - 1$ 次加法, 如果算上 bias 加法, 则为 $C_{in}\cdot K_w \cdot K_h$ 次加法, 然后根据输出的 tensor 的 shape, 可以知道总共需要计算的像素点数为 $C_{out}\cdot W_{out} \cdot H_{out}$. 于是可以得到一个卷积层总共的 FLOPs 为:<script type="math/tex; mode=display">(2\times C_{in}\cdot K_w \cdot K_h - 1) \times (C_{out}\cdot W_{out} \cdot H_{out}) \tag{不计 bias}</script><script type="math/tex; mode=display">(2 \times C_{in}\cdot K_w \cdot K_h) \times (C_{out}\cdot W_{out} \cdot H_{out}) \tag{计入 bias}</script></li>
<li><strong>全连接层:</strong> (M, N) (输入神经元数量, 输出神经元数量). 输出一个神经元需要 $M$ 次乘法, $M-1$ 次加法, 如果算上 bias, 就是 $M$ 次加法, 扩展到输出 N 个神经元, 所需要 FLOPs 为:<script type="math/tex; mode=display">(2\times M - 1)\times \tag{不计 bias}N</script><script type="math/tex; mode=display">(2\times M)\times N \tag{计入 bias}</script></li>
</ol>
<p><span id="除了 FLOPs, 还有哪些影响模型速度的因素"></span></p>
<h2 id="除了-FLOPs-还有哪些影响模型速度的因素"><a href="#除了-FLOPs-还有哪些影响模型速度的因素" class="headerlink" title="除了 FLOPs, 还有哪些影响模型速度的因素"></a>除了 FLOPs, 还有哪些影响模型速度的因素</h2><p>参考 ShuffleNetV2 论文</p>
<p><a href="https://www.jiqizhixin.com/articles/2017-09-11-2" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-09-11-2</a> (内存带宽与计算能力，谁才是决定深度学习执行性能的关键)</p>
<p><strong>结论:</strong> 模型的执行速度除了和总的计算量有关外, 还与运算强度(每单位数据执行的运算操作)有关, 比如 1x1 卷积虽然参数量是 3x3 卷积的 1/9. 但是由于运算强度降低, 导致计算性能下降, 因此其执行速度并不能降低到 1/9. 在进行算法的速度优化的时候, 可以参考 Roofline 模型曲线, 进而决定到底是应该增大带宽还是应该降低计算量.</p>
<p><strong>分析:</strong></p>
<p><div style="width: 600px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/bottle.jpg?x-oss-process=style/blog_img" alt="%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2Fbottle.jpg"></div></p>
<p>内存带宽对于硬件系统的性能影响如上图所示。如果把内存比做瓶子，运算单元比作杯子，那么数据就是瓶子里的各色颗粒，而内存接口就是瓶口，通过瓶口数据才能进入杯子被消费（处理）掉。而内存带宽就是瓶口的宽度了。瓶口宽度越窄，则数据需要越多时间才能进入杯子（处理单元）。正所谓「巧妇难为无米之炊」，如果带宽有限，那么即使处理单元无限快，在大多数时候也是处理单元在空等数据，造成了计算力的浪费.<br>算法对于内存带宽的需求通常使用「运算强度 (operational intensity，或称 arithmetic intensity)」这个量来表示，单位是 OPs/byte。这个量的意思是，在算法中平均每读入单位数据，能支持多少次运算操作。运算强度越大，则表示单位数据能支持更多次运算，也就是说算法对于内存带宽的要求越低。所以，运算强度大是好事！<br>我们来举一个例子。对于步长（stride）为 1 的 3x3 卷积运算，假设输入数据平面大小为 64x64。简单起见，假设输入和输出 feature 都为 1。这时候，总共需要进行 62x62 次卷积运算，每次卷积需要做 3x3=9 次乘加运算，所以总共的计算次数为 34596，而数据量为（假设数据和卷积核都用单精度浮点数 2byte）：64x64x2（输入数据）+ 3x3x2（卷积核数据）= 8210 byte，所以运算强度为 34596/8210=4.21。如果我们换成 1x1 卷积，那么总的计算次数变成了 64x64=4096，而所需的数据量为 64x64x2 + 1x1x2=8194。显然，切换为 1x1 卷积可以把计算量降低接近 9 倍，但是运算强度也降低为 0.5，即对于内存带宽的需求也上升了接近 9 倍。因此，如果内存带宽无法满足 1x1 卷积计算，那么切换成 1x1 卷积计算虽然降低了接近 9 倍计算量，但是无法把计算速度提升 9 倍。</p>
<p><div style="width: 600px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/RooflineModel.jpg?x-oss-process=style/blog_img" alt="%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2FRooflineModel.jpg"></div></p>
<p>典型的 Roofline 曲线模型如上图所示，坐标轴分别是计算性能（纵轴）和算法的运算强度（横轴）。Roofline 曲线分成了两部分：左边的上升区，以及右边的饱和区。当算法的运算强度较小时，曲线处于上升区，即计算性能实际被内存带宽所限制，有很多计算处理单元是闲置的。随着算法运算强度上升，即在相同数量的数据下算法可以完成更多运算，于是闲置的运算单元越来越少，这时候计算性能就会上升。然后，随着运算强度越来越高，闲置的计算单元越来越少，最后所有计算单元都被用上了，Roofline 曲线就进入了饱和区，此时运算强度再变大也没有更多的计算单元可用了，于是计算性能不再上升，或者说计算性能遇到了由计算能力（而非内存带宽）决定的「屋顶」（roof）。拿之前 3x3 和 1x1 卷积的例子来说，3x3 卷积可能在 roofline 曲线右边的饱和区，而 1x1 卷积由于运算强度下降，有可能到了 roofline 左边的上升区，这样 1x1 卷积在计算时的计算性能就会下降无法到达峰值性能。虽然 1x1 卷积的计算量下降了接近 9 倍，但是由于计算性能下降，因此实际的计算时间并不是 3x3 卷积的九分之一。</p>
<p>显然，一个计算系统的内存带宽如果很宽，则算法不需要运算强度很大也能轻易碰到计算能力上限决定的「屋顶」。在下图中，计算能力不变，而随着内存带宽的上升，达到计算力屋顶所需的运算强度也越低。</p>
<p><div style="width: 600px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/RooflineModel2.png?x-oss-process=style/blog_img" alt="%E9%9D%A2%E8%AF%95-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2FRooflineModel2.png"></div></p>
<p>Roofline 模型在算法-硬件协同设计中非常有用，可以确定算法和硬件优化的方向：到底应该增加内存带宽／减小内存带宽需求，还是提升计算能力／降低计算量？如果算法在 roofline 曲线的上升区，那么我们应该增加内存带宽／减小内存带宽需求，提升计算能力／降低计算量对于这类情况并没有帮助。反之亦然。</p>
<p><span id="BN 放在不同位置的区别"></span></p>
<h2 id="BN-放在不同位置的区别"><a href="#BN-放在不同位置的区别" class="headerlink" title="BN 放在不同位置的区别"></a>BN 放在不同位置的区别</h2><p>结论: 由于目前我们对于神经网络内部网络层之间的影响机制还不是特别清楚, 所以在实际中通常就是前面放着试一下, 后面放着试一下, 然后取一个在具体场景下效果最好的. 目前在 <strong>实际上</strong>, Conv-ReLU-BN 的组合方式效果较好.<br>个人拙见: BN 放在激活层之前还是之后取决于你想要进行归一化的对象, 它更像是一个超参数, 需要通过实验结合实际场景来决定. 做了一些简单的实验, 发现小模型使用 BN-ReLU, 大模型使用 ReLU-BN 效果较好.</p>
<ol>
<li><p>Conv-BN-ReLU: 这是比较常见的使用方式, 这种实现方法有一个直接的好处就是可以在网络做前向 inference 的时候, 将 BN 融合到 Conv 中进行加速. 还有另一种好处是个人理解, 就是 BN 在 ReLU 的激活之前, 可以防止某一层的激活值全部被抑制(及某一层的值均小于0), 从而防止从这一层传播的梯度全是 0, 进而可以防止梯度消失现象. (BN 的减均值处理会使得相当一部分响应值变为正, 进而解决了零梯度问题)</p>
</li>
<li><p>Conv-ReLU-BN: 在具体的实验中, 通常 BN 放在最后面效果最好. 个人见解: BN 实际上就是一种归一化, 而归一化通常是对于输入层使用的, 因此, 把 BN 放在最后, 实际上就是对下一个卷积段的输入进行归一化, 从这个角度看, 将 BN 放在激活层之后, 是比较自然的一种做法. 另外, BN 的原文使用的是 sigmoid 和 tanh 激活函数, 但是对于 ReLU 激活来说, 其曲线图像有较大区别, 而 BN 层会起到一定的平滑隐藏层输入分布的作用, 因此, 对于不同的激活函数, BN 的最佳位置或许有些许不同.</p>
</li>
</ol>
<p><span id="BN 在 Inference 阶段的加速"></span></p>
<h2 id="BN-在-Inference-阶段的加速"><a href="#BN-在-Inference-阶段的加速" class="headerlink" title="BN 在 Inference 阶段的加速"></a>BN 在 Inference 阶段的加速</h2><p>在 Inference 阶段, 我们已经确定了 BN 层所需的 mean, std, $\gamma$, $\beta$ 等参数, 不用再单独的计算这些参数的值, 又因为 BN 层的运算实际上就相当于两次 Scale (缩放平移) 操作, 因此当 BN 层和 Conv 层相邻时, 我们可以将 BN 层融合到 Conv 层中, 这对于 Conv 层来说只是改变了一些计算规则, 并没有增加卷积层的计算量, 因此可以起到一定的加速作用.</p>
<p>具体在融合时分为两个情况:</p>
<ol>
<li><p>Conv-BN:<br>卷积层操作: $Y = \vec w X + \vec b$<br>BN层操作: $Y’ = \gamma \frac{Y - \hat \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta$<br>将上面两个公式融合后可变为: $Y’ = \gamma \frac{Y - \hat \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta = \gamma \frac{\vec w X + \vec b - \hat \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta = (\frac{\gamma}{\sqrt{\sigma^2 + \epsilon}} \vec w)\cdot X + \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}} \cdot \vec b - \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}}\hat \mu + \beta = k\vec w \cdot X + \vec b’$<br>可见, 融合后的 BN 就相当于是给卷积层多乘了一个常量, 同时多加了一个常量.</p>
</li>
<li><p>BN-Conv: BN-Conv 无法进行融合, 始终都需要再单独执行 BN 的 Scale 操作, 然后再执行 Conv 的卷积操作</p>
</li>
<li><p>Conv 和 BN 中间有激活层: 无法融合, 需要单独执行每一个网络层</p>
</li>
</ol>
<h2 id="Anchor-的作用是什么-为什么需要-Anchor"><a href="#Anchor-的作用是什么-为什么需要-Anchor" class="headerlink" title="Anchor 的作用是什么? 为什么需要 Anchor?"></a>Anchor 的作用是什么? 为什么需要 Anchor?</h2><p>结论: 为了将 bbox 的 scale 和 aspect ratio 划分到若干个固定的子空间中, 降低问题的复杂度, 同时也降低模型的学习难度. 另一方面, anchor 可以解决多个物体 overlap 过大导致检测结果容易丢失的问题(YOLO 单个 cell 只负责单个物体, Overlap 过大的多个物体可能会落在同一个 cell 中).</p>
<p>Faster RCNN 引入 Anchor 的 motivation:</p>
<blockquote>
<p>In contrast to prevalent methods [8], [9], [1], [2] that use pyramids of images (Figure 1, a) or pyramids of filters (Figure 1, b), we introduce novel “anchor” boxes that serve as references at <strong>multiple scales and aspect ratios</strong>. Our scheme can be thought of as a pyramid of regression references (Figure 1, c), which avoids enumerating images or filters of multiple scales or aspect ratios.</p>
</blockquote>
<p>可见, Anchor 机制要解决的问题是变化范围较大的 bbox 的 scale 和 aspect rotios 问题. 之前的解决方法都是利用 pyramids of images(耗时) 或者 pyramids of filters(传统图像处理). 此外, Anchor 机制还顺便解决了另外一个重要的问题: gt box 之间如果 overlap 较大, 那么它们就会落到一个 cell 上, 从而导致个别 gt box 丢失. 而 anchor 机制不同 scale 和 aspect ratio 的 anchor 会负责各自的 gt box, 即使有多个框映射到同一个 cell, 也不会导致 gt box 丢失.</p>
<h2 id="Anchor-是越多越好吗"><a href="#Anchor-是越多越好吗" class="headerlink" title="Anchor 是越多越好吗?"></a>Anchor 是越多越好吗?</h2><p><strong>当增加超过 6~9 个 anchor 后模型并没有显示出进一步的收益。 性能饱和意味着认为定义的、密度过大的 anchor 并没有呈现出巨大的优势。</strong><br>过于密集的 anchor 不仅会增加 前景-背景 的优化难度，而且还可能导致模糊位置定义问题。 对于每个输出空间的 location 来说，其 anchors 的标签根据与 GT 的 IoU 值定义。 其中，有一些 anchor 被定义为 positive samples，而另一些则被定义为 negative samples。 但是，它们共享这相同的 feature maps。因此分类器不仅需要区分不同位置的样本，还需要在同一位置区分不同的 anchor。</p>
<p><strong>anchor 的数量并不是越多越好</strong>, 虽然直观上来说, anchor 越多时, 可以覆盖越好的 gt box, 但是, 当 anchor 的数量过多时, 一方面由于每一个点上产生的 anchor 实际上共享了一块相似的特征, 但是这些 anchor 有一部分作为正样本, 而另一部分作为负样本, 因此, 对于神经网络来说, 他要通过不断学习来区分这些样本, 不仅如此, 他还要将这些样本与其他点产生的 anchor 区分开, 虽然 anchor 数量的增多, 学习的难度也就慢慢增多, 最终甚至会出现掉点的现象, 个人认为不会掉的特别多, 因为毕竟更多的 anchor 可以覆盖更多的局部最优解. 但是 anchor 会导致计算量的大幅度上升, 因此不建议设置过多 anchor.</p>
<p>FoveaBox 的优势(就 anchor 来说): (1) 神经网络的输出维度大大降低(1/A), 学习起来相对简单直接; (2) 不会出现 anchor 之间互相矛盾的现象 (3) 没有了 anchor 后, 检测网络变的更加简单直接, 扩展性更好</p>
<p>详细见 FoveaBox 分析</p>
<h2 id="Anchor-based-方法和-Anchor-free-方法各有什么优缺点"><a href="#Anchor-based-方法和-Anchor-free-方法各有什么优缺点" class="headerlink" title="Anchor based 方法和 Anchor free 方法各有什么优缺点?"></a>Anchor based 方法和 Anchor free 方法各有什么优缺点?</h2><ul>
<li>Anchor-based 方法处理的尺度范围小(基于 anchor 的设定), 但是更加精准(学习难度小); Anchor-free 方法覆盖的尺度范围大(没有认为设定的 anchor), 但是检测小尺度的能力较低.</li>
<li>Anchor-based 需要根据不同的任务设置更多的超参(anchor scale, aspect ratio)</li>
<li>Anchor-based 方法产生的预选框要在训练阶段和 gt box 进行 IoU 的计算才能确定正负样本, 这会占用一定的内存和运行时间, 降低训练速度. 此外, 对于 SSD 类的算法来说, 为了使其能够更为有效的检测小目标, 通常会在更大尺度的特征图上生成候选框, 这就导致候选框的数量大幅增加.</li>
<li>针对不同的任务, 所有的超参都需要重新调节, 这样一个模型的迁移能力就体现不出来了.</li>
<li>anchor-free 的方法能够在精度上媲美 anchor-based 的方法，最大的功劳我觉得应该归于 FPN，其次归于 Focal Loss。（内心OS：RetinaNet 赛高）。在每个位置只预测一个框的情况下，FPN 的结构对尺度起到了很好的弥补，FocalLoss 则是对中心区域的预测有很大帮助</li>
</ul>
<h2 id="CNN-具有平移不变性吗"><a href="#CNN-具有平移不变性吗" class="headerlink" title="CNN 具有平移不变性吗?"></a>CNN 具有平移不变性吗?</h2><p>首先, 有两个概念需要区分:</p>
<ul>
<li>平移不变性(translation invariant): 对于同样的 input, 其 output 保持不变.</li>
<li>平移等变性(translation equivalence): 如果 innput 平移, 那么其 output 也会发生相应的平移, <strong>但是 output 的取值应该保持不变</strong>.<br>对于分类(classification)任务来说, 我们希望网络具有平移不变性, 因为对于一个物体的平移来说, 不应该改变这个物体的类别. 但是对于检测(detection), 分割(segmentation)任务来说, 我们希望网络具有平移等价性, 即当物体的位置发生变化时, 我们输出的框的位置也应该发生相应的变化, 但是它的取值, 即框的大小, 框的类别应该保持不变.</li>
</ul>
<p>常见网络层对于平移不变性和平移等价性的影响:</p>
<ul>
<li>卷积层: 从卷积的运算定义来看, 卷积应该具有一定的平移等价性, 但是这种等价性需要在物体平移量为 stride 的整数倍时才 <strong>严格成立</strong>(不是整数倍时, 也具有一定程度的平移等价性). 而对于平移不变性来说, 只有当卷积核的值分布比较均匀(值相差不大), 而输入的 feature map 上的值也有很多值分布均匀(值相差不大)的区域时来具有比较弱的平移不变性, 因为这个时候 feature map 上的微小移动对于输出的改变较少.</li>
<li>池化层: 目前大部分的观点都认为, 卷积网络的平移不变性主要是通过池化层实现的, 其中最大池化相对于均值池化来说带有更强的平移不变性, 全局池化层则具有更强的平移不变性. 由于池化操作往往会忽略核内元素的位置, 因此通常认为池化层是不具有平移等价性. 另外, 个人觉得正是因为池化层具有一定程度的平移不变性, 且几乎不具有平移等价性, 因此在处理一些需要平移等价性的任务(比如检测, 分割)的时候, 会经常使用 stride 为 2 的卷积层来代替池化层, 而在分类任务中, 往往会使用池化和全局池化来消除平移的影响. 在 18 年的一篇论文(Why do deep convolutional networks generalize so poorly to small image)中也提到了 stride 为 2 的降采样操作会使得 CNN 网络丢失平移不变性.</li>
<li>全连接层: 从全连接层的计算规则来看, FC <strong>即不具有</strong> 平移不变性 <strong>也不具有</strong> 平移等价性. 因为当参与计算的向量值发生偏移时, 很明显 FC 的输出结果会发生较大的变化, 尤其适当 FC 上的神经元权重相差较大时. (等价性也要求结果保持相对不变). 但是, 我们不能就此断定添加了 FC 层的网络就丧失了平移不变性, 18 年的那篇文章里面给出的实验结果发现 VGG 的平移不变性均好于 ResNet 和 InceptionResNetV2, 文中作者的分析是因为 VGG 具有更大的 max pooling 层而另外两个网络相对较少, 同时后面两个网络更深. 但是还有一点要注意的是, <strong>VGG 有全连接层</strong> 而其他两个没有, 这说明全连接层并不是破坏 CNN 平移不变性的主导因素.</li>
</ul>
<p>我个人认为评价一个网络层是不是具有平移不变性或者平移等价性, 一方面要看它的结构特点, 另一方面也要着重看一下这个网络层学习到的参数, 不同的参数值具有的平移不变性和等价性的强度有较大区别, <strong>而参数的值又来自于数据</strong>, 所以很多时候, 想办法拿到更好的数据也是非常关键的一步. 有文章(也是18那篇)也分析了目前的大部分数据集中的数据, 都具有一定的偏向性, 这种偏向性也就导致训练出来的参数具有一定的偏向性, 不能说这种偏向性不好, 但是它对于网络的泛化能力也确实有一定的影响.</p>
<h1 id="为什么说-ReLU-中的神经元会大量死亡-死亡的神经元可以复活吗-有什么解决办法"><a href="#为什么说-ReLU-中的神经元会大量死亡-死亡的神经元可以复活吗-有什么解决办法" class="headerlink" title="为什么说 ReLU 中的神经元会大量死亡? 死亡的神经元可以复活吗? 有什么解决办法?"></a>为什么说 ReLU 中的神经元会大量死亡? 死亡的神经元可以复活吗? 有什么解决办法?</h1><p>为什么实际使用中不使用 LeakyReLU?(死亡的神经元也可以起到一定的正则作用, 实际使用效果较好)</p>
<p>在Mobile v1里面使用ReLU6，ReLU6就是普通的ReLU但是限制最大输出值为6（对输出值做clip）</p>
<p>看mobilenetv2的论文注意到激活函数是relu6，查了一下，有人说是方便后面参数的定点化Why the 6 in relu6?，　也有说relu6可以让模型学到稀疏性？</p>
<h1 id="未整理的问题"><a href="#未整理的问题" class="headerlink" title="未整理的问题"></a>未整理的问题</h1><p>Why Anchor? <a href="https://mp.weixin.qq.com/s/R0mqIUzyj-8m5JqJ-kMC5Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R0mqIUzyj-8m5JqJ-kMC5Q</a><br>盘点: 性能最强的目标检测算法 <a href="https://mp.weixin.qq.com/s/N7QdQVzm6UuPvPN9niHI6w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/N7QdQVzm6UuPvPN9niHI6w</a></p>
<p>此外，变体ShuffleNet v2<em>具有最好的精度，仍然比其他方法更快。这引发了一个实际的问题:<em>*如何增加接受域的大小?这对于高分辨率图像[39]中的目标检测至关重要。</em></em> 我们以后会研究这个话题。</p>
<p>ResNet 之后还有什么模型?</p>
<p>Batch 的 size 怎么选, 显存中一般会存储写什么: 显存占用 <a href="https://blog.csdn.net/lien0906/article/details/7886311" target="_blank" rel="noopener">https://blog.csdn.net/lien0906/article/details/7886311</a></p>
<p>【链接】网络inference阶段conv层和BN层的融合<br><a href="https://zhuanlan.zhihu.com/p/48005099" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/48005099</a></p>
<p>模型压缩方法: SVD(由于近似计算, 会降低精度), Network Pruning, Crompression.</p>
<p>手写 iou, nms, soft-nms</p>
<p>二值交叉熵, softmax 公式</p>
<p>手写计算两向量的欧式距离</p>
<p>BN</p>
<p>链表排序</p>
<p>卷积参数量的计算</p>
<p>过拟合遇到过吗？怎么处理的</p>
<p>训练时出现 Nan 可能的原因是什么?  怎么办?<br><a href="https://blog.csdn.net/Michael__Corleone/article/details/78531795" target="_blank" rel="noopener">https://blog.csdn.net/Michael__Corleone/article/details/78531795</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25110930" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25110930</a></p>
<p><a href="https://www.zhihu.com/question/49346370" target="_blank" rel="noopener">https://www.zhihu.com/question/49346370</a></p>
<p>PCA了解不，其优化目标是什么, Pca白化是什么？</p>
<p>手写BN的实现。注意BN的mean和std是在哪个维度求梯度的，mean和std是滑动平均的值。基于numpy实现</p>
<p>说下牛顿法</p>
<p>反卷积具体怎么实现的</p>
<p>为什么dropout能减少过拟合</p>
<p>NMS的原理，假设两个人靠的非常近，则会识别成一个bbx，会有什么问题，怎么解决</p>
<p>Pytorch当中permute和view的功能</p>
<h1 id="逻辑回归-1"><a href="#逻辑回归-1" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>Logistic(Sigmoid) 函数: $g(z) = \frac{1}{1+e^{-z}}$<br>Logistic 表达式: $h_\theta (x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^Tx}}$<br>线性回归模型: $\theta^T x = \sum^n_{i=1}\theta_i x_i$<br>SGD</p>
<p>Logistic 的梯度更新表达式和最小二乘法(LMS)的公式相同, 虽然看上去完全相同, 但实际上 SGD 和 LMS 是两个完全不同的算法, 因为 SGD 中的 $h_\theta (x)$ 表示的是关于 $\theta^T x$ 的一个非线性函数.</p>
<p>机器学习500问 第二章<br>百面机器学习 第三章</p>
<h1 id="线性回归和逻辑回归的原理和区别"><a href="#线性回归和逻辑回归的原理和区别" class="headerlink" title="线性回归和逻辑回归的原理和区别"></a>线性回归和逻辑回归的原理和区别</h1><h1 id="在Faster-RCNN中-如果两个物体重合度很高-会怎么样"><a href="#在Faster-RCNN中-如果两个物体重合度很高-会怎么样" class="headerlink" title="在Faster RCNN中, 如果两个物体重合度很高, 会怎么样"></a>在Faster RCNN中, 如果两个物体重合度很高, 会怎么样</h1><p>由于 Faster RCNN 在提取感兴趣区域的时候, 它的类别默认是只有二类, 即是否包含物体, 所以如果两个物体重合度很高的话, 最终可能就只能检测出一个物体.(right?)</p>
<h1 id="卷积神经网络复杂度分析"><a href="#卷积神经网络复杂度分析" class="headerlink" title="卷积神经网络复杂度分析"></a>卷积神经网络复杂度分析</h1><p><a href="../深度学习-卷积神经网络复杂度分析">卷积神经网络复杂度分析</a></p>
<h1 id="卷积计算-卷积层特参数个数及征图谱尺寸计算"><a href="#卷积计算-卷积层特参数个数及征图谱尺寸计算" class="headerlink" title="卷积计算,卷积层特参数个数及征图谱尺寸计算"></a>卷积计算,卷积层特参数个数及征图谱尺寸计算</h1><p>卷积层输入图谱大小为 $D_in \times D_{in} \times depth_{in}$ , 卷积核尺寸为 $F \times F \times depth_{in}$, 步长为 $stride$ ,结合padding,输出的图谱size是多少</p>
<script type="math/tex; mode=display">D_{out} = \frac{D_{in} - F + 2*Padding}{stride} + 1</script><p>输出的特征图谱的深度为卷积核的个数: $depth_{out} = Num_{filters}$</p>
<p>本层的偏置参数数量: $Num_{bias} = Num_{filters}$, 注意只与卷积核的个数有关, 与输入的特征图谱的深度无关</p>
<p>该层的参数个数 = 卷积核参数个数 + 偏置项参数个数:</p>
<script type="math/tex; mode=display">Num_{params} = F \times F \times depth_{in} \times depth_{out} + Num_{bias}</script><h1 id="L2正则化和L2规范化-归一化-的不同"><a href="#L2正则化和L2规范化-归一化-的不同" class="headerlink" title="L2正则化和L2规范化(归一化)的不同"></a>L2正则化和L2规范化(归一化)的不同</h1><p>正则化是指正则项, 计算完以后是一个矢量. 归一化是将向量中每个元素进行归一化, 计算完以后还是同size的向量, L2归一化实际上就是对每一个元素除以L2正则项.</p>
<h1 id="从-rcnn-到-faster"><a href="#从-rcnn-到-faster" class="headerlink" title="从 rcnn 到 faster"></a>从 rcnn 到 faster</h1><p><a href="https://blog.csdn.net/xiaoye5606/article/details/71191429" target="_blank" rel="noopener">https://blog.csdn.net/xiaoye5606/article/details/71191429</a></p>
<h1 id="为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好"><a href="#为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好" class="headerlink" title="为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???"></a>为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???</h1><h1 id="神经网络参数初始化"><a href="#神经网络参数初始化" class="headerlink" title="神经网络参数初始化"></a>神经网络参数初始化</h1><h1 id="分类问题为什么用交叉熵"><a href="#分类问题为什么用交叉熵" class="headerlink" title="分类问题为什么用交叉熵"></a>分类问题为什么用交叉熵</h1><p><strong>典型错误答案1:</strong> 如果用交叉熵，能保证神经网络训练时是一个凸优化问题</p>
<p>错误原因: 凸函数的复合并不一定是凸函数</p>
<p><strong>典型错误答案2:</strong> 如果当前值与目标值相差很远，则梯度下降法迭代时收敛的更快一些</p>
<p>错误原因: 欧式距离(平方损失)也能起到这个作用, 为什么不用?</p>
<p><strong>正确答案:</strong></p>
<p>Cross-Entropy vs. Squared Error Training: a Theoretical and Experimental Comparison.</p>
<h1 id="Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么"><a href="#Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么" class="headerlink" title="Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?"></a>Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?</h1><p>Relu是强制正则化(所有神经元的输出值, 只要小于0, 就置为0)</p>
<p>Dropout是随机正则化(随机让一些神经元的不起作用)</p>
<h1 id="介绍一下-hard-negative-mining-难样例挖掘"><a href="#介绍一下-hard-negative-mining-难样例挖掘" class="headerlink" title="介绍一下 hard negative mining(难样例挖掘)"></a>介绍一下 hard negative mining(难样例挖掘)</h1><h1 id="dropout内部是怎么实现的"><a href="#dropout内部是怎么实现的" class="headerlink" title="dropout内部是怎么实现的"></a>dropout内部是怎么实现的</h1><p>在 <strong>训练阶段</strong> 给每个神经元的参数都会乘以 $\frac{1}{\alpha_{dropout}}$, 这样一来, 在训练阶段可以随时更改dropout的参数值, 而对于测试阶段来说, 无需对神经元进行任何额外处理, 所有的神经元都相当于适配了训练过程中dropout对参数带来的影响.</p>
<h1 id="简述一下BN"><a href="#简述一下BN" class="headerlink" title="简述一下BN"></a>简述一下BN</h1><p>首先标准化就是将数据归一到一个希望的区间内, 一般都是归一化到激活函数敏感区域内, 而BN和传统标准标准化的区别主要有两点:</p>
<ul>
<li>BN是在每一个batch上做标准化的, 并且不仅仅只对输入层数据做标准化, 对网络内部的隐藏层输入也会进行标准话</li>
<li>第二就是BN并不是在标准的减均值初标准差之后, 还会进行一个线性变换,<strong>其本质就是改变数据分布的方差和均值</strong>. 对应的两个参数是通过学习学出来的. 其主要思想是考虑到数据可能本身就具有一定的不对称性, 并且激活函数也不一定就在面对标准数据时才有最好的表现, 因此</li>
</ul>
<p>关于BN的详细解析可以看:</p>
<p><div style="width: 550px; margin: auto"><img src="Batch-Normalization深入解析" alt=""></div></p>
<h1 id="各种初始化方式，及公式各个参数对训练的影响"><a href="#各种初始化方式，及公式各个参数对训练的影响" class="headerlink" title="各种初始化方式，及公式各个参数对训练的影响"></a>各种初始化方式，及公式各个参数对训练的影响</h1><h1 id="目标检测，数据不平衡问题怎么解决"><a href="#目标检测，数据不平衡问题怎么解决" class="headerlink" title="目标检测，数据不平衡问题怎么解决"></a>目标检测，数据不平衡问题怎么解决</h1><p>对于目标物的不平衡问题, 通过采样方法来缓解.</p>
<p>对于前后景样本数的不平衡问题, 尝试使用FocalLoss来解决</p>
<script type="math/tex; mode=display">L = -(1-p_t)^\gamma log(p_t)</script><h1 id="你的zerotensor和TF比性能上有优势吗"><a href="#你的zerotensor和TF比性能上有优势吗" class="headerlink" title="你的zerotensor和TF比性能上有优势吗"></a>你的zerotensor和TF比性能上有优势吗</h1><h1 id="常用的数据增强技术"><a href="#常用的数据增强技术" class="headerlink" title="常用的数据增强技术"></a>常用的数据增强技术</h1><p>水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转</p>
<h1 id="有哪些可以避免过拟合的办法"><a href="#有哪些可以避免过拟合的办法" class="headerlink" title="有哪些可以避免过拟合的办法"></a>有哪些可以避免过拟合的办法</h1><p>数据增强, 正则化, 模型融合(其中dropout是模型融合方法中最高效和常用的技巧)</p>
<p>为了防止过拟合，增加训练样本是一个好的解决方案。此外，还可使用数据增强、L1 正则化、L2 正则化、Dropout、DropConnect 和早停（Early stopping）法等</p>
<h1 id="正则化L1和L2的区别"><a href="#正则化L1和L2的区别" class="headerlink" title="正则化L1和L2的区别"></a>正则化L1和L2的区别</h1><h2 id="rcnn。。"><a href="#rcnn。。" class="headerlink" title="rcnn。。"></a>rcnn。。</h2><h1 id="推导svm"><a href="#推导svm" class="headerlink" title="推导svm"></a>推导svm</h1><h1 id="卷积层的参数个数计算公式是："><a href="#卷积层的参数个数计算公式是：" class="headerlink" title="卷积层的参数个数计算公式是："></a>卷积层的参数个数计算公式是：</h1><p>输入的filers×kernerl size ×输出的filters。如：</p>
<p>（3×3×256）×512   括号前面是每一个卷积核的大小，后面的是总共有512个卷积核</p>
<h1 id="梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"><a href="#梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法" class="headerlink" title="梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"></a>梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法</h1><p>详见<a href="">梯度消失和梯度爆炸问题深入解析</a></p>
<p><span id="activation"> </span></p>
<h1 id="关于各种激活函数的解析与讨论"><a href="#关于各种激活函数的解析与讨论" class="headerlink" title="关于各种激活函数的解析与讨论"></a>关于各种激活函数的解析与讨论</h1><h1 id="简述ResNet"><a href="#简述ResNet" class="headerlink" title="简述ResNet"></a>简述ResNet</h1><h1 id="嵌入式开发很底层-一般还是倾向于做一些上层的东西"><a href="#嵌入式开发很底层-一般还是倾向于做一些上层的东西" class="headerlink" title="嵌入式开发很底层   一般还是倾向于做一些上层的东西"></a>嵌入式开发很底层   一般还是倾向于做一些上层的东西</h1><h1 id="推导SVM"><a href="#推导SVM" class="headerlink" title="推导SVM"></a>推导SVM</h1><h1 id="比较Boosting和Bagging的异同"><a href="#比较Boosting和Bagging的异同" class="headerlink" title="比较Boosting和Bagging的异同"></a>比较Boosting和Bagging的异同</h1><p>二者都是集成学习方法, 都是将多个弱学习器组合成强学习器的方法, 它们的区别在于:</p>
<p>Boosting: 每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重, 训练得到k个弱分类器, 他们都有各自的权重, 通过加权组合的方式得到最终的分类结果</p>
<p>Bagging: 从原始数据集中每一轮又放回地抽取训练集(抽取的训练集小于原始数据集), 训练得到k个弱学习器, 然后将这k个软学习器的分类结果结合, 得到最终的分类结果.</p>
<h1 id="无监督学习中存在过拟合吗"><a href="#无监督学习中存在过拟合吗" class="headerlink" title="无监督学习中存在过拟合吗?"></a>无监督学习中存在过拟合吗?</h1><p>存在.<br>//TODO 补充  什么情况下会产生无监督的过拟合</p>
<h1 id="什么是K折交叉验证"><a href="#什么是K折交叉验证" class="headerlink" title="什么是K折交叉验证?"></a>什么是K折交叉验证?</h1><p>将原始数据集划分为k个子集, 将其中一个子集作为验证集, 其余k-1个子集作为训练集, 如此训练和验证一轮成为一次交叉验证. 交叉验证重复k此, 每个子集都会做一次验证, 最终得到k个模型, 然后可以对这k个模型的结果加权平均, 以作为评估整体模型的依据</p>
<h1 id="关于k折交叉验证-需要注意什么"><a href="#关于k折交叉验证-需要注意什么" class="headerlink" title="关于k折交叉验证, 需要注意什么?"></a>关于k折交叉验证, 需要注意什么?</h1><p>k越大, 不一定效果越好, 而且越大的k会加大训练时间;</p>
<p>在选择k时, 需要考虑最小化数据集之间的方差, 比如对于2分类任务, 如果采用2折交叉验证, 即对原始数据集二分,若此时训练集中都是A类别, 验证集中都是B类别, 则交叉验证效果会非常差</p>
<h1 id="对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化"><a href="#对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化" class="headerlink" title="对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?"></a>对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?</h1><p>准确率 = TP / (TP + FP), 召回率 = TP / (TP, FN)</p>
<p>若增大阈值t, 则更多不确定的样本将会被分为负例, 剩余确定样本的所占比例会增大, 那么准确率就会提升(或不变); 同时, 由于那些不确定的样本中还可能包含有正例, 引起, 阈值调大后, 这些正例就会被认为是负例, 所以召回率减小(或不变)</p>
<h1 id="增加网络层数-是否总能减小训练集错误率"><a href="#增加网络层数-是否总能减小训练集错误率" class="headerlink" title="增加网络层数, 是否总能减小训练集错误率?"></a>增加网络层数, 是否总能减小训练集错误率?</h1><p>不能, 有时候网络层数过深, 还会因为梯度消失导致模型退化, 使得模型性能降低</p>
<h1 id="在目标检测问题上-如何做数据增广"><a href="#在目标检测问题上-如何做数据增广" class="headerlink" title="在目标检测问题上, 如何做数据增广?"></a>在目标检测问题上, 如何做数据增广?</h1><h1 id="softmax怎么跟交叉熵损失函数结合"><a href="#softmax怎么跟交叉熵损失函数结合" class="headerlink" title="softmax怎么跟交叉熵损失函数结合?"></a>softmax怎么跟交叉熵损失函数结合?</h1><h1 id="用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值"><a href="#用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值" class="headerlink" title="用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?"></a>用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?</h1><p>输入数据本身存在nan值, 或者考虑是否梯度爆炸了(可以试着降低学习率, 或者利用截断法先知梯度的值)</p>
<h1 id="有没有自己试过更改模型的框架"><a href="#有没有自己试过更改模型的框架" class="headerlink" title="有没有自己试过更改模型的框架."></a>有没有自己试过更改模型的框架.</h1><p>有时候读paper会遇到一些好的点子或者方法, 自己会去加到现有的网络中去验证一下是不是能够提升模型的性能, 一般情况下, 比较经典且认可度较高的一些算法, 由于在网上都能找到相应的源码, 加上去的时候性能往往会有一点提升, 但是有时候有的方法比较偏, 我加完了以后有时候是没作用, 有时候是性能降低了, 我不知道到底是我实现的和paper有出入, 还是这个东西不适合当前框架</p>
<h1 id="说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升"><a href="#说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升" class="headerlink" title="说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!"></a>说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!</h1><p>OHEM ~3%</p>
<h1 id="SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高"><a href="#SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高" class="headerlink" title="SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高"></a>SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高</h1><h1 id="池化的优点-优化的缺点"><a href="#池化的优点-优化的缺点" class="headerlink" title="池化的优点, 优化的缺点"></a>池化的优点, 优化的缺点</h1><p>优点:</p>
<ul>
<li>显著减少参数数量, 降低过拟合</li>
<li>池化单元具有平移不变性</li>
</ul>
<p>缺点:<br>pooling能够增大感受野, 让后续的卷积看到更多的信息, 但是它在降维的过程中丢失了一些信息, 这对segmentation要求的精确location有一定的影响, 所以pooling层跟segmentation有一定的冲突, 但是感受野的增大有可以特征检测实例的准确率, 还可以降低计算量, 增强泛化能力. 所以这个是实例分割问题需要解决的一个关键点之一.</p>
<h1 id="待定"><a href="#待定" class="headerlink" title="待定"></a>待定</h1><p><a href="https://blog.csdn.net/comway_Li/article/details/82532573" target="_blank" rel="noopener">https://blog.csdn.net/comway_Li/article/details/82532573</a></p>
<h1 id="完善bisai待看"><a href="#完善bisai待看" class="headerlink" title="完善bisai待看"></a>完善bisai待看</h1><p><a href="https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion/64986" target="_blank" rel="noopener">https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion/64986</a></p>
<p><a href="https://arxiv.org/abs/1809.00778" target="_blank" rel="noopener">https://arxiv.org/abs/1809.00778</a></p>
<p><a href="https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion" target="_blank" rel="noopener">https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion</a></p>
<h1 id="谈谈你参加的比赛"><a href="#谈谈你参加的比赛" class="headerlink" title="谈谈你参加的比赛"></a>谈谈你参加的比赛</h1><p>对于一个比赛任务, 我会首先进行预处理,  之后, 会根据数据集的数据分布来对参数进行调整, 比如, 先只训练顶层, 然后逐步放开, 最后再训练所有层的参数.  在训练的时候,我一般都会采用bagging的思想, 将训练集随机28分, 分成3份, 然后训练, 最后进行模型融合,  融合的时候我一般都是对训练结果进行融合.</p>
<p>如果是目标检测累任务, 那么就:…</p>
<p>如果是实力分割类任务, 那么就:</p>
<h1 id="对于一个新任务-你一般都会使用那些数据预处理方法"><a href="#对于一个新任务-你一般都会使用那些数据预处理方法" class="headerlink" title="(对于一个新任务,) 你一般都会使用那些数据预处理方法"></a>(对于一个新任务,) 你一般都会使用那些数据预处理方法</h1><ol>
<li>训练数据可视化</li>
</ol>
<p>首先, 不论是什么样的数据集, 我都会先随机挑选 20 到 100张 的训练数据, 然后根据标签, 将图片数据可视化出来, 比如说如果是目标检测的任务, 我就会用opencv 的<code>cv2.rectangle()</code> 函数和 <code>cv2.putText()</code> 函数将标签里面的bbox标签和类别标签画到图片上去, 并且建立一个字典结构, 将不同的class-id对应到不同的颜色,  如果是实力分割任务, 我就会将mask标签反应到图片上去, 一般就是先将单通道的mask扩展成多通道的, 同时根据不同的class-id赋予不同的颜色, 最后利用numpy的where方法和原始图片进行叠加.  一般对于这种几十张的smaple图片, 我都是直接保存, 这样以后想再看的时候也不用重新跑脚本了.</p>
<p>之后, 我就会先简单浏览一下这些数据, 对整个数据集有一个初步的把握, 大概知道哪些物体被标注了, 有时候也能发现很多标注存在问题, 不过这也没有办法,  毕竟标注是一个很费时费力的工作, 错误在所难免.</p>
<ol>
<li>计算数据分布信息</li>
</ol>
<p>然后我就会写个脚本对整个数据集和标签进行遍历, 统计一些信息, 通常我会检测这么几个信息:</p>
<p>图像的平均尺寸, 整个数据集的像素平均值, 每张图片平均包含的目标个数, 每个类别的目标个数以及目标的平均大小,</p>
<p>同时, 因为平均值有时候往往反应不出来太多信息, 所以我还会用matplotlib把每种信息的直方图画出来, 然后看一下数据的整体分布是什么样子的, 比如图片size的分布, 目标大小的分布等等, 我主要就是根据这些分布信息来决定我最开始的参数设置.  主要调的参数就是imagesize,anchors相关的参数, 其他的还有就非极大抑制和置信度的阈值, 有时候还会试一下BN的作用(默认是关闭的)</p>
<p>然后一般情况下我都会对数据集做增广</p>
<p>常用的就是裁剪, 反转, 虚化, 颜色变换等等, 增广我不会做太多, 一般就用一些常用的增广方法</p>
<h1 id="比赛中用到的模型融合方法"><a href="#比赛中用到的模型融合方法" class="headerlink" title="比赛中用到的模型融合方法:"></a>比赛中用到的模型融合方法:</h1><p>对于目标检测任务:</p>
<p>我用的融合策略就是先以一个结果文件为基准, 然后用另一个结果文件里面的某张图片的框去跟前一个结果文件对应图片的所有框作比较, 因为之间会对框的面积做排序, 所以只与面积相似的框作比较, 看看框的位置是不是也相似, 如果相似, 就认为检测的是同一个物体, 然后就看他们的类别是否相同, 这里我一般会使用三个结果文件(来自于三个不同模型)进行投票选择.</p>
<p>对于有的框不在另一个文件的,  我就会根据框的置信度来设置一个阈值, 大于阈值的我就直接把框加进去, 如果有票数相同的, 就按置信度来区分.</p>
<h1 id="你的方法与其他人方法的区别是什么-为什么比别人的方法差"><a href="#你的方法与其他人方法的区别是什么-为什么比别人的方法差" class="headerlink" title="你的方法与其他人方法的区别是什么? 为什么比别人的方法差?"></a>你的方法与其他人方法的区别是什么? 为什么比别人的方法差?</h1><h1 id="对于faster-rcnn-你都调了哪些参数"><a href="#对于faster-rcnn-你都调了哪些参数" class="headerlink" title="对于faster rcnn 你都调了哪些参数?"></a>对于faster rcnn 你都调了哪些参数?</h1><p>首先调的是anchor相关参数, 比如anchor size 和 anchor ratio</p>
<p>然后是学习率, 前景后景的样本比例, 非极大抑制的阈值, 候选区域块的生成个数, 图片的缩放尺度等等</p>
<h1 id="BN具体是什么实现的"><a href="#BN具体是什么实现的" class="headerlink" title="BN具体是什么实现的"></a>BN具体是什么实现的</h1><h1 id="对于平均移动了解吗"><a href="#对于平均移动了解吗" class="headerlink" title="对于平均移动了解吗"></a>对于平均移动了解吗</h1><h1 id="积分图-快速求矩阵的核"><a href="#积分图-快速求矩阵的核" class="headerlink" title="积分图, 快速求矩阵的核"></a>积分图, 快速求矩阵的核</h1><h1 id="样本不均衡问题怎么解决"><a href="#样本不均衡问题怎么解决" class="headerlink" title="样本不均衡问题怎么解决"></a>样本不均衡问题怎么解决</h1><h1 id="详细说一下Focal-Loss"><a href="#详细说一下Focal-Loss" class="headerlink" title="详细说一下Focal Loss"></a>详细说一下Focal Loss</h1><h1 id="说一下为什么Faster-比YOLO和SSD更准确"><a href="#说一下为什么Faster-比YOLO和SSD更准确" class="headerlink" title="说一下为什么Faster 比YOLO和SSD更准确"></a>说一下为什么Faster 比YOLO和SSD更准确</h1><h1 id="样本采样的理论化值是"><a href="#样本采样的理论化值是" class="headerlink" title="样本采样的理论化值是"></a>样本采样的理论化值是</h1><h1 id="anchor的参数设值怎么选的？-为什么这么设置"><a href="#anchor的参数设值怎么选的？-为什么这么设置" class="headerlink" title="anchor的参数设值怎么选的？  为什么这么设置"></a>anchor的参数设值怎么选的？  为什么这么设置</h1><h1 id="在调试RPN网络时有没有遇到什么问题？"><a href="#在调试RPN网络时有没有遇到什么问题？" class="headerlink" title="在调试RPN网络时有没有遇到什么问题？"></a>在调试RPN网络时有没有遇到什么问题？</h1><h1 id="简述一下faster-rcnn模型"><a href="#简述一下faster-rcnn模型" class="headerlink" title="简述一下faster rcnn模型"></a>简述一下faster rcnn模型</h1><h1 id="简述一下ResNet模型及它解决的问题"><a href="#简述一下ResNet模型及它解决的问题" class="headerlink" title="简述一下ResNet模型及它解决的问题"></a>简述一下ResNet模型及它解决的问题</h1><h1 id="如何优化CNN-Backbone"><a href="#如何优化CNN-Backbone" class="headerlink" title="如何优化CNN Backbone"></a>如何优化CNN Backbone</h1><p>我们在DataParallel的语境下面讨论这个问题。也就是说，每张显卡都保存一份参数全集，一份数据+数据形成FeatureMap的子集。</p>
<p>我们知道，就像组装深度学习服务器一样，你的预算一定的条件下，如何搭配一台服务器才能让CPU对数据预处理够用、内存加载数据够用、硬盘I/O够用，以及最重要的是，选择一块好的GPU卡。资源不是无限的。这其实是一个线性规划问题。在这里不赘述。</p>
<p>进行CNN Backbone优化同样有这个问题：</p>
<h1 id="你的显存利用率和GPU算力利用率如何达到最高？"><a href="#你的显存利用率和GPU算力利用率如何达到最高？" class="headerlink" title="你的显存利用率和GPU算力利用率如何达到最高？"></a>你的显存利用率和GPU算力利用率如何达到最高？</h1><p>降低Batch-size会减小Feature Map占用缓存，但收敛情况怎么样，可能饮鸩止渴。<br>加宽直接影响参数数量。<br>加深不仅影响参数数量还影响Feature Map大小。<br>分组极大节省参数，甚至还能提高效果。<br>结构复用、压缩节省参数，增加计算量。<br>特征拼接、高阶操作降低并行效率，尤其不是inplace的那种。在动态图框架尤为如此。<br>Bilinear大量使用额外参数。<br>非对称带来额外的代码工作。<br>任何新颖结构的引入带来非连续超参，让模型BP，让超参优化无B可P。<br>如何提高CNN Backbone设计品位？<br>美就是简单<br>美就是复用<br>美就是对称<br>美就是分形<br>Inception-ResNet.v2干不过ResNeXt，我一点都不意外。<br>Mask-RCNN标配ResNeXt101 Backbone，我一点都不意外。</p>
<h1 id="为什么要压缩模型，而不是直接训练一个小模型"><a href="#为什么要压缩模型，而不是直接训练一个小模型" class="headerlink" title="为什么要压缩模型，而不是直接训练一个小模型"></a>为什么要压缩模型，而不是直接训练一个小模型</h1><p><a href="https://www.zhihu.com/question/303922732/answer/541660954" target="_blank" rel="noopener">https://www.zhihu.com/question/303922732/answer/541660954</a></p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/知识点梳理/" rel="tag"><i class="fa fa-tag"></i> 知识点梳理</a>
          
            <a href="/tags/计算机视觉/" rel="tag"><i class="fa fa-tag"></i> 计算机视觉</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/z_post/计算机视觉-目标检测训练策略/" rel="prev" title="计算机视觉-目标检测训练策略">
                <i class="fa fa-chevron-left"></i> 计算机视觉-目标检测训练策略
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/z_post/面试-算法刷题-LeetCode-record/" rel="next" title="LeetCode 算法题(记录总结)">
                LeetCode 算法题(记录总结) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar_zz.png"
                alt="ZeroZone" />
            
              <p class="site-author-name" itemprop="name">ZeroZone</p>
              <p class="site-description motion-element" itemprop="description">并不是什么厉害的地方<br>只是一个安静的学习角落</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">263</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">40</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hellozhaozheng" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:hellozhaozheng@foxmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://blog.csdn.net/ksws0292756" title="零域CSDN博客" target="_blank">零域CSDN博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://xinghanzzy.github.io/" title="BoXiao的博客" target="_blank">BoXiao的博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://oldpan.me/" title="Oldpan的博客" target="_blank">Oldpan的博客</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#总目录篇"><span class="nav-text">总目录篇</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习篇"><span class="nav-text">机器学习篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念"><span class="nav-text">基本概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归"><span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机"><span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树"><span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#降维"><span class="nav-text">降维</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类"><span class="nav-text">聚类</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习篇"><span class="nav-text">深度学习篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化方法"><span class="nav-text">优化方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初始化方法"><span class="nav-text">初始化方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#损失函数"><span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数"><span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#归一化"><span class="nav-text">归一化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感受野"><span class="nav-text">感受野</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#全连接层"><span class="nav-text">全连接层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积层"><span class="nav-text">卷积层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#反卷积层"><span class="nav-text">反卷积层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#池化层"><span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练问题"><span class="nav-text">训练问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#网络结构篇"><span class="nav-text">网络结构篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#AlexNet"><span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VGGNet"><span class="nav-text">VGGNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#InceptionV1"><span class="nav-text">InceptionV1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#InceptionV3"><span class="nav-text">InceptionV3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-InceptionV2-相比于-GoogLeNet-有什么区别"><span class="nav-text">简述 InceptionV2 相比于 GoogLeNet 有什么区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-InceptionV3-相比于-GoogLeNet-有什么区别"><span class="nav-text">简述 InceptionV3 相比于 GoogLeNet 有什么区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#InceptionV4-and-Inception-ResNet"><span class="nav-text">InceptionV4 and Inception ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-InceptionV4-做了哪些改进"><span class="nav-text">简述 InceptionV4 做了哪些改进</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Inception-Resnet-v1-做了哪些改进"><span class="nav-text">简述 Inception-Resnet-v1 做了哪些改进</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Inception-ResNet-v2-做了哪些改进"><span class="nav-text">简述 Inception-ResNet-v2 做了哪些改进</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xception"><span class="nav-text">Xception</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet"><span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNeXt"><span class="nav-text">ResNeXt</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DenseNet"><span class="nav-text">DenseNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SqueezeNet"><span class="nav-text">SqueezeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MobileNet"><span class="nav-text">MobileNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MobileNetV2"><span class="nav-text">MobileNetV2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ShuffleNet"><span class="nav-text">ShuffleNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ShuffleNetV2"><span class="nav-text">ShuffleNetV2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SENet"><span class="nav-text">SENet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测篇"><span class="nav-text">目标检测篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#NMS"><span class="nav-text">NMS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-NMS-的原理"><span class="nav-text">简述 NMS 的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NMS-算法源码实现"><span class="nav-text">NMS 算法源码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Soft-NMS-的原理"><span class="nav-text">简述 Soft-NMS 的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-NMS-算法源码实现"><span class="nav-text">Soft-NMS 算法源码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#介绍一下其他的-NMS-算法"><span class="nav-text">介绍一下其他的 NMS 算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#R-CNN"><span class="nav-text">R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fast-R-CNN"><span class="nav-text">Fast R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Faster-R-CNN"><span class="nav-text">Faster R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mask-R-CNN"><span class="nav-text">Mask R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FPN"><span class="nav-text">FPN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FCN"><span class="nav-text">FCN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RFCN"><span class="nav-text">RFCN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deformable-CNN"><span class="nav-text">Deformable CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cascade-R-CNN"><span class="nav-text">Cascade R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SSD"><span class="nav-text">SSD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv1"><span class="nav-text">YOLOv1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv2"><span class="nav-text">YOLOv2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv3"><span class="nav-text">YOLOv3</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FocalLoss"><span class="nav-text">FocalLoss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SNIP"><span class="nav-text">SNIP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SNIPER"><span class="nav-text">SNIPER</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TridentNet"><span class="nav-text">TridentNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DenseBox"><span class="nav-text">DenseBox</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CornerNet"><span class="nav-text">CornerNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FSAF"><span class="nav-text">FSAF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FoveaBox"><span class="nav-text">FoveaBox</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FCOS"><span class="nav-text">FCOS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ExtremeNet"><span class="nav-text">ExtremeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CenterNet"><span class="nav-text">CenterNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CenterNet-Objects-as-Points"><span class="nav-text">CenterNet(Objects as Points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CornerNet-Lite"><span class="nav-text">CornerNet-Lite</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TridentNet-1"><span class="nav-text">TridentNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HTC"><span class="nav-text">HTC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他"><span class="nav-text">其他</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像处理篇"><span class="nav-text">图像处理篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#图像放缩"><span class="nav-text">图像放缩</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#边缘检测算法"><span class="nav-text">边缘检测算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#霍夫变换"><span class="nav-text">霍夫变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像保边滤波器"><span class="nav-text">图像保边滤波器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像平移"><span class="nav-text">图像平移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像开操作、闭操作"><span class="nav-text">图像开操作、闭操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像旋转"><span class="nav-text">图像旋转</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像重建质量评价指标"><span class="nav-text">图像重建质量评价指标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#光流法"><span class="nav-text">光流法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像去噪的方法"><span class="nav-text">图像去噪的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#度量图像patch相似度的方法"><span class="nav-text">度量图像patch相似度的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#传统图像处理CDC做过吗？"><span class="nav-text">传统图像处理CDC做过吗？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#傅里叶变换"><span class="nav-text">傅里叶变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像融合算法有哪些？"><span class="nav-text">图像融合算法有哪些？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像增强算法有哪些"><span class="nav-text">图像增强算法有哪些</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像滤波方法"><span class="nav-text">图像滤波方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#直方图均衡化"><span class="nav-text">直方图均衡化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#算法实现篇"><span class="nav-text">算法实现篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN"><span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#K-Means"><span class="nav-text">K-Means</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IoU"><span class="nav-text">IoU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NMS-1"><span class="nav-text">NMS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵乘法"><span class="nav-text">矩阵乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高斯滤波"><span class="nav-text">高斯滤波</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数学基础篇"><span class="nav-text">数学基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#概率分布"><span class="nav-text">概率分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性代数"><span class="nav-text">线性代数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常见问题篇"><span class="nav-text">常见问题篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目前的-SOTA-目标检测模型"><span class="nav-text">目前的 SOTA 目标检测模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SSD-FPN-RefineDet-PFPNet-STDN-M2Det-等特征金字塔的区别"><span class="nav-text">SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#常用的训练-Trick"><span class="nav-text">常用的训练 Trick</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#有哪些数据增广方法-怎么实现的"><span class="nav-text">有哪些数据增广方法? 怎么实现的?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FCN-是如何降低计算量的"><span class="nav-text">FCN 是如何降低计算量的?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch-和-TensorFlow-的区别"><span class="nav-text">PyTorch 和 TensorFlow 的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目标检测领域还有哪些可以继续改进或者优化的地方"><span class="nav-text">目标检测领域还有哪些可以继续改进或者优化的地方</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#one-stage目标检测算法中-浅层特征图检测小目标，为什么不同时也检测大目标？"><span class="nav-text">one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPU-两个重要指标之间的关系"><span class="nav-text">GPU 两个重要指标之间的关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络显存占用"><span class="nav-text">神经网络显存占用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节省显存的方法"><span class="nav-text">节省显存的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#各个网络层的参数量"><span class="nav-text">各个网络层的参数量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#如何计算-FLOPs-和-MAC"><span class="nav-text">如何计算 FLOPs 和 MAC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#除了-FLOPs-还有哪些影响模型速度的因素"><span class="nav-text">除了 FLOPs, 还有哪些影响模型速度的因素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BN-放在不同位置的区别"><span class="nav-text">BN 放在不同位置的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BN-在-Inference-阶段的加速"><span class="nav-text">BN 在 Inference 阶段的加速</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-的作用是什么-为什么需要-Anchor"><span class="nav-text">Anchor 的作用是什么? 为什么需要 Anchor?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-是越多越好吗"><span class="nav-text">Anchor 是越多越好吗?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-based-方法和-Anchor-free-方法各有什么优缺点"><span class="nav-text">Anchor based 方法和 Anchor free 方法各有什么优缺点?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN-具有平移不变性吗"><span class="nav-text">CNN 具有平移不变性吗?</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么说-ReLU-中的神经元会大量死亡-死亡的神经元可以复活吗-有什么解决办法"><span class="nav-text">为什么说 ReLU 中的神经元会大量死亡? 死亡的神经元可以复活吗? 有什么解决办法?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#未整理的问题"><span class="nav-text">未整理的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归-1"><span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归和逻辑回归的原理和区别"><span class="nav-text">线性回归和逻辑回归的原理和区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在Faster-RCNN中-如果两个物体重合度很高-会怎么样"><span class="nav-text">在Faster RCNN中, 如果两个物体重合度很高, 会怎么样</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络复杂度分析"><span class="nav-text">卷积神经网络复杂度分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积计算-卷积层特参数个数及征图谱尺寸计算"><span class="nav-text">卷积计算,卷积层特参数个数及征图谱尺寸计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#L2正则化和L2规范化-归一化-的不同"><span class="nav-text">L2正则化和L2规范化(归一化)的不同</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#从-rcnn-到-faster"><span class="nav-text">从 rcnn 到 faster</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好"><span class="nav-text">为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络参数初始化"><span class="nav-text">神经网络参数初始化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类问题为什么用交叉熵"><span class="nav-text">分类问题为什么用交叉熵</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么"><span class="nav-text">Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#介绍一下-hard-negative-mining-难样例挖掘"><span class="nav-text">介绍一下 hard negative mining(难样例挖掘)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#dropout内部是怎么实现的"><span class="nav-text">dropout内部是怎么实现的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下BN"><span class="nav-text">简述一下BN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#各种初始化方式，及公式各个参数对训练的影响"><span class="nav-text">各种初始化方式，及公式各个参数对训练的影响</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测，数据不平衡问题怎么解决"><span class="nav-text">目标检测，数据不平衡问题怎么解决</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的zerotensor和TF比性能上有优势吗"><span class="nav-text">你的zerotensor和TF比性能上有优势吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常用的数据增强技术"><span class="nav-text">常用的数据增强技术</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有哪些可以避免过拟合的办法"><span class="nav-text">有哪些可以避免过拟合的办法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则化L1和L2的区别"><span class="nav-text">正则化L1和L2的区别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#rcnn。。"><span class="nav-text">rcnn。。</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#推导svm"><span class="nav-text">推导svm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积层的参数个数计算公式是："><span class="nav-text">卷积层的参数个数计算公式是：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"><span class="nav-text">梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于各种激活函数的解析与讨论"><span class="nav-text">关于各种激活函数的解析与讨论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述ResNet"><span class="nav-text">简述ResNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#嵌入式开发很底层-一般还是倾向于做一些上层的东西"><span class="nav-text">嵌入式开发很底层   一般还是倾向于做一些上层的东西</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#推导SVM"><span class="nav-text">推导SVM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#比较Boosting和Bagging的异同"><span class="nav-text">比较Boosting和Bagging的异同</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#无监督学习中存在过拟合吗"><span class="nav-text">无监督学习中存在过拟合吗?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是K折交叉验证"><span class="nav-text">什么是K折交叉验证?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于k折交叉验证-需要注意什么"><span class="nav-text">关于k折交叉验证, 需要注意什么?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化"><span class="nav-text">对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#增加网络层数-是否总能减小训练集错误率"><span class="nav-text">增加网络层数, 是否总能减小训练集错误率?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在目标检测问题上-如何做数据增广"><span class="nav-text">在目标检测问题上, 如何做数据增广?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#softmax怎么跟交叉熵损失函数结合"><span class="nav-text">softmax怎么跟交叉熵损失函数结合?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值"><span class="nav-text">用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有没有自己试过更改模型的框架"><span class="nav-text">有没有自己试过更改模型的框架.</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升"><span class="nav-text">说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高"><span class="nav-text">SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#池化的优点-优化的缺点"><span class="nav-text">池化的优点, 优化的缺点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#待定"><span class="nav-text">待定</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#完善bisai待看"><span class="nav-text">完善bisai待看</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#谈谈你参加的比赛"><span class="nav-text">谈谈你参加的比赛</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于一个新任务-你一般都会使用那些数据预处理方法"><span class="nav-text">(对于一个新任务,) 你一般都会使用那些数据预处理方法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#比赛中用到的模型融合方法"><span class="nav-text">比赛中用到的模型融合方法:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的方法与其他人方法的区别是什么-为什么比别人的方法差"><span class="nav-text">你的方法与其他人方法的区别是什么? 为什么比别人的方法差?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于faster-rcnn-你都调了哪些参数"><span class="nav-text">对于faster rcnn 你都调了哪些参数?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BN具体是什么实现的"><span class="nav-text">BN具体是什么实现的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于平均移动了解吗"><span class="nav-text">对于平均移动了解吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#积分图-快速求矩阵的核"><span class="nav-text">积分图, 快速求矩阵的核</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#样本不均衡问题怎么解决"><span class="nav-text">样本不均衡问题怎么解决</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#详细说一下Focal-Loss"><span class="nav-text">详细说一下Focal Loss</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#说一下为什么Faster-比YOLO和SSD更准确"><span class="nav-text">说一下为什么Faster 比YOLO和SSD更准确</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#样本采样的理论化值是"><span class="nav-text">样本采样的理论化值是</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#anchor的参数设值怎么选的？-为什么这么设置"><span class="nav-text">anchor的参数设值怎么选的？  为什么这么设置</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在调试RPN网络时有没有遇到什么问题？"><span class="nav-text">在调试RPN网络时有没有遇到什么问题？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下faster-rcnn模型"><span class="nav-text">简述一下faster rcnn模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下ResNet模型及它解决的问题"><span class="nav-text">简述一下ResNet模型及它解决的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#如何优化CNN-Backbone"><span class="nav-text">如何优化CNN Backbone</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的显存利用率和GPU算力利用率如何达到最高？"><span class="nav-text">你的显存利用率和GPU算力利用率如何达到最高？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么要压缩模型，而不是直接训练一个小模型"><span class="nav-text">为什么要压缩模型，而不是直接训练一个小模型</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZeroZone</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">2.5m</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">37:45</span>
  
</div>










  <div class="footer-custom">勤练带来力量</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.3.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  





  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>


</body>
</html>
